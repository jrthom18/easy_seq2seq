until i started answering this question, i hadn’t realised that using the &amp; control operator to run a job in the background starts a subshell
btrfs balance status /mountpoint   man 8 btrfs   [filesystem] balance status [-v] &lt;path&gt;         show status of running or paused balance.          options          -v   be verbose  
use the eval command.  eval "echo \${machine${counter[0]}}"   notice that the first $ is escaped so that it isn't evaluated until eval processes the string.  the way this works is that eval executes a command the same as if you had typed it at the command prompt
traditional unix permissions are limited to owner, group and other
with awk read file2 first and save $1 in seen[$1] then read file1 and if $1 wasn't "seen" replace it with nomatch:  awk 'fnr==nr{seen[$1]++; next} {(fnr==1 || ($1 in seen)) || $1="nomatch"};1' file2 file1   if you prefer join, you need sorted input
from the inputs gathered from the folks above (rahul and julie pelletier), i was able to install kernel package from a specific repo by disabling the repo you don't want to include (in my case it is rhel_7_0 repo).  yum --disablerepo rhel_7_0 install -y kernel   then i was able to install kernel from rhel_7_2 repo inside my rhel 7.0 box and boot successfully.  [root@desktop2 ~]# yum list kernel loaded plugins: product-id, subscription-manager this system is not registered to red hat subscription management
&gt; is not a command but a file descriptor redirection
i was just looking for the very same thing
if you have a /proc filesystem, the file /proc/modules exists if and only if the kernel if compiled with module support
try creating subshell with (...) :  ( command_which_takes_time input &gt; output ) &amp;   example:  ~$ ( (sleep 10; date) &gt; /tmp/q ) &amp; [1] 19521 ~$ cat /tmp/q # enter ~$ cat /tmp/q # enter (...) #after 10 seconds ~$ cat /tmp/q #enter wed jan 11 01:35:55 cet 2012 [1]+  done                    ( ( sleep 10; date ) &gt; /tmp/q )  
to replace a single 0 on a line:  sed 's/^0$/x/'   ^ matches the beginning of the line  $ matches the end of a line  so the above command matches the beginning of a line, followed by 0, followed by the end of the line
use find in conjunction with xargs
you can write a single wrapper script that executes a jar named after the way it's called, and make one symbolic link for each jar
i have worked out how to do this
here's a small implementation of what you want in python (run it as server.py &lt;port&gt;:  #!/usr/bin/env python  import socket import sys  _, port = sys.argv  sock = socket.socket(socket.af_inet, socket.sock_stream) sock.bind(("0.0.0.0", int(port))) sock.listen(1)  while true:     conn, addr = sock.accept()     ip, port = addr     conn.send(ip.encode("ascii") + b"\n")     conn.close()     $ ./server.py 1234 &amp; [1] 20315 $ nc localhost 1234 127.0.0.1 $  
ibus is known to do this (at least on 14.04)  see https://bugs.launchpad.net/ubuntu/+source/ibus/+bug/1278569 
you are right
to rip an audio cd you should really use a tool such as cdparanoia.  this will handle jitter and error correction, will retry as necessary, and try to create a "perfect" datastream.  typically you would use this to create the wav files, which can then be converted to flac format as necessary.  there are other tools, including some front end guis, that can talk to external databases like cddb to automatically work out the album and track names, but for raw audio ripping cdparanoia is hard to beat. 
you can do this directly from the shutdown command, see man shutdown:  synopsis    /sbin/shutdown [-akrhphffnc] [-t sec] time [warning message]  [...]     time   when to shutdown.   so, for example:  shutdown -h 21:45   that will run shutdown -h at 21:45
you can split and open a new file at the named tag with the command :stag, it appears to default to the binding ctrl-w, ctrl-].  you could bind that to whatever then:  map &lt;f2&gt; :stag   if needs to be done in a tab, then, you can do it in two steps:  ctrl-w,ctrl-] ctrl-w, t  or you can map it:  map &lt;f2&gt; :tab split &lt;cr&gt;:exec("tag ".expand("&lt;cword&gt;"))&lt;cr&gt;   for the gf equivalent of opening in new tab  ctrl-w,gf   or window split:  ctrl-w,f      and again if you want to split and then open in new tab,  ctrl-w,f    ctrl-w, t 
bsdtar (based on libarchive) can filter tar (and some other archives) from stdin to stdout
from here.  me@host:~$ date -d @1286536351.746 fri oct  8 11:12:31 utc 2010  
this was the suggested solution by don_crissti, and i am providing an explanation of it here for users just getting started with unix and linux
you could use another character that cannot appear in a file name: / so once you got your list of files you know that paths are separated by two slashes: // (the second being part of the path as each path starts with a slash but doesn't end with one)
5,6) 9pins is usually enough, the extra pins are secondary data or extra hand shake
the problem is that your asterisk is interpreted by the shell before it is passed to find as an argument.  i.e
when you write:  alias thm="cd $set_dir/sites/all/themes/"   you're expanding the value of set_dir at the time you define the alias
debian does not provide a single command to upgrade the os to a new release
this is not distro specific so much as desktop environment or window manager specific
i have always used unison in a star topology to synchronise my four machines
follow these steps to reset the xfce panel, and please note that instead of permanently deleting those files which are deleted in the following steps, you can also just move them to a different place.   first quit the panel:  xfce4-panel --quit  kill the xfce notification daemon, xfconfd:  pkill xfconfd  delete the panel settings:  rm -rf ~/.config/xfce4/panel  clear the xfconfd settings:  rm -rf ~/.config/xfce4/xfconf/xfce-perchannel-xml/xfce4-panel.xml  restart the panel:  xfce4-panel    now your panel should have its default settings.  references   resetting xfce panels to default settings?  
gnome should have screenshot abilities built already in.    however, the default trigger is the print key, which your keyboard may lack
when you pipe the output of curl into sh you're making the script text be standard input of the shell, which takes it in as commands to run
i realised that i had already tried the solution, but it did not work because i did not have sshd listening on the vpn interface i was using
it is usually true on unix systems that the number of links to a directory is the number of subdirectories plus 2
installed through wine, works :) 
as a workaround you can use display_filter setting  add to your .muttrc:  set display_filter="sed -e '/^tags:.*/d'"  
we can apply something like this code in bash:  #!/bin/bash  data[0]="     _/  _/    _/                            _/    " data[1]="  _/_/_/_/_/  _/_/_/      _/_/_/    _/_/_/  _/_/_/ " data[2]="   _/  _/    _/    _/  _/    _/  _/_/      _/    _/" data[3]="_/_/_/_/_/  _/    _/  _/    _/      _/_/  _/    _/ " data[4]=" _/  _/    _/_/_/      _/_/_/  _/_/_/    _/    _/  "  # virtual coordinate system is x*y ${#data} * 5  real_offset_x=0 real_offset_y=0  draw_char() {   v_coord_x=$1   v_coord_y=$2    tput cup $((real_offset_y + v_coord_y)) $((real_offset_x + v_coord_x))    printf %c ${data[v_coord_y]:v_coord_x:1} }   trap 'exit 1' int term trap 'tput setaf 9; tput cvvis; clear' exit  tput civis clear  while :; do  for ((c=1; c &lt;= 7; c++)); do   tput setaf $c   for ((x=0; x&lt;${#data[0]}; x++)); do     for ((y=0; y&lt;=4; y++)); do       draw_char $x $y     done   done done  done   source http://wiki.bash-hackers.org/scripting/terminalcodes 
you just chain the commands 1
how do i tell what sort of data (what data format) is in a file? → use the file utility.  here, you want to know the format of data in a device file, so you need to pass the -s flag to tell file not just to say that it's a device file but look at the content
talking about "option 2", it's not a good idea to mount an already mounted remote directory
so...the format of an awk program is a series of expression { action } statements
this is the result of an editing error in the e2fsprogs patch debugfs: add support to properly set and display extended timestamps
i have used taskset for this
posix  searching through the specification for the strings "user config" or "configuration files" turned up zero hits, so i would say no it doesn't specify this in any way.   http://pubs.opengroup.org/onlinepubs/9699919799/   fhs  looking at the fhs - filesystem hierarchy standard it had this bit:     user specific configuration files for applications are stored in the user's home directory in a file that starts with the '.' character (a "dot file")
this question had the answer that i needed
you can build the latest gnome shell (sandboxed) using jhbuild pretty easily, as explained here.  note that this doesn't care about which distribution you're using, so there might be another way, i.e., some fedora analogue of using experimental packages on debian, that i don't know of
simple awk command:  awk 'nr%2==0{ print $0 &gt; "file "++i }' rs='"' file   rs defines " as record separator and nr is the record number
debian versions of mysql packages store the mysql data in /var/lib/mysql directory by default
you want to use the --to-command option of tar:  tar xf tarfile.tar --to-command='sh -c "mkdir -p $(dirname $tar_filename) &amp;&amp; base64 -d &gt; $tar_filename"'   this is described in the manual here.  backup-specs is part of the backup system the manual claims is distributed with tar, however my system lacks this and i don't think actually uses it, at least not anymore. 
i had the same problem... you have to include sslprotocol all -sslv2 -sslv3 within every virtualhost stanza in httpd.conf  the virtualhost stanzas are generally towards the end of the httpd.conf file
i rewrote script
you can do it with awk, the idea is to run a substitute command on columns 3 and 4 to replace the single quote with a blank
i fixed this by adding   package: * pin: release o=lp-ppa-gwendal-lebihan-dev-cinnamon-stable pin-priority: 800  to the file in etc/apt/ called preferences (increase 800 to whatever is higher than everything else)  i also had to install muffin and nemo (from that ppa) to get it to run...  however - i'm having other problems now with muffin not launching. 
 load the kernel module: modprobe snd-aloop use plughw:card=loopback,dev=0 device for recording use plughw:card=loopback,dev=1 device for playing (or vice versa).  
the new folder is not created until you actually provide a name, normally by typing something in what looks like a directory/folder name in the currently open directory/folder in the manager
you probably don't need to extract the drivers from your windows install
7z and lzma are the same compression algorithm, with a different container
the solution was pretty elegant and simple: editing /etc/inputrc and disabling vi mode.  here's the renewed inputrc file:  # /etc/inputrc - global inputrc for libreadline # see readline(3readline) and `info rluserman' for more information.  # be 8 bit clean. set input-meta on set output-meta on  #set editing-mode vi  # to allow the use of 8bit-characters like the german umlauts, uncomment # the line below
the answer to this question can range from a simple command, to complex monitoring tools, depending on your needs.  you can start by simply running top -b -n 1 &gt;&gt; file.txt (-b for batch mode, -n 1 for running a single iteration of top) and store the output (appended) in the file.txt
well, you can omit the dot caracter for folders if you wish but the both are ok  cd ./bar   or  cd bar   are equivalent - but you'll agree that the second is more convenient.  if you want to execute your bar.txt file (which may be executable with chmod 755 for example) then you have to use the ./ indicator  ./bar.txt will execute the script  bar.txt will do nothing  cat bar.txt or cat ./bar.txt will do the same.  hope that help :)  edit: if you want to have more information about why ./ is needed to run script, just follow: http://stackoverflow.com/questions/6331075/why-do-you-need-dot-slash-before-script-name-to-run-it-in-bash      because on unix, usually, the current directory is not in $path.   when you type a command the shell looks up a list of directories, as > specified by the path variable
the echo built-in performs backslash expansion on your system (this is configurable, and the default is system-dependent)
with awk  awk 'fnr==nr{   a["&gt;"$1]=$2;next } $1 in a{   sub(/&gt;/,"&gt;"a[$1]"|",$1) }1' file2 seq.fa   get the scaf value from file2 and save it in an array a with index "&gt;"$1.  if $1 of seq.fa is an index in array a substitute the $1 to include the scaf value a[$1] after &gt;.  then print all lines in seq.fa 
this line  x=123 echo $x   is evaluated in the following order:   $x is exapanded to the value of x in the current shell. the value of x in the environment of the command to be executed is set to 123 the expanded command line is searched for a command, and echo is found. echo is run in an environment where x is set to 123, and $1 is set to  whatever value x had in step 1. echo outputs $1 to standard output, but otherwise ignores the other values  in its environment.   note that $x as an argument is separate from the x that precedes the command. 
you want the cflags environment variable.  for example:  $ export cflags='-ggdb3' $ make test cc -ggdb3    test.c   -o test  
this is dependent on that editor you use.  if vim you can use esc and :wq or esc and shift+zz
naive solution:  git rev-list --all | xargs -n1 git ls-tree --full-name -r --name-only  | sort -u   this lists all commits, then uses that to list all files in every commit
assuming you have access to the password database, something like john the ripper could help you
thank you for the link in your comment, jigglynaga
if you install compiz config settings manager with:  sudo aptitude install compizconfig-settings-manager  you can then enable this functionality with grid mode
this looks like the dec special graphics character set.  reading the xterm control sequences docs, it sounds like the terminal uses those when receiving esc ( 0.  so you should be able to reproduce using  printf '\033(0'   or  printf '\033(0' &gt; corrupt-my-terminal cat corrupt-my-terminal   and get back using  printf '\033(b'   which according to the same page selects usascii.    other ways to restore the state include  tput sgr0  # resets all terminal attributes to their defaults   and  reset      # reinitializes the terminal   you could tput sgr0 in your prompt_command (bash), or precmd (zsh) to ensure it always gets reset automatically.    or you could just make sure to use less, vim, or anything other than cat to view a file.  to make less act like cat and automatically quit if the file is under one page long, run less -fx, or do export less=-fx.  or if you don't want to always use those less options, make a new alias, e.g.  alias c='less -fx'  
it is a security risk
to get this information from sysfs for a device file, first determine the major/minor number by looking at the output of ls -l, eg   $ ls -l /dev/sda  brw-rw---- 1 root disk 8, 0 apr 17 12:26 /dev/sda   the 8, 0 tells us that major number is 8 and the minor is 0
did you mean to type -onlcr  you wrote -onclr 
linux stores time internally, regardless of your hardware clock (a.k.a
look up dlna
it is completely dependent on the tool
there is loopback device for that:  https://github.com/umlaeute/v4l2loopback  just add device with modprobe and stream to it with ffmpeg or gstreamer whatever video you want, or anything else for that matter: https://github.com/umlaeute/v4l2loopback/wiki 
you can do this with bash by using read and parameter substitution/expansion/splitting
virtual packages and the debian alternatives system (which is where binaries come into play) are related but not the same
if you add the new directory to your path environment variable temporarily, the command launcher window (alt-f2) will not find it
simply re-register each bcache device in the cache set (both backing and cache devices) to the kernel:  echo /dev/&lt;path_to_device&gt; &gt; /sys/fs/bcache/register   or, if the udev rules from bcache-tools are in place, then partprobe will automatically register the devices when they are scanned. 
if you have space, please back up the disk as a whole (e.g
you can use -o for logical or
even though it isn't mentioned in the procmail manual, i believe (i haven't checked) that putting a backslash before the space removes its special meaning (like in other parts of procmail).  :0 * from: .*stack\ exchange stack\ exchange/   if that doesn't work, use a variable.  stackexchange_mailbox=stack exchange :0 * from: .*stack\ exchange $stackexchange_mailbox  
nothing particular happens
using awk and reading the file twice
you could do it like this using ffmpeg
this is documented (at least for gnome-shell/nautilus) in gvfs-udisks2-volume-monitor:  the gvfs-udisks2-volume-monitor process is responsible for the disks, media, mounts and fstab entries shown in the desktop user interface. .......................................... a device is either mounted (in which case its directory is known) or it's not
you can try this one:  top -p "$(pidof &lt;process_name&gt; | awk 'ofs="," { $1 = $1; print; }')"  
if you  insist to do it with sed:  ( sed 1q file2.csv; sed 1d file1.csv ) &gt;file3.csv &amp;&amp; mv file3.csv file1.csv   without sed:  ( head -1 file2.csv; tail -n +2 file1.csv ) &gt;file3.csv &amp;&amp; mv file3.csv file1.csv  
you'll laugh at me for this one - so stupid!  it turns out i had num lock on, but the light was to weak to see it was on
have you set gnome-terminal to use dark theme in the preferences of it? 
it may be a bug in the filesystem driver for fat32 on recent versions of osx
you should really not worry about a temperature of 50-60°, that's normal
according to _syscall(2) man page the _syscall0 macro may be obsolete and requires  #include &lt;linux/unistd.h&gt;; indeed linux 4.x don't have it   however, you might install musl-libc and use its _syscall function.  and you could simply use the indirect syscall(2) in your user code
umask 002   files (and directories) after this will be created with 0664 permissions. 
you could try killing off the individual processes that are still running as you, or just purge the system of everything running as you: pkill -u username 
fedora core 3 reached end of life on january 16th, 2006
it depends on the filesystem
while trying to answer my own question i tried some different things and it all worked out by experimenting.  1) i am guessing that "enabling clicolor" means to set it to 1 (i.e
as people in the comments have pointed out, it's possible to use smb/cifs,nfs, or use scp
since neither don_crissti nor julie pelletier have converted the perfectly good comment into an answer, here's what don came up with:  sed 's/[[:blank:]]*=[[:blank:]]*/=/g'   ..
tehehe, you got the schema behind the command line wrong
if you want to list all the users, that own a file in the current directory, you can use this command:  ls -la | tr -s ' ' | cut -f3 -d ' ' | sort | uniq  it lists all the files with ls -la, then collapses the multiple spaces into single ones with tr -s ' ', so we can use cut -d ' ' -f3 to get the 3rd column of the output
(strange situation, doesn't something like the triangle inequality hold for internet routing?)  anyway, try the following, on a, ssh into b with a -d argument,  ssh -d 1080 address-of-b   which acts as a socks5 proxy on 127.0.0.1:1080, which can be used by anything supporting socks5 proxied connections
add term at386 to your .screenrc in order to override term
useradd  you can control how long a user's account is valid through the use of the --expiredate option to useradd
in /var/lib/dpkg/info are .list text files that list all the files contained in each package¹ installed through debian's package manager.  finding all files in the filesystem not matching any entry there can be achieved with something naïve like this:  find / -xdev -type f \( -exec grep -xq "{}" /var/lib/dpkg/info/*.list \; -or -print \)   this will obviously take a very long time as the whole filesystem will be scanned
judging by the specific output connection to connection to 10.1.0.100 53 port [udp/domain] succeeded! you are using openbsd-netcat
as suggested by @dave_thompson_085, putting the ip address to resolve to first and the hostname after this is correct.  example:  0.0.0.0 node1 0.0.0.0 node2  
you could use an open source ocr engine, say tessaract, in order to figure out is there an english text or not. 
echo "1 abcd 2 1 efg 2 hij 3 klmnopqrs 5 tuv 6 5 wxyzäüö 6" |  perl -lne '     @out = ();     /1 (.+?) 2/                 and push @out, $1;     /.+2 \k(.+?) 3 (.+?)(?= 5)/ and push @out, $1, $2;     /(5.+?6)/                   and push @out, $1;     /.+5 (....)/                and push @out, $1;     print join " ", @out '     abcd hij klmnopqrs 5 tuv 6 wxyz     we need to take care to escape the regex special chars properly:  perl -lne '     @out = ();     /\((.+?)\)/                 and push @out, $1;     /.+\) \k(.+?)\.(.+)(?= \[)/ and push @out, $1, $2;     /.+\[(....)/                and push @out, $1;     print join " ", @out ' &lt;&lt;end (test)(te st) tesst
according to man rc:      the following characters are special: # ; &amp; | ^ $ = ` ' { } ( ) &lt; >   the  single  quote  (')  prevents  special treatment of any character other than itself.   so = is a special char which you need to escape
most laptops require pressing fn to get the sysrq key
you can know about each processor core by examining each cpuinfo entry:  processor       : 0 [...] physical id     : 0 siblings        : 8 core id         : 0 cpu cores       : 4 apicid          : 0  processor       : 1 [...] physical id     : 0 siblings        : 8 core id         : 1 cpu cores       : 4 apicid          : 2   processor       : 2 [...] physical id     : 0 siblings        : 8 core id         : 2 cpu cores       : 4 apicid          : 4   processor       : 3 [...] physical id     : 0 siblings        : 8 core id         : 3 cpu cores       : 4 apicid          : 6  processor       : 4 [...] physical id     : 0 siblings        : 8 core id         : 0 cpu cores       : 4 apicid          : 1  [and so on]   physical id shows the identifier of the processor
nohup should only affect the hangup signal
you can do so by modifying the xorg.conf by adding the line   section "monitor"      identifier      "monitor1"      option  "rotate"        "left" endsection   or after login use the xrandr command as:     xrandr --output dvi-2 --rotate left   replace dvi-2 and left as per your requirement  xrandr solution will be effective till session exist
if they are aliases, you'll have to write it:  myfunction() {   export some_var=/path/to/main/folder   
in english, this sed program means: for each line,   [123!] if the current line number is not 123, then [d] delete the current line and start the next cycle (i.e
looking at the man page for lsdev there is this comment:     this program only shows the kernel's idea of what hardware is present, not what's actually physically available.   the output of lsdev is actually just the contents of the /proc/interrupts file:  excerpt from man proc     /proc/interrupts         this  is  used to record the number of interrupts per cpu per io          device
here's a perl one-liner that will do what you want:  perl -e '$sig{chld} = sub{exit 0}; open $fh, "|-", @argv or die; sleep 20 while 1;' /usr/bin/program   it's essentially the same as a mythical* sleep forever | /usr/bin/program, except it also watches for the program to finish, and will quit immediately when it does
thanks to @slm for sending me to the how-to reference
the solution was to use the disk manager utility
what you see in c is using threads, so the process usage is the total of all its threads
it appears that all of those were automatically installed as dependencies of the gnome metapackage
// is a special case, covered in the posix definition of the word "pathname":     multiple successive &lt;slash&gt; characters are considered to be the same as one &lt;slash&gt;, except for the case of exactly two leading &lt;slash&gt; characters.   on most systems // is the same as /, but it is allowed to be different according to posix.  further reading:   on what systems is //foo/bar different from /foo/bar? how does linux handle multiple consecutive path separators (/home////username///file)? unix, difference between path starting with &#39;/&#39; and &#39;//&#39;   (i think the first of these links is the best.) 
for adding multiple tor services in the same server, it is as simple as editing /etc/tor/torrc and adding two lines per each service, each with it´s own directory under /var/lib/tor/ ;  for instance, to launch another two web sites in the same server, you can leave in the right side also port 80, and in the left side, using another port in the localhost side as in:  hiddenservicedir /var/lib/tor/www2_service/ hiddenserviceport 80 127.0.0.1:8080  hiddenservicedir /var/lib/tor/www3_service/ hiddenserviceport 80 127.0.0.1:8081   i would add a note that the part of leaving as the tor side the port 80 for several sites is a welcomed facility, as it does not obliges the user to add a port after a url to access an onion site/service, allowing the mapping of tcp-based services in their canonical ports to ports of your own choice in the local server.  nginx would then be configured with 2 new vhosts:  server {     listen 127.0.0.1:8080;     server_name zyew6pdq6fv4i6sz.onion;     ... }  server {     listen 127.0.0.1:8081;     server_name yyew6pdh6hv1i3sy.onion;     ... }   if also need arises to temporarily to access the ssh service via tor as a poor man's vpn, and to bypass firewall rules, a 4th entry to the /etc/tor/torrc file can also be added:  hiddenservicedir /var/lib/tor/ssh_service/ hiddenserviceport 22 127.0.0.1:22   as mentioned in how to create a darknet/tor web site in linux?, after you run:  service tor reload   the directories will be created, and inside of each of the new directories, two files are generated automatically, hostname and private_key.  the content of the hostname file inside each directory with be the new .onion address by which the corresponding new services can be used inside the tor network. 
how about using two different configuration files for tsocks?  according to this manpage, tsocks will read its configuration from the file specified in the tsocks_conf_file environment variable
you should edit the file /etc/default/console-setup and change the fontsize variable
instead of:  ls /var/log/hello grep -i hello.log
in bash you can use extglob:   $ shopt -s extglob  # to enable extglob  $ cp !(b*) new_dir/   where !(b*) exclude all b* files.  you can later disable extglob with   $ shopt -u extglob  
instead of specifying numbers, you can do  unset histsize  unset histfilesize shopt -s histappend   in which case only your disk size (and your "largest file limit", if your os or fs has one) is the limit.  however, be aware that this will eventually slow down bash more and more
depending on the kind of files you are working with, you could use a git repository on the stick.  just push your work to the stick, move it to the other box and pull all the changes
one way with sed:  sed -e 's/[".]//g' &lt;file  
if i recall correctly, yum should retry from different mirrors until one works, as mine would keep trying at school since the http ones were all blocked, though this could help: http://fedoranews.org/tchung/yum-mirrorlist/ 
this file is under a directory matching the pattern, use:  ls -d ./[[:upper:]]*   by default, when passed a directory name as argument, ls displays its content, not its name
short summary of the page suggested by don_crissti:  scattering utilities over different directories is no longer necessary and storing them all in /usr/bin simplifies the file system hierarchy
cpu has not drivers! the only thing a cpu has, is a microcode which is usually distributed by intel and used as is at boot to patch the microcode of the cpu
if you need it for a build, then you need the #include headers as well
i decided to go for a work-around..
this works for me the best:   install htop
in the settings manager choose window manager tweaks, then on the third tab, accessibility you will find the control key used to grab and move windows:   
xubuntu.  xfce looks better and is less spartan than lxde, i've kept the beloved ubuntu, xfce's panel is great, compiz-fusion works, drag-and-drop is no problem between thunar (xfce's file manager) and nautilus (gnome's one) and the desktop
this is not possible.  "note that a bridge cannot be established over wi-fi networks operating in ad-hoc or infrastructure modes
it's a somewhat standard keyboard shortcut (it works in konsole, too).  it's simply bound to reduce font size (and simmetrically, ctrl+ to increase font size).  you can easily disable/modify by going to the shortcuts preferences. 
check the script for windows line endings by logging in on the server and running  cat -v /path/to/script   if the line ends with ^m, that is the problem
the short answer is 0, because entropy is not consumed.  there is a common misconception that entropy is consumed — that each time you read a random bit, this removes some entropy from the random source
paste file1 file2 | awk '{ print $1 + $2; }' &gt; file3 
you can use gs - ghostscript (postscript and pdf language interpreter and previewer) as follows:   set pdfwrite as output device by -sdevice=pdfwrite use the appropriate -dpdfsettings.  from documentation:     -dpdfsettings=configuration   presets the "distiller parameters" to one of four predefined settings:         /screen selects low-resolution output similar to the acrobat distiller "screen optimized" setting.   /ebook selects medium-resolution output similar to the acrobat distiller "ebook" setting.   /printer selects output similar to the acrobat distiller "print optimized" setting.   /prepress selects output similar to acrobat distiller "prepress optimized" setting.   /default selects output intended to be useful across a wide variety of uses, possibly at the expense of a larger output file.     -o option to output file which also set -dnopause and -dbatch (see interaction-related parameters)     example:  $ du -h file.pdf  27m file.pdf     $ gs -sdevice=pdfwrite -dpdfsettings=/ebook -q -o output.pdf file.pdf     $ du -h output.pdf  900k    output.pdf   here -q suppress normal startup messages, and also do the equivalent of -dquiet which suppresses routine information comments 
edit  /etc/mdm/mdm.conf   and set  automaticloginenable=false  
a terminal is at the end of an electric wire, a shell is the home of a turtle, tty is a strange abbreviation and a console is a kind of cabinet.  well, etymologically speaking, anyway.  in unix terminology, the short answer is that   terminal = tty = text input/output environment console = physical terminal shell = command line interpreter     console, terminal and tty are closely related
to avoid shell-dependent effects, pass a full path to .
just upgrading sshd typically won't replace the host key
. is an internal shell command
install the package pdfgrep, then use the command:  find /path -iname '*.pdf' -exec pdfgrep pattern {} +  
tl;dr: tar -cv dir | wc -c - | cut -d' ' -f 1 | awk '{print $1/1000"k"}'  du doesn't actually count the size of the file itself
you, glen, are the owner of the directory (see the . file in your listing)
assuming usernames are one per line  or separated by one or more spaces, in the listfile, you can use this :   for user in $(cat listfile)  do     useradd -m -d /home/top100/${user} ${user}  done  
you can use the -y switch:  $ yum -y install php54w   excerpt from the yum man page  -y, --assumeyes       assume yes; assume that the answer to any question which would be asked       is yes
space doesn't get allocated to directories, so it's impossible to utilize all the space allocated to a directory.  space gets allocated to filesystems.  (if you don't understand what a "filesystem" is, think of it, to a first approximation, as a partition.)  filesystems contain directory trees; a filesystem is generally referenced by the name of the directory at the top of its tree.  so, for example, you always have a / filesystem; /home, /usr, and /tmp are frequently separate filesystems.  things like /proc and /sys are special file systems; sometimes /dev and/or /devices are, also.  they don't take up any real disk space at all (or very little), so let's ignore those for the moment.  to find out what filesystems your system has, run the mount command.  you should get output something like this:   /dev/sda5 on  /  type ext4 (rw,errors=remount-ro) proc on /proc type proc (rw,noexec,nosuid,nodev) sysfs on /sys type sysfs (rw,noexec,nosuid,nodev) tmpfs on /tmp type tmpfs (rw,noexec,nosuid) udev on /dev type devtmpfs (rw,mode=0755) devpts on /dev/pts type devpts (rw,noexec,nosuid,gid=5,mode=0620) none on /run/lock type tmpfs (rw,noexec,nosuid,nodev,size=5242880) /dev/sda6 on /mydata type ext2 (rw) /dev/sda7 on /backup type vfat (rw) /dev/sdb on /media/myusb type vfat (rw,nosuid,nodev)  the directory names that appear as the third word on each line (after the on) are the mounted filesystems.  so anything of the form /proc/something is in the /proc filesystem, anything of the form /backup/something is in the /backup filesystem, and so on.  everything else under the sun is part of the / filesystem.  this gives you a first idea of where you need to be looking.  also, of course, the df command lists your filesystems along with total size, used space, and available space.    find / -type d -print   will list all the directories in the system.  if your version of find supports it,  find / -maxdepth 2 -type d -print   will list all the directories in the first two levels; i.e., it will include /usr/share but not /usr/share/man.  and  find / -xdev  -maxdepth 2 -type d -print   or  find / -mount -maxdepth 2 -type d -print   will list the first two levels of directories in the / filesystem.  this gives you a better idea of where you need to be looking.    but, if your system supports this, you can go one better:  du -x -d2 /   or  du --one-file-system --max-depth=2 /   will show you the space used in each directory in the first two levels of directories in the / filesystem.  (note that it shows cumulative totals; e.g., the number shown for /usr includes files in /usr/bin, /usr/share, etc.)  this can help you find out where your disk space is being used.  (sorting it by size is a useful trick to find the directories that are using the most space.) 
as for me more secure way to use find  find dir/* -prune -type d -name "[a-y]" ! -name "z" -exec mv -t dir/z {} +  
you can check /var/log/apt/history.log  when you issue apt-get install, it records the command line as commandline: record, and real packages installed as install: 
putting the following line in a script will do it:  grep -c "$1" ~/mydir/* | grep -v ':0' | sort -t: -k2 -r -n | head -1 | sed 's/:.*//' | xargs less   then just call ./myscript searchterm  if you want to search recursively, change -c to -cr in the first grep command.  the parts of this pipeline, in order:  grep -c "$1" ~/mydir/*    # outputs a list of the files in ~/mydir/ with :&lt;count&gt;                           # appended to each, where &lt;count&gt; is the number of                           # matches of the $1 pattern in the file.  grep -v ':0'              # removes the files that have 0 results from                           # the list.  sort -t: -k2 -r -n        # sorts the list in reverse numerical order                           # (highest numbers first) based on the                           # second ':'-delimited field  head -1                   # extracts only the first result                           # (the most matches)  sed 's/:.*//'             # removes the trailing ':&lt;count&gt;' as we're                           # done with it  xargs less                # passes the resulting filename as                           # an argument to less   if there is no match at all, less will open empty. 
the normal way to find what is preventing a filesystem from being unmounted is to list the processes that have a file open on it (or a file descriptor, or their current directory, etc.):  lsof /path/to/mount/point fuser -m /path/to/mount/point   review the list of processes and kill them if warranted.  there are also a few ways in which the kernel itself can have something going on that prevents the unmounting, for example if there is another mount point beneath it (e.g
it isn't possible from the mount command, because mount handles a variety of different filesystem types - including ones that might not support 'classic' ugo unix style permissions.  you are "stuck with" chown/chgrp/chmod
might you have something running that is watching for changes to that directory?  if i try this with nothing running but a shell prompt, the access time of ff matches the modify and change times
this should do the trick:  (awk '{printf "%s/", $2}' /proc/loadavg; grep -c processor /proc/cpuinfo;) | bc -l   also, you should get the load from /proc/loadavg where the command uptime also gets it. 
sysv init  the /etc/init.d/mountall.sh init script mounts local filesystems only:  mount -a -t nonfs,nfs4,smbfs,cifs,ncp,ncpfs,coda,ocfs2,gfs,gfs2,ceph -o no_netdev   other filesystems are mounted by separate init scripts, like for example /etc/init.d/mountnfs.sh, which declare (via lsb headers) their dependency on $network
as the name implies, roughly a pager is a piece of software that helps the user get the output one page at a time, by getting the size of rows of the terminal and displaying that many lines
a lot depends on what you have in your busybox and other commands
the bufname() command returns the filespec of the passed-in buffer number
you need to adjust the opacity of popup windows.  how to adjust opacity  the following instructions are applicable to xfce 4.8 and newer.   run setting manager from settings > settings manager or using command-line xfce4-settings-manager via terminal click on window manager tweaks and select compositor tab in the last entry, there is an option called opacity of popup windows:  drag the slider control until it reached furthest to the right (toward opaque) finally, click close button   now the popup menu is no longer transparent and fully opaque.  before: semi-transparent    after: fully opaque   
you are being asked for the passphrase for your private key, not for the password to your account
awk  $ some-command | awk '{print "hi "$1" bye"}'   sed  $ some-command | sed 's/\(.*\)/hi \1 bye/'   examples  using awk:  $ echo -e "john\nbob\nlucy" | awk '{print "hi "$1" bye"}' hi john bye hi bob bye hi lucy bye   using sed:  $ echo -e "john\nbob\nlucy" | sed 's/\(.*\)/hi \1 bye/' hi john bye hi bob bye hi lucy bye  
if it's raid 1, and if you know the data offset (e.g
you can use touch -r to use another file's timestamp instead of the current time (or touch --reference=file)  here are two solutions
i got it working with fetch mail and msmtp
finally i've found a solution.  it appears, that the setting is in dconf-editor after all
the iptables-save command has a very straightforward output
i think the clue is in the port numbers, take these two entries  smtpd   12950 postfix    9u  ipv4 35762406      0t0  tcp hostname:smtp-&gt;spe.cif.ic.ip:55277 (established) smtp    13007 postfix   13u  ipv4 35762309      0t0  tcp hostname:34434-&gt;fake.vvvvv.fr:smtp (established)   smtpd has received a connection on port smtp(25) from a high port number, whilst smtp connects to remote port smtp(25) and has a local high port number
not directly with logcheck
this is actually quite simple - all you need to do is change the home directory definition of that user's entry within /etc/passwd
first of all, the man files are usually just gziped text files somewhere in your file system
you need to open cinnamon settings => windows => uncheck "enable edge flip":   
when you run ssh example.com, the ssh daemon starts a login shell for you, and the login shell reads your ~/.profile (or ~/.bash_profile or ~/.zprofile or ~/.login depending on your login shell)
(disclaimer: i'm an arch user, never used slackware.)  the program that prints the quotes is usually called fortune
answer to 1.  try adding this to your emacs configuration file (should be ~/.emacs.d/init.el or alike):  (define-key global-map [(meta s)] [?\u00df])  
mailing list archives:  http://www.spinics.net/lists/hotplug/  git repository: http://git.kernel.org/?p=linux/hotplug/udev.git;a=summary  documentation: http://www.kernel.org/pub/linux/utils/kernel/hotplug/udev/ it's also in the source. 
i don't have references, but from memory try h (for headers).  there is also ? for other misc commands. 
xset dpms force off   works for most x setups. 
you can pretty easily get the return from any subshelled process by echoing its return out over its stdout
yes, your standard version is not posix-standard, as the question you linked to notes
ansi-c quoting  according to the bash manual, this is called ansi-c quoting
create a file /etc/mk.conf with something like the following:  wrkobjdir=/home/foo/build/ports distdir=/home/foo/build/distfiles package_repository=/home/foo/packages   the path can be to anywhere you want, so obviously replace /home/foo with the directory you want
if you don't want to use prinf you have a couple of of options, at least according to this so q&amp;a, titled: echo “-n” will not print -n?.  this seems to be your best option:  $ echo "x-n" | cut -c 2- -n   or some variation:  $ echo -- '-n'|cut -d" " -f2 -n   printf  printf doesn't have this issue:  $ printf "%s\n" -n -n  
if quora feans' answer does not help, you can add the option -i or --itemize-changes to get rsync to explain why it is updating the files
the kernel knows device numbers because it decides device numbers
stupid workaround, escape all the backslashes:  oldpassword="$(printf "$oldpassword" | sed 's/\\/\\\\/g')" sed -i "s/$oldpassword/$newpassword/g" myfile.txt  
sort -t '\t' -k9,9 -k14,14 -k16,16n   (remember you need to specify where sort keys start and where they end, otherwise (as in when you use -k9 instead of -k9,9) they end at the end of the line). 
not unless you taught the program to do so somehow (say, on receipt of a particular signal such as sigusr1 it reopens sys.stdout and sys.stderr on /dev/null)
it turns out that the reason dmidecode and lshw don't work is because the machines i was testing them on were virtual machines, apparently
no you can't, the permission of sysfs is defined in kernel space and can't be changed with userspace tools (unless with kernel side support).  but for your own problem, you could setup a sudo entry that allow everyone to write to that path, i.e all all = (all) nopasswd: /usr/bin/tee /sys/class/leds/asus\:\:kbd_backlight/brightness  and when you write to that directory, use a script like this, echo 1 | sudo /usr/bin/tee "/sys/class/leds/asus::kbd_backlight/brightness" 
     warning: doing anything to your filesystems without a known-restorable backup is ill-advised.     do not run any of the following steps if you're not sure your / is clean. if you're not sure, run the following (as root):  # touch /forcefsck   and reboot
here is how to do the other way around: forcing cron execution to use your login environment:  bash -lc "your_command"  from the bash manual:  -c string     if the -c option is present, then commands are read from string.               if there are arguments after the string, they are assigned to the                positional parameters, starting with $0. -l            make bash act as if it had been invoked as a login shell                (see invocation below).   invocation (a bit stripped):     when bash is invoked as an interactive login shell, or as a non-interactive shell with the --login option, it first reads and executes commands from the file /etc/profile, if that file exists
note that's the uuid of the filesystem (or other structured data with a uuid the udev scripts know about) on the partition, not the uuid of the partition itself (not all partitioning schemes give uuids to partition anyway)
i wrote the following script so that i could change my scale factor dynamically using keyboard shortcuts on my dell mini 10v netbook:   #!/bin/bash #/usr/local/bin/xrandr-scale-tool  #first, we read the config files if [ -r ~/.config/xrandr-scale-tool/xscale ]    then      xscale=$(~/.config/xrandr-scale-tool/xscale  fi if [ ! -e ~/.config/xrandr-scale-tool/output ]    then      output=lvds1      echo $output>~/.config/xrandr-scale-tool/output  fi if [ ! -e ~/.config/xrandr-scale-tool/baseresx ]    then      baseresx=1024      echo $baseresx>~/.config/xrandr-scale-tool/baseresx  fi if [ ! -e ~/.config/xrandr-scale-tool/baseresy ]    then      baseresy=600      echo $baseresy>~/.config/xrandr-scale-tool/baseresy  fi  #if they aren't readable, exit with status 1 if [ ! -r ~/.config/xrandr-scale-tool/xscale ] || [ ! -r ~/.config/xrandr-scale-tool/baseresx ] || [ ! -r ~/.config/xrandr-scale-tool/baseresy ] || [ ! -r ~/.config/xrandr-scale-tool/output ]    then      echo a config file could not be read      exit 1  fi  #now, we check the first argument to see what to do if [ -z "$1" ]   then     #restore from settings     xrandr --output $output --scale ${xscale}x${xscale} --panning 0x0+0+0     xrandr --output $output --scale ${xscale}x${xscale} --panning `xrandr -q | awk -f'current' -f',' 'nr==1 {gsub("( |current)","");print $2}'` fi  if [ "$1" == "+" ]   then     #increment and apply     amt=$2     xscale=`echo $xscale+$amt|bc`     xrandr --output $output --scale ${xscale}x${xscale} --panning 0x0+0+0     xrandr --output $output --scale ${xscale}x${xscale} --panning `xrandr -q | awk -f'current' -f',' 'nr==1 {gsub("( |current)","");print $2}'`     sleep 2     notify-send "scale factor: $xscale" --icon=display fi  if [ "$1" == "-" ]   then     #decrement and apply     amt=$2     xscale=`echo $xscale-$amt|bc`     xrandr --output $output --scale ${xscale}x${xscale} --panning 0x0+0+0     xrandr --output $output --scale ${xscale}x${xscale} --panning `xrandr -q | awk -f'current' -f',' 'nr==1 {gsub("( |current)","");print $2}'`     sleep 2     notify-send "scale factor: $xscale" --icon=display fi  if [ "$1" == "reset" ]   then     #reset     xscale=1     xrandr --output $output --scale ${xscale}x${xscale} --panning `echo $xscale*$baseresx|bc`x`echo $xscale*$baseresy|bc`     sleep 2     notify-send "scale factor: $xscale" --icon=display fi  #record changes in scale to file before exiting echo $xscale>~/.config/xrandr-scale-tool/xscale exit 0   this script assumes that your default resolution is 1024x600, and you're using the display on lvds1
while for tied arrays, you can use rici's answer, in the general case, you could do:  foo() {   eval "local array; array=(${(q)array[@]})"   ... }   the (q) is to quote the elements of the arrays
this depends on which desktop environment you are using.  in gnome, kde, unity and xfce the default keyboard shortcut for the run prompt is alt + f2.  as jofel pointed out, xdg-open is a desktop-independent tool for opening a file or url in a preferred application
i'm not that familiar with suse but on other distros you can use the service command to stop/start/restart services
you have three problems:   with read, if there are fewer variable names than fields in the input, the last var will be bound to all the remaining fields on the line, with delimiters
you do need to have unstable listed in your sources.list
a few possibilities:   bind the history-search-backward/forward commands
i prefer gawk for this:  awk -vofs='\t' 'nf{$1=filename ofs $1;$2=strftime("%c",$2)}1' filename.txt   here is one perl alternative too:  perl -nae 'print$argv,"\t",$f[0],"\t".localtime($f[1]),"\n"' filename.txt   as you also asked about bash, here is what it could do:  while read -r who when; do   readlink -n /proc/$$/fd/0   echo -en "\t$who\t"   date -d "@$when" done &lt; filename.txt   regarding sed, its usage would be hard and the benefit would be insignificant as it is unable to tell the name of its input file and to convert date. 
the memory represented by "buffers/cache" in free is your filesystem cache, which linux caches to speed up reading data from your disk, as hitting the disk is generally a fairly slow way to access data repeatedly
historically the original /bin/sh bourne shell would use $ as the normal prompt and # for the root user prompt (and csh would use %)
check if $ssh_client is empty as well as $display
something like this:  sources := $(wildcard source/*) targets := $(patsubst source/%.x, target/%.y, $(sources))  all: $(targets)  target/%.y: source/%.x     program -i $&lt; -o $@  
i found out that you can change the nameservers that dnsmasq uses by adding the following lines to /etc/dnsmasq.conf:  server=8.8.8.8 server=8.8.4.4   i didn't have a /etc/dnsmasq.conf file though, since it's installed by the dnsmasq package, but ubuntu only comes with dnsmasq-base
you can first remove all unneeded locales by doing:  $localedef --list-archive | grep -v -i ^en | xargs localedef --delete-from-archive   where ^en can be replaced by the locale you wish to keep  then  $build-locale-archive   if this gives you an error similar to   $build-locale-archive /usr/sbin/build-locale-archive: cannot read archive header   then try this  $mv /usr/lib/locale/locale-archive /usr/lib/locale/locale-archive.tmpl $build-locale-archive   if that still fails, check your version
to be able to execute as ./disk.py you need two things:   change the first line to this: #!/usr/bin/env python make the script executable: chmod +x disk.py  
gs is complaining about file arguments such as ---plaa---plaa.pdf because they look like long options but aren't.  workaround: precede the filename argument with a -- option to signal that there are no more options, or use a pathname such as ./---plaa---plaa.pdf. 
yes, the exec builtin ultimately makes use of one of the exec*() family of system calls
disclaimer: use this script on your own risk     what it does ?  as o/p wants, lat say he want to add somedomain.bar44.com and the somedomain44.bar44.com exists in zone then it should remove somedomain44.bar44.com and should be add somedomain.bar44.com into zone
on linux, you can find out which driver a network interface is using with this command:  ls -l /sys/class/net/&lt;interface name&gt;/device/driver   you can rmmod that unless it is statically linked into the running kernel (not likely for a distribution kernel and a wireless driver)
adobe’s flash plugin is not included in fedora because it is not free
the gzip error message states pretty much what is going on -- the file is being written to (by mysql in this case) during compression
you need to use function, not alias, so that  mancat () { man "$1" | cat ; } mancat grep   will do what you want.  similarly  mygrep () { "$1" "$3" "$2" | "$1" -v "$4" | "$5" -n1; } mygrep grep pattern1 file pattern2 head mygrep grep pattern1 file pattern2 tail   will grep for pattern1 in the file and then select only lines which don't match pattern2 (grep -v) and at the end select only first (or last) line. 
i'm going to assume you've got debian lenny and have your sourcelist geared towards the stable release which by default only has python2.5 (someone correct me?)  from a brief scan of their package tree, python3.1 exists in the debian sid (unstable) and debian squeeze (testing) tree. see here  you can w-get directly from the links provided, but that's often messy as you'll need to resolve any dependencies yourself through a game of what don't i have? with the cli.  if you're apt for switching your package tree to squeeze, you can change your /etc/apt/sources.list to match that of the squeeze tree
system-wide themes are stored in /usr/local/share/themes; user themes are stored in ~/.themes
perl's rename (as typically found on debian where it's also called prename), or this derivative (rename package on debian):  rename 's/\.tif$//' *.tif   util-linux rename (as typically found on red hat, rename.ul on debian):  rename -- .tif '' *.tif   (note that that one would rename blah.tiffany.tif to blahfany.tif) 
try with printf:   for((i=32;i&lt;=127;i++)) do printf \\$(printf '%03o\t' "$i"); done;printf "\n"   see also : bash faq 
in order to compile things on that system, it needs to have make, gcc, and a whole lot of other stuff that's not usually found on embedded devices
watch 'command | othertool | yet-another-tool'  
this is because the shell expands the variable in the command line before it actually runs the command and at that time the variable doesn't exist
actually, 3dd deletes what is to the left of the cursor.  you want 4d. 
yes, you can do this just with bash: redirect stdout to a tee process that can do something when your patterns are seen
as noted, this is jargon
unless you have a particular need for another uid or gid, the most suitable values are 0 and 0, respectively
here are some major problems with this solution :  tar tf test.tar|while read file;do echo $file $(tar xof test.tar $file|sha1sum);done   1-the tar of busybox cannot show differently filenames with newlines.  2-the "read" from shells does not handle backslash properly
since you are not using the default /boot/grub directory, you need to tell grub to use /boot/grub2:  grub-install --boot-directory=/boot/grub2 /dev/sda2  
use dpkg -l chntpw to show package contents, then look for paths in /usr/bin, /bin/ etc.  e.g dpkg -l wget shows the following output,  # dpkg -l wget /. /usr /usr/bin /usr/bin/wget /usr/share /usr/share/doc /usr/share/doc/wget /usr/share/doc/wget/readme /usr/share/doc/wget/changelog.debian.gz /usr/share/doc/wget/authors /usr/share/doc/wget/mailing-list /usr/share/doc/wget/copyright /usr/share/doc/wget/news.gz /usr/share/info /usr/share/info/wget.info.gz /usr/share/man /usr/share/man/man1 /usr/share/man/man1/wget.1.gz /etc /etc/wgetrc   then you know /usr/bin/wget is the binary file to execute 
for http to redirect to https you need to (the first 3 steps you probably already did):   allow port 80 in your router. forward port 80 to your server. punch hole in your firewall:  sudo iptables -a input -p tcp -m tcp --dport 80 -j accept  define virtualhost for port 80 (as well as for 443):  &lt;virtualhost *:80&gt;   servername             erichermansson.com   serveralias            www.erichermansson.com   rewriteengine          on   rewritecond            %{http_host} ^www\.(.*)$ [nc]   rewriterule            ^(.*)$ https://%1/$1 [r]   rewritecond            %{https} !on   rewriterule            ^/?(.*) https://%{server_name}/$1 [r=301] &lt;/virtualhost&gt;  &lt;ifmodule mod_ssl.c&gt;    &lt;virtualhost *:443&gt;    ..
you can check what the access point is broadcasting in its beacons by doing this (you'll need the wireless-tools package):  $ sudo iwlist wlan0 scanning   the output varies by device, and will display every ssid the interface can see
your vm is running on top of qemu (kvm), and reporting the cpu and chipset emulated by qemu
gdb will ask you to confirm certain commands, if the value of the confirm setting is on
as documented in the man page, screen looks for a null title-escape-sequence
getting different nmap results from local machine and remote machines means there is some kind of firewall(whether running locally or some remote machine) which is blocking
devil's pie does have such an option
while @wnoise's answer is a the nicer solution, it might not be possible for you to implement it (i.e
if you reply to an email the "original" email address will only be used by thunderbird if there is an identity that matches that email address for that account
debian and derivatives (ubuntu, linux mint, …)  the configuration for the kernel /boot/vmlinuz-version is stored in /boot/config-version
sure
if you want to convert a random time from the local timezone to a time in another timezone:  $ date -d @$(date +%s -d '2014/10/01 12:34:56') wed oct  1 12:34:56 cest 2014 $ tz=australia/sydney date -d @$(date +%s -d '2014/10/01 12:34:56') wed oct  1 20:34:56 est 2014   i use seconds since the unix epoch as the natural way to communicate a point in time. 
on archlinux, with kde, there is this way, or that way. i suppose it works with mint too.. you can check in /etc/xdg/autostart/ or ~/.config/autostart/ for example. 
to send an attachment, you need to encode the message using mime.  you could use mutt  mutt -s subject -a attachment_file email_address &lt; message_file   or mpack  mpack -s subject -d message_file attachment_file email_address   see also:   how do i send a file as an email attachment using linux command line? how to send mail from the command line? sending email with attachments on unix systems  
you can use a subshell, running all three commands and piping the output a single time:  if ((($4) &lt; 3000 )) then     (     echo "memory utilization is less than 5% free of total memory"     free -m     ps -eo pid,ppid,rss,vsize,pcpu,pmem,cmd -ww --sort=vsz|cut -c1-130|tac|head     ) | mail -s "please bounce high consuming jobs on server" vamsi.muluguru@gmail.com else     exit 0 fi  
   $ touch ./-c $'a\n12\tb' foo $ du -hs * 0       a 12      b 0       foo 0       total   as you can see, the -c file was taken as an option to du and is not reported (and you see the total line because of du -c)
you can use the directive identitiesonly in conjunction with the identityfile directive.  on the commandline you can use:  ssh -v -o "identitiesonly=yes" -i /users/wwerner/.ssh/my_test dev.example.com   as alternative you can set the directive in your .ssh/config file at the section for your host.  see man ssh_config for details 
drop the lib parameter; that should install the package in a directory within your home directory:  install.packages("gridextra")   if you need to specify a mirror (which appears to be the case), add it using the repos parameter; for example:  install.packages("gridextra", repos = "http://cran.univ-lyon1.fr")   you can pick an appropriate mirror by running  choosecranmirror()   at an r prompt somewhere you can run it interactively, then you can determine the mirror's url by running  options("repos")   or you can view the list of mirrors on http://cran.r-project.org/mirrors.html 
you can't do it from the inside of your script
there are several ways to do this  using ssmtp:  you can find a detailed article here
according to explanation in comments:   sed " # for lines which starts with if /^if\b/{     /==/! {         # add logic statement to first alphanums after (          s/\((\w\+\)/\1 == 1b'1 /         # add logic statement to second alphanums after &amp; if it is present          s/\(&amp;\!\?(\?\w\+\)/\1 == 1b'1 /         # if ! sign in section replace 1 by 0 at the end of statement          s/\!(\([^']*'\)1 )/ \10 /g           }        } " file   other variant - remove everithing except part which will be modified, change it, than construct full line back:  sed "/^if\b/{         /==/!{             h             s/if (.*) //             x             s/if (\(.*\)) (.*/\1/             s/\w\+/&amp; == 1'b1 /g             s/!(\(.*\)1 )/ \10/g             s/.*/if (&amp;)/             g             s/\n/ /              }             }" file  
you must not allow any spaces around the =  al=nihao   see http://www.gnu.org/software/bash/manual/bashref.html#shell-parameters  if you carefully read this section (http://www.gnu.org/software/bash/manual/bashref.html#executing-commands) you'll understand why "al" was being treated as a command. 
you could investigate using auditing to find this
upgrading to oracle virtualbox 5.0..
use the "escape character" (normally, the tilde ~) to control an ssh session:   ~ followed by . closes the ssh connection; ~ followed by ctrl+z suspends the ssh process; ~ followed by another ~ sends a literal ~.   you can set the escape character using the -e option to  ssh.  additionally, remember that     you should also remember to press enter before ~
use backticks
from man bash:     ${parameter#word}   ${parameter##word}      remove matching prefix pattern
you can run history -a; history -c in all windows to save the history
you can use simple command substitution:  variable=`cat text.txt` echo $variable   or in bash:  variable=$(cat text.txt)   same with:  variable=`tr '[a-z]' '[a-z]' &lt; text.txt`  
you can see all this for an individual program with a debugger like gdb, but it changes so rapidly that you wouldn't be able to see anything watching it live, and even tracking it so you could see it at all would slow the computer to a crawl
first, create some directory for the mountpoint, e.g:  mkdir -m 755 ~/zyxelnas   if you don't have mdadm installed, you need to install it now:  sudo apt-get install mdadm   supposing the drive is sdb, 2nd partition, as in my case, we assemble the one-drive array; note that if you already have some arrays configured, please change md0 to a suitable value:  sudo mdadm --assemble --force /dev/md0 /dev/sdb2   if it succeeds, supposing it is your ony array md0, mount it as follows:  sudo mount /dev/md0 ~/zyxelnas  
go to administration -> software sources and search for nvidia-current
there are several possible answers depending on what exactly you want to know (i don't know which one aix's bootinfo corresponds to).   you can see whether the cpu is 64-bit, 32-bit, or capable of both by checking the flags line in /proc/cpuinfo
first you may check whether ssh-agent is running and start it if not:  if ! [ -n "$ssh_auth_sock" ] ||    ! { ssh-add -l &amp;&gt;/dev/null; rc=$?; [ "$rc" -eq 0 ] || [ "$rc" -eq 1 ];}; then     echo "starting agent..."     eval "$(ssh-agent -s)" fi   ssh-add -l exits with code 1 if there are no identities and with code 2 if it cannot connect to ssh-agent.  then you add the passphrase for the key you need.  ssh-add ~/path/to/keyfile  
yes, by running stat on target file and local file, and get a file size,  i.e stat -c "%s" /bin/ls   and you get the percentage of data copied by comparing the two value, that's it  in a very basic implementation that will look like this:  function cpstat() {   local pid="${1:-$(pgrep -xn cp)}" src dst   [[ "$pid" ]] || return   while [[ -f "/proc/$pid/fd/3" ]]; do     read src dst &lt; &lt;(stat -l --printf '%s ' "/proc/$pid/fd/"{3,4})     (( src )) || break     printf 'cp %d%%\r' $((dst*100/src))     sleep 1   done   echo }  
while both are designed to contain files not belonging to the operating system, /opt and /usr/local are not intended to contain the same set of files.  /usr/local is a place to install files built by the administrator, typically by using the make command (e.g., ./configure; make; make install)
here is awk solution:  $ awk '     $4 &lt; 1.5 {       uniq[$1] = $3;       uniq[$2] = $3;       next;   }   {       uniq[$1] = $3;       dup[$2] = $3;       delete uniq[$2];   }   end {     print "--unique.txt--";     for(i in uniq) {         print i,uniq[i]     }     print "";     print "--duplicate.txt--";     for(i in dup) {         print i,dup[i]     }     }' file --unique.txt-- 764157 ericcartman 56797854 ericcartman 53723848 timburnes  --duplicate.txt-- 53530214 timburnes 52986038 ericcartman 12651711 timburnes   with your second example:  $ awk '     $4 &lt; 1.5 {       uniq[$1] = $3;       uniq[$2] = $3;       next;   }   {       uniq[$1] = $3;       dup[$2] = $3;       delete uniq[$2];   }   end {     print "--unique.txt--";     for(i in uniq) {         print i,uniq[i]     }     print "";     print "--duplicate.txt--";     for(i in dup) {         print i,dup[i]     }     }' &lt;&lt; end &gt; 17412193 43979400 ericcartman 2.16667 &gt; 21757330 54678379 andrewruss 0.55264 end --unique.txt-- 21757330 andrewruss 54678379 andrewruss 17412193 ericcartman  --duplicate.txt-- 43979400 ericcartman  
a simple loop will do the trick.  cd working for dir in */*/; do   [ -e "$dir/files.zip" ] ||   # skip directories where the zip already exists   ( cd -- "$dir" &amp;&amp; zip -r files.zip .) done   note that zip is smart enough to skip the zip file that is being built when recursing in that directory
ok, that is weird.  on the rpi, pkg install vim goes through the process of downloading 46 packages, but only installs 17 of them
remove the quotes, or the shell will try to execute the full string as a command (which obviously does not exist).  #!/bin/sh exec urxvt -e mutt -f /path/to/muttrc "$@"   not tested, but the presence of quotes is the explanation for the vanishing of the terminal. 
you can use tr:  wc filename | tr ' ' '\n'    , or if you just want the numbers:  wc filename | tr ' ' '\n' | head -3  
the hard link count is stored in the inode
cryptography involves intensive numerical computations that are significantly faster when implemented in a low-level language such as c and compiled to machine code, than when implemented in a high-level language such as python and executed as interpreted bytecode
it's not clear what you want to match: your examples are contradictory.  grep -f matches an exact string
issue the command -  echo 500 &gt; /sys/class/backlight/intel_backlight/brightness  replace 500 with a number of your choice
i have always done it by pulling the disk i want to keep during the install
buffers field of free is representing all the i/o directly to block devices on your host, either via direct-io or via filesystem metadata blocks ex: find etc. you can find more info on which devices using these pages look at my blog page here  slabtop is representing separate cache area used by kernel and it's allocated for frequently used kernel objects
(first things first: i have never used nor installed hulahop, what follows is generic, based on glancing over the source tree.)    to get this straight, there are basically two ways to install something in a debian(-derived) distribution:   the clean way: via a .deb package and some tool like apt-get, aptitude, dpkg, you can build them yourself or semi-self by using tools like checkinstall (for example, there are probably others); this enables you to use your distribution's tools to remove them and you're thus save from cluttering up your system, what is the danger of... the manual way, i.e., using whatever is provided in the sources to compile and install it yourself
if you don't mind moving the files...  you could do this by moving the files into a git repository, and symlinking them to their old locations; you'd end up with   ~/gitrepo/somedir/otherdir/file1 moved from ~/somedir/otherdir/file1 ~/gitrepo/otherdir/somedir/file2 moved from ~/otherdir/somedir/file2 a symlink from ~/somedir/otherdir/file1 to ~/gitrepo/somedir/otherdir/file1 a symlink from ~/otherdir/somedir/file2 to ~/gitrepo/otherdir/somedir/file2   you can then safely commit the files in the git repository, and manipulate them using git, and anything using the old file paths will see whatever is current in the git workspace
an lvm volume group is an abstraction of a hard drive, or multiple hard drives, or multiple raids, or..
from :h :w:                                                  :w_a :write_a e494 :[range]w[rite][!] [++opt] &gt;&gt;                         append the specified lines to the current file.  :[range]w[rite][!] [++opt] &gt;&gt; {file}                         append the specified lines to {file}
you need to use -vo vdpau and -vc ffh264vdpau,ffmpeg12vdpau,ffwmv3vdpau,ffvc1vdpau, command line options or put them in ~/.mplayer/config. 
you can perhaps do what you want using bash's readline with -i which provides an initial input to -e edit
you can update the firmware from the built-in firmware setup; this is documented on the asus site. 
looking at this wonderful answer to a related question reveals the differences between the package groups of "basic server" and "virtual host":     basic server: base, console-internet, core, debugging, directory-client, hardware-monitoring, java-platform, large-systems, network-file-system-client, performance, perl-runtime, server-platform   virtual host = basic server + virtualization, virtualization-client, virtualization-platform  thus the first guess would be that virtual host is best suited; but looking at the redhat virtualization guide the "virtualization-*" package groups probably mean kvm
yes, if your shell supports process substitution (bash and ksh93 does) you may do like this:  $ join file1 &lt;( yourcommand )   this runs the join command with file1 and a file descriptor in /dev/fd connected to the standard output of yourcommand (which would be your curl thingy).  note that join expects all input to be sorted
first of all, in vim you can enter : (colon) and then help help, ala :help for a list of self help topics, including a short tutorial
ls displays that information because the data is stored in the size field of the inode for the directory
so long story short, this is the best way i have found to achieve this, in case someone else is interested:  find /mnt* -type d -name snapshots &gt; dir.list; \    tar -czpf - -t dir.list | ssh user@host "openssl aes256 \    -out /mntc/backups/snapshot.tgz.enc -salt -k 'secret'"  
for dual boot with separate hard drives, you'll have to change the booting sequence in your bios.  for example, if win8 is on c drive, and xubuntu is on d drive
so, you want to replace things in a brand-specific format? at the first look it looks bad, but the new docx format is a bit better for that than the old doc format, because it's actually a zip file containing xml files.  so the answer lies in unzipping it, then you'll have to rummage through the files and figure out on which one to call sed and zip it up again.  check out the file word/document.xml in the zip file. 
you can right click -&gt; properties -&gt; file type options and edit, delete, reorder or add the entries, which will appear in the "open with" dialog. you can access this same dialog via `system settings -> file associations 
to keep the installation smaller, debian's emacs metapackage does not include the elisp source code (as you've noticed)
you can do this in single user mode.   restart system, at grub prompt press down or up arrow so grub screen will be pause. press "e" to edit grub entries, select the kernel line and again press "e" to edit mode now add "1" or "single" at end of the line
why not use rsync instead?  rsync -a /branch2/media/ /branch1/media/   the reason why mv can't move /branch2/media/cd/ to /branch1/media is because /branch1/media already has a cd/ in it
this is an approximation to your problem:  #+tblname: pepe | /tmp      | | /usr/info |  #+begin_src sh :var tt=pepe du -sh $tt #+end_src  #+results: | 4.0k | /tmp      | | 532k | /usr/info |  
cp -p file file.orig &amp;&amp; \ tail -n 4 file.orig &gt; file &amp;&amp; \ rm file.orig   this will copy the original file to a backup copy, retrieve only the last 4 lines from the backup copy, put those 4 lines into the original file name, then remove the backup copy. 
the primary advantage of backtrack is that someone else did all the work a recent broad-selection of tools into a single distribution, and it makes them all available by default without you having to install them or search for them
have you looked at the linux benchmark suite? it includes multiple tools to measure performance on a wide range of storage formats, including disk (memory cards, etc) and memory (ram, l1 and l2 cache, etc). 
in pulseaudio, each sound card has a profile set associated with it
gnu unrtf does almost exclusively what you want.  pandoc can do a lot more. 
this can be easily done with bash/ksh93/zsh arrays:  a=(*) cp -- "${a[@]: -4}" ~/   this works for all non-hidden file names even if they contain spaces, tabs, newlines, or other difficult characters (assuming there are at least 4 non-hidden files in the current directory with bash).  how it works   a=(*)  this creates an array a with all the file names
let awk do it all for you:  &lt;/proc/cpuinfo awk -f : '/mhz/{printf "core %d%smhz\n", n++, $2}'  
you need a space between [[ and $2.  for bash [[ is not syntax, it is a builtin command (or keyword to be precise)
you can use prtconf to get the bitness of the running kernel:  $ prtconf -k kernel type: 64-bit   you could also ls -l /unix or file /unix, but that's not guaranteed to be the kernel you're currently booted from.  $ file /unix /unix: 64-bit xcoff executable or object module not stripped $ ls -l /unix lrwxrwxrwx    1 root     system           21 dec  9 06:48 /unix -&gt; /usr/lib/boot/unix_64  
tl;dr: here the problem was apparently caused by an issue (most probably some obscure race condition) between opengl and kwin.  to workaround it, one must disable opengl and use xrender instead (in system configuration > desktop effects > advanced > compositing type, select "xrender" instead of the default opengl).  a few desktop effects will not be available anymore, but at least the system will be stable and not freeze anymore.    long story:  the issue occurred every few weeks randomly, some times several times a day, some times two or three weeks with no issue, and was therefore quite difficult to analyze (btw at some point i switched to another video card, switching from radeon to intel i915 without any impact on the issue, therefore it is related neither to the graphic card nor its driver).  i left a script running in the background and doing automatic checks every three minutes in an infinite loops so they could hopefully catch something when the desktop freeze.  indeed, the freeze can be programmatically detected through qdbus, and in particular this call fails if and only if the desktop is frozen:  qdbus org.kde.kwin /app org.freedesktop.dbus.peer.ping   while normally it has no output and a return code of 0, when the desktop is frozen this command fails with a return code 2 and a "noreply" error message.  for information, i've also checked the status of org.kde.plasma-desktop, org.kde.kuiserver and org.kde.kded which all seem sane when a freeze occurs, therefore kwin seems the real culprit.  i tried several ways to restore the desktop environment integrity with no luck
the reason that the permanently store this exception checkbox in firefox is disabled is because you're in private browsing mode, or your security settings in firefox are set to never remember history.  set it to remember history, reload the page then permanently store it
you should be able to list the printer options with  lpoptions -l   (add -p and the name of the printer if it is not the default)
on command line you need to learn a few comparatively low level but extremely flexible tools, which serve as building blocks for anything more complex
you cannot safely interpolate a variable in a sed command, because the substitution is performed by the shell, not by sed
i found /usr/share/zsh/functions/completion/unix/_git which had some tips for aliases like this and ended up defining these functions for the aliases:  _git-ls () {   # just return the _git-ls-files autocomplete function   _git-ls-files }   then, i did a straight compdef g=git
make sure that you've turned on the fancy autocompletion
#make a clean working directory mkdir -p work/crap #get in to that directory cd work/crap #clone git head git clone https://git.gnome.org/browse/meld #get in to that project directory cd meld #install dependencies sudo apt-get install intltool itstool gir1.2-gtksource-3.0 libxml2-utils #install meld sudo python setup.py install   if you wanted to work on the code itself without re-installing, i typically do that by installing in a venv and opening the installed to folder in the venv in an ide.  result of running meld in a terminal after those steps:    note that the current version of meld requires gtk+ 3.14, which is not available on ubuntu 14.04 (meld requires gtk+ 3.14 or higher. error)
recommend way is as follows
first, the easy way: rsync has a --bwlimit parameter
use the -a (and) condition, e.g   find 
when you do this with your own user, you're using the ssh keys in your own $home/.ssh/ directory
to fix this error, i think the command you wish to find is "yum-config-manager --disable ". in your case, try both "yum-config-manager --disable ffmulticonverter_stable" or "yum-config-manager --disable ppa:ffmulticonverter/stable"
the ultimate goal is to restore the master boot record (mbr) to the hard drive, removing grub, so you can boot to your windows partition in the future without stopping at the grub command line.  the easiest way to achieve this is to boot from your windows 7 installation media
the instructions in the book are for bash
what you're asking is difficult if not impossible
the problem  for f in $(find .)   combines two incompatible things.  find prints a list of file paths delimited by newline characters
because of the lack of reactions, i posted my question on another forum.  and there i got the answer!  this is what my /etc/rc.conf.local now looks like:  ntpd_flags= inetd_flags= inetd=yes  
from man sort:  -k, --key=pos1[,pos2]        start a key at pos1 (origin 1), end it at pos2 (default end of line) ...  pos  is f[.c][opts], where f is the field number and c the character position in the field; both are origin 1
using pam is the best solution
you can also do this without using expect:  { echo foo ; cat ; } | command  
the x server's copy of the cookie is not stored in your home directory, since it's not associated with your user, but in the system files.  if you find the x server process in ps you'll usually see it was started with an -auth argument specifying the path to the cookie file, such as:  test  1498  1497   0   jun 24 vt/7        9:47 /usr/bin/xorg :0 -nolisten tcp -br -novtswitch -auth /tmp/gdm-auth-cookies-94aq  
use a spare partition and a disk benchmark utility like bonnie++ to get a general feel for which systems take performance hits in what areas
direct solution  for file in file{1..3}; do     sort -rk2 "$file" | awk '$1 &gt; 290{print;exit}' done   or without awk  for file in file{1..3}; do     while read field1 field2 ; do         [ "field1" -gt 290 ] &amp;&amp; { echo $field1 $field2; break; }     done &lt;(sort -rk2 "$file") done   or awk alone   awk '     fnr == 1 || $1 &gt; 290 &amp;&amp; max &lt; $2 {         max = $2         if (fnr == 1 &amp;&amp; max) {             print line             if ($1 &lt;= 290)                 max = -1     }         line= $0                     }     end {         print line }     ' file{1..3}  
iso files cannot be mounted and then written to
as noted in comments zgrep is better choice for such kind of tasks with globstar option which allows to use ** as all path inside the directory except hidden  shopt -s globstar zgrep -m 10 '^\([^|]*|\)\{13\}20160920100643|\([^|]*|\)\{7\}567094398953' ./**muc*_*_20160920_*.unl* shopt -u globstar  
take a look at this debian wiki article
sudo apt-get remove php5-cli sudo apt-get install php5-cli   and the one liner,  sudo apt-get install --reinstall php5-cli  
fsck has an option which makes it delay the automatic check when the laptop is on battery power; that is, if the filesystem is configured to check once every 30 mounts, it will interpret that as once every 60 battery-powered mounts
here is one method:  $ v='\n*******************************************************************************************************************************************************************\n' $ awk -v ors="$v" '{print;}' file 027,027,0,3,,1,0,1,1,0,0,0,0,0,0,0,0,6,1,,1.211100,1,2015-08-03,2015-07-04,,2015-11-01,0,0,2015-11-01,1,1,,0,0,0,0,0,131,0,0,0,0,0,2015-06-01,10000000000000000000,, ******************************************************************************************************************************************************************* 136,136,0,0,,1,0,1,1,0,0,0,0,0,0,0,0,1,1,,0.350000,1,2015-08-17,2015-07-18,,2015-11-15,0,0,2015-11-15,0,0,,0,0,0,0,0,131,0,0,0,0,0,2012-11-20,10000000000000000000,, ******************************************************************************************************************************************************************* 633,633,0,0,,1,0,1,1,0,0,0,0,0,0,0,0,3,1,,3.125300,1,2015-08-31,2015-08-01,,2015-11-29,0,0,2015-11-29,0,0,,0,0,0,0,0,131,0,0,0,0,0,2014-12-12,10000000000000000000,, ******************************************************************************************************************************************************************* 802,802,0,0,,1,0,1,1,0,1,0,0,0,0,0,0,7,1,,0.060000,1,2015-08-05,2015-07-06,,2015-11-03,0,0,2015-08-05,1,1,,0,0,0,0,0,131,0,0,0,0,0,2014-08-10,10000000000000000000,, *******************************************************************************************************************************************************************   here is another method to achieve the same effect but without explicitly setting ors:  awk '{print;} {for(i=1;i&lt;=length($0);i++)printf "*";print"";}' file  
i use set list and set listchars in .vimrc to show tabs and trailing white spaces, you can use a condition for selective file type like this.  if !(&amp;filetype == "txt")   set list                " show special characters   set listchars=tab:→\ ,trail:·,nbsp:· endif   so my files look like this when those charaters are present.  function somefunc() { // no trailing spaces here →   var a = "hola"; // 3 trailing spaces.···     alert(a); // this line starts with spaces instead of tab // next a line with 4 white spaces and nothing else ···· // next a line with a couple tabs →   →    }   note: · is not .  edit  so to answer to your comment, you can do that by adding this to your ~/.vimrc, make sure to add it after the colorscheme, or it will be hi clear'd.  if !(&amp;filetype == "txt")   highlight whitespaces ctermbg=green guibg=#55aa55   match whitespaces /\s\+$/ endif   you can change the highlight colors and refine the regular expression as needed
they way i would go about this is to partition the ssd as you want it (/, /boot, /home, etc) and since you're moving everything to a new ssd you don't need to worry about shrinking partitions or anything complicated like that
 mount the raid partition to /mnt/var  uuid=&lt;raid uuid&gt; /mnt/var ext4 defaults 0 0   create mount point /mnt/var  cd /mnt; mkdir var  reboot copy content into /mnt/var  cp -a /var/log /mnt/var cp -a /var/cache /mnt/var cp -a /var/games /mnt/var cp -a /var/tmp /mnt/var  modify fstab as follow to mount them to /var on next boot  uuid=&lt;raid uuid&gt; /mnt/var ext4 defaults 0 0  /mnt/var/log   /var/log   none bind 0 0 /mnt/var/cache /var/cache none bind 0 0 /mnt/var/games /var/games none bind 0 0 /mnt/var/tmp   /var/tmp   none bind 0 0  reboot  
courtesy @hbdgaf, this how-to put me on the right track:  export debian_frontend=noninteractive echo mysql-apt-config mysql-apt-config/enable-repo select mysql-5.7-dmr | sudo debconf-set-selections wget http://dev.mysql.com/get/mysql-apt-config_0.2.1-1ubuntu12.04_all.deb sudo dpkg --install mysql-apt-config_0.2.1-1ubuntu12.04_all.deb   i put together this gist for the whole process. 
use a shell to provide this
package sources are listed in /etc/apt/sources.list and /etc/apt/sources.list.d/*.list
you may use the stat command:          $stat -c --%x file or symlink   it doesn’t change it , it just report the last access time    man stat   name    stat - display file or file system status    synopsis    stat [option]..
you can specify the address of your specific command/regular expression
your requirements state,     you can feed the user name to finger using the whoami command and piping the output to xargs
your idea to use a regex record separator is elegant, but remember that awk will consume the corresponding text, which in your case will be the first non-whitespace character of the following record
in nautilus, select file | connect to server ...  there are a lot of options to share a file-system over a network in unix/linux
you can use awk:  awk '{print &gt; $2".txt"}' input-file   it redirects the output to a filename made from the second field. 
judging from the archwiki's pages on syslinux, i suppose the only way this is possible is to chainload another syslinux-bootloader, like (untested)  label boot_hd2_2 menu label boot second primary partition from thirth hard drive com32 chain.c32 append hd2 2   where hd2,2 also carries syslinux bootcode, in the usual "boot kernel from here"-style.  (this is kind of clumsy, why not just use grub2?) 
it's not a bug
i can address your question, having previously worked with the linux fb
generally, the solution is "don't try to install from source into directories managed by your packaging system".  you can install your custom-compiled code into /usr/local, for example, and having anything that depends on it look to /usr/local for libraries and include files using appropriate invocations of your build system (e.g., setting cppflags/cflags/ldflags for a typical makefile).  you could even install everything into an application-specific directory (e.g., /usr/local/myapp, or /opt/myapp).  this is also a great use case for something like docker, which makes it very easy to set up isolated development/runtime environments that are isolated from your host. 
if i understand correctly you need to access some ansible variables defined for a generic host
try mitmproxy.   mitmproxy is an ssl-capable man-in-the-middle proxy for http
the problem:  with lsof -i :3000 -t, you will look for any processes connected to a port 3000, which may be on the remote side.  in the cases where you use your script, the browser seems to have a connetction to the rails server on port 3000
first of all, make sure your favorite bash is in $path before the system one
you can use tee and process substitution for this:  cat file.txt | tee &gt;(pbcopy) | grep errors   this will send all the output of cat file.txt to pbcopy, and you'll only get the result of grep on your console.  you can put multiple processes in the tee part:  cat file.txt | tee &gt;(pbcopy) &gt;(do_stuff) &gt;(do_more_stuff) | grep errors  
in linux, you can try this:  top -bn1 &gt; output.txt   from man top:  -b : batch-mode operation             starts top in 'batch' mode, which could be useful for sending             output from top to other programs or  to  a  file
the following uses data.csv as a link to the requested file to keep status between iterations.  # check to see if an argument is given if [ "$#" -ne 1 ]; then         echo "illegal number of parameters"         exit fi  # check if ran before if so move that to processed/ directory if [ -h "data.csv" ]; then         prev=`readlink data.csv`         echo "found previous run $prev"         rm -f data.csv  # remove link         mv -f $prev processed/  # move previous file to processed directory         echo "moved to processed/$prev" fi  # check to see if file exists if [ -e data$1.csv ]; then         ln -s data$1.csv data.csv  # link data.csv to the requested file         echo "linked data.csv -&gt; data$1.csv" else         echo "no such file data$1.csv" fi  
basically, your original /etc/uswsusp.conf was written by the scripts invoked by dpkg while installing uswsusp
please try this:   copy / yank the lines you want to copy switch to the buffer you want to change grctrl-r0esc   translation:   gr enters visual replace mode (cf
once you use sub-replace-special, introduced with \=, everything has to be a vim expression; you cannot prepend / append literal replacement text
well, other than run interactively, you can try fsck -y like my answer in the other question :-p  if you want to dd an image on top of the rootfs, your best bet is going to be to do that from your initramfs before mounting the rootfs.  you can do it with the system booted to that rootfs, but this is one of those things where unix gives you the rope (with the loop already nicely tied for you)
it is explained in the less faq can less display non-english language characters?     less has two ways to display non-english characters
in terminal:  ln -s /folder/of/the/script/script /home/yourusername/desktop/linkname.desktop  ln is used to create link to files:    the -s switch tells the command to create a symbolic link, which means something very similar to ms windows shortcuts. the first field is for full path of the target destination (in your case the script you wish to run clicking the icon on your desktop) the second field is for the the path of the link you are creating, which in your case must be in desktop folder under your homedir.   a couple of final notes:   depending on your localization, your desktop folder may vary, in my case for example is under /home/username/scrivania/ (i'm from italy) the .desktop appendix in destination filename is needed to make destination file appear on desktop, given that you are using unity as desktop manager (the default dm in latest ubuntu distros)
try   nat interfaces: vm1: 10.0.2.15/24 - vm2: 10.0.2.16/24   internal network interfaces: vm1: 10.0.3.1/24 vm2 10.0.3.2/24   you will have trouble using same network on differents interfaces. 
there's no real difference in behavior
awk:   awk '{print (nf&gt;1) ? $1 : ""}' file   if the number of fields is more than 1, print the first field, otherwise print an empty line.  a couple of extra thoughts:   if your data is tab-separated, then  awk -f '\t' '{print $1}' file  if you want to extract the first 8 characters  awk '{print substr($0,1,8)}' file   
# possibility 1: echo "line 1" &gt;&gt; greetings.txt echo "line 2" &gt;&gt; greetings.txt  # possibility 2: echo "line 1 line 2" &gt;&gt; greetings.txt  # possibility 3: cat &lt;&lt;eot &gt;&gt; greetings.txt line 1 line 2 eot  
what i do to distribute systems easily is create an image (using clonezilla over pxe and samba / nfs storage) and "cast" these images to different computers
possibly sox would be an option.  invoked like this:  sox sound.wav sound.dat   it writes a textual representation of the sample data to the file sound.dat
another approach is to disable the mouse and keyboard (assuming a system with usb input devices):  00 23 * * * rmmod usbhid 00  7 * * * modprobe usbhid   this won't prevent you from turning the system off and on again, which would re-enable the keyboard and mouse..
found a solution - if somebody else is interested...  #!/bin/sh -e  runwhen=",h/6"  # the constraint string consists of a sequence of unit constraints
if cell a2 contains 012345678, then to get 78 to display in cell d2, enter =right(a2, 2) in cell d2. 
given the vast array of file systems out there, i'm certain that exceptions exist, but traditionally, the inode had an array of disk block numbers in it.  for example, in /usr/include/linux/ext3_fs.h, i see a definition of struct ext3_inode.  inside struct ext3_inode, i see a member i_block[ext3_n_blocks];/* pointers to blocks */  different file systems have had different ways of keeping track of which disk blocks belong to an inode (the on-disk data structure that represents the file's data)
most people run their httpd (apache, nginx, etc) through an init system
with sed, like so:  sed '20,37d; 45d' &lt; input.txt &gt; output.txt   if you wanted to do this in-place:  sed --in-place '20,37d; 45d' file.txt  
the usb ports found on computer monitors are usually those of a built-in usb hub: you would have to connect the monitor's hub to your computer using a usb cable for it to work
tomcat rotates its log files itself: by default at least localhost_access_log_ (configured using an accesslogvalve in server.xml, look in /opt/alfresco/tomcat/conf) and the log files configured using a filehandler in logging.properties (catalina.out and so on).  i'm not sure how you'd go about compressing the log files natively within tomcat's logging framework, short of adding your own handler... 
if your grep supports perl compatible regexp (-p), you can do:  grep -po '(?&lt;=^|\s)\d[^\s]*(?=\s|$)' file.txt    assuming by word you meant characters separated by whitespaces only ?&lt;=^|\s) is the zero width positive look behind pattern ensuring our desired word is preceded by either the start of the line or a whitespace \d[^\s]* is our desired match, word starting with a digit (?=\s|$) is the zero width positive lookahead pattern ensuring our desired match is followed by a whitespace or end of the line.  
i assume you want a better way to do it, based on columns not characters, if so:  free | #the option for free don't work for me sed -re 's/[ ]+/\t/g' | #convert delimiter to single tab cut -f1-4,7 # choose columns 1 2 3 4 7  
pssh makes this much easier, but for your simple use case ssh will also work.  while what you have above could have worked, provided the server is set up to run a command and exit on login (which is somewhat unlikely) you probably meant something like this:   ssh $i &lt;command&gt; | grep tsm | ...   if you really need to check a login banner for tsm, try using the command exit to immediately return back from the ssh rather than starting an interactive shell:  ssh $i "exit" | grep tsm | ...  
there are multiple tools to check which processes are using how much cpu and memory.  in most cases when your system gets slow there is either a process that uses all the cpu or your memory is full.  on all system you should find ps and top both are command line tools that show the list of all processes.  top is a small interactive program that shows the processes in a sorted order and it refreshes every two seconds. you can quit top by pressing q and you will get help for the rest of the top-commands by pressing ?.  a more advanced top is htop which you have to install
rm sequence_1*.hmf   removes files beginning with sequence_1 and ending with .hmf
thanks to this page, i got the solution.  using the jre x64 rpm mentioned in the question, without icedtea plugin, all you need to do is linking the jre library to firefox this way :  ln -s /usr/java/jre1.7.0_05/lib/amd64/libnpjp2.so ~/.mozilla/plugins/   in fact i just copied it the first time this is why it crashed
alt-tab feature is handled by the window manager
somewhere in your ppp setup (probably either in /etc/ppp/options or at the command line), you have an option called connect followed by a command used to setup the modem for a connection
try using extent instead like this:  $ convert puma1.png -gravity center \     -background white \     -compress jpeg \     -extent 1755x2475 puma1.pdf   example  your gravatar.  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  and the resulting pdf file.  $ convert 453f11e81477e1e0334962ee262b3bcd.png -gravity center \     -background white \     -extent 500x500 \     -compress jpeg 453f11e81477e1e0334962ee262b3bcd.pdf     references   use imagemagick to place an image inside a larger canvas  
it would be worth a try to run systemd-analyze blame, see http://0pointer.de/blog/projects/blame-game.html and https://www.linux.com/learn/tutorials/539856-more-systemd-fun-the-blame-game-and-stopping-services-with-prejudice
advanced cp  cp -r /home/username/a/
"installing as root user" isn't a bad thing necessarily, especially if they installed using package managers
with (t)csh, bash or zsh history expansion you could write:  vagrant up &amp;&amp; !#:0 ssh   but, seriously, you wouldn't 
with the sony driver loaded the driver provides standard led kernel interfaces:  echo 255 &gt; /sys/class/leds/*buzz1/brightness echo 0 &gt; /sys/class/leds/*buzz1/brightness  
the man page of bash reads:            -d delim                  the first character of delim is  used  to  terminate  the                  input line, rather than newline.   because strings are usually null terminated, the first character of an empty string is the null byte
the sandbox command was removed from the package because it was not ready for release
by default all syslog daemons read incoming messages from: /dev/log  additionally syslog can bind to udp socket on port 514. see /etc/services::  $ cat /etc/services | grep syslog syslog          514/udp   second is mostly used for passing logs between syslog daemons
your problem comes from the .*
assuming your script is to run under linux, you can use inotifywait from an init script
virtualenv is python-specific, so no: apt-get will operate in your whole system
if you want to run an ssh server on a rooted phone, you can install sshdroid.  you can build a debian image via deboostrap
the following script works for both with gnuclient or emacsclient, though its (original) docstring says, "kill buffer, taking gnuclient into account." ..
for a permanently attached disk for storing backups of other hosts, /var/bacula is fine; hier(7) says /var is for "multi-purpose log, temporary, transient and spool files" (emphasis mine)
   my biggest problem is in understanding all the opaque terminology they've invented for it
you can only dynamically increase/decrease the memory for an lpar within the partition profiles' configured minimum/maximum
use the following pattern: ~(~n)
it's a timestamp
export puts the variable in the program environment, which is propagated to forked processes
"bind's internal libraries" don't care what the serial number is
you could create per directory limits by mounting filesystem image files on subdirectories in /home
if you have bash and don't care about also matching files like apple.not-a-number, try  shopt -s extglob mv apple.!(0) /new/directory  
such a fortune-mod does indeed exist.  fortune-mod-sec on sourceforge 
you can get it with svn from https:/github.com/gnome (svn checkout url is available on the right side of the page)
follow the instructions given in the documentation:   open the "software &amp; updates" setting in system settings. select the 3rd tab called "updates". set the "notify me of a new ubuntu version" dropdown menu to "for any new version". press alt+f2 and type in "update-manager" (without the quotes) into the command box. software updater should open up and tell you: new distribution release '16.04 lts' is available. click upgrade and follow the on-screen instructions
any changes to /etc/group will be made immediately.  that file is parsed when looking for access.  if you are trying to modify membership for a user already logged in though, that user may need to log out and back in for the membership changes to take effect. 
aside: @codesinchaos chrome says "outdated security settings", not "obsolete cryptography", for sha1 cert past end of year
you could use:  find "$source" -name "*.zip"   and if needed pipe it to xargs  or use:  shopt -s dotglob for file in "${source}"/*.zip do    if [ -f "${file}" ]; then       printf '%s\n' "$file"    fi done   to print only the zip files that are regular files or symlinks to regular files. 
you could try changing the runlevel in the /etc/inittab file from id:3:initdefault: to id:5:initdefault:. 
there are a few approaches using either tr, awk or sed  tr:   iconv -l | grep iso |head -5 |tr '/' '-'   awk:  iconv -l | awk '/iso/{gsub("//","--"); print $0}' |head -5   sed:  iconv -l | grep iso |head -5 | sed 's/\//-/g' # or, to avoid needing to escape the backslashes: iconv -l | grep iso |head -5 | sed 's#/#-#g'  
idspartidos=($(mysql -d parley --user=root -- ="easypassword" -s -n -e "select id from partidos where fecha = curdate() and date_add(now(), interval 2 hour) &lt; concat(fecha,' ',hora) and competencia = \"${compactivas[$(($n))]}\";")   towards the end of the line you're missing a }
thanks to @frostschutz, i could measure the write performance in linux without ncq feature
i found an answer here http://www.gelato.unsw.edu.au/ia64wiki/ipv6ddns  essentially dhcpd has a way to add hooks for events, so on a ipv4 registration call a script that will generate the standard mac based ipv6 address and register that.  update: (i'm using ich dhcp 4.1)  when using the "on commit" hook, it removes the existing dynamic update so you need to copy that into your "on commit" section, mine now looks like this:  on commit {     if (not static) {         # setup ipv6 address         set new-ddns-fwd-name = pick-first-value(ddns-hostname, host-decl-name);         if (exists host-name and option host-name ~~ "^[a-z0-9.-]+$") {                 set new-ddns-fwd-name = option host-name;         } elsif (exists dhcp-client-identifier and option dhcp-client-identifier ~~ "^[a-z0-9.-]+$") {                 set new-ddns-fwd-name = substring(option dhcp-client-identifier, 1, 50);         } elsif (new-ddns-fwd-name = "") {                 set new-ddns-fwd-name = binary-to-ascii (16, 8, "-",                                  substring (hardware, 1, 6));         }         set ddns-fwd-name = new-ddns-fwd-name;         execute ("/opt/bin/ddns-ipv6", ddns-fwd-name, ucase(                 binary-to-ascii(16, 8, ":", substring(hardware, 1, 6))),                 binary-to-ascii(10, 8, ".", leased-address));         unset new-ddns-fwd-name;          switch (ns-update (not exists (in, a, ddns-fwd-name, null),                            add (in, a, ddns-fwd-name, leased-address,                                 lease-time / 2))) {         default:             unset ddns-fwd-name;             break;          case noerror:             set ddns-rev-name =                 concat (binary-to-ascii (10, 8, ".", reverse (1, leased-address)), ".",                          pick (config-option server.ddns-rev-domainname,                               "in-addr.arpa."));              switch (ns-update (delete (in, ptr, ddns-rev-name, null),                                add (in, ptr, ddns-rev-name, ddns-fwd-name, lease-time / 2)))             {             default:                 unset ddns-rev-name;                 on release or expiry {                     execute ("/opt/bin/ddns-ipv6", "-d",  pick-first-value(ddns-hostname, host-decl-name));                     switch (ns-update (delete (in, a, ddns-fwd-name,                                            leased-address))) {                     case noerror:                        unset ddns-fwd-name;                        break;                     }                     on release or expiry;                 }                 break;              case noerror:                 on release or expiry {                     execute ("/opt/bin/ddns-ipv6", "-d",  pick-first-value(ddns-hostname, host-decl-name));                     switch (ns-update (delete (in, ptr, ddns-rev-name, null))) {                     case noerror:                         unset ddns-rev-name;                         break;                     }                     switch (ns-update (delete (in, a, ddns-fwd-name,                                            leased-address))) {                     case noerror:                         unset ddns-fwd-name;                         break;                     }                     on release or expiry;                 }             }             break;         }    } }  
this is done via an authorization manager called polkit:     polkit provides an authorization api intended to be used by privileged   programs (“mechanisms”) offering service to unprivileged programs   (“subjects”) often through some form of inter-process communication   mechanism.   with systemd and polkit users with non-remote session can issue power related commands
a very simple use of the ftp client would be to specify the server's hostname on the command line: ftp hostname
it's probably killed by kernel's oom killer
the debian openjdk packages are marked multi-arch: same so you should be able to do:   sudo dpkg --add-architecture i386 sudo apt-get update sudo apt-get install icedtea-6-plugin   you might need to remove the amd64 version of the browser plugin first, but you can have both versions of java itself installed at the same time. 
you should check the file permissions.  nginx must be able to write to the php5-fpm or hhvm unix socket.  you probably can find a line like this one inside the nginx error log /var/log/nginx/error.log, confirming that this is the problem:  2015/10/28 16:32:24 [crit] 14845#0: *1 connect() to unix:/var/run/php5-fpm.sock failed (13: permission denied) while connecting to upstream, client: 127.0.0.1, server: localhost, request: "head /test.php http/1.1", upstream: "fastcgi://unix:/var/run/php5-fpm.sock:", host: "localhost"   solution: add the nginx user to the group of the user owning the socket (usually www-data)
this is an optional feature, that is not always desired - especially in scripts
if you trust git's point of view on what is a binary file or not, you can use git grep to get a list of non-binary files
serge's comment made me do my homework - study the man page in more depth than before
this is a shell script
uptimed  one such tool that i came across many years ago is called uptimed
the bash builtin getopts is a lot easier to use
i did it by detaching the volume from the current instance than added it to the other instance as a secondary volume
no, there isn't
i do not have access to dnsmasq but according to this thread titled: dnsmasq is it caching? you can send the signal usr1 to the dnsmasq process, causing it to dump statistics to the system log.  $ sudo pkill -usr1 dnsmasq   then consult the system logs:  $ sudo tail /var/log/syslog jan 21 13:37:57 dnsmasq[29469]: time 1232566677 jan 21 13:37:57 dnsmasq[29469]: cache size 150, 0/475 cache insertions re-used unexpired cache entries. jan 21 13:37:57 dnsmasq[29469]: queries forwarded 392, queries answered locally 16 jan 21 13:37:57 dnsmasq[29469]: server 208.67.222.222#53: queries sent 206, retried or failed 12 jan 21 13:37:57 dnsmasq[29469]: server 208.67.220.220#53: queries sent 210, retried or failed 6   note: i believe that dnsmasq retains its cache in ram.  so if you want to dump the cache you'll need to enable the -q switch when dnsmasq is invoked
this works with mawk:  awk 'nr==1{$7="g";print;next} \   $3~/^[a,c,g,t]$/ || $4~/^[a,c,g,t]$/ {$7="p"} \   $3~/^[i,d,r]$/ || $4~/^[i,d,r]$/ {$7="q"} \   $4~/[a-z][a-z]/ || $3~/[a-z][a-z]/ {$7="q"} 1' file    line: in the first line write the g in the header. line: if $3 of $4 are a, c, g or t then $7 is p. line: if $3 of $4 are i, d, or r then $7 is q. line: if $3 of $4 are more than one letter then $7 is q
debian uses a system called alternatives to manage some interchangeable dependencies that provide a particular set of functionalities
you are getting the warning because you are installing grub to a partition instead of the mbr
you have to convert the iso to udrw format using:  hdiutil convert -format udrw -o destination_file.img source_file.iso   for further steps and reference click this link,  go with the steps: create bootable usb stick from iso in mac os x 
the account will be setup without login possibilities as there is no valid password assigned to the account, and that is different from no password.  you can check this by doing  sudo grep -f system-user /etc/shadow
syncthing does the the job if you want something to, well, be synced
find 
with ansi, cygwin, linux, vt100, vt220, and xterm terminfo definitions, i expect you'd be able to hit 98% of the terminal emulations that you'll encounter in the wild
i found the solution
apparently from http://rush.heroku.com/handbook/environment, i'm guessing you'd put this into ~/.rush/commands.rb -- modifying the source entry for the vi proc here  def emacs(*args)   names = entries.map { |f| f.full_path }.join(' ')   system "emacs #{names} #{args.join(' ')}" end  
preferred dhcp addresses are usually configured on the dhcp server side.  you will need to add an entry in your dhcp server's address table for your device's mac address and assign it to an ip address
first of all, history is the bash specific way, none better
well, there are a couple of cases:   this disk is part of a raid array
why not use vim?  open all files in vim  vim $(find 
i believe, you can use blockdev command, which is available from util-linux package (in debian)  blockdev --flushbufs /dev/ram0   source 
i think you could treat the first centos installation dvd as a repository, i.e
normally in a shell script, even a line that generates an error will not stop the shell script from executing
send sigcont  the only way to resume the suspended shell is to send the sigcont signal, presumably from another shell
if you want to separate a service and its ui, you need some kind of ipc mechanism to make them communicate
i don't know about gnome-terminal specifically, but you can place the standard xterm with a specific columns and rows size like this:  xterm -geometry 80x24+50+100   that's an 80 column, 24-line xterm, with the northwest corder at (50, 100)
one can delete a pool without volumegroup like this:  the files are stored in  /etc/libvirt/storage   as xml files
[a-z] only matches the characters a to z
when you have an account on a unix system, there are two main ways to gain administrative privileges:   with su, which requires knowing the password to the root account; with sudo, which requires having prior authorization and typing your account's password.   many variations are possible (other tools, other authentication methods), but if you haven't configured anything special, one of these is likely to work
you need to install some obscure extensions to modify this panel
you can do (as user1) something like  sudo -u website cat ~website/somefile &gt; ~user1/somefile   note that ~user1/somefile will be firstly created by user running the shell (user1), and the cat will be executed as website  you can use tar(1) with same trick, for multiple files:  sudo -u website tar cf - ~website/foo ~website/bar | tar xf -   run as user1 in his directory, that will "create" tar archive on stdout as website, and the another tar (without sudo, so running as same user as the one running the shell, that is user1) would unpack that virtual tar file to current directory (to which user1  can write).  update note that tar will create subdirectories leading to a file, you can reduce that behaviour by specifying -c so tar will entet specified directory before starting:  sudo -u website tar -c ~website -cf - foo bar | tar xf -   this way,  foo and bar will be created in current directory without leading subdirectories (but if you added blah/baz, it would create blah as subdir in which baz resides) 
calculating the average per core usage from /proc/stat  the best solution i have come up so far uses bc to account for floating point arithmetic:  # calculate average cpu usage per core. #      user  nice system   idle iowait irq softirq steal guest guest_nice # cpu0 30404 2382   6277 554768   6061   0      19    0      0          0 a=($(sed -n '2,5p' /proc/stat)) # user         + nice     + system   + idle b0=$((${a[1]}  + ${a[2]}  + ${a[3]}  + ${a[4]})) b1=$((${a[12]} + ${a[13]} + ${a[14]} + ${a[15]})) b2=$((${a[23]} + ${a[24]} + ${a[25]} + ${a[26]})) b3=$((${a[34]} + ${a[35]} + ${a[36]} + ${a[37]})) sleep 2 # user         + nice     + system   + idle c=($(sed -n '2,5p' /proc/stat)) d0=$((${c[1]}  + ${c[2]}  + ${c[3]}  + ${c[4]})) d1=$((${c[12]} + ${c[13]} + ${c[14]} + ${c[15]})) d2=$((${c[23]} + ${c[24]} + ${c[25]} + ${c[26]})) d3=$((${c[34]} + ${c[35]} + ${c[36]} + ${c[37]})) # cpu usage per core e0=$(echo "scale=1; (100 * ($b0 - $d0 - ${a[4]}   + ${c[4]})  / ($b0 - $d0))" | bc) e1=$(echo "scale=1; (100 * ($b1 - $d1 - ${a[15]}  + ${c[15]}) / ($b1 - $d1))" | bc) e2=$(echo "scale=1; (100 * ($b2 - $d2 - ${a[26]}  + ${c[26]}) / ($b2 - $d2))" | bc) e3=$(echo "scale=1; (100 * ($b3 - $d3 - ${a[37]}  + ${c[37]}) / ($b3 - $d3))" | bc) echo $e0 echo $e1 echo $e2 echo $e3   the average cpu usage per core can be directly computed from /proc/stat (credits to @mikeserv for the hint for using /proc/stat.):  # here we make use of bash direct array assignment a0=($(sed '2q;d' /proc/stat)) a1=($(sed '3q;d' /proc/stat)) a2=($(sed '4q;d' /proc/stat)) a3=($(sed '5q;d' /proc/stat)) # user         + nice     + system   + idle b0=$((${a0[1]} + ${a0[2]} + ${a0[3]} + ${a0[4]})) b1=$((${a1[1]} + ${a1[2]} + ${a1[3]} + ${a1[4]})) b2=$((${a2[1]} + ${a2[2]} + ${a2[3]} + ${a2[4]})) b3=$((${a3[1]} + ${a3[2]} + ${a3[3]} + ${a3[4]})) sleep 0.2 c0=($(sed '2q;d' /proc/stat)) c1=($(sed '3q;d' /proc/stat)) c2=($(sed '4q;d' /proc/stat)) c3=($(sed '5q;d' /proc/stat)) # user         + nice     + system   + idle d0=$((${c0[1]} + ${c0[2]} + ${c0[3]} + ${c0[4]})) d1=$((${c1[1]} + ${c1[2]} + ${c1[3]} + ${c1[4]})) d2=$((${c2[1]} + ${c2[2]} + ${c2[3]} + ${c2[4]})) d3=$((${c3[1]} + ${c3[2]} + ${c3[3]} + ${c3[4]})) # cpu usage per core e0=$(((100 * (b0 - d0 - ${a0[4]} + ${c0[4]})) / (b0 - d0))) e1=$(((100 * (b1 - d1 - ${a1[4]} + ${c1[4]})) / (b1 - d1))) e2=$(((100 * (b2 - d2 - ${a2[4]} + ${c2[4]})) / (b2 - d2))) e3=$(((100 * (b3 - d3 - ${a3[4]} + ${c3[4]})) / (b3 - d3))) echo $e0 echo $e1 echo $e2 echo $e3   or even shorter by making extensive use of bash direct array assignment:  # here we make use of bash direct array assignment by assigning line # 2 to 4 to one array   a=($(sed -n '2,5p' /proc/stat)) # user         + nice     + system   + idle b0=$((${a[1]}  + ${a[2]}  + ${a[3]}  + ${a[4]})) b1=$((${a[12]} + ${a[13]} + ${a[14]} + ${a[15]})) b2=$((${a[23]} + ${a[24]} + ${a[25]} + ${a[26]})) b3=$((${a[34]} + ${a[35]} + ${a[36]} + ${a[37]})) sleep 0.2 # user         + nice     + system   + idle c=($(sed -n '2,5p' /proc/stat)) d0=$((${c[1]}  + ${c[2]}  + ${c[3]}  + ${c[4]})) d1=$((${c[12]} + ${c[13]} + ${c[14]} + ${c[15]})) d2=$((${c[23]} + ${c[24]} + ${c[25]} + ${c[26]})) d3=$((${c[34]} + ${c[35]} + ${c[36]} + ${c[37]})) # cpu usage per core e0=$((100 * (b0 - d0 - ${a[4]}  + ${c[4]})  / (b0 - d0))) e1=$((100 * (b1 - d1 - ${a[15]} + ${c[15]}) / (b1 - d1))) e2=$((100 * (b2 - d2 - ${a[26]} + ${c[26]}) / (b2 - d2))) e3=$((100 * (b3 - d3 - ${a[37]} + ${c[37]}) / (b3 - d3))) echo $e0 echo $e1 echo $e2 echo $e3   a top based solution  this can also be achieved without installing an additional tool with top only (i used this in a later post.) by default top does only show the average cpu load when it is started but it will show all cpus when you press 1
i have found the culprit.  it was indeed due to a faulty swap setup
you can drop-ship text from the cut buffer with swap-pasting -- pasting into a selection swaps, so dwvp line-deletes everything but the deleted word.  start with  use three words. this is the first string of another block of strings. this is the second string of another block of strings. this is the third string of another block of strings.   and do   :normal ggdd    " three-word line in the cut buffer, cursor on first "this" line :normal pdwvpo&lt;esc&gt;j  " dwvp is cut a word and exchange-paste it back for the rest of the line :normal pdwvpo&lt;esc&gt;j  " do it again :normal pdwvpo&lt;esc&gt;j  " again   for just three i wouldn't qq that but ggddqqpdwvpo&lt;esc&gt;jq@q@@ is shorter. 
yes, there's always trickle
you could ask gnome to close the current session before the shutdown
why not just apt-get install xfonts-terminus ?  the terminus fonts are already available pre-packaged for mint, see xfonts-terminus 
run which shutdown to see where the path to the shutdown program is. you can rename the file, although i recommend against it
some implementations of man, including the one used by ubuntu, replace spaces in its search terms with hyphens and attempt to find a manual page under that name
i'd recommend getting it directly from a dns server.  most of the answers here all go over http to a remote server
your server settings, like any system-wide program settings, are to be found under /etc
with netcat-openbsd, there is a -u option
suspending implies that the data you were working with is in the memory
either type reset at the prompt, or if it's a graphical terminal it probably has a menu option to reset the terminal
libata does not have a noprobe option at all; that was a legacy ide option...  but i went and wrote a kernel patch for you that implements it
you can call your favorite shell with the script as a parameter.  bash ./script.sh  
if you have a internet connected to you server, it is very easy:  # yum -y install parted  
use @reboot in addition to your timing (if your crond supports it):  @reboot command 23 0 * * * command   the obvious caveat is that if you boot your computer at 22:59 the command will run twice in very short order
edit
if you want to display all files under $home, including those referenced via symbolic links, that end with .tex and contain the string janne:  find -l "$home" -type f -name '*.tex' -exec grep -l 'janne' {} + 2&gt;/dev/null | vim -r -   if you want to display only symbolic links found under $home named *.tex corresponding to files that contain the string janne:  find -l "$home" -xtype l -name '*.tex' -exec grep -l 'janne' {} + 2&gt;/dev/null | vim -r -   the only way to avoid the error message "too many levels of symbolic links" is to discard all errors, which i've done with the 2&gt;/dev/null construct.  in both cases the find verb will not traverse across files and directories that it has already traversed - it remembers where it's already visited and prunes those parts of the filesystem tree automatically
this sounds like a crontab entry
to track the packages that are installed, updated and removed on an ubuntu system, there is the /var/log/dpkg.log file which list all the operations done.  to track the version of the kernel used at boot time, you can see this with the last command
duncaen on #voidlinux at freenode gave me this link
in vi or vim you can ignore case by :set ic, and all subsequent searches will consider the setting until you reset it by :set noic
probably don't actually have to use bsdinstall, but it provides a certain degree of confirmation
the "blocks" that stat() reports are 512 byte units
turns out that it's about configuration of getaddrinfo, which is controlled at /etc/gai.conf.  more information about how it can be solved: http://askubuntu.com/questions/32298/prefer-a-ipv4-dns-lookups-before-aaaaipv6-lookups 
procmail comes with the formail command to manipulate mail headers
the 12 lines are the nodes the packet had to go through to get to wikimedia's server
boot.img is a small(ish) file that contain two main parts.            * kernel(important for android)           * ramdisk( a core set of instruction &amp; binaries)   unpack boot.img:  it contains the following steps:   download the tool using wget http://android-serialport-api.googlecode.com/files/android_bootimg_tools.tar.gz extract the file using tar xvzf android_bootimg_tools.tar.gz.  it contains two binaries:         * unpackbootimg        * mkbootimg    3.then execute ./unpackbootimg -i &lt;filename.img&gt; -o &lt;output_path&gt;  it will contain,             * boot.img-zimage     ----&gt; kernel            * boot.img-ramdisk.gz ----&gt; ramdisk   we can extract ramdisk also, using the following command  gunzip -c boot.img-ramdisk.gz | cpio -i   after changing the files, we can again pack those files as boot.img using mkbootimg  have fun! 
well it looks like it was the arp table going stale (even though we're streaming udp like crazy, that doesn't kick the arp timeouts, and tcp traffic is much more sparse under normal operation) upping the timeouts stopped the issue from appearing for "breaks" of less than ~2mins (at which point the rtsp client session times out anyway):  arp gc_staletime extended from 60sec to 360sec arp base_unreachable time extended from 30sec to 240sec   unfortunately this took a fair bit of poking about as we're on busybox without an arp command available, but it now seems reliable for the situation we're trying to handle.  i'm still keen to understand how the network stack works - at the moment the arp table/entry goes stale it stops sending out packets yet seemingly doesn't cause errors further up the chain in the code that's trying to send packets. 
if by opencv you mean the computer vision libraries at http://opencv.willowgarage.com/ then they are already packaged for debian by the debian science team.  your best bet is to download the debianised source package from your nearest debian mirror, modify the debian/rules and/or makefile or configure etc as needed to compile correctly on the raspberry pi and rebuild the packages.  the packaging work is already done, there's no need to do it again....and again and again every time your want to update them.  there's a whole bunch of binary packages, but libopencv-dev is probably what you want to start with http://packages.debian.org/search?keywords=libopencv-dev 
short answer:  it's entirely possible that the cache will not be comprehensive
since you've got a thinkpad, besides the other suggestions (preliminary the systemd hint), if you're using the thinkpad_acpi driver, you might want to have a look at /sys/devices/platform/thinkpad_acpi/wakeup_reason
stat -f /dev/mapper/fedora_12345-root returns information about the filesystem containing the device node, which is /dev
looking at this answer and that one in particular, i ended up running this command which removed all the unwanted files:  7z l archive.zip | awk ' {print $6} ' | awk '   function basename(file) {     sub(".*/", "", file)     return file   }   {print basename($1)} ' | xargs rm -rf  
create a volume group.  mkvg  create a logical volume in the volume group.  mklv  create a filesystem on that logical volume.  crfs or mkfs  couldn't get more consistent naming than aix commands (pre-around v6).  obviously, you can use the man pages to get everything you need
if you installed the packages with aptitude and appended the --add-user-tag &lt;tag&gt; option you can list the user tags for a package by running:  aptitude show &lt;package_name&gt;   and the last line of the output should display the user tags.  you can use the following to search in all installed packages  aptitude show '~i' | grep "user tags"  
sure (it's limited on the number of glyphs, but it seems your locale is using utf-8 encoding).  i use this for testing:  #!/bin/sh # send character-string to enable utf-8 mode if test ".$1" = ".off" ; then     printf '\033%%@' else     printf '\033%%g' fi   and (calling it "utf8"), "utf8 on" turns the encoding on.  using the example given with pstree, here is an example after running the script (before, the same sort of output as in the question):    as noted in a comment, there's a script unicode_start which does more, but all that is needed to address the question posed is the small script used as an example.  addressing a different comment: at least on my system (and in the screenshot shown in the question), all of the characters used by pstree are supplied in the 512-glyph font used by default for unicode support in the linux console.  further reading:   console_codes - linux console escape and control sequences into the mist: how linux console fonts work  
the ^m is a carriage-return character
you could use the read command (bash builtin) to force characters to be read one by one :  netcat localhost 9090 | (     cnt=0     line=     while read -n 1 c; do         line="$line$c"         if [ "$c" = "{" ]; then             cnt=$((cnt+1))         elif [ "$c" = "}" ]; then             cnt=$((cnt-1))             if [ $cnt -eq 0 ]; then                 printf "%s\n" "$line"                 line=             fi         fi     done ) | grep sender   this script should print every full output with balancing {and }, but you can change the script to do whatever you want
   i cannot figure out how to get it running.   in the daemontools family world, log services are just services like any other
if it's the case of missing bootloader, i usually use http://www.ultimatebootcd.com/ 
if you have gnu coreutils ≥ 7.0, then you can use version sort
use the geometry argument.  $ abiword --geometry=[your_screen_width]x[your_screen_height] 
you don't want to reduce it, but rather increase its lazy usage — the more clean pages are already in swap, the better, it means they can easily be set off ram when free ram is needed
i think the module on rhel/centos/fedora is pcspkr
used the compiler provided in friendlyarm toolschain (download from friendlarm ftp server):  export cc=/opt/friendlyarm/toolschain/4.5.1/bin/arm-none-linux-gnueabi-gcc  i followed these instructions   modified .config as follow:  cflags += -i/home/vagrant/libnl-3.2.24/include libs += -l/home/vagrant/libnl-3.2.24/lib  # use libnl v2.0 (or 3.0) libraries. config_libnl20=y  # use libnl 3.2 libraries (if this is selected, config_libnl20 is ignored) config_libnl32=y   note that i had to compile libnl-3.2.24 first
i found the answer on askubuntu.com
in your loop, there is a short window of time between the "stty echo" at the end of the loop and the "stty -echo" at the next iteration
in the 21st century, especially if you're targeting machines that are likely to have bash or zsh, you can count on type being available
from find's man page:      numeric arguments can be specified as     +n     for greater than n,    -n     for less than n,     n     for exactly n.    -mtime n           file's data was last modified n*24 hours ago
it depends on the network setup with your vm
the easiest to do would be to boot a gparted live cd/dvd/usb, shrink the / partition by 800mb, move it to the right and then extend the /boot to 1 gb total.  furthermore, there are reasons to have a separate /boot partition but looking at the kind of questions you're asking, next time you re-install, make the /boot, /tmp and /var part of your /: less hassle and you won't run out of disk space on important directories..
as others have already mentioned -- is used to delimit options from arguments
i think you want this command:  ls -l partition | cut -c5-7 | tr rwx cse |sed 's/-//'   you can remove the one extra command(cut -d ' ' -f 1) and replace it with your last cut command(cut -c5-7)  and also add sed 's/-//' at the end to remove all -s
changing the default python (or perl, etc) on an os is really bad idea
apparently there is but only with gcc >= 4.3,the switch -frecord-gcc-switches causes the whole command line to be put into ascii commentaries.  see here for an answer to this question on so. 
the error is generated by find, not rm.  the reason is that you have written it so 'rm -i &lt;file&gt;' is the single argument
on way is to use equery's depends function to get the list of things that depend on a package.  # equery depends perl   if you want to rebuild all of them, try something like:  # emerge -a --oneshot `equery depends perl|awk '{print " ="$1}'`   you'll have issues with that if you have packages installed that were removed from the portage tree, so a sync and world update beforehand is a good idea.  for this specific case, you might also want to look at app-admin/perl-cleaner - it has specific features to rebuild perl modules. 
date (at least in the gnu implementation common today) can take the modification time of a file directly:  &gt; date -r ~/.bashrc +'%y-%m-%d %h:%m:%s %z' 2015-11-10 18:50:49 +0100   (or whatever format you desire) 
you can check /sys:  anthony@zia:/sys/class/net$ ls -l /sys/class/net/ total 0 lrwxrwxrwx 1 root root 0 dec 11 15:38 br0 -&gt; ../../devices/virtual/net/br0 lrwxrwxrwx 1 root root 0 dec 11 15:38 lan -&gt; ../../devices/pci0000:00/0000:00:1e.0/0000:07:01.0/net/lan lrwxrwxrwx 1 root root 0 dec 11 15:38 lo -&gt; ../../devices/virtual/net/lo lrwxrwxrwx 1 root root 0 dec 11 15:38 tun0 -&gt; ../../devices/virtual/net/tun0   so, actual devices show in /sys/class/net
figure out exactly what escape sequence your terminal sends for ctrl+arrow by typing ctrl+v, ctrl+arrow in insert mode: this will insert the leading esc character (shown as ^[ in vim) literally, followed by the rest of the escape sequence
this is well presented already in openssh documentation such as man pages.  in the configuration file ~/.ssh/config  host 123.4.5.67     user another   on the command line:  ssh -l another 123.4.5.67  
(posting as community wiki instead, thanks to the contributions in the comments)  it is mentioned in the book from bash to z shell (chapter 8, page 186, "generating numbers with braces") that this syntax is borrowed from perl.  in addition, it is also suggested that pascal had the .. range notation dating back as far back as 1970 (emphasis mine) ("the programming language pascal", section 6.1.2, page 17 of the linked pdf).  in conclusion, even the wikipedia link from the question stated some examples where .. is used
for file in f*.txt do name=${file:1} awk 'nr==fnr {h[$1]=$3; next} {print $1,$2,h[$1]}' "$file" "l$name" &gt; "t$name" done   thanks to @don_crissti
looking at xmonad's contrib packages, you'll find xmonad.actions.windowgo, which exports the following function:  runorraisemaster :: string -&gt; query bool -&gt; x ()   which takes a string argument of the program to run, e.g
it slightly simplifies system administration, because users can be locked out by using /etc/nologin and kill, without having to worry about processes coming back through cron or at.  it shouldn't be a big problem if you can run your own cron daemon. 
that depends on the system you are running
a very "untechnical" explanation:  swap area is hard drive space that is reserved to act as extra ram for when your computer needs more ram than what is available
use the metric directive in the interfaces
does your system use pluggable authentication modules (pam)? most modern linux or bsd use pam.  pam allows you to hook into logins
the softvol controls are stored in memory together with other data related to the actual sound card, and are saved to and restored from /var/lib/alsa/asound.state when the machine is shutting down or booting.  so to remove them, you have to   unload the sound driver module (rmmod snd-hda-intel, or whatever you're using), and then remove the entry from /var/lib/alsa/asound.state (or the entire file).  
% echo ./24feb/frfr | cut -c 1-2,5- ./feb/frfr   that would be the inverse of cut -c 3-4, that is outputs all characters (bytes with current versions of gnu cut) of each line except the 3rd and 4th.  the gnu implementation of cut also has a --complement option for that:  cut --complement -c 3-4   to remove the first sequence of decimal digits, you can use sed instead:  sed 's/[0-9]\{1,\}//'   to remove it, only if it's in 3rd position:  sed 's/^\(..\)[0-9]*/\1/'   or to be very explicit on what pattern should trigger the removal:  sed 's|^\(./\)[0-9]*\([[:lower:]]\{3\}/\)|\1\2|'   that is only removed the &lt;0-or-more-digits&gt; in a line matching: ./&lt;0-or-more-digits&gt;&lt;3-lowercase-letters&gt;/&lt;anything&gt;. 
what is a bind mount?  a bind mount is an alternate view of a directory tree
you ask for "known workarounds."  here is a simple one:  $ date -d "$(echo 20140103t1422 | sed 's/t/ /')" fri jan  3 14:22:00 pst 2014   this uses sed to replace "t" with a space
the bash extended glob +([^.]) will match files without any . in their name
   what is the difference between removing support for a feature that appears in the defaults by using -useflag in the make.conf file vs
you could use a partition on an existing linux system
did you set the where option correctly during the restore? from the manual:      before running the job, please note that the default location for   restoring files is not their original locations, but rather the   directory /tmp/bacula-restores  
rkhunter --enable rootkits --rwo   will run only the rootkit tests
for question 1: just edit /etc/gdm/custom.conf with your favorite editor
quotes (either single or double) around an argument inhibit glob expansion.  your first example passes a regular expression as an argument to grep
one way to do it, is just redefine your path  export path=/users/myself/.rvm/gems/ruby-2.0.0-p353/bin: /users/myself/.rvm/gems/ruby-2.0.0-p353@global/bin: /users/myself/.rvm/rubies/ruby-2.0.0-p353/bin: /usr/local/bin: /usr/bin: /bin /usr/sbin: /sbin: /opt/x11/bin: /usr/texbin: /users/myself/.rvm/bin:   (you'll need to put all of this on one line.)  though having a path defined twice won't hurt anything
it means that the password is locked
it is actually possible if you have set a weak password with no key files
i think you're running into this:  excerpt from thinkwiki - how to control fan speed     fan control operations are disabled by default for safety reasons
apparently at some point my os got messed up
it depends on how foolproof you want the block to be, and how much you control the system
bash works well for this:  $ cat replace foo/bar\baz the second line  $ cat file the replacement string goes &gt;&gt;here&lt;&lt;  $ repl=$(&lt;replace)  $ str="here"  $ while ifs= read -r line; do     echo "${line//$str/$repl}" done &lt; file     the replacement string goes &gt;&gt;foo/bar\baz the second line&lt;&lt;   awk would work, except that it will interpret backslash escapes (the \b in my example)  $ awk -v string="here" -v replacement="$(&lt;replace)" '     {gsub(string, replacement); print} ' file the replacement string goes &gt;&gt;foo/baaz the second line&lt;&lt;  
have you tried using yum to access the the rhel repositories and install the version of sharutils that matches your release?  $ yum update $ yum install sharutils   centos packages are generally one-to-one equivalents to rhel packages with branding removed
you could add a subshell to your alias.  alias composer='php $(pwd)/composer.phar'  
i have fresh installed debian 8.4 x64 with only gnome
it seems that no locale is generated
you are getting that error because you using an older version of bash (3.2.25).     since bash4, there's &amp;&gt;&gt;target, which is equivalent to &gt;&gt; target 2&gt;&amp;1.   source: appending redirected output  so, you should take in consideration an upgrade
from this output alone, you can't determine what program called the mkdir command.  if you have bsd process accounting, the following command shows which program had pid 24114:  dump-acct /var/log/account/pacct | awk -f '|' '$10 ~ / 24114 / {print}'   this is probably sh
i'm getting 2 from your code
from man 2 kill:     the only signals that can be sent to process id 1, the init process, are those for which init has explicitly installed signal handlers
awk '{ f[$2] = $1; sum += $1} end { for (i in f) { print f[i]/sum, i } }' &lt;/tmp/data  
you can use \r to move the "cursor" to the beginning of the line
the original v1 version of unix had a label in the source code (assembly language) called panic:
you can't do this in a sane way for google search queries.  why? google is using https (ssl) everywhere now
you can setup munin to monitor cpu temp (as well as many other things) and graph them, by default it does sampling at 5min intervals
some classic ascii invisible whitespace characters are:   tab  : \t new line: \n carriage return : \r form feed : \f vertical tab: \v   all of these are treated as characters by the computer and displayed as whitespace to a human
an idea migth be to pipe the output of tail through sed and replace the newline with bell/newline.  but there is propably an easier solution if you use tail within an x-window
you can select a column of text in konsole by holding ctrl + alt while selecting with the mouse. 
the filesystem has gone likely read-only due to same damage, as you've guessed
use something like this perhaps (if gnu grep).  grep -r 'content pattern' --include==*.cpp   man grep      --include=glob search only files whose base name matches glob (using wildcard matching as described under --exclude)   also see the options for null delimiters.     -z, --null  output a zero byte (the ascii nul character) instead of the character that normally follows a file name
the program login sets the mail environmental variable when you login to a linux virtual console.  from the login(1) manpage:     the value for $home, $user, $shell, $path, $logname, and $mail are set  according  to  the appropriate fields in the password entry
given an absolute path to the source directory:  cp -rs $pwd/sourcedir/ targetdir/   the symbolic links in targetdir will then contain absolute paths to sourcedir.  otherwise, if it just made a symbolic link, it would create something like:  targetdir/filename -&gt; sourcedir/filename   but that isn't the correct relative path to find the original file, it should be:  targetdir/filename -&gt; ../sourcedir/filename   cp doesn't try to figure out how the source and target directories relate to each other, so that it can add the appropriate number of ../ prefixes. 
this should be configured on whatever equipment you have between the dns server and the outside world
you are in a pager program, where you can scroll through the change logs of the packages that you are installing
my only experience in dealing with semaphores and shared memory is through the use of the command ipcs
do:  awk '{for (i=2;i&lt;=nf;i++) sum[$1]+=$i-10} end{for (i in sum) \           print i, "total =", sum[i]}' file.txt    {for (i=2;i&lt;=nf;i++) sum[$1]+=$i-10} iterates over the fields add creates array sum with first field as the key, and the field values subtracted by 10 as the value(es) end{for (i in sum) print i, "total =", sum[i]}, prints the keys and values of the array in desired output format   example:  % cat file.txt employee1 75 75 75 75 75 75 75 employee2 80 80 80 80 80 80 80 employee3 50 50 50 50 50 50 50  % awk '{for (i=2;i&lt;=nf;i++) sum[$1]+=$i-10} end{for (i in sum) print i, "total =", sum[i]}' file.txt employee1 total = 455 employee2 total = 490 employee3 total = 280  
i believe you can use the command ppstats -z to display compression statistics
"real" time is elapsed time, which is usually the difference between wall clock times, but not always.  for example, if you start a process at 01:59:00 on the day in which daylight-savings (summer) time takes effect in a locale in which the time change is at 02:00, and the process takes two minutes, then the real elapsed time will be two minutes, while the wall clock will show a difference of one hour and two minutes
top will display what is using your cpu
because that's not an &lt;, it's a &lt;() which is completely different
you probably want to use the serveralive settings for this
find will look through a directory structure and return results based on a glob:  find /your/dir -name "*abcde*"  adding the -type f switch will refine your search criteria to only return files.  find /your/dir -type f -name "*abcde*"  you could also include other switches like -maxdepth 2 to restrict the search to 2 levels of directories bellow the specified one.  in this way you can build up a rich, highly targetted search command that will quickly return exactly what you need
the easiest solution is to use this:  find 
for redhat derivatives, drivers are found in  /lib/modules/$kernel_version/kernel/drivers/   you can see the status of the drivers in the kernel by using lsmod.  you can find info on a module by using modinfo which will show you the location.  for example  modinfo cryptd   filename:       /lib/modules/2.6.32-504.8.1.el6.x86_64/kernel/crypto/cryptd.ko description:    software async crypto daemon license:        gpl srcversion:     8ab98ad1f94057a296739ab depends:         vermagic:       2.6.32-504.8.1.el6.x86_64 smp mod_unload modversions   
you can use rsync for that.  name        rsync - a fast, versatile, remote (and local) file-copying tool   example:  rsync -av "/path/to/source" "/path/to/destination"   note: where "/path/to/source" is the path of source directory and "/path/to/destination" is the path to directory which contains destination directory
the manual is out of date with the program
this will show all directories currently used by users:  fuser -u $(find sasuser.v91 -type d) 2&gt;&amp;1 | grep 'c('  
below is a function that you could call after the (successful) mv commands, giving it the same parameters as you did for mv, and the function will echo out corresponding commands that should put the files back where they were
in bash, you can do it with either a coproc (bash has lousy support for multiple coprocs, but you only need one here):  #!/bin/bash set -e coproc { while read -r line; do echo "$bashpid read: $line";  done; } i=0; while :; do     echo "$bashpid writing&gt;&gt; $i"     echo $i &gt;&amp;"${coproc[1]}"     read -r line &lt;&amp;"${coproc[0]}"     echo "$bashpid coproc produced&gt;&gt; $line"     i=$((i+1)) done   or named pipes (those work in simple posix shells too):  #!/bin/bash set -e trap 'rm -rf "$tmpd"' exit tmpd=$(mktemp -d)  mkfifo "$tmpd/p0" "$tmpd/p1" exec 3&lt;&gt;"$tmpd/p0" exec 4&lt;&gt;"$tmpd/p1" rm -rf "$tmpd"  ( while read -r line; do echo "$bashpid read: $line";  done; ) &lt;&amp;3 &gt;&amp;4  &amp; i=0; while :; do     echo "$bashpid writing&gt;&gt; $i"      echo $i &gt;&amp;3     read -r line &lt;&amp;4     echo "$bashpid coproc produced&gt;&gt; $line"     i=$((i+1)) done    they both might seem ugly if you're not used to fd-handling in shells.  also, due to the effect pipes have on scheduling (writing to pipes with a full pipe buffer blocks you as does reading from a pipe with an empty one), you might get deadlocked with certain read/write patterns
after searching at greater length and finding a few other sources, i think it's safe to say that gksu is nothing more than a wrapper around sudo in most cases
i think you are looking for pbzip2:     pbzip2 is a parallel implementation of   the bzip2 block-sorting file   compressor that uses pthreads and   achieves near-linear speedup on smp   machines.   have a look at the project homepage or check your favorite package repository. 
alternatively you can try to discuss your idea on irc first:   http://userbase.kde.org/irc_channels https://live.gnome.org/gnomeircchannels   but for a broader audience you might really be better off to post on the mailinglists first:   http://www.kde.org/support/mailinglists/ https://mail.gnome.org/   if you have a specific idea and are able to contribute some programming i'd suggest posting a well formulated proposal to the the respective -dev lists
yes, that would work.  if unsure, you may test it with    sleep 15 ctrl+z fg; echo "it works"  
use uname:  uname -i   for more information, see  man uname   if you get x86, it means you have 32 bit linux os and if you get x86_64, it means you have 64 bit linux. 
/dev/xvde is a xen virtual disk, and /dev/xvde1 and /dev/xvde2 are partitions on that virtual disk.  on the xen host (the dom0), /dev/xvde could be a raw disk or disk partition, an lvm volume, a disk image file, an iscsi disk or something else.  from your vm's pov, that's completely irrelevant - just treat it the same as any other disk
the first thing you have to get out of the way is the comparison to ext[234]
progress can do this for you — not quite a progress bar, but it will show progress (as a percentage) and the current file being processed (when multiple files are processed):  gpg ..
try this way:  lastcommit=$(git log -1 --oneline | cut -f1 -d" ") git diff-tree --no-commit-id --name-only -r $lastcommit  
the only options i can think of are the obvious ones:   time machine backup. grab them from a fresh install or install disk.  
if you install the busybox binary, it includes the nohup command (this will require root access)
readline library usually handles this, and inputrc tells you which codes are emitted
here is the final version of your command  find /home/student/eny/abc -type f -exec ./lynx.sh {} \;  points to note:   -type f finds files only you should specify path to your script ./ (dot slash) means current dir, you may want to specify the full path lynx.sh should have executable bit set file mode 0755 would be fine  
in a screen or tmux session, set up a shell that will reverse your changes after a delay
if you are using rsyslog or similar you can edit your config file /etc/rsyslog.conf or similar
simply,  printf '0\n%.0s' {1..1000}   or using for loop,  for i in {1..1000}; do echo "0"; done   using awk,  awk 'begin{for(c=0;c&lt;1000;c++) print "0"}'     as @stéphanechazelas pointed out, using {1..1000} requires zsh or recent versions of bash, yash or ksh93 and also means storing the whole range in memory (possibly several times)
./myshell.sh means the script myshell.sh is found in the current directory
unless you have audit logging enabled there isn't typically any way to see a log of what scripts were executed postmortem.  if it was a script that was executed from a a scheduler such as cron and/or at then these will show up in various log files under /var/log, in different log files depending on which linux distro you're using.  references   auditd man page  
sudo yum -y install iptraf &amp;&amp; sudo iptraf   might be one place to start. 
localhost as its name says can only be accessed from your local system.  if you need other users to access yout custom url you need to map your system ip address with the name used and then add this entry on all your lan workstations by editing theirs /etc/hosts files for example:  127.0.0.1         &lt;custom_name&gt; # this is for localhost &lt;your_ip_address&gt; &lt;custom_name&gt; # this is to be added to other workstations in the lan   other solution is to use a dns server in your local lan and create an a record for your custom name that will allow other users in you lan to access your link. 
that's the effect of multios.  echo foo &gt;&amp;2 | grep foo   will write foo to stderr and also pipe foo to grep
it might be possible to use aptitude's --safe-resolver option to do what you want
setting up a dummy interface  if you want to create network interfaces, but lack a physical nic to back it, you can use the dummy link type
you can determine your default shell with the following command:  grep -- "$logname" /etc/passwd | awk -f":" '{print $7}'   in my machine, sh is a link to dash, try:  ls -l "$(which sh)"  
as per the official cygwin installation page:     installing and updating cygwin for 64-bit versions of windows      run setup-x86_64.exe any time you want to update or install a cygwin   package for 64-bit windows
i think your issue is the use of eval
define your cdc function as  cdc() {     for fn do         if [[ "${fn##*/}" == .* ]]         then             source-highlight --src-lang=sh --out-format=esc -i "$fn"         else             source-highlight               --out-format=esc -i "$fn"         fi 2&gt; /dev/null  ||  /bin/cat "$fn"     done }    for fn do is short for for fn in "$@"; do. ${fn##*/} looks at the value of $fn and removes everything from the beginning up through (and including) the last /.  i.e., if $fn is a full pathname, this will be just the filename part. [[ (the_above) == .* ]] checks whether the filename matches the .* glob/wildcard pattern; i.e., whether the filename begins with a ..  note that this usage of == works only inside [[ … ]]; it does not work inside [ … ]. so, if $fn is a “dot file”, run source-highlight with the --src-lang=sh option.   you should always put shell variable references in double quotes unless you have a good reason not to, and you’re sure you know what you’re doing.  unix/linux filenames can contain spaces.  if you had a file named foo bar, and you said /bin/cat "foo bar", cat would display the contents of the file foo bar.  but, if you said cdc "foo bar" (with the current version of your cdc function), you would run source-highlight with -i foo bar, which would look for a file called foo and generally make a mess of things.  and so it would fail, and your function would try /bin/cat foo bar, which would likewise fail.  using "$fn" makes this work for filenames that contain spaces. the cp program requires you to specify, on the argument list, the name of the file or directory you want it to write to.  this is one of the few exceptions to the rule that most programs write to standard output by default (unless you specify otherwise).  you don’t need to say -o stdout, and i wonder why the author(s) of the program even made it possible for you to specify that.   and, yes, i realize that you just copied all of that from the answer to your other question. obviously, if $fn is not a dot file, just run source-highlight the normal way, and let it check for an extension. note that the 2&gt; /dev/null and the ||  /bin/cat "$fn" can be done for the if … then … else … fi block in its entirety; they don’t have to be repeated for each branch.   hmm.  my version of source-highlight (3.1.7) has a --src-lang=language option (-s language, as used by yaegashi, for short).  i just noticed that it isn’t in the source-highlight man page excerpt you included in your question.  so, obviously, if your version of source-highlight doesn’t support that option, my answer won’t work for you.  (and, of course, neither will yaegashi’s.)  if that’s the case, you should see if you can install version 3.1.7 (or compatible) of source-highlight. 
the whole point of the shadow password file is that getpwnam doesn't return passwords from it
i made it works  steps while adding:   uri address:  ipp://192.168.1.220/printer  pick (in any of three ways: ppd, database or find by printer model) this printer  ricoh aficio 2018d – pxl driver (for me ps doesn't work) additional hardware:  output option: not installed  option tray: not installed printet desc according to you   ad 1:  do you have any idea how to check the ipp having only printer?  i found out my case ipp, becuase of these:   ip got from windows (printer already installed) queue got from here http://acksyn.org/?p=175   is there a general solution? 
it may be possible that your .profile does not load the .bashrc file.  cat ~/.profile   should look somewhat similar to:  # ~/.profile: executed by the command interpreter for login shells. # this file is not read by bash(1), if ~/.bash_profile or ~/.bash_login # exists. # see /usr/share/doc/bash/examples/startup-files for examples. # the files are located in the bash-doc package.  # the default umask is set in /etc/profile; for setting the umask # for ssh logins, install and configure the libpam-umask package. #umask 022  # if running bash if [ -n "$bash_version" ]; then     # include .bashrc if it exists     if [ -f "$home/.bashrc" ]; then     
this is a very elementary question
pw is the command you are looking for
ok, so in computer science, i'm not overly fond of saying "you can't get there from here", but in this case, you're trying to fit a square peg into a round hole.  the sector size is usually set by the device
unfortunately, i think the answer is no
vim add-ons are not enabled for all users by default
you can do this with env:  env -i your_command   contrary to comments below, this does completely clear out the environment, but it does not prevent your_command setting new variables
the problem is that the default type of regex's used by find is emacs-style
it's not easy
in makefile, you refer to a variable by using syntax $(var_name)
from man feh     ctrl+delete [delete]      remove current file from filelist and delete it   ctrl+delete will do the job 
 check that you usb fat16 partition is still /dev/sdb1. open a terminal window (ctrl+alt+t). execute this command:  $ sudo syslinux --directory /syslinux/ --install /dev/sdb1  
on any system that uses terminfo:  printf "the password is %s " "swordfish" read -r line tput cuu1; tput el   press enter to erase the password and quit, or ctrl+c to quit immediately
i use keychain to manage my ssh-agent environment variables, and it deals with making sure only one agent is running at a time
how about this
there is no problem using multiple 'sudo' calls in scripts.  i find it better than running the whole scripts as root as the risks are limited by restricting the privilege elevation to the commands that really need them. 
you should always use shutdown.  you can add this to your ~/.bashrc file:  prompt_command='history -a'   this will append the in-memory history to your history file after each command is completed. 
this is a nice utility, part of linux-ftools
why don't you just split it in the files you propose and then just cat them all together?   cat rc-something.xml rc.keyboard.xml rc.mouse.xml &gt; rc.xml  the only problem is that you will need to cat them each time you modify one of the individual files, but that should be trivial.. 
one thing to bear in mind is that bash implemented arrays like ksh, that is as associative arrays where keys are limited to positive integers (contrary to other languages like perl or zsh for instance).  in:  a[123]=foo a[456]=bar a[789]=baz   in bash, you've got an associative array with 3 elements, while in perl, you'd have an array with 790 elements (789 with zsh).  in ksh or bash, ${a[@]:0} returns the first element of the array in the list of elements sorted by indices
"sda5_crypt" crypttab change as per suggestion below:  replace old_name with new_name in /etc/crypttab, and then:  # dmsetup rename old_name new_name # update-initramfs -c -t -k all # update-grub # reboot  
as @vakufo said, have you tried sending it an appropriate signal? some of the more useful ones can be issued from a terminal keyboard: ctrl-c and ctrl\ issue two of the more standard ones
if nothing else, you need a case statement.  random(){         printf "%d^${2##*[!0-9]*}\n"  "$(($(                 export  lc_all=c; a=$1                 while   x=${a%"${a#?}"} s=                         case  $a     in                         ([a-z]-["$x"-z]*|[a-z]-["$x"-z]*)                                 a=${a#??} s=?                                 printf  '(%d-%d+1)+' "'$a" "'$x";;                         ([0-9]-["$x"-9]*)                                 x=${a%"${a#???}"} a=${a#"$x"}                                 printf  "$((-($x)+1))+";;                         (?-*)   a=${a#??}                                 echo 2+;;                         (?*)    x=${a%%[a-za-z0-9]-*}                                 a=${a#"$x"}                                 echo "${#x}+";;                         (*) !   echo 0          ;;esac                 do              a=${a#$s}       ; done         )))"    |       bc|     sed 's/$/ possibilities./                                       /^1 /s/....$/y./' }   ok, i have to apologize - i only now realized that what i thought were char classes were literal arg strings - and that you were parsing them
the dd command need to be run in the background (i.e
this is a solution that only needs bash and netcat (traditional version)
rsync is able to do this.  rsync --ignore-existing &lt;src&gt; &lt;dest&gt;   you can perform also various kinds of updates
i've always used unetbootin to do these types of installations
loop device is a pseudo ("fake") device (actually just a file) that acts as a block-based device
you basically just need to edit your grub boot menu.  as root, or using sudo, edit /boot/grub/menu.lst  the first thing to do is change the timeout value to something more to your liking
your previous question made me think of machines in a local network configuration
afaik, the only way to "catch" a signal like this is to use the trap command
it's the vm that will need a (virtual) graphics card, not the host.  just use the -vnc option to kvm/qemu and connect to that vnc server from a machine that has a graphical interface (any machine with a vnc viewer even ms-win will do).  kvm -hda your-disk.img -cdrom installer.iso -m 1024 -boot d -vnc :0 -monitor stdio   and connect from the vnc viewer to the-host:0.  -monitor stdio is so you can control that vm (shutdown, attach devices, send keys...) from the command line. 
in os x 10.8.5, bash 3.2.53(1), macports 2.3.4 you should actually do nothing.  i don't know though why it didn't work at first
first, from your experience with the second card, it seems that your reader is damaged and now damages the cards you insert into it
it seems by defaul help foo is actually equivalent to help foo*. but if some special globbing characters are used then the ending "*" is not implicitely added.  so, a possibility would be help [r]ead.  the globbing used is the one used by the shell for file matching; afaik there isn't any equivalent of \&lt; nor \&gt;. 
you could do like this if there are more number of files,  grep '' *.csv | cut -d: -f2 | sort -u &gt; output.csv  
on debian-derived systems, for hardware information use lshw, hwinfo, udevadm, hdparm, inxi (this one needs installing first) etc
probably not
using only the nomodeset kernel option got me the results i wanted, the console now fills the entire screen. 
ooooh i found it, i just need to use the $'' syntax instead of $"":  $ grep -c1 --group-separator=$'\n\n' 'hello' a hello this is me    something else hello hello bye   from man bash:     quoting      words of the form $'string' are treated specially
you don't need any variables here.  scp /local/michael.txt /local/jason.txt /local/jerry.txt \     /local/wong.txt /local/lee.txt /local/mark.txt       \     root@example.com:~/   you can also use the brace expansion:  scp /local/{michael,jason,jerry,wong,lee,mark}.txt root@example.com:~/  
(this started as a comment but became too long so is now an answer)  unfortunately, the answer is "no"
accounting for the comment that echo only "beeps" my computer, the question is not looking for a way to use echo (or tput bel), but for something like that mentioned in remotely make the computer beep on built-in speaker.  that wouldn't be in the standard centos repositories since it is not in red hat enterprise
i had the same question, and found the existing answers and comments here a little uninformative
the optimum way is to simply ignore curlftpfs for this access, because the ftp protocol has an append command to add data to a file
the simplest is to use three consecutive printf, the main one with %s instead of %q:  $ printf '{"log": "'; printf '%s\\n' $(&lt;file); printf '"}\n' {"log": "1\n2\n'\n3\n4\n"}  
you would need to switch it on.  it's unlikely you're going to have wake on lan available for a virtual host, because a switched off vm is more like having the power cord removed
do piping of the result [sato]  find |  | cut -c -80   or    find ..
to change the default filemanager you can edit the file ~/.local/share/applications/mimeapps.list  don't know how to specify thunar but to use nemo over nautilus i do this:  thomas@localhost ~&gt; cat .local/share/applications/mimeapps.list  [added associations] inode/directory=nemo.desktop;   also if you are curious why the wrong filemanager is started if you click on a folder icon check the actual command the starter launches.  after resolving the issues (see comments) you also have to look in the file  /usr/share/applications/mimeinfo.cache   there you can change the filemanager also:  inode/directory=nautilus.desktop inode/directory=nemo.desktop  
this is all due to the fact that the x server is out-dated, ill-suitable for today's graphics hardware and basically all the direct video card communication is done as an extension ("patch") over the ancient bloated core
i finally found a solution.  this is the fifo device i create when system boots:  log_dev=/dev/logi if [ ! -r $log_dev ]; then     mkfifo $log_dev     chmod 640 $log_dev     chown root:morfik $log_dev fi   i just added this to the /etc/init.d/rsyslog file.  having that device i can send all logs there by placing the following line in the /etc/rsyslog.conf file:  *.*                 -/dev/logi   it's the fist line in the rules section, so every log goes there and continues processing other rules in the config file
as root you can bypass the requirements
if an alternate program is an option, i think i used jpeginfo -c the last time i needed to check the validity of a bunch of jpeg files. 
you can filter it in find by using -mindepth option
sed/awk are really about regular expressions. check this answer on stackoverflow why parsing html/xml with regular expressions is a bad idea.  for xml you really need to build a dom of the document and then find your information
short answer  in bash (and dash) the various "job status" messages are not displayed from signal handlers, but require an explicit check
several sources:   git clone http://git.kernel.org/pub/scm/docs/man-pages/man-pages http://tldp.org/manpages/man.html http://ubuntu-manual.org/?lang=en_us   these are just a few ;) 
in the normal interface, linux's fdisk applies alignment constraints to partitions
i am not familiar with ubuntu but there is no reason to assume that an ubuntu live cd/dvd has problems with md softraid
if you're using gnome, or have some gnome tools installed, you can use gnome-screenshot with the --delay=# option
first, here's the specific answer to your question of why the unknown user error persists: the error was in how you created the user
your solution works, just could be simplified, plus the output saved, with feedback:  $ sed -r 's/(.{79})/\1\n/g' output.txt | tee output2.txt    sed command can already take file..
another option   ls -i    which give (with proper inode value)  5233 &gt; option[value='2016']   5689 foo   then  find 
for freya, apparently installing elementary tweaks and changing the setting there works:  apt-get install elementary-tweaks   then, access the settings menu and click on the tweaks icon.     you can then toggle single click on/off as you like.    unfortunately, this didn't work for me, and the setting immediately toggled back on as soon as i exited the settings menu.  i had better luck with the following command:  gsettings set org.pantheon.files.preferences single-click false  
follow the tutorial posted on the official website to upgrade linux mint 17 to 18 using mintupgrade tool or using the linux-mint.iso:  1) using the mintupgrade tool  use the backup tool to backup your data.   using the update manager, click on "refresh" to refresh the apt cache and apply all level 1, 2 and 3 updates. give your terminal unlimited scrolling:  open a terminal.  click on "edit"->"profile preferences"->"scrolling".  check the "unlimited" option and click "ok". install the upgrade tool  apt install mintupgrade check the upgrade  mintupgrade check download the package upgrades:  mintupgrade download apply the upgrades  mintupgrade upgrade   2) using the  live dvd linux-mint 18 :  this tuto explain how to upgrade your current version and how to restore your data and your software selection. 
tar -c data_dir | wc -c without compression  or  tar -cz data_dir | wc -c with gzip compression  or  tar -cj data_dir | wc -c with bzip2 compression  will print the size of the archive that would be created in bytes, without writing to disk
no, there's no posix way, other than compiling a c program that does it
based on the error messages, it looks like your upgrade is trying to upgrade your 5.3.6 version of php to an older version (5.2.17), and it's running into conflicts.  did you add an extra repo in the past?  what is the output of   yum list *php*   i'd expect that you have 2 different repos listing php
there are a list of web browsers that use trident shell as listed in the wiki page here.  apparently, tencent has support for linux and it uses trident shell
there are multiple ways to achieve what you want
aliases are like commands in that all arguments to them are passed as arguments to the program they alias
interact will get its input from expects standard input, which is the pipe to echo now closed.  you can write it instead (ksh/zsh/bash syntax):  expect &lt;(echo "spawn gdb   expect \"(gdb) \"   send \"help\r\"   expect \"(gdb) \"   interact" )   that's still fed via a pipe, but this time, the pipe is given as a path argument to expect so expect's stdin is not affected.  in this case though, the obvious may to write it would be:  expect -c '   spawn gdb   expect "(gdb)"   send "help\r"   expect "(gdb) "   interact'   expect like sh and most shells allow passing inline scripts with -c.  if you still need to pass the output of a command (like echo in your case), you can do it with -c as well with:  expect -c "$(echo...)"   that means however that contrary to the pipe approaches expect won't start until that command has finished.  btw, here, you could use a .gdbinit  file instead or -ix option to gdb, you don't really need expect. 
they are compiler hints for gcc
as for overwriting each disk with random data, it's redundant
convert the number into hex than use echo to print the according byte sequence and pipe that into base64
iused means inodes space used
apps will only max out the cpu if the app is cpu-bound. an app is cpu-bound if it can quickly get all of its data and what it waits on is the processor to process the data.  apt-get, on the other hand, is io-bound
the vm is the only secure solution.  you could use chroot-ed setup to isolate the app in question from the rest of your system, but remember, that if that app is clever enough to detect that it runs under wine, that wine is running under osx and, finally, it succeeds to break the chroot jail then you are at risk.  although the probability of such a situation is quite low, it is still possible
for swf in *.swf; do     xml="$swf.xml"     swf2xml "$swf" "$xml"     sed -i '' -n '/swf/p' "$xml" done  
they are a completely random 192-bit identifier (c.f
sed -n '/foo/{:a;n;/^\n/s/^\n//;/bar/{p;s/.*//;};ba};'   the sed pattern matching /first/,/second/ reads lines one by one
removing the drive mid-session did cause file system corruption
if you want to print only the first 75 characters of the second column (including spaces, and assuming only two columns in the file), you can do:  $ perl -pe 's/(\t.{75}).*/$1/' file xy981743    foobarlkasdf saflkas asfzr!sgfad asdsad asdsadf sadfasdf46lk lksad bar fool   or, with gnu sed:  $ sed 's/\(.*\t.\{75\}\).*/\1/' file xy981743    foobarlkasdf saflkas asfzr!sgfad asdsad asdsadf sadfasdf46lk lksad bar fool   or:  $ sed -r 's/(.*\t.{75}).*/\1/' file xy981743    foobarlkasdf saflkas asfzr!sgfad asdsad asdsadf sadfasdf46lk lksad bar fool   alternatively,  you could use fold, telling it to cut at the first 91 characters (that's 8 for the identifier and another 8 for the tab), and printing only the first line:  $ fold -w 91 file | head -n1 xy981743    foobarlkasdf saflkas asfzr!sgfad asdsad asdsadf sadfasdf46lk lksad bar fool     if your file can have more than 2 columns and you only want to truncate the second, you can do (which, as i just noticed, is just a rewording of stephen's answer):  $ awk -f"\t" -vofs="\t" '{$2=substr($2,1,75)}1;' file xy981743    foobarlkasdf saflkas asfzr!sgfad asdsad asdsadf sadfasdf46lk lksad bar fool   or (note that this will break if the first 75 characters of the 2nd column can be interpreted as a regular expression):  $ perl -f"\t" -pale 's/$f[1]/substr($f[1],0,75)/e' file xy981743    foobarlkasdf saflkas asfzr!sgfad asdsad asdsadf sadfasdf46lk lksad bar fool  
usually the main criterion for snat is "traffic that's going out a given interface" (i.e
i use a structure like:  /var/www/sites/ /var/www/sites/project.com/ /var/www/sites/project.com/includes/ /var/www/sites/project.com/library/ /var/www/sites/project.com/www/ /var/www/sites/project.com/www/index.php   where /var/www/sites/project.com/www/ is set as the virtual host's document root, and i use index.php to include files from library/ &amp; includes/  this way i have organized my project to have the bulk of the php outside of apache's document root -- as you're looking to do
there are different ways to achieve your goal.  if the guests share a virtual network (i.e
with the following script it works (using mplayer, which is probably not present on many systems).  #!/bin/sh grep -a 1000 --text -m 1 ^ogg "$0" | mplayer - exit oggs^@^b^@^@^@^@^@^@^@^@^]f&lt;8a&gt;g^@^@^@^@lyß¸^a^^^avorbis^@^@^@^@^a"v^@^@^...   the last line is the beginning of the audio file binary.  the grep command searches for the first occurrence of ogg in the file $0 (which is the script file itself) and prints 1000 lines after that line (is enough for my small audio test file)
you can use chpasswd to do it, like this:  echo "username:newpassword" | chpasswd   you can pipe into chpasswd from programs other than echo, if convenient, but this will do the trick.  edit: to generate the password within the shell script and then set it, you can do something like this:  # change username to the correct user: usr=username # this will generate a random, 8-character password: pass=`tr -dc a-za-z0-9_ &lt; /dev/urandom | head -c8` # this will actually set the password: echo "$usr:$pass" | chpasswd   for more information on chpasswd, see http://linux.die.net/man/8/chpasswd  (command to generate password was from http://nixcraft.com/shell-scripting/13454-command-generate-random-password-string.html) 
if you want list all ip address, regardless its name, try this:  ifconfig | perl -nle 's/dr:(\s+)/print $1/e'   or:  ifconfig | awk '/inet addr/{print substr($2,6)}'  
there's a evident wrong configuration:  lvm_crypt /dev/sda5 none luks  you decrypted the volume and named it lvm_crypt while mounting /dev/mapper/mint-root  were you asked to input the password during boot ?  also, did you updated initramfs afterwards ? because this crypttab need to be embedded since it's for root partition.  edit  mint_root /dev/sda5 none luks  and chroot inside, do update-initramfs -u will fix it. 
 all modern operating systems support multitasking
you can use lookbehinds and lookaheads after enabling pcre (via -p):  root@xxxxxxvlp03 ~ $ echo "temp=50.0'c" | grep -po "(?&lt;=temp\=).*(?=\'c)" 50.0 root@xxxxxxvlp03 ~ $  
screw grub
thanks @dubu i didn't know that flag existed
you asked,     whether a backup utility like rsync is suitable for copying data from a database, mysql or not   the answer here is an emphatic "no!".  unless you are prepared to switch off mysql while you perform an rsync-based backup you will almost certainly end up with a corrupted database on your backup
your drops are all marked as tcp syn
i believe it is from loopback,     loopback, or loop-back, refers to the routing of electronic signals, digital data streams, or flows of items back to their source without intentional processing or modification.   it is a loop device because it is backed by a file on a different file-system.  see also loopback device,     a loopback device is a mechanism used to interpret files as real devices
not sure where to start here.   gnome is a gui user environment, not an os
run the script as follows:  $ sudo bash /home/amal/netbeans-7.3-javaee-linux.sh   this script will execute and install netbeans. 
try:  find /mystuff/temp/videos -type d ! -name 'folder1' -exec chmod 777 {} +   a note that you should not set 777 permission, it's a big hole in security. 
the man page for my mailx says a lot of things about set nosave and so on, but they dont seem to work
replacing the main theme with the dark one in /usr/share/themes is not an ideal solution as each time gnome-themes is updated your theme will revert to default
(based on comments)  you have overridden the default library resolver path so that the stdc++ library is being called from the xilinx directory, rather than the os default
you can use awk to search by the third column  awk -f"-" '$3 ~ /@woods.com/' list.txt  
some unix systems allow only members of the wheel group to use su
an x11 client is storing context data on the x server side
it is not clear if you search for page in/out caused by paging or by swapping
you can't
you want pane-active-border-style and pane-border-style:  see the entry in the man page:               pane-active-border-style style                      set the pane border style for the currently active pane
i do not think this is possible
if you look at your sources.list then it'll show something something similar to  deb http://ftp.us.debian.org/debian/ jessie main non-free contrib deb-src http://ftp.us.debian.org/debian/ jessie main non-free contrib  deb http://security.debian.org/ jessie/updates main non-free contrib deb-src http://security.debian.org/ jessie/updates main non-free contrib  # jessie-updates, previously known as 'volatile' deb http://ftp.us.debian.org/debian/ jessie-updates main non-free contrib deb-src http://ftp.us.debian.org/debian/ jessie-updates main non-free contrib   the "fun" part is that it says us.debian; this means "pick a us based server".  debian maintain a list of regional mirrors for many countries at  https://www.debian.org/mirror/list   you can pick a regional mirror, or delve down to a specific provider based on that list. 
a regular solaris instance will provide you the global zone.  using zonecfg and zoneadm you can configure and install zones  a typical zone creation is performed by:  #configure the zone zonecfg -z zu9dms create #make some modifications if you want an alternate zonepath or autoboot for example verify exit   it is very important that the directory which will contain the zones is owned by root and that the mode is 700  #install the zone zoneadm -z zu9dms install  #boot the zone and enter the console of the zone zoneadm -z zu9dms boot; zlogin -c zu9dms  #wait until smf is configured and follow the system configuration assistant   for further reading i suggest you to read the man pages man zonecfg and man zoneadm 
tput can handle expressions (for instance in sgr and setaf) which the typical shell-scripter would find less than usable
actually, the problem sorted itself
the / character is an operator in sed
looks like you missed something. from the debian documentation:     6.3.2
if you've just downloaded the user script and its name is appearing in the bottom bar, open the extensions page (menu &gt; tools &gt; extensions, chrome://chrome/extensions/), then drag-and-drop from the download bar to the middle of the extensions page
if you are using bash try to put this in your bashrc/bash_profile:  alias cd='cd $1 &amp;&amp; ls -lrth'   update:  this is not correct, i just double checked it, it is just listing the dir you did want to cd in but it stays in your actual dir where you launched the command.  update 2:  you have to create a bash function instead of an alias it is much safer than overriding a built in command.  cdd() {      cd "$1" &amp;&amp; ls -lhtr; }   this should work. 
i strongly agree with faheem.  this is kind of a "why choose the easiest solution when one can do it the hard way?" case.  seriously, put your cd, erase everything, let the installer choose or just use 2 partitions: / (root) and swap (2 times your ram)
please check stat output:  # stat .xsession-errors    file: ‘.xsession-errors’   size: 839123          blocks: 1648       io block: 4096   regular file device: 816h/2070d      inode: 3539028     links: 1 access: (0600/-rw-------)  uid: ( 1000/     lik)   gid: ( 1000/     lik) access: 2012-05-30 23:11:48.053999289 +0300 modify: 2012-05-31 07:53:26.912690288 +0300 change: 2012-05-31 07:53:26.912690288 +0300  birth: -  
the answer to my own question is
as long as i found the proper solution, i will answer my own question
the behavior can be reproduced with:  export histsize=v=   for some reason i had that in my .bashrc file
ssh "$1" "find /var/images -type f -print0" |   xargs --null --replace --max-procs=x rsync "${1}:{}" /my/destination   should do the trick. 
use perl rename
you'll want to run brew install homebrew/versions/boost155  $ brew search boost boost                              homebrew/science/boost-compute boost-bcp                          homebrew/versions/boost149 boost-build                        homebrew/versions/boost150 boost-python                       homebrew/versions/boost155 caskroom/cask/iboostup             caskroom/cask/pivotalbooster   caskroom/cask/turbo-boost-switcher  
libbpg depends on version  1.6 of the png library, which you cannot install with apt-get on linux mint 17
note that lilo is the default slackware bootloader, although you can find a grub package in the extra directory of your slackware dvd
assuming you want to use a &amp;&amp; b || c, then simply call the function directly:  tst &amp;&amp; echo "success" || echo "failure"   if you want to use [[, you'd have to use the exit value:  tst if [[ $? -eq 0 ]] then      ...  
use -r flag:     -r or --raw-control-chars      causes "raw" control characters to be displayed
the correct virtual link is:  ln -s /tools/lib/crt*.o /tools/lib/gcc/i686-lfs-linux-gnu/4.8.2/  
to get rid of the subtitles i believe you can add the -nosub switch, right after the .vob file's name.  example  $ mencoder videos/test/video_ts/vts_01_1.vob -nosub -nosound -ovc x264 \ -x264encopts direct=auto:pass=2:bitrate=900:frameref=5:bframes=1:\ me=umh:partitions=all:trellis=1:qp_step=4:qcomp=0.7:direct_pred=auto:keyint=300 \ -vf scale=-1:-10,harddup -o video.avi   details  these incantations are often very dense so to break this one down a bit   input file:  videos/test/video_ts/vts_01_1.vob output file: -o video.avi no subtitles: -nosub don't encode sound: -nosound encode with given codec: -ovc x264   list of other codecs  $ mencoder -ovc help mencoder svn-r36171-4.8.1 (c) 2000-2013 mplayer team  available codecs:    copy     - frame copy, without re-encoding
$ alias magick="printf '%5s\n'" $ magick 10    10  
to change your default group on the fly, use newgrp:  newgrp some_group   after running that command, you will be in a new shell with your group set to some_group and files that you create will be in group some_group
that depends on how you define which files should be set as executables
 psqlcmd1="psql -c \"""alter user root with encrypted password 'd1£lf1a\!2enzy6p$9examplepassword';""\""    with history expansion turned off, the value of psqlcmd1 is  psql -c "alter user root with encrypted password 'd1£lf1a\!2enzy6pexamplepassword;"   inside double quotes, the only characters that don't stand from themselves are \"$`, plus ! if history expansion is enabled
the dirty bit is set and cleared in the kernel, when mounting and unmounting a device; see http://lxr.free-electrons.com/source/fs/fat/inode.c?v=3.19#l578 for the implementation
you can get it from /dev/vcs1 (for the first virtual console (tty1)).  cat /dev/vcs1   but chances are those lines are also in a log file
you can't use escaping this way
the correct way to delete a package is pacman -r package-name
i guess you could run your full-screen program in tmux or screen pane directly, without additional shell session (shell is just another program).  another way, which i prefer, is to use tiling/stacking window manager like i3 and terminal program urxvt
the link given by @steve is appropriate, but if you want to try something simple first just to see what the device does you can use dnsmasq, which is a simple dns and dhcp server
i assume that you use vim, because  :helpoctal is a vim's command
this is changed by changing the environment variable ps1.  you can see the current value of ps1 by:  root@monu dev# echo $ps1   you can see the value to be equal to \u@\h \w\$, where:   \u : username \h : hostname \w : current working directory \$ : a # symbol for the root user, a $ symbol for other users   if you want the change to be permanent, you have to add the script changing the value of ps1 in ~/.bashrc, since that it gets executed every time a user logs in. 
the standard command for that is od, for octal dump (though with options, you can change from octal to decimal or hexadecimal...):  $ echo apple | od -an -vtu1   65 112 112 108 101  10   note that it outputs the byte value of every byte in the file
i solved this by installing yaourt and customizepkg, which allows me to have the best of both worlds: the latest and greatest versions from the official repositories, automatically patched to my specific needs. 
you can try adding the string init=/bin/sh to the kernel line in grub
   i'm not sure what best practice dictates as far as setting the "group" and "others" file permissions.   a normal approach would be 755, so group and other have read-execute permission
in your ~/.bashrc or ~/.bash_profile simply source the "enable" script provided with the devtoolset
it's all about risk mitigation; if make does something destructive, you can only lose whatever data was modifiable (or deletable) by the user running it
the file can be access through the /proc filesystem: you already know the pid and the fd from the lsof output.  cat /proc/21742/fd/5  
ok, you messed things up
memcached doesn't have a configuration file on arch anymore since may 2013. 
suppose your usb drive is mounted to /media/usb then it would be sufficient to do   sudo umount /media/usb   suppose the your usb is /dev/sdb1 then you could also do  sudo umount /dev/sdb1   you may also have a look at the anwers of one of my questions, how to umount all attached usb devices with a single command: umount all attached usb disks with a single command 
the linux kernel has options to restrict what physical address ranges it will use as ram, but that won't prevent buggy drivers or access through /dev/mem to escape those ranges
it isn't bash doing this optimization, it's gnu tar
for os x look for your share name under /volumes (it may have a "-digit" at the end if you have many mounts with the same name)
what i do, as the root user:   install the srpm as you would any other package (rpm --install [source-rpm-filename]) examine /root/rpmbuild/specs directory and find the specs file that matches your package rpmbuild -bb /root/rpmbuild/specs/[found-filename]   the resulting binary packages are then located in the /root/rpmbuild/rpms/ directory which are ready to be installed via the standard rpm --install command.  note: this just builds what is in the standard binary package
you need to escape the special characters, e.g.  $ rsync server:/var/log/foo/2014-07-06-\*.log .   or  $ rsync 'server:/var/log/foo/2014-07-06-*.log' .   or better, install url-quote-magic, e.g.  autoload -uz url-quote-magic zle -n self-insert url-quote-magic zstyle ':urlglobber' url-other-schema http https ftp mailto   so that zsh will automatically do this for you
deamontools you mentioned work just fine as user
e4fsprogs on rhel5 is just a newer version of e2fsprogs
one interesting possibility i forgot is what tyler szabo's answer to my question multiseat gaming? @gaming.se suggests:     i would use vmware
you have to use the following format :  #!/bin/bash saveifs=$ifs while ifs= read -r line &lt;&amp;3 do     echo "$line" done 3&lt; myfile.txt ifs=$saveifs   test is :  root@debian:/home/mohsen/test/shell# ./linebylibe.sh  ff dd gg tt tt ww ee   and my myfile.txt is :  root@debian:/home/mohsen/test/shell# cat myfile.txt  ff dd gg tt tt ww ee  
you can try to find the relevant files with find:  find /usr/something -maxdepth 1 -user antoine   you can then use -exec to create a zip file from the results of find:  find /usr/something -maxdepth 1 -user antoine -exec zip /tmp/file.zip {} +   leave out the maxdepth if you want to recurse. 
each number (also referred to as an octal because it is base8) in that grouping represents 3 bits
you are confusing bash with python
i think you're simply confused by the broken punctuation on that page
you can check whether the process is in stopped state, t is ps output.  you can do:  [ "$(ps -o state= -p pid)" = t ] &amp;&amp; kill -cont pid    [ "$(ps -o state= -p pid)" = t ] tests whether the output of ps -o state= -p pid is t, if so send sigcont to the process
the ssh protocol is defined by what the ssh and sshd programs accept
determine your exposure  taking your output from the netstat command, what looks like a lot of services is actually a very short list:  $ netstat -lntup | awk '{print $6 $7}'|sed 's/listen//'| cut -d"/" -f2|sort|uniq|grep -v foreign avahi-daemon:r dhclient dropbox nmbd rpcbind rpc.statd smbd sshd   getting a lay of the land  looking at this list there are several services which i'd leave alone
not the most elegant way, but here's how i would do it:   replace the port specifications in your original file with a unique pattern
actually, all of these interfaces are capable of backlight control (and more), as long as both, graphics card and the monitor support the display data channel.  ddc is based on i²c, so you have to install and load appropriate kernel modules to make it work.  # debian sudo apt-get install i2c-tools sudo modprobe i2c-dev  # rhel sudo dnf install i2c-tools   after that, you have to find out which i²c bus is connected to the monitor using sudo i2cdetect -l.  # example output for intel graphics card i2c-0   i2c         i915 gmbus dpc                      i2c adapter i2c-1   i2c         i915 gmbus dpb                      i2c adapter i2c-2   i2c         i915 gmbus dpd                      i2c adapter i2c-3   i2c         dpddc-b                             i2c adapter i2c-4   i2c         dpddc-c                             i2c adapter  # example output for amd graphics card i2c-0   i2c         radeon i2c bit bus 0x90             i2c adapter i2c-1   i2c         radeon i2c bit bus 0x91             i2c adapter i2c-2   i2c         radeon i2c bit bus 0x92             i2c adapter i2c-3   i2c         radeon i2c bit bus 0x93             i2c adapter i2c-4   i2c         radeon i2c bit bus 0x94             i2c adapter i2c-5   i2c         radeon i2c bit bus 0x95             i2c adapter i2c-6   i2c         card0-edp-1                         i2c adapter i2c-7   i2c         card0-vga-1                         i2c adapter   in intel case, the right bus is one of dpddcs (display port ddc), depending which on port are you using
i believe i got it working, it may just work on synology dsm systems that run linux based, so ymmv
trap "exit 1" int  while true; do     ping host -c 1 -w 3 &gt; /dev/null &amp;&amp; break;     sleep 1 done  trap - int # restore handler  
you need to have collation locale changed
this is an easy to fix bug, please see the 7th entry on my blog post about fixing common steam on debian linux problems: http://www.yannbane.com/2013/02/how-to-steam-on-linux-debian-70.html.  solution:   right click on desktop create launcher... start writing "steam" into the name box, and then select it from the suggestion. create   try to run it! i doesn't work, does it? well, neither did mine, but i've figured out how to fix it:  sudo mousepad /usr/bin/steam, after the line that begins with a '#!' (shebang) add:  steamlibs=${home}/steamlib ld_library_path=${steamlibs}  export steamlibs export ld_library_path    completely quit steam. try your new launcher.  
you can't do this with iptables alone.  you could use iptables for the network redirect, and then a webserver vhost  to redirect the url from 192.168.2.19/* to 192.168.2.15:6969/test.js/* (or whatever). 
your function was trying to evaluate $returnstring on the left-hand side during the assignment; instead, you want:  egrepusernames(){     returnstring="";     for username in "${usernames[@]}"     do         returnstring="$returnstring -e $username" # this line changed     done     printf '%s ' $returnstring;  ## so did this one }  
you can use rename (it's designed for that)
note  this no longer works with more recent versions of os x, including 10.10 yosemite (i'm not sure about 10.9 mavericks)
emerge pfl &amp;&amp; e-file filename  you need to use the full file name (it also supports full path), it doesn't do partial matches as that would yield too many results; probably to spare bandwidth
yes
add after=mysql.service to your service file (or change it to the correct service name), e.g:  [unit] description=boardies email server startup script after=mysql.service  [service] execstart=/home/bits/emailserver/start.email restart=always  [install] wantedby=multi-user.target   please note that you don't have to put your service file into /lib/systemd/system, it is a user provided file and you should only copy it to /etc/systemd/system.  to get a list of all service files you can use systemctl list-unit-files and determine the correct name for your database service (it is probably either mysql.service or mysqld.service) 
install disper.  in ubuntu-beased systems:     sudo apt-get install disper   in arch-based systems it is in aur.  various commands available with this utility here.  the command to cycle between clone, extended, internal and external displays should be like this:  disper --cycle-stages='-e : -c : -s : -s' --cycle   in that case, it would extend to the right
like this?  [root@b se]# wget -cqo - https://github.com/jeffhoogland/moksha/archive/0.1.0.tar.gz | tar -xz --transform=s/moksha-0.1.0/moksha/ [root@b se]# ls moksha [root@b se]# ls moksha about-nls       config.guess          debian                 makefile.am aclocal.m4      config.guess.dh-orig  depcomp                makefile.in authors         config.h.in           doc                    missing autogen.sh      config.rpath          enlightenment.pc.in    netwm.txt autom4te.cache  config.sub            enlightenment.spec.in  news backports       config.sub.dh-orig    install                po bugs            configure             install-sh             readme changelog       configure.ac          intl                   src compile         copying               ltmain.sh              xdebug.sh config          data                  m4                     x-ui.sh   from the tar manual page:   --transform=expression, --xform=expression     use sed replace expression to transform file names.   so sed is probably required for this to work
after replacing the networking interface card, there will remain old entries in /etc/udev/rules.d/70-persistent-net.rules.  the solution is to remove the lines containing the old mac addresses in this file, in our case there were 3 lines that could be removed, reboot and bingo.  the e1000e is now correctly loaded again: networking fixed.  thanks to: http://linuxadmin.com.pl/replacing-network-interface-card-nic-in-ebian5-os/ 
i think that what you need is a file manager, like midnight commander
if you are kernel development you could have sudden kernel panic, sysrq key will be very valuable
if you're using linux, the best way to distinguish between input devices is to use the linux event interface
unix commands almost always (with very few exceptions) have source before target
assuming you want to view the nth line of a file, you could simply do:  sed -n '42p' yourfile.py   replace 42 with whatever line number you want to see.  after your edit: if you also want to execute this code, simply pipe it to python:  sed -n '42p' yourfile.py | python  
as mentioned by @kusalananda, usually upgrades are done by removing the old file, and creating a new one with the same name
you can use bash's string substitution features for that:  for file in /tmp/p/dsc*.jpg; do   cp "$file" "${file%.jpg}"_orig.jpg done   the general format is ${string%substring} which will remove substring from the end of string
use expect, or an implementation of such in another language (wikipedia has a list of these at present)
edit /etc/samba/smb.conf, in [global] section, change the following configurations:  netbios name = debian server string = debian  
you just need to escape the $ character, as in   echo "\${str1}" &gt;&gt; myfile   or   echo "\$str2" &gt;&gt; myfile   alternatively, you can use single quotes  echo '${str1}' '$str2'  
the capability to define a new connection on the command line with nmcli dev wifi con … was added in networkmanager 0.9.6
this is possible for syslinux:  syslinux ~/floppy.ima   the syslinux installer contains enough magic to be run on an unmounted filesystem
try paste command :  paste -d';' file1 file2 &gt; file3  
you could pipe it through tr, sort, uniq, for example on command prompt you can test this:   $ var1='50003 50003 50003 50001 50003'   next,   $ echo $var1 | tr ' ' '\n' | sort | uniq 50001 50003   as you can see it outputs unique, and sorts it in case you want to do something with it later that requires sorted input.  update  for your additional question in comments, if you wish to save the results into a variable, you can, in script:  var2="$( echo $var1 | tr ' ' '\n' | sort | uniq )"    $( ..
when you see the handlers like gphoto2:// and smb:// these are special interfaces that the gnome desktop or whatever file browser you're using is making available to access these devices
host + f1, default host key is right ctrl. 
generally not, but with newer versions of mount/swapon/fsck..
note that with zsh, you can do:   printf '%s() {\n%s\n}\n\n' ${(kv)functions[(r)*gitignore*]}   to retrieve the information from the currently defined functions (that doesn't include the comments obviously).  now, if you want to extract the information from the source file, then you can't do reliably unless you implement a full shell parser.  if you can make some assumption on how your functions are declared, like for instance if you always use that ksh-style function definition, with function and } at the start of the line, you could do:  perl -l -0777 -ne 'for (/^function .*?^\}$/gms) {   print if /gitignore/}' ~/.bashrc   or to only look in the function body:  perl -l -0777 -ne 'for (/^function .*?^\}$/gms) {   print if /\{.*gitignore/s}' ~/.bashrc  
look in your conf file /etc/php5/fpm/pool.d/www.conf
you can't directly set values to the positional paramaters like this.  you can set them with the set command, but this will set all the values ($1, $2, ...)  e.g.  $ set -- first second third fourth fifth $ echo $1 first $ echo $2 second   now there are two cases where $2 can be the empty string; first if no value has been passed, or second if "" is passed as an actual argument and so there may still be a $3, $4 etc.  we can handle each case in a slightly complicated way:  #!/bin/bash  echo before 1=$1 2=$2 3=$3 4=$4  if [ -z "$2" ] then   first=$1   shift 2   set -- "$first" value "$@" fi  echo after 1=$1 2=$2 3=$3 4=$4   the bit inside the if test will ensure all other values are retained.  e.g.  % ./testing arg1 "" "arg 3" "and arg 4" before 1=arg1 2= 3=arg 3 4=and arg 4 after 1=arg1 2=value 3=arg 3 4=and arg 4   but you might be able to do things simpler and just use ${2:-value} which will evaluate to value if $2 is not set, so then you don't need to worry about rewriting the arguments. 
the problem is only bash has prompt_command
vgx   enter visual mode, go to end of file, delete.  alternatively, you can do:  vggx   to delete from the current position to the beginning of the file. 
this is what pipes were made for:   gzip -dc | less  
turns out that the version of dialog supplied by my package manager was out of date
the easiest way would probably be to use iotop it is like top but lists i/o operations
cd "`dirs +&lt;number&gt;`"   where &lt;number&gt; is 0 or 3 or something else.  in any case, i recommend you check out a cd wrapper such as  http://davidcorne.com/tag/cd/ , which pushes onto the dir stack in the background and allows you to do cd -- instead of dirs -v and cd -&lt;number&gt; to get you into the directory you want
i'm really not quite sure why you're getting this error
on possibility would be to create an array with those items from the glob, then you could see if the array has any elements
with your rhel tag, i guess that you are using a red hat system
after going through a list of errors, i found a solution for my problem:   the path to my second hdd is
quoting the debian administrator's handbook     ..
not a single command, but a single line (and filename is created with the correct mode and content), on shells which support process substitution:  install -m 0755 &lt;(echo "file content") filename  
if by "use as a proxy" you meant that you want to provide ipv6 connectivity to your entire network, you need two things:   enable ip(v6) forwarding configure the apropriate prefix advertisements to be sent   on linux, this would be /proc/sys/net/ipv6/conf/all/forwarding and the radvd daemon, respectively.       how to set up the dns? is there any open dns that supports ipv6? i found articles talking about setting up a private ipv6 dns
first, this isn't specific to bash
the difference between the two versions are due to different macro sets; the original man set and the newer mdoc set
xdotool exposes the pointer location (xdotool getmouselocation), and recent versions (since 2.20110530.1) indicate which window is at that location as well
this awk script should get you started:  begin { fs = "," } $1 {     if ($1 == "end_" tablename) {         exit 0;     } else if ($1 == "start_" tablename) {         in_table = 1;     } else if ($1 == tablename) {         count = split($0, columns);     }     next; }  in_table {     for (i = 2; i &lt;= nf; i++) {         values[i] = values[i] "," $i;     } }  end {     for (i = 2; i &lt;= count; i++) {         if (columns[i]) {             print columns[i] " - " substr(values[i], 2);         }     } }   call it like this:  awk -f config.awk -v tablename=interfaces_setup config.csv  
try something like:  for dir in /app/instance/*; do     ls -lcrt "$dir/logsarchive"/*/weekend.log | tail -n 1 done   the loop goes through the subdirectories of /app/instance one by one, and tail -n 1 keeps only the last line from ls, which is sorted by time
there is a helpful comparison of wireless management methods on the arch wiki.  if you are looking for a combination of automation, ie., you do not want to manually issue commands every time you connect to a network, and are looking for a lightweight solution that can be run both in x and in a tty, then wicd-curses fulfills the criteria.  it has few dependencies and is also able to manage your wired connection.  for an even simpler approach, there is also a bash wifi connector script that will provide the base functionality with no additional dependencies.1   1
assuming your script is running with a controlling terminal (so that the output has somewhere to go to be seen) you just need to add one line:  /bin/mail -s "$subject" "$email" &lt; $emailmessage cat $emailmessage  
it's looking that you need software profilers eg: for memory i use valgrind massif with linuxtools on eclipse.  if you are not restricted by system/gpl try dtrace on solaris/sunos if not try systemtap(eclipse + linuxtools) or gprof if you have source code. 
you have mucked up your quotes
if your top supports filtering, start top then type the following interactive command:  ocommand=afile   the field name, command, must be all uppercase.  from the man page:  5e
to apply your changes you need to rebuild this package
afaik, it's not possible.  you can preseed a pre-encrypted password for the root and the first user accounts
if i need to know what it is say linux/unix , 32/64 bit  uname -a    this would give me almost all information that i need,   if i further need to know what release it is say (centos 5.4, or 5.5 or 5.6) on a linux box i would further check the file /etc/issue to see its release info ( or for debian / ubuntu /etc/lsb-release )  alternative way is to use the lsb_release utility:  lsb_release -a   or do a rpm -qa | grep centos-release or redhat-release for rhel derived systems 
arch linux is a rolling release distro, once you install it you don't have to 'upgrade' the entire os
in legacy bios systems, the bios looks up the master boot record (mbr) of the disk it is set to boot
the conventional way to convert terminfo to termcap is with  infocmp -cr   the infocmp option -c tells infocmp to use termcap names, and the -r option tells it to translate terminfo capabilities to termcap format
there are plenty of alternatives such as roffit, troff, man2html
note the warning on the arch wiki microcode page:  warning: with linux 3.17-2 and linux-lts 3.14.21-2 and newer versions, intel microcode updates are not triggered automatically any more.  the intel-ucode package will only install the intel-ucode.img to /boot/ if you are running a 3.17.* kernel
to find all *beta directories that have new files in them (-mtime -1) and save those directories names in list.txt, try:  find -type f -path '*beta/*' -mtime -1 | sed 's|^\./||; s|beta/.*|beta|' | sort -u &gt;list.txt   since your goal is to create newline-separated data in the file list.txt, that must mean that you do not expect any of the directories or files to have names which themselves contain newline characters
basically, if this is an upgrade, and your old program can also rely on 0.24, i would recommend overwritting your previous library install with the new one (which is what we call "upgrading" at a higher level)
you can use yum to do the installation too.  $ yum --nogpgcheck localinstall *.rpm   yum will then make sure that the dependencies are all set before attempting to install
echo $above_string | grep -op "^([^?]*\?){2}\k[^?]*"   change 2 to the n - 1 value in order to obtain the nth string.  this assumes that you want the nth string in that line
the advantage of using the uuid is that it is independent from the actual device number the operating system gives your hard disk
you can use comma as a separator to separate two different ranges of port
a makefile recipe will stop executing if any command in it returns a failure status (unless the command is preceded by a -)
what your routine is lacking is some way to exit once the correct i is found. for that you can look at the exit code given back from curl:  for i in {2000..3000} do    curl http://admin:$i@mywebsite.com/link   if [ "$?" -eq 0 ]; then     echo found "$i"     break   fi done   the exit value of curl is 0 when everything is correct and can be checked directly after the program stops by inspecting the special variable $?. use man curl and search for exit code to see all the different things curl can tell you with its exit code. 
depends entirely on what mechanism you're using
.gtkrc is the configuration file for gtk, the gui library used by gnome applications and others
you have been hit by the confusion with tollef's parallel from moreutils
can't comment on another answer, so i'm posting here
as matters currently stand, there is no "safe" way to use linux on a ps3 you buy brand new from a retail store
one option is to use a distro with a merged /usr; then you can mount /usr ro and the rest rw, and have most of the relevant stuff ro
you have to parse it:     all shells and programs that use exec*p library calls   next is the verb:     handle searching for executables in directories named in path   the exec*p refers to a subset of the system "exec" functions, whose name ends with p, as a clue to the fact that they (as the rest of the sentence says) use the environment variable path as a list of directories to search for executable programs with a given name (a parameter of the function).  further reading:   execl, execlp, execle, execv, execvp, execvpe - execute a file  this is an example of the page that shell and environment variables might point to. how does execvp run a command?  
ctrlg this will abort the search 
i assume you want a feature that allows you to tile your windows like shiftit allows via cmd+shift+left and cmd+shift+right  as your question seems to be targeted at gnome you might want to try bluetile that seems to specifically target the gnome-desktop.  apart from that i think the new unity-desktop from canonical allows similar features via ctrl+shift+left, ctrl+shift+right and the numpad keys (in 12.04 at least you can press the windows key and see an overview over the available shortcuts).  and - even though i have never used it the grid-plugin for compiz might also fit your needs.  apart from that there are a ton of window managers that can do all the tiling for you, but they may require initial setup and be very different to use than the more common ones
assuming gnu or bsd ls:  ls -latr /foo  
i just now had to figure out an answer to this, because the last apt-get upgrade on a debian server made it impossible to boot the most recent kernel beyond a busybox, failing to mount the zfs root partition
try whereis
use /etc/profile or /etc/profile.d/ folder 
there is a configuration option services.logind.extraconfig.  open your nixos configuration file (/etc/nixos/configuration.nix)
man has an option to read a local file: -l     -l, --local-file                 activate  `local'  mode
a blocking call will return when there is data available (and wait for said data), a non-blocking call will return data if there is data to return, otherwise returns an error saying there's no data (but always returns "immediately" after being called).  whether you use one or the other depends on what you want to do — if you want to get that data and there's nothing else to do, you just call a blocking call
try ssh -f user@host '&lt;your command here&gt;'.  from the ssh man page:  -f      requests ssh to go to background just before command execution.              this is useful if ssh is going to ask for passwords or              passphrases, but the user wants it in the background.  for example, if i do ssh -f &lt;my computer&gt; 'echo "hello $(pstree -p | grep sshd | wc -l) person in ssh!", it prints hello 1 person in ssh!.  after it prints 2 the session automatically exits, but you do not have to wait for it to exit
if dirty hacks are welcomed, the following might come close:  ls -c --color -f -1 | rev | sort | rev   essentially:   rev to get the last character first then sort, which will now use the last character first then rev again to get back the original line   this, unfortunately, has single-column output
my /etc/dhcp/dhclient.conf file uses the following configuration, notice the supercede line   # configuration file for /sbin/dhclient, which is included in debian's #   dhcp3-client package. # # this is a sample configuration file for dhclient
for your sample input:  $ cat /tmp/data | 2015-08-21 - 10:15 | jones | view | main.home |  | 172.29.192.106 | | 2015-08-21 - 10:31 | wilson | view | main.home |  | 172.19.6.107 | | 2015-08-21 - 11:40 | smith | resetpasswd | wilson |  mozilla | 172.19.15.105 | | 2015-08-21 - 11:41 | james | view | main.changepassword |  | 172.19.15.102 | | 2015-08-21 - 11:41 | james | changepasswd | wilson |  | 172.19.15.102 | | 2015-08-21 - 11:41 | james | view | main.home |  | 172.19.15.102 | | 2015-08-22 - 08:31 | doe | view | main.info |  | 172.19.6.103 |   you can use awk:  $ awk '-f|' 'begin { ofs = "|" }{ if ($3 ~ "wilson") { print }  }' /tmp/data | 2015-08-21 - 10:31 | wilson | view | main.home |  | 172.19.6.107 |   instead of $3 ~ "wilson" you could also use $3 == " wilson " assuming that there will always be spaces surrounding the field.  to answer your follow-up question, you could wrap it in a bash script:  $ cat foo.sh #/bin/bash names="$(cat patlist.txt)"  for name in ${names}; do     awk -f'|' '$3 == " '"${name}"' "' /tmp/data done  $ cat patlist.txt wilson jones  $ bash foo.sh | 2015-08-21 - 10:31 | wilson | view | main.home |  | 172.19.6.107 | | 2015-08-21 - 10:15 | jones | view | main.home |  | 172.29.192.106 |  
you can convert any ansi escape sequences into conky colour commands and use execp instead of exec to then have the output parsed
from man ffmpeg:     subtitle options:      -scodec codec       force subtitle codec ('copy' to copy stream)
just put as the last line of your ~bob/.bash_profile file on foo:  cd /home/guest &gt;&amp; /dev/null   now each time you log in (whether by ssh or otherwise), the cd command will run
execute the command sudo -i vi /etc/hosts.allow, it will give you a list of services supported by tcp wrapper
   title:5: command not found: nf   this error message shows an error in a function called title, which by the name presumably sets your terminal's title to the command being run
lftp would do this with the command mirror -r -p 20 localpath - mirror syncs between locations, and -r uses the remote server as the destination , with p doing 20 parallel transfers at once
you can figure out which packages are providing all the kernels using  dpkg -s /boot/vmlinuz*   these are the packages which take up room in /boot
this should work with all the image types that imagemagick can handle without having to specify *.png, *.jpg, *.jpeg etc:  #!/bin/bash  images=$(identify -format '%f\n' * 2&gt;/dev/null)  ifs=$'\n' set -e  max_dims=$(   identify -format '%w %h\n' $images 2&gt;/dev/null |   awk '($1&gt;w){w=$1} ($2&gt;h){h=$2} end{print w"x"h}'   )  orig_dir=originals_$(date +%y-%m-%d_%t) mkdir "$orig_dir" mv -- $images "$orig_dir" cd "$orig_dir"  set +e  for image in $images; do   convert -- "$image" -gravity center -extent "$max_dims" "../$image" done   this will move the original images into a dated directory in case the results are not desirable
there are several commands that are useful to debug dns resolution, and to show the path travelled to resolve dns lookpups:   dnstracer   install it with:  apt-get install dnstracer   example of usage:  $ dnstracer www.cnn.com tracing to www.cnn.com[a] via 193.136.188.1, maximum of 3 retries 193.136.188.1 (193.136.188.1) got answer [received type is cname]   |\___ ns1.fastly.net [fastly.net] (23.235.32.32)   |\___ ns4.fastly.net [fastly.net] (104.156.84.32)   |\___ ns3.fastly.net [fastly.net] (23.235.36.32)    \___ ns2.fastly.net [fastly.net] (104.156.80.32)     name        dnstracer - trace a chain of dns servers to the source   description        dnstracer determines where a given domain name server (dns) gets its        information from, and follows the chain of dns servers back to the        servers which know the data.     debug mode of nslookup   example:  $ nslookup &gt; set debug &gt; www.cnn.com server:     193.136.188.1 address:    193.136.188.1#53  ------------     questions:     www.cnn.com, type = a, class = in     answers:     -&gt;  www.cnn.com     canonical name = turner.map.fastly.net.     ttl = 191     -&gt;  turner.map.fastly.net     internet address = 151.101.36.73     ttl = 30     authority records:     -&gt;  fastly.net     nameserver = ns2.fastly.net.     ttl = 13130     -&gt;  fastly.net     nameserver = ns3.fastly.net.     ttl = 13130     -&gt;  fastly.net     nameserver = ns4.fastly.net.     ttl = 13130     -&gt;  fastly.net     nameserver = ns1.fastly.net.     ttl = 13130     additional records:     -&gt;  ns1.fastly.net     internet address = 23.235.32.32     ttl = 13130     -&gt;  ns2.fastly.net     internet address = 104.156.80.32     ttl = 13130     -&gt;  ns3.fastly.net     internet address = 23.235.36.32     ttl = 13130     -&gt;  ns4.fastly.net     internet address = 104.156.84.32     ttl = 13130 ------------ non-authoritative answer: www.cnn.com canonical name = turner.map.fastly.net. name:   turner.map.fastly.net address: 151.101.36.73    dig - trace    example:  $ dig +trace +recurse +all www.cnn.com
i'm sorry to tell but seems like it, you need an x86_64 kernel on the host in order to run a 64bit guest.  looking at kvm faq, we could read:     can kvm run a 32-bit guest on a 64-bit host? what about pae?      kvm supports 32-bit guests on 64-bit hosts, and any combination of   pae and non-pae guests and hosts
   what it means, i don't know really   $_ means the last argument to the previous command.  example:  echo "foo" "bar" foo bar echo $_ bar   read more here. 
just because you ran  vi demo.c   does not mean a file demo.c was created
the best would be to upgrade to another lts version of ubuntu (8.04 to 10.04 is a supported upgrade path; from there you can go to 12.04)
taken straight from hpux documentation for nslookup     ls [option] domain list the information available for domain [...]
you're not going to save much time using one over the other, but if efficiency is what you care about, use http
you want to make runlevel 3 your default runlevel
the last ubuntu version having readahead-fedora was 15.04, according to ubuntu.packages.  ubuntu 15.10 came up with systemd which changed the boot process so readahead-fedora is no longer applicable. 
iptables is working on ip and tcp level, so it doesn't actually know dns
you can use any function key that screen recognizes as the escape character
simply pressing "a" in ncmpcpp will bring up a screen where you can select a playlist to add the currently playing (or selected) item to. 
a shell assignment is a single word, with no space after the equal sign
first of all, for i in file should probably be for i in $file; the dollar sign is needed when retrieving a variable's value.  i would alter your script in the following ways:  echo "what file names are you searching for?" read files filepath=/test/dir1  for f in $files do     echo "$f"     find "$filepath"/"$f" done   i removed the assignment to $file from $filenames, and assumed you meant for the user to enter several whitespace-separated file names.  then i passed find a single path, constructed by separating the directory name and the file name with a single slash
you can use kpartx for this
enable  universe repository in software and updates and then run the below commands,  sudo apt-get update sudo apt-get build-dep python-matplotlib  
this will highly depend on what is happening on the system besides your elisp program running, because the bash program (and all required libs) may or may not be cached at that moment in time
you probably want to discard any stderr output as well
i think what you want is:  find /home/milenko/serradomel/mt10 -type d -exec cp -v n1.sh {} \;   i added the "-v" so you can see the file being copied. 
zip -ff runs a specific block of dedicated code, which doesn't handle other options such as -x
you created a link to /opt/firefox (is this really the firefox binary, can you start ff when calling /opt/firefox?) in the directory that was your current working directory when you issued the command, likely your home directory
in a shared web-hosting environment, there are a couple issues that you need to address right off the bat.  regarding directory permissions and only being able to access your files: what you want to do is set home directory permissions such that the "others" group has no permission whatsoever
you can assign straight into fields in awk with $n, for n the field number: $9 = "yes" will add a new field at the end with the value "yes":  awk -f, -v ofs=, '{ if ($5 &gt; 5) { $9 = "yes" } else {$9 = "no"} };1' data   when we assign into $9 we create the ninth field, which is one beyond the end for this data
a snapshot, in this sense, is the state of the source code at a point in time
for a gnu tar:  --sort=order  specify the directory sorting order when reading directories.  order may be one of the following:  `none'       no directory sorting is performed
there is a theoretical limit of sorts: eventually the latency (which has a minimum value due to the fact that each hop must add an overhead of a few cpu instructions) will become so high that it will be larger than tcp timeouts
you can use an array to fetch the results in and use the number of array elements to display the n ips found in dns line
have the at-script call itself once it's done.  # cat t.txt true cat t.txt | at 9am mon # bash t.txt warning: commands will be executed using /bin/sh job 680 at mon sep  8 09:00:00 2014 #   just replace true with your actual script. 
simply:  sed -e '1h;g;s/\n/ /' &lt;file  
on a gnu system:  find / -type d -print0 | shuf -zn5 | xargs -r0n1 cp foo   (now copying the file to things like /sys or /proc would not make sense or even be possible, you may want to add -xdev to only select directories on the file system mounted at /).  you could make it compatible with both freebsd and gnu with:  find / -type d -print0 | sort -zr | tr '\0\n' '\n\0' | head -n5 |   tr '\0\n' '\n\0' | xargs -r0n1 cp foo  
you have have the timezone set incorrect
you can add some shell scripting to /etc/bashrc or /etc/bash.bashrc maybe bepending on your linux distribution
as romeo pointed out, you're using double quotes around your command
the solution turned out to be simpler than it appeared
it's all there
as comments have already stated, you're probably better off with xdg-open (no alias needed), but to answer the question: you can use xdg-mime to query and set default applications
i'd use zsh where the line editor has many more capabilities and is a lot more customizable:  #! /bin/zsh - insert-and-accept() {   zle self-insert   # rbuffer= # to discard everything on the right   zle accept-line } zle -n insert-and-accept bindkey ";" insert-and-accept bindkey "^m" self-insert vared -p "&gt;&lt;&gt; " -c srccommand   with bash-4.3 or above, you can do something similar with a hack like:  # bind ; to ^z^c (^z, ^c otherwide bypass the key binding when entered # on the keyboard)
you can use this to delete all symbolic links:  find -type l -delete   with modern find versions.  on older find versions it may have to be:  find -type l -exec rm {} \; # or find -type l -exec unlink {} \;   to limit to a certain link target, assuming none of the paths contain any newline character:   find -type l | while ifs= read -r lnkname; do if [ "$(readlink '$lnkname')" == "/your/exact/path" ]; then rm -- "$lnkname"; fi; done   or nicely formatted   find -type l |  while ifs= read -r lnkname;  do    if [ "$(readlink '$lnkname')" = "/your/exact/path" ];    then      rm -- "$lnkname"    fi  done   the if could of course also include a more complex condition such as matching a pattern with grep.    tailored to your case:  find -type l | while ifs= read -r lnk; do if (readlink "$lnk" | grep -q '^/usr/local/texlive/'); then rm "$lnk"; fi; done   or nicely formatted:  find -type l | while ifs= read -r lnk do   if readlink "$lnk" | grep -q '^/usr/local/texlive/'   then     rm "$lnk"   fi done  
this is a choice
to create a bootable usb, you can follow the steps below:    step 1  go to the website of the os you wish to install, and find an iso image to download
i think the best way is as is shown in red hat documentation. this is your second method
putting this in my .tmux.conf file was the trick:  set -g history-limit 20000  
i found the answer myself
i made a small change to the test framework, and the problem went away.  specifically, rather than calling kpartx -u /dev/vda after i repartition the device, i call kpartx -d followed by kpartx -a
quite generally speaking, all operations happen in ram first - file systems are cached
first, you need to make sure there is at least 1mb or so of free space at the end of the existing disk
well, the exact sequence may vary, as there might be a shell alias or function that first gets expanded/interpreted before the actual program gets executed, and then differences for a qualified filename (/usr/libexec/foo) versus something that will be looked for through all the directories of the path environment variable (just foo)
the line %_denyhosts    all=(all) all means that users in the _denyhosts group are allowed to run any command as any user
there is no way to retroactively capture the error output, because at the time the command returns with a non-zero exit status, the output already has been done
have a look into this plugin, it's likely what you want:  ansiesc.vim : ansi escape sequences concealed, but highlighted as specified 
this sounds like the modeline feature (see the on-line help)
your program should at least exit(3) exit_success (i.e
a recent version of ss should also display udp listeners in that way
run blkid to find out the uuid of the relevant partition, then edit /etc/fstab accordingly:  uuid=..
   for example, i have a vagrant box on my mac (linux guest on mac host)   it would be interesting to know which distribution this is..
what you are asking dose not make sense
i don't think you can do this - not reliably, and not the way you ask
probably not.  that site looks like a koji build server, and poking around in here for example does not show any of the metadata directories created by createrepo or such necessary for yum to act on
during a boot sysctl settings are initially set to default values hardcoded into the kernel
with bash you can make file globbing drop __pycache__, by setting:  $ export globignore=__pycache__   now if you issue:  $ ls __* ls: cannot access __*: no such file or directory   also with bash you can use the fignore environment variable to skip file suffixes
you don't want them owned by www-data
a.) working but not recommended solution  i managed to install the drivers manually following this guide:   http://www.if-not-true-then-false.com/2015/fedora-nvidia-guide/comment-page-11/   the problem with this approach, that (according to some forums and my experience) the nvidia driver overrides some other libs as well, and a dnf update can override those libs, which will result a very unstable system
you should not use df because it shows the size as reported by the filesystem (in this case, ext4).  use the dumpe2fs -h /dev/mapper/existingext4 command to find out the real size of the partition
that's hard, because as far as rpm is concerned there isn't much difference between packages which anaconda installed as part of the install and those you have installed since
you need to create aliases of your network interface.   by creating temporary aliases using ip address add command
the answer that suggested system_profiler | grep 'system version' is what i have tried to use in the past, but it has 2 problems.   it is slow since it generates a full system_profiler dump of the machine, gathering all hardware and software inventory information. the output of system_profiler has changed over time
you can use a client that supports the fxp protocol, as described in one of the answers from this webmaster.stackexchange.com q&amp;a: how can i transfer files from one server to another server using ftp  the following is from the smartftp knowledge base:  excerpt     what is fxp?      fxp stands for file exchange protocol
the logic is right - but you've made a couple of errors:  awk -vofs=, -f, '{       for(i = 1; i &lt;=nf; i++ ){           $i -= 1;       }       print;    }' file.txt    getline (as you've used it) reads the next line into $0 - it doesn't make sense here. you need to tell awk to split (fs or using -f) on a comma, by default it will split on whitespace $0 is the whole line so you want to start your loop at i = 1 if you want to print commas on the output you need to set ofs=, (output field separator).   alternatively you can use perl:  perl -ple 's{(\d+)}{$1 - 1}eg;' file.txt  
with dnf (or any other repository-based package installation tool), you can only install packages which are published in your repositories; dnf install squid-3.1.23 instructs dnf to install version 3.1.23 of the squid package, which isn't available in the fedora 22 repositories
try:  eval "`date +'@ s = (86400 - %s) - 60 * (%m + 60 * %h)'`"; echo $s   however note that in timezones that have winter and summer time, it won't give  the right result if called on the day of the switch from/to summer time, before the switch (which generally happen very early in the morning).  beware that in csh, arithmetic operators are right-associative with */ having precedence over +-, as in  @ s = 1 - 2 + 3 - 4   is  @ s = 1 - (2 + (3 - 4))   and not:  @ s = (((1 - 2) + 3) - 4)   as in other languages
taking advantage of gnu mv's -t option to specify the target directory, instead of relying on the last argument:  find 
i just wrote this in c:  #include &lt;stdio.h&gt; #include &lt;curses.h&gt; #include &lt;time.h&gt; //time(0) #include &lt;sys/time.h&gt;                // gettimeofday() #include &lt;stdlib.h&gt;  void waitfor (unsigned int secs) {     //credit: http://stackoverflow.com/a/3930477/1074998     unsigned int rettime = time(0) + secs;   // get finishing time.     while (time(0) &lt; rettime);               // loop until it arrives. }  int main(void) {      struct timeval t0, t1, t2, t3;     double elapsedtime;      clock_t elapsed_t = 0;     int c = 0x35;      initscr();     cbreak();     noecho();     keypad(stdscr, true);      halfdelay(5); //increae the number if not working //adjust below `if (elapsedtime &lt;= 0.n)` if this changed     printf("\nstart again\n");      elapsed_t = 0;     gettimeofday(&amp;t0, null);      float diff;      int first = 1;     int atleast_one = 0;        while( getch() == c) { //while repeating same char, else(ffff ffff in my system) break              int atleast_one = 1;              if (first == 1) {                 gettimeofday(&amp;t1, null);                 first = 0;             }              //printf("debug 1 %x!\n", c);             gettimeofday(&amp;t2, null);             elapsedtime = (t2.tv_sec - t1.tv_sec) + ((t2.tv_usec - t1.tv_usec)/1000000.0);               if (elapsedtime &gt; 1) { //hit max time                  printf("hit max, quit now
this is probably caused by some peculiarity of your bios
@eyoung100's comments helped me find the solution on my own
not sure if this will help because i did not see any selinux errors.  but i'm posting what worked for me and the problems i encountered in the hope it helps.  after installing fedora 17 i upgrade to the latest release but did not reboot
/etc/environment is a configuration file for pam_env, not a file read by a shell
i'm not sure about the first question but here there is a localized package called manpages-zh
in case of fuse and zfs, performance is awful, and that's understandable
if it is in your path, then you can run either type git or which git
testlogin isn't a command here, but an argument to echo
the one without the version number is just a placeholder package that has a dependency on the currently supported version.  from http://packages.debian.org/squeeze/all/postgresql/filelist, the file list is just:  /usr/share/doc/postgresql/readme /usr/share/doc/postgresql/changelog.debian.gz /usr/share/doc/postgresql/copyright   from: http://packages.debian.org/stable/database/postgresql     this package always depends on the currently supported postgresql database server version.   in other words, if you want the latest supported version, you just install "postgresql", and it will pull in the actual package for the currently supported version of the server. 
if you're using it as a storage device i would configure it now, turn it on, and share your drive via nfs/samba, etc, then never touch it again.  effecively, you're turning your laptop into a nas
you can specifiy multiple directories in grep:  grep -r "string" app/assets/javascripts spec/javascripts   alternatively - sometimes more useful is list files to grep by find, and then grep them, for example  find app/assets/javascripts spec/javascripts -type f -print0 |   xargs -0 grep "string"   or   find app/assets/javascripts spec/javascripts -type f -exec grep -h "string" {} +  
you really are not going to be able to do this with a simplistic sed script
something like this should do what you want:  #! /bin/sh for f in ./file*; do     sort -u "$f" done | \     sort | \     uniq -c | \     sort -rn | \     head -40   the point of the for is to make sure each line is counted only once per file
port 5901, generally by convention port 5900 + xdisplaynumber, is the tcp port on which the vnc service listens
use the -q option to tell sftp to be quiet, thereby suppressing most of the output you don't care about:  echo "ls *.txt" | sftp -q user@host.example.com:/path   you will still see the lines for the interactive prompt to which you are echoing, e
web browsers are notorious memory pigs and leakers of memory, especially if the pages they're viewing have any javascript
i'd offer perl's quotemeta function
give the installation via terminal a try:   open terminal run the command: sudo apt-get install chromium-browser   alternatively you can add the chromium repository via commandline to your sources like this and install it from there:   open terminal sudo add-apt-repository ppa:chromium-daily/stable sudo apt-get update sudo apt-get install chromium-browser  
any decent editor is able to highlight diffs conveniently
using parameter expansion:  line="/usr/share/man/man5/xpak.5.bz2"  # printf "%s\n" "${line##*/}"                                       # xpak.5.bz2 file="${line##*/}" printf "%s\n" "${file%.*}" xpak.5   in zsh, you can do nested parameter expansions:  printf "%s\n" "${${line##*/}%.*}" xpak.5  
try sudo umount -v /run/media/harry/2030-0761
you are not giving grep any files to search
reading through the 'at' source code it is a fairly trivial patch to alter the mail header that the at command creates to include a content-type field.  the complete answer may be to add an environment variable e.g
"they" can correlate the ssh session with both your real ip and the traffic coming out of the ssh server
   are there any historical reasons for there being two commands instead   of one?   there was just history manner
obiously using unix tools is the easiest way to do it
the target "-j mark --set-mark 2" will set the mark 2 on  the packet, whatever the previous value was. if you want to avoid your mark to be erased, you can simply end the packet path in the chain with -j accept
!! is listed in the bash manual under the heading "event designators":     an event designator is a reference to a command line  entry  in  the    history list
you mistaken options -i and -i of openssh.  from man ssh:     -i pkcs11 - specify the pkcs#11 shared library ssh should use to communicate with a pkcs#11 token providing the user's private rsa key.      -i identity_file - selects a file from which the identity (private key) for public key authentication is read.   after -i ssh expects shared library and tries to load your id_rsa as shared library, so it expects elf header.  in this case you can omit -i because ~/.ssh/id_rsa is default file
kubuntu makes many modifications to various applications (e.g., firefox, openoffice), so it is unlikely that there is an easy way to recreate the kubuntu look on archlinux.  that being said, i moved from kubuntu to archlinux and i now prefer the vanilla applications (e.g., openoffice looks much better).  one thing that helped a lot in synchronizing the look of gtk applications with kde was to install qtcurve, a theme that works for both qt (kde) and gtk (gnome) apps.  pacman -s qtcurve-gtk2 qtcurve-kde4 gtk-chtheme gtk-chtheme # change the theme for qtcurve  
1
as it is clear that there is no "vanilla" i3 way to do this, i have created a small preprocessor called i3bang that allows me to achieve this.  simply   download and set up i3bang. wrap all of your keybindings in default mode like so:  !@&lt;+default_keybindings bindsym ... &gt;  now include a reference to that section at the end of the mode you would like to keep default keybindings in:  mode "skype" {         bindsym $mod+!!1..9,0 exec xdotool mousemove 90 !&lt;70+40*!!&lt;0..9&gt;&gt;; \                               exec xdotool click 1         ...         !@default_keybindings }   since i3 (somewhat unintuitively) uses the first occurrence of a binding to a certain key if there are multiple bindings that use the same key, putting the reference to default_keybindings last means that any conflicting keybindings in your new mode will override the default.   full disclosure: in case it isn't clear enough already, this is my own tool. 
use ps option -o to select fields you want to display to show process pid, start time and command name, optionally selecting the processes you're interested in right away (-c), sort on start time, kill all but the last one.  since ps is notoriously known to be a command line options hell, you'll have to check the man page for your implementation
it looks like your hadoop_home variable has been defined to a value that ends with a carriage return, i.e.,     / o p t / h a d o o p - 2 . 6 . 1 carriage return   so when you do  echo $hadoop_home/bin   you're getting the output     / o p t / h a d o o p - 2 . 6 . 1 carriage return   / b i n   only all on one line, so the /bin overwrites the /opt on the screen and it looks like    /bin/hadoop-2.6.1   you can check this by doing  a=/opt/hadoop-2.6.1 echo $a | od -cb echo $hadoop_home | od -cb   try to find where hadoop_home is being defined.  it may be one of your "." files; e.g., .profile, .bashrc, or .bash_profile in your home directory, or a similarly named file in /etc.  if you use vi, it should show a ^m at the end of the string; that represents carriage return.  delete the ^m. 
actually i was able to recover all my data which includes quite a few gibabytes...  what i did:   booted the system with the usb installation disk in 'live mode'  installed the program testdisk through it i was able to view and copy all the data i wanted to an external disk  
in general you can just ignore fragmentation altogether
solution for gnome 2 (debian 6):  i tried one more thing..
as far as i can read, latest version is 1.4.21 from nov 22nd 2014
yes to both
you could use gnuplot for this:   primes 1 100 |gnuplot -p -e 'plot "/dev/stdin"'   produces something like    you can configure the appearance of the graph to your heart's delight, output in various image formats, etc. 
both ssds are already fully committed to your three raid-1 partitions
you have to indicate what to kill:  kill -9 $(ps | grep "server1" | grep -v grep | awk '{ print $1 }')   you can also use the trick:  kill -9 $(ps | grep "server[1]" | awk '{ print $1 }')  
there's an undocumented --verifydb flag that's been around since at least rpm-4.1.  see rpm/rpmdb.c:  { "verifydb", '\0', (popt_arg_val|popt_argflag_or|popt_argflag_doc_hidden),     &amp;mode, mode_verifydb, n_("verify database files"), null},   so rpm --verifydb should do exactly what you're looking for. 
why don't you install the same centos 6.5 where you can download updates via yum, and go this way:  http://www.cyberciti.biz/faq/yum-downloadonly-plugin/  you can download all rpm's you need and then install them on your server. 
the problem is that top by defaults includes ansi/vt100 escape codes
you can use the expression register, "=, with p (or p) in normal mode or &lt;c-r&gt; in insert mode:  in normal mode: (&lt;c-m&gt; here means control+m, or just press enter/return)  "=strftime('%c')&lt;c-m&gt;p   in insert mode: (&lt;c-m&gt; has the same meaning as above, &lt;c-r&gt; means control+r)  &lt;c-r&gt;=strftime('%c')&lt;c-m&gt;   if you want to insert the result of the same expression many times, then you might want to map them onto keys in your .vimrc: (here the &lt;c-m&gt; and &lt;c-r&gt; should be typed literally (a sequence of five printable characters—vim will translate them internally))  :nmap &lt;f2&gt; "=strftime('%c')&lt;c-m&gt;p :imap &lt;f2&gt; &lt;c-r&gt;=strftime('%c')&lt;c-m&gt;  
a shell alias behaves pretty similarly to a #define, i.e
awk can do that all alone:  df -b kb | awk 'nr!=1&amp;&amp;$1!~/tmpfs|cdrom/{printf "'$(date "+%y-%m-%d-%h:%m:%s")','$(hostname)',%s,%s,%s,%s\n", $2, $3, $4, $1}'   explanation:   df -b kb: prints the values in kb awk   nr!=1: avoid the first line $1!~/tmpfs|cdrom/: if the first field contains not the excluded filsystems printf: print formatted $(date +%y-%m-%d): the date in the desired format $(hostname): the hostname %s,%s,%s,%s\n: and the rest   
i found the "colored lettering" animation (in entrance -> moderate), which at least does one letter at a time, slightly better than a horizontal wipe.  as @grochmal says, svg animation would be the only way to get "brushstrokes", but this is a decent half-way point for now.  bonus points for anyone that can figure out how to get something that looks vaguely like a "blackboard erase" effect for making the text disappear! 
this really depends on who you are trying to prevent from reading the script and what resources you are expecting the system to have.  one option is to simply use many different programs to do different parts of your script: shell, awk, sed, perl, etc
use the -pixmap option to set the background image for rxvt
first, gnupod does not work directly with the ipod database, you need to convert from and to the gnupod database, so you want to run tunes2pod.pl first
the scaling mode property is not yet implemented in the intel driver (see here)
i managed to test this and figured it out.  here is the proper way to structure the data contained in the variable you will send to bsqldb:  myvariable="select @@servername"$'\n'"select @@language"$'\n'"select @@version"   as you see each sql commands sent to bsqldb must be on a separate line
i think it is pretty obvious -- convert your data to the format accepted by the program you would like to use (idea the program should somehow read your custom format is, ekhem, naive?). 
i wonder if i should delete this question
use:  curl http://mysite.com/myfile.jpg &gt; myfile.jpg  
those firewall rules ordinarily suggest that traffic is otherwise blocked, and they only serve to allow traffic to and from the given port
from the pacman rosetta, since you're looking for the equivalent to apt-file:  pkgfile filename   pkgfile used to be in the pkgtools package
to scalably blank all fields from the nth to the mth in an awk command, you shouldn't hardcode the values; you should use a "for" loop:  awk 'begin { fs = ","; ofs = ","} {for (i = 3; i &lt;= 4; i++) { $i = "" }; print}' inputfile   if you want to blank out a different range, adjust the values "3" and "4" in the above code.    explanation:  the begin { ..
cp ../ryu/spyware ../ryu/spyware.exe 
both symbols before the # represent the current directory you're in
according to the vim wiki you should be able to do it with ctrl+^ however it doesn't work on my system, it will only alternate between files
in bash, just use something like alertcommand | grep $(date +"%m/%d")  $() executes a command in a subshell and returns the output of the command as string
to give you the formula which involves the wc-based check:  (($(wc -l&lt;input_file)&lt;=$(tput lines))) &amp;&amp; echo 'will fit' || echo 'not enough'   there is a $lines shell variable which can also be used:  (($(wc -l&lt;input_file)&lt;=lines)) &amp;&amp; echo 'will fit' || echo 'not enough'   but $lines is updated only when at the command prompt
no
the entry for rhel4 on the table on wikipedia indicates "28 february 2015" as the end of "extended life phase", the end of "production 3 phase" was 29 february 2012
the answer turned out to be really simple
mkdir /mymount with root user before mount --bind /home/myfolder/ /mymount/ 
the pcregrep utility supports matching for multi-line patterns, so this is easy.  first, you need a list of files to search within; in a git repository, my own git find utility can be useful for this, but regular find(1) and other tools will also do.  pass the list of files to pcregrep, dump its output into a temporary file, then hand-review the file list (e.g
i haven't used xdm in a long while but as far as i know autologin is not supported by xdm (and, as per one of the devs, not needed). 
try ctrl alt backspace - this is the standard combination to kill x server
according to the documentation for dnf clean:     performs cleanup of temporary files kept for repositories
the trash folder is located at $home/.local/share/trash
in addition to tony´s answer, of querying opendns, which i use in my scripts upon logging on to my servers to display both the local machine and remote public ip address:  echo `hostname` `hostname -i` `dig +short +time=1 myip.opendns.com @resolver1.opendns.com`   google also offers a similar service.  dig txt +short o-o.myaddr.l.google.com @ns1.google.com | awk -f'"' '{ print $2}'   if you have a private ip address, behind a home or corporate router/infra-structure, or even if you are your own router, these services in the internet will reveal the public ip address you are using to reach them, as it is what arrives to them doing the request
which files were installed by package? dpkg -l package. which files will package install? apt-file list -f package.  also the other direction is possible:  which package installed this file? dpkg -s file which package do i need to install for file? apt-file search file. 
it appears that disk 1 is dynamic which is proprietary to microsoft
there isn't an equivalent for mount, and there is no default or standard way to do what you want
i tried your line, i get the following in /var/log/secure (fedora19):  getty[12336]: bad speed: 34800   try this:  agetty -s 38400 -t 600 tty8 linux  
you have the client (and, i believe, also the server) installed
using sed -  echo "abcd 1234 -type 53 efgh 5678" |sed -r 's/^.*-type\s+([0-9]+).*$/\1/' 53   replace the line used here with $line and assign to a variable 
use gparted, it's easy to use! you just need to find your swap partition (/dev/sda4 on my system as you can see in the screenshot below) and then resize it
what's the value of the listen directive in the config file in /etc/apache2/ports.conf?  
everything looks as expected
fortunately rpm does offer this itself:  rpm -qa --last   or if you can limit the packages by name  rpm -qa --last 'lib*' 'morelibs*'  
from http://stackoverflow.com/questions/10832350/howto-find-the-file-for-a-loopmounted-device:    from losetup(8) man page     if only the loopdev argument is given, the status of the corresponding   loop device is shown.   so you only need to use  $ losetup /dev/loop1 /dev/loop1: [0802]:4751362 (/volumes/jfs.dsk)   if you have a recent kernel (2.6.37 or above), you can also get the target file in /sys/block/loopx/loop/backing_file.  $ cat /sys/block/loop1/loop/backing_file /volumes/jfs.dsk   ...    substitite busybox losetup for losetup above. 
nproc gives the number of cpu cores/threads available, e.g. 8 on a quad-core cpu supporting two-way smt.  the number of jobs you can run in parallel with make using the -j option depends on a number of factors:   the amount of available memory the amount of memory used by each make job the extent to which make jobs are i/o- or cpu-bound   make -j$(nproc) is a decent place to start, but you can usually use higher values, as long as you don't exhaust your available memory and start thrashing.  for really fast builds, if you have enough memory, i recommend using a tmpfs, that way most jobs will be cpu-bound and make -j$(nproc) will work as fast as possible. 
you should prefer to put your application folders to /opt which is exactly what you are asking for.  the /usr is the folder in which the files and folders are maintained by package managers like apt-get for debian or yum for centos.  also, you may want to check filesystem hierarchy standard for linux. 
edit: answer completely rewritten according to comments  the issue could be related to selinux
$ ps aux | tee &gt;(head -n1) | grep syslog user       pid %cpu %mem    vsz   rss tty      stat start   time command  syslog     806  0.0  0.0  34600   824 ?        sl   sep07   0:00 rsyslogd -c4   the grep and head commands start at about the same time, and both receive the same input data at their own leisure, but generally, as data becomes available
i chose to reset firefox as detailed in their tutorial  however, it did not fix the problem immediately
writing date as an argument to another command will not get you the output of that command, just the string you typed.  in bash you can insert the result from a command by including it in $(  )
you can install alacarte to you edit menu entries
try at your own risk:  tail -n 0 -f /tmp/bar | { grep -q -m1 zoo &amp;&amp; echo found ; pkill -p $$ '^tail$' ; }   the pkill command is necesary if the match is in the last line
how about:  grep --color=auto -r -n sometext *   example output:  filename:10:    foo sometext bar   the first field is the filename, second field is the line number and sometext is colored. 
why do not modify your work a little bit:  echo -e 'asdfze3033141xycf\nasdfinsfrhxycf' | sed -e 's/^\(asdfze[0-9]\{7\}\)xycf$/\1\n/'  
you can use any of the following to run commands when $1 is empty:  [[ ! $1 ]] &amp;&amp; { commands; } [[ $1 ]] || { commands; } [[ -z $1 ]] &amp;&amp; { commands; } [[ -n $1 ]] || { commands; }   also, you don't need to quote the expansion in this particular example, as no word splitting is performed.  if you're wanting to check if there are arguments, though, you'd be better to use (( $# )).  if i've understood your intentions, here is how your code could be written with getopts:  #!/bin/bash  (( $# )) || printf '%s\n' 'no arguments'  while getopts ':n:h' opt; do     case "$opt" in         n)             [[ $optarg ]] &amp;&amp; printf '%s\n' "commands were run, option $optarg, so let's do what that says."             [[ ! $optarg ]] &amp;&amp; printf '%s\n' "commands were run, there was no option, so let's run some stuff."             ;;         h) printf '%s\n' 'help printed' ;;         *) printf '%s\n' "i don't know what that argument is!" ;;     esac done  
after finding sshd process inoperative, i noticed that something similar is happening, but instead of a missing module, it was something with sshd_config.  check status of the daemon:  user1@&lt;host&gt;:/usr/sbin &gt; lssrc -s sshd subsystem         group            pid          status  sshd             ssh                           inoperative   attempt to manually start (using absolute path) :  user1@&lt;host&gt;:/usr/sbin &gt; /usr/sbin/sshd /etc/ssh/sshd_config: line 1: bad configuration option: penbsd: /etc/ssh/sshd_config: terminating, 1 bad configuration options   turns out this file was incorrectly removed earlier (prior to sshd restart attempt), but new file was created to be an exact copy of another machine (or so we thought, it was actually a bad copy/paste job)
if the filesystem is ext2, ext3 or ext4, then you can use the command tune2fs to find out particulars about a given filesystem on a device.  $ sudo tune2fs -l &lt;dev&gt;   example  $ sudo tune2fs -l /dev/sda2 tune2fs 1.42.8 (20-jun-2013) filesystem volume name:   &lt;none&gt; last mounted on:          /boot filesystem uuid:          xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx filesystem magic number:  0xef53 filesystem revision #:    1 (dynamic) filesystem features:      has_journal ext_attr resize_inode dir_index filetype needs_recovery extent flex_bg sparse_super huge_file uninit_bg dir_nlink extra_isize filesystem flags:         signed_directory_hash  default mount options:    user_xattr acl filesystem state:         clean errors behavior:          continue filesystem os type:       linux inode count:              128016 block count:              512000 reserved block count:     25600 free blocks:              355130 free inodes:              127934 first block:              1 block size:               1024 fragment size:            1024 reserved gdt blocks:      256 blocks per group:         8192 fragments per group:      8192 inodes per group:         2032 inode blocks per group:   254 flex block group size:    16 filesystem created:       tue jul 15 21:26:21 2014 last mount time:          fri sep  5 08:17:04 2014 last write time:          fri sep  5 08:17:04 2014 mount count:              38 maximum mount count:      -1 last checked:             tue jul 15 21:26:21 2014 check interval:           0 (&lt;none&gt;) lifetime writes:          172 mb reserved blocks uid:      0 (user root) reserved blocks gid:      0 (group root) first inode:              11 inode size:           128 journal inode:            8 default directory hash:   half_md4 directory hash seed:      xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx journal backup:           inode blocks   the parameter "filesystem features" lists what you're asking for.  what devices do i have?  you can use the command lsblk to list these out.  85.9g  0   lvm  $ lsblk | head -8 | column -t name           maj:min  rm  size    ro  type  mountpoint sda            8:0      0   238.5g  0   disk ├─sda1         8:1      0   200m    0   part  /boot/efi ├─sda2         8:2      0   500m    0   part  /boot └─sda3         8:3      0   237.8g  0   part ├─fedora-root  253:0    0   50g     0   lvm   / ├─fedora-swap  253:1    0   2g      0   lvm   [swap] └─fedora-home  253:2    0   185.9g  0   lvm  
if you are configuring a mail server, it should be able to send mail just about anywhere on its own
to get the octal permission notation.  stat -c "%a" file 644   see the manpage of stat, -c specifies the format and %a prints the permissions in octal.  or for multiple files and folders:  stat -c "%a %n" * 755 dir 644 file1 600 file2  
grep -o 'f.*'   or (we need more than 30 chars)  perl -pe 's!.*?f!f!'  
this red hat issue held the key* to my issue:     i had the same issue - seems to have something to do with a user ssh config - i renamed mine, re-did it, and it worked   oh ho, thought i - i do have an ssh config, and this isn't the first key i've copied, and i'm specifying example in the file instead of having to type subdomain.example.com.  so i tried specifying the full domain:  ssh-copy-id -i /users/wwerner/.ssh/my_other_key me@subdomain.example.com                                                                                                                                                                                        $? 1  12:34:54 /usr/local/bin/ssh-copy-id: info: attempting to log in with the new key(s), to filter out any that are already installed /usr/local/bin/ssh-copy-id: info: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys  number of key(s) added:        1  now try logging into the machine, with:   "ssh 'me@subdomain.example.com'" and check to make sure that only the key(s) you wanted were added.   and boom, it worked
   how do you delete ssh if you suspect ra root administrating your macbook.
here's one way of doing it in awk:  $ printf "%s\n" "$data" |      awk -f'\n' -v rs='(^|\n)#\n' '/./ {print $1}'  first record, first field second record, first field#   the trick is to set the record separator to either the beginning of the file (^), or a newline, followed by a # and another newline \n.   
in a nutshell and assuming sufficient disk quota, none.  most (note the qualifier) software nowadays uses the automake tools to help set themselves up at compile time; if whatever software you're trying to install does this, you can just tell it configure --prefix=~ and it will install all its software, configuration files and libraries under your home directory where you have write access.  note that this will rapidly create a thorough mess and it's generally recommended you ask the actual sysadmin to install the software you need after you explain to them why you need it -- matplotlib certainly sounds like something astrophysics students could use. 
according to setpriority(2), the allowed range of priorities on linux is -20 to 19 since kernel 1.3.43
without any deeper knowledge, i would suggest looking at the linux usb project, section usb host-to-host cables, and possibly easy transfer cable (although that seems to be mainly a windows thingy)
your system is swapping heavily (17g swap used) which will make any i/o from regular processes to the respective drive extremely slow - which translates into high %wa
xargs is the unix utility i was looking for
you need to modify one of the theme config files in config-directory/themes/ (presumably ~/.config/powerline/themes/ on your system)  one way to do it is to put something like this in config-directory/themes/shell/__main__.json  {     "segment_data": {         "cwd": {             "args": {                 "dir_shorten_len": 4,                 "dir_limit_depth": 3             }         }     } }   that sets the default arguments for the cwd function when called from the shell extension, but you can still override with a different argument in the theme config file.  e.g., config-directory/themes/shell/default.json:  {     "segments": {         "left": [             ...other-segments...             {                 "function": "powerline.segments.shell.cwd",                 "priority": 10,                 "args": {                     "dir_shorten_len": 1,                     "dir_limit_depth": 5                 }             }         ],         "right": [             ...right-segments...         ]     } }   also, in addition to powerline.segments.shell.cwd, there is also the more general powerline.segments.common.env.cwd
pacman-color only colours the output for pacman commands.  to colourize a wide range of terminal output for a variety of programmes, you can use a tool like cope.  both packages are in the aur
find ..
the short answer to your question is that  *(pattern-list) will match zero or more occurrences of the given patterns
it is called brace expansion and is present also in zsh.  one important difference between bash and zsh is that in zsh parameter expansion is performed inside braces, but in bash this is not the case. 
you may want to check easy2boot
indeed, try sudo ifconfig wlan0 up
i figure since this question hasn't had any activity for over a year (as of march 2014), no-one has an answer so i'll write how i have sort-of solved the problem.  for packages whose source install method respects virtualenvs (numpy/scipy, pyside), use wheels to avoid having to rebuild in every venv.  for packages that don't (gtk), it depends on how they hook into python. 
if your perl script produces no other output than the value of $circle, you can use command substitution to store that output in a variable
that eol setting is not for the key that would take you to the end of some line-editing buffer, that's a setting of the tty line discipline.  it is for its very basic line editor, the one used when entering input for applications (like cat, sed) that don't have their own line editor
toor was a valid password for root, so i was able to shutdown
the curses program tabs will allow you to change what the terminal believes to be the width of a ^i
a closed source driver distributed by another channel won't be much different as one can't recompile it
i had to check out my old portuguese dictionary looking for this:  caixa mágica (magic box) has changed the distro is based of from redhat to debian, then ubuntu since v.16
testdisk is your friend
are you sure you don't have any?  fd is decimal 253 which is the virtblk device driver (eg vda2).  % ls -l /dev/vda2 brw-rw---- 1 root disk 253, 2 aug 24 07:49 /dev/vda2   alternatively,if you want to find the actual file it's pointing to, rather than the device, we could cheat and look at /proc/6813/fd to see what files that process has open and compare them to the inode numbers.  eg i see in my /proc/locks the entry:  21: flock  advisory  write 1324 fd:03:390139 0 eof   so  find -l /proc/1324/fd -maxdepth 1 -inum 390139 -exec readlink {} \;   (the -l will follow the /proc/.../fd symlinks to the real file, so we can check the inode number of the target; the maxdepth will mean that any symlinks to directories won't be followed).  in this case i get  # find -l /proc/1324/fd -maxdepth 1 -inum 390139 -exec readlink {} \; /var/spool/postfix/pid/master.pid  
you can accomplish what you want like this:  $ gnome-terminal -e "bash -c '&lt;cmd1&gt;;&lt;cmd2&gt;;exec $shell'"   this will open up &lt;cmd1&gt;, when that's complete, it will open up &lt;cmd2&gt;, finally it will leave you at a command prompt exec $shell.  for example:  $ gnome-terminal -e "bash -c 'vim;vim;exec $shell'"   runs vim, if i close the 1st vim, a 2nd vim is started
the count of colors available to tput is given by tput colors
just use a variable to track the first matched:  awk -v first=1 'first &amp;&amp; /  end/ {first=0;next};1' &lt;file  
this is probably caused by a recent kernel update
use the tz environment variable
you can embed data within shell scripts
an approach that works fairly well for me...   connect one of those obsolete monitors you have lying around "just in case" to each of the small computers (raspberrypi, etc.). run a tiny, fast, ram-based o/s like puppy linux (see how it works) on every computer. setup passwordless (pre-shared password distribution) ssh between all computers. install kvm software like synergy on every computer, running the "server" on the computer with the keyboard and mouse
found it..  /proc/diskstats   the 6th and 10th columns are respectively read blocks and write blocks, to get the value in bytes, multiply with 512..  /sys/block/sdx/stat   the 3rd and 7th values are respectively the same as above 
i'm working on linux, which means the is the command md5sum which outputs:  &gt; md5sum * d41d8cd98f00b204e9800998ecf8427e  file_1 d41d8cd98f00b204e9800998ecf8427e  file_10 d41d8cd98f00b204e9800998ecf8427e  file_2 d41d8cd98f00b204e9800998ecf8427e  file_3 d41d8cd98f00b204e9800998ecf8427e  file_4 d41d8cd98f00b204e9800998ecf8427e  file_5 d41d8cd98f00b204e9800998ecf8427e  file_6 d41d8cd98f00b204e9800998ecf8427e  file_7 d41d8cd98f00b204e9800998ecf8427e  file_8 d41d8cd98f00b204e9800998ecf8427e  file_9 b026324c6904b2a9cb4b88d6d61c81d1  other_file_1 31d30eea8d0968d6458e0ad0027c9f80  other_file_10 26ab0db90d72e28ad0ba1e22ee510510  other_file_2 6d7fce9fee471194aa8b5b6e47267f03  other_file_3 48a24b70a0b376535542b996af517398  other_file_4 1dcca23355272056f04fe8bf20edfce0  other_file_5 9ae0ea9e3c9c6e1b9b6252c8395efdc1  other_file_6 84bc3da1b3e33a18e8d5e1bdd7a18d7a  other_file_7 c30f7472766d25af1dc80b3ffc9a58c7  other_file_8 7c5aba41f53293b712fd86d08ed5b36e  other_file_9   now using awk and xargs the command would be:  md5sum * | \ sort | \ awk 'begin{lasthash = ""} $1 == lasthash {print $2} {lasthash = $1}' | \ xargs rm   the awk part initializes lasthash with the empty string, which will not match any hash, and then checks for each line if the hash in lasthash is the same as the hash  (first column) of the current file (second column)
i believe ctrl-' will not be passed to applications in the console
you need to install gvfs to get pcmanfm's trash can to work.  it stores the files in the freedesktop standard location: ~/.local/share/trash/files 
i found out the driver uses different pins (in the board header file, of the device drivers) than the actual hardware for the sd device
/etc/cron.d is not a symlink on my centos 5.x box:   drwx------ 2 root root 4096 feb  5  2013 /etc/cron.d   so, if it's missing entirely, you can restore it with:  # install -d -m 700 -o root -g root /etc/cron.d   if something else is in its place, you could move it out of the way, recreate the directory, and then selectively move things back in place.  to get a list of all files that are supposed to be installed there, say:  # rpm -qla | grep /etc/cron.d   saying rpm -qf filename will tell you which package owns that file, hence which package you can reinstall to restore that file. 
if you don't want to descend into any of the directories named @eadir then you should not use ! before -name:   mkdir -p a/@eadir  mkdir -p b/c/@eadir  mkdir -p d/e/f  touch a/@eadir/xxx  touch b/yyy  touch b/c/@eadir/xxx  touch d/e/f/yyy  find 
if you're using the ssh command line, and you haven't switched the escape character feature off, then you can type ~c after a newline to open a mini-console on the ssh client
an application that ran in the terminal has left the terminal in a state where printing a newline only moves the cursor to the next line, but doesn't move it back to the beginning of the line
being one of the kate developers, i can explain the workflow like this:  when kate or the system crashes, you loose all text buffers that were never saved. however, if you are working on a text file (that exists as file on disk), a swap file is created next to the file, called .filename.kate-swp
i kinda worked around that problem with this:  tail -n2 -f file | while read line do echo $line | lpr -l -h -p epson-lq-500 done   but i'm not sure, whether this is best practice. 
using ; (semicolon) or + (plus sign) is mandatory in order to terminate the shell commands invoked by -exec/execdir.  the difference between ; (semicolon) or + (plus sign) is how the arguments are passed into find's -exec/-execdir parameter
you can do the work of zgrep manually
there is a way:  :~# f=5 ; eval echo {1..$f} 1 2 3 4 5   alternative:  :~# f=5 ; echo `seq 1 $f` 1 2 3 4 5  
you can do this using wmctrl.  example  get your window's id.  $ wmctrl -l 0x02a00004  0 grinchy saml@grinchy:~ 0x0620004f  0 grinchy [gnome] bash command for maximizing and unmaximizing windows in gnome? - google chrome   then toggle window id 0x0620004f, like so.  $ wmctrl -i -r 0x0620004f -b toggle,maximized_vert,maximized_horz  
   how we come to know which value is holding which file descriptor   (printing the values of file descriptor using shell)   you can list all files descriptors of a process using via the /proc filesystem, using  ls -l /proc/&lt;pid&gt;/fd   example:  $ ls -l /proc/2218/fd total 0 lr-x------ 1 setacinq setacinq 64 mar 14 09:29 0 -&gt; /dev/null l-wx------ 1 setacinq setacinq 64 mar 14 09:29 1 -&gt; /dev/null lr-x------ 1 setacinq setacinq 64 mar 14 09:29 18 -&gt; pipe:[14524] l-wx------ 1 setacinq setacinq 64 mar 14 09:29 19 -&gt; pipe:[14524] l-wx------ 1 setacinq setacinq 64 mar 14 09:29 2 -&gt; /home/setacinq/.xsession-errors lrwx------ 1 setacinq setacinq 64 mar 14 09:29 22 -&gt; anon_inode:[eventfd] lrwx------ 1 setacinq setacinq 64 mar 14 09:29 23 -&gt; anon_inode:[eventfd] lrwx------ 1 setacinq setacinq 64 mar 14 09:29 28 -&gt; socket:[14566] lr-x------ 1 setacinq setacinq 64 mar 14 09:29 30 -&gt; /usr/share/unity/lenses/commands/commands.lens lrwx------ 1 setacinq setacinq 64 mar 14 09:29 32 -&gt; socket:[11753] lr-x------ 1 setacinq setacinq 64 mar 14 09:29 35 -&gt; /usr/share/unity/lenses/music/music.lens lr-x------ 1 setacinq setacinq 64 mar 14 09:29 36 -&gt; /usr/share/unity/lenses/files/files.lens lr-x------ 1 setacinq setacinq 64 mar 14 09:29 37 -&gt; /usr/share/unity/lenses/applications/applications.lens lr-x------ 1 setacinq setacinq 64 mar 14 09:29 38 -&gt; /usr/share/unity/lenses/video/video.lens lr-x------ 1 setacinq setacinq 64 mar 14 09:29 8 -&gt; anon_inode:inotify lrwx------ 1 setacinq setacinq 64 mar 14 09:29 9 -&gt; /home/setacinq/.config/compiz-1/compizconfig/done_upgrades  
finally figured it out
those are tcp connections that were used to make an outgoing connection to a website
after the substition happens (which btw in posix could only target the left side before any ">") there is no more evaluation on whether there is any ">" so the approach you envisioned wouldn't work.  if you don't care about posix-conformity (after all you tagged this as 'bash') you could still find a solution by dynamically setting the right side but i would personally go for a totally different approach; have a look at the following post detailing a verbose/silent mode based on custom file descriptors: http://stackoverflow.com/a/20942015/2261442.  a code excerpt from that post to show how nice it would then look like:  # some confirmations: printf "%s\n" "this message is seen at verbosity level 3 and above." &gt;&amp;3 printf "%s\n" "this message is seen at verbosity level 4 and above." &gt;&amp;4 printf "%s\n" "this message is seen at verbosity level 5 and above." &gt;&amp;5  
join -t, &lt;(sort file1) &lt;(sort -t, file2)   the above does the job. 
yes, you can go to koji build system and grab the latest build:   http://koji.fedoraproject.org/koji/packageinfo?packageid=32   but be careful because there are other derived packages from selinux-policy so you should download them as well if they are installed on your system.  use dnf to update, for example:  $ sudo dnf update selinux-policy-3.13.1-191.10.fc24.noarch.rpm selinux-policy-targeted-3.13.1-191.10.fc24.noarch.rpm ...  
you can use the bridge object ip  the ip command, or the bridge command that makes part of the iproute2 package.  basic link manipulation  to create a bridge named br0, that have eth0 and eth1 as members:  ip link add name br0 type bridge ip link set dev br0 up ip link set dev eth0 master br0 ip link set dev eth0 master br1   to remove an interface from the bridge:  ip link set dev eth0 nomaster   and finally, to destroy a bridge after no interface is member:  ip link del br0   forwarding manipulation  to manipulate other aspects of the bridge like the fdb(forwarding database) i suggest you to take a look at the bridge(8) command
sudo cp /etc/var/more/evenmore/file{abc,def} will copy fileabc as filedef in the same folder. in general cp /xyz/{file1,file2} will copy /xyz/file1 as /xyz/file2
it looks like that the hook lvm2 run after the hook encrypt during arch linux's initial ram filesystem phase is not able to activate thinly provisioned logical volumes.  with the same storage configuration as depicted in my question except for normal logical volumes instead of thinly provisioned ones the volume group containing these can be activated without any problems
colours are provided by the font-lock minor mode.  to disable colouring in your current buffer, toggle font-lock-mode off with this command:  m-x font-lock-mode   to disable font-lock-mode permanently, add to your init file (~/.emacs):  (global-font-lock-mode 0)   more info is available under font-lock in the gnu emacs manual 
try:  # loadkeys us   from a terminal, it does not make sense to run this over ssh as the keyboard you use over ssh is the local one and the ssh client sends the keys after they have already been interpreted according to your local keymap
i recommend the dstat tool
that is pretty simple and also explained in the man page of the at command     the at command mails you all output from standard output and standard   error for the scheduled commands, unless you redirect that output.   it also writes the job number and the scheduled time to standard   error.   same as for cron, simply redirect stdout and stderr to some file or to /dev/null if you don't need the output, but then you should be pretty sure what job you're running and how to check the results
you have 2 choices
do cd a/b/c and hit tab several times
in bash you can use the trailing slash (i think it should work in any posix shell):  rm -r -- */   note the -- (thanks for adding that, stephane) which separates options from arguments and allows one to remove entries starting with a hyphen - otherwise after expansion by the shell the entry name would be interpreted as an option by rm (the same holds for many other command line utilities). 
sorry everyone, it was a bonehead error on my part
here is one way to do this in bash:  for i in *; do [ "${i/%mp3/mp3}" != "$i" ] &amp;&amp; echo "$i" "${i/%mp3/mp3}"; done   i've used echo here so the command itself doesn't do anything but print pairs of files names
if you run customized kernels for your embedded hw and have some hw register/bit available you may be able to customize the kernel crash code to set a flag in that hw location which you'd check after reboot.  if not afaik you're only chance is to configure your kernel core dumping facility
with pdftk and gnu coreutils  determine the number of pages in the pdf file, then call shuf to generate a randomized list of page numbers, and call pdftk again to extract the given sequence of pages.  pdftk original.pdf cat $(shuf 1-$(pdftk original.pdf dump_data | awk '$1=="numberofpages:" {print $2}')) output randomized.pdf   with python and pypdf  #!/usr/bin/env python2 import random, sys from pypdf import pdffilewriter, pdffilereader input = pdffilereader(sys.stdin) output = pdffilewriter() pages = range(input.getnumpages()) random.shuffle(pages) for i in pages:      output.addpage(input.getpage(i)) output.write(sys.stdout)'   usage: /path/to/script &lt;original.pdf &gt;randomized.pdf 
you can do this in two steps:  find 
running top with batch mode via -b should get you the information you're looking for.  here's a very messy start to what you could do:  top -b -n 1 | head | grep -a 1 pid | grep "^[0-9]" | cut -f1 -d" " | xargs kill   you can always kill a process from an interactive run of top using the k key as well, since you might not like what it picks...  not sure what kernel you're running, but cgroups may also be of use to you in addition to limits.conf 
scp does detect whether it's got a controlling tty
@cuonglm's comment illustrates how you can do this with sed:  sed -e 's/.*\(apple\)/\1/' input.txt   you might also consider using good old grep:  grep -o 'apple.*' input.txt   caveat 1 - i don't have any solaris handy, so it might be that the solaris grep doesn't have the -o option
that's probably not possible
if none of the file names contain space, tab, newline, ?, *, [ characters or are called -, this should do it:  grep "exit 0" -- $(ls -tr a*)   $() is called command substitution
i assume you mean that your network cable is unplugged
the virtio drivers are included in freebsd 10.1, so there's no need to install the port, hence the error message
i use the usbmount package to automount usb drives on my ubuntu server install
when you write to a pipe whose other end has been closed, you normally receive a sigpipe signal and die
screen by default will use sizes which were current when screen was started
it looks like monodevelop 2.95 is a development release, so won't find it in the repository
ssh provides a connected stream from the local system running your rsync to another instance running on the remote server
your question is distro-neutral, so if i mention anything specific that you don't have, just use the equivalent on your side
thanks to @mat:  # mkdir -p /mnt/ram # mount -t ramfs -o size=20m ramfs /mnt/ram  
use sed's insert (i) option which will insert the text in the preceding line.  sed '1 i\   question author's update:  to make it edit the file in place - with gnu sed - i had to add the -i option:  sed -i '1 i\anything' file   also syntax  sed  -i '1i text' filename  
because it isn't set up in the relevant shell startup files for root.  traditionally, /usr/local has been used for unofficial, locally installed software (often to override buggy/broken/limited "official" versions; a friend quipped that the first step when a new sun arrived was gnu &gt; /usr/local)
well as jofel commented there is unattended-upgrade to automate the upgrade process, there is also the update-manager-core package that gives you access to the update-manager-text binary
vlock will do as you ask
   my question is: why is it possible for a computer on the 172.16.2.0/24 subnet to ping 172.16.1.1 (ip address of eth1 interface)?   because you allowed it, and linux does it by default.  linux uses what is called a weak host model
cups 1.6+ changed the way it gives access to print queues
have a read through man periodic and look for all the bits that mention output  create a file /etc/periodic.conf if one doesn't already exist and set the *_output variables from /etc/defaults/periodic.conf to a log file
i wouldn't use a shell loop to process text.  here, you can just do:  cut -d _ -f 2 &lt; country.txt   or if the input may contain lines without _ characters:  awk -f _ 'nf &gt;= 2 {print $2}' &lt; country.txt   if the country name may contain _ character and you want instead to return the part of the line in between the first _ and the first occurrence of _raw or _clean after that, you could do:  perl -ne 'print $1 if s/^[^_]*_(.*?)_(clean|raw)/' &lt; country.txt   or with gnu grep:  grep -po '^[^_]*_\k.*?(?=_clean|_raw)' &lt; country.txt   with -p (provided grep has been built with pcre support), the regexp is a perl-compatible one
if jboss-cli.sh reads from standard input, you can pipe the command to it:  echo 'undeploy flcerp.ear' | ./jboss-cli.sh --connect   if you want to send multiple commands, a here-doc may be easier:  ./jboss-cli.sh --connect &lt;&lt;eof undeploy flcerp.ear other commands go here eof  
the reason why tar (or cpio) is recommended over cp for this procedure is because of how the tools operate.  cp operates on each file object in turn, reading it from disk and then writing it in its new location
that feature was introduced by ksh (in ksh86) and was making use of the /dev/fd/n feature (added independently in some bsds and at&amp;t systems earlier)
i found out that in centos 7 yum-cron has nothing to do with the "install updates &amp; restart" prompt
a good answer was provided on super user.   whether or not the files discussed are precise extensions of the legacy file my author refers to remains unknown
a program that monitors window creation doesn't come to mind, but you don't need that.  you can run wmctrl -l in a loop or on a timer (e.g
basics  with an amd apu, the following factors are of interest.   if your system will only use console output, you will want to use the radeon driver for it
letting badblocks write the pattern in the first place should be no slower than writing it any other way
if i were to guess, i'd suspect ifs
the very simple way to do it is like the following:  export pythonpath="/your/module/path"   from the terminal
why not use rsync instead?  it's made for the job!  rsync -uan --progress --exclude=".*" &lt;source&gt; &lt;destination&gt;   the above will list all the files to be archived without actually copying anything
vimperator founder here:  yes, it is possible
unfortunately, you can't do this with the nss implementation of gnu libc
quick hack:  for ip in $(cut -d" " -f 4 &lt; input_file.txt | sort -u); do     grep "$ip" input_file.txt | head -n1    grep "$ip" input_file.txt | tail -n1    echo done   however, this is not very fast, because it loops through the log file 3 times. and the output is not in the same order has your example; i'm not sure whether that is important to you. 
as suggested by stephane chazelas, you could use find and check for ctime.  assuming the backup was initiated 200 minutes ago, and terminated 100 minutes ago, this will find anything with a ctime in that interval:  find -cmin -200 -cmin +100   do your dry-runs and if it looks good, construct your restauration based on that.  update:  a general starting point for moving your files could look like (remove echo to mv for real):  find source --mindepth 1 -cmin -200 -cmin +100 -exec echo mv -v "{}" target \;   where --mindepth 1 helps avoid source itself being moved (in that case you could just mv source target), and "{}" makes mv work for pathnames containing spaces
the redirects are interpreted by the shell
no, there's only one /etc/hosts
not a direct answer to your question (since aliases can only be one word), but you should be using git-config instead:  git config --global alias.civ commit -v   this creates a git alias so that git civ runs git commit -v
ok, after some more thought i think i have a clear solution
   do they just mark the space as "free"?   yes.  "removing" the file would take extra work and is in most cases unnecessary. 
the kernel allocates a major:minor number, either statically (in drivers that do have a static allocation and haven't run out) or dynamically (in drivers that support dynamic allocation and have used up their static allotment)
save your function definitions in a file like factorial.bc, and then run  bc factorial.bc &lt;&lt;&lt; '1/fact(937)'   if you want the factorial function to always load when you run bc, i'd suggest wrapping the bc binary with a shell script or function (whether a script or function is best depends on how you want to use it).  script (bc, to put in ~/bin)  #!/bin/sh  bc ~/factorial.bc &lt;&lt; eof $@ eof   function (to put in shell rc file)  bc () {     bc ~/factorial.bc &lt;&lt; eof     $@     eof }     from the bc posix specifications:     it shall take input from any files given, then read from the standard input.  
there are two possible cases:   you have ordered from both isps the fixed ips (or ranges) and you made a special arrangement with isp that handles your outbound traffic to allow the traffic from your site that has different source ip addresses in ip packets than this isp provided to you. also, most likely, this isp would request a proof from you that these ip's are assigned to you by another isp/internet authority. then this is possible. you did not make any arrangements with isps in this regard and do send the traffic with altered source addresses on your own
i discovered that i had to "set forward-as-attachment" then i could forward out the mail... 
a user has one shell
you can use find ..
i came across this post from phoronix and in it, it said:     the short story to running amd a-series trinity apus on linux is that it works
this is a harder version of show only stderr on screen but write both stdout and stderr to file.  the applications running in the terminal use a single channel to communicate with it; the applications have two output ports, stdout and stderr, but they're both connected to the same channel.  you can connect one of them to a different channel, add color to that channel, and merge the two channels, but this will cause two problems:   the merged output may not be exactly in the same order as if there had been no redirection
install a minimal, base-system only debian
not sure what you mean
it is easy to try this out
i'm pretty sure that your lid callback is going to be called every time the lid is closed as well as opened.  the sleep.sh file here states:  # if launched through a lid event and lid is open, do nothing echo "$1" | grep "button/lid" &amp;&amp; grep -q open /proc/acpi/button/lid/lid/state &amp;&amp; exit 0   the "lid open" scenario is one your script is not checking for...  you could quickly test this by echoing some parameters to a log file 
why not just  files = sys.argv[1:] if not files:     files = ["/dev/stdin"]  for file in files:     f = open(file)     ...  
make does this using its built-in rules
 the ln command creates the symlink in the current directory if no directory is specified
alias tree="ls -r | grep ":$" | sed -e 's/:$//' -e 's/[^-][^\/]*\//--/g' -e 's/^/   /' -e 's/-/|/'"    ls -r: list subdirectories recursively grep ":$": grep only for lines with : at the end of the line sed -e 's/:$//': remove : at the end of the line -e 's/[^-][^\/]*\//--/g': replace all path components except of last dir with --
rather than mess with the system level python, might i suggest using something like virtualenv together with virtualenvwrapper
in one word: yes :)  how to do it is a different question.  try this in single user mode: mount -o ro,remount /  realize that some programs might not work (vim is the first thing that comes to mind). 
partial answer regarding compression, from openssh's man page ssh_config(5) (what you can configure using the -o option of ssh (i.e
in  echo variable "$var" is not initialised.   you're passing 5 arguments to echo (6 if you count echo), echo will output them separated by a space character terminated with a newline.  in:  echo "variable $var is not initialised."   you're passing 2 arguments, of which the first one already has the echo.  in this particular case and in most cases, that is going to be functionally equivalent.  the second means less work for the shell to parse the command and store it into arguments before running echo and less work for echo to go through its arguments.  that's unlikely to make a very significant difference
this is as simple as it could be
after some more research, i have found that the term swapcached in /proc/meminfo is misleading
yes, just the regular ntpd provides this
i understand your question that you want to control the function
with bash, zsh and ksh processsubstitution :   while ifs= read -r line; do     echo "$line" done &lt; &lt;(p4 opened -c $changelist)   see http://mywiki.wooledge.org/processsubstitution and http://mywiki.wooledge.org/bashfaq/024  if not using one of these shells (like  joseph r
in posix shell, arithmetic expansion has form:  $((expression))   if expression contains variables, and those variables contain valid integer value - leading plus or minus is fine - then "$((var))" and "$(($var))" will return the same result (note: using unsanitized data in shell arithmetic evaluation leads to security implication)
okay, so, the answer is that the redshift program, pointed out by stéphane gimenez in a comment above, can do this pretty simply
you misunderstand regex syntax
short clarification : actions can be added to the interface configurations as actions do be done before or after interfaces are up with the directives pre-up and if-up.  adding to your configuration an instruction to take down eth0 after wlan0 goes up successfully:  auto wlan0 iface wlan0 inet manual wpa-driver nl80211 wpa-roam /etc/wpa_supplicant.conf iface default inet static address 192.168.1.101 netmask 255.255.255.0 gateway 192.168.1.1 dns-nameservers 192.168.1.1 if-up ifconfig eth0 down if-down ifconfig eth0 up   i recommend ifconfig instead of ifdown as ifconfig does not throw an error back if the interface is not up and is a simpler operation (ifdown is a script) 
      what is tmpfs?      tmpfs is a file system which keeps all files in virtual memory.  read more          what is /dev/sdc1 and how can i use the enough space available (46g)      /dev/sdc1 is just another file system that you have created and mounted in your system
almost like nsg's answer: use a lock directory
press ctrl+_ and instead of entering a line number hit ctrl+v. 
to exclude specific paths, on linux:  find / -path /sys -prune -o -path /proc -prune -o -type d   another approach is to tell find not to recurse under different filesystems.  find / -xdev -type d   you could also use locate to query a database of file names (usually updated nightly) instead of the live system.  locate '*' | shuf -n 1  
if i were doing this i would build the whole thing in an iso so once it's working you're done
i puzzled a bit around what would be the enumeration scheme on my systems and i've came up with following algorithm:  the /dev/sdy devices are created in the same order as the atax identifiers are enumerated in the kern.log while ignoring non-disk devices (atapi) and not-connected links.  thus, following command displays the mapping:  $ grep '^may 28 2'  /var/log/kern.log.0  | \    grep 'ata[0-9]\+.[0-9][0-9]: ata-' | \    sed 's/^.*\] ata//' | \    sort -n | sed 's/:.*//' | \    awk ' { a="ata" $1; printf("%10s is /dev/sd%c\n", a, 96+nr); }' ata1.00 is /dev/sda ata3.00 is /dev/sdb ata5.00 is /dev/sdc ata7.00 is /dev/sdd ata8.00 is /dev/sde ata10.00 is /dev/sdf   (note that ata4 is not displayed because the above log messages are from another system.)  i am using /var/log/kern.log.0 and not /var/log/kern.log because the boot messages are already rotated
i understand ash to be bourne-derived, so i think this should work:  if ping -c1 www.google.com &gt; /dev/null; then     echo "it worked" else     echo "no dice" fi  
either (additionally) export that subdirectory in virtualbox and mount it the same way, or mount the main folder to a temporary mount point and use a bind mount to mount the subdirectory to the actual place:  mount -t vboxsf vm_shared /mnt mount --bind /mnt/subdir ~/shared/  
the [ binary residing under the /bin tree in many gnu/linux distributions is not something to be alarmed off
$ mv projects/landmarks/ projects/landmarks/all/ mv: rename projects/landmarks/ to projects/landmarks/all/landmarks/:  invalid argumentyou can not move the main directory into one of its subdirectories
try to align to emmc erasure block size
if one has the canon scanner drivers installed, that means that in most cases a scanning application called scangear is already installed.    that can be started by opening a terminal and doing scangearmp
you can do that in ubuntu because they ship vim 7.4 on their repositories
actually it's much simpler
in order to hibernate, the system has to have somewhere on the disk to write the data that is in ram to save it from extermination when the power goes out
here's how it's done:  # must install 7 first or else when uninstalling six, it will try to install a bunch of replacement gcj stuff. sudo apt-get install openjdk-7-jdk sudo apt-get remove openjdk-6-jre sudo apt-get remove openjdk-6-jre-lib   afterwards:  &gt; java -version java version "1.7.0_03" openjdk runtime environment (icedtea7 2.1.1pre) (7~u3-2.1.1~pre1-1ubuntu3) openjdk 64-bit server vm (build 22.0-b10, mixed mode)  
the only hack i can think of, would be to make a directory with fake "binaries" using the same names as the list you provide, symlinked to some inert executable script like:  #!/bin/sh echo "this is a fake binary, and should never execute
this vulnerability has a high potential impact because if your system has been attacked, it will remain vulnerable even after patching, and attacks may not have left any traces in logs
i solved my own problem ! here is the solution, move the themes from home/.themes to /usr/share/themes
as long as you don't mind that the intermediate storage won't be usable as such:  split -b 1024m /dev/dvd iso-pieces. # pop out original, pop in blank cat iso-pieces.* | growisofs -z /dev/dvd=/dev/stdin  
from the wikipedia's "checksum" article:     a checksum or hash sum is a small-size datum from a block of digital data for the purpose of detecting errors which may have been introduced during its transmission or storage
as of today i have successfully installed this distribution and can use it as if it were arch :) below is the simplest way to do so:   install arch on the hard drive remove everything in / (in the local disk), except for /boot mount the root-image.sqfs image in the linux-gamers live dvd and copy everything inside to / repeat the previous step with the overlay.sqfs image   step 2, 3, 4 may have to be performed with a live cd
you need to move the line  partof=app.service   out of [service] and into the [unit] section, and add to the [unit] of app.service the list of customers to start, eg  wants=app@customer1.service app@customer2.service   or as sourcejedi said in the comments, requires= the same thing
this is happening because ~ has not been expanded
most gnu software is fully documented in info manuals rather than traditional manual pages
as long as your html tags are confined to a single line, the following will work:  sed 's/&lt;[^&gt;]*&gt;//g'  
multiple slashes are allowed and are equivalent to a single slash
keyboard methods   if using the sdl frontend of qemu:  you can release focus using the left ctrl+ left alt
on centos there is /var/log/secure
i would recommend creating a private/public key pair on the client machine, and copying the public key to the remote machine.  you can generate such a keypair with ssh-keygen and copy it to the remote machine using ssh-copy-id.  the logs are probably readable by all user accounts on the server (at least they are on my machine)
a2ps was the answer
while it looks easy, it is really very hard.  jobs started by gnu parallel are not started inside the same shell as gnu parallel is run from
the manpage reveals the answer
i did it !  first of all, i removed all the unnecessary boot entries by:  efibootmgr -b &lt;entry_hex_number&gt; -b   then, reformatting the esp partition with fat32 filesystem.  mkfs.vfat -f32 /dev/sda1   then installed grub to /dev/sda not /dev/sda1  grub-install /dev/sda  
..
i managed to get this to work:  cvlc -vvv --daemon --pidfile ./coffee_stream.pid rtsp://10.217.112.30:554/axis-media/media.amp?videocodec=h264 --sout="#transcode{vfilter=gradient{type=1},vcodec=theo,acodec=vorb,vb=800,ab=128}:standard{access=http{mime=video/ogg},mux=ogg,dst=:8091}"  
desktop icons are handled by the file manager, which is   nemo in cinnamon edition caja in mate edition thunar in xfce edition   with kde there's a special case, as there are no icons directly on the desktop
starting the process inside a network namespace that can only see the desired ip address can accomplish something similar
the ubuntu 11 to 14.04 upgrade means your kernel libraries, and therefore, binaries will have to be different, including apache and mysql server
see the sshd_config man page:     listenaddress      specifies the local addresses sshd(8) should listen on
there are a few hack-ish options out there, see here, and here.  but i certainly wouldn't do it
if you need to select more specific files than only directories use find and pass it to while read:  shopt -s dotglob find * -prune -type d | while read d; do      echo "$d" done   use shopt -u dotglob to exclude hidden directories (or setopt dotglob/unsetopt dotglob in zsh).  see asymlabs answer below for more find options    edit: in case you need to create an exit value from within the while loop, you can circumvent the extra subshell by this trick:  while read d; do      if [ $d == "something" ]; then exit 1; fi done &lt; &lt;(find * -prune -type d)  
using "perl"  perl -0777 -pe 's/&lt;body&gt;.*&lt;\/body&gt;//s' &lt;file    option -0777 makes perl read the file as a single line the s/…// substitution replaces the body tags and everything within
it is usually worth reading output of ./configure --help
it depends on how your address was configured in the first place
with ntpdate:  ntpdate -d 0.debian.pool.ntp.org   or for the offset only:  ntpdate -d 0.debian.pool.ntp.org | sed -n '$s/.*offset //p'  
don't use the commandlinefu solution from the other answer: it's unsafe¹ and inefficient.²  instead, if you are using bash, just use the following functions
the linux-headers package is only needed when you want to compile sources, kernels or build other packages
first of all: there are no drivers under linux.  there is something called "modules" which serves the same purpose and as some large company in redmond, wa calls those "drivers", some people call it that too under linux..
the cause  firstly, let's look at the manual page of bash:     a non-quoted backslash () is the escape character
i found ssmtp very simple to use.  in debian based systems:  apt-get install ssmtp   then edit the configuration file in /etc/ssmtp/ssmtp.conf  a sample configuration to use your gmail for sending e-mails:  # root is the person who gets all mail for userids &lt; 1000 root=your@email.com  # here is the gmail configuration (or change it to your private smtp server) mailhub=smtp.gmail.com:587 authuser=your@gmail.com authpass=yourgmailpass usetls=yes usestarttls=yes   note: make sure the "mail" command is present in your system
from the 4bsd ps man page:     the state is given by a sequence of   four letters, e.g
i believe xdmcp is using the fonts local to the solaris system
the correct way is:  ./configure cflags="-i/usr/local/include" ldflags="-l/usr/local/lib"   but this may not work with all configure scripts
wildcards with sudo commands are a bit dicey
hash is a shell builtin.  if you are using bash, check:  help hash   for your convenience, here it is:     hash: hash [-lr] [-p pathname] [-dt] [name ...]  remember or display program locations.  determine and remember the full pathname of each command name
it is impossible to have nul bytes in command line arguments, so the question is what do you want to happen in case there are nul bytes in the standard input.  as you've noted, your candidate solution #1 runs the command multiple times in this case
what you could do to avoid writing a copy of the file is to write the file over itself like:  {   sed "$l1,$l2 d" &lt; file   perl -le 'truncate stdout, tell stdout' } 1&lt;&gt; file   dangerous as you've no backup copy there.  or avoiding sed, stealing part of manatwork's idea:  {   head -n "$(($l1 - 1))"   head -n "$(($l2 - $l1 + 1))" &gt; /dev/null   cat   perl -le 'truncate stdout, tell stdout' } &lt; file 1&lt;&gt; file   that could still be improved because you're overwriting the first l1 - 1 lines over themselves while you don't need to, but avoiding it would mean a bit more involved programming, and for instance do everything in perl which may end up less efficient:  perl -ne 'begin{($l1,$l2) = ($env{"l1"}, $env{"l2"})}     if ($
you can create following script:  #!/bin/bash "$@" &gt;/dev/null 2&gt;&amp;1 &amp;   save as for example 'gui'. next, allow to execute:  chmod +x gui   copy to /usr/bin  # cp gui /usr/local/bin   be happy of typing   gui program_name   ! 
this is the same file, not the actual firewall rules in the kernel, but they appear here in the same order they would in a running firewall
if i recall correctly, you need to explicitly set it, even with bindkey -v
this code works:  ls --color=al &gt; /dev/null 2&gt;&amp;1 &amp;&amp; alias ls='ls -f --color=al' || alias ls='ls -gf'   basically it sees if ls color=al works
find 
you are asking wget to do a recursive download of http://ccachicago.org, but this url doesn't provide any direct content
several alternatives:  awk '! (/foo/ &amp;&amp; !/bar/)' awk '/bar/ || !/foo/' sed -e /bar/b -e /foo/d sed '/foo/{/bar/!d;}' perl -ne 'print unless /foo/ &amp;&amp; !/bar/'   gnu grep with pcre support:  grep -vp '^(?!.*bar).*foo'   (using pcre's negative look-ahead operator (?!...)).  of those, only perl allows in-place editing portably (on systems where any version of perl is installed) with the -i option.  standard sed doesn't do in-place editing
you could create a normal user, e.g
i tried one more reboot, it seems that the last 3 steps i did fixed the problem:  using fdisk to switch off bootable flag for /dev/sda1 partprobe so the kernel knows about changes remounted everything again on top of root at /mnt/root and performed: grub-install /dev/sda  (from the chroot) update-grub   the mbr dump made me believe it worked this time
download translate shell  cd wget https://github.com/soimort/google-translate-cli/archive/master.tar.gz tar -xvf master.tar.gz cd google-translate-cli-master/   install   use make  sudo make install   or use checkinstall  sudo apt-get install checkinstall sudo checkinstall   if you see this: 3 -  version: [ master ]then   press 3 enter a number, e.g
the canonical way to do this is with the batchmode option:  ssh -o batchmode=yes …   according to the manual:     if set to “yes”, passphrase/password querying will be disabled
the problem is that in the syntax:  if-shell shell-command tmux-command1 tmux-command2   you can use $() in the 2nd part shell-command as the shell will interpret this, but not in the two tmux command parts
you can store the code passed to /usr/bin/awk in a variable and /usr/bin/awk in a separate variable like so (untested):  awk=/usr/bin/awk  awkcommand=' $1 == "group" {printf("\section{%s %d}\n", $1, $2); next} { title = sep = "" for (i=1; i&lt;=nf; i++)    if ($i ~ /^[0-9][0-9][0-9]$/) {     printf("\subsection{%s} \n\testdetails{%d}\n", title, $i)     break   }   else {     title = title sep $i     sep = fs   } } '   usage:  $awk "$awkcommand"   note that i changed the double quotation marks to single quotation marks. within double quotation marks, $i is substituted by the contents of the shell variable i
i think there is no daemon for that
after changing your group, you have to log out and log in again for your new group assignment to be active
i am guessing this
the loopback networking interface is a virtual network device implemented entirely in software
i have been searching solutions for this problem until your quertion inspire me.by simply adding  deb http://old.kali.org/kali moto main non-free contrib   to   /etc/apt/sources.list   and     apt-get update then  apt-cache search linux-headers   now we find the kernel headers file of the old version!  however a new problem arise.as my kali runs a gcc-4.9 where linux-headers-3.18.0-kali3-amd64 depends on gcc-4.7,i can't install the headers,and i have a problem removing gcc-4.9 . try finding ways..
according to the passwd man page:  -d     this is a quick way to delete a password for an account
write a udev script that floats the built-in keyboard using xinput. 
found this method on askubuntu that shows using a crontab entry along with amixer to mute/unmute the sound
solaris ips (image packaging system) is definitely based on a repository infrastructure and behaves like yum/apt if you mean automatically handles dependencies
the system-wide nanorc file is at /etc/nanorc  you can also add a .nanorc file to /etc/skel so all new users have a local nanorc file added to their home folder. 
i’ve been able to do this with an udev rule, after some trickery (and using lsusb to find out the vendor and product id of the device in flash mode):  $ cat /etc/udev/rules.d/nxt.rules # disable nxt in flash mode action=="add", attr{idvendor}=="03eb", attr{idproduct}=="6124", run="/bin/sh -c '/bin/echo -n $kernel:1.0 | /usr/bin/tee /sys/bus/usb/drivers/cdc_acm/unbind | /usr/bin/logger -t nxt-flashmode'"   this rule is triggered when an nxt brick is plugged in while in flash mode, or put into flash mode while plugged in
inotify would be a good candidate to do this sort of counting but as suspected this approach isn't ideal and prone to race conditions, in the end i agree that in fact i'm trying to count the number of transactions with this, so it would be better to do this in the application itself and keep count. 
you need to quote your expansion, otherwise it will undergo word splitting, which is what you are experiencing.  acl=$(getfacl somefile.dat) echo "$acl"   bear in mind that $( strips trailing newlines anyway (it is considered a feature)
some people have been able to get ntldr to chain to grub: http://stringofthoughts.wordpress.com/2009/04/27/booting-linux-from-ntloader-windows-bootloader/  although in practice it's easier to use a live cd
you can use the glibc manual as a reference
_kadmin is probably a completer function for the kadmin tool - not a directory
this has already been answered in this question, which i quote (original text by echox):     there are 3 kind of "timestamps":         access - the last time the file was read   modify - the last time the file was modified (content has been modified)   change - the last time meta data of the file was changed (e.g
clonezilla would be a suitable product for a whole-disk image
on linux, top actually supports focusing on a single process, although it naturally doesn't have a history graph:  top -p pid   this is also available on mac os x with a different syntax:  top -pid pid  
i presume that by “doesn't have valid ip” you mean that the computer you want to connect to (let's call it bob) does not have a public ip address and is behind a nat.  you can only make tcp connections (such as ssh connections) to a computer that has a public ip address
add your excludes to a file, then use --exclude-from=/path/to/exclude_file  e.g.  # cat rsync.excludes .ht* error_log .ds* old ...  # rsync --exclude-from=rsync.excludes  
what you get when you press ctrl + alt + f1 is not xterm, or anything to do with x or your de
i think i'm starting to get what happened
in less, you can type f to keep reading at the end of a file (like tail -f); you can type :e and a file name to view a different file, but unfortunately, if you enter the name of the current file, less doesn't reload the file
to check if there were no arguments provided to the command, check value of $# variable then,  if [ $# -eq 0 ]; then     echo "no arguments provided"     exit 1 fi   if you want to use $*(not preferable) then,  if [ "$*" == "" ]; then     echo "no arguments provided"     exit 1 fi   some explanation:  the second approach is not preferable because in positional parameter expansion * expands to the positional parameters, starting from one
i am not sure why your version is not working, but i am able to do this using the call option and putting the settings in a function like this:  set tabstop=4 set softtabstop=4 set shiftwidth=4  function! setaltprefs()     set tabstop=2     set softtabstop=2     set shiftwidth=2 endfunction  autocmd filetype xml,html,xhtml,javascript call setaltprefs()   this should get fired any time a file is loaded into a buffer or the filetype changes
your strace output shows that ping6 is trying to make dns requests to find the ip address of www.google.com.  the first dns request is being directed to 209.244.0.3, which is resolver1.level3.net
current util-linux versions of fdisk support gpt, the one i'm looking at here is fdisk from util-linux 2.24.2 (reported via fdisk -v).  run fdisk /dev/whatever
if you're on a system using gnu coreutils (almost any linux), you can try stdbuf:  … | stdbuf -ol cut -d '@' -f 1 | …   -ol makes it line buffered, which seems like what you want. 
call rsync and exclude the directory where you're putting the copy.  cd mkdir copy rsync -a --exclude=copy 
i have the following code for you; below it there's an explanation how it works.  first go into the working directory (cd /user/mydata/) to run this program:  awk '   fnr==1 { sample = filename ; sub(/\.fasta/, "", sample }   /^&gt;/   { target = substr($0,2)".fasta" ; next }          { print "&gt;" sample &gt; target ; print &gt; target } ' sample_*.fasta   the awk program iterates over all sample_*.fasta files
you need to pass your arguments to push-mark, not global-set-key:  (global-set-key (kbd "m-spc") (lambda() (interactive) (push-mark nil nil 1)))  
that file looks like sh syntax
if switching to xterm is an option, you could use the hack below
this whole discussion is about a hypothetical option that was proposed, not about an actual feature
what is happening is that grep -q '[^[:space:]]' is processing the remaining lines in standard input (which is what grep does by default if you haven't given it any input), leaving nothing for the next read - the file pointer is at eof
-e is strictly the flag for indicating the pattern you want to match against
further investigation brought me to this page
welcome to stackexchange
i am not sure i understood your question but... if you have a gnome terminal or similar, you can try to:  in your terminal:  (right button    select profile     profile preferences        scrolling   and change the number of lines for scrolling 
a question very close to this one was posted on unix.stackexchange here giles has a pretty complete | cool answer for the ways he describes.  # cat /proc/version  linux version 2.6.32-71.el6.x86_64 (mockbuild@c6b6.centos.org) (gcc version 4.4.4 20100726 (red hat 4.4.4-13) (gcc) ) #1 smp fri may 20 03:51:51 bst 2011     # uname -a  linux system1.doofus.local 2.6.32-71.el6.x86_64 #1 smp fri may 20 03:51:51 bst 2011 x86_64 x86_64 x86_64 gnu/linux  # cat /etc/issue  centos linux release 6.0 (final) kernel \r on an \m   cat /proc/config.gz cat /usr/src/linux/config.gz cat /boot/config*  though i did some checking and this was not very reliable except on suse.  # zcat /proc/config.gz | grep -i kernel config_suse_kernel=y # config_kernel_desktop is not set config_lock_kernel=y  release files in /etc (from unix.com)   novell suse---> /etc/suse-release     red hat--->/etc/redhat-release, /etc/redhat_version   fedora-->/etc/fedora-release     slackware--->/etc/slackware-release, /etc/slackware-version     old debian--->/etc/debian_release, /etc/debian_version  new debian--->/etc/os-release mandrake--->/etc/mandrake-release   yellow dog-->/etc/yellowdog-release      sun jds--->/etc/sun-release   solaris/sparc--->/etc/release       gentoo--->/etc/gentoo-release   there is also a bash script at the unix.com link someone wrote to automate checking.  figuring out what package manager you have is a good clue.  rpm yum apt-get zypper +many more  though this is by no means foolproof as the vendor could use anything they want
with freebsd 9+ the camcontrol utility can be used to control if either a sata or a scsi drive is disconnected, or not, in such circumstances:  camcontrol negotiate /dev/&lt;dev&gt; -d disable  
sudo gedit /usr/share/contractor/make_executable.contract   add this content and save:  [contractor entry] name=make executable icon=name.of.icon.wanted description=make a file executable mimetype=inode;application/x-sh;application/x-executable; exec=gksudo chmod +x %u   should do the trick.  but it is possible that in elementaryos a file that was made executable may still lack the option of being run from context menu or click: it may open instead in a text editor, etc.  to add a 'run' menu entry to run such a file create a new contractor entry   sudo gedit /usr/share/contractor/run.contract   like this:  [contractor entry] name=run  icon=run description=run mimetype=inode;application/x-sh;application/x-executable; exec=sh %u  
one thing you can do is boot a working kernel, run lsmod, and make sure that all the modules listed are turned on in your config (either built-in or as modules).  it's easiest to start with a working config, and then tweak it
if you're using a modern shell like bash or zsh, use $ so that the shell evaluates \t and replaces it with an actual tab:  nl -ba -s $'\t' full_media &gt; full_media2   even so, if you examine the output, it looks like the default separator is a tab:  $ nl -ba -s $'\t' ~/at.sh | od -c 0000000                       1  \t   n   o   h   u   p       s   g     $ nl -ba  ~/at.sh | od -c         0000000                       1  \t   n   o   h   u   p       s   g       indeed, the default separator is tab, as specified by posix
the beautiful thing about *nix, and open source in general, is that you have no shortage of resources
first of all, you have to find and .xpi file for the requested language
the shortcut is -  try cd -  if you want to use this in your prompt, you have to refer to it with ~-.  see the example:  [echox@kaffeesatz ~]$ cd /tmp [echox@kaffeesatz tmp]$ ls cron.idds32  serverauth.cfigexuvka [echox@kaffeesatz tmp]$ cd - /home/echox [echox@kaffeesatz ~]$ ls ~- cron.idds32  serverauth.cfigexuvka  
two things you can do:   read the log files on the server
this is a security thing, it's not actually taking long to realize it
you can position the cursor on the first match using the -s (script) option
there's a mistake, you need &lt; &lt;(command) not &lt;&lt;&lt;$(command)  &lt; &lt;( ) is a process substitution, $() is a command substitution and &lt;&lt;&lt; is a here-string
the question (and suggested answer) are a little obscure, but what is being described is mutt's use of the default color feature of ncurses (or slang)
it is not possible, from outside the process itself
thats three questions in one ;-)  auto_cd option and howto find it  first of all the option you are looking for is auto_cd. you can easily find it by looking up man zshoptions
assuming a posix shell (like bash), $$ is the pid of the current shell and $ppid is the pid of the parent
you can use kill -9 11394 to kill the process completely ungracefully, this will invoke the following:  from the 3 most important "kill" signals on the linux/unix command line:     the kernel will let go of the process without informing the process of it
apache 2.4 doesn't use the init scripts
each lvm object (physical volume, volume group, logical volume) has a uuid
with the exception of shell builtins, commands are just programs
note to myself and others: the solution i use now is aptly.  from their website:     aptly is a swiss army knife for debian repository management: it allows to mirror remote repositories, manage local package repositories, take snapshots, pull new versions of packages along with dependencies, publish snapshots as debian repositories.   so far my experiences with aptly have been quite good. 
there are many reasons for broken symbolic links:   a link was created to a target which no longer exists. resolution: remove the broken symlink. a link was created for a target which has been moved
postfix is delivering to a mailbox file rather than a maildir
perl regular expressions and perl compatible regular expressions are slightly different to the posix "basic" or "extended" regex that utilities like grep implement
you could delete the symlinks for them in the /etc/rc2.d (or rc3.d) directory
as @roaima pointed out, you likely want to run the script in a separate process
the . builtin looks for the script passed argument in the command search path ($path) if it doesn't contain a /
upon close inspection of /var/lib/dpkg/info/ttf-mscorefonts-installer.postinst it seems the package is a stub to get fonts from outside sources using wget:  167                     if ! wget --continue --tries=1 --connect-timeout=60 --read-timeout=300 $quiet_arg --directory-prefix 
the following is only a rough idea, no ready solution (especially no code!).  i would convert a sample of the small graphic and the screenshots to a raw (uncompressed) format (tga has abolultely no compression, it's just a complete dump of every pixel) and then grep for the graphic in the screenshot file
this discussion is enlightening.  at the very least, even if not ideal, you should be able to do:  xmllint --xpath "//*[local-name()='product_version']/*[local-name()='name']/text()" file.xml   or use xmlstarlet instead:  xmlstarlet sel -t -v //swid:product_version/swid:name file.xml  
you could automate the process by wrapping the abcde with a script that invokes abcde and checks for 'unknown artist/unknown album' directory existence after abcde completion
there are two errors in your command:   leave out the "*bz2" option to bzip2, the {} will be replaced by any file find returns add a space between {} and \;   so the full command would be   find -name "*bz2" -print -exec bzip2 -d {} \;  
this has nothing to do with debian, the problem you are experiencing happens long before the operating system is started
vi is (also) a standard
while this doesn't completely solve the problem raised here, there is an option called -dynroot-sparse in the openafs client these days, which tries to reduce the number of directories that are visible under /afs
the console doesn't use ttf fonts, like inconsolata.  you can use an application like fbterm that can draw text with freetype2 to allow you to use ttf/otf type fonts. 
i realize this is late coming but:      checking the select box offered the easiest most succinct resolution in my situation
this should work:  systool -c fc_host -v  
with awk:  ps -af -u sas | awk 'begin {rs=" "}; /-dapp.name/' 
there is standard output (1), error output (2), and input (0)
on my system ps finds this:  /usr/bin/xorg -br :0 vt7 -nolisten tcp -auth /var/lib/xdm/authdir/authfiles/a:0-wejjac   the display manager starts x with the auth file to use as parameter
to regenerate them you'd need to re-install the applications..
assuming your program runs with the current user (no setuid, etc), you can use strace to get this information, e.g.,  strace -o foo.out ~/apps/simutrans/simutrans   and look in the output file for open calls. 
solution found on procmail  default=/var/spool/mail/$logname/new orgmail=/var/spool/mail/$logname maildir=/var/spool/mail/$logname deliver="/usr/lib/dovecot/deliver -d $logname" logfile=/root/procmail.log verbose=yes  # deliver spam to spam folder  :0 * ^x-spam-status: yes .spam/   and on dovecot  inbox = yes   #mailbox name {     # auto=create will automatically create this mailbox.     # auto=subscribe will both create and subscribe to the mailbox.     #auto = no      # space separated list of imap special-use attributes as specified by     # rfc 6154: \all \archive \drafts \flagged \junk \sent \trash     #special_use =   #}    # these mailboxes are widely used and could perhaps be created automatically:   mailbox drafts {     special_use = \drafts     auto = create   }   mailbox spam {     special_use = \junk     auto = subscribe   }   mailbox trash {     special_use = \trash     auto = create   }  
i was reading my question and found the answer in it
what i could not see is that screen1 was actually a clone of screen0
i think you can do this with pulseaudio
similar to what jw013 suggested in the comments with separate compression/decompression steps, i.e
find -maxdepth 1 -type d | while read -r dir; do printf "%s:\t" "$dir"; find "$dir" -type f | wc -l; done   thanks to gilles and xenoterracide for safety/compatability fixes.  the first part: find -maxdepth 1 -type d will return a list of all directories in the current working directory
looking through the man pages  if you look at the man page for mount.cifs which is what will be used to mount any shares listed in /etc/fstab there is a note that mentions noexec.  excerpt - mount.cifs man page     this command may be used only by root, unless installed setuid, in   which case the noeexec and nosuid mount flags are enabled
one way:  cat -s file | sed 's/^$/---/'   from man page of cat :     -s, --squeeze-blank           never more than one single blank line   once cat has squeezed the blank lines, sed replaces the blank with with a --- 
it's not related to the find command itself, it's a feature of the shell called history expansion
upon reflection, i think you are approaching this the wrong way.  w3m is used to render html messages in mutt; but that doesn't mean that you will easily be able to open links in the rendered html (moving your cursor to the link, for example, is only possible with the mouse).  instead, you could either use a perl script like extracturl1 or, if your terminal supports it, something like urxvt-perls.   1
this is very similar to @goldilock's approach but, imo, simpler and can deal with empty lines in the file and replaces | with a line break :  #!/usr/bin/env perl my ($time, $text, $next_time, $next_text); my ($c,$i)=0; while (&lt;&gt;) {     ## skip bad lines     next unless /^\s*([:\d]+)\s*:(.+)/;     ## if this is the first line
the zombie isn't waiting for its child
   was the idea behind the controller to be able to control devices from a different manufacturers with the same driver?    no
on linux, you'd do something like   sudo sysctl -w net.ipv4.ip_local_port_range="60000 61000"    instruction for changing ephemeral port range on other unices can be found for example at http://www.ncftp.com/ncftpd/doc/misc/ephemeral_ports.html 
that is possibly considered as a bug, but for manjaro perhaps it is a feature, making manjaro the prefered boot os for your system
(2) you may configure sshd to chroot() for this user
today, nobody tells the cd-rom to play a cd but rather to read a cd and to send the read data to the audio interface of the computer.  when a cd is actually read, you cannot send/execute another scsi command to the same drive, so there is no way to tell what you like.  what you can to is to call cdrecord -minfo to get the state of the currently inserted medium and to call cdrecord -toc to get the table of content. 
afaik, editing /boot.cfg is the preferred method
in place of   inp="${inp%/*}"   try:   inp="${inp%%/*}"   both of these shell substitution are examples of suffix removal
you could create a file with your "new prompt" tweaks and then source it from the command line.   vim new_prompt.bash  source ./new_prompt.bash   the new prompt will only be active in that shell
running reboot is a perfectly safe way of doing it
most of these answers are far too late to the game, as the * usage was used on usenet and elsewhere to refer to the multiplicity of unixoid systems
torify as a nice frontend for torsocks which makes life far easier
works fine for me (in ~amd64 gentoo), however try removing the udev useflag from lvm2 as a workaround, as udev is not important at initramfs stage
suppose that the new path that we want to add is:  new=/opt/bin   then, using any posix shell, we can test to see if new is already in the path and add it if it isn't:  case ":${path:=$new}:" in     *:$new:*)  ;;     *) path="$new:$path"  ;; esac   note the use of colons
strace helped, the bad device was the /dev/cdrom 
 virtually all shell arrays (bourne, csh, tcsh, fish, rc, es, yash) start at 1
there is no need at-all to blank your usb device. just use   dd    command, and it will overwrite everything (it needs) to be a boot-able usb linux distro 
sudo apt-get install automake/rosa dh-python/rosa libssl1.0.2:amd64/rosa openssl/rosa   should do the trick; it will prompt you to verify you really do want to downgrade. 
cp --reflink=always is almost certainly working correctly
as per the instruction manual, you linked above, you want to skip the optional dependencies, so we skip:  sudo apt-get install libqt4-opengl python-opengl python-qt4 python-qt4-gl python-numpy python-scipy wget -o - http://www.pyqtgraph.org/downloads/pyqtgraph-0.9.8.tar.gz | tar -zxv &amp;&amp; cd pyqtgraph-0.9.8 &amp;&amp; sudo pyth     and then during the build/compile phase we skip make deps
man sort suggests that you can use sort --key=1.12 to get the desired effect. 
here are the steps you need to add a new custom resolution and apply it
to see what's happening change the rsync command to an echo command first
you can add a rate limiting tool to your pipeline.  for example there is pv which has a rate-limiting option:   -l rate, --rate-limit rate       limit the transfer to a maximum of rate bytes per second
yes, rm *.xvg will only delete the files with the specified extension in your current directory.  a good way to make sure you are indeed in the directory you want delete your files is to use the pwd command which will display your current directory and then do an ls to verify you find the files you are expecting.  if you are bit apprehensive about issuing the rm command, there are 2 things you can do:   type ls *.xvg to see a list of what files would be affected by this command. unless you have a lot of files, you could always also use the -i command line switch for rm (also exists for cp and mv)
the file /etc/bashrc is marked as %config(noreplace) file in the setup rpm
you can call shell scripts from c application using system() function:     system()  executes  a  command specified in command by calling /bin/sh   -c command, and returns after the command has been completed
i was about to answer this question with a link to the release man page and go into great detail about how to build packages and include them in releases etc.  but then i realized that your question is mixing up which packages are installed after the install
you can use the entries in /proc to truncate such files.  # ls -l /proc/4315/fd   that will show all the files opened by process 4315
i believe mint is running networkmanager, and that's what connects your wireless network.  edit your wireless connection profile, there's an option called automatically connection, disable that. 
i have a few ways to do this, easy ones first:  making the install prefix flexible is hard - i would just make the install prefix to your home directory, or somewhere that you can access on any of the machines, and use  make install destdir=/path/to/place/where/binaries/should/be/installed   to install them to somewhere other than the prefix.  i personally have my binaries in $home/bin, so my commands would look like this:  ./configure --prefix=$home   some programs (i know ffmpeg is one) can be build with all libraries compiled into the program, avoiding shared libraries
shell is the oldest of these 3 choices
there is xautolock which can start a script after some idle time.  it is used like this  xautolock -time "$minutes" -locker "$script"   it is supposed to be used with xlock which can lock the screen and starts a screensaver.  since you need to deactivate the screen when the timeout is reached and reactivate it when you move the mouse or press any key
unix system v is from 1983
since you use the two [[ ]] test form, this is bash (or ksh), so :  #!/bin/bash  glib=$(ldd --version | awk '/ldd/{print $nf}')  if [[ $glib == 2.17 ]] &amp;&amp; systemctl | grep -q '\.mount'; then   echo "i have to execute certain specific stuff to glib ver 2.17" fi   note   use $( ) not `` in modern shell place spaces around [[ and ]]  your regex try is better written with a grep  
i use version 6.0.472.63 and i found change font and language settings under customize and control chromium --> options --> under the hood. 
it serves primarily as making sure the posix tool-chest is available both inside and outside a shell.  also, the cd command changes directories but has other side effects: it returns an exit status that helps determine whether you're able to chdir() to that directory or not, and outputs a useful error message explaining why you can't chdir() when you can't.  example:  dirs_i_am_able_to_cd_into=$(find 
 $ps2  each time the user enters a \newline prior to completing a command line in an interactive shell, the value of this variable shall be subjected to parameter expansion and written to standard error
keep the dotfiles as portable as possible and avoid os dependent settings or switches that require a particular version of a tool, e.g
with input:  &lt;abc&gt;def&lt; &lt;firstword&gt;anotherword&lt;/firstword&gt; &lt;ghi&gt;klm&lt;   use:  sed 's/&lt;\([^&gt;]*\)&gt;\(.*\)&lt;$/&lt;\1&gt;\2&lt;\/\1&gt;/' input   output:  &lt;abc&gt;def&lt;/abc&gt; &lt;firstword&gt;anotherword&lt;/firstword&gt; &lt;ghi&gt;klm&lt;/ghi&gt;   the sed line only affects lines ending in &lt; (because of the &lt;$) and catches the patterns between the first &lt;&gt; pair and between '>&lt;' and pastes everything back in duplicating the first pair at the end (plus a closing '>') 
lscpu, in util-linux, describes the cache layout without requiring root:  [...] l1d cache:             32k l1i cache:             32k l2 cache:              256k l3 cache:              8192k   the files in /sys/devices/system/cpu/cpu*/cache/ should contain all the information you're looking for, including associativity, and are readable without being root, but it's a little harder to parse:  grep 
in such circumstances, script is very handy: it runs a shell, recording all the output
the answer i found was this from manjaro wiki     these releases are more accurately new snapshots of the manjaro system
you forgot the name of the class to run
here's a starting point; it assumes that the indexes only go up to 9; you'll have to extend it if that's not true.  #!/bin/bash  index=0 lastseq= for file in *.jpg do   base=$(basename "$file" .jpg)   lastchar=${base: -1:1}   if [[ $lastchar =~ [[:digit:]] ]]   then     index=$((index + 1))     newname=$(printf "acdfff%03d" $index)     lastseq=$lastchar   else     seclast=${base: -2:1}     if [[ $seclast != $lastseq ]]     then       index=$((index + 1))       lastseq=$seclast     fi     newname=$(printf "acdfff%03d%s" $index $lastchar)   fi   echo mv "$file" "${newname}.png" done  
for colour, you need to specify the actual esc character (not the escaped form \e).
the only reliable solution i found was the brute force method outlined in the question
there is not really a more specific term
it depends
idea #1 - hidden os  as an alternative method you could make use of truecrypt's "hidden operating system"
sudo fuser /dev/dm-31 /dev/dm-31:          24799 ps -fp 24799 vbox     24799     1  2 may18 ?        04:37:39 /usr/lib/virtualbox/vboxheadle.....   or when using lvm2 (on ubuntu, sles may vary in detail):  ls -l /dev/mapper | grep dm-1$ lrwxrwxrwx 1 root root       7 may 11 19:01 vg_diablo-var -&gt; ../dm-1   you may also want to check man dmsetup eg
have you tried to use dpkg --get-selections &gt;packages? if you want to exclude some packages, you can edit the output file packages
this works:  command | tee -a "$log_file"   tee saves input to a file (use -a to append rather than overwrite), and copies the input to standard output as well. 
you could use fping output as nmap target list:  fping -aqg ip/24 | xargs nmap -sn --traceroute     if your problem is that some gateway in your network is giving fake arp responses (generating false positives), you can use -sn -pe to fix that:  nmap -sn -pe --traceroute ip/24   that way, nmap will exclusively show a host (and make a traceroute) if the host reply the icmp request (ping). 
you can add all columns but the id (idle), wa (io wait) and the st (stolen) ones to get the cpu load.  you'll find most columns meaning in the top manual page:         us, user    : time running un-niced user processes        sy, system  : time running kernel processes        ni, nice    : time running niced user processes        wa, io-wait : time waiting for i/o completion        hi : time spent servicing hardware interrupts        si : time spent servicing software interrupts        st : time stolen from this vm by the hypervisor  
so you are ready for trying an alternative to openssh's client?  good for you
sure:   function '$'; eval $argv; end   then  myprompt$ $ echo hello world hello world  
you could do something like:  screen_send_to_copy_mode() (   tmp=$(mktemp) || exit   cat &gt; "$tmp" &amp;&amp;     screen -x readbuf "$tmp"   ret=$?   (sleep 2; rm -f -- "$tmp")&amp;   exit "$ret" )  echo 'this is an example' | screen_send_to_copy_mode      
   when a process exits, all its children also die (unless you use nohup in which case they get back to init).   this is wrong
$ less -j 4 file   that will put the pattern you searched for on line 4 of the terminal.  to save typing this every time, you can put less=j4 into your environment. 
no, setting the bit would have no effect during boot
well, there are a few things you could try
a modern computer contains hundreds of parts that can be turned on and off or clocked faster or slower independently
directories on ext4 file systems generally have at least 2 links
%cpu should be low during a copy
yes, m-. is bound to yank-last-arg
it looks that that isn't an option here (fedora 19, shadow-utils-4.1.5.1-5.fc19)
there is no real need to disable "extra" ttys as under systemd gettys are generated on demand: see man  systemd-getty-generator for details
you should fix /etc/initramfs/post-update.d/flash-kernel so that it successfully flashes your kernel &amp; initrd
first, you don't want to use bjam, even though the boost project uses it, and seemingly recommends it
grep will return success if it finds at least one instance of the pattern and failure if it does not
use the -d switch:  ls -d *ro*   ..... 
you can simply place code in a separate file and include it with  dofile("somefile.lua")   note: the working directory is $home
you could do something along these lines:  file=/some/file newtext='sol { mass = 42, start = 9.2 }' tac -- "$file" |    newtext=$newtext awk -v size="$(wc -c &lt; "$file")" '     $1 ~ /^[^#]/ {       system("dd bs=1 seek=" size - length(footer) " conv=notrunc if=/dev/null")       printf "%s\n%s", environ["newtext"], footer       exit     }     {footer=$0 "\n" footer}' 1&lt;&gt; "$file"   that overwrites the file in place and only stores the footer in memory
use ctrl-a a, or change screen's escape keystroke (option -e). 
the problem is you are using p as a modifier which prints the "pattern space", i.e
disabling the root password isn't really useful
this setup was performed with ibm cognos business intelligence server 10.1.0 32-bit, running on debian wheezy stable for i686 on an virtualbox virtual machine; so far i haven't been able to reproduce it on amd64 or other distros
use the --trust-server-names option:     --trust-server-names: if this is set to on, on a redirect the last component of the redirection url will be used as the local file name
-g sets the initial, or primary, group
you need to use \zs as delimiter to split string into individual characters:  :echo split("hello", '\zs') ['h', 'e', 'l', 'l', 'o']  
look at the ls -l /etc/localtime to see at what time the change happened
the /etc/motd file is data (cannot contain a script, such as "echo -e"), and is presented to all logins irregardless of their actual terminal type
this will not work as it unlikely that your hosts mapped in filesystem (i.e
you say integers, but i suspect you mean positive numbers
boost is a mostly header-only library, so there is no library to link with (most of the time).  as for the headers, ubuntu place them in /usr/include/, which is one of the include paths gcc use by default
well, this is a hack, but anyway:  let's use file3 and file2 and resolve the groups to a intermediate file resolved with something like:  awk '     fnr == nr {         group = $1         $1 = ""         groups[group] = $0     }     fnr != nr {         for (i = 2; i &lt;= nf; i++) {             print $i" "groups[$1]         }     } ' &lt;(tail -n+2 file3) file2 &gt; resolved   to:  $ cat resolved rs009  1 3 3 3 rs103  1 3 3 3 rs591  3 3 2 3 rs112  3 3 2 3 rs004  3 3 2 3   and then use resolved to combine it with file1 with:  awk '     fnr == nr {         group = $1;         for (i = 2; i &lt;= nf; i++) {             groups[group][i] = $i         }     }     fnr != nr {         if ($1 in groups) {             group = $1         }         for (i = 2; i &lt;= nf; i++) {             if (groups[group][i] != 3) {                 $i = 0             }         }         print     }  ' resolved &lt;(tail -n+2 file1)   which produces:  rs009 0 t a a rs888 0 t t t rs103 0 c c c rs591 a a 0 a rs112 a a 0 a rs004 c c 0 c   utilizing column and adding back the header and we are fine. 
this is trivial to do with a little script
you can tell ps to sort its output
i changed the "auto channel" option to a fixed channel and the "channel width" option to 20 mhz in my ap and it solved my problem. 
you can use the command line switch -m to php to see what modules are installed.  $ php -m | head [php modules] bz2 calendar ctype curl date dbase dom exif fileinfo ...   you could also use php -i to get phpinfo(); output via the command line which would include this info as well.  references   extension_loaded - php documentation  
delete the file ~/.gnupg/random_seed
here is a step-by-step guide for what i did to make nvidia optimus work on kubuntu 15.10 64-bit
you can install just kde-runtime and kde-workspace packages. 
with pax as found on debian, suse, openbsd, netbsd at least:  find 
you're missing (at least) rpmbuild tool:  ./packages/redhat/ati-packager.sh: line 221: rpmbuild: command not found   this (according to centos wiki) should be in rpm-build package which can be installed by running yum install rpm-build. 
openssl crypt you password with an algorithm and a salt
your ctrl-r is being intercepted by the kernel-based terminal cookied line processing engine.  while sleep is running, the terminal is in cooked mode, which means that the kernel-based tty line editor is working
thankfully, there is no linux equivalent of the windows registry
one of the fundamental differences between windows cmd and posix shells is who is responsible for wildcard expansions
this line is printed by the shell
running   ps ax | grep ntpd   and checking that the output contains something like   6497   ?     ss    0:04    /usr/sbin/ntpd ...   will confirm that ntpd is running
pass the user name through the -o user option, or through the equivalent user directive in the client configuration file (~/.ssh/config).  sftp -o port:8777 -o user=user@domain.com domain.com   this applies to ssh, scp and sshfs as well
the problem was solved by adding a gateway to enp8s0:  [match] name=enp8s0  [network] address=10.10.26.160/25 gateway=10.10.26.129  
a long time ago, find … -exec … used {} as the string to be replaced by the name of the matched file
the compiler flags used are a function of   the debian/rules file, the package's build files (since the upstream author may specify flags there too), the build system used (dh, cdbs etc.), the default compiler settings.   to see the flags used you effectively need to at least compile the package:  debian/rules build   trying things like  debian/rules -n   generally won't take you very far; for instance on a dh-based package it will just say  dh build   or something similar; asking dh to show what that would do (with --no-act) will produce  dh_testdir dh_auto_configure dh_auto_build   and so on.  there is no fool-proof, easy-to-explain way to determine the build flags by reading debian/rules; you can get some idea by looking for flags set there, and also (where appropriate) by looking for options for dpkg-buildflags (such as deb_build_maint_options) and running that
your kernel is updated, but you need to reboot into the new version
the difficulty here is that when tee is invoked in the pipeline, its stdout has already been aimed at perl's stdin
grep by default searches standard input if no files are given:     grep searches the named input files (or standard input if no files are   named, or if a single hyphen-minus (-) is given as file name) for   lines containing a match to the given pattern
if i understand correctly, you want to move files from the current directory and its subdirectories recursively to another directory, but only if the file command reports them as “microsoft word” files
looking at the kbuild script it does appear to be os x &amp; brew specific.   https://github.com/kevmoo/kbuild/blob/master/bin/kbuild   excerpt from script  ... brew_prefix = subprocess.check_output(['brew', '--prefix']).strip() compiler_search_path = path.join(brew_prefix, 'cellar/closure-compiler', '*', 'libexec/build/compiler.jar') compilers = glob.glob(compiler_search_path) ...   the homebrew directory on github would seem to lead credence to this too:     if you'd like to install kbuild via homebrew:      brew install https://raw.github.com/kevmoo/homebrew-kevmoo/master/kbuild.rb      or      brew tap brew tap kevmoo/kevmoo brew install kbuild  
you can change them if you tell sed to take the m the begins the line with ^m.  sed -i "s/^m/mt/g" filename   explanation:   the -i will instruct sed to replace the entry in the file
you could sum the usage columns with awk:  ps --no-headers -u $user -o pcpu,rss | awk '{cpu += $1; rss += $2} end {print cpu, rss}'   you might also be interested in the free command for memory usage:  $ free              total       used       free     shared    buffers     cached mem:       2055480    1806596     248884          0      14016     346276 -/+ buffers/cache:    1446304     609176 swap:      2097148     132980    1964168   the output is in kilobytes (use free -m for megabytes)
i think it is not possible
try detaching it first with screen -d
you could use sed to select a single line, for example line 12:  ls | sed -n 12p   option -n asks sed not to print every line (which is what it normally does), and 12p asks to print the pattern space when the address is 12. 
if you want to the isos, you can download them using torrent:   centos 4.7 i386 centos 4.7 x86_64   you can always find older versions on http://vault.centos.org if you need to. 
one method is to use cups and the pdf psuedo-printer to "print" the text to a pdf file
you can use graphical tools to achieve this, such as gparted
those files you removed may actually still be opened by another process
answer  perl -0777 -p -i -e 's/,(\n*)\z/\1/m' *.txt   will remove the last ',' in all files ending in .txt, if the ',' is followed only by 0-or-more newline characters then the end of the file.  from your example:  reedm@www:~/tmp $ cat &gt; test.txt blah blah blah, blah blah blah, blah blah blah,   reedm@www:~/tmp $ perl -0777 -p -i -e 's/,(\n*)\z/\1/m' *.txt reedm@www:~/tmp $ cat test.txt blah blah blah, blah blah blah, blah blah blah   reedm@www:~/tmp $    wat?  perl is an esoteric beast at the best of times, and perl one-liners can be particularly cryptic.  the -e flag allows us to pass a perl program on the command line
you sure you need the very last? couldn't be backports?  it may be more easier just to install backports instead building from source
there's no way to tell once the output has already been printed
enter single user mode, move to free up the /home mount point  mount --move /home /mnt/home, then move the files over:  mv /mnt/home /home   check with an ls -ld /, tree -d /home or something that it looks ok (you don't want to end up with /home/home or something like that)  umount /mnt/home, then lvremove /dev/mapper/fedora_dhcppc4-home, and finally lvextend /dev/mapper/fedora_dhcppc4-root with as many extents as were in your fedora_dhcppc4-home lv (-l flag)
you can double check if a key is already imported using rpm -qi gpg-pubkey-&lt;version&gt;-&lt;release&gt;
the xdg-mime command is used to query or set file associations.  jinx:735 z$ xdg-mime query default application/pdf   evince.desktop  
on debian and other systems that use pam (which is most of them nowadays), you can set environment variables (including path) in /etc/environment
 double checking the configuration  this is the first thing you want to make sure is correct
you could try like this:  awk 'nr==1{h=$0; next} !seen[$3]++{f="file_"filename"_"$3".txt";print h &gt; f}  {print &gt;&gt; f}' infile   the above saves the header in a variable h (nr==1{h=$0; next}) then, if $3 not seen (!seen[$3]++ i.e
you can use something like  $ last | grep -e -c 'user1|user2'   the -e allows to leave out the \ character that you would otherwise need before the |.  if you have many user names listed in a file, one per line, you can read them from the file directly:  $ last | grep -f -c -f userlist.txt   the -f means the lines in the files are strings that should match as they are, not regular expressions. 
from version 217 onwards, is possible to do that using:  tag-="uaccess"   for older versions, sadly it isn't
does your laptop normally boot to gnome, and when it came back up after being forced off, did it come back to gnome? assuming so, you either got there by a crash, or by inadvertantly switching virtual terminals (vts)
i'd take a look at using this package, vnstat which purports to do what you want using the same data that you're looking at from ifconfig.   http://humdi.net/vnstat/   excerpt of features        quick and simple to install and get running   gathered statistics persists through system reboots   can monitor multiple interfaces at the same time    several output options      summary, hourly, daily, monthly, weekly, top 10 days   optional png image output (using libgd)      months can be configured to follow billing period   light, minimal resource usage   same low cpu usage regardless of traffic   can be used without root permissions   online color configuration editor     
make install simply copies the kernel image to the /boot directory
i figured it out
the only place i've seen this info is in virt-manager and in the vm's xml file when you dump them
i am not familiar with sfdisk, but you could accomplish the same thing, partition table and mbr back up using dd.  this was in my notes and i am not the author...  backing up the mbr  the mbr is stored in the the first 512 bytes of the disk
the normal way to access a filesystem at an offset on a disk is with a partition
what kinds of danger do you expect? data loss, of course, but how do you expect that data loss to happen? this immediately rules out several strategies
this is more of a job for perl or python, but you can do it with pure bash
edit based on updated question:  to avoid being asked about removing files, simply add the -f ("force") option:  rm -f /path/to/file   this has one side effect you should be aware of: if any of the given paths do not exist, it will not report this, and it will return successfully:  $ rm -f /nonexistent/path $ echo $? 0     original answer:  here's one simple solution:  yes "$string" | head -n $number | tr $'\n' $'\r'   yes repeats any string you give it infinitely, separated by newlines
terminal parameters are stored as $lines and $columns variables
you need to enable 'debuginfo' repository for rhel and install kernel-debuginfo rpm to get required vmlinux  # rpm -qf /usr/lib/debug/lib/modules/3.10.0-229.14.1.el7.x86_64/vmlinux  kernel-debuginfo-3.10.0-229.14.1.el7.x86_64      information on how to enable this repo could be found at   https://access.redhat.com/solutions/9907  
found this on github : https://github.com/volatilityfoundation/volatility  you could try :  $linux_yarascan   or :   $linux_volshell   which should open a shell in the linux memory image. 
for disk i/o trending there are a few options
to remove an environment variable, run  unset all_proxy   note that an environment variable only takes effect in a program and the program it launches
okay, if i get you right dd is what you need (comes with os x)
maybe these schema can clarify the situation. this is the usual setting:                                  terminal  (/dev/ttyx or /dev/pts/x)                                 device                                    |                     (screen)&lt;--[&lt;output]----x-------(stdout) process1         terminal  (keyboard)---[input &gt;]---o-\-----&gt;(stdin)                                             \ \ (hardware console or                         \ `----(stdout) process2  virtual console or terminal                  `----&gt;(stdin)  emulators like xterm, …)    and there is no way to plug some new process3 like this:                                terminal                               device                                  |              (screen)&lt;---o---[&lt;output]--x------(stdout) process1   terminal (keyboard)---/-x--[input &gt;]-o-\----&gt;(stdin)                        | /              \ \                        | |               \ `---(stdout) process2                        | |                `---&gt;(stdin)                        | |                        \ `---------------------(stdout) process3                         `---------------------&gt;(stdin)    what screen (and others) does is allocating some pseudo terminal device (like xterm does) and redirect it to one or more "real" terminals (physical, virtual, or emulated):                terminal                   pseudo              devices              ,--&gt; terminal (/dev/pts/x)                 |         _______/      device terminal &lt;--[&lt;output]--- |       |        |  1       ---[input &gt;]--&gt; |screen | &lt;--[&lt;output]---x-----(stdout) process1                          |process| ---[input &gt;]--o-\---&gt;(stdin) terminal &lt;--[&lt;output]--- |       |                \ \  2       ---[input &gt;]--&gt; |_______|                 \ `--(stdout) process2                                                     `--&gt;(stdin)    using screen -x you can attach one more terminal, xterm, whatever (say terminal 3) to the screen session.  hope this helps! 
you could use find, provided it's available:  $ find "/mac1/2014-08-31-173253/macintosh hd" -wholename "*/users/me/*.txt" -or -wholename "*/users/me/*.csv"   this will search /mac1/2014-08-31-173253/macintosh hd for files containing the pattern */users/me/*.(txt|csv) in their paths. 
if you don't have to use the loop option to mount a regular file, it is because mount is detecting this and activating it for you automatically
try:  wget -r -np -k -p http://www.site.com/dir/page.html   the args (see man wget) are:   r recurse into links, retrieving those pages too (this has a default max depth of 5, can be set with -l). np never enter a parent directory (i.e., don't follow a "home" link and mirror the whole site; this will prevent going above ccc in your example). k convert links relative to local copy. p get page-requisites like stylesheets (this is an exception to the np rule).   if i remember correctly, wget will create a directory named after the domain and put everything in there, but just in case try it from an empty pwd. 
besides sudo the only other method i'm aware of is to use setuid
unless it's write protected with a hardware switch, that shouldn't matter
you can accoplish that with custom xkb map
you need to add the  rpm fusion  repositories to have "free world" package, like get_iplayer
the message comes from src/core/manager.c in the systemd sources
not sure why you chose vsftpd, as the documentation is notoriously lacking/distributed
solution:  sudo apt-get install python-qt4 python-pip sudo pip install https://download.electrum.org/2.6.4/electrum-2.6.4.tar.gz#md5=4840a883e60083d055064d5614c3353e  
you can use ps -c to only display process information for a particular command name.  e.g.  ps -c opera   you can then use other ps options to extract just the data you are looking for
this is happening because cut is outputting null characters in the output
there's a workaround by using the grep regex syntax for matching the empty string at the beginning and end of a word!  # grep regex syntax for matching words only man grep | less -p '\&lt;'  # posix 1003.2 regular expression syntax for matching words only # should work for sed, ed, ... man re_format | less -p '\[\[:&lt;:\]\]'  echo 'foo bar baz' | egrep -o '\&lt;baz\&gt;'  echo 'foo bar baz' | sed -n '/.*[[:&lt;:]]\(baz\)[[:&gt;:]].*/s//\1/p'   if you insist on using grep's -w flag, try the precompiled rudix 2010 grep binary (grep-2.5.4-1.dmg).  http://rudix.org/packages-ghi.html#grep 
each package that compiles with the debian policy contains a changelog file in /usr/share/doc/package-name/changelog.debian
i understand your concern but the answer is "no" there is not such thing. the usual method is to ask the os the user's home path, or get the $home variable
unpack .tbz with tar xf to empty directory, edit +install and pack it again with tar cjf ../new_package.tbz *
i gave up consolekit and migrated to systemd
i normally use this style of command to run grep over a number of files:  find / -xdev -type f -print0 | xargs -0 grep -h "800x600"   what this actually does is make a list of every file on the system, and then for each file, execute grep with the given arguments and the name of each file.  the -xdev argument tells find that it must ignore other filesystems - this is good for avoiding special filesystems such as /proc
i don't know a thing about showoff, but i did use dzslides in a similar way
simply type sh to switch to an interactive bash shell..
in english, supersede means (from oed)     to take the place of (something set aside or abandoned); to succeed to the place occupied by; to serve, be adopted or accepted instead of
ssh doesn't let you specify a command precisely, as you have done, as a series of arguments to be passed to execvp on the remote host
i believe your simple algorithm would work, but you must realize the router would never know for sure whether the pc is actually awaken or not
looking through the official bug tracker it would appear that this features hasn't been implemented and there is no timeframe given for when it might get implemented, if ever!  kovid goyal (kovid) wrote on 2012-11-19: re: calibre bug 1080721     #1 the calibre viewer currently does not have support for highlighting
you can do that via system settings > keyboard (or gnome-control-center keyboard in terminal): go to typing and set modifiers-only switch to next source to caps lock    alternatively, set the corresponding xkb option (which is what the above does underneath) via gsettings or dconf: navigate to org > gnome > desktop > input-sources and add  grp:caps_toggle to your xkb-options:    note each option is enclosed in single quotes, options are separated by comma+space. 
that button locks/unlocks screen orientation on devices that can detect which way they are held - usually touchscreen devices - see screen orientation section on the gnome wiki touchscreen page: easy ability to temporarily disable and enable auto-rotation (rotation lock)
you will notice differences certainly
in order to specify automount options across any de you can specify this with udisks configuration: https://wiki.archlinux.org/index.php/udisks#udisks  something such as:  udisks --mount /dev/sda1 --mount-options options  autofs also works: https://wiki.archlinux.org/index.php/autofs 
from the dd(1) man page:     status=noxfer           suppress transfer statistics   thus:  dd if=boot1h of="/dev/r$temp1" status=noxfer   this still outputs the   0+1 records in 0+1 records out   garbage when dd exits, so redirecting to a data sink really is your only option. 
a single shortcut: m-backspace  alt + ←&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
the ftp program is for the insecure ftp protocol
sunday is 0, monday is 1, etc.  http://man7.org/linux/man-pages/man5/crontab.5.html     the time and date fields are:            field          allowed values           -----          --------------           ...           day of week    0-7 (0 or 7 is sunday, or use names)  
i posed this question to my mentor and he said to use grep, so i tried it out and i succeeded
netfilter encourages to use iptables-save command since it will provide you a detailed view of your built-in chains and those you've defined yourself
early versions of c didn't have unsigned integers
i usually use hdparm to benchmark my hdd's
yes
there is apache user instead of www-data in centos. 
you can achieve this by either splitting or freezing the spreadsheet
i have created a loop device for testing:  dd if=/dev/zero of=tmp.img bs=1m count=100 modprobe loop dd if=/dev/zero of=tmp.img bs=1m count=100 losetup /dev/loop0 tmp.img   and then:   # parted --script /dev/loop0 unit s mklabel msdos \    mkpart primary fat32 1 2048 mkpart primary fat32 2049 4096 print  warning: the resulting partition is not properly aligned for best performance.  warning: the resulting partition is not properly aligned for best performance.  model: loopback device (loopback)  disk /dev/loop0: 204800s  sector size (logical/physical): 512b/512b  partition table: msdos   number  start  end    size   type     file system  flags   1      1s     2048s  2048s  primary               lba, type=0c   2      2049s  4096s  2048s  primary               lba, type=0c   formatting  mkfs.vfat -f 32 /dev/sdb1  
thanks to brm's comment and reading the xrandr man page, i figured out what the issue was
ok i got this working mostly with help from the following instructions: http://code.google.com/p/modwsgi/wiki/installationonfreebsd  here's what i did (as root user):  reinstall apache  i already had apache22 installed from a binary package but apparently the package version is compiled without thread support and you need threads for mod_wsgi
make menuconfig and enable it as a module
i think you're looking for the vfs_recycle module to samba.   http://www.samba.org/samba/docs/man/manpages/vfs_recycle.8.html   in your smb.conf file for a given share:  [share]     path = /data/share     vfs objects = recycle     recycle:repository = .recycle     recycle:keeptree = yes     recycle:versions = yes  
as adduser script just calls passwd and there are no such strings as enter new password or enter new unix password in /usr/sbin/passwd binary but later string is found in /lib/security/pam_unix.so, i'd recommend checking /etc/nsswitch.conf and /etc/pam.d/* for something unusual related to passwords. 
dynamically combining the content of several directories is exactly what a union mount (or union filesystem) is about
if you don't use absolute path, apache assume that it's relative path to serverroot directive.  according to apache doc:     the errorlog directive sets the name of the file to which the server   will log any errors it encounters
the is controlled by the histcontrol variable
the first reason that comes to mind is that since that is an absolute link (it points to /data/git and not ../git), this will allow it to still work even if you move the directory later
you've got:  egrep..
@milne's answer works, but subprocess.call() gives you little feedback.  i prefer to use subprocess.check_output() so you can analyse what was printed to stdout:   import subprocess  res = subprocess.check_output(["sudo", "apt", "update"])  for line in res.splitlines():      # process the output line by line   check_output throws an error on on-zero exit of the invoked command  please note that this doesn't invoke bash or another shell if you don't specify the shell keyword argument to the function (the same is true for subprocess.call(), and you shouldn't if not necessary as it imposes a security hazard), it directly invokes the command.  if you find yourself doing a lot of (different) command invocations from python, you might want to look at plumbum
   description      the type utility shall indicate how each argument would be interpreted if   used as a command name.      (…)      the following exit values shall be returned:      0  successful completion.   &gt;0  an error occurred
you mean something like this (1 to 100)?  for i in {1..100}; do   find /home/ -name "${i}_*_*_*_*_*_*.nii" -exec cp '{}' /home/${i} \; done  
that is certainly not trivial task that can't be done in userspace
your yum repos were not configured correctly as el6 packages were showing up
if you are trying to delete a directory foo/bar/, the permissions of bar isn't the relevant factor
thanks to don_crissti for answering this for me.  the correct if block is below.  if [[ ! -a ~/.zkbd/$term-${${display:t}:-$vendor-$ostype} ]]; then     zkbd fi  
see the man page for the date command and look at the -d option:   % date -d '+1 day'  mon jul 15 21:51:06 pdt 2013  % date  sun jul 14 21:51:16 pdt 2013  %   i'd also suggest running:   info date   for more explicit information. 
to install centos you need   a virtual machine for try centos,on mac os you can try virtualbox or parallel. try directly on a pc,but will erase your current os or you can partition hard disk and get dual boot,or install on different internal or external hd(linux can run on usb devices,of course usb3,usb2 works but is really slow)   is impossible to run linux by click on dvd dmg/img! maybe in the future... 
it seems that i have solved my problem
nohup gedit &amp;&gt; /dev/null   is posix syntax and is the same as:  nohup gedit &amp; &gt; /dev/null   that is run nohup gedit in background and then do a &gt; /dev/null redirection without running a command.  nohup gedit &gt;&amp; /dev/null   is not posix syntax and is the csh way to redirect both stdout and stderr to /dev/null
to find out which app/program grabbed your key use the debug keysym xf86loggrabinfo
i find the filesystem hierarchy standard document invaluable when looking for this stuff.  there are a few options,   /tmp - 'non-permanent' temporary files /var/tmp - 'permanent' temporary files /var/cache - 'application' transient data files   it really depends on the kind of data you're storing. 
it's because wget is newely invoked for each url
while it's not clear from the documentation, running the example you will find that the order is indeed from left to right.  myrule_step1 myrule_step2 myrule  
it seems that you have a lot more files than normal expectation.  i don't know whether there is a solution to change the inode table size dynamically
the correct format is simply to use:  result=10#1$result  
by default, a linux filesystem reserves 5% of the space for root (the user) usage and maintenance
permitrootlogin no doesn't prevent root logins entirely, it only prevents root logins through ssh
you can use ${#var} to get the length of a variable $var:  if [ "${#filename}" -eq 5 ]; then    rename_file fi  
try this:   create a partition or raid array or logical volume..
if you can go with full kernel source tree, here are the steps i have followed in order to compile and install a driver on the source tree:  lets say you have the kernel sources extracted at /sources/linux-3.19   cd /sources/linux-3.19 make mrproper make menuconfig   here make sure to select your driver with "m" label
my first step would be to run strace on the process, best   strace -s 99 -ffp 12345   if your process id is 12345
it depends on what kind of signature you're talking about
 $ dpkg -s /sbin/init systemd-sysv: /sbin/init    your init system is systemd, not sysvinit
you should definitely try aufs, which is described as "an entirely re-designed and re-implemented unionfs"
i actually just figured it out: it does require an 800x600 white image to merge with, but that's fine.  convert ~/white.jpg ~/input.png  -resize 800x600 -gravity center -composite ~/output.jpg   if there's a general opinion that posting a question and then answering it myself is a waste of time, then i'm happy to delete the question. 
tilde expansion, parameter expansion, command substitution and arithmetic expansion are listed in the same step
from the command line:  emacsclient -a emacs file1.java file2.java file3.java file4.java   this opens the file in an existing emacs if there is one and you have started the server ((server-start) in your .emacs)
if you have a x server running and the display environment variable is set to :0, that tells applications to connect to the x server using a unix domain socket which is generally to be found on linux in /tmp/.x11-unix/x0 (though see below  about the abstract namespace on recent linux).  when you ssh to machine remotemachine, sshd on remotemachine sets display to localhost:10 (for instance), which this time means that x connections are do be done over tcp to port 6010 of machine localhost
i never ran it manually before, but install-info looks like what you want (if you guessed it has an info manual, you're right, info install-info — although there is a man page, too). 
got the answer from sparhawk:  kbuildsycoca4  
i discovered it !  the php uses iv and key variables as strings, and the openssl cli needs the hexadecimal version of the strings, without spaces and new line as i will show
yes, you can do this with the /sys filesystem.  /sys is a fake filesystem dynamically generated by the kernel &amp; kernel drivers. in this specific case you can go to /sys/block/sda and you will see a directory for each partition on the drive
in the linux kernel, each process is represented by a task_struct in a doubly-linked list, the head of which is init_task (pid 0, not pid 1)
i'm answering my own question since it hasn't gotten any answer and the solution suggested on the comments worked like a charm.  i solved this by enabling config_numa in my kernel configuration and rebuilding it
that should work: are you sure your .bash_aliases is read? (it's not a standard file, but it might be sourced by your ~/.bashrc
the problem is error ouput printed to stderr, so the sed command can't catch the input
the saved portion of each captured packet is defined by the snaplen option
using prename (perl renamer)  prename 'if(/(.+?)-(.+?)-(.*)/){mkdir $2; $_="$2/$_"}' *.jpg  
system accounts should already be locked, by setting their password hash to an invalid one (i see x and ! in my /etc/shadow)
first off, if the software is built for unix then it won't run on windows
most likely the enctypes your kerberos kdc has for your principal isn't something that kinit on your ubuntu system is set up to use
ony my linux systems, man 1 man mentions the manwidth environment variable, which, now that i look it up, is also specified in the freebsd man(1) manpage:  manwidth     if set to a numeric value, used as the width manpages should              be displayed
which is actually a bad way to do things like this, as it makes guesses about your environment based on $shell and the startup files (it thinks) that shell uses; not only does it sometimes guess wrong, but you can't generally tell it to behave differently
as discovered in chat, the solution is:  copy your .iso image to /var/lib/libvirt/images and run virt-install like so:  virt-install --name=public-centos7 --disk path=/home/publicvm/some.img,size=10 --graphics none --vcpus=2 --memory=2048 --location /var/lib/libvirt/images/centos-7-x86_64-dvd-1503-01.iso --network bridge=br0 --os-type=linux --os-variant=rhel7.0 --extra-args console=ttys0   if there is a failed previous attempt still running, you need to delete and undefine it first using virsh:  virsh destroy public-centos7 virsh undefine public-centos7  
sockets are a kernel api for communication
your sendmail may be configured in "client only" mode (internal and send out) without accepting emails from outside
you didn't specify any file: you have to add the file (with path) after the colon:  a$ scp &lt;myuserid&gt;@hostb:/absolutepath/file .   or  a$ scp &lt;myuserid&gt;@hostb:relativepath/file .   for a path relative to your home directory.  if you don't specify a different user (i.e., the user on a and b are the same) you don't need the @  a$ scp hostb:/path/file .  
there is an option which allows to import pool with a broken device
it's good to check the man page
you might not want to have the ability for some random person to walk up to the keyboard and reset the machine, or even worse, start printing registers, syslog or all tasks to the console, all without logging in
using udev:  you can get useful information querying udev (on systems that use it - almost all desktop-type linuxes for sure)
method #1 - from networkmanager's applet  try disabling the wireless networking under the network applet that's accessible from under the icons in the upper right of your desktop.  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  note: the networking applet's icon looks like a triangle wedge
xdmcp is designed for this
yes, the ;:  do_some_task ; say 'done'  
if you do not care at all for the data stored on that machine you can perfectly insert a bootable install cd and install into that debian partition, which will probably get formated before the new linux is installed
as far as i know, there is no gui application allowing that for gnome 3
there's no difference at all
what you want isn't possible
   when a usb mouse is connected how does the system tell it's a mouse? does it send some signal?   yes, it sends a usb descriptor, from which the host can tell that it is a mouse and how it expects the host to start reading input from it.     how do i take the input x and y coordinates from the board and tell the system to control the mouse using them?   making it a proper usb device is a possible solution, which might even get you extra credit
it only gets simpler if you know that you haven't changed some of these default chains
you can use gpasswd:  # gpasswd -d user group   then the new group config will be assigned at the next login, at least on debian
ifconfig  if i understand what you're asking for, you'd like a one line command that will take the output from ifconfig and return the next eth:xx device to use.  so if we have eth0:0, eth0:1, and eth0:2 in use, the command should return 3?  example  a command such as this one should do what you want.  $ if (ifconfig | grep -q "^eth"); then \       echo $(($(ifconfig | grep -po "(?&lt;=^eth[0-9]:)\d+" | sort -n | tail -1) + 1)); \       else echo 0;fi   so if we have one ethernet device:  $ ifconfig | grep eth eth0:0      link encap:ethernet  hwaddr f0:de:f1:2f:7d:4e     our command would return a 1:  $ if (ifconfig | grep -q "^eth"); then echo $(($(ifconfig | grep -po "(?&lt;=^eth[0-9]:)\d+" | sort -n | tail -1) + 1)); else echo 0;fi 1   if we have no ethernet devices, then we'll return a 0:  $ if (ifconfig | grep -q "^eth"); then echo $(($(ifconfig | grep -po "(?&lt;=^eth[0-9]:)\d+" | sort -n | tail -1) + 1)); else echo 0;fi 0   details  ok it would appear there is a lot going on here but it's pretty straightforward.   if statement - initially we need to know if there is any ethernet devices, so we run ifconfig and grep the output looking for one
when i installed sl in my ubuntu box (apt-get install sl) i got the binary /usr/games/sl-h too
looks like scrot is able to do it, tested with:  xinit thunar -- :128 display=:128 scrot   gave me a correct screenshot.  (but unfortunately, scrot has been unmaintained for quite a while) 
you could test out if image based pdf's are polluted as well
works ok for me when looking at a file that's being appended to but not when input comes from a pipe (using the f command - control-c works fine then).  see discussion at follow a pipe using less? - this is a known bug/shortcoming in less. 
you can add newline with \n, eg the substitute s/a/a\nb/ will insert a newline followed by b after an a
use unattended-upgrades package  the following is excerpted from the ubuntu documentation, but last time i checked the same thing worked with debian.   install the package with sudo apt-get install unattended-upgrades. edit /etc/apt/apt.conf.d/50unattended-upgrades. edit /etc/apt/apt.conf.d/10periodic.   there are a lot of options, but the steps above (and the documentation links) should definitely get you started.  disabling unattended upgrades  if you're trying to disable (rather than enable) unattended upgrades, you'd probably want to remove the package and purge the listed files
what i've managed to find out
this processor can run 64 bit versions (i compared your cpu flags with mine that is running 64 bit, and none of the differences are important features).  you can make sure for yourself by burning an installation cd of a 64bit version of your os (or make a usb stick) and boot that
 backup reformat restore   cryptsetup luksremovekey would only remove an encryption key if you had more than one
with sed:  sed 's/status/\n&amp;/g' file  
i don't use multitail, but looking to your regular expressions, you probably mean this:  colorscheme:my-color cs_re:red:^\[e.* cs_re:yellow:^\[w.* cs_re:magenta:^\[d.* cs_re:green,,bold:all session\(s\) filled for.*   
hdparm -y /dev/sdx should do that. 
use  for i in *.dat ; do dot -tpdf "$i" -o "$(basename "$i" dot)pdf" ; done   edit: correct handling of filenames with whitespaces. 
a hardlink is by definition a link to an inode
a trivial search for $( in the shell man page gives the answer.  as $name causes parameter expansion $(command) causes command substitution i.e
it looks like bbedit is some kind of paid osx editor
you can use sed:  sed -i 's/^/your_string /' your_file   thanks to stephane and marco's comments, note that the -i option isn't posix
a solution:  the problem is that this serial port is non-plugnplay, so the kernel does not know which device was plugged in
open ~/.config/terminal/terminalrc change the line with miscdefaultgeometry, to (for example): miscdefaultgeometry=x*y*z to your default size 
 make sure you have some temp directory where you write your output, because otherwise you cannot run the command on *.rb twice without getting blob_processed_processed.rb files
copied from frostshutz comment:     the initrd.gz (initramfs) contains the busybox userland and debian scripts written to that purpose
   is there a smart/secure/easy way to make these changes temporary for specific process?    environment variables such as $java_home are inherited, not global to the system
see how does awk &#39;!a[$0]++&#39; work?  basically use a=!a this will negate a turning 0 to 1 and 1 to 0.  you can test with  ls | awk '{a=!a; if ( a ) printf "good %s\n",$0 ; else printf "bad\n";}'  
in general, there's no reason why you shouldn't be able to delete the ubuntu partition or install elementary os on top of it.  in the vast preponderance of cases, linux distros attempt to detect all available os installations (including buggy, obsolete products from redmond, wa), construct a boot menu based on the detected installations, and then install grub to the mbr of the boot drive
you could make use of the builtin compgen:    compgen: compgen [-abcdefgjksuv] [-o option]  [-a action] [-g globpat] [-w wordlist]  [-f function] [-c command] [-x filterpat] [-p prefix] [-s suffix] [word]      display possible completions depending on the options.      intended to be used from within a shell function generating possible     completions
python is required by many of the linux distributions
one solution using perl:  content of script.pl:  use warnings; use strict;  ## acept one argumnet, the input file. @argv == 1 or die qq[usage: perl $0 input-file\n];  while ( &lt;&gt; ) {         ## remove last '\n' char.         chomp;          ## split line with string 'asdfasdf22'         my @f = split /(asdfasdf22)/;          ## print line but print first 49 chars plus a space of the special string.         printf qq[%s%-50s%s\n],                 join( qq[], @f[0,1] ),                 substr( $f[2], 0, 49 ) 
you can execute the following command to add /bin, or whichever directory you need, to path.  export path="$path:/bin"   you can then add that line to .profile or .bashrc (if you use bash) to make sure that directory is included in your path each time you log in. 
pid randomization was never available in the mainstream linux kernel
the ^([^8]*(8([^38]|3[^4])+)*)+$ pattern should do the trick, thanks to mikeserv, who pointed it out to me. 
groff -man -tascii &lt; /path/to/manpage/without/gz | less   eg:  groff -man -tascii &lt; c:/programs/msysgit/mingw/man/man1/gcc.1 | less   note: although switching shells is not needed here, mysysgit uses sh (not bash) as the default shell
you can use find.  find ./ -type d -execdir chmod 750 {} +   where 750 is the mode you'd like to apply and "./" is the directory you will recursively search.  edit: thanks to @gilles and find(1), i've revised this for additional security and performance. 
 .exrc is the configuration file for vi, whereas .vimrc is the config file for vim no
you can remove a string from a text file with sed (others tools exist).  for example:  sed -i -e '/myapp/d' .bash_profile   removes from .bash_profile every line containing the string myapp. 
one thing you could do is replace spaces with newlines and then use awk or cut
comprehensive listing  despite being advertised as a replacement for netstat, ss does not yet show sctp sockets
some notes on your question, maybe it helps, hopefully:   ~/.xinitrc is not the right place for these settings, see for example here, in the "archwiki" don't fight your distribution, archlinux's system startup is configured via /etc/rc.conf, which is pretty neat
xargs  one method that i'm aware of is to use xargs to find this information out.  $ xargs --show-limits --no-run-if-empty &lt; /dev/null  your environment variables take up 4791 bytes posix upper limit on argument length (this system): 2090313 posix smallest allowable upper limit on argument length (all systems): 4096 maximum length of command we could actually use: 2085522 size of command buffer we are actually using: 131072   getconf  the limit that xargs is displaying derives from this system configuration value.  $ getconf arg_max 2097152   values such as these are typically "hard coded" on a system
have a look at man bash (or whatever shell you are using):     ${parameter##word}           remove matching prefix pattern
tl/dr:  make sure you get the right device name, ensure it's not mounted, and do as many random overwrites as you can afford
console commands due to the lack of a gui option...  1.) open console.  2.) type the following command...  sudo swapoff -a   3.) enter your root password.  4.) type the following command...  sudo nano /etc/fstab   5.) comment out the swap line (seems to be the last, will say "swap" on it.  6.) press ctrl+x to save if using nano and confirm the file by pressing 'y'.  was told that the caret ^ signifies the ctrl (control) key
the documentation and example you are looking for is located at /usr/share/doc/initscripts-*/sysvinitfiles on centos/rhel
on debian, reboots are logged
when vim reads an existing file, it tries to detect the file encoding
you could look for "invalid user" which is thrown when someone tries to logon with an account that does not exist
you can't, because they are literally the same file, only reached by different paths
the command  tar czf /media/masi/ntfsdisc/backup_home.tar.gz $home/   is the same as this:  tar cf - $home/ | gzip &gt; /media/masi/ntfsdisc/backup_home.tar.gz   when you ran top, it showed the gzip was using up around 100% of one cpu thread
in my mind, the only benefit you really get from compiling your own linux kernel is:  you learn how to compile your own linux kernel.  it's not something you need to do for more speed / memory / xxx whatever
you missing ; character to terminate primary expression (see posix find):  find 
killing 0 isn't killing the pid 0
free pulls its data from /proc/meminfo  slkwr133701:/usr/src/linux # free               total       used       free     shared    buffers     cached mem:       2053456     434572    1618884          0      77888     201820  slkwr133701:/usr/src/linux # cat /proc/meminfo  memtotal:        2053456 kb memfree:         1618736 kb buffers:           77928 kb ....   this refers to memory used for temporary block i/o storage. the kernel has to assign and free the same size units constantly like block i/o transfers, network packets, and socket buffers  you can get a better look at caches and buffer allocations by running slabtop  in response to your usage question: the system will typically allocate more blocks than it needs but as the "memory pressure" increases these additional blocks will be released. 
early shells had only a single data type: strings
the insmod command in grub2 relates purely to grub modules and not to the kernel that it is loading
the problem is happening because of precedences
if the segmentation fault produces a "core" file, you can run file &lt;core-filename&gt; to identify the executable
add cd /home/xxxx/documents/scripts/ if you want your job to run in that directory
   where can i learn, basically, how to set them up?   for setting up a script which executes commands, just create a file (e.g
logrotate is used by the system to rotate logs so you have 2 choices
i made an 300mb extended partition with a 100mb logical partition; deleted just the extended partition; then recreated it - all with fdisk
tr's man page explains it pretty well; it's a filter that converts characters from one set to another
check your /var/log/messages log file
the \+ and \? parts of your sed command are gnu extensions - posix compatible sed cannot use these aspects of extended regex at all
please run this command as an example:  clear; tput cup 4 10; printf "menu item 1"; tput cup 7 30;  printf "menu item 29";tput cup 23 0; printf "make your selection"   then look at the man page of tput command to understand how it functions
i've now distilled enough information to answer my own question
awk "/^entry '234238'/ {printline = 1; print; next}      /^entry / {printline = 0}      printline"  
you could pipe the message to ripmime, which lets you specify a destination directory on the command line...e.g.:  ripmime -i - -d ~/myfiles/   the -i - tells ripmime to read from standard input, and -d specifies a destination directory
you need to escape both the shell, and sed:  $ a=w $ b="\\\ " $ echo word | sed "s/$a/$b/" \ ord  
check /etc/crontab file and set mailto=root in there
0:root@server:/root # lsvirprt -q printqueuename -d 'hp@printqueuename' | grep -i time mc      string to send to printer "mz" times when job is     \0                 mz      number of times to send string "mc" to printer       14688              0:root@server:/root #    it cannot be set, better to create the print queue again, but with rembak backend
try   awk '/mail:|fullname:/{s=s", "$0} /uid:/ {s=s", "$0 "\n" ;} end{printf substr(s,3)}' dump2.txt   assuming no % in field  other solution   awk '/mail:|fullname:/{s=s", "$0} /uid:/ {print substr(s,3) ", "$0 ;s=""} ' dump2.txt   assuming uid: is last. 
in order for the grub-reboot command to work, several required configuration changes must be in place:   the default entry for grub must be set to saved
from set system font in lxde?:  the "default font" combo is (mis)placed in the "widget" tab
standard output is not a terminal when you launch the command remotely through ssh
assuming that plugin uses the same syntax as the python regexp engine: use \g&lt;1&gt;0 as the replacement text. 
there's a dedicated tool to do this, avimerge:  avimerge -o cd.avi -i cd1.avi cd2.avi  
you can get the files with full path with this command:  find /   or list files from the current directory down:  find $(pwd)  
before you do anything to the usb-stick, you should make an image of it:  dd bs=4k of=stick.img if=/dev/disk/by-id/usb-jetflash_transcend_4gb_qtmfkjqq-0\:0   then you put your stick safely away and use the stick.img file to do your fiddling, instead of destroying more data.  are there important files on it? check http://www.cgsecurity.org/wiki/photorec for recovery tools
 i replaced the label logitech_ff with logiwheels_ff in the file  /usr/src/linux-2.6.34-12/drivers/hid/kconfig. set default y as shown below:    config logiwheels_ff       bool "logitech force feedback support"       depends on hid_logitech       default y       select input_ff_memless       help         say y here if you have one of these devices:         -logitech wingman cordless rumblepad         -logitech wingman cordless rumblepad 2         -logitech wingman force 3d         -logitech formula force ex         -logitech wingman formula force gp         -logitech momo force wheel          and if you want to enable force feedback for them.       note: if you say n here, this device will still be supported, but without         force feedback    the fftest worked with constant force as shown below.  linux-dopx:/home/anisha/ # fftest /dev/input/event4 force feedback test program. hold firmly your wheel or joystick to prevent damages  device /dev/input/event4 opened axes query:  effects: constant  number of simultaneous effects: 16 upload effects[0]: invalid argument upload effects[2]: invalid argument upload effects[3]: invalid argument upload effects[4]: invalid argument upload effects[5]: invalid argument enter effect number, -1 to exit 1 now playing: constant force enter effect number, -1 to exit   thanks to: simon from linux-input mailing list. http://www.spinics.net/lists/linux-input/msg19084.html 
interactively, you can always run your scripts by typing ~/yourscript.sh on the command line, but that's very limiting, especially if you want to write more scripts that call the scripts you've already written.  a more integrated and flexible approach involves putting all your scripts into one directory and adding that directory to your path environment variable.  after you do that, you'll be able to type yourscript.sh, and no matter which directory you're in, the shell will find your script and execute it.  this is how it's usually done:   make a bin directory under your home directory and mv your scripts into it. change all the scripts to executable (chmod +x). ensure that your path environment variable contains your $home/bin directory
yes, you can
from inside top you can try the following:   press shift+f press the letter corresponding to %mem press enter    you might also try:  $ ps -eo pmem,pcpu,vsize,pid,cmd | sort -k 1 -nr | head -5   this will give the top 5 processes by memory usage. 
what you're asking for is called dma
http://marc.info/ has a link for each message to get the raw body, and https://lkml.org/ has (in the sidebar) links to download any contained diffs.  there are also archives with nntp access that may provide raw messages, though i haven't tried this. 
to change options permanently and in the sanctioned manner, edit the files in /etc/sysconfig that have the same name as the service.  for example, consider httpd
you can use gnu find to list the files with the modified time expressed as epoch time, then use sort to sort the list, finally head and tail to get the desired numbered file name :  find 
in my opinion, you need to recommend to your client to change their policy
this directory might be created by any application that follows the freedesktop userdirs standard
using screen -x allows you to connect to a session that it currently attached, without forcing it to detach
this is not yet close to be a definite answer
using the case statement and command substitution :   for file in *; do     case $(file --mime-type -b "$file") in         image/*g)        ..
check (my) /etc/vconsole.conf:  keymap="hu"   see releated wikipage for more information! 
the best solution for this is to use awk:  $ ldd /usr/bin/ppdhtml | awk '/ =&gt; / { print $1 }' | head -n1 libcupsppdc.so.1   to do this using grep, you will need to use the lookahead and lookbehind features of pcre:  $ ldd /usr/bin/ppdhtml | grep -po '(?&lt;=\t).+(?= =&gt; )' | head -n1 libcupsppdc.so.1   the lookahead and lookbehind features affect that match, but are not included in the match
if you have hexdump (which is pretty likely), you could do something like this:  $ echo "hello, world!" | hexdump -v -e '/1 "[%_c]: "' -e '/1 "%02x\n"' [h]: 48 [e]: 65 [l]: 6c [l]: 6c [o]: 6f [,]: 2c [ ]: 20 [w]: 77 [o]: 6f [r]: 72 [l]: 6c [d]: 64 [!]: 21 [\n]: 0a   for a simple space separated hex dump into a variable:  $ v=$(printf %s 1273455667 | hexdump -v -e '/1 "%02x "') $ echo "$v" 31 32 37 33 34 35 35 36 36 37  
i've managed to fix this by going to system settings -&gt; applications -&gt; web browser and setting parameter open http and https urls to in the following browser -&gt; firefox   this works with kde 5, but should work similar in previous versions. 
there's a piece of software called handbrake that has served me very well. 
before:   server:/etc/syslog-ng # tail -3 syslog-ng.conf # # log { source(src); destination(/var/log/messages); }; server:/etc/syslog-ng #    edit the syslog-ng.conf file:  vi /etc/syslog-ng/syslog-ng.conf   after:  server:/etc/syslog-ng # tail -3 syslog-ng.conf #log { source(src); destination(/var/log/messages); }; filter heartbeat_filter { not match("pfilter-drop") and not match("dst=192.168.202.255") and not match("proto=udp"); };  log { source(src); filter(heartbeat_filter); destination(/var/log/messages); }; server:/etc/syslog-ng #    restart syslog-ng  /etc/init.d/syslog restart # or whatever you use to restart syslog-ng # now check   rotate if needed  logrotate /etc/logrotate.conf  
use latex
first, they're called "packets", not "packages"
disregarding the "group" and "other" permissions, something being owned by root means only root has total control over the file/directory.  something being owned by another user means that user in addition to root has total control over that file
i hate to do this but the answer is (after more research):   getfattr -d -m - file   i apparently missed this in my reading of the man page
you may want to read this: http://www.postfix.org/sasl_readme.html search for "configuring sender-dependent sasl authentication" on this page
i've finally found how to do that.  it's a bit hackish thought, but it works.  i've used some part of this thread : http://stackoverflow.com/questions/25166085/how-can-a-systemd-controlled-service-distinguish-between-shutdown-and-reboot  and this thread :  how to run a script with systemd right before shutdown?  i've created this service /etc/systemd/system/shutdown_screen.service  [unit] description=runs only upon shutdown conflicts=reboot.target after=network.target  [service] type=oneshot execstart=/bin/true execstop=/bin/bash /usr/local/bin/shutdown_screen remainafterexit=yes  [install] wantedby=multi-user.target   which will be executed at shudown/reboot/halt/whatever. (don't forget to enable it)   and in my script /usr/local/bin/shutdown_screen i put the following :  #!/bin/bash # send a shutdown message only at shutdown (not at reboot)     /usr/bin/systemctl list-jobs | egrep -q 'reboot.target.*start' || echo "shutdown" | nc 192.168.0.180 4243 -w 1   which will send a shutdown message to my arduino, whom will shutdown my screen. 
in the last source distribution, (rtnet-0.9.12.tar.bz2), i can see rtnet-0.9.12/drivers/experimental/rt_r8169.c, so the rt_ nomenclature remains
here are two methods:  you can ensure that keychain only opens on one tab like this:  if mkdir /tmp/keychain.lock; then   eval `keychain --eval --agents ssh id_dsa`   rm -r /tmp/keychain.lock fi   but it may not be on the first tab you land on - you might have to hunt for it, which could be just as annoying
you can just pipe the output to shuf.  $ seq 100 | shuf   example  $ seq 10 | shuf 2 6 4 8 1 3 10 7 9 5   if you want the output to be horizontal then pipe it to paste.  $ seq 10 | shuf | paste - -s -d ' ' 1 6 9 3 8 4 10 7 2 5   $ seq 10 | shuf | paste - -s -d ' ' 7 4 6 1 8 3 10 5 9 2   $ seq 10 | shuf | paste - -s -d ' ' 9 8 3 6 1 2 10 4 7 5    want it with commas in between? change the delimiter to paste:  $ seq 10 | shuf | paste - -s -d ',' 2,4,9,1,8,7,3,5,10,6  
i finally managed to actually test the python script i mentioned as the second option in my question
the parts of the window you pointed out are rendered by the client, i.e
sorting the history  this command works like sort|uniq, but keeps the lines in place  nl|sort -k 2|uniq -f 1|sort -n|cut -f 2   basically, prepends to each line its number
not a task for less  no, i do not think you can do that directly, because less does not have a cursor to begin with. it would need one to navigate to start and end of the text to select. less is just not the right tool for character-level navigation.  tabs already expanded  you can use the key shift and the mouse to make a selection; this is handled by the terminal, not by less
this will currently only work with version 1.30.0-ish or higher, it does not work on any current version of ubuntu, unless you build from source.  virt-sysprep -a centos-6-x86_64-genericcloud-1601.qcow2 --root-password password:asd --ssh-inject root:file:/root/my.key.pub  
adding this as an answer as it seems to have helped:  you should ensure that imagemagick itself is installed, i.e
on linux, you probably already have an tmpfs filesystem that you can write to at /dev/shm.  $ &gt;/dev/shm/foo $ df /dev/shm/foo filesystem           1k-blocks      used available use% mounted on tmpfs                   224088         0    224088   0% /dev/shm   this may use swap, however
here is a solution inspired by soubunmei's answer:  #!/bin/sh  activewindowmanagerpid() {     local windowmanager="$1"      local windowmanagerpids="$(pidof "$windowmanager")"      local displaynumber="$(echo $display \         | awk 'begin { fs = "[:.]" } { print $2 }')"      ps e -p "$windowmanagerpids" \         | awk -v n="$displaynumber" \             '$0 ~ " display=:" n "[\n .]" { print $1 }' }  kill "$(activewindowmanagerpid blackbox)"  
you have 2 options, you can either comment out or remove the line from the /etc/fstab or you could specify the noauto option, leaving the line intact in the /etc/fstab file.  example  /dev/dvd    /media/dvd    auto        noauto,rw,user,exec    0 0  
i think you can do it with this:  $ startx -- :1   note that you need to be on a text console
pam is not a daemon, but just a library
centos is based on rhel directly
sure, you can setup a screen or tmux hardline.  example using screen: http://blog.boreas.ro/2008/03/gnu-screen-for-win.html  example using tmux:    tmux and screen are awesome - you should learn how to use them. 
you can restart the gnome-shell by pressing alt+f2 and then typing in either "restart" or just "r" and pressing enter.  otherwise i've noticed that it automatically refreshes .desktop files after waiting a little while. 
   security is highered if only one machine can do the decryption.   availability can take a serious hit if that machine goes bust, though.     how would you suggest to allow only one computer to be able to decrypt an luks partition? i would simply need to get a set of variable specific to my machine and add them in the passphrase [...]   well, you could base it on some hardware serial numbers (sudo dmidecode to see some) but this is less useful than you think
strings sent to the standard output go to /dev/console (most often you can see them on your screen, but not always)
yup
you can also use the lsb_release command
actually, it looks like this is a solved problem
benchmarking the disk with dd, hdparm or similar tools won't neccesarily tell you if the disk is defective
try   awk -f\| '{ print $1 &gt; $2 ; }' file   where   -f\| tell awk to use | as separator, | need to be escaped. &gt; $2 redirect print to $2's value.   in case of many ( > 10 ) files :  for x in $(awk -f\| '!a[$2]++ { print $2}' file) do     awk -f\| -v f="$x" '$2 == f { print $1}' file &gt; "$x" done    first awk merely list uniq filename 52 files are ok, this might get slow if hundreds of files.   another alternative, provided field are "safe" to put in shell  awk -f\| '{printf "echo %s &gt;&gt; %s\n",$1,$2;}' file | bash    be sure to delete filex before, in case of re-run.  
this allows you to construct a command with full vi editing
use "--" to make rm stop parsing command line options, like this:  rm -- --help  
you could do that this way:  [[ `id -u` -eq 0 ]] || { echo "must be root to run script"; exit 1; }   ("ordinary" conditional expression with an arithmetic binary operator in the first statement), or:  (( `id -u` == 0 )) || { echo "must be root to run script"; exit 1; }   (arithmetic evaluation for the first test).  notice the change () -> {} - the curly brackets do not spawn a subshell
besides stat (linux-specific), there are tools which allow you to do this as a side effect
use the --base option:  wget -i file-of-filenames --base http://example.com/fetch/from/here/  
aliases don't handle arguments
i believe it's just a typo
mint actually uses ubuntu's repositories for most of the packages you'd install
read from a pipe, write to a file  if you want the daemon to read input produced by some arbitrary process, you need to connect that process to a pipe
i solved my problem by this way:  create a new group  sudo addgroup exchangefiles   create the chroot directory  sudo mkdir /var/www/groupfolder/ sudo chmod g+rx /var/www/groupfolder/   create the group-writable directory  sudo mkdir -p /var/www/groupfolder/files/ sudo chmod g+rwx /var/www/groupfolder/files/   give them both to the new group  sudo chgrp -r exchangefiles /var/www/groupfolder/   after that i went to /etc/ssh/sshd_config and i added in the end of the file   match group exchangefiles   # force the connection to use sftp and chroot to the required directory.   forcecommand internal-sftp   chrootdirectory /var/www/groupfolder/   # disable tunneling, authentication agent, tcp and x11 forwarding.   permittunnel no   allowagentforwarding no   allowtcpforwarding no   x11forwarding no   now i'm going to add new user with obama name to my group   sudo adduser --ingroup exchangefiles obama    now every thing is completly finish we need one commend to restart the ssh again   sudo service ssh restart   notice: the user now can't do any thing out file directory  i mean all his file must be in file folder 
to squash multiple hyphens (one hyphen followed by one or more hyphens) into a single one for all files in the current directory use:  rename 's/--+/-/g' -- *   the -- is important if files start with a hyphen, otherwise they would be interpreted as command line arguments
not sure if vi is required for this operation.  there is xclip utility that allows you to copy anything from console output to x server clipboard.  you should specify display=:0.0 environment and execute it like this:  cat file | xclip   or for remote file  ssh remote "cat file" | xclip   or from vi (note, that this way will temporaly clear vi buffer content, to revoke it press esc + u, data will stay in x cilpboard):  :%!xclip   now you're able to paste it anywhere with middle mouse button (note, that ctrl+v or shift+ins won't work). 
there are a number of tools to allow you to do that
* i'm not an expert in iptables or linux network scheduling, but i'll try to help! looking at iptables manual page user@host:~$ man 8 iptables we can see in nat (network address translation) table description:     "this table is consulted when a packet that creates a new connection is encountered
try  ls -ld foo   and you will get what you want
start by apt-get uninstall networkmanager on the server
check out badblocks if you want a utility that is specifically designed to write/read each lba of a drive, testing for errors on the way
try this:  sudo ssh root@pacific ssh root@loquat sudo -u wwwrun svn status -uq /srv/www/htdocs/loquat 2&gt;&amp;1  
if i am reading this question correctly, there is a program called tree
instead of bothering with this wasteful approach why not setup an ipset instead
use install instead of cp:  sudo install -o belmin /etc/foo.txt ~/foo.txt  
this answer checks the list of all attached block devices and iterates over them with udevadmin to check their respective id_bus.  you can see all attached block devices in /sys/block
the classical tool top shows processes by default but can be told to show threads with the h key press or -h command line option
no, you cannot, as the abis differ
lscpu  the lscpu command shows (among other things):  byte order:            little endian   systems this is known to work on   centos 6 ubuntu (12.04, 12.10, 13.04, 13.10, 14.04) fedora (17,18,19) archlinux 2012+ linux mint debian (therefore assuming debian testing as well).   systems this is known to not work on   fedora 14 centos 5 (assuming rhel5 because of this)   why the apparent differences across distros?  after much digging i found out why
the fundamental tool for sound format conversions and simple transformations is sox, the swiss army knife of sound-processing programs.  sox foo.mp3 foo.flac   if you're running debian, support for writing mp3 in sox is broken in lenny and squeeze (and as far as i know the same problem affects ubuntu 10.04 and 10.10)
why don't you just add test/ to the path of the file you're trying to create, i.e.  #!/bin/bash &gt; `pwd`/test/process_ids.txt while true;do   echo "the process: `ps`" &gt;&gt; `pwd`/test/process_ids.txt   #some code to parse the process, etc
i think it stands for "diagnostic messages", as per the older man page (referenced here too)
as it follows from the redhat's documentation on networking profiles, you should not use base interface name (eth0) for profile interfaces, but have one called as eth0_work and so on
if you read the man page (emphasize mine):  $attr{file}, %s{file}         the value of a sysfs attribute found at the device where all keys of the rule         have matched
you don't need cut at all, just bare grep is enough in the form:  grep "^$fruit:$count:$cost$" fruitdb.txt   remove any variable you don't want to grep at the time (but leave separators :, and begining and end of line signs ^ and $ (for edge variables)).  for example to grep those with count=20:  $ grep ":$count:" fruitdb.txt orange:20:2 banana:20:4   grep those with count=20 and cost=2:  $ grep ":$count:$cost$" fruitdb.txt orange:20:2  
note the double space in bash's error message before "grep": that probably means you've typed an unbreakable space (altgr+space), which can happen quite easily if your keyboard requires altgr to produce the pipe symbol.  try dropping the spaces around the pipe symbol:  ps aux|grep xscreensaver   in your updated examples:  [root@hostname ~]# ps aux |  grep xscreensaver bash:  : command not found...   bash is trying to run the "unbreakable space" command, which doesn't exist; hence the error message, "unbreakable space": command not found...  [root@hostname ~]# ps aux | grep xscreensaver bash:  grep: command not found...   bash is trying to run the command whose name is "grep" preceded by an unbreakable space, which doesn't exist either; hence the error message with two apparent spaces between "bash:" and "grep". 
simply download tar.bz2 archive from mozilla site, unpack it to /opt and make a symlink to /usr/local/bin:  ln -s /opt/firefox/firefox /usr/local/bin  
--format only parses percent escapes and adds a newline at the end
in bash, just !636 will be ok. 
if this is actually a website, you can embed it using html5 video - you will need a more recent version of a browser to use it
the bash process that keeps running is the parent of tee, not the original script
as far as i understand, openvz guests share the host's kernel and all loaded modules
the module.symvers is (re)generated when you (re)compile modules
to replace xcape, i instead installed at-home-modifier, which does a similar thing, but at a root level
   change the gconf key with      gconftool-2 --type string --set /desktop/gnome/session/required_components/windowmanager compiz      you can go back to the default gnome metacity window manager with      gconftool-2 --type string --set /desktop/gnome/session/required_components/windowmanager gnome-wm      if this fails you can simply add compiz --replace   to your startup applications
a command line program can take input from a user via two sources: from stdin (which you are piping to), and by attaching directly to the tty
the table in this stack overflow answer (which got it from the bash hackers wiki) explains how the different bash variables are expanded:    you're doing python -i -c "from $@", which turns into python -i -c "from sys" "import" "stdout", and -c only takes a single argument, so it's running the command from sys
if your not familiar with "vi" or "emacs" prompt commands the best would be to use the fc shell built-in command look at the "fc" help into the  man sh-posix manpage
this question can't be simply answered. it usually means that something with your printing device driver is messed up.  any additional information?  most likely you are using cups.  did you have a look at the logfiles? /var/log/cups/ ?  maybe this will help you, to specify your questions.  try to do some printing at a low level to eliminate any error sources with some applications
you could do something like  df -p file | awk 'nr==2{print $nf}'   or even  df -p file | awk 'end{print $nf}'   since awk splits on whitespace(s) by default, you don't need to specify the -f and you also don't need to trim the whitespace with tr
tr \; \\n &lt;in &gt;out   ...is very likely the most efficient means of going from your sample input to your sample output
you can use arandr, a gui front end for xrandr
the above iptables config will only let tcp and udp packets get past the firewall (unless they came from loopback)
you can use recoll from the command line if you want so. 
the gnu grep can do it  grep -z 'is\san\sexample\sfile.' file   to fulfill some points which arise in comments there are some modifications to script:   grep -oz '^[^\n]*\bis\s*an\s*example\s*file\.[^\n]*' file   regarding huge files i have no imagination of memory limitation but in the case of problem you are free to use sed  sed '/\bis\b/{           :1           n           /file\.\|\(\n.*\)\{3\}/!b1          }      /\&lt;is\s*an\s*example\s*file\./p      d' file   that keep no more than 4-lines (because 4 words in pattern) in memory (\(\n.*\)\{3\}). 
to apply those permissions to a directory:  chmod 755 directory_name  to apply to all directories inside the current directory:  chmod 755 */  if you want to modify all directories and subdirectories, you'll need to combine find with chmod:  find 
typically, python package source files are located in /usr/lib/python&lt;version&gt;/site-packages
one of the easiest ways to filter out text is to use reverse grep (from man grep):     -v, --invert-match           invert the sense of matching, to select non-matching lines
i found these 2 methods for doing it
yes, that is possible
to shut any command line program just type ctrl+c. it will look like this on the command line : ^c  i think this is called the escape sequence.  edit i think you may be able to use ctrl+d or ^d also 
may be you can use:  dmidecode -t 9   for getting number of slots:  dmidecode -t 9 | grep "system slot information" | wc -l   for getting count of available:  dmidecode -t 9 | grep -a3 "system slot information" | grep -c -b1 "available"   more info dmidecode. 
there are really two types of variable:   environment variables shell variables   to make things more complicated, they both look the same, and a shell variable can be converted to an environment variable with the export command.  the env command will show the current set of environment variables.  $ myvar=100 $ env | grep myvar $ export myvar $ env | grep myvar myvar=100   variables can also be temporarily exported for the life of a command.  $ env | grep anothervar $ anothervar=100 env | grep anothervar anothervar=100 $ env | grep anothervar $    when the shell starts up it inherits a number of environment variables (which may be zero)
 install nautulus (avoiding the whole gnome desktop with --no-install-recommends)  sudo apt-get install -–no-install-recommends nautilus dconf-tools  open dconf-editor
assuming your certificates are in pem format, you can do:  openssl verify cert.pem   if your "ca-bundle" is a file containing additional intermediate certificates in pem format:  openssl verify -untrusted ca-bundle cert.pem   if your openssl isn't set up to automatically use an installed set of root certificates (e.g
since you've already worked out how to get your requests per second, you need to decide what your 'average' represents; i.e
this happens when a file contains \r\n as a line terminator instead of \n, since \r is a c0 control code meaning "go to the beginning of the current line".  to fix, run dos2unix foo.py.  example session:  ben@joyplim /tmp/cr % echo '#!/usr/bin/env python' &gt; foo.py ben@joyplim /tmp/cr % chmod +x foo.py  ben@joyplim /tmp/cr % ./foo.py  ben@joyplim /tmp/cr % unix2dos foo.py  unix2dos: converting file foo.py to dos format ... ben@joyplim /tmp/cr % ./foo.py        : no such file or directory ben@joyplim /tmp/cr % ./foo.py 2&gt;&amp;1 | xxd  0000000: 2f75 7372 2f62 696e 2f65 6e76 3a20 7079  /usr/bin/env: py 0000010: 7468 6f6e 0d3a 204e 6f20 7375 6368 2066  thon.: no such f 0000020: 696c 6520 6f72 2064 6972 6563 746f 7279  ile or directory 0000030: 0a                                       .   specifically note the 0d3a in the output. 
something like this will do:  $ dig +short www.google.com | head -1 74.125.225.113   but be careful because most servers that have multiple ip addresses will do some form of round robin at the dns level so the list is typically rotating every time you run the dig command:  $ dig +short www.google.com 74.125.225.116 74.125.225.112 74.125.225.113 74.125.225.114 74.125.225.115  $ dig +short www.google.com 74.125.225.115 74.125.225.116 74.125.225.112 74.125.225.113 74.125.225.114  $ dig +short www.google.com  74.125.225.114 74.125.225.115 74.125.225.116 74.125.225.112 74.125.225.113   notice how the ips move around from query to query? this is done to balance the load across those servers.  capturing the ip into a variable  the following command will capture the output of the ip address and put it into a shell variable.  $ ip=$(dig +short www.google.com | head -1)   you can confirm this like so:  $ echo $ip 74.125.225.114  
since you don't seem to accept neither our opinions not the various pages we have linked to as 'official', perhaps the official red hat documentation will convince you:     in this example the total amount of available memory is 4040360 kb.   264224 kb are used by processes and 3776136 kb are free for other   applications
i posted this on a similar question    if you have a cron daemon, one of the predefined cron time hooks is @reboot, which naturally runs when the system starts
ultimately, it was an arbitrary choice made by the creators of unix over four decades ago now
you're not seeing any performance benefit because you're not actually hitting disk when using a file - the data's on its way to the disk, but your execution thread doesn't need to wait for it to land there, so you're not actually seeing the speed penalty of hitting the disk.  if you want to wait for the disk operation to complete to see how much slower that gets, call a sync() (how to varies on your python version, see here) - you'll be looking at tens of thousands of microseconds just for your disk to seek a couple times to get the file written out (assuming it doesn't have some kind of fast write cache like in a raid controller). 
ext3 stores the last mount time and can be retrieved with:  dumpe2fs -h /dev/node   i'm not sure that fat stores this information. 
some distributions have opted to include compatibility scripts so that old style commands still work
i finally copied using a tar pipe.  # cd /mnt/sda1/ &amp;&amp; tar cf - * | nc 192.168.1.1 2222 # on laptop # cd /mnt/sda5/ &amp;&amp; nc -l 2222 | tar x # on desktop   copying was way faster and seemed to work.  i wasn't able to boot in windows 7 thought
there's a program called radeontop which should provide some or all of the information you're after.  i've installed and run it on my debian laptop (which has a radeon hd 6320 gpu) and it seems to work as advertised.  if you need data for further processing rather than a top-like display, it has a -d or --dump option for dumping the data to a file (unfortunately, only as percentages rather than as raw numbers)
you need the ralink firmware, https://packages.debian.org/jessie/firmware-ralink  # apt-get install firmware-ralink 
just hit upon two different ways:   transfer files via network
it is shown after you have selected a user
in openssl.cnf at the top add the entry san = "email:copy" (to have a default value in case the environment variable san is not set) and in the respective section use subjectaltname = ${env::san}
i tried all sorts of things, mainly using following resource
have you read pacman(8)?  to list all the files being installed by a particular package, run:  $ pacman -ql &lt;package_name&gt;   daemons are usually systemd services in arch linux, hence you could run:  $ pacman -ql &lt;package_name&gt; | grep service   to see a list of service files installed by that package
it does indeed - the "placeholder" account will sum all of the subaccounts, and will convert the values based on the most recent exchange rate you have stored. 
the reason is unix does not lock an executable file while it is executed or even if it does like linux, this lock applies to the inode, not the file name
since pwdx accepts pids then you can use:  $ pwdx $(ps -c "node server.js" --format pid --no-headers) 2781: /home/user 4405: /home/user/src.git/   and possibly define a function in your .zshrc or .bashrc:  function select_by_dir() {   if (( $# == 0))l then     pwdx $(ps -c "node server.js" --format pid --no-headers)    else     pwdx $(ps -c "node server.js" --format pid --no-headers) | grep $1   fi }   } 
to find out about a key binding.  in bash:  $ bind -p | grep -a '{' "\e{": complete-into-braces "{": self-insert  $ less='+/complete-into-braces' man  bash    complete-into-braces (m-{)           perform filename completion and insert the list of possible com‐           pletions  enclosed within braces so the list is available to the           shell (see brace expansion above).   or with info:  info bash --index-search=complete-into-braces   (or info bash and use the index with completion (i key))  however note that the pre-built info page that comes with bash-4.3 sources at least is missing some index entries including that for complete-into-braces, so unless your os rebuilds the info page from the texinfo sources, the above command won't work.  in zsh  $ bindkey| grep w "^w" backward-kill-word "^[w" copy-region-as-kill $ info --index-search=copy-region-as-kill zsh copy-region-as-kill (esc-w esc-w) (unbound) (unbound)  copy the area from the cursor to the mark to the kill buffer.   if called from a zle widget function in the form 'zle  copy-region-as-kill string' then string will be taken as the text  to copy to the kill buffer
i split this up into two regexes, this looks like it is working :  cat filename | grep -e '^[0-9]{5}$|^[0-9]{0,3}[hh]{1}[oo]{0,1}[0-9]{0,5}$'   the first part of the regex will try the filenames having only 5 digits, and the second part is trying for filenames having 0-3 digits, 1 'h' or 'h' letter, 0 or 1 'oo' letter, 0 to 5 digits.  this regex works with awk too :  cat filename | awk  '/^[0-9]{5}$|^[0-9]{0,3}[hh]{1}[oo]{0,1}[0-9]{0,5}$/ {print}'  
this is pretty much right—though you're missing a line like this:  lxc.network.ipv4.gateway = x.x.x.x   i have an lxc guest running on debian
if you press ctrl+u immediately after ctrl+j, the justification is undone
if your locate implementation understands the option -0:  locate -0 pattern | xargs -0 ls -sd   otherwise:  locate pattern | xargs -i {} ls -sd   of course you may want to vary the flags passed to ls, e.g
to enable inline data in ext4, you'll need to use the "wip" version of e2fsprogs (clone the git repository)
if your application needs an x server for some weird reason but doesn't do anything useful with it, give it a virtual x server
according to the ubuntu webpage time synchronisation with ntp:     sudo apt install ntp   the manpage for ntpd.conf says      wily (5) ntpd.conf.5.gz   provided by: openntpd_5.7p3_1_i386   and following that link: openbsd ntp daemon says     this is an alternative implementation of the ntp software, made by the openbsd    project
an awk program is a series of condition-action pairs, conditions being outside of curly braces and actions being enclosed in them
alias my_du=$'while printf \'%s \' "$(df -p / | awk \'nr==2 { print $(nf-1) }\')"; do sleep 3; done'   you can check the result with  alias my_du   if $() is quoted by " instead of ' or \ then it is substituted and the result rather than the intended program call becomes part of the alias definition. 
not directly, at least not for gnu mv according to its man page
sorting algorithms in modern locales are quite complex.  each character (actually collating element which could consist of a sequence of several characters like the czech ch) is given a number of collating weights that decide of their sorting order.  when comparing two strings, the first weight of all the characters is used first, and other weights are used later to decide ties if the two strings sorted the same with the first weights.  for instance, in many locales, e, é and e have the same primary weight (they are of the same equivalence class, they all match [=e=]).  so, when comparing for instance echo, été and enter, in the first pass, e, é and e having the same primary weight, it's the second character that will determine the order (c before n before t).  when comparing été, Été, ete, after the first pass, they all sort the same, so we use the second pass using the secondary weight
you will need to use a different user than the account that you are setting up encryption for (this is primarily the 'root' user but could be any user who has access to 'sudo')
looks like you're trying to use update-rc.d as an unprivileged user? since this tool is located in /usr/sbin/ you probably don't have it in your $path
from some quick searching, it doesn't look like there is a way to get gnome to display the dimensions
description  understanding this will take some effort
as mentioned in comment you can use:  read -t 1 -n 1 key   which because of -t option we can remove sleep, so your script could be:  #!/bin/bash  for ((i=0; i&lt;100; i++)); do     read -t 1 -n 1 key     if [ "$key" = "k" ]; then         i=$((i + 10))     fi     echo $i done   but i think more portable could be:  #!/bin/bash  if [ -t 0 ]; then stty -echo -icanon -icrnl time 0 min 0; fi  keystroke='' i=0 while [ $i -lt 100 ]; do     keystroke="$(dd bs=1 count=1 2&gt;/dev/null)" # http://www.tldp.org/ldp/abs/html/     if [ "$keystroke" = "k" ]; then         i=$(( i + 10 ))     elif [ "$keystroke" = "q" ]; then         break     fi     i=$(( i + 1 ))         echo $i     sleep 1  done  if [ -t 0 ]; then stty sane; fi  exit 0  
if you're trying to ensure the usb key only contains the image and the remaining space is all zeros, you could do this instead:  cat myiso.iso /dev/zero &gt; /dev/sdb   there doesn't seem to be much point in writing all zeros and then the image on top... 
running a process in background and closing ssh session  there are many ways to do so:  1.the nohup command  you can use the nohup command to execute commands after you exit from a shell prompt
run   type caller   and you will see it is a shell built-in. running  help caller   will show its function, reported as well in bash's manual page
long answer short: use the extension put windows (''move focus using the keyboard'' says it all)  first you check that it is really not currently possible   the feature does not seem to be listed in the gnomeshell cheatsheet, neither in gnome3 > keyboard
i hope i don't confuse you with this code, see the comments starting with a #.  i will test with the following input file:  text1 "text2" text3 1,2 this "/usr/strange path with spaces/" works 2,3   the input of the next script can be given as cat input | while ...
busybox has chpasswd(8) which is a utility best used to create/update a lot of users very quickly and with one command
installing the dropbox deb files from the dropbox website (ubuntu or debian, i have not tested others) will not install nautilus, although gdebi says a nautilus extension will be installed
you can use bash scripting, but for compression etc
it looks like you can't do this in nanobsd
are you talking about classic history expansion, or readline processing? cd !$ on the next input line will substitute in the last argument of the previous line, or m-. or m-_ will yank it using readline. 
this is weird
i found this q still-unanswered; g-man and bratchley have pointed out the error; getuid() returns the "real user id of the calling process" while geteuid() returns the "effective user id of the calling process".  you can see the difference with this program:  #include &lt;stdio.h&gt; #include &lt;sys/types.h&gt; #include &lt;unistd.h&gt; int main (void) {   printf ("getuid=%d, geteuid=%d\n", getuid(), geteuid());   setuid(geteuid());   printf ("getuid=%d, geteuid=%d\n", getuid(), geteuid()); }  $ gcc -o getuid getuid.c $ sudo chown root getuid $ sudo chmod u+s getuid $ su nobody -c ./getuid getuid=60001, geteuid=0 getuid=0, geteuid=0  
from solaris 10:  ~ touch testfile ~ rm -- testfile ~ ls testfile testfile: no such file or directory ~ touch testfile ~ rm -- -f testfile -f: no such file or directory ~ ls testfile testfile: no such file or directory ~ rm - - -f testfile -: no such file or directory -f: no such file or directory testfile: no such file or directory ~   so to answer your question, in solaris 10, if the second instance starts with a hyphen, it is treated as a file. 
you should probably simply use kscreen instead, which should solve all your issues
yes the genrsa switch is the key that's getting generated in the req command
the name in /etc/hostname is what your computer thinks it's called
you can use xinput.  &gt;xinput --list ⎡ virtual core pointer                      id=2    [master pointer  (3)] ⎜   ↳ virtual core xtest pointer            id=4    [slave  pointer  (2)] ⎜   ↳ mouse0                                id=6    [slave  pointer  (2)] ⎣ virtual core keyboard                     id=3    [master keyboard (2)]     ↳ virtual core xtest keyboard           id=5    [slave  keyboard (3)]     ↳ keyboard0   there you get the name of the mouse in this case mouse0.  with the following command you slow down the speed of your mouse by a factor of 100000, which is then basically zero.  xinput --set-prop 6 'device accel constant deceleration' 100000   or  xinput --set-prop mouse0 'device accel constant deceleration' 100000   to revert you can use the same  xinput --set-prop mouse0 'device accel constant deceleration' 1  
to get information about a package file:  dpkg -i some_stuff_all.deb   this gives you all available information about the file, including package:, version:, depends:, description:, etc.  see dpkg --help for a summary of options, and man dpkg for details
try this instead:  echo "alias aaa='cd \"$pwd\"'" &gt;&gt; ~/.bash_aliases  
/usr/ports/ports-mgmt/portmaster man page has example how to do bulk port re-install. 
this is quite tricky to do on a live system
i think you want the trap function, specifically:  error_func()  {     echo 'an error occurred!'     exit 1 }  trap error_func err   errors later will jump to the function
use xsetwacom.  basically, you'll want to list your current configuration, then re-configure the buttons to be the opposite way around, e.g
straight out of man tcpdump  -l     make stdout line buffered
pip install gprof2dot installs the script as gprof2dot, not gprof2dot.py.  just remove the .py in your command and you should be good to go.    for future reference: you can enter a part of an unknown command at your shell prompt and press tab to try and auto-complete it (which i did in this case).  for packages installed via pip, you can also list the files they contain:  $ pip show -f gprof2dot --- name: gprof2dot version: 2015.12.01 location: /tmp/tenv/lib/python2.7/site-packages requires:  files:   ../gprof2dot.py   ../gprof2dot.pyc   ./   sources.txt   dependency_links.txt   top_level.txt   pkg-info   entry_points.txt   ../../../../bin/gprof2dot   anything that's executable should be in a bin directory somewhere. 
the postinst of the chrome package doesn't to anything out of the ordinary
bfm only blocks addresses which try to brute force directadmin itself; for other services it only notifies you.  if you want something which will actually block addresses which attempt to brute force other services, try fail2ban. 
each line in the /etc/fstab file contains the following fields separated by spaces or tabs:  file_system    dir    type    options    dump    pass   a typical mount point added in /etc/fstab would look like the following:  # &lt;file system&gt;        &lt;dir&gt;         &lt;type&gt;    &lt;options&gt;             &lt;dump&gt; &lt;pass&gt; /dev/sda1              /             ext4      defaults,noatime      0      1   you can't simply add a mount statement in the file
using sed and i/o redirection:   {   sed -n '1,64p' wizard-run;   base64 package.deb;   sed -n '66,$p' wizard-run; } &gt; wizard-run.tmp &amp;&amp; mv wizard-run.tmp wizard-run  
awk might work
the file ~/.bash_history saves the list of executed commands
reverse records (for ipv4) are stored (backwards) somewhere under the in-addr.arpa zone, which tools like host will handily reverse for you, while other tools may need to be fed the reversed ip address and so forth.  % host 8.8.8.8 | awk '{print $nf}' google-public-dns-a.google.com. % host 104.16.117.182 host 182.117.16.104.in-addr.arpa
inside the loop, you want:  run_this_command "whatever.${n}x${n}.in"   so that the shell knows you're talking about $n, and not $nx. 
you can use a test case.  while [[ ! -e ../test_data/all_enc_coords.txt ]]; do   if [ $(find ../test_data/local_enc* | wc -l) -eq 2 ]; then     cat ../test_data/local_enc* &gt; ../test_data/all_enc_coords.txt   else     sleep 0.001   fi done   as per the comments, if you were checking for the file containing data before writing, you could use:  while [[ ! -s ../test_data/all_enc_coords.txt ]]; do   if [ $(find ../test_data/local_enc* | wc -l) -eq 2 ]; then     cat ../test_data/local_enc* &gt; ../test_data/all_enc_coords.txt   else     sleep 0.001   fi done  
short answer:  try this:  0 * * * * echo hello &gt;&gt; ~/cron-logs/hourly/test`date "+\%d"`.log   note the backslash escaping the % sign.  long answer:  the error message suggests that the shell which executes your command doesn't see the second back tick character:     /bin/sh: -c: line 0: unexpected eof while looking for matching ``'   this is also confirmed by the second error message your received when you tried one of the other answers:     /bin/sh: -c: line 0: unexpected eof while looking for matching `)'   the crontab manpage confirms that the command is read only up to the first unescaped % sign:     the  "sixth"  field  (the rest of the line) specifies the command to   be run
i think you've jumped the gun a bit — while many people may agree wayland has a better design for the modern era (though some still disagree even on that), the implementation is not yet finished, and it doesn't yet do everything needed to overtake x, nor are the applications and toolkits ready for it
echo 212334123434test233abc44 |  awk '{gsub("[^0-9]+","\n"); print;}' |  awk '{ if (length($0) &gt; max) {max = length($0); maxline = $0} }    end { print maxline }'  212334123434  
you can poke around the system to find indicators
the most natural way would be to kill the session manager process for that session
usage from a red hat based distro  i believe the -k switch just fakes that the system is shutting down and so will print the wall message, but does little else.     -k        don't halt, power-off, reboot, just write wall message.   to cancel a shutdown event:  $ sudo shutdown -c   usage from ubuntu  when i tried using the above on ubuntu 12.04 i was able to do the following command:  $ sudo -i $ strace -s 2000 -o sdown.log shutdown -k 23:00  broadcast message from manny@manny     (/dev/pts/1) at 20:25 ...  the system is going down for maintenance in 155 minutes!  $ shutdown -c shutdown: cannot find pid of running shutdown   looking through the strace log file, sdown.log i saw nothing that would seem to indicate it had any effect at actually blocking logins from users.  $ grep open sdown.log open("/etc/ld.so.cache", o_rdonly|o_cloexec) = 3 open("/lib/x86_64-linux-gnu/libnih.so.1", o_rdonly|o_cloexec) = 3 open("/lib/x86_64-linux-gnu/libnih-dbus.so.1", o_rdonly|o_cloexec) = 3 open("/lib/x86_64-linux-gnu/libdbus-1.so.3", o_rdonly|o_cloexec) = 3 open("/lib/x86_64-linux-gnu/libc.so.6", o_rdonly|o_cloexec) = 3 open("/lib/x86_64-linux-gnu/librt.so.1", o_rdonly|o_cloexec) = 3 open("/lib/x86_64-linux-gnu/libpthread.so.0", o_rdonly|o_cloexec) = 3 open("/usr/lib/locale/locale-archive", o_rdonly|o_cloexec) = 3 open("/usr/share/locale/locale.alias", o_rdonly|o_cloexec) = 3 open("/usr/share/locale/en_us.utf-8/lc_messages/upstart.mo", o_rdonly) = -1 enoent (no such file or directory) open("/usr/share/locale/en_us.utf8/lc_messages/upstart.mo", o_rdonly) = -1 enoent (no such file or directory) open("/usr/share/locale/en_us/lc_messages/upstart.mo", o_rdonly) = -1 enoent (no such file or directory) open("/usr/share/locale/en.utf-8/lc_messages/upstart.mo", o_rdonly) = -1 enoent (no such file or directory) open("/usr/share/locale/en.utf8/lc_messages/upstart.mo", o_rdonly) = -1 enoent (no such file or directory) open("/usr/share/locale/en/lc_messages/upstart.mo", o_rdonly) = -1 enoent (no such file or directory) open("/usr/share/locale-langpack/en_us.utf-8/lc_messages/upstart.mo", o_rdonly) = -1 enoent (no such file or directory) open("/usr/share/locale-langpack/en_us.utf8/lc_messages/upstart.mo", o_rdonly) = -1 enoent (no such file or directory) open("/usr/share/locale-langpack/en_us/lc_messages/upstart.mo", o_rdonly) = -1 enoent (no such file or directory) open("/usr/share/locale-langpack/en.utf-8/lc_messages/upstart.mo", o_rdonly) = -1 enoent (no such file or directory) open("/usr/share/locale-langpack/en.utf8/lc_messages/upstart.mo", o_rdonly) = -1 enoent (no such file or directory) open("/usr/share/locale-langpack/en/lc_messages/upstart.mo", o_rdonly) = -1 enoent (no such file or directory) open("/etc/localtime", o_rdonly|o_cloexec) = 3 open("/var/run/shutdown.pid", o_rdonly) = -1 enoent (no such file or directory)   so i would be inclined to think that the man page is simply wrong in the way that it's phrasing that the -k switch will disable logins.  a bug in shutdown's source?  per a comment left by @gilles, he directed us to the source of shutdown.c, specifically from this url: http://packages.ubuntu.com/trusty/admin/upstart
if you're moving within the same filesystem, mv is atomic -- it's just a rename, not copying contents
as already mentioned other packages may require files or something else from the "provides" list of the package:  rpm -q --list openssl openssl-libs rpm -q --provides openssl openssl-libs   to see whether there are some "whatrequires" (not all):  rpm -e --test openssl openssl-libs   to list all is imo not directly possible with rpm but in yum case (untested):  yes "n" | yum remove openssl openssl-libs   or  yum deplist openssl openssl-libs   or  repoquery --alldeps --whatrequires openssl openssl-libs  
the question nearly gives it away, if you're familiar with pipes:     to do this, note the who command will show each user who is logged in along with identification of their computer
i'm not familiar with a gui to accomplish this but the steps to do this manually from a terminal aren't too bad
you can trace the system calls that a program makes
from less, type s then type the file name you want to save to, then enter. from the man page, under commands:  s filename       save the input to a file
my colleague found pykg-config, which proved to be much faster then pkg-config. 
you can use ssh's -l flag to create a tunnel from your system to a remote:  ssh -l &lt;localport&gt;:&lt;streamhost&gt;:&lt;streamport&gt; &lt;user&gt;@&lt;remote&gt;   you can then connect to your end of the tunnel with mplayer as you would otherwise:  mplayer localhost:&lt;localport&gt;  
you can use the identifier instead of an email address:  gpg --output "output_filename" --encrypt --recipient fxxxxx3d "input_filename"   (you should really specify the full fingerprint but that's another story.) 
i think this should work:  $   # create test file $ echo "hello, world" &gt; h.data $ $   # move contents up by 2 bytes $   # note if= and of= are the same for in-place editing $ dd bs=2 if=h.data skip=1 seek=0 conv=notrunc of=h.data 5+1 records in 5+1 records out 11 bytes (11 b) copied, 0.000598796 s, 18.4 kb/s $ $   # note 11 bytes were moved above $   # truncate the file after byte 11 $ dd bs=11 if=h.data skip=1 seek=1 count=0 of=h.data 0+0 records in 0+0 records out 0 bytes (0 b) copied, 0.000338852 s, 0.0 kb/s $ $   # display edited file: $ cat h.data llo, world $    wrapping this all up in a script you could have something like this:  #!/bin/bash  size=$(stat -c %s "$2") dd bs=$1 if="$2" skip=1 seek=0 conv=notrunc of="$2" dd bs=$((size - $1)) if="$2" skip=1 seek=1 count=0 of="$2"   call this as:  ./truncstart.sh 2 file.dat   where 2 is the number of bytes to delete from the beginning of file.data    as @gilles points out, this solution is not robust in case of unplanned outage, which could occur part-way through dd's processing; in which case the file would be corrupted. 
i found a shorter and simpler way to implement with python.  sample code below.  #!/usr/bin/python  import mailbox import email.utils import os  mbox = mailbox.maildir(os.environ['home'] + "/maildir" ) mbox.lock() spam = mbox.get_folder('inbox.junk') print "inbox:" for message in mbox:     print "- [%s] %s:  \"%s\"" % ( message['date'], message['from'], message['subject'] ) print print "spam messages:" for message in spam:     print "- [%s] %s:  \"%s\"" % ( message['date'], message['from'], message['subject'] )  mbox.close()  
gdebi is the appropriate tool for this:  sudo gdebi foo_1.0.0.deb   will install foo from the given package file, and any necessary dependencies. 
it look like you had the text encoded in utf-8 (that is good, as it is the standard for unix), but then something read it as iso 8859-1 / microsoft®'s windows latin-1 and then output it's interpretation
note: no error checking
all the files you tried to change are read after you log in
as val0x00ff suggests, awk can cover this  this would match 100 anywhere in field 2, e.g
something like this:  # your variable initialization readonly folder_location=/export/home/username/pooking/primary readonly machines=(testmachineb testmachinec) partitions=(0 3 5 7 9 11 13 15 17 19 21 23 25 27 29) # this will have more file numbers around 400  dir1=/data/snapshot/20140317  # delete all the files first find "$folder_location" -mindepth 1 -delete  # bash function to copy a single file based on your script do_copy() {   el=$1   scp -o controlmaster=auto -o 'controlpath=~/.ssh/control-%r@%h:%p' -o controlpersist=900 david@${filers_location[0]}:$dir1/s5_daily_1980_"$el"_200003_5.data $primary/
the history is persisted in the viminfo file; you can configure what (and how many of them) is persisted via the 'viminfo' (and 'history') options.  you can clear the history via the histdel() function, e.g
tmux kill-session [-t session_name]   the processes in the virtual terminals should receive sighup. 
by default there is no such key binding
as root (or using sudo), use the yum option history.  [root@fedora ~]# yum history list loaded plugins: langpacks, presto, refresh-packagekit id     | command line             | date and time    | action(s)      | altered -------------------------------------------------------------------------------    250 | -y update google-chrome- | 2013-01-30 18:02 | update         |    1 ee    249 | -y update                | 2013-01-25 07:11 | update         |   22       248 | -y update                | 2013-01-23 17:56 | update         |   12       247 | -y update                | 2013-01-23 08:41 | update         |    9 ee    246 | -y update                | 2013-01-20 21:49 | update         |    4       245 | -x kernel* update        | 2013-01-07 08:11 | update         |    3      you can view the packages and changes for a specific yum transaction:  [root@fedora ~]# yum history info 250 loaded plugins: langpacks, presto, refresh-packagekit transaction id : 250 begin time     : wed jan 30 18:02:31 2013 begin rpmdb    : 1624:34a60f2e27ebe4d959f1473055da42645705b96f end time       :            18:02:59 2013 (28 seconds) end rpmdb      : 1624:f4ef7af3a97b1f922f41803ba6b9578a7abe3e71 user           : user &lt;user&gt; return-code    : success command line   : -y update google-chrome-stable.x86_64 transaction performed with:     installed     rpm-4.9.1.3-1.fc16.x86_64               @updates     installed     yum-3.4.3-25.fc16.noarch                @updates     installed     yum-metadata-parser-1.1.4-5.fc16.x86_64 @koji-override-0/$releasever     installed     yum-presto-0.7.1-1.fc16.noarch          @koji-override-0/$releasever packages altered:     updated google-chrome-stable-24.0.1312.56-177594.x86_64 @google-chrome     update                       24.0.1312.57-178923.x86_64 @google-chrome scriptlet output:    1 redirecting to /bin/systemctl start  atd.service   you can view the history specific packages with:  [root@fedora ~]# yum history packages-list yum loaded plugins: langpacks, presto, refresh-packagekit id     | action(s)      | package                                               -------------------------------------------------------------------------------    148 | updated        | yum-3.4.3-24.fc16.noarch                           ee    148 | update         |     3.4.3-25.fc16.noarch                           ee     94 | updated        | yum-3.4.3-23.fc16.noarch                                  94 | update         |     3.4.3-24.fc16.noarch                                  52 | updated        | yum-3.4.3-7.fc16.noarch                                   52 | update         |     3.4.3-23.fc16.noarch                                   2 | updated        | yum-3.4.3-5.fc16.noarch                            ee      2 | update         |     3.4.3-7.fc16.noarch                            ee      1 | install        | yum-3.4.3-5.fc16.noarch                                 man 8 yum or yum help history will list more options that are possible with the history option. 
the file dpkg.tar.gz is the instructions to actually build the package
the script being monitor was a python script
to escape slashes, you can use any character other than a forward slash to separate regular expressions.  e.g
this is a job for rsync
install the poweriso package:  # pacman -s poweriso  convert the image to iso:  $ poweriso convert file.nrg -o file.iso  mount it:  # mount file.iso folder/ 
you can run it from your terminal:  man --locale=it  
here's an awk script that searches a multiline string (matches must consist of whole lines)
so you want to display the results without scientific notation? try this:  seq -f "%.0f" 4000000 4100000   so i'm actually changing the format (using -f) into a floating-point format with 0 decimal places (%.0f)  on my mac this results in:  4000000 4000001 4000002 4000003   etc.  4099997 4099998 4099999 4100000  
you need to write an init script for your web application
i was able to figure it out using strace -f and writing a small proof of concept in c.  it appears that bash just manipulates file descriptors in the child process before calling execve as i thought.  here's how ls -la &gt; diroutput.log works (roughly):   bash calls fork(2) forked bash process sees the output redirection and opens the file diroutput.log using open(2). forked bash process replaces the stdout file descriptor using the dup2(2) syscall bash calls execve(2) to replace it's executable image with ls which then inherits the already setup stdout   the relevant syscalls look like this (strace output):  6924  open("diroutput.log", o_wronly|o_creat|o_trunc, 0666) = 3  6924  dup2(3, 1)                        = 1  6924  close(3)                          = 0  6924  execve("/bin/ls", ["ls", "-la"], [/* 77 vars */]) = 0  
"hostname -h"   does not return 255 on my rhel machine.  it does return error 4 which make sense  hostname -h usage: hostname [-v] {hostname|-f file}      set hostname (from file) ........ echo $? 4   if you take a look at hostname.c from net-utils you will clearly see that:  static void usage(void) {     fprintf(stderr, _("usage: hostname [-v] {hostname|-f file}      set hostname (from file)\n")); ........   exit(4); /* e_usage */ }   and reference to usage() in here in the same file:  ........     case '?':     case 'h':     default:         usage();      };   so i am not really sure why you are getting 255, on mac version you might get "1", but i never seen "255".  edit you are right, i've just looked at fedora19 and hostname comes from hostname rpm and indeed for usage they do return 255:  void usage(file *stream) {         fprintf(stream, .....  exit(-1); }   ;  so here i will try to explain your confusion.  well, first doing exit(-1) there is a mistake by a programmer, at least for posix environment, since in such os anything that not 0 in exit status considered failure, but:  what about the exit() function found in the standard c library?  it’s manpage tells us that “the exit() function causes normal process termination and the value of status &amp; 0377 is returned to the parent”
you can "subscript" that pseudo-array
you can try this:  date -d @1427792481 +"%f"   or for 20150331:  date -d @1427792481 +"%y%m%d"  
enable one of the ssh keepalive messages, for example by enabling tcpkeepalive or clientaliveinterval in the server's sshd config.  similarly, in the client config you can use tcpkeepalive and serveraliveinterval.  tcpkeepalive used to just be keepalive, if you have an old version of openssh.  tcp keepalives are a feature that is part of tcp, and operates outside the encrypted tunnel built by ssh
i think that the biggest problem is to understand what “complement” means in the description of the -c option
meta-answer: all the raw stuff happening to the linux kernel goes through lkml (the linux kernel mailing list)
the backticked expression: echo {} | tr mkv m4v (which is not what you want, for a variety of reasons; see below) is expanded once, when the find command is parsed
i've found how to do it in the yajsw help,   thanks @gilles for the guiding  it's enough just to specify in wrapper.conf  wrapper.logfile= &lt;path and filename &gt;   thanks anyway!  
you have --assume-no parameters in apt-get.  try something like  sudo apt-get --assume-no upgrade &lt;package-name&gt;   details:  the manual page of apt-get (you can also refer to manual page with man apt-get command) mentions:     --assume-no      automatic "no" to all prompts
function lnmv     set dest_dir $argv[1]     set files $argv[2..-1]      for f in $files         set dest $dest_dir/$f         mv -- $f $dest         and ln -s -- $dest $f     end end  
the following command yields the requested output:  cut -d ' ' -f 1,3-10 file1  
you can set a variable to hold the variant part
the reason you are having extra package installations, is because of python-minimal's recommends
from the command line:   sudo dmidecode -s system-product-name or sudo dmidecode --string system-product-name  alternatively  sudo dmidecode | grep -a3 '^system information'     dmidecode provides a description of the computer's hardware information.  the -s --string flag with the dmi string system-product-name, only outputs the make and model of your computer.  | grep pipes the output to grep and the -a3 flag for grep prints 3 lines after a match for system information. 
you can find it in /usr/src or you can download from here (src.txz).  in freebsd the base system is outside of package manager
if the decrypted volume is /dev/mapper/crypto then you can get the information with  dmsetup table crypto 0 104853504 crypt aes-cbc-essiv:sha256 000[...]000 0 254:2 4096   if the encrypted volume is /dev/storage2/crypto then you get the information with  cryptsetup luksdump /dev/storage2/crypto luks header information for /dev/storage2/crypto  version:        1 cipher name:    aes cipher mode:    cbc-essiv:sha256 hash spec:      sha256 [...]  
i doubt we'll ever be able to tell you where it went, but you should just be able to reinstall it using yum.  yum reinstall man  yum doesn't check to see if files exist when you run yum install, it just checks a database of which packages have been installed
yes  it's not too hard
the apt history is usually kept in /var/log/apt
the longer number is called a universally unique identifier (uuid)
assuming that the elements do not contain spaces, you could translate spaces to commas:  echo a{b,c,d} | tr ' ' ,   which produces:  ab,ac,ad   you can also use ranges with characters:  echo a{b..d} | tr ' ' ,   this is especially useful if you want a larger range. 
i don't know how to do this with the shell
the closest equivalents that i can think of are virtualbox or xen
found the answer elsewhere
found it:  in the [network] section, where you configure the ip address (address=) you can add the subnet mask by adding a / to it, and the subnet mask bit count afterwards
it is not too uncommon to have tools that expect to be installed at user level
you can't "write a file" at an "offset into the partition" using dd this way -- you are just writing data into a file named "aaa" within the mounted file system on that partition.  "seek=" will indeed cause dd to lseek to the given position before beginning its writes -- that means that it will simply create a file called /mypart/aaa and lseek the given number of blocks into that file before writing.  if you omit "seek=", dd will write starting at the beginning of the file named "aaa". 
in string:  rtsp://user:pass@my.webserver.org:5554/my-media/media.amp?videocodec=h264   you have ? in that string, so the shell will perform pathname expansion on that string, using pattern matching rules.  in bash, if failglob options was not set, which is default, then failed pattern will be left as-is:  $ echo does-not-exist? does-not-exist?     while zsh will report no pattern match error with nomatch option set, which is default:  $ echo does-not-exist? zsh: no matches found: does-not-exist?   you can make zsh suppress the error and print the pattern:  $ setopt nonomatch $ echo does-not-exist? does-not-exist?     you can make bash behave like zsh with nomatch option set, by turning on failglob:  $ shopt -s failglob $ echo does-not-exist? bash: no match: does-not-exist?     more general, you can disable shell filename generation:  $ set -f $ : "the command" $ set +f   (or set -o noglob, set +o noglob)  or using one of shell quoting methods to make the shell treats ? and other pattern matching special characters literally.    zsh also provide the noglob builtin, which disable filename generation in any words for the following simple command:  $ noglob echo * *  
technically it's very sound, i think that the fact distributions do provide this method of patching yet is:   it does not integrate with the existing update methods (packaging wise) it adds to the burden of the distro to provide another method of upgrading.  
weird aspects of unix usually exist for good reason, so you're right to look for one
if the size of the disks are the same, you can copy the whole disk
info gettext might give you some clues
edit ~/.config/openbox/lxde-rc.xml with your favorite text editor and then, within the existing &lt;keyboard&gt; element, add the following lines:  &lt;keybind key="print"&gt;   &lt;action name="execute"&gt;     &lt;command&gt;scrot&lt;/command&gt;   &lt;/action&gt; &lt;/keybind&gt;   use the openbox --reconfigure  command to use the new settings
you can use the bash man page
the manpage shows that      --min-width    --min-height   can be used to adjust the output size so the resulting command would be  xvfb-run cutycapt --min-width=1080 --min-height=1920 --url ..
it won't return to the script when exec'ed command terminates
   what is the difference between procfs   and sysfs?   proc is the old one, it is more or less without rules and structure
   how can i switch to tty1 where xorg session is running and back to the session?   because x is running on tty1, but not on tty2
i don't know how to achieve this with capture, but you could use sub:  jq '.[] | {id: .logicalname, bus: .businfo | sub("pci@"; "")}' /var/tmp/network.json  
what about using diff to compare two files, counting the lines of differentiated text with 'wc -l' and then counting the actual lines in both of the compared files
reproduced (and improved) from the comp.unix.shell faq (since i happen to have written that section of the faq):  how do i get the exit code of cmd1 in cmd1|cmd2  first, note that cmd1 exit code could be non-zero and still don't mean an error
@derobert explained how du operates.  he didn't mention that unless you have an absolutely huge number of small files / directories (so the metadata takes a huge amount of memory), then running du again right away usually produces a result much more quickly.  one large file doesn't make du slow, but copying it is more likely to push directory caches out of memory
the following is the grub.conf present immediately after installation of fedora 14 within a virtualbox vm
most hotkeys are highly configurable
as ctrl-d said, my first thought would be have them (userb) create a ssh key, and add it to your (usera) .ssh/authorized_keys file
you cannot detect or create such files in general
its the difference between how bash and dash handle cases when a command is not found.  in bash, there is a function named command_not_found_handle :  $ type command_not_found_handle  command_not_found_handle is a function command_not_found_handle ()  {      if [ -x /usr/lib/command-not-found ]; then         /usr/lib/command-not-found -- "$1";         return $?;     else         if [ -x /usr/share/command-not-found/command-not-found ]; then             /usr/share/command-not-found/command-not-found -- "$1";             return $?;         else             printf "%s: command not found\n" "$1" 1&gt;&amp;2;             return 127;         fi;     fi }   so in bash :  $ foobar foobar: command not found   in case of dash, there is no such function defined and we get :  $ foobar dash: 1: foobar: not found   as ubuntu uses dash as the default shell for internal operations so when dash is parsing some script it would show its own format. 
(cd /a   &amp;&amp; ./script1)&amp; (cd /a/b &amp;&amp; ./script2)&amp;   if the names don't contain spaces or special characters like *, (, or ), you don't need quotes. 
try:  scp /path/to/file/* user@server:/path/to/files/   it will complain about not copying directories.  if you want to copy the files in the directories under /path/to/, you can do:  scp /path/to/*/* user@server:/path/to/files/  
edit: changed -t to -t 0, which does correctly detect input from terminal or file.  i think the key here is knowing whether your input is coming from a terminal or from a file
if you have access to gnu grep:  grep -vp '^(\d+-\d+-\d+|=+)$' file   and, if you don't:  grep -ve '^([0-9]+-[0-9]+-[0-9]+|=+)$' file   both commands use grep's -v flag which means "print lines that don't match the pattern and look for lines consisting of either 3 groups of digits separated by dashes or one or more = from the beginning (^) to the end ($) of the line.  you can do the same thing in sed with:  sed -e '/([0-9]+-[0-9]+-[0-9]+|=+)/d' file  
(warning: this is very dangerous if you do not know what you are doing)  yes, you can, but i do not recommend it (though i did it a few times, mostly to transfer a partition to another hdd).  dd if=/dev/sdaa of=/dev/sdab   will transfer the data from sdab to sdaa, but no checking will be done, all the partition will be copied (even the empty space), you must be sure that sdaa is bigger or equal sdab (otherwise you overwrite the beginning of following partition), and the system most likely won't boot - you'd have to boot from rescue cd/usb, mount /dev/sdab, modify grub configuration and re-run grub-install
try running:   # dpkg --configure --pending  # dpkg --configure -a  # apt-get -f install   if that doesn't help, and you are unable to resolve further conflicts/problems on your own or get someone whos more experienced with dpkg at the helm, or just backup /etc and reinstall. 
as @stephanechazelas stated this isn't possible
i suspect your script and your shell are different
okay, several things here:   you're not even remotely the only person that wants something like this (i've been looking for a good one for a while now). there are a couple of projects out there that attempt to fill this niche but none of the ones i have found are quite as simple to use as i'd hoped.     big update!  it looks like there is a wonderful soul out there that has finally accomplished nearly the perfect setup!  patat is a terminal presentation tool written in haskell which uses pandoc to parse the slides
you can escape the $ with \:  rm \$file  
you're deleting the \;
the setting is edited in the ppd file: /etc/cups/ppd/foo.ppd where foo is the printer name.  the normal way to modify these settings from the command line is the lpoptions command
seems the easiest way is to redirect output to a file and then to source this file.  in script it will look like:  #!/bin/sh program &gt; tmp_file 
going through lib/quotearg.c  in the coreutils source reveals that the quoting is dependent on your locale setting
i've got it installed
the "stuff" between the values seems a visual representation of the newline character to me ( octal character code 12), which you would get when using:  echo -e 'a\012b'   what you could try is pipe the output through tr '\n' ' ' as with:  echo -e 'a\012b' | tr '\n' ' '  
the docs, which say they're valid for samba 3 and 4, say:  "...make sure, that your smbd is compiled with cups support:"  # smbd -b | grep cups    have_cups_cups_h    have_cups_language_h    have_cups    have_libcups  
the protocol specification doesn't set any explicit limits
this sounds like your mint installation has kexec installed.  kexec is a system call which tells the kernel to load another kernel image, and to jump to its entry point
before reading the other responses, my guess was that pid_t exists for portability reasons
the c- notation doesn't refer to actual keyboard hardware combinations
there are two ways: an implicit and an explicit.  first way — stopwhenunneeded=  the first way is to use the stopwhenunneeded= directive
yes, it is possible to install linux from another linux install
there is no way, but to prevent this i like using tmux
tasks do represent the number of opened processes
$_ does not seem to be an environmental variable in bash, bash only appears to export it into a child process' environment
in kde's settings manager (kcontrol), you should find a "default applications" entry under "workspace appearance and behaviour"
that log looks like the effect i get from pulling out a usb drive without unmounting and reinserting
you can do that using command substitution, like this:  more "$(perldoc -l www::mechanize)"  the command in parentheses will be run first in a subshell
yes, all you need to know is the process id (pid) of the process
ls is the best choice
the html-xml-utils package, available in most major linux distributions, has a number of tools that are useful when dealing with html and xml documents
the command ulimit -u shows the maximum number of processes that you can start
your question is about the features of bash, which is probably the shell you are using as command line.  for the switching part you can use cd - to switch back to the previous directory.  if you want to reference that previous directory in a command you can use $oldpwd like this:   cp $oldpwd/* .   also have a look at help pushd, help popd and generally man bash. 
it's under shell grammar, simple commands (emphasis added):     a simple command is a sequence of optional  variable  assignments  followed  by  blank-separated  words and redirections, and terminated by a control operator
$2 and $3 are in single quotes
there are two constituent parts here: the disk write cache, and the filesystem cache.  the disk write cache can be disabled using hdparm -w 0 [device]
you need to set up a kernel virtual address mapping for the location e.g.     mem_addr = ioremap_nocache(baseaddr + offset, size);   (you appear to have asked the same question twice - see enter link description here). 
the general format of sed commands is   [address[,address]] function    when a command has a single address, it operates on all lines that match that address
yes you can remove your password from popup authentication, as well as remove passwords in general or your keyring
if you have an account with sudo permission, you can run:  sudo passwd root   to unlock root password.  if you don't have sudo permission, you should boot into single user mode (by editing boot option if you use grub) or using a live cd, then editing /etc/shadow file (not /etc/passwd) to remove pair of exclamation mark !! or ! before hash password, example:  root:!!&lt;hash password here&gt;:9797:0:::::   after that, reboot and now you can log in with root again. 
group varies when creating subdir:  drwxrwx---+ 28 admin sftponly 4.0k oct 22 15:19 .. dr-xrwx---+  2 admin *users* 4.0k oct 22 22:41 subdir   nested directory creation possibly restricted by the subdir's distinct group. 
so what i did is that i trimmed the list file down to the first two values (id;name), then i used this script on the source text file:  #!/usr/bin/env bash  dos2unix "$1" sed -e '/sideboard/,$d' "$1" -e '/^$/,$d' | tee source_strip | cut -d ' ' -f 2- &gt;temp while ifs= read f; do   sed -n "s/\([0-9]*\);$f$/\.\1/p" list done &lt;temp &gt;ids sed -ni 's/^\([0-9]*\) \([a-za-z]*\)/\1\t\2/p' source_strip paste ids source_strip &gt; final cat final   of course this assumes an id number exists for every name search otherwise this won't properly work
susv2 susv3 posix 2008 
the answer is/isn't sexy, depending on your point of view.  perl is very useful
that depends on your distribution.   aptitude-based distributions (ubuntu, debian, etc): dpkg -l rpm-based distributions (fedora, rhel, etc): rpm -qa pkg*-based distributions (openbsd, freebsd, etc): pkg_info portage-based distributions (gentoo, etc): equery list or eix -i pacman-based distributions (arch linux, etc): pacman -q cygwin: cygcheck --check-setup --dump-only * slackware: slapt-get --installed   all of these will list the packages rather than the programs however
you need to change the priority of the web crawler
first, you need to massage the git branch output into a useable format  $ git branch   experiment * master   new feature  $ git branch | awk '/^\* / { print $2 }' master   now, you want to use that as an argument:  $ git pull --rebase origin $(git branch | awk '/^\* / { print $2 }')   (or you can use backticks as in psusi's answer).  this should be ok, the awk command should always match exactly one line, and i'm assuming you can't have spaces in branch names
it was found that the problem did not reside in the bbt offset as previously stated
try howto: the ultimate logrotate command tutorial with 10 examples from the geek stuff. 
ssh and ssl are entirely different protocols
let's break this down
mount() requires root (or cap_sys_admin on linux), but it is possible to specify a mountpoint in /etc/fstab that is allowed to be mounted by a user by using the users option
you can use head to print the first line and tail to search with grep starting after the header for the pattern.  head -n 1 file.csv &amp;&amp; tail -n +2 file.csv | grep "some pattern"  
solution : just reselect the remaining source from it's root folder, and then copy it in the destination, unless there are already folders with the same name
for util-linux  man cal:  -m, --monday  display monday as the first day of the week.    for freebsd according to this recent thread on the freebsd boards, you will need the deskutils port.  for ubuntu there is a bug report: seems you can either use ncal or the debian patch. 
you could wrap the cd and the femsolver into a backgrounded subshell, like so:  (cd currentcaseafolder; femsolver) &amp;   when they finish running you will messages something like the ones below.  [2]+  done                    ( cd currentcasebfolder; femsolver) [4]+  done                    ( cd currentcasedfolder; femsolver)  
put your data in the file data and run:  perl -csd -lne 'print if /\p{han}/' data   see also:   extract only chinese characters  
i found some useful code(even, it is not efficient way to handle the logs files)  #!/bin/bash  maxfilesize=10000000 #max file size 10mb while true do     python /root/rtt/rtt.py &gt;&gt; /root/script_logs/rtt.log      sleep 60     com=`du -b /root/script_logs/rtt.log`     file_size=`echo $com | cut -d' ' -f1`     if [[ "$file_size" -gt "$maxfilesize" ]]     then           echo ' ' &gt; /root/script_logs/rtt.log     fi done  
   should i output to a temporary file, then copy it over the final file only if the backup works?   not copy but rename.  but this is impossible for the backup script if it writes to stdout
it means the apparmor profile affecting the program /usr/sbin/nmbd has been removed ("unconfined") using the apparmor_parser tool
alternatively a traditional c-style for loop can be used:  for ((i=375; i&lt;=3500; i+=5)); do     echo $i done   this is perhaps less clear than using seq, but it doesn't spawn any subprocesses
i would use awk to do this:  awk '$1 ~ /^[0-9]+$/ {$2*=$2}; 1'   if first column is a number, multiply the second by itself
the base system is described in debian policy as all packages with required or important priority.  you can search for the packages that the required and important priorities are attached to with the aptitude utility.  aptitude search ~prequired -f"%p" aptitude search ~pimportant -f"%p"   debootstrap installs these packages during the setup process.  tasksel will then install whatever other roles you choose on top, normally standard is the default selection that is used.  on top of what is listed in the base system you will get    a kernel (thankfully) input/locale/dictionary packages. hardware packages
there are only a few places crontabs can hide:   /etc/crontab /etc/cron.d/* /etc/crond.{hourly,daily,weekly,monthly}/* these are called from /etc/crontab, so maybe an asterisk on this /var/spool/cron/* (sometimes /var/spool/cron/crontabs/*)   be sure to check at as well, which keeps its jobs in /var/spool/at/ or /var/spool/cron/at*/  also, instead of   su &lt;user&gt; crontab -l   just do this:  crontab -lu &lt;user&gt;  
in zsh, using zmv:  autoload zmv; alias zcp='zmv -c'  # this can go into your .zshrc zcp '/home/(*)/.bash_history' '~/user-bash/$1.txt'   in other shells:  for x in /home/*/.bash_history; do   u=${x%/*}; u=${u##*/}   cp "$x" ~/user-bash/"$u.txt" done  
if you really want to “write exactly bash scripts into makefiles” then you'll need to do it a bit indirectly
on linux threads count towards the ulimit -u count, but they don't show up normally with ps -a
control+ z suspends (tstp/sigstop signal) the most recent foreground process, which returns you back to your shell
creating a bootable centos usb using windows is possible with http://iso2usb.sourceforge.net/ 
try xargs command, for example:  cat file | xargs ls   or   cat file | xargs gzip -c  
as long as the device is used for ppp traffic, it is not possible to run at commands at the same time1. for this reason all modern modems will provide more than one serial interfaces, e.g
i think on debian cron writes logs in /var/log/syslog. if your system depends on rsyslogor syslogd you can check and uncomment either in /etc/rsyslog.conf or /etc/syslog.conf for line:  # cron.* /var/log/cron.log   and then restart services
use $(), not ${}  echo "your disk usage is $(df -h)."   note that df -h has multi-line output (one line for the header, and one for each mounted filesystem), so including it in an echo statement looks quite ugly.  you can work around that by being more specific about what you want to display (e.g
you could try something like this:  start on runlevel [2345] stop on runlevel [016]  chdir /opt/data/data_server respawn  post-start script     echo "service started at `date +"%f %t"` on `hostname`" | mail -s "service started" pqr@host.com end script  post-stop script   sleep 30 end script  limit nofile 8092 8092 setuid david exec ./data_server --file=../config/property.init --data_port=8080   the hostname command in the echo will print the server's hostname so you should be able to tell in the email what server it was restarted on. 
short: no  longer: shell scripts require a full filename, but you can define aliases for your commands to refer to them by various names
i think ifstat will help you :   [root@localhost ~]# ifstat -i eth0 -q 1 1        eth0  kb/s in  kb/s out  3390.26     69.69  
from man expr     arg1 % arg2      arithmetic remainder of arg1 divided by arg2   4 % 4 evaluates to 0 as that is the remainder     arg1 / arg2       arithmetic quotient of arg1 divided by arg2   4 / 4 evaluates to 1 as that is the ratio of these two numbers 
i'm guessing you're asking how they manage to update their systems without ever having down time
gnu ls provides the -x option to achieve that. 
passing the file through pygmentize-f terminal will attempt to detect the type from the filename and highlight it appropriately. 
given that it's a sempron with only 512 mb of ram
here is a code example which detects the desktop the environment and reloads the dynamic wallpaper background explicitly when required by the detected desktop environment.  the code should work with gnome 3, kde 4, unity and xfce
simple
for starters try something like this
not according to the man page, which only calls out the attach -r option to enable read-only mode.  also, in the source code, only the following line in cmd-attach-session.c sets the read only flag
here is a solution:  printf 'n file-%02d.tar\n' {2..100} |      tar -ml 716800 -cf file-01.tar documents/ 2&gt;/dev/null   where 100 is a number greater or equal to the number of volumes.  edit  setting a big number should not be a problem, though i tend to not take a ridiculous one.  an alternative could be a "next volume" script, that you can set with the -f option,   tar -ml 716800 -f './myscript file' -cf file.tar documents/ 2&gt;/dev/null   then in ./myscript put  #!/bin/bash  prefix="$1" n=1 while [[ -e "$prefix-$n.tar" ]]; do   ((n++)) done mv "$prefix.tar" "$prefix-$n.tar" echo "$prefix-$n.tar"   it will be executed at each volume end, and will move file.tar to the appropriate filennn.tar
i just looked at the maldet source code, and can see that the bug lies here, where paths are not properly quoted.  because the path is not properly quoted, the logic being performed fails (as it only looks at part of the path)
as far as i know apache2 is not a metapackage
while read -r f11 f12 f13 do   grep -qxfe "$f11" file2 &amp;&amp;    grep -qxfe "$f12" file3 &amp;&amp;    grep -qxfe "$f13" file4 &amp;&amp;    printf "%s\n" "$f11 $f12 $f13" done &lt; file1  
   is there any way to ask parted to print partition sizes in mib unit   instead of mb unit?   yes:  parted &lt;&lt;&lt;'unit mib print all'   or  printf %s\\n 'unit mib print list' | parted   or  parted &lt;&lt;\in                              unit mib print list in   same in interactive mode: launch parted and then enter unit mib print list 
13ushm4n's answer shows how to execute a script during shutdown, but if you want to track the amount of time your computer is on, there are tools for that
   where is $network defined?   this is a good question, and i've generalized it here.     how exactly is $network defined via the +networking +ifupdown elements?   afaict it isn't defined by that, it defines what services must (optionally) also declare any dependencies the facility has (?? -- see the question i posted and linked above)
in addition to sending them to the background, use the wait built in to wait for all background processes to finish before continuing.  for el in $test1_partition do     (scp david@${server_location[0]}:$dir1/pp_monthly_9800_"$el"_200003_5.data $test1/
as the filenames are newline separated in the file txtfile, you can read each file, check if the number of lines is equal to (or greater than 20), if so print the first 20 lines, else print newlines for the remaining lines:  while ifs= read -r f; do      lines=$(wc -l &lt;"$f")     if (( lines &lt; 20 )); then         cat -- "$f"          for ((i=20; i&gt;lines; i--)); do              echo         done     else          head -20 -- "$f"     fi done &lt;txtfile  
you would need to edit the file /etc/default/grub
in ubuntu 14 or ubuntu 15, you can use this command :  - first, you activate routing :  sudo echo 1 &gt; /proc/sys/net/ipv4/ip_forward   - second, you write a dynamic translation rule source ip address.  sudo iptables -a postrouting -t nat -s address/mask -o internet_interface -j masquerade   where adress/mask is a address range who don't have the internet access, and then internet_interface is the interface who have the internet access. example of this rule :  sudo iptables -a postrouting -t nat -s 192.168.7.0/24 -o ppp0 -j masquerade   i hope that this can help you. 
edit your "~/.bashrc" or "~/.bash_profile" to include the alias command.  add this line to your profile:  alias m="/usr/cti/my_scripts/magic.bash"  
the wait command waits for the background processes to complete:  startsetup1 &amp; startsetup2 &amp; wait report  
to save a file descriptor, you duplicate it on another fd
thanks for @muru to point out the librepo responsible for download.  the current workaround is define a debug_function and pass it to set_debug_log_handler (refer to download_packages.py ) in repo.py:  def download_payloads(payloads, drpm):     # download packages     drpm.err.clear()     targets = [pload.librepo_target() for pload in payloads]     errs = _downloaderrors()     try:          #start my custom code         def debug_function(msg, _):             print("##hole## msg:", msg)         librepo.set_debug_log_handler(debug_function)         #end my custom  code          librepo.download_packages(targets, failfast=true)     except librepo.librepoexception as e:         errs.fatal = e.args[1] or '&lt;unspecified librepo error&gt;'     ...   this repo.py file can be located by manually:  [xiaobai@xiaobai log]$ python -c 'import sys, dnf.repo; print(sys.modules["dnf.repo"])' &lt;module 'dnf.repo' from '/usr/lib/python2.7/site-packages/dnf/repo.py'&gt; [xiaobai@xiaobai log]$    [update] in fedora 24, the path is /usr/lib/python3.5/site-packages/dnf/repo.py.  and now i'm able to get the url http://ftp.jaist.ac.jp/pub/linux/fedora/releases/21/everything/source/srpms/r/readline-6.3-5.fc21.src.rpm:  [xiaobai@xiaobai test]$ dnf download --source readline [sudo] password for xiaobai:  using metadata from thu dec 31 19:18:09 2015 (1 day, 11:59:10 hours old) ... ##hole## msg: select_next_target: selecting mirror for: r/readline-6.3-5.fc21.src.rpm ##hole## msg: select_suitable_mirror: skipping rsync url: rsync://ftp.jaist.ac.jp/pub/linux/fedora/releases/21/everything/source/srpms/ ##hole## msg: prepare_next_transfer: url: http://ftp.jaist.ac.jp/pub/linux/fedora/releases/21/everything/source/srpms/r/readline-6.3-5.fc21.src.rpm ##hole## msg: prepare_next_transfer: resume ignored, existing file was not originaly being downloaded by librepo ##hole## msg: lr_download: downloading started ##hole## msg: lr_headercb: server returned content-length: "2493152" (converted 2493152/2493152 expected)                             ] ---  b/s |   0  b     --:-- eta ##hole## msg: check_transfer_statuses: transfer finished: r/readline-6.3-5.fc21.src.rpm (effective url: http://ftp.jaist.ac.jp/pub/linux/fedora/releases/21/everything/source/srpms/r/readline-6.3-5.fc21.src.rpm) ##hole## msg: check_finished_trasfer_checksum: checksum (sha256) 521bd47a3293e694190a237921a9954b20fa41d0e8e38183d186452d4cc62ac8 is ok readline-6.3-5.fc21.src.rpm                                                                                                             1.4 mb/s | 2.4 mb     00:01     ##hole## msg: lr_download_packages: restoring an old sigint handler [xiaobai@xiaobai test]$    of course, it could be better if dnf log this url for future reference, either retrieve from command dnf history or file /var/log/dnf.log. 
in bash
wicd is a very good wi-fi manager
when you press ctrl+x, your terminal emulator writes the byte 0x18 to the master side of the pseudo-terminal pair.  what happens next depends on how the tty line discipline (a software module in the kernel that sits in between the master side (under control of the emulator) and the slave side (which applications running in the terminal interact with)) is configured.  a command to configure that tty line discipline is the stty command.  when running a dumb application like cat that is not aware of and doesn't care whether its stdin is a terminal or not, the terminal is in a default canonical mode where the tty line discipline implements a crude line editor.  some interactive applications that need more than that crude line editor typically change those settings on start-up and restore them on leaving
fedora's selinux documentation is a good place to start
you can use apt-mark for that
why don't you just write  sed -i -e 's/a/a/g' messages.txt   the -i means "in place" 
get hold of a solaris install disk
i found the answer:  note this system is fedora 20.  selinux was denying clamscan from writing, creating and more to the system.  so follow the directions in the selinux troubleshooter on allowing clamscan the access and repeat for all accesses
ed is the standard editor, because you can use it to develop ed scripts and let it do its work, as you tested before, interactively
no
i think the problem is that you cannot use snapshot.debian.org directly as a source of packages
check the gnu sed manual (http://www.gnu.org/software/sed/manual/html_node/other-commands.html#other-commands) -- the i command is actually the i\ command, so you just need an extra backslash  echo match | sed -e '/match/i\\tline1\n\tline2' # ---------------------------^  
install gnome-alsamixer and a specific option is there: "headphone jack sense".   
as in the page you linked:     in line mode, term basically acts like shell mode (see shell mode)
when true exits, the read side of the pipe is closed, but yes continues trying to write to the write side
you're probably lacking the diffutils package, which will provide the cmp binary that postfix needs for its sanity checks
the syntax is:  find ..
short answer: you can't do this in general.  for your specific problem , to check to see if it's doing something, use top
i think rozcietrzewiacz found the main thig that's bothering you
the following script takes an argument like "file*.x" and applies it to find | sort to get a list of files to process
i found a simple solution with a small script
you will need to either type export histfile on the command line prior to starting the python interpreter (or running your python script) or add export histfile to your .bashrc file so that it is automatically exported when you login. 
there are some undocumented ioctls you can use to set non-standard speeds, provided the driver implements them
you can use feh:  feh --bg-scale /path/to/wallpaper   you can also set up bash scripts to change wallpaper to random one every x minutes(i use it with feh), get random wallpaper on each boot, etc
this because /usr/bin/x11 is a symlink to /usr/bin (the dot at the end means the same directory as the link is in ):  $ ls -l /usr/bin/x11 lrwxrwxrwx 1 root root 1 may  5  2013 /usr/bin/x11 -&gt; .   if you browse or cd to this directory, you are really just looking at /usr/bin. 
you could pass the whole pattern to awk  letter=a awk -v pattern="task .* $letter" -v rs='-+' '     $0 ~ pattern ' text.txt   or construct the pattern as a string in awk  letter=a awk -v ltr="$letter" -v rs='-+' '     begin {pattern = "task .* " ltr}     $0 ~ pattern ' text.txt   since awk variables are not prefixed with $, you can't embed them inside a /regex constant/ -- it's just text in there.  (it's my preference to put all awk variables at the front with -v) 
you can use the ignored-patterns style to exclude some completions.  zstyle ':completion:*:umount:*' ignored-patterns "^/run/media/$user/*"   under the default settings, you can still get completion for ignored patterns if there is no non-ignored candidate.  (this answer is for plain zsh using the compinit completion system
with setopt histignorespace, the command is removed from the current session history
you could use file to determine the type of the plist and if it is binary:   plutil -convert xml1 $file &amp;&amp; sed /*whatever*/  $file &amp;&amp; plutil -convert binary1 $file   otherwise of course you can just use sed (or perl) directly on the xml file
it should be closer to what you want if you add some more options to the end of your fstab entry:  ,uid=testuser,gid=sftponly  
is there any chage sort of command on aix? check /etc/shadow file thats where the expiry information is stored.  update: it seems there is a passwdexpired subroutine that can be loaded and checks the user's password to determine if it has expired
by default, (for xterm-type terminals) tmux uses a control sequence to automatically set the external clipboard/selection to whatever is copied
here are a couple additional options:   apt-cache depends &lt;package_name&gt; will give you dependency info about a package (installed or not) including suggests
how many partitions  i believe other, faster and better people have already answered this perfectly
other answers show how to download and compile dos2unix, but if you're simply looking to convert files from dos-style line endings (cr-lf) to unix-style line endings, there are several other approaches which shouldn't involve installing anything:   if you have tr:  tr -d '\r' &lt; input &gt; output  if you have perl:  perl -pi -e 's/\r\n/\n/g' input   (which converts the file in-place, same as dos2unix) if you have sed:  sed -i 's/^m$//' input   where you'd press ctrlv then ctrlm to get ^m.  
i would disconnect the command from its standard input/output and error flows:  nohup python3 -u &lt;script&gt; &lt;/dev/null &gt;/dev/null 2&gt;&amp;1 &amp;     ssh needs an indicator that  doesn't have any more output and that it does not require any more input
my first guess would be that you're mixing yum repositories
diskutil list   will show you the drives.  a partition is /dev/diskxsy.  so  dd if=/dev/diskxsy of=/backupimage.img   with the appropriate x and y should do it for you
use df -p:      -p, --portability           use the posix output format    $ df -p filesystem                    1024-blocks     used available capacity mounted on /dev/mapper/vg00-lv_root       14987656  4220264   9999392      30% / tmpfs                             4026908    60932   3965976       2% /dev/shm /dev/sda1                          487652    36259    425793       8% /boot /dev/mapper/vg00-lv_tmp         5916420    47636   5561584       1% /tmp /dev/mapper/vg00-lv_var        20027260  1683820  17319440       9% /var ...  
you're trying to use the generic modesetting driver, but you somehow got xserver-xorg-video-intel installed again
just run:  sudo status testing   that gives you the status of the running upstart service.  and with tail -f /var/log/syslog you can see if it is respawning.  the "hello world" goes is i think going nowhere.  i recommend testing with:  #!/usr/bin/python import time import os  with open('/var/tmp/testing.log', 'a') as fp:     try:         while true:             print &gt;&gt; fp, "hello world", os.getpid()             fp.flush()             time.sleep(5)     except exception as e:         print &gt;&gt; fp, 'exception', e         fp.flush()         raise   and run tail -f /var/tmp/testing.log in an other window. 
( this is bash )  printf "p1: 2 p3: 1 p7: 5\n" printf "\033[2a\033[4c3\033[2b\r"   will print p1: 2 p3: 1 p7: 5 and then change it to p1: 3 p3: 1 p7: 5.  general way of printing terminal escape codes is:  \033 value [ code  ,where example codes are: a - cursor up, b - cursor down, and c - cursor forward  here you have list of available escape codes. 
a bit dirty and there is probably a cleaner solution (maybe using selinux or grsec) but you can hide a process by mounting an empty directory inside of /proc/&lt;pid&gt;.  for example something like this :  mount -o bind /empty/dir /proc/42  will prevent regular users from seeing process 42.  they will however see that something is hidden as they will be able to see the mount point.  if you want to do this for a service you would have to do this everytime it is started, using its init script or whatever.  if you want to hide the pid only from a specific user, you could play with namespaces (maybe using pam_namespace) to have the mount bind done only in the namespace of the target user. 
it is for the sake of clarity
source: http://comments.gmane.org/gmane.linux.redhat.fedora.general/385326  install the xdotool package (available on f11...not sure if f14 has it) and then use one of the commands to move the mouse. 
if you just want to check whether two files are identical or not, use cmp. to get an output only for identical files, you could use  for f in ./*; do for i in ./*; do cmp -s "$f" "$i" &amp;&amp; echo "files $f and $i are identical"; done; done   diff tries to produce a short, human-readable list of the differences, and this can take quite a lot of time, so avoid the overhead if you don't need it. 
you could use nc -l as a method to do what you are looking for
the $terminfo special parameter in zsh is filled from data that comes from the terminfo database on your system.  in your case, it seems that the entry in the database for the terminal you're using is incorrect.  the terminfo database is indexed on the value of the $term environment variable.  so either $term is incorrect or the database is incorrect.  what terminal is that? is that the console of some bsd operating system? what does $term contain? are you logged in locally or logging in to some remote system (which may have a different terminfo database) over ssh/rsh? 
the easiest way would be to use a for loop of your shell of choice
the working directory does not affect your $path1, thus i guess what's happening can be understood if you do the same thing in a terminal, i.e.  $ cd ~/bin/red5-1.0.0 $ red5.sh   will not work either; what does work is one of the following:  $ cd ~/bin/red5-1.0.0 $ ./red5.sh            # note the relative path to the script   or   $ cd ~/bin/red5-1.0.0 $ export path=~/bin/red5-1.0.0:$path   # add the path to $path which is where  $ red5.sh                              # the shell looks for red5.sh   so, guessing that gnome-terminal works similar (regarding where it looks for executables), you could probably alter your script in one of these ways, too.  1: if your $path does not contain ., as kevin pointed out (how about other relative paths, btw?). 
you can use udevadm to get this information
the rsync command doesn't have a mechanism for handling this directly, so i would use a different approach
if you have a recent version of bash:  for i in {1..3}; do     for j in {10..50..10}; do         echo "$i $j"     done done   if you have an older version:  for i in {1..3}; do     for j in {1..5}; do         echo "$i ${j}0"     done done   or, using seq:  for i in $(seq 1 3); do     for j in $(seq 10 10 50); do         echo "$i $j"     done done  
see if your ls has the options:   -h, --dereference-command-line      follow symbolic links listed on the command line   --dereference-command-line-symlink-to-dir      follow each command line symbolic link that points to a directory   if those don't help, you can make your macro work without messing up cd - by doing:  (cd /rmn ; ls -l)   which runs in a subshell. 
you should be able to find all open ports in /proc/net/tcp and /proc/net/udp
this one worked for me for netflix:  mozilla/5.0 (x11; linux x86_64) applewebkit/537.36 (khtml, like gecko) chrome/41.0.2227.0 safari/537.36  but it doesn't work for amazon
in shell scripting, everything is a string
-size with a suffix of b is for 512-byte blocks, not bytes
you could do this by mounting the remote folder as a file-system using sshfs
yes you can consume all the inodes of a system
as @cutrightjm has mentioned apt-pinning is the solution.  if you create a file /etc/apt/preferences.d/backports with the following content  package: * pin: release a=jessie-backports pin-priority: 800   apt will always install packages from jessie-backports, except when you pin another package source with a priority higher than 800.  if you want to see all available versions of a package, their priority and which one will be installed, you can use apt-cache policy &lt;packagename&gt;. 
you can use any xmpp client afaik(facebook im is xmpp based). there is also an option of using non offical facebook messenger desktop version. http://messengerfordesktop.com/  can also try: empathy, kopete or emesene.  edit: pidgin works fine with facebook, make sure you have package: purple-facebook 
i'm guessing, but it looks like you want to block connections to port 21 and port 22 
as root user, and since fedora 20 uses systemd the more appropiated way to do this is through the hibernate target:  systemctl hibernate   if you want to do this as normal user, you could use sudo and add the following line on /etc/sudoers through the visudo command:  user hostname =nopasswd: /usr/bin/systemctl hibernate   other solution to allow hibernate with a normal user involves some thinkering with polkit.  to work without further problems, i suggest you to have at least the same size of swap that you have in ram(look at hibernation - fedora uses the same method). 
udev support running external programs  kernel=="sdb", run+="/usr/bin/my_program"  
/tmp is meant as fast (possibly small) storage with a short time to live (ttl)
bash has a printf builtin, which can around the same as we could learn in c
the standard trick for this kind of problem in awk is to use an associative counter array:  awk '{ print $0 "\t" ++count[$1] }'   this counts the number of times the first word in each line has been seen
use xargs:  $ command ls /proc | grep -v "^[0-9].*" | xargs   the command part is necessary because if your ls is aliased to ls --color for example, it adds non-printing escape sequences to its output that grep somehow searches through and produces undesirable results.    other options  if you don't mind your pwd changing:  $ cd /proc &amp;&amp; echo [^0-9]*   if you don't want to change your pwd:  $ pushd 
diff isn't doing any caching
you need to set the script permissions to executable:  chmod +x ./foo  # or sudo chmod +x ./foo ./foo  
you can definitely compile a new version of glibc and have it stored in a separate directory. the first thing you'll have to do is download the version of glibc that you want from http://ftp.gnu.org/gnu/glibc/.  run the configure script and set the --prefix= to something like /home/you/mylibs.  after you've managed to install it into that directory, you'll have to set your ld_library_path to the location of the new glibc.  you'll need to figure out any dependencies you may need to compile
. is the directory where you are.  .. is your directory's parent.  so the command would be cd .. 
if you have a 1k file occupying a 4k filesystem block, it will contribute 4k to the df output.  df calculates the number by asking the kernel for the free block count (with statfs/statvfs) and multiplying that by block size / 1024.  just divide by 4
this sed line selects sequences of chars and replace them with "
the pts/0 is telling you which "pseudo terminal" the user was logged in on
you can do this by using cron and ntpdate.  first set your timezone
the man page says:     -k, --key=pos1[,pos2]           start  a  key at pos1 (origin 1), end it at pos2 (default end of           line)
my xdotool help informs me that your two switches are the same (xdotool version 3.20150503.1),  --name          check regexp_pattern agains the window name --title         deprecated
you can entirely avoid the need to quote using here documents
use a ubuntu livecd with persistant storage.  create a file called casper-rw.  touch /media/casper-rw   then run the folowing command.  dd if=/dev/zero of=/media/casper-rw bs=1m count=128   you will then be able to boot into the livecd like normal, but any changes made will be saved in the casper-rw file. 
cp should do what you want
maybe you're interested into xv6; xv6 is a teaching operating system developed in the summer of 2006 for mit's operating systems course
there are various ways to do this
the way i implemented it was with an if with an error code check
yes :  id userlogin   this will show you uid(and name) of the userlogin, followed by his primary group gid (and name) then all the groups userlogin belongs to gid(s) (and name(s))  you can also specify some options like :   id -g userlogin     # gives only the gid id -ng userlogin    # gives group name instead of gid id -g userlogin     # gives list of group(s) id(s) id -ng userlogin    # gives list of group(s) name(s)  
from man timeout:      if  the  command times out, and --preserve-status is not set, then exit    with status 124
change ls | to ls -l |.  you have evidently aliased ls to ls -l in your shell (possibly a function and/or other options); use type ls to see what you're actually executing
   i want to know: what is the recommended method of checking all running   services across these systems?   since you are aware of chkconfig,service, and may be ntsysv,rcconf,   but you can check using below command which almost work in all flavor   ls -1 /etc/rc$(runlevel| cut -d" " -f2).d/s*   what is s* ?  the traditional init style makes symlinks that start with s, or k
i went to the directory /etc/x11 and took created a file default-display-manager (for some reason it was missing)
   i have also .1 as i can see from the content it is used for manual    yes, these are written in groff markup
the cat command outputs contents of the file .ssh/id_rsa.pub; the | (pipe) receives this text output and then sends (i.e
you don't have to run abrtd, no
creating a hardlink should probably be avoided, there's no need for one and a symlink is simpler and safer
you can probably just use the yum repo they include with the full dvd iso
   obviously if the system runs for days i might no get this information
certain cases of disk encryption require you to enter a passphrase during boot to unlock the root partition, else the system can't continue booting, because it can't get its data from disk.  only the boot partition won't be encrypted (or is unlocked by grub), so the kernel and the initramfs can still be loaded
well, if you use a variable on the command line like that, it will be split to words, but that happens after syntactical items like { (or if) are parsed
add at the end of your script:  read junk     see bash manual for more info. 
autocd was introduced into bash with version 4
you can use one of the five preset layout modes (tiled) to achieve this
a socket is a file for processes to exchange data
awk 'begin { fs=ofs="," } {print $0,$5-$3,$6-$3}' my_file 
try specifying playpath -y, like this:  $ rtmpdump -r rtmp://video4.earthcam.com/archives/mp4:abbeyroad_archives/2016/03/26/1700.mp4 -y mp4:abbeyroad_archives/2016/03/26/1700.mp4 -o ~/2016-03-26_1700.mp4   explanation  regarding the error netstream.play.streamnotfound, "nhjm" at mplayerhq.hu wrote:     rtmpdump wasn't able to figure out the app/playpath on its own, so you need       to tell it what they are:    "nhjm"'s full solution used both specifying app, playpath. however, for your needs, it seems to work simply by specifying playpath: -y mp4:abbeyroad_archives/2016/03/26/1700.mp4   man rtmp:     --playpath     -y path      overrides  the  playpath  parsed  from the rtmp url
mail spools are typically under here:  /var/spool/mail/$user   where $user is your username
with prompt="…$(build_prompt)", you're running build_prompt at the time of the assignment, i.e
the user that nagios runs as requires sudo rights just like with your normal account
   i want to replace the string group::000 with nothing,   that translates to s/group::000//g  and this  sed -i s/group::000//g myfile  should do the trick. 
assuming xz honors the standard set of commandline flags - including compression level flags, you could try:  tar -cf - foo/ | xz -9 -c - &gt; foo.tar.xz   
you can format the datafile with any of several scripting languages
you need to download something called steamcmd
when using bash -c type structures you need to put the whole command inside " characters. e.g  $ bash -c echo hello  $ bash -c "echo hello" hello   so in your case  env bash -c "exec ruby script.rb"   however, the env in this example doesn't really do much; did you mean env -i to create an initial environment?  also, unless there's some magic happening inside the bash startup scripts, you may not need bash at all.   env -i rubypath=/some/dir rubylib=/other/dir /path/to/ruby script.rb  
that package doesn't seem to be available in any of the default repositories
su -c "echo $hi" bela expands to the words su, -c, echo ​ and bela
one option is to use a perl regex, like this:  cat in.txt | perl -pe 's/(([^ ]+ +){4})/$1\n/g' &gt; out.txt   the regular expression said to find one or more not spaces followed by one or more spaces and group the previous 2 things in a set of 4 then add a new line after each match.  test case:  echo "snp200 snp1 snp100 snp32 1 13454356 0 2 0 0 0 2 2 2 2 1" | perl -pe 's/(([^ ]+ +){4})/$1\n/g' snp200 snp1 snp100 snp32  1 13454356 0 2  0 0 0 2  2 2 2 1  
quite simply, the package libxcursor1 contains it. 
this isn't supported out-of-the-box on any unix i know, but you can do pretty much anything with fuse
find 
i assume you are not running x
freebsd has clicolor.  on linux and any other system with gnu tools, you need to set ls_colors, grep_color, and grep_options='--color=auto', but even then you still need to run ls --color=auto
here is a quick one-liner that you can type in a terminal:  find 
the answer to your questions are maybe, and yes.  lsblk will hide empty devices -- however, in its case, it is only talking about partitions, not the data on those partitions
if you don't want to use the user's keyring at all, point gpg to a temporary keyring.  tmp= trap 'rm -rf "$tmp"' exit int term hup tmp=$(mktemp -d) export gnupghome="$tmp" gpg --import &lt;&lt;eof … eof gpg -e -r … myfile.txt   if you want to use the user's keyring as well, set gnupghome only during the import command and pass --keyring "$tmp/pubring.gpg" to the second gpg command. 
yes, this is by design.  the man page for systemctl disable says:     disables one or more units
depending on how your exact distribution is set up, /etc/init.d/cron start or variations thereupon might do the trick. 
it would be easier to use a named pipe to communicate with the processes than try to modify the fd whilst it's open
as maxschlepzig said you could use kill  for a 'polite' end to the process (prefer this for normal use), sent sigtstp:  kill -tstp [pid]   for a 'hard' kill, sent sigstop:  kill -stop [pid]   note that if the process you are trying to stop by pid is in your shell's job table, it may remain visible there, but terminated, until the process is fg'd again.  to resume execution of the process, sent sigcont:  kill -cont [pid]  
your best bet is going to be to write a script rather than trying to pass a big ugly command via ssh arguments
if you want to know what version is installed, just run:  rpm -q libxcb-devel   if you want to prevent upgrades to this package, you can add the package to the yum exclude configuration
why use grep, find can do the job:  find /home/user/logfileserror/ -maxdepth 1 -type f -name "xy_*" -daystart -mtime -1  
your problem is lines like this:  opt: cxxflags += -o3 -funroll-loops   while bsd make honors some += operations, this is generally a gnu make feature
moving mouse to bottom of the screen is usually enough to show bottom panel
you can use the technique described on this page:  http://fvue.nl/wiki/debian_4.0:_installing_gpg-agent  here's the gist:   install gpg-agent and pinentry program:  sudo apt-get install gnupg-agent pinentry-curses  add the lines below to ~/.profile
well, after experimenting for some time, it appears that the software of host1 (which i did not have direct access to) is configured so that user2@host2:user1 is actually a username.  hence ssh user2@host2:user1@host1 works. 
you script is far more complicated than it needs to be and has a few problems:   you use backticks rather than $(). your script ignores all but the first logical volume it finds. you assume that lack of a mount-point for an lvpath means that there are no logical volumes
system refers to the entire box.  if you buy a pre-assembled computer with a specific model name, the vendor would put that information into the system block
lslocks, from the util-linux package, does exactly this.  in the mode column, processes waiting for a lock will be marked with a *. 
a simple loop should be enough:  for i in {1..22} do     wget "ftp://ftp.ncbi.nih.gov/genomes/homo_sapiens/chr_${i}/hs_alt_chm1_1.1_chr${i}.fa.gz"     gunzip "hs_alt_chm1_1.1_chr${i}.fa.gz" done   the loop index doesn't have to be just numbers, you can get the mt, un, x and y files as well, with:  for i in {1..22} mt un x y   since the first set of numbers have to be zero-padded, you can use printf for that:  or:  firsti="$(printf "%02d" $i)" wget "ftp://ftp.ncbi.nih.gov/genomes/homo_sapiens/chr_${firsti}/hs_alt_chm1_1.1_chr${i}.fa.gz"   you can run a test for this each loop, but it's simpler to just move the characters (mt un x y) to a separate loop using the original wget. 
systemd does not support custom actions on units.  to explain "why": a unit is (primarily) something that participates in dependency graph
i'm not sure it can be done with a single find command, but it can certainly be done with a simple bash script
is all the writes in bytes that the partition has since it's creation
while openness is certainly part of it, i think the key factor is linus torvald's continued insistence that all of the work, from big to small, has a place in the mainline linux kernel, as long as it's well done
warning do not attempt to run this on a production machine
i have arch linux installed on my macbook pro 7.1 &amp; everything works perfectly.  for special keys -> pommed touchpad driver -> default works fine (has two finger scroll &amp; three finger middle click pre-configured).  i am not really sure about the two gpu things as i have only one nvidia 320m
i got this same problem a few weeks ago (debian wheezy 7.6) and after some days of troubleshooting i found out that there was a config file missing which was preventing to the cryptroot script on init-top to run correctly, hence it was not stopping to ask the password via ssh, killing the dropbear at the end of the sequence (init-bottom).  the config file is called cryptroot and should be under /etc/initramfs-tools/conf.d/ if i am not mistaken that config file should have been created automatically during install (i have read just one tutorial talking about that config file) but somehow it did not (tested in a physical server and in a vm, same os and versions)  it took me a couple of tries to configure it properly, since i could not find the proper syntax at that time
you can do this with awk, keeping track of numeric versus non-numeric columns and summarizing at the end:  #!/usr/bin/awk -f begin {     width = 0; } {        if (width &lt; nf)         width = nf;     for (n = 1; n &lt;= nf; ++n) {         if ( $n ~ /^[0-9]+$/ ) {             number[n] += $n;             total[n] += 1;         } else {             others[n] += $n;         }     }     print;     next; } end {     printf "sum";     for (n = 1; n &lt;= width; ++n) {         printf "%5d", number[n];     }     printf "\n";     printf "total";     for (n = 1; n &lt;= width; ++n) {         printf "%5d", total[n];     }     printf "\n";     printf "percent";     for (n = 1; n &lt;= width; ++n) {         if ( total[n] != 0) {             printf "%5d", 100 * number[n] / total[n];         } else {             printf "%5d", 0;         }     }     printf "\n"; }  
$@ could contain anything, even things which make your function suddenly syntactically invalid
it's helpful to remember that [ is actually a command, usually also available as test
running these two commands will give this mapping: prefix, /,/ (you'll need to hit / twice.) which will put you into copy mode and then search-backwards  bind-key / copy-mode bind-key -t vi-copy '/' search-backward   mapping / to search-backward causes you to (obviously) lose forward search which you might want because tmux sometimes puts the cursor at the top of the text in copy mode (e.g
i'm going on some examples of pdbedit output i found online
using your wget command i found the following file name after the download completed.  jre-8u45-linux-x64.rpm?authparam=1445366776_75a96af45f0e6aafeed6e8fe224c008d   rename the file to jre-8u45-linux-x64.rpm and you should be able to execute your rpm command.  mv jre-8u45-linux-x64.rpm\?authparam\=1445366776_75a96af45f0e6aafeed6e8fe224c008d jre-8u45-linux-x64.rpm   edit  your actual file name may differ
this has more to do with systemd rather than the kernel, and in short, it means you just had a clean shutdown
all the files there are x resources files for rxvt (most of them specifically for urxvt, the unicode-aware version of rxvt)
you can make it confirm before using a key with the -c option to ssh-add
- 1 month will subtract one from the month number, and then if the resulting date is not valid (february 30, for example), adjust it so that it is valid
a loop device is a particular type of block device, managed by the loop device driver
note that goto was a separate utility, so not part of the thomson shell per-se.  when you invoke the thomson shell as:  sh the-script   sh opens the-script on stdin (fd 0) as if you had written  sh &lt; the-script   instead.  the goto command will seek stdin back to the beginning (which obviously if stdin were a terminal and not a regular file wouldn't work) then look for the label in there and would leave the cursor in the file just after that
the [bash] man page says: "-c string if the -c option is present, then commands are read from string
i see three solutions using .last_dir
some answerer provided the right answer yesterday but deleted it, which i only saw in my inbox, so i can't tell who they are
you mention rhel in your tags, so i assume this is what you're using.  with rhel 6 and earlier, when you upgrade the tzdata package then it triggers tzdata-update
you can use kill -stop pid to pause a job and kill -cont pid to resume it
if i understand you correctly, you want to use the free space on sdd2 for creating another partition sdd3
shc  you can try the steps outlined on this website, titled: how to encrypt your bash shell script on linux using shc
this is, in general, not possible on unix
assuming gnu date(1):  mv sample.xml a"$(date +%y%m%d.%h%m)_$(date -d 'now +3 minutes' +%h%m)"  
assuming you meant :prev (:p is short for :print, not :previous), you can add a file to the list by editing it:  :e filename   or, if you don't want to switch to the new file immediately, you can add it to the list of arguments:  :argadd filename   the list of buffers is separate, while editing a new file does create a buffer, you can create a buffer without adding to the argument list:  :badd filename   to traverse the buffers, you can do :bn and :bp. 
take a look at setting up an ad-hoc connect 
no need for ls here
 as far as i can see the reconnection is immediate (although it sometimes takes some time for it to detect that connection is broken). i believe there's no lag between retries but you can set up it by using holdoff n where n is the number of seconds between the disconnection and next try to reconnect. as for a number of retries, it defaults to 10, but you can change it: with maxfail option you can get all the options by looking at man pppd.  
since you are on ubuntu 12.04, have a look at the i/o logging abilities activated via the log_input and log_output options.     log_inputif set, sudo will run the command in a pseudo tty   and log all user input
what you're really after is this:  % strings -e s ./hello   from the manual page:     for each file given, gnu strings prints the printable character sequences that are at least 4 characters long (or the number given with the options below) and are followed by an unprintable character.   since you have non-ascii characters: the option -e s tells strings to look for 8-bit characters instead of the default (regular ascii)
there is not -- unless you manually put it into the eeprom using sneep:     oracle serial number in eeprom (sneep) provides a software-accessible   chassis serial number (csn) for all oracle solaris hardware platforms.      sneep uses the system eeprom for persistent storage of the chassis   serial number and other important user-defined data such as asset   information, contract id, or the serial numbers of attached storage   devices.      the presence of the software-accessible serial number and other   service-related information can significantly simplify activities   related to system service and asset management.      without sneep, only a subset of the solaris-based hardware platforms   have a mechanism to maintain a software-accessible serial number.   among those platforms, there is a wide variety of mechanisms for this,   making consistent access to this information difficult.      sneep provides one simple and consistent interface to the management   of this information on all solaris hosts, domains, and zones
the better way to change the column separator and use columncommand:  sed 's/   */;/g' file | column -ts';'   which produce:  item code  active  description                                  store room  row  shelf  bin  on hand  38nutzsl  y       3/8"-16 hex zinc nut                         b           03   c      2    0  weld-al   y       weld, alum
you can launch any program with a different language by setting the lc_messages environment variable (or lang to include other regional settings besides display language such as sort order, number and date formatting, etc).  $ lang=en_us gnome-terminal   keep in mind that anything you launch from that terminal will inherit the language
the man pages on your system correspond to the software that's installed on your system
if you are an ordinary user on host2, you can see who is currently logged in from where with the who command, and who logged in from where in the past with the last command
description  from the lvmetad man page:     lvmetad is a metadata caching daemon for lvm
virtualbox images can be resized from outside virtualbox
the question is about using rpm metadata to retrieve information about package specific compile time options
try the unicode utility:  $ unicode ‽ u+203d interrobang utf-8: e2 80 bd  utf-16be: 203d  decimal: &amp;#8253; ‽ category: po (punctuation, other) bidi: on (other neutrals)   or the uconv utility from the icu package:  $ printf %s ‽ | uconv -x any-name \n{interrobang}   you can also get information via the recode utility:  $ printf %s ‽ | recode ..dump ucs2   mne   description  203d         point exclarrogatif     or with perl:  $ printf %s ‽ | perl -cls -mcharnames=:full -lne 'print charnames::viacode(ord) for /./g' interrobang   note that those give information on the characters that make-up that glyph, not on the glyph as a whole
(this answer is about xmodmap only
that is the title command, e.g,.  :title bad-window   in the manual:     title [windowtitle]      set the name of the current window to windowtitle
the simplest answer to check if a cronjob works when you expect it to (short of reading the man page) would be to add a simple cronjob that will report the date to a particular file:  0 * * * * date &gt;&gt; /tmp/cronjob.test   then check it the next day (or whenever) and ensure it's triggering when you expected it to.  i personally would recommend reading the man page instead—it's faster—but the above is the longer lazier way
rsync  with rsync it should be fairly easy to do, though not complete.  assuming ./new_main_directory exists, otherwise mkdir ./new_main_directory  rsync -a --include '*/' --include '*.mcp' --exclude '*' main_directory/ new_main_directory/   this would copy only the *.mcp files and the directory structure they lie in. you can always test rsync commands with the --dry-run option.  source: http://ubuntuforums.org/showthread.php?t=763833  cp  if you want to use cp, you can try something like the following.  for d in ./*/; do set -- "$d/"*.mcp if [ -e "$1" ]; then    # there is at least one .mcp file in $d    cp -rp -- "$d" ./new_main_directory/ fi done   source: find and copy directories containing file type 
this reads from stdin:  echo foo | tee &gt;(read line &lt;/dev/stdin; echo "internal $line")   you have to keep in mind that a process substitution acts "like" a file. it could be used where a file is expected
i have been searching for an answer to this, and the best i can do is go to system settings > notifications and turn "enable notifications" off
iscsi enterprise target (iet) is what you want.  on the server end, you tell iet to take a file or block device and expose it as an iscsi target.  on the client end, you run an iscsi initiator
since you can find the ip with host, add an entry to your /etc/hosts file with a new name to the same ip.  /etc/hosts  198.100.51.37  u_nyx.isthereanydeal.com   then:  $ ping -c 1 u_nyx.isthereanydeal.com ping u_nyx.isthereanydeal.com (198.100.51.37): 56 data bytes 64 bytes from 198.100.51.37: icmp_seq=0 ttl=48 time=69.157 ms  --- u_nyx.isthereanydeal.com ping statistics --- 1 packets transmitted, 1 packets received, 0.0% packet loss round-trip min/avg/max/stddev = 69.157/69.157/69.157/0.000 ms  
directories are special files, hence they have inodes.  you can test that with ls:  ls -li   or using stat:  stat -c '%f : %i : %n' *   example:  % stat -c '%f : %i : %n' * regular file : 670637 : bar.csv regular file : 656301 : file.txt directory : 729178 : foobar   the number in the middle is the inode number. 
your problem is that you try to enter c code into a shell prompt, this doesn't work for obvious reasons
here's a way:  $ crontab -l|sed -r 's/([^[:space:]]+[[:space:]]){5}//'  
honestly, systemd services shouldn't be running interactive events
the / sign is for path separator.  when you execute that command the result will be  report-07/05/13 but the shell will interpret like this  report-07 - parent directory  05 - subdirectory 03 - filename   if indeed you want the directory report-07/05 then first you need to create it with:  mkdir -p report-`date +%m\/%d` touch report-`date +%d`   if you want is just a file named date-m.d.y then it will be easier to change the separator  touch report-`date +%m.%d.%y`  
i think you mean pgid, which stands for process group id.  when a process is forked, it inherits its pgid from its parent
you don't need a live environment for this
i'm using linux mint 17.2 too:  # cat /etc/*release distrib_id=linuxmint distrib_release=17.2 distrib_codename=rafaela distrib_description="linux mint 17.2 rafaela" name="ubuntu" version="14.04.3 lts, trusty tahr" id=ubuntu id_like=debian pretty_name="ubuntu 14.04.3 lts" version_id="14.04" home_url="http://www.ubuntu.com/" support_url="http://help.ubuntu.com/" bug_report_url="http://bugs.launchpad.net/ubuntu/" cat: /etc/upstream-release: is a directory   there is an application installed by default called "startup applications", start it and try to add the following entry :    then reboot and lets see what happen : ) 
the problem is your semicolon/&amp;&amp;
there is a setup script available for node.js 0.12:  curl -sl https://deb.nodesource.com/setup_0.12 | sudo bash - sudo apt-get install -y nodejs   a little comment: in my humble opinion, it's a very bad idea to curl | sudo bash
some of the utilities installed as part of the package are perl scripts:  $ head -n 1 /usr/bin/mysql_fix_extensions #! /usr/bin/perl  $ head -n 1 /usr/bin/mysql_convert_table_format #! /usr/bin/perl   and so on... 
there is no mv command in the interactive mode of sftp
do you have ssh compression enabled?  this kind of scrolling and highlighting generates a whole lot of redundant terminal traffic; compression makes a huge difference over a remote link. 
by definition (at least, by a common definition), a 64-bit process can only see 264 bytes of memory
the answer is much simpler
so, i discovered a sort of a workaround that enables me to do what i want, these are the steps:   "snap" a window, by hitting ctrl + super + arrow key (same behavior as tiling a window, but this time in "snap mode") maximize the other window: it will fit in the space remaining after the "snapped" window resize the snapped window until you're happy   the other window will adapt its to the remaining space when you finish resizing.  learned after description in this post: http://segfault.linuxmint.com/2013/10/cinnamon-2-0-released/ 
step-by-step manual how to install to linux the multiple fonts from the specific folder:   open the terminal application and gain root privileges by typing su and the correct root password. go to the folder with the fonts by using cd command, e.g suppose, the user font folder is in downloads:  cd /home/**user_name**/downloads/fonts  copy the font files to the system-wide fonts directory /usr/share/font:  find 
local solution: use su yourself to login again
you could specify the file be created in /tmp by adding that value to /etc/pulse/client.conf:  cookie-file = /tmp/pulse-cookie 
personally , i do the opposite - i mark the end of previous output with my prompt:  ------------------------------------------------- dir:/python|14:49|skolodya@ubuntu: $ echo "helloworld" helloworld ------------------------------------------------- dir:/python|14:50|skolodya@ubuntu: $    the prompt itself can be modified in .bashrc or in any rc file that your shell uses to be something like this:  ps1='------------------------------------------------- $ '   add username or any other info as you wish  
the generated archive has a --list option, which you can use to list its contents.  for reference, i'm talking about this version in debian:  ii  makeself       2.2.0-1      all          utility to generate self-extractables   which generates this chunk in the script:  ms_help() {        cat &lt;&lt; eoh &gt;&amp;2  makeself version 2.2.0   1) getting help or info about $0 :    $0 --help   print this message    $0 --info   print embedded info : title, default target directory, embedded script ..
you can use sshfs to mount / on your desktop to /mnt/server/ on your pc
if you're running vt a.k.a
( sleep 300 ; echo "80" &gt; /sys/class/leds/blue/brightness ) &amp;   that way your script continues, or you restore control immediately, while a new background task of the script starts, with two commands: sleep, and echo.  the common error is trying to give either sleep or echo or both the &amp; which will not work as intended
the options in fstab are supposed to be used to remount it, applying the options specified ( which may not include rw access )
you can try the following to create a case insensitive filesystem in /tmp:  truncate -s 100m /tmp/vfat losetup /dev/loop0 /tmp/vfat mkfs.vfat /dev/loop0 mkdir /mnt/vfat mount /dev/loop0 /mnt/vfat   if you don't want to use tmpfs but ramfs instead, create a ram mount first:  mkdir /mnt/ramfs mount -t ramfs -o size=110m ramfs /mnt/ramfs   then follow the steps above to create the vfat placeholder file, filesystem and mount. 
running shell scripts under sudo is safe provided that sudo is configured to reset the environment
you have to use command substitution for this, i.e
sure you can use lsof to see what activity is currently taking place on the server
if you are referring to the tty, ie., not a terminal emulator running in x, you can change the font to a larger size, or a different font using setfont, or you can change the colours that the font is displayed in, which may increase the legibility for you.  for the former, see my answer to how to temporarily change font size in text console.  for the latter, see my answer to how to colourize the output of ls. 
you can use -type d in the find string:  find /path/to/target -type d -mtime 1  
it looks like you are hard-coding your shell in the .screenrc to bash, is that your login shell as well?  try commenting out that line and trying.  failing that, compare the value of your $path from outside of tmux/screen, from inside screen, and from inside of tmux?  if nothing jumps out from there, compare the output of env from all three setups. 
i don't claim to be an expert with iptables rules but the first command is making use of the connection tracking extension (conntrack) while the second is making use of the state extension.  data point #1  according to this document the conntrack extension superseded state.   obsolete extensions:   • -m state: replaced by -m conntrack   data point #2  even so i found this sf q&amp;a titled: firewall questions about state and policy? where the op claimed to have asked this question on irc in #iptables@freenode
in addition to iostat you should also consider atop ( http://www.atoptool.nl/ ) to identify non-cpu bottlenecks
your problem(s) are in this line:  if `cat $htmlfile | grep -ine "\&lt;br\&gt;"` ; then   it's telling the shell to:   cat a file, parse it and look for lines that match the &lt;br&gt; tag, execute the output   the problem is the last step, you shouldn't execute the output of the command but test it:  if grep -ineq "\&lt;br\&gt;" $htmlfile ; then   of course, to parse html you should use a real parser, no regexes. 
for compiling kernel module you should create makefile and to include kernel module makefile /usr/src/share/mk/bsd.kmod.mk for example:  # note: it is important to make sure you include the &lt;bsd.kmod.mk&gt;  makefile after declaring the kmod and srcs variables.  # declare name of kernel module kmod    =  module  # enumerate source files for kernel module  srcs    =  module.c  # include kernel module makefile .include &lt;bsd.kmod.mk&gt;   and finally you run make to compile it so you can test it if it compiles properly. and as it is not presented in kernel modules (/boot/kernel/*.ko), but it is listed in sys/conf/files i think you should recompile your kernel to apply changes
the symlink points to the name of the real file (inode) in the file system
turns out the problem was actually the keyboard layout - switching to english (dvorak alternative international no dead keys) (xkbvariant="dvorak-alt-intl" in /etc/default/keyboard) fixed it.  unfortunately i can't find a way to set this for my user only. 
you should also ensure that you have the right to access (go through) the /home/nazeem/public_html and /home/nazeem folders
sysdig can monitor for these using the evt.type=kill filter:  # terminal uno perl -e 'warn "$$\n"; $sig{int}= sub { die "aaaaargh" }; sleep 999'  # terminal dos sysdig -p '%proc.pname[%proc.ppid]: %proc.name -&gt; %evt.type(%evt.args)' evt.type=kill  # terminal tres kill -int 11943  # or whatever   a more specific filter may be necessary to avoid e.g
in no particular sequence:   meld is a very nice diff program which does very nice diffs and three-way merges. git config --global merge.conflictstyle diff3 gets you three-way merge output for use with tools like meld. wdiff does word diffs, very nice if colored: wdiff -w "$(tput bold;tput setaf 1)" -x "$(tput sgr0)" -y "$(tput bold;tput setaf 2)" -z "$(tput sgr0)" ... to minimize cruft in the diff output, i usually use the --ignore-all-space (-w) option diff-ignore-moved-lines* does what it says on the label. difff* can be used to diff only lines which match in given fields.   * disclaimer: i'm the author, and developed these to help with cli and gui diffing and merging. 
use quotes:  $ ls "$(./myscript)"  
kill it!  #!/bin/bash killall epiphany   and btw: on my system (debian jessie) the process name is just epiphany. you can see the process list e.g
with gnu sed:  sed 's|\x22\x27|\x27|;s|\x27\x22|\x27|' file   output:   'this text' "that text" 'other_text'   see: http://www.asciitable.com/ 
i don't know of a method inside thunderbird, but storing the message as a file and dropping to the shell will reveal the information you're looking for.  getting verbose  gpg -vv will output very verbose information on the input, including the information you're looking for.  an example  an example of the output can be generated by encrypting and signing a message to your own key:  echo 'foo' | gpg --recipient a4ff2279 --encrypt --sign | gpg -vv   the slightly stripped output (removing bulky parts not relevant to the question at all) looks like:  :pubkey enc packet: version 3, algo 1, keyid cc73b287a4388025     data: [4095 bits]  [snip, gpg asking for passphrase]  gpg: public key encrypted data: good dek :encrypted data packet:     length: unknown     mdc_method: 2 gpg: encrypted with 4096-bit rsa key, id a4388025, created 2014-03-26       "jens erat (born 1988-01-19 in stuttgart, germany)" gpg: aes256 encrypted data :compressed packet: algo=2 :onepass_sig packet: keyid 8e78e44dfb1b55e9     version 3, sigclass 0x00, digest 8, pubkey 1, last=1 :literal data packet:     mode b (62), created 1418376556, name="",     raw data: 4 bytes gpg: original file name='' foo :signature packet: algo 1, keyid 8e78e44dfb1b55e9     version 4, created 1418376556, md5len 0, sigclass 0x00     digest algo 8, begin of digest 81 67     hashed subpkt 2 len 4 (sig created 2014-12-12)     subpkt 16 len 8 (issuer key id 8e78e44dfb1b55e9)     data: [4095 bits] gpg: signature made fri dec 12 10:29:16 2014 cet using rsa key id fb1b55e9 gpg: using subkey fb1b55e9 instead of primary key a4ff2279 [snip, trust validation] gpg: binary signature, digest algorithm sha256 gpg: decryption okay   interpreting the output  if gnupg only prints algorithm ids (like for the compression), these can be looked up in rfc 4880, section "constants"
you do not need an svn login if you have direct file access to the svn database
you can use iptables-save and iptables-restore, or you can once more install firestarter and use the config file from the old machine. 
you don't need the paranoia at all
subversion  i would put the contents of the crontab under subversion control and only grant access to this user through sudo
curl www.google.de | lynx --stdin   as man lynx does help:     -stdin read the startfile from standard input (unix only).   as an alternative you could also ditch lynx and use pub instead, as pointed out here 
encrypt the data before storing it
yes from pacman wiki  to install a single package or list of packages (including dependencies), issue the following command:   # pacman -s package_name1 package_name2 .. 
there are a number of questions.  to the first bunch of questions, your computer's chipset doesn't support usb3
you need to have root access to add a user to the sudoers file
you meant to write from shh to shh2, right? to change the string, alias shh, to the string, alias shh2, just edit the korn shell rc file and re-source it
this following command will give you the name of focused application  xdotool getwindowfocus getwindowname  using this, you can write a wrapper-script to achieve your goal.  e.g.  while [ true ] do   focusapp=`xdotool getwindowfocus getwindowname`   if [ "xterminal" -eq "x$focusapp" ]; then           xinput disable bcm5974   else           xinput enable bcm5974   fi done   above code will run forever checking for focused application
quick and dirty  awk -f\[ 'nr==fnr { s[nr]=$1 ; } nr &gt; fnr { printf "%s[%s%s\n",$1,s[fnr],$2 ;}'   where   -f\[ tell awk to use [ as separator if in first file (nr==fnr), record line (using position in file as index) next file, print two field, and recorded value.  
summary: the primary reason for switching from gcc to clang is the incompatibility of gcc's gpl v3 license with the goals of the freebsd project
completion of the command (along with other things) is handled via bash readline completion
this is slightly modified from the instructions found here (and i haven't even checked if they work):   install the chkfontpath package from atrpms (click on either the i686 or x86_64 package, depending on whether you have a 32-bit or 64-bit machine). as root, install some packages you'll need for the following steps:  yum install rpm-build cabextract ttmkfdir wget  download the ms core fonts smart package file:  wget http://corefonts.sourceforge.net/msttcorefonts-2.0-1.spec  build the core fonts package:  rpmbuild -ba msttcorefonts-2.0-1.spec  install the core fonts package:  yum install --nogpgcheck /root/rpmbuild/rpms/noarch/msttcorefonts-2.0-1.noarch.rpm   
jobs submitted to the at daemon will send any output to you from stderr and stdout upon completion
how much do you know about the lan in question? i'm assuming you don't know anything just plugged in the cable or connected to wifi.   try requesting an ip address with dhcp
use xargs replacement string flag  you need to use the replacement string flag for xargs
use trap ' ' int before running python to tell your shell to ignore sigint and trap - int afterwards to restore default behavior:  memcache_start mongodb_start trap ' ' int python fg trap - int memcache_stop mongodb_stop   after the trap ' ' int line the shell is instructed to ignore sigint, but python is not affected by this
i wouldn't recommend this, but try:  eval "./script.sh $(./look_up_args.pl 234)"   this should work, but keep in mind that eval will evaluate whatever look_up_args.pl happens to output, meaning you leave yourself vulnerable to code injection.  a better option would be what @thrig suggested in the comments: use a standardized data format to pass data between tools
vim tries to resemble the syntax and semantic of vi command as much as possible
you could build a pxe boot server
yes, it is possible, please refer to http://www.blackmoreops.com/2013/10/30/add-official-kali-linux-repositories/  i added kali linux repositories in my ubuntu 14.04, and successfully installed kali tools like sqlmap, join-the-ripple.  the problem after adding kali linux repositories i found is lsb_release changed from ubuntu to kali
if you're running the bash shell, then &amp;&gt;/dev/null will redirect the standard output and error streams to /dev/null (it's the same as &gt;/dev/null 2&gt;&amp;1), but it won't run the ( ..
writing a .desktop file is not enough
you don't need patch for this; it's for extracting changes and sending them on without the unchanged part of the file.  the tool for merging two versions of a file is merge, but as @vonbrand wrote, you need the "base" file from which your two versions diverged
if you have a switch that support port mirroring you could do the following way   create a mirror port of your uplink, or if you have multiple level of switches(core, distribution, dep) make a mirror of your internet facing port to another port of this switch. install ntop on your *nix system
the syntax you used is wrong.  cmd &amp;2&gt;1 &gt;file   will be split down as  cmd &amp; 2&gt;1 &gt;file   this will   run cmd as a background job with no redirections in a seperate process (without a command!) will redirect stderr to a file literally called 1 and redirect stdout to file   the syntax you want is  cmd &gt;file 2&gt;&amp;1   the order of operations is important
      what shall be done to zfs pool to make it shareable?      you need to install the nfs server packages for your distribution and share the pool with the already mentioned command:  sudo zfs set sharenfs=on tank/home   see http://zfsonlinux.org/faq.html#howdoisetupshares  note that you might alternatively use the os native method to share a file system, i.e
maybe solarized? http://ethanschoonover.com/solarized  there's a bunch of projects that do similar terminal colorization schemes with an eye to usability. 
awk has a match function that does something that sounds like what you want  awk '{ print match($0, /[0-9][0-0]rest_of_your_pattern/) }' your_file   if no match is found then match returns 0 (and printed). 
this command will forward all tcp traffic arriving on the localhost interface (127.0.0.1) via port 33890 to port 3389 in the guest  $ vboxmanage modifyvm "xp" --natpf1 "guestrdp,tcp,127.0.0.1,33890,,3389"  
did you restart the sshd service after making the changes to /etc/ssh/sshd_config?  sudo /etc/init.d/ssh restart  ensure the chroot directory for the sftp user (in this case /home/lenny) is owned by root, not the sftp user
this should do the trick:  echo -n $ips | xargs --max-args=1 -i {} --delimiter ' ' --max-procs=0 \   sh -c "wget -q -o- 'http://{}/somepage.html' | egrep --count '^string'" | \   { num=0; while read i; do num=$(($num + $i)); done; echo $num; }   the idea here is to make separate counts and sum these at the end. might fail if the separate counts are big enough to be mixed, but it should not be the case. 
resend-message (esc-e) lets you create and edit a new message based on a previous one
you can use :  sudo dpkg-reconfigure tzdata   for configuring your timezone .  for updating time and date from internet use the following :  install  if ntpd is not installed use any one of the following command to install ntpd:   for rpm based:  yum install ntp   for debian based:  sudo apt-get install ntp    configuration  you should at least set following parameter in /etc/ntp.conf config file: server   for example, open /etc/ntp.conf file using vi text editor:    # vi /etc/ntp.conf   locate server parameter and set it as follows:    server pool.ntp.org   save the file and restart the ntpd service:    # /etc/init.d/ntpd start   you can synchronize the system clock to an ntp server immediately with following command:    # ntpdate pool.ntp.org   *for setting the time and date manually use the following syntax:   date --set="string"   for example, set new data to 2 oct 2006 18:00:00, type the following command as root user:  # date -s "2 oct 2006 18:00:00"   or  # date --set="2 oct 2006 18:00:00"   you can also simplify format using following syntax:  # date +%y%m%d -s "20081128"   to set time use the following syntax:  # date +%t -s "10:13:13"   where,  10: hour (hh) 13: minute (mm) 13: second (ss)  use %p locale’s equivalent of either am or pm, enter:  # date +%t%p -s "6:10:30am"  # date +%t%p -s "12:10:30pm"  
debian has a command that enables possibilities to choose a program from a list of programs that do something similar
after you do the kill -- -$group_id wait for all the processes to end
the problem is the error is happening before bash runs.  when you run a script starting with #! then the kernel looks at the rest of the line and runs that, with the filename as the first parameter
this variable is just for building the default ps1 shell prompt down below:  ps1='${debian_chroot:+($debian_chroot)}\u@\h:\w\$ '   so it is not essential to create the file, although it can be nice having the prompt identifying where you are.  as you can see -r tests for a file and if the user can read it, and if it exists, debian_chroot gets the content of it, so create /etc/debian_chroot inside the chroot with the wording you want
ok, so i guess your problem was that multiple-quote marks per line were pulling in more than you wanted because regex is inherently greedy - it will always match as much as possible if it can.  so the solution is to ensure you only match between the two double-quote marks, like:  grep -o 'class_name:"[^"]*"' script.js  
for squeeze use squeeze-lts if possible! (i386 and amd64 only...)  append this to your sources.list:  deb http://http.debian.net/debian squeeze-lts main contrib non-free deb-src http://http.debian.net/debian squeeze-lts main contrib non-free   and then run  apt-get update apt-get install -t squeeze-lts --only-upgrade bash   here is more detail on squeeze-lts: https://wiki.debian.org/lts/using  if you really want to patch debian lenny check out this gist (but rather consider updating to a newer distro!) 
you should log into your router via webinterface and add port redirection
go to http://packages.debian.org/, go to the bottom of the page, select your version of debian, enter dpkg-buildpackage as the keyword and click search
the output of smbclient -l remote-server contains the domain; the linked page shows an example:  smbclient -l zimmerman   the output of this command should look something like this:   server time is sat aug 10 15:58:27 1996 timezone is utc+10.0 password:  domain=[workgroup] os=[windows nt 3.51] server=[nt lan manager 3.51]  server=[zimmerman] user=[] workgroup=[workgroup] domain=[]      sharename      type      comment     ---------      ----      -------     admin$         disk      remote admin     public         disk      public      c$             disk      default share     ipc$           ipc       remote ipc     oreilly        printer   oreilly     print$         disk      printer drivers   this machine has a browse list:      server               comment     ---------            -------     hopper               samba 1.9.15p8     kernigan             samba 1.9.15p8     lovelace             samba 1.9.15p8     ritchie              samba 1.9.15p8     zimmerman               reference: http://www.tldp.org/howto/smb-howto-8.html 
glenn's answer is good; here's a refinement for multiple files:  md5sum file1 file2 file3 | # or *.txt, or whatever     while read -r sum filename; do         mv -v "$filename" "$sum"     done   if you're generating files with find or similar, you can replace the md5sum invocation with something like find 
mv "$dir_path"/* ... will not only move files but everything in "$dir_path"
according to this post titled: all vs
the localhost:11 is not a port is a display number (like a session number) regarding x11
mplayer wants to read from standard input (you can use keyboard shortcuts in the terminal as well as in the mplayer window) and to display messages on standard output
generally speaking ssh keys identify clients, not servers (well, at least for the keys in ~/.ssh)
here's a script that splits out the latex commands in a source file
linux usually has gnu sed, os x uses sed from bsd
some distributions (including ubuntu) separate packages that contain libraries into two packages: one containing the files needed to run programs that use the library, and a -dev package containing the files needed to compile programs that use the library
if you just want to join every 4 lines into one, you can do it with a recursive macro:  ggqaqqa4jj@aq@a   explanation:   gg go to start of file qaq clear any previously stored macro in register a qa start recording a macro in register a 4j join 4 lines into one j go down one line @a have the macro in register a call itself q stop recording @a call the macro in register a which will keep working on the file until it's done.   an alternative in perl  perl -ni -e 'chomp;print $_, $.%4? " ":"\n"' your_file   reference   record a recursive macro  
using just awk:  free | awk  'ors=""; end {print $2}'  explanation:  end prints just the last line  {print $2} prints just the second column  ors="" removes the trailing newline  or, another way with awk:  free | awk  'end {printf "%s", $2}'  
did you try the following syntax ?      http_proxy=http://address:port/ wget --proxy-user=username --proxy-password=password http://url  
generate v1/v2 ssh keys with ssh-keygen -t rsa1 or ssh-keygen -t rsa
with the perl rename tool (which is called rename on debian and friends including ubuntu, it may be prename elsewhere):  rename -n 's/(?&lt;!\.)jpg$/.jpg/' *  # -n makes it show you what it'll do,                                    # but not actually do it
all¹ x11 programs open their windows on the display indicated by the environment variable display
how about something like this in bash:  for file in abc.*; do cp "$file" "${file/abc/def}";done   you can test it by putting echo in front of the cp command:  for file in abc.*; do echo cp "$file" "${file/abc/def}";done  
you would first disable getty running on your serial port device /dev/ttys0 (or whatever it is named for your hardware) to free it (for example, by editing /etc/inittab and running telinit q - if you managed to steer away from systemd)  and then you would run pppd(8) on it (either manually with appropriate parameters or via additional tools like wvdial) 
use the -o option.  wifi-menu -o      wifi-menu -h  [...]       -o, --obscure  show asterisks for the characters of the password                      and store the password as a hexadecimal string  
ftp has quite a few commands
something like:  dd if=/dev/video0 | mplayer tv://device=/dev/stdin   works for me (soa#1) locally
the question has little sense
there is no such kernel option as far as i can tell
the -m or --match option is used to enable one or more extended packet matching modules with the given name(s)
for most http servers, nmap simply grabs the server header, so that could be enough
commands run by at don't run in the terminal where they were registered
try:  find 
an usb flashdrive on which the hybride iso has been written, cannot be re-partitioned with fdisk or gparted anymore because hybrid partitions (combining iso partition, gpt and mbr partitions) confuse fdisk and gparted
you need to copy the postinst file (and other similar files) to the package staging directory
when a child process is created with clone with the clone_newns flag, the child process gets its own mount namespace
u+1fb0 is not in the x.org standard compose map.  you can define your own compose map by creating a file .xcompose in your home directory
update: i dont know why or what happened since back then.
alternatively, if your date doesn't support %s, with many awk implementations, you can use srand() to get the current unix time:   awk 'begin{srand(); d = srand() - 3 * 30 * 24 * 60 * 60}; $1 &gt; d' &lt; a.txt   or use perl:   perl -ne'begin{$d = time - 3 * 30 * 24 * 60 * 60}print if $_ &gt; $d' &lt; a.txt   note that 3 months here are counted as a fixed period of 90 days of 86400 seconds each.  if instead you want: not before the same day of the month, 3 months ago at the same time of the day (if now is 2013-12-15 21:02:01, that would be since 2013-09-15 21:02:01 (91 days and 1 hour ago in a european union timezone for instance)), see @zelda's answer, or:   perl -mposix -ne 'begin{@t=localtime;$t[4]-=3;$d=mktime @t}                    print if $_ &gt; $d' &lt; a.txt   (with the caveat that on may 29 (non leap year), may 30 &amp; 31, jul 31st and dec 31st, the 3-months ago date will be the same as for gnu date -d '3 months ago').  if instead, you mean this month, the previous, or the one before the previous (if today is 2013-12-15, that would be since 2013-10-01 00:00:00), that would be:   perl -mposix -ne 'begin{@t=localtime;$d=mktime 0,0,0,1,$t[4]-2,$t[5]}                    print if $_ &gt;= $d' &lt; a.txt  
use this:  $ dpkg --get-selections | grep -o "^linux-image-$(uname -r)" linux-image-3.13.0-32-generic   or  $ dpkg -l | grep -o "linux-image-$(uname -r)" linux-image-3.13.0-32-generic   edit: if you have multiple versions of the same kernel release, run the following bash script:  #!/bin/bash rel="$(uname -r)" ver="$(uname -v)" current="${rel%-*}.${ver:1:2}" echo "$(dpkg -l | grep -po "linux-image-${rel}(?=\s+${current})")"  
the source-tree is a directory which contains all of the kernel source
can you please provide more details. like the partition table, how comfortable you are with grub, etc.  you may want to set root (not boot) to (hd0, x)  x being 6 implies it's the second logical disk in the extended partition on your hard drive, is this correct?  if you have a chance, burn a cd/make bootable usb (faster!) and boot ubuntu or mint from it (or your favourite distro of linux), then you can chroot into your hard drive's linux partition and fix grub from there
the problem is that tmux does not expect a control0.  in key_string_lookup_string, it strips off the modifiers, and then (because you have the control modifier) tries to convert it from something like ^a (see source code)
the \{7\} construct is a simple case of the \{m,n\} for "match at least m and at most n, in your case it'll be:  sed -e 's/\(aaaa[a-z]\{2\}[0-9]\{7,8\}\)xxxx/\n\1/g'   perhaps a simple:  sed -s 's/xxxx//g'   is enough in your case? 
do this way instead:  find 
you can use grep to check if the directory is listed in your exclude file, as shown in this answer on so:  #!/bin/bash  #start time=`date +%y-%m-%d_%hh%mm`     # append date and time to backup file srcdir=/srv                      # location of directories to backup desdir=/srv/backup               # destination of backup files exclude=exclude.txt  # file which defines what to exclude from archiving  for dir in $srcdir/*/ do   base=$(basename "$dir")   if grep -fxq "$base" $exclude   then     echo "$base excluded"   else     tar -cpzf $desdir/$base-$time.tar.gz $dir   fi done #end  
unless you're sure you're never, ever, going to want to have windows 8 back on the system and you really need every byte that can be made available from the 1tb drive, i would leave all those partitions as they are
$ type set set is a special shell builtin   since set is a shell builtin, it is documented in the documentation of your shell.   beware that some systems have man pages for shell builtins, but these man pages are only correct if you're using the default shell
i think you're probably looking for containers.  or perhaps not
just add the base64 encoding of newline (cg==) after each file name and pipe the whole thing to base64 -d:  find 
you need to add 30 08 02 * * and \;  # crontab -e 30 08 02 * * /bin/find /home/admin -type f -exec /bin/rm {} \;   now it will work. 
this is not an error message generated by grep, but by man
that's a known (1, 2, 3, 4, 5, 6) limitation of the gnu implementation of tr.  it's not as much that it doesn't support foreign, non-english or non-ascii characters, but that it doesn't support multi-byte characters.  those cyrillic characters would be treated ok, if written in the iso8859-5 (single-byte per character) character set (and your locale was using that charset), but your problem is that you're using utf-8 where non-ascii characters are encoded in 2 or more bytes.  gnu's got a plan to fix that and work is under way but not there yet.  freebsd or solaris tr don't have the problem.    in the mean time, for most use cases of tr, you can use gnu sed or gnu awk which have been internationalised.  for instance, your:  tr -cs '[[:alpha:][:space:]]' ' '   could be written:  gsed -e 's/( |[^[:space:][:alpha:]])+/ /'   or:  gawk -v rs='( |[^[:space:][:alpha:]])+' '{printf "%s", sep $0; sep=" "}'   to convert between lower and upper case (tr '[:upper:]' '[:lower:]'):  gsed 's/[[:upper:]]/\l&amp;/g'   (that l is a lowercase l, not the 1 digit).  or:  gawk '{print tolower($0)}'   for portability, perl is another alternative:  perl -c -pe 's/([^[:space:][:alpha:]]| )+/ /g' perl -c -pe '$_=lc$_'   if you know the data can be represented in a single-byte character set, then you can process it in that charset:  (export lc_all=ru_ru.iso88595  iconv -f utf-8 |    tr -cs '[:alpha:][:space:]' ' ' |    iconv -t utf-8) &lt; russian-file.utf8  
after changing to backports kernel 3.2.0-0.bpo.3-amd64 there is no longer a wake of all drives between issuing reboot and message will now restart. appears, with or without swap being enabled
you can skip ctrl+w v and just do:  :vert diffsplit &lt;other_filename&gt;  
assuming history files are hidden (beginning with .), i would do like:  ls -1 ~/.*history   with output:  /home/birei/.bash_history /home/birei/.mysql_history /home/birei/.ptksh_history /home/birei/.sqlite_history /home/birei/.xsh2_history /home/birei/.xsh_history   execute:  for hist_file in ~/.*history; do cp "$hist_file" "$hist_file$(date +%m%d%y).txt"; done   and then:  ls -1 ~/.*history*   with following output:  /home/birei/.bash_history /home/birei/.bash_history07172012.txt /home/birei/.mysql_history /home/birei/.mysql_history07172012.txt /home/birei/.ptksh_history /home/birei/.ptksh_history07172012.txt /home/birei/.sqlite_history /home/birei/.sqlite_history07172012.txt /home/birei/.xsh2_history /home/birei/.xsh2_history07172012.txt /home/birei/.xsh_history /home/birei/.xsh_history07172012.txt   i hope it can be useful for your question. 
you may want to start with something like:  find 
pidof -x test.sh should give you what you need to get the pid.  from the man page,     -x     scripts too - this causes the program to also return process id's of shells running the named scripts.   here's my test,  tony@trinity:~$ ls -l testit.sh -rwxr-xr-x 1 tony tony 83 jan  5 14:53 testit.sh tony@trinity:~$ ./testit.sh 1000 999 998 997   meanwhile  tony@trinity:~$ ps -ef | grep testit.sh tony      4233 20244  0 14:58 pts/5    00:00:00 /bin/bash ./testit.sh tony      4295  3215  0 14:58 pts/6    00:00:00 grep --color=auto testit.sh   and then  tony@trinity:~$ pidof -x testit.sh 4233   your later query is a common issue, one solution is,  ps aux | grep test.sh | grep -v grep   which should give you only a single line (assuming test.sh is unique).  and lastly, in your final command, you're not just passing a single pid, you're passing a whole line of text, and that's not how ps expects to be given a pid anyway (it expects the pid after -p).  for example,  tony@trinity:~$ ps aux | grep testit.sh tony      4233  0.1  0.0   4288  1276 pts/5    s+   14:58   0:00 /bin/bash ./testit.sh tony      5728  0.0  0.0   3476   760 pts/6    s+   15:04   0:00 grep --color=auto testit.sh   so we need to grep out the grep, and then only return the pid.  tony@trinity:~$ ps aux | grep testit.sh | grep -v grep | awk '{print $2}' 4233   then,  tony@trinity:~$ ps -o stat --no-headers -p $(ps aux | grep testit.sh | grep -v grep | awk '{print $2}') s+   there are probably plenty of less convoluted ways to get there, but i wanted to show the progress. 
there is no ranking or inheritance between groups
currently, as i have not found an actual fix, my temporary workaround is to not invoke tmux in my .bashrc
you can compare just two numbers with dc like:  dc -e "[$1]sm $2d $1&lt;mp"   ..
naturally, you need to unmount any filesystems on the disk, and it'd be a good idea to deactivate any lvm groups (vgchange -an), and generally make sure nothing is using the disk for anything.  once you've done that, it should be safe to unplug
no
change the age of password to 0 day   syntax chage -d 0 {user-name}  in this case   chage -d0 foo   this works for me over ssh also  
ffmpeg -i "stream_link" -codec copy -f mpegts - -codec copy -f flv - |   myprogram -h 127.0.0.1 -p 12345 -f - |  myprogram -h 127.0.0.1 -p 12345 -f -   so if i understand correctly, you are tryithisng to combine these 2 commands into one
if you don't want rsh and rsyslog to be ever completed in any situation just add the following into .zshrc:  zstyle ':completion:*' ignored-patterns 'rsh|rsyslog'  
virt-install ..
this is just shell variable expansion by bash
this should work for bind9:  zone "foo.com" in {     type forward;     forwarders {         10.0.10.1;     }; };  zone "vpn.foo.com" in {     type forward;     forwarders {         8.8.8.8;     }; };  
for configuring the su path, have a look at /etc/login.defs:  env_supath      path=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin env_path        path=/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games   there are also a number of other places path can be changed, including:   /etc/environment /etc/bash.bashrc /etc/profile /etc/profile.d/* ~/.bashrc ~/.bash_profile   without anything special in per-user settings, su seems to be getting its path from /etc/environment and su - seems to be getting its environment from /etc/login.defs env_supath.  so on your system, my guess is that you have the same path value in /etc/login.defs as in /etc/environment, or you have some extra configuration in /etc/profile.d, /etc/bash.bashrc, or some rc file in /home/someuser. 
changing startupnotify from true to false in /usr/share/applications/gvim.desktop solves the problem.  source: http://www.phacks.net/open-multiple-text-files-as-tabs-gvim-kde4/ 
one portable way to remove such a file if only one exists:  set -- "${file_path}/${file_name}"* [ $# -eq 1 -a -e "$1" ] &amp;&amp; rm -- "$1"   it seems to me that if you don't care how many of these 'ant' files exist beforehand, but want them (all) gone when you're done, just:  rm -f "${file_path}/${file_name}"*   -- that way, if there were no such files, rm will (forced-quiet) not doing anything, but if there were (any -- 1 or more!) such files, rm will remove them. 
the alpine program does not support maildir format mailboxes out of the box, although there is a patch floating around out there somewhere that adds this feature
from vi you can type :cq to exit without saving and with a non-zero return code
to run google chrome as root, follow these steps:   open google-chrome in your favorite editor (replacing $editor with your favorite):  $editor $(which google-chrome)  add --user-data-dir at the very end of the file.  my file looks like this:  exec -a "$0" "$here/chrome"  "$profile_directory_flag" \   "$@" --user-data-dir  save and close the editor.   you’re done
the shell will read commands from your terminal (i.e
the simplest solution is to use gpt partitioning, a 64-bit version of linux, and xfs:   gpt is necessary because the ms-dos-style mbr partition table created by fdisk is limited to 2 tib disks
rm  "$(ls -1t fruits_*.gz | tail -1)"   the above gets the names of files, one per line, sorted by age (ls -1t) and deletes (rm) the last, that is, oldest, one (tail -1).  (the above would not work for all files, but since your files are sensibly named, it will be fine.)  another possibility, as per @anthon's comment, is to delete backups that are older than, say, 30 days
according to man readline:  $include     this directive takes a single filename as an argument and reads commands and bindings from that file
on linux systems there's the getent program, which utilizes the standard get*ent(2) functions (getpwent() being the one to use here)
with pulseaudio, you can just mute the application stream
try:  $ gawk 'begin{rs="\n2016"}; /user1/ {print}' input   this produces the output;  2016-05-31 09:54:36 (16667) heritage_w?   from: ip68-8-49-100.sd.sd.cox.net   user: user1wizard (wizard)   agent: mozilla/5.0 (windows nt 10.0; wow64) applewebkit/537.36 (khtml, like gecko) chrome/50.0.2661.102 safari/537.36   referer: http://dbase.apollo3.com/heritage_w?i=290   #accesses 3,435 (#welcome 415) since 03/07/2012 -05-31 09:54:41 (16677) heritage_w?w=   from: ip68-8-49-100.sd.sd.cox.net   user: user1wizard (wizard)   agent: mozilla/5.0 (windows nt 10.0; wow64) applewebkit/537.36 (khtml, like gecko) chrome/50.0.2661.102 safari/537.36   referer: http://dbase.apollo3.com/heritage_w?   #accesses 3,436 (#welcome 416) since 03/07/2012   notice that the second record is missing the initial 2016
you cannot kill a &lt;defunct&gt; (zombie) process as it is already dead
using 'sudo' instead of 'su' solved the problem, as suggested by mdpc. 
yes you can, zypper's man page has two example uris of doing just that.  man 8 zypper  cd or dvd drive        optionally with devices list for probing.         cd:///        dvd:/subdir?devices=/dev/sr0,/dev/sr1   you can add them repo zypper's addrepo command
if you are using firefox als your http-client there's the option to use the "tamper data" addon to investigate your http post requests (and even replay them with an editable set of data). 
if you use the same compilation options as ubuntu, and you also install the corresponding modules, and you regenerate the initramfs, this will work
it's considered good practice to install "local" programs that you've downloaded (and possibly compiled yourself) into /usr/local
terminal application itself has no relation to the feature you describe
with at least some versions of gnu diffutils' diff, you can use the -n flag to do that directly (although the documentation appears to say that only works for directory diffs).  $ ls foo $ cat foo foo $ diff -u foo bar diff: bar: no such file or directory $ diff -un bar foo --- bar 1970-01-01 01:00:00.000000000 +0100 +++ foo 2012-09-04 12:45:34.000000000 +0200 @@ -0,0 +1 @@ +foo $ diff -un foo bar --- foo 2012-09-04 12:45:34.000000000 +0200 +++ bar 1970-01-01 01:00:00.000000000 +0100 @@ -1 +0,0 @@ -foo $ diff -v diff (gnu diffutils) 2.8.1 copyright (c) 2002 free software foundation, inc.  
3 options, as i see it.  1 - disable browser plugins  i would say that the primary threat of java is by allowing it to be invoked from the browser
partprobe calls the blkrrpart ioctl, which is documented in, err, include/linux/fs.h, and beyond that the kernel source (the meat is in rescan_partitions()):  #define blkrrpart  _io(0x12,95) /* re-read partition table */   the easiest way to find this out is to run strace -e raw=ioctl -e open,ioctl partprobe /dev/sdb.  i think what you tried with /sys/*/*scan tells the kernel to check if there's been a change of drive
try (also from @iporsircer comment) this instead:  while true;do~/bin/ap; sleep 2; done 
creating an .onion service in the tor network is as simple as editing /etc/tor/torrc and adding:  hiddenservicedir /var/lib/tor/www_service/ hiddenserviceport 80 127.0.0.1:80   after restarting the tor service with  sudo service tor restart    or  sudo service tor reload   the directory will be created automagically, and inside the new directory, two files are generated, hostname and private_key.  the hostname file has a somewhat random name inside, that is your address in the .onion network
"formating" a partition is done by simply creating a filesystem on that device
this stackoverflow question asks a very similar thing, just not bash-specific
in linux, processes can be in different states:   running(r): this is a state where a process is either in running or ready to run. interruptible(s): this state is a blocked state of a process which awaits for an event or a signal from another process uninterruptible(d): it is also a blocked state
since piping directly didn't work, i tried connecting tail -f, sed and less +f via a temporary file
you could use tricks:  echo " $evar" echo  -e "\055e" echo $'\055e'   but as i said: those are tricks
you can use the stty command to set such parameters.  this will show all settings on the first serial port (replace ttys0 with ttyusb0 if using an usb serial port):  stty -f /dev/ttys0 -a   this will set the baud rate to 9600, 8 bits, 1 stop bit, no parity:  stty -f /dev/ttys0 9600 cs8 -cstopb -parenb   one thing that generally confuses people is that most serial drivers will reset the settings to the defaults once the device is closed (i.e
messages to the users go on stderr
yes setfacl should do it
i think it's essentially impossible because apple's a series soc used in the iphone is way different than the generic arm architecture for which ubuntu touch is targeted. 
'in-place' sed (usng the -i flag) was the answer
you can do something simple like this, which uses execpi to run a shell script every 30 seconds that parses the output of df / and converts it into a long string of conky color commands and \# characters (since # is used for comments):  ${execpi 30  df --output=pcent / | awk 'nr==2 {   n = ($1+0)/2; yellow = 20; red = 40;   if(n&gt;=red)   { r = "${color #ff0000}"; for(;n&gt;=red;n--)   r = r "\\#" }   if(n&gt;=yellow){ y = "${color #ffff00}"; for(;n&gt;=yellow;n--)y = y "\\#" }                  g = "${color #00ff00}"; for(;n&gt;0;n--)      g = g "\\#";   print g y r   printf "%50s"," "  }' } ${color}   my df --output=pcent outputs 2 lines; the second one is a percentage used, eg 69%
yeah, the versions of unison that you are running have to be identical
you can't
you could use find and xargs:  $ find some_folder -type f -name "*.bub" |      sed "s/\.bub$//" |      xargs -i% mv -iv %.bub %.aaa `some_folder/a.bub' -&gt; `some_folder/a.aaa' `some_folder/v.bub' -&gt; `some_folder/v.aaa' `some_folder/dr.bub' -&gt; `some_folder/dr.aaa' `some_folder/catpictures/or.bub' -&gt; `some_folder/catpictures/or.aaa' `some_folder/catpictures/on.bub' -&gt; `some_folder/catpictures/on.aaa'   ..
i think i know how it works.  i connected another disk to my machine because it has a big almost empty partition ~458g 
the usual setup is that x display managers run the /etc/x11/xsession shell script, and that script sources or runs scripts from the directory /etc/x11/xsession.d.  on the ubuntu family of distribution (and probably on other debian derivatives), one of the standard files in that directory sources the file .xsessionrc in your home directory, if it exists (it doesn't, by default).  if you create that file, you can put relevant commands inside it, including sourcing another .*rc file, or other command
like this?:  $ bluefish &amp; $ software-center &amp; $ unity-control-center &amp;   and one of  $ date $ cal  $ xclock &amp;    in practice, some programms write out some or many warning messages to stdout or stderr, which may clutter the terminal too much to use one terminal running multiple background programs, because you may see lots of mixed-up output, which you did not want to see in the first place.  so, if you had run a programm, it was writing errors and warnings (often in some subcomponent unknown to the programs author), but did work well enough, so you will not need the output actually use it, it makes sense to discard all output, from both output streams:  $ software-center &gt;/dev/null 2&amp;&gt;1 &amp;   if you may want to close the starting shell while the programms are still running in background, you could disown them from the shells job control, or use nohup to prevent the signal hup ("hangup"), that would trigger the termination, from reaching the programm.  $ nohup xclock &gt;/dev/null 2&amp;&gt;1 &amp;  
firefox's rendering engine will substitute glyphs from other installed fonts (if it can find one with the required glyph) instead of displaying broken glyphs
you can try this sort of things :  #!/bin/bash  ksh -c ' typeset -a arr arr['foo']=1 arr['bar']=2 arr['base']=3 print "${arr[@]}"'   or using a here-doc  #!/bin/bash  ksh &lt;&lt;'eof' typeset -a arr arr['foo']=1 arr['bar']=2 arr['base']=3 print "${arr[@]}" eof   disclaimer  as stated by @glenn jackman in the comments, the best you can do is to fully make your script in pure ksh, why bother you with a mix of bash &amp; ksh ?  output  3 2 1  
you should check sadf manpage to know exactly what option will show seconds since epoch time, there is a difference between versions of sysstat.  with my ubuntu 12.04.4 lts:  $ sadf -v sysstat version 10.0.3 (c) sebastien godard (sysstat &lt;at&gt; orange.fr)   with this version, option to show epoch time is -t:  -t     display timestamp (utc - coordinated universal time) in  seconds        from the epoch.   but with sysstat 8.1.2-2, this option is -d.  -d     this  option  is  equivalent to option -d below, except that the        timestamp  is  always  expressed  in  seconds  since  the  epoch        (00:00:00 utc 01/01/1970).  
the correct invocation according to the directory listings you gave would be:  -l/usr/local/lib/boost1.55/lib/ -lboost_system   -l is used to specify the path where libraries are found
i found it, but the solution may vary from whois server to whois server.  for whois.internic.net, use the keyword domain in your query:     often, the search finds more records than just the one wanted
find 
mapped_ratio  mapped_ratio can be calculated like so:  mapped ratio = (nr mapped * 100) / total memory;   source: https://www.cs.columbia.edu/~smb/classes/s06-4118/l19.pdf  nr_mapped  the value, nr_mapped can be read from /proc/vmstat:  $ grep nr_mapped /proc/vmstat nr_mapped 47640   distress  according to this article, titled: linux memory - implementation notes     “this is a measurement of how much difficulty the vm is having reclaiming pages
the command bash ./program.elf will send the file through the bash  interpreter.  an elf file is a compiled binary file and should run from the command line like so: ./program.elf  do not forget to set the executable bit for the file with:  chmod a+x ./program.elf  
don't use the -a switch.  diff -nur dir1/ dir2/   this will only output 'files dir1/afile and dir2/afile differ' on binary files. 
looks like you found the answer already
have you tried using rpmbuild -bi in testing, so that the you get everything built up through the %install phase? that should show you what's going on without automatically cleaning afterwards.  then when you're satisfied, build as normal. 
you can't really do this, because the user's fpath isn't set by a simple assignment in a key-value configuration file, it's set by a potentially complex script
this is used to get the filename from the full path
prepare your archive inside a fakeroot session
from the rpm guide:  defining installation scripts:     rpm supports a script run prior to installation, %pre, and a script   run after installation, %post
you sudo the command command, the redirection of the output to /some/file.log is done by your current shell, which is running as the normal user.  what you could try in order to get the output written by root is:  sudo bash -c "command &gt; /some/file.log"  
olivier d is almost correct, but you must set posixly_correct=1 before running unset
found this solution:  crontab -e i @reboot /opt/teamspeak3-server_linux-x86/ts3server_startscript.sh restart &lt;esc&gt; :wq  
luks doesn't “auto-unlock” a volume
in general it should be possible, if both hosts really have the same specifications (i.e
let's say we have an ipset named mytestset, and that this ipset is of type hash:ip
the blacklist is read by modprobe where insmod just tries to insert a module without bothering with dependencies or blacklists or anything.  insmod man page:  insmod is a trivial program to insert a module into the kernel
your issues with getting the ethernet adapter to show are likely a lack of drivers in the older kernel that would support the virtual nic that virtualbox presents
you could do that with ed:  ed -s infile &lt;&lt;\in 2&gt;/dev/null 1s/pattern/&amp;/ ,p q in   the trick here is to try to replace pattern on 1st line with itself
set the int signal to be ignored:  trap '' int   this will cause sigint, which is what ctrl-c sends, to do nothing to your script.  the user experience consequences of doing this are a bit unclear to me; this could be annoying if the script gets stuck in a operation that takes a long time to complete
you can use backticks (`) to evaluate a command and substitute in the command's output, like:  echo "number of files in this directory: `ls | wc -l`"   in your case:  wget `echo http://maps.google.be/maps?saddr\=$1\&amp;daddr\=$2 | sed 's/ /%/g'`  
either  rm ./--help   or   rm -- '--help'   see utility syntax guideline 10 in the posix.1-2008 specification for a description of the end-of-options indicator, -- 
aptitude update will update your software resources list and with this update you can upgrade your linux distribution
if your grep has it, try the -a1 option.  it looks like it is not a case of wrapping, but that the entry is on a separate line.  /usr/sbin/ss -i | grep -a1 &lt;some_ip_add&gt;   look at context line control in man grep.  an alternative would be to use   -p perl-regex  -z suppress-newline -o print only matching   as in:  ss -i | grep -pzo '.*ipaddress.*\n.*'   then you won't get the surrounding dashes which context gives.    an alternative could be sed:  sed -n '/ipaddress/{n;p}' # or joining the two lines by: ss -i | sed -n '/ipaddress/n;s/\n/ /p'   awk:  awk '/ipaddress/{print; getline; print}' # or as joined lines: awk '/ipaddress/{printf "%s ", $0; getline; print}'  
try  ls |  awk '{d=substr($0,6,2) ; printf "mkdir %s ; mv %s %s\n",d,$1,d }' | bash    in this case, you can use ls result as input. you'll get error message as dir exists after first mkdir, to get rid use :  awk '{d=substr($0,6,2) ; printf "test -d %s || mkdir %s ; mv %s %s\n",d,d,$1,d }'   
an “action in linux's terminal” is presumably a command that you typed at a shell prompt.  typical shells record a history of past commands
the difference is because of some shell quoting specialties.  if you execute either of these (they are equivalent ways of quoting in the shell)  git log --pretty=format:'%ad %s%d' git log '--pretty=format:%ad %s%d' git log --pretty=format:%ad\ %s%d git log --pretty=form'at:%ad %'s%d git log --pretty=format:%ad" "%s%d git log --pretty=format:"%ad %s%d"   git will get two arguments, the first being log and the second --pretty=format:%ad %s%d
problem  as you have discovered, gentoo only allows one profile setup at a time
 with newline  echo -en '-e\n'  without newline  echo -e '-e\c'  with spaces around:  echo '-e ' echo ' -e'  using backspace (thanks to joseph r.):  echo -e ' \b-e'    the behaviour of echo may depend on bash version, tested with gnu bash 4.2.53(1)
i don't think it is possible for standard cal, but you may want to take a look at gcal, the gnu calendar.  to highlight the text you need to pass -h option:  -h text --highlighting=text     set highlighting sequence / marking character pairs explicitly.     in this sense, highlighting sequences are control character sequences      which cause a color or intensity switch in output text
you can install thin as a runlevel script (under /etc/init.d/thin) that will start all your servers after boot.  sudo thin install   and setup a config file for each app you want to start:  thin config -c /etc/thin/myapp.yml -c /var/...   run thin -h to get all options.  read the thin documentation! 
what you most likely want to do is export the variables you are interested in
the meaning of the report is in the first two lines:  debugger entered--lisp error: (file-error "cannot open load file" "browse-kill-ring")   require(browse-kill-ring)   you are trying to load browse-kill-ring and emacs cannot do it.  you need to install this package before you can use it. 
please post the command you used? it's likely you just needed to escape the url because it had special characters to the shell such as apersands (&amp;).  example  $ curl http://tools.pingdom.com/fpt/#!/dnmig9/www.google.com bash: !/dnmig9/www.google.com: event not found   however if i put the url in single quotes:  $ curl 'http://tools.pingdom.com/fpt/#!/dnmig9/www.google.com' |&amp; head -10   % total    % received % xferd  average speed   time    time     time  current                                  dload  upload   total   spent    left  speed   0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0&lt;!--&lt;!doctype html public "-//w3c//dtd xhtml 1.0 transitional//en"         "http://www.w3.org/tr/xhtml1/dtd/xhtml1-transitional.dtd"&gt; &lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;--&gt; &lt;!doctype html&gt; &lt;head itemscope itemtype="http://schema.org"&gt;     &lt;meta http-equiv="content-type" content="text/html; charset=utf-8"/&gt;     &lt;meta name="description" content="use this free website speed test to analyze the load speed of your websites, and learn how to make them faster."&gt;     &lt;!-- google plusone --&gt;   other issues  sometimes you need to have cookies local or you need to be a certain type of browser or even have to appear to be coming from a particular url within the site
if it is an sh script - as in, it explicitly references #!/bin/sh - which might still be bash but would be like invoking it with --posix --no-rc --no-profile - then you can specify the env file with the env environment variable:  env=/path/to/rcfile sh   specific variables need either to be declared on the command-line - as above for $env - or else with export
i got this running
i apologize for bringing up this question again, but i figured i should assign a proper answer with what i have learned.     you can install from disk, but the installation can't repartition the disk or overwrite the partition containing the image from which you install
 you have to first exit the chroot session, usually a simple exit will do:  exit  then umount all binded directories:  umount /mnt/rescue/dev/ umount /mnt/rescue/proc/ umount /mnt/rescue/sys/  then:  umount /mnt/rescue      in case you were worried that sync isn't used here, note that it has no influence on whether unmounting is possible
you can use find with a negation (at your own risk).  find all file and folders named "a" or "b":  find -name a -o -name b   find all files and folders name "a" or "b" in the current directory"  find -maxdepth 1 -name a -o -name b   find all files and folders not named "a" and not named "b" in current directory:  find -maxdepth 1 ! -name a ! -name b   also exclude current directory from result  find -maxdepth 1 ! -name a ! -name b ! -name .   now you can use rm to delete all founded elements:  find -maxdepth 1 ! -name a ! -name b ! -name 
you submit a support call to ibm who then give you the hscpe user password, which is good for one day
i wouldn't call it multithreading as such but you could simply launch 70 jobs in the background:  for i in {1..70}; do     wget http://www.betaservice.domain.host.com/web/haschanged?ver=0 2&gt;/dev/null &amp; done   that will result in 70 wget processes running at once
all versions of find that i know will match underscores with wildcards.  be warned that when doing.  find 
you appear to be running the first example in bash, and the second in whatever is pointed to by /bin/sh, which is a posix shell requiring an argument to be passed specifying the variable you wish to put the input into
i have posted this as a comment, but will do so as an answer
it is a backup of the previous copy of the file that is version of the file  before the last change
you can get the columns to line up, without using the column command, entirely within awk, by doing  # fcinfo hba-port | awk '                         begin{man[-1]="hba_manufacturer"                               ver[-1]="firmware_version"                               sta[-1]="state"                               man[0]="----------------"                               ver[0]="----------------"                               sta[0]="-----"                               i=1                              }                         /manufacturer:/     {man[i]=$2}                         /firmware version:/ {ver[i]=$3}                         /state:/            {sta[i]=$2; i++}                         end {                              maxlen1 = maxlen2 = maxlen3 = 0                              for (j=-1; j&lt;i; j++) {                                  if (length(man[j]) &gt; maxlen1) maxlen1 = length(man[j])                                  if (length(ver[j]) &gt; maxlen2) maxlen2 = length(ver[j])                                  if (length(sta[j]) &gt; maxlen3) maxlen3 = length(sta[j])                              }                              for (j=-1; j&lt;i; j++) {                                  printf("%-*s  %-*s  %-*s\n", maxlen1, man[j],                                                               maxlen2, ver[j],                                                               maxlen3, sta[j])                              }                             }'   this reads the entire input text, storing the data (including the headers) in the man, ver, and sta (manufacturer, version, and state) arrays.  the column headings are placed in the [-1] entries, and the dashes (which form a line between the headings and the data) are placed in the [0] entries; these become the first two lines of the output (see below).  the actual data start at [1].  when it gets to the end of the data, it determines the maximum length of the data (including the headings) in each column, and then prints all the data (from the arrays), using the calculated column widths.   printf("%16s", "emulex") prints           emulex (ten initial blanks, followed by the six character name, for a total of 16 characters). printf("%-16s", "emulex") (note the -) prints emulex           (the six character name, followed by ten trailing blanks, for a total of 16 characters). printf("%-*s", 16, "emulex") does the same as printf("%-16s", "emulex"), except it gets the 16 from the argument list instead of the format string. so the above will produce output like  hba_manufacturer  firmware_version  state ----------------  ----------------  ----- emulex            2.82a4            online emulex            2.82a4            online emulex            2.82a4            offline emulex            2.82a4            offline emulex            2.82a4            online emulex            2.82a4            online   if you want more space between the columns, add spaces to the printf format.  for example, "%-*s    %-*s   %-*s\n" would give you something closer to the example output you show. the example output you show features a continuous row of dashes after the headers.  my command, as shown above, will give only a short row of dashes under each header.  this becomes even more obvious if some of your data are longer:  hba_manufacturer         firmware_version  state ----------------         ----------------  ----- emulex                   2.82a4            online emulex                   2.82a4            online some_other_manufacturer  2.82a4            offline emulex                   2.82a4            offline emulex                   2.82a4            online emulex                   2.82a4            online   this can be fixed, if necessary. this may fail if your input data are huge, because awk might run out of space to hold all the data. this might fail with a syntax error if you have an older version of awk (e.g., on solaris).  if that happens, try putting the printf statement all on one line, as      printf("%-*s %-*s %-*s\n", maxlen1, man[j], maxlen2, ver[j], maxlen3, sta[j])  
this type of issue can be tricky to debug
with awk setting the field separator and record separators to your use case:  awk 'begin { fs="\n"; rs ="" } /testvar/' yourfile testvar=test1 \         test2 \         test3  see the manual entry for multiple line records. 
if you're using / as delimeter with sed, a solution could be:  sed -i 's/..\/..\/..\/plumed.h/\/usr\/local\/include\/plumed.h/g' file   or, you can use a different delimeter than /, for example ::  sed -i 's:../../../plumed.h:/usr/local/include/plumed.h:g' file   another way with awk:  awk '{ gsub("../../../plumed.h","/usr/local/include/plumed.h"); print $0}' file  
i'll admit, nothing in the more documentation jumps out at me as saying that this will happen.  but, since you want to start displaying (outputting / processing) the input (list of files) at a specified line number (specifically, 11), the logical command to use is tail:  ls -r | tail -n +11 | …   a word to the wise: test things like this by piping into cat or xargs (with no command) before you do something dangerous like xargs rm. 
the original question asked how to grant users the capability to change file ownership
the kde application kruler should fit the bill.  to start kruler, choose graphics-&gt;kde screen ruler from your k menu.  the rotation buttons allow you to change it's orientation in steps of 90 degrees, or you can click your middle mouse button (if you have one) to change it to a vertical ruler. 
i have also run into this in the past (cant speak for ss specifically) this helped me out
the iwlwifi driver loads the microcode file for your wifi adapter at startup
you forgot to backslash the double quote when you wrote \\" which should be \\\"
drop the of=largerfile.txt and append stdout to the file:  dd if=/dev/zero bs=1 count=262144 &gt;&gt; largerfile.txt  
archiving old directories that you rarely access as tarballs can definitely improve the performance of a file-based backup system.     i wonder, is this a documented phenomenon (benchmarks?)   it's not really a "documented phenomenom" so much as a natural consequence of having to scan the filesystem and examine each file one by one to determine whether it needs to be backed up.  you could reduce the frequency of backups as faheem mitha suggests, but you may find it troublesome to maintain multiple backups at different frequencies (for oft-updated stuff and old archived stuff) or to maintain file exclusions lists and such
   sysctl kern.geom.debugflags=16   this solve it for me
the three block devices are logical volumes in an lvm volume group, fedora
found the cli tool
it's a bit more complex than what you're trying to do.  first, there are some syntax issues on your command
i got this by issuing the passwd command at the cli  -l, --lock                    lock the password of the named account   it locks the account so that root has to unlock the account before this person can log-in and use the account again.  edit as it was indicated this is a duplicate of this 
it's simply   locate some_file   if you are going to use wildcards you must enclose the name in quotes
ah, asked too quickly
grep "^[^#;]" smb.conf   the first ^ refers to the beginning of the line, so lines with comments starting after the first character will not be excluded
awk '{print $nf,$0}' file.txt | sort -nr | cut -f2- -d' '  
this is a security risk because file ownership in the fs is stored not by symbolic name, but by uid and gid
i think it's taking your + x as a time-zone specifier (e.g., consider 2013-04-25 19:52:36 +4 is a valid timestamp, in in a time zone 4 hours ahead of utc).  it's then seeing the word 'minutes', and treating it as a synonym of minute, so giving you one minute later.  if you put in an explicit timezone specifier, it works:  anthony@zia:~$ tz=utc date -d "1970-01-01 00:00:00 utc" +"%s"    0 anthony@zia:~$ tz=utc date -d "1970-01-01 00:00:00 utc + 0 minutes" +"%s" 0 anthony@zia:~$ tz=utc date -d "1970-01-01 00:00:00 utc + -1 minutes" +"%s"  -60 anthony@zia:~$ tz=utc date -d "1970-01-01 00:00:00 utc + 1 minutes" +"%s"  60   note the utc after the seconds field
you can make it:  has_ports() {   ls -a "/sys/devices/virtual/net/$1/brif/" 2&gt; /dev/null | grep -q . }  has_ports br0 || brctl delbr br0   or:  if ! has_ports br0; then   brctl delbr br0 fi   (note that you do need the -a as interface names are allowed to start with .).  to count the number of ports:  with zsh:  ports=(/sys/devices/virtual/net/$bridge/brif/*(dn:t)) printf '%s\n' "$#ports ports in $bridge"   (:t) to only have the file names instead of full paths.  with bash:  shopt -s nullglob dotglob ports=("/sys/devices/virtual/net/$brige/brif/"*) printf '%s\n' "${#ports[@]} ports in $bridge"   (note that ports contains the full paths as bash has no equivalent for zsh's :t).  both would return 0 for a bridge that doesn't exist. 
maybe you are looking for lpoptions ?   use lpoptions -l in order to know what's the name for your printer.  you can play it like thi (example with an hp photosmart) :   lp -o scaling=//100// -ocolormodel=kgray image.jpg  
you can just get rid of the autostart file in /etc:  rm /etc/xdg/autostart/orca-autostart.desktop   ought to prevent it from starting
you can use info command to know more details about any command in coreutils.  here is some portion in info ls, explain the -l option:  `-l' `--format=long' `--format=verbose'      in addition to the name of each file, print the file type, file      mode bits, number of hard links, owner name, group name, size, and      timestamp (*note formatting file timestamps::), normally the      modification time
my current best idea
/etc/init/tty1.conf (and others) has a line that says:  exec /sbin/getty -8 38400 tty1   just change the binary to qingy  in some versions, these files may be under /etc/event.d  you can do a lookup such as   sudo locate tty1.conf  
note that glance can be scripted:    # cat /opt/perf/examples/adviser/disk_sar    #the following glance adviser disk loop shows disk activity comparable   #to sar -d data.    #note that values will differ between sar and glance because of differing   #data sources, calculation methods, and collection intervals.  headersprinted = 0  # for each disk, if there was activity, print a summary: disk loop {   if bydsk_phys_io_rate &gt; 0 then {     # print headers if this is the first active disk found this interval:     if headersprinted == 0 then {       print "--------    device          %util   queue   r+w/s    kb/s    msecs-avserv"       headersprinted = 1     }     print gbl_stattime, "   ",bydsk_devname|15, bydsk_util|7|2,           bydsk_request_queue|8|2, bydsk_phys_io_rate|8|0,           bydsk_phys_byte_rate|8|0, bydsk_avg_service_time|16|2   } }  if headersprinted == 0 then   print gbl_stattime, "   (no disk activity this interval)"   to use that script :   glance -aos /opt/perf/examples/adviser/disk_sar  -j 5   here bydsk_util is the % of time the disk is busy during the collection interval.  read /opt/perf/paperdocs/gp/c/gp-metrics.txt  and /opt/perf/paperdocs/ovpa/c/methp.txt to see the available metrics.  if you prefere other tools
it is your ifs=: not set properly
 /usr/bin/ssh-copy-id: error: no identities found    this command only works if you have an identity previously created via ssh-keygen.  "common threads: openssh key management, part 1" 
the answer is easier than expected
in this case type has nothing to do with the bash built-in type, but more on that later on.  a little about "type"  the bash built-in type command gives you information about commands
xterm puts the variable windowid in the environment of its subprocess
there must not be any whitespace around = in variable declaration in shell.  remove the whitespaces:  num=0   also if you don't have any good reason, don't use all uppercases for a user defined shell variable name as there is chance that this could conflict with any environment variable.  better do:  number=0  
you can use p7zip
on my computer (111):  ssh -x 192.168.0.222   followed simply by:  xclock   will run xclock on the other computer (222) and display on my computer (111).  note: for this to work x11forwarding should be enabled in /etc/ssh/sshd_config at computer (222) 
ntpd is not responsible for syncing the local hardware clock
a chroot should not impact performance
you need to replace the form feed character (\f) with proper ansi escape codes.  you can do this with gnu sed:  sed 's/\f/\o33[2j\o33[0;0h/g' /dev/ttyacm0   in detail: \033[2j clear screen, \033[0;0h: go to pos 0,0  (if this does not work, try  tail -f /dev/ttyacm0 | sed 's/\f/\o33[2j\o33[0;0h/g') 
fn(){ printf %s\\n "${v-not set}"; } v=value; fn; unset v; fn     value not set   a shell function is a literal string stored in the shell's memory
touch calls the utimes system call to set the file's modification time and its access time
in bash (version 3.0 (2004) and above), ksh (since ksh93r (2006)) and zsh (version 5.0.6 (2014) and above):  touch {a..z}   (note that only zsh supports characters other than ascii letters and digits, none goes as far as perl's .. operator which inspired those shells operators).  with other zsh version (since 2.2 (1992)):  setopt braceccl touch {a-z}  
firmware:  firmware:       i915/skl_dmc_ver1.bin   many devices need two things to run properly
using --short option:  $ git rev-parse --short=5 head 90752  $ x=$(git rev-parse --short=5 head) $ printf '%s\n' "$x" 90752  
fedora 20 is considered old, unsupported
this is a case of an implementation detail that has leaked.  in a unix system, every directory consists of a list of names mapped to inode numbers
with awk:  awk '   /^end/ { sub("  ", "", indent) } # or { indent = substr(indent, 3) }   { print indent, $0 }   /^describe/ { indent = indent"  " } ' &lt;file  
in which i half-provide context, half rant  you're running into an example of the main reason i don't like managing solaris systems: nothing is ever just easy
some programs react to environment variables by selecting e.g
after fork, you have two copies of the same program
easiest way to do this from the command line is to use the passwd command with root privileges.  passwd username  from man 1 passwd  name        passwd - update user's authentication token synopsis        passwd  [-k]  [-l]  [-u [-f]] [-d] [-n mindays] [-x maxdays]        [-w warndays] [-i inactivedays] [-s] [--stdin] [username] description        the passwd utility is used to update user's authentication token(s).   after you set the user password, you can force the user to change it on next login using the chage command (also with root privileges) which expires the password.  chage -d 0 username  when the user successfully authenticates with the password you set, the user will automatically be prompted to change it
for gnu gzip 1.6 or above, freebsd and derivatives or recent versions of netbsd, see don_cristi's answer.  with any version, you can use shell redirections as in:  gzip &lt; file &gt; file.gz   when not given any argument, gzip reads its standard input, compresses it and writes the compressed version to its standard output
this link seems to be what you are looking for
just prefix it with ./:  less ./-   or use redirection:  less &lt; -   note that since - (as opposed to -x or --foo-- for instance) is considered a special filename rather than an option, the following doesn't work:  less -- -   # this does not work  
you can set a timezone for the duration of the query, thusly:  tz=america/new_york date   note the whitespace between the tz setting and the date command
the problem is service strips all environment variables but term, path and lang which is a good thing
under linux (or freebsd, netbsd, macos x) fuse comes to mind, it already features some archive file systems, that you should have a look at.  if the fuse-mounted virtual file system just passes through non-archive-files, this could be what you want. 
this is not answering you question, but this answer on su is solving your problem, i guess:  using proxycommand in your ~/.ssh/config should do everything for you:  host server   hostname server.tld   user {server user} host proxy   proxycommand ssh server -w %h:%p   user {proxy user}   then you can access your server simply by using ssh server 
the results of both has to be the same, in that a hard link is created to the original file.  the difference is in the intended usage and therefore the options available to each command
du == disk usage
the problem is that the redirections are not enough to have /dev/tty1 be considered as the controlling terminal for the login session.  why not to use the -a (autologin) option from agetty? example:  c1:12345:respawn:/sbin/agetty -a username 38400 tty1 linux  
when i used to use netflix on my pc the best solution i had available was to run windows xp inside of a virtual machine using virtualbox.  the virtualbox documentation actually does a fairly good job of explaining how to install and configure windows in a newly-created vm:  https://www.virtualbox.org/manual/ch01.html#gui-createvm  once the windows vm is installed and you have silverlight set up, you can get a movie playing, full-screen the browser window, then use your linux window manager to display it however you want--fullscreen, managed, or floating
try this iptables rule:  $ sudo iptables -t nat -a output -p tcp --dport 80 -j dnat --to-destination ip:80   the above says to:   add the following rule to the nat table (-t nat)
you could do something like:  tail -f example.log | awk '   begin {     n = split("pattern1,pattern2,pattern3,pattern4,pattern5", pats, /,/)   }   {     found=0     for (i in pats) if ($0 ~ pats[i]) {       found=1       delete pats[i]       n--     }   }   found {print; if (!n) exit}'   note that awk will exit as soon as it has seen all the patterns, but tail will only exit (of a sigpipe) only the next time it writes something after that.  or if lines may not match several patterns and if you don't care about exiting when all patterns are found, shorter but less efficient:  awk '/pattern1/&amp;&amp;!a++ || /pattern2/&amp;&amp;!b++ || /pattern3/&amp;&amp;!c++ || \      /pattern4/&amp;&amp;!d++ || /pattern5/&amp;&amp;!e++'   with zsh and gnu grep:  (trap '' pipe;tail -f example.log &gt; &gt;(grep -m1 pattern1) \                                   &gt; &gt;(grep -m1 pattern2) \                                   &gt; &gt;(grep -m1 pattern3) \                                   &gt; &gt;(grep -m1 pattern4) \                                   &gt; &gt;(grep -m1 pattern5))   but note that lines matching multiple patterns will be printed as many times. 
when you do &lt;(some_command), your shell executes the command inside the parentheses and replaces the whole thing with a file descriptor, that is connected to the command's stdout
i'm guessing that  sudo cp can't stat keepass-2.14.zip because $home is on an nfs mount, and the nfs server doesn't grant your machine root permission to the nfs share.  try:  cp keepass-2.14.zip /tmp sudo cp /tmp/keepass-2.14.zip /usr/keepass/  
you can mount an ramfs and store data there (as a file)  # mkdir /media/ram # mount -t ramfs none /media/ram # &lt;texfile grep pattern &gt; /media/ram/ram # cat /media/ram/ram # umount /media/ram  
you can use find:  $ find / -type d -name foo -print  
this is impossible: root can always access all data
you have mixed wheezy and  squeeze entires in your sources.list
i covered this pretty extensively in a blog post titled: command line tools for analyzing disk usage on fedora/centos/rhel
not so much a solution as a few nuggets of advice which may be helpful to consider if using tar/cpio/rsync etc
after learning bash i find that tcsh is a bit of a step backwards
irssi can't do it out of the box, but you can use the nicklist script to achieve the desired effect
instead of using modify and set wifi-sec.psk, use nmcli edit id myid and then activate in the interactive mode and it will prompt for password securely.    
in the end it wasn't too hard to do this manually, based on stéphane's and xenoid's hints and some prior experience with find. i had to adapt a few commands to work with freebsd's non-gnu tools — gnu find has the -printf option that could have replaced the -exec stat, but freebsd's find doesn't have that.  # create a list of "&lt;inode number&gt; &lt;tab&gt; &lt;full file path&gt;" find rsnapshots -type f -links +1 -exec stat -f '%i%t%r' {} + &gt; inodes.txt  # sort the list by inode number (to have consecutive blocks of duplicate files) sort -n inodes.txt &gt; inodes.sorted.txt  # remove the first file from each block (we want to keep one link per inode) awk -f'\t' 'begin {lastinode = 0} {inode = 0+$1; if (inode == lastinode) {print $2}; lastinode = inode}' inodes.sorted.txt &gt; inodes.to-delete.txt  # delete duplicates (watch out for special characters in the filename, and possibly adjust the read command and double quotes accordingly) cat inodes.to-delete.txt | while read line; do rm -f "$line"; done  
you need fgrep -f or grep -f -f:  if grep -fxq -f "$sites.txt" sites_old.txt then       : found something else       : nothing found fi  
as i understand it, you want to change a series of file in-place
as eddy_em suggested, just link to it:  mv ~/.bash_profile ~/dropbox/.bash_profile ln -s ~/dropbox/.bash_profile ~/  
the commandline parameters a and en can be accessed in shell scripts using $1 and $2:   #! /bin/bash zip -j version_"$1"_"$2".zip "$2"_filea1.txt "$2"_fileb2.json   care has to be taken when you have numbers following them in the text, that is why i always tend to put them in double quotes, but in this case you could leave them out. 
i don't know anything about amazon ec2, but you should be able to:    retrieve the name of the user running apache with a command similar to this:  ps aux | grep apache # the username should be in the first column.  retrieve the groups this user is part of with the groups(1) command:  groups [username]   
linux deletes a file completely differently than the way windows does
all values is correct and have different meanings./proc/sys/kernel/pid_max is maximum value for pid, ulimit -u is maximum value for number of processes.  from man 5 proc:  /proc/sys/kernel/pid_max (since linux 2.5.34)               this  file  specifies the value at which pids wrap around (i.e.,               the value in this file is one greater  than  the  maximum  pid).               the  default  value  for  this  file, 32768, results in the same               range of pids as on earlier kernels
you're hitting a quoting problem; the $5 is being interpreted at the wrong time
your comment is the right approach; if you have to use grep you should probably use -v
there sure is:  apt-get source fdupes   have a look here 
you can set up a "session directory" so that some data is stored and, when you exit rtorrent cleanly, you can open it without going through the hashing.  according to the manpage, this can be done using the -s path option, so -s ~/torrentdir would use that as session directory
in command mode:  :put =string(l)   string(expr) function convert expr to a string
you simply do  seq 1 n | xargs -n 5 echo   n being the number you want to reach  if your os has bash but not seq, here is an alternative (thx to @cuonglm and @jimmyj for their remarks)  echo {1..n} | xargs -n5   (you may have to be careful when reaching very high number with that one, depending on the os and bash version, and if bash actually tried to expand first or in that case is clever enough to feed little by little without trying to fit the whole 1..n as a string in memory and feed that to echo...)  and thanks to cuonglm and stephanechazelas, i add an alternative that is very, very less cpu heavy than my first xargs solution (in which xargs calls /bin/echo, instead of being able to use the shell's builtin, every 5 numbers) (it's probably similar to the 2nd one where xargs doesn't invoke echo) :  printf '%s %s %s %s %s\n' {1..n}   that 2nd and 3rd solution differs from the 1st in that the shell have first to expand 1..n, before printf (or xargs) can start printing, if i'm not mistaken..
ps1='\u@\h:\w \d \a\$ '   going to extremes of readability:  declare -a prompt=(     [user]='\u'     [host]='\h'     [dir]='\w'     [date]='\d'     [time]='\a'     [prompt]='\$ ' ) ps1="${prompt[user]}@${prompt[host]}:${prompt[dir]} ${prompt[date]} ${prompt[time]} ${prompt[prompt]}"  
kvm is normally supported already via libvirt and the kernels in modern distros without much hassle
use the -o flag between different parameters.  find ./ -type f \( -iname \*.jpg -o -iname \*.png \) works like a charm. 
btshowmetainfo, formerly included in the bittorrent distribution but now largely installed with bittornado (a fork of the bittorrent 3.x codebase), does just that.  $ btshowmetainfo amd64cd-5.1.2.iso.torrent  btshowmetainfo 20030621 - decode bittorrent metainfo files  metainfo file.: amd64cd-5.1.2.iso.torrent info hash.....: e30c05f2330ba4869eefb90bf5978a505303b235 file name.....: amd64cd-5.1.2.iso file size.....: 253325312 (966 * 262144 + 94208) announce url..: http://tracker.netbsd.org:6969/announce  
this isn't a capability of any of the common shells.  recent versions of att ksh have a unique feature among shells called discipline functions
you can use the "kill-pane" command.   kill-pane [-a] [-t target-pane]                (alias: killp)          destroy the given pane
don't know if that's still an issue for you but wanted to give a hint because i was in same situation today and found a solution for me, which builds a hybrid iso for i386 and amd64...  either export this before executing build-simple-cdd or put the whole line in your simple-cdd.conf:  export arches="i386 amd64"   hope this helps, marcel 
from less='+/tags' man ranger:   tags     tags are single characters which are displayed left of a filename
open terminal and ln -s /media/sf_fedora ~/documents/sf_fedora would create a symlink in documents folder. 
solution that worked for my machine with debian wheezy is comprised of two steps:   on two tty's create an autologin. after autologin, automatically start the x with given seat.   i will not post more details because both steps are distro-specific.  just a few notes:   autologin can be done for two distinct users but also for one user. for example in arch, one must start x on terminal where the user is logged, because otherwise the server will fail due to permissions on /dev/tty's
create a new file for terminal 1 '/lib/systemd/system/getty@tty1.service' and copy into it the config you defined above.  in /lib/systemd/system/getty@.service use the following:  execstart=-/sbin/agetty --noclear %i $term  console 1 will autologin as diagnosticuser all other consoles will prompt for credentials. 
first you should decide which protocol to enable
the key to what's happening is that it hung in modprobe: it's probably hung trying to load a module for a piece of hardware.  stuff to try:   add noapic to the kernel command line, and make sure quiet isn't present so you can see what's going on make sure your laptop's bios is at the latest version if you do manage to figure out which module is causing the hang, boot from a recovery cd and add modules to /etc/modprobe.d/blacklist.conf  
use the option noauto in /etc/fstab for that mount point to make sure the init process will not mount it at boot. you might have a line like this in /etc/fstab :  /dev/sda1  /mnt/your_partition  ntfs-3g  defaults,noauto  0 0  
run (as root) apt-get remove --auto-remove libgtk-3-common, and it should remove gnome-shell too, which is a large part of what's billed as gnome 3
quoting: in short, variables are not replaced with their values inside 'single-quoted' strings (aka
comment or delete the 3rd last line, as this looks very suspicious:   deb http://security.ubuntu.com/ubuntu/ trusty-security multiverse restricted main universe    note that you already have some security stuff defined in the 6th section of sources.list (lines 38ff.). 
in theory, in your c program, you should add a line like this:  int res = system("/bin/parted &lt;options&gt;");   the c program must be executed with root privileges (or run through sudo)
the right thing to do here is to set up bash to prompt for installation, as explained in samk's answer
short answer: ext4 is the standard file system on most linux distribution
apt-get update downloads the list of available packages.  the list of packages can change over time
there's no -t option for bsd-mailx, it's a bug regarding that error message
yes, info has support for pretty much any key binding scheme you like; see http://www.gnu.org/software/texinfo/manual/info-stnd/html_node/custom-key-bindings.html and note in particular the --vi-keys startup option for info. 
on debian, you can add the xvfb command to /etc/rc.local
i don't see how you can get atomic operation
hitting ctrl+a then esc should get you into a special mode to look through the scroll-back buffer much like hitting esc in vim gets you into a mode where you can navigate the file rather than inserting into it.  if your scroll-back buffer doesn't have enough lines in it to be useful you can change this in your ~/.screenrc file:  defscrollback 10000   once in the scroolback buffer, you can use common key bindings like j/k/h/l, pgup/pgdown, g/shift+g, ^/$ and arrows to navigate
the less than and symbol (&lt;) is opening the file up and attaching it to the standard input device handle of some application/program
i've split my answer into two separate answers so you can up/downvote the "wrapper" and "patch" approaches separately.  solution 1: write a wrapper function  ssh () {     controlpath=""     for argument in $@     do         if [[ "$argument" = "-"*"4"* ]]         then             controlpath="~/.ssh/tmp/%l_%r@%h:%p.inet"         fi         if [[ "$argument" = "-"*"6"* ]]         then             controlpath="~/.ssh/tmp/%l_%r@%h:%p.inet6"         fi     done      if [ -n "$controlpath" ]     then         /usr/bin/ssh -o "controlpath=$controlpath" $@     else         /usr/bin/ssh $@     fi }   this wrapper function will instruct ssh to create separate control sockets for ssh host, ssh -4 host, and ssh -6 host. it might not parse something like ssh -464466 host correctly (even though that's technically allowed), but it should be the easiest workaround for simple scenarios. 
presumably, your browser is interpreting whatever file you're pointing it to as html
your . trick can only be used when you're copying a directory, not a file
since darwin lacks lesskey (see here and here) i installed less 458 via macports and added the bindings using the defaults path for my system
you can use cmp for checking if everything was copied fine:  $ cmp -n `stat -c '%s' debian-x-netinst.iso` debian-x-netinst.iso /dev/sdx   this solution does not explicitly compute the checksum of your /dev/sdx - but you don't need to do that because you have already done this for the source of the comparison (i.e
why would you want to see unallocated space with partitions? you can see that between /dev/sda2 and /dev/sda3 is a gap (look at fdisk, end sector of sda2 and start of sda3).  you can always create the arch partition under gparted in ubuntu
in my experience the better way to manipulate pdf is via inkscape
how about simply using wget?  $ wget http://picasaweb.google.com 2&gt;&amp;1 | grep location: location: /home [following] location: https://www.google.com/accounts/servicelogin?hl=en_us&amp;continue=https%3a%2f%2fpicasaweb.google.com%2flh%2flogin%3fcontinue%3dhttps%253a%252f%252fpicasaweb.google.com%252fhome&amp;service=lh2&amp;ltmpl=gp&amp;passive=true [following] location: https://accounts.google.com/servicelogin?hl=en_us&amp;continue=https%3a%2f%2fpicasaweb.google.com%2flh%2flogin%3fcontinue%3dhttps%3a%2f%2fpicasaweb.google.com%2fhome&amp;service=lh2&amp;ltmpl=gp&amp;passive=true [following]   curl -v also shows some info, but looks not as useful as wget.  $ curl -v -l http://picasaweb.google.com 2&gt;&amp;1 | egrep "^&gt; (host:|get)" &gt; get / http/1.1 &gt; host: picasaweb.google.com &gt; get /home http/1.1 &gt; host: picasaweb.google.com &gt; get /accounts/servicelogin?hl=en_us&amp;continue=https%3a%2f%2fpicasaweb.google.com%2flh%2flogin%3fcontinue%3dhttps%253a%252f%252fpicasaweb.google.com%252fhome&amp;service=lh2&amp;ltmpl=gp&amp;passive=true http/1.1 &gt; host: www.google.com &gt; get /servicelogin?hl=en_us&amp;continue=https%3a%2f%2fpicasaweb.google.com%2flh%2flogin%3fcontinue%3dhttps%253a%252f%252fpicasaweb.google.com%252fhome&amp;service=lh2&amp;ltmpl=gp&amp;passive=true http/1.1 &gt; host: accounts.google.com  
your problem is not too few versions of git available, but too many; git is in the base/updates repo set, but a newer version is also in epel, and they are treading on each other's feet
cruft is a useful tool exactly for this purpose: it makes a comparison between a file system and the database of installed debian packages
!!:0 is the 0'th word of the previous command, and !!:* is all the words except the 0'th.  !!:0 -l !!:*   is the command you're looking for.  source https://www.gnu.org/software/bash/manual/bash.html#word-designators 
you can't without writing a bit of code.  those symlink shortcuts work because vim is written that way
i know not enough about lex/flex to be sure, but, given the code i see in the question, i'd try to add this code to main():  file * myfd = fopen(argv[2], "w");   and use fprintf() instead of printf(), as in:  { fprintf(myfd, "%s: is a verb", yytext); }   i used argv[2] as source of the file name, which means you have to provide it as second argument in the program call, but you can also hard-code a string with a file name. 
in general, the difference from a user perspective should be purely cosmetic
there are two approaches you can use
pushd expects the directory as a command line argument, not as standard input so you cannot pipe the directory to it
neither
remove the $ from the assignment line inside the loop
i somehow solve this by boot0cfg -t 18 device  that automatically boot in 18 ticks (about 1 second)
part of the answer depends on what you mean by your own distro
add a format string  printf '%s' '-xdebug'   or use -- to signal end of option processing  printf -- '-xdebug'  
you should not enforce encryption, otherwise you will not be able to seed for those who don't want or can't use encryption.  but most of the "best" seeding settings are in fact about knowing how your isp deals with the connection: setting up nat and opening firewall ports if needed, avoiding commonly blacklisted bittorrent ports, knowing if the isp is screwing with non-encrypted bittorrent traffic, and so on.  the vuze wiki has a nice list of isps and their quirks, a good place to look for information on your isp, if it's there, of course.  there is also a blog post with some patches to tweak the magic rtorrent does behind the curtains — although i never used these suggestions, and one of these is not even recommended (a change to lie about the seeding ratio), the others sound interesting. 
tell the person who suggested || that he's an idiot
you can't match files by full path with solaris find, but you can match files by inode
your ps command should work if you sort it properly
i updated my script to following code
you have to use source or eval or to spawn a new shell.  when you run a shell script a new child shell is spawned
i don't know if you were able to fix your issue but here is, to anyone who's experiencing the same issue; as of sep
create test files    echo -e "\t   foo-somethingfoo" &gt;something.foo echo "    bar-bar-somethingbar" &gt;something.bar_bar echo "baz-baz-baz-somethingbaz" &gt;something.baz_baz_baz echo "  spaces    something  s" &gt;something.spaces   produce full glorious colour :)  grep --colour=always "something" something.* |   sed -re  's/^([^:]+):(\x1b\[m\x1b\[k)[[:space:]]*(.*)/\1\x01\2\3/' |    column -s $'\x01' -t   output (run it to get the colour).  something.bar_bar      bar-bar-somethingbar something.baz_baz_baz  baz-baz-baz-somethingbaz something.foo          foo-somethingfoo something.spaces       spaces    something  s     tested in gnome-terminal, konsole, terminator, xterm 
you sound really confused.  all those function definitions you ran were in the shell
h  although the help text may not be particularly clear, h is the command to list messages
in bash, use funcname array:  tt() {   printf '%s\n' "$funcname" }     with some ksh implementations:  tt() { printf '%s\n' "$0"; }   in ksh93:  tt() { printf '%s\n' "${.sh.fun}"; }   from ksh93d and above, you can also use $0 inside function to get the function name, but you must define function using function name { ...; } form.    in zsh, you can use funcstack array:  tt() { print -rl -- $funcstack[1]; }   or $0 inside function.    in fish:  function tt   printf '%s\n' "$_" end  
i guess the problem is (or: was) that the gateway definition collides with dhcp
i have implemented the comment of @rob and succeeded to get the desired result
during initialization (and at any time a user runs fcrontab -z), fcron loads and compiles the fcrontabs
i can reproduce your behaviour if i alias fi:  $ alias fi=: + alias fi=: $ 
prefacing the command with the env vars directly only makes it take for the duration of the command, which may or may not be suitable given the final application.  lc_messages=c /sbin/ifconfig | grep ...  
you could work around that issue by editing the /etc/hosts file
seems to me like your installation folder is incomplete
the 9 previous yanks are saved in registers called 1 through 9
as answered elsewhere, the trick is adding the option identitiesonly yes which makes sure that only the configured keys will be used even if others are available from the agent. 
you just need to escape the dollar $.:  echo \$path $path   or surround it in single quotes:  echo '$path' $path   this will ensure the word is not interpreted by the shell. 
seems to me that it is definitely 1, if by default you mean, without the -j switch
if the end goal is to put the files in the archive in the desired order, then a simple solution is to create an archive with the files to sort first, then add the files to sort last to the existing archive
i don't know if it is more efficient, but you could do this entirely in awk:  awk -f': *' '$1 == "name" {name = $2; next};  $0 == "account disabled (or locked): true" {    print gensub(/.*\\/, "", 1, name) }'  
for popular software you will usually find other users who provide ready to use packages for your distro.  example: https://launchpad.net/~thomas-schiex/+archive/ubuntu/blender  anything you install should go through the package manager in any case, so you can keep track &amp; get rid of its files in the future.  if you just unpack a binary tarball somewhere in your home, i guess you'll also have to create your own menu icon for it..
you just need to prepend it with esc: esc-tab does completion, and it will even give you a tiny dropdown if you do it twice
instead of defining a function, you can use the variable $_, which is expanded to the last argument of the previous command by bash
i'm running arch linux, and this is what i do to reduce heat emissions.   i use laptop-mode-tools to control cpu frequency scaling and spinning down of the hard disk
as gena2x suggested, you can use centos
probably your virtual machine is suffering some kind of memory ballooning operation ordered from the virtualization platform
if you read the manpage for semget, in the notes section you'll notice:     system wide maximum number of semaphore sets: policy dependent (on linux, this limit can be read and modified via the fourth field of /proc/sys/kernel/sem).   on my system, cat /proc/sys/kernel/sem reports:  250 32000   32  128   so do that on your system, and then echo it back after increasing the last number:  printf '250\t32000\t32\t200' &gt;/proc/sys/kernel/sem   (there are tab characters between the numbers, so i'm using printf to generate them.) 
use -c:  tar czf archive -c directory .   this instructs tar to use directory as its working directory, and archive everything contained in the directory (.).  using -c is nearly equivalent to using cd; archive above is interpreted relative to the current directory when tar starts, then tar changes its working directory to directory before interpreting ..  i'm not sure how widespread support for tar -c is, but any linux distribution should support it. 
as you note, there are many possibilities
you can define a new 'tunnel' in your subversion configuration (~/.subversion/config)
if you happen to have a file that looks like this:  old_name1, new_name1 old_name2, new_name2 old_name3, new_name3   you can do a dirty little trick:  sed 's/^/mv -vi "/;s/, /" "/;s/$/";/' &lt; names.csv | bash -   the sed comamnds (delimited by semicolons) does this (s is for substitute, / is used as a delimiter, any other character would do, @ is often used as well):   s/^/mv -vi "/ - adds mv -vi " at the beginning of each line (^ is beginning of line); s/, /" "/ - replaces comma followed by a space with " "; s/$/";/ - appends double quotes to all lines ($ means end of line)   and hence the output of sed will be this:  mv -vi "old_name1" "new_name1" mv -vi "old_name2" "new_name2" mv -vi "old_name3" "new_name3"   which will be fed to bash to execute
i'd strongly suggest getting more memory installed so that you are not swapping
i've finally managed to reduce dramatically this constant writing activity on the disk, though still i don't understand totally how all this is linked
you can use errupdate to set an error as non-reportable
you can run this command, and then click on the window you want to have a dark window title:   xprop  -f _gtk_theme_variant 8u -set _gtk_theme_variant dark   if you have some mechanism to find the x window id, you can pass that into xprop -id. 
how about :e .? this opens the current directory in vim, i.e
print it separately
use nl=$'\n'
debuging your one ligner -- several minor problems:   print -- print /att/{print "card" "sg" "class" "att" } -- /att/{print} or /att/; /yes|no/{val=$1} is also trigered in the 3 fields records, cleaning the previously saved value
no, you can't
when on linux you can use the inotify mechanism in combination with incron
since raid1 means there are two identical disks, so checksums need to match  [root@server ~]# head -100 /dev/sdb3|cksum 2207220453 6836 [root@server ~]# head -100 /dev/sda3|cksum 2207220453 6836 [root@server ~]#   
if your phone is rooted (which based on your statement, "i tried to root it by typing su" i'm gonna guess it isn't but i'm not sure), you can just install busybox and a terminal emulator to have more of the linux commands you're probably expecting or used to
with recent dnf versions (e.g
from the command line you can use the smbtree tool:   $ smbtree  password:  workgroup     \\wolever               wolever         \\wolever\ipc$              ipc service (wolever)         \\wolever\downloads         downloads     \\macbook-d397e8        some macbook         \\macbook-d397e8\ipc$               ipc service (some macbook)         \\macbook-d397e8\screenshots        screenshots     \\my-hp               
sensu has documentation on how to do this here: https://sensuapp.org/docs/latest/clients#client-socket-input  basically, each sensu client (client.json) has an internal socket that you can send external data to; by default this socket only listens on 127.0.0.1:3030 so the config for the client has to be adjusted:  {   "client": {     "name": "my.host",     "address": "x.x.x.x",     "subscriptions": [       "all"     ],     "socket": {       "bind": "0.0.0.0",       "port": 3030     }   } }   the external script then needs to send data to that clients socket via tcp or udp in json using the following format:  {   "name": "some_name",   "output": "its down oh no!",   "status": 2 }  
if you use proxy to make internet connection, maybe your system set some environment variable for your user to set the proxy server ip
it's more easily done with perl:  perl -pe 's/[-+]?\d*(?:\.?\d|\d\.)\d*(?:[ee][-+]?\d+)?/sprintf("%.2g",$&amp;)/ge'  
this isn't a bug in date; it's caused by the definitions in lc_time
configuring the external address is the job of ifconfig
depending on what exactly you want to count, you are better doing this per filesystem rather than counting all files under root
you can, but it's not a good idea
updated answer  i stumbled across this gem  touch -r filename -d '+8 days' filename   from the info coreutils touch invocation (thank you @don_crissti ):     '-r file'      '--reference=file'   use the times of the reference file instead of the current time.  if this option is combined with the '--date=time' ('-d time')  option, the reference file's time is the origin for any relative  times given, but is otherwise ignored
rc mean release candidate, it means your release could be released as production version soon, this is the last version before production
nohup is a command which makes another command safe from hup signals
with traditional unix mail clients, /var/spool/mail/$user is the user's inbox
create a makefile like this.  ifneq ($(kernelrelease),) obj-m   := mymodule.o else kdir    := /lib/modules/$(shell uname -r)/build pwd     := $(shell pwd) all:         $(make) -c $(kdir) subdirs=$(pwd) modules install:         $(make) -c $(kdir) subdirs=$(pwd) modules_install %:         $(make) -c $(kdir) subdirs=$(pwd) $@ endif   assuming your module's source is in mymodule.c, running make will create mymodule.ko. 
you can mount a tmpfs partititon and write the file there:  mount -t tmpfs -o size=500m tmpfs /mountpoint   this partition now is limited to 500 mb
grep interprets \n as a newline character
i had problems with network manager on ubuntu , so i set up static networking
it's currently not possible (to my knowledge) to be able to take strings and create associative arrays with them in bash
sudo python -m simplehttpserver 80  for python 3.x version, you may need :  sudo python -m http.server 80  ports below 1024 require root privileges
the best way to do this is with avahi which implements multicast-dns (this is what apple calls bonjour).  i would disable network manager and go with configuring networking in /etc/network/interfaces
it is (currently) not possible to let qemu pick the next free port for spice
at does not support decimals:  at now + 1.5 minutes syntax error
since sshfs is based on fuse, it's easier to use a non-root automounter
have you tried just using su?  most of the time the default user on a livecd has passwordless sudo, and can also su passwordlessly to any other user. 
to get rid of the error you need to set your user name and email address. there are two main contexts where you will likely want to set this   specific to your user account i.e
try to put in your ~/.inputrc   set revert-all-at-newline on   in some case you can find it in the default value (off). it should force readline to undo all changes to history lines before returning when accept-line is executed
the usermod command will allow you to change a user's primary group, supplementary group or a number of other attributes
it looks like dropping the capabilities works
if you are using the new plasma5, some say it has problems with keyboard shortcuts (not that i've noticed).  you can easily change workspace by using the "desktop grid" effect
http://menehune.opt.wfu.edu/kokua/irix_6.5.21_doc_cd/usr/share/insight/library/sgi_bookshelves/sgi_developer/books/xlib_winsys/sgi_html/ch08.html  #override merges the translations with the existing translation, overriding any that conflict, compared to #augment which also merges, but the existing translations that conflict take precedence. 
i believe the answer lies in how you define "unix-like"
the notion of daemon is attached to processes, not files
because the full debian distribution for even a single architecture now well exceeds seven dvds, and the packages on each dvd are sorted by popularity, not by common theme
this is classical sysadmin problem, if i get it right, this tool is just what you need:  module  what it does is control environment variables, if you want to load a specific version of glibc you need to put it on the ld_library_path (and ideally remove the other one), same deal with programs and applications.  the environment is controlled by loading and unloading modulefiles, the syntax for those files is explained here. 
sudo -u postgres allows you to impersonate the postgres user when running the command
just force it to use the builtin:  builtin echo foo   if echo is not a builtin, this will fail. 
that's a roundabout and grossly inaccurate method
you can get that behavior by setting the completion style completer to include the _expand control function
you can use the combination find, grep and awk command to get the desired result
binary file is pretty much everything that is not plain text, that is contains data encoded in any different way than text encoding (ascii, utf-8, or any of other text encodings, e.g
ssh -o 'proxycommand ssh -w %h:%p user@192.168.123.101'   then you can simply run ssh pc1.  best used through an alias in ~/.ssh/config:  host pc1 hostname 192.168.0.2 user user proxycommand ssh -w %h:%p user@192.168.123.101   for older versions of openssh that don't have the -w option (i think this means ≤5.4), make sure that netcat is available on pc2 and use  host pc1 hostname 192.168.0.2 user user proxycommand ssh user@192.168.123.101 nc %h %p  
i do this:   c-x c-v (find-alternate-file) c-a (move-beginning-of-line) c-k (kill-line) c-g (keyboard-quit)   it's quicker than using the minibuffer history
/etc/systemd is for user defined services
what i've done here is to test whether the root of the init process (pid 1) is the same as the root of the current process
under linux, you can find the pid of your process, then look at /proc/$pid/status
normally i'd just use the ${parameter#word} bash parameter expansion
if you prefix a function with c-h f you can read documentation for it
the problem is not winetricks - multi-arch works in a different way as you think (i suggest (re-)reading the first sections of debian's multiarch-howto).  you actually need to install the wine:amd64-package instead of the wine:i386-package
sed -n '3,10p' big-file.txt &gt; your-section.txt   replace 3 and 10 with your range of lines
usually you do it like the following.  to assign a primary group to an user:  $ usermod -g primarygroupname username   to assign secondary groups to an user:  $ usermod -g secondarygroupname username   from man-page:  ... -g (primary group assigned to the users) -g (other groups the user belongs to) ...  
have you looked at this?  i think what you are looking for is:  5-59/15 * * * * /root/job.sh &gt;&gt; /root/job.log  
on solaris 10 you can do:  find /usr/share/lib/terminfo -type f -print   you should be able to do something like:  find /usr -type d -name terminfo -print   to find where the directory is located.  you can also read to find the exact path:  man terminfo  
with xte tool from xautomation package it is as simple as  xte "key f5"   it will act on the current active window, so you'd have to make sure the proper one is selected previously. 
i have found a solution.  calc () {   awk '     function asin(x) { return atan2(x, sqrt(1-x*x)) }     function acos(x) { return atan2(sqrt(1-x*x), x) }     function atan(x) { return atan2(x,1) }     function tan(x) { return sin(x)/cos(x) }     begin { pi=atan(1)*4; print '"$(echo "$@" | tr , .)}" | tr 
iostat is part of the sysstat package, which is able to show overall iops if desired, or show them separated by reads/writes.  run iostat with the -d flag to only show the device information page, and -x for detailed information (separate read/write stats)
the problem is /bin/ls don't just need the shared libraries, which you provided
i'm not aware of any frameworks or tools that will assist in doing this
the shell will expand patterns according to filename.   first form expands to abcdfg (no e) and/or abcefg (no d) and neither file exists, so the pattern is left unexpanded, and the command is what you think it is; effectively,  mv -v "abcdefg" "abc[de]fg"  second form expands to abcdefg, and this file exists, so the pattern expands to the file name, and thus the command is, effectively,  mv -v abcdefg abcdefg    try this to see when pattern is kept or expanded.  touch abcdefg ls -l abc[de]fg ; echo abc[de]fg ls -l abc??fg ;   echo abc??fg ls -l abc?fg ;    echo abc?fg ls -l abc[d]efg ; echo abc[d]efg  
there is nothing wrong with --create - if you know what you are doing.  the only problem is: you don't know.  when you create a raid, the command is usally something short, like:  mdadm --create /dev/md42 --level=5 --raid-devices=3 /dev/sdx1 /dev/sdy1 /dev/sdz1   dead simple, right?  except it isn't, really
i found that if i just:  url='http://subs.sab.bz/index.php?s=ece2929c25861a7244025e1628e7ee5a&amp;act=download&amp;attach_id=75766' curl -e "$url" "$url" &gt;out.rar   then i could:  unrar e out.rar   and the results were:  extracting from out.rar  extracting  dominion.s01e01.720p.hdtv.x264-dimension.srt              ok extracting  dominion.s01e01.hdtv.x264-lol.srt                         ok extracting  dominion.s01e01.hdtv.xvid-afg.srt                         ok extracting  - readme - subs.sab.bz - brought to you by  xen.headoff.com -.html   ok all ok   so it seems to be perfectly willing to accept the download link itself as the referrer. 
i was actually able to figure this out, and i figure i'd add it here for the next googler who bangs their head against the same wall.  i had a grep alias and grep_options set
source packages are not added to the rpm database, so they will not show on query.  probable location is ~/rpmbuild/{sources,specs} with sources containing the package sources and distribution patches while the specs subdirectory containing the .spec file being used to build the package (see rpmbuild (8) man page for details).  if you can't find the sources there, than reinstall with the -vv option to check the location if it's overwritten:   $ rpm -ivvh kernel-3.10.0-229.7.2.el7.src.rpm  --- snip --- updating / installing...    1:kernel-3.10.0-229.7.2.el7        ################################# [100%] d: ========== directories not explicitly included in package: d:          0 /home/user/rpmbuild/sources/ d:          1 /home/user/rpmbuild/specs/ d: ==========  
this should be a standard solution:  type type -t type -p  
this should be distinguished from the situation where you're trying to replicate a full package tree from an official repository and fine tuning sources priority
with a typical busybox installation, i think you're going to have to parse the output of ls to get the size
you want linux containers: http://lxc.sourceforge.net/  you can both run a single process and a whole os
you can disable the searchable-scrollback feature by putting this in your .xresources:  urxvt.perl-ext-common: "default, -searchable-scrollback"   source: urxvt manpage (under perl-ext in the resources section) 
   sending kill -9 to a process doesn't require the process' cooperation (like handling a signal), it just kills it off.   you're presuming that because some signals can be caught and ignored they all involve cooperation
this might get you there...   enable custom tab completion in your .bashrc  shopt -s progcomp create a compgen function and add it to .bashrc after your notes functions.  _notes() { local cur     cur=${comp_words[comp_cword]}     compreply=( $(compgen -f $home/n/$cur | cut -d"/" -f5 ) )     }    complete -o filenames -f _notes n   this works for me - at the basic level
you could use xautolock:  xautolock monitors console activity under the x window system, and fires up a program of your choice if nothing happens during a user configurable period of time
i suspect an attack like this would work, where «something» is a kernel module that will try to load after rootfs is mounted:  $ sudo mkdir -m 777 /lib/modules/`uname -r`/a $ cp evil.ko /lib/modules/`uname -r`/a/«something».ko   note also that you could use other names, depending on the aliases declared in the module
this sounds like an issue with windows 8 and nothing to do with the samba server
sed '1458,$d'   you can use that with -i to edit the file in place if necessary.  e.g  sed -i '1458,$d' filename.txt  
you could use the columns command from gnu autogen.  $ seq 60 | columns 1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60   with zsh, you can use print -c:  $ print -c4 {1..20} 1   6   11  16 2   7   12  17 3   8   13  18 4   9   14  19 5   10  15  20  $ print -ac4 {1..20} 1   2   3   4 5   6   7   8 9   10  11  12 13  14  15  16 17  18  19  20   and if you need to sort them first (like ls does):  $ print -oc4 {1..20} 1   14  19  5 10  15  2   6 11  16  20  7 12  17  3   8 13  18  4   9  
see apple's promo page for info about thunderbolt
update-rc.d was initially used by package upgrade scripts
ps output can be filtered in may ways
this is part of the output of the linuxlogo command, specifically part of the output of linuxlogo -l gnu_linux which in full looks like this screenshot from the debian version:    the logos are constructed from templates that accompany the command
according to your data samples in your question this seems to be what you want (otherwise clarify your question, please):  awk '$5 &gt; max { max = $5 ; out = $0 } end { print out }' datafile   this will print that line in datafile where the value in the 5th column is the maximum.  the program works as follows: for each line the fifth column element will be compared against the stored maximum max (which is initially 0), and if a larger value is found max gets that value assigned (for subsequent comparisons) and the current line ($0) containing the maximum is stored in variable out
an inode is a structure in some file systems that holds a file or directory's metadata (all the information about the file, except its name and data)
simply source it:  
dir=${1%/}   will take the script's first parameter and remove a trailing slash if there is one. 
i figured out a way
to make less run in a different encoding from the terminal's, use luit (which ships with the x11 utility suite).  lang=ru_ru.cp1251 luit less subs.srt   if you want to detect the encoding automatically, that's trickier, because a text file carries no indication of its encoding
so you're looking for a package containing a file called system.windows.forms.dll
depending on your os, try /var/spool/cron/. on debian its a little further, /var/spool/cron/crontabs/.  usually, this is mentioned in man crontab 
a colleague confirmed that pkgparam can be used to compare the inputs used at installation time to the inputs of a response file.  the syntax pkgparam -v &lt;name of package&gt; will show actual keys and values that were used, which will include items that do not appear in the response file
it is possible to add multiple lines of localforward:  host myhost     hostname 123.123.123.123     identityfile ~/.ssh/id_myhost     localforward 8811 localhost:8811     localforward 6006 localhost:6006     identitiesonly yes   is this what you want? 
wine works even for windows cli apps. 
you will not be able to hide information in a shell script
i think that behind your description, there is a misconception
i finally found an answer to this problem based on this post from another forum (see "attempt 1b" for reference)
you need execute permissions on /home/bob/inputs
edit /etc/gdm/custom.conf and add or change the exclude directive in the [greeter] section:  [greeter] exclude=nobody,alice,bob   users alice and bob won't be shown on the list at the login screen but can still log in by typing their name and password (if they have a password).  see more details in how to hide users from the gdm login screen? (it's mostly distribution-independent — some details might change, for example files may located in different places, and the threshold for system users is 500 on most red hat derivatives but 1000 on most debian derivatives). 
press o to change the options
i think the most compelling reason would be to run zfs under a familiar gnu/linux userspace. 
on my rhel system, the file command sits ontop of libmagic and uses that to do the file magic detection
you should just quote the second argument.  myfunc(){         echo "$1"         echo "$2"         echo "$3" }  myfunc hi "hello guys" bye  
a process that's currently running in kernel mode, i.e
you don't need systemd for that &hellip; but there's a systemd way of doing it as well, as long as you are running the systemd-logind daemon, or something that provides the same api.  first obtain a list of sessions:  $ systemd-loginctl list-sessions    session        uid user             seat                    c89       1000 jdebp            seat0             1 sessions listed.   then for each session that you are interested in show its status:  $ systemd-loginctl session-status c89 c89 - jdebp (1000)        since: tue, 07 oct 2014 20:16:20 +0100; 15s ago       leader: 24453 (3)         seat: seat0; vc6          tty: /dev/tty6      service: login; type tty; class user       active: yes       cgroup: /user/jdebp/c89           ├ 24453 login           ├ 25661 -zsh           └ 25866 systemd-loginctl session-status c89   the systemd people have renamed them to loginctl and logind in more recent versions.  further reading   loginctl
method #1  i generally just do this via the command line if i want to copy a dvd to a directory and then make it into an iso:  $ cd /dir/where/you/save/the/dvd   now insert dvd to be copied:  $ dvdbackup -m $ genisoimage -dvd-video -udf -o movie.iso /dir/where/you/save/the/dvd $ eject /dev/dvd   method #2  if on the other hand if i just want to make an iso directly from a dvd:  $ genisoimage -dvd-video -udf -o movie.iso /dvd/mounted/to   method #3  if you want to rip or burn using a gui then i'd suggest using k3b.  references   [one-liner]: how to backup a movie dvd via the command line on fedora 14 &amp; centos 5  
run su -c 'ssh-keygen -n ""' nagios to generate the key pair, or alternatively generate the key pair as another user then copy it in place into ~nagios/.ssh
you can do this by listing both sets of packages and determining the difference between the two results:  grep -fxv -f &lt;(apt list | grep unstable | cut -d/ -f1) &lt;(apt list | grep experimental | cut -d/ -f1)   this produces “experimental minus unstable”, and can be adapted to calculate any difference by changing unstable and/or experimental
with grep -p/pcregrep, using a positive look-behind and a positive look-ahead:  grep -p -o '(?&lt;=string1).*?(?=string2)' infile   in your case replace string1 with filename- and string2 with \.tar\.gz    if you don't have access to pcregrep and/or if your grep doesn't support -p you can do this with your favourite text processing tool
the a.out file is still leftover from when compilers were using the a.out format
so you have an old custom package which triggers an error when systemd is upgraded due to a bad configuration file.  given the order in which maintainer scripts are executed, the earliest time at which the new version of your package can intervene is the preinst upgrade step, which happens before the new package is unpacked, well before the postinst configure steps
currently on ubuntu, the actual shutdown is performed by console-kit-daemon, the consolekit daemon, which runs with root privileges
this should help you out
as a sum up of the comments
you need oracle's java, not debian's default jre/..
all the basic text processing utilities are meant to act as filters, and most are meant to process their input as a stream (i.e
first of all, you should be aware that you cannot delegate domains to your recursors in this setup, even apart from the axfr issue
without attempting to detect troublesome input (e.g
you have basically three options:   use a wrapper around your libraries, that will set ld_library_path appropriately and then execute the desired library - something like:   #!/bin/sh export ld_library_path="path/goes/here" exec "$@"  link with -rpath (-wl,rpath) which adds search path for dynamic linker into the binary (see also so answer - it also mentions the wrapper). you won't like reading this one: update your cluster (note the emphasis on "your")
logs probably go to syslog, which varies depending on what syslog daemon is involved and how that is configured to log, start with  grep -r cron /etc/*syslog*   to find where and what is going on on the system, or per derobert under systemd the relevant command is  journalctl -b 0 _systemd_unit=cron.service   adding a test cron job that touches a file (ideally not in /tmp, unless the vendor makes that per-user private, for security reasons) should also confirm whether cron is working or not, just be sure to eventually remove the test cron job before it fills up a partition or something silly.  other usability and security pointers: some cron daemons can run scripts directly, in which case you can just copy the script into /etc/cron.daily, though this may not suit something that you do not want to run (with everything else!) at exactly the top of the hour
several ways to do that
that's because:   python performs output buffering if redirected to a pipe or a file. http.server writes the first line to stdout then access logs to stderr.   you need to do like:  exec 3&lt; &lt;(python3 -u -m http.server 2&gt;&amp;1)   speaking about your goal, i suppose the script needs to continue reading from the pipe even after it's gotten that specific output, because the subprocess will stop running as soon as its output to the pipe gets blocked. 
you don't need stalonetray and nm-applet to select a wifi network
this is a bug with the elementary tweaks
you are only able to mount partitions with known filesystems on it (yes that information is on the disk)
on a machine with the gnu coreutils (most linux distros), the cp command has -x.  from cp man page:  -x, --one-file-system  
find considers finding nothing a special case of success (no error occurred)
long before there were computers, there were teleprinters (aka teletypewriters, aka teletypes)
if you don't need physical security, and even for a subset of physical attackers, it seems to me openbsd could do it unless there is a perfect storm of bugs and poorly chosen world-accessible services that can allow running arbitrary code in kernel mode.  read up on chflags(1)
you describe the gnu tail utility
ok, i think i have the pieces you need, but i'll leave it up to you to string them together into a cohesive whole.  the tmux environment variable will tell you if the current process is running under tmux or not:  &lt;~&gt; $ echo $tmux /private/var/folders/1s/ff98nkc90mv7pfglffklcv8w0000gn/t/tmux-501/default,27570,8   the last value (8) is the session id (which may or may not also be the session name)
choose options from the menu bar, then panel options. you have it right there, 5th option on the left column: "show hidden files".   
i had the exact same problem when updating my ports tree. i could fix this by completely de-installing the existing openjdk port and re-installing it again. it looks like the openjdk port does not compile properly when there is already an jdk installed during compile time.  pkg delete '*jdk*' '*java*' cd /usr/ports/java/openjdk7 &amp;&amp; make install clean  
if you only create directories with the mkdir command at the shell prompt, you could have:  umask 7 mkdir() (umask 2 &amp;&amp; command mkdir "$@")   in your shell customisation file (~/.zshrc for zsh, ~/.bashrc for bash...).  that is set the umask to 7, but redefine mkdir to a function where the real mkdir is called (with the same arguments ("$@")) with a umask of 2
there are multiple solutions to this problem
how about $(dirname "$0")/myfile? 
two options  i use at home modifier to achieve this
you missed a ; or a + and a {}:  find 
glxinfo | grep "opengl version" 
i very recently asked myself the same question, but i quickly came to the realisation that it doesn't work that way.  when you use the mount command-line program, systemd is not involved: mount reads /etc/fstab (or takes options from the command-line) and mounts the device
install gdisk which is available from sourceforge as well as from the ubuntu universe repositories.  then use the sgdisk command (man page here) like so  sgdisk -r /dev/sdb /dev/sda sgdisk -g /dev/sdb   the first command copies the partition table of sda to sdb (be careful not to mix these up)
it is defined in an include-file read by the make program, e.g., by this line at the end of the port makefile:  .include &lt;bsd.port.mk&gt;   on my freebsd 10 system, the include-files are in /usr/ports/mk, and grep finds these matches:  $ fgrep -n python_rel * bsd.python.mk:70:# python_rel           - version number in numerical format, to ease bsd.python.mk:353:python_rel=           341 bsd.python.mk:364:python_rel=           335 bsd.python.mk:375:python_rel=           325 bsd.python.mk:386:python_rel=           278 bsd.python.mk:394:python_rel!=          ${python_cmd} -c 'import sys; h = "%x" % sys.hexversion; \ bsd.python.mk:505:      defined(python_rel) bsd.python.mk:553:.if ${python_rel} &gt;= 320 &amp;&amp; defined(python_py3k_plist_hack) bsd.python.mk:569:.endif # ${python_rel} &gt;= 320 &amp;&amp; defined(python_py3k_plist_hack)   and bsd.python.mk is included conditionally (grep is your friend):  $ fgrep -n bsd.python.mk * bsd.port.mk:398:#                                 implies inclusion of bsd.python.mk
if you let g:ycm_always_populate_location_list = 1, youcompleteme will populate vims location list with new diagnostic data
(just as a guideline, the format is not exactly the same):  ll=$(last -1 -r  $user | head -1 | cut -c 20-) export ps1="last login time [$ll]"'\n\h:\w\$ '   edit: if you want last information to be printed only once (wise idea)   ll=$(last -1 -r  $user | head -1 | cut -c 20-) echo "last login time [$ll]"    # adjust to your login messages, fortunes, etc export ps1='\n\h:\w\$ '         # replace by your favorite prompt  
unfortunately there's no way to have dpkg automatically install dependencies - it just doesn't support that
just use double quote instead of single quote, and you don't have to use cat (see uuoc):  grep -f -- "$pwd" file   and remember that without -f, $pwd would be treated as a regular expression as opposed to a string to be looked for in the file. 
if you are using apt-get/aptitude you can use -v to show a detailed status of the packages to be upgraded, if you add more v's the report will be more verbose:  sudo apt-get -vv upgrade  reading package lists..
each folder consumes one inode (256 byte) and at least one block (probably 4096 byte)
it is like a check disk on a physical file that constitute your virtual disk
to your script you only need to add two commands: p (print up to the first newline) and d (delete up to the first newline and repeat if there is any text left).  sed -e '{ s/\(.\{75\}\)\(.\)/\1\n \2/; p; d }' file  
grep won't help you here
to organize the files by world:  $ paste -d'\n' &lt;(grep world1 file) &lt;(grep world2 file) &lt;(grep world3 file) &lt;(grep world4 file) world1.com           /randomkeygahjuh572/key639839 world2.com           /randomkey788gauh72/key63whjk world3.com           /randomkey788gauh72/key63whjk world4.com           /randomkeyhghgdh778/key67567 world1.com           /randomkeyhueh34778/key67uuu77 world2.com           /randomkeyjjjj1111/key63333 world3.com           /randomkey7hhhh0000/key6333355k world4.com           /randomkey8998382/key6hh77686   how it works  we can use grep to select the lines for each world:  $ grep world4 file world4.com           /randomkeyhghgdh778/key67567 world4.com           /randomkey8998382/key6hh77686   paste combines lines from multiple files
an awk solution:  $ awk '$0 == "unix" {i=1;next};i &amp;&amp; i++ &lt;= 2' file test 5 test 6   explanation   /^unix$/{i=1;next}: if we see unix, we set variable i = 1, processing to next input. if variable i is set (meaning we saw unix), i &amp;&amp; i++ &lt;= 2 only evaluated to true value in next two lines after unix, causing awk performed default action print $0. before seeing unix, i was not defined and begin at 3rd line after unix, i had a value greater than 2, which make expression i &amp;&amp; i++ &lt;= 2 evaluated to false, causing awk do nothing.  
you could always try to install the rpm from the later fedora versions
cp a b &amp;&amp; mv b c &amp;&amp; rm a &amp; is correct
press space to select an option 
i guess the question is why read -d '' works though read -d'' doesn't.  the problem doesn't have anything to do with read but is a quoting "problem"
you should not parse xml with sed, use an xml parser like xmlstarlet instead
you can put relative paths in the search path
there's no formal definition of “public interface”
i understand how to do. first create or convert a qcow2 compressed image(is the qemu format) then create a dockerfile like this and rename it  dockerfile   from rancher/vm-base:0.0.1 copy centos.img  /base_image/centos7.img cmd ["-m 2002m"]   then import in docker,of course do this where you copied the image(in my case is /root/centos.img and pwd is root)  docker build -t "centos7:kvm"   then open ranchervm webgui,do "create instance" and put centos7:kvm in "image",setup other things how you like it and click ok you can run the docker image created via kvm via vnc on browser. 
kill sends signals to processes, it defaults to sending the term signal
icmp redirects are sent to define a better route/gateway to a destination.  as you have to have an ip address in the same network as the gateway/exit for a route, the route will only be inserted in the routing table if all the following conditions are true:    accept_redirects is set to 1  the machine in question has an interface with an address that belongs to the network of the gateway  it does not have an ip address in the same network as the destination route.   otherwise the route will be discarded
an awk way:  $ awk 'nr != $1 { for (i = prev + 1; i &lt; $1; i++) {print i} } { prev = $1 + 1 }' file 3 5 6 7 9   more clearly:  awk 'nr != $1 {   for (i = prev + 1; i &lt; $1; i++) {     print i   } }  {    prev = $1 }'   for each line, i check if the line number matches the number, and if not, prints every number between the previous number (prev) and the current number (exclusive, hence i = prev + 1). 
the pattern given to an aptitude search is a regex, so you can use that to find exact matches:  aptitude search '^z$'   when you know the exact package name, you are not really "searching"
the fs comes from the additional segment register named fs on the 386 architecture (end of second paragraph).  my guess is that after ds for data segment and  es for extra segment intel just went for the next characters in the alphabet (fs, gs)
the chromium sandbox is a separate program, chrome-sandbox (even for chromium rather than chrome)
your color codes are alright, i'm just not sure whether read supports colored output.  i split your read in two commands, one to print the question and one to receive the answer:  version=1.0.1 textgreen='\e[92m' nocolor='\e[0m' echo -e "is this version ok?: ${textgreen}${version}${nocolor} (y/n)" stty raw reply=$(dd bs=1 count=1 2&gt; /dev/null) stty -raw if [[ $reply =~ ^[yy]$ ]] then ...   echo supports colored output with the -e option
the basic concept to grasp here is that path can be defined in many places
the name of the output file is always the original name with the extension changed (unless you specify something other with command switches) so you could do this instead of piping.  tex file.tex; dvips file.dvi; ps2pdf file.ps   this executes the commands one after the other
you could use homebrew for mac os x: https://github.com/mxcl/homebrew and install the coreutils package from there
the problem was that since the su statement was in double quotes, the variables were all expanded before the su command was called, which means $var becomes "cat" but $i becomes "" since it was not defined
if your version of grep supports pcre mode, you can use grep -po 'xmx\k\d+'  ex.  echo 'f arg[30] = -xmx4096m' | grep -po 'xmx\k\d+' 4096  
the first thing that jumps to mind is "files with holes"
you could start by saying find /var/dtpdev/tmp/ -type f -mtime +15. this will find all files older than 15 days and print their names. optionally, you can specify -print at the end of the command, but that is the default action. it is advisable to run the above command first, to see what files are selected.  after you verify that the find command is listing the files that you want to delete (and no others), you can add an "action" to delete the files. the typical actions to do this are:   -exec rm -f {} \; (or, equivalently, -exec rm -f {} ';') this will run rm -f on each file; e.g.,  rm -f /var/dtpdev/tmp/a1/b1; rm -f /var/dtpdev/tmp/a1/b2; rm -f /var/dtpdev/tmp/a1/b3; …  -exec rm -f {} + this will run rm -f on many files at once; e.g.,  rm -f /var/dtpdev/tmp/a1/b1 /var/dtpdev/tmp/a1/b2 /var/dtpdev/tmp/a1/b3 …   so it may be slightly faster than option 1.  (it may need to run rm -f a few times if you have thousands of files.) -delete this tells find itself to delete the files, without running rm. this may be infinitesimally faster than the -exec variants, but it will not work on all systems.   so, if you use option 2, the whole command would be:  find /var/dtpdev/tmp/ -type f -mtime +15 -exec rm -f {} +  
history  originally, unix only had permissions for the owning user, and for other users: there were no groups
i managed to achieve what i wanted:  echo "welcome to the lab $(cat /var/mail/pi|grep "was granted entry" |grep -v "&lt;p&gt;" | sed "s/ was.*/ /"|tail -1 | awk -f ", " ' { t = $1; $1 = $2; $2 = t; print; }')" |espeak -ven-us+f4 -s150 2&gt;/dev/null  
the amplification attacks work because bad actors do talk to several vulnerable servers at once
just type: sudo update-initramfs -u. 
your export line says  192.168.178.10(ro,sync,no_subtree_check,root_squash)   the root_squash entry means "when remote user root tries to access the file, pretend the user is nobody instead
alternate method:  cat  /proc/sys/kernel/random/boot_id   this version contains some dashes
as i understand it, to do this permanently, you simply pile all the addresses together, i.e.:  address=192.168.59.1/24 192.168.1.5/24  
to find out firmware your system is looking for but can't find (which is the firmware you might need), you should look for firmware-related messages in your kernel logs:  dmesg | grep firmware   that will give you the names of firmware files which the kernel is looking for; apt-file will then tell you which package to install (if the firmware is packaged).  you've got a skylake system running with an intel gpu, you'll probably need at least firmware-misc-nonfree (skylake gpus need firmware):  apt-get -t jessie-backports install firmware-misc-nonfree   this will fix the i915 firmware loading errors
sudo is a a normal application with the suid bit
you're missing the usual case $1 in stop, start, restart, status stuff (you can see what i mean if you look at existing scripts in /etc/init.d (apologies if you're already aware of that), but as it stands your init script is accepted by chkconfig on my redhat 5 vm so i would expect it to work for you
the timeout command will do this for you, i.e.  timeout 10s command   it will kill command after 10 seconds
you can try below awk command :     awk -f"|" '$2 ~ /^9/ &amp;&amp; $3 ~ /^9/ { print $2,$3 }' filename   output contain space between second and third word but you can set it according to your need with ofs.  edit :  your program will look like this :  case "$3" in       -id)          echo "lines matches with the pattern $4 :"           filename=$2          id=$4          echo "`grep "^$id" $filename | awk -f"|" -v id="$id" '$1==id'|awk -f "|" '{print $2,$3,$5}'`"                  ;;  esac  
forget about shred, it spends a lot of time doing useless things and misses the essential.  shred wipes files by making multiple passes of overwriting files with random data (a “gutmann wipe”), because with the disk technologies of 20–30 years ago and some expensive laboratory equipment, it was possible (at least in theory) to recover overwritten data
you can use the command:  vboxmanage controlvm vmname keyboardputscancode &lt;scancodes&gt;   where scancodes are those generated by a pc-at keyboard such as described here
you don't need to run process in some control groups if you already in certain namespace, instead you have to manipulate with namespaces
you can get all of the old debian versions at the offical debian archives
the official encrypted container on openbsd is through vnode pseudo devices, set up with vnconfig
 probably not
thanks to @affix's answer which gave me the right direction to head, i've figured out the solution to the problem.  the problem is definitely caused by udev as you've guessed
there is some work done, with some success, according this project page: http://code.google.com/p/x265/ 
that would be i386
assume eth0 is dhcp client interface. one of options is to check dhcp client lease files dhcpd.leases place and name depend on system, some fedora box under /var/lib/dhclient/  are lease files, where interesting string is like that :    option routers 192.168.1.1;   another option, which worked for me on funtoo box: dhcpcd -u eth0 prints nice table, ready to source in scripts  broadcast_address=192.168.1.255 dhcp_lease_time=86400 dhcp_message_type=5 dhcp_server_identifier=192.168.1.1 domain_name_servers='192.168.1.1 192.168.1.101' ip_address=192.168.1.101 network_number=192.168.1.0 routers=192.168.1.1 subnet_cidr=24 subnet_mask=255.255.255.0   there also another options like dhcping, dhclient -n according google and manpages, but they fails on my boxes, but may work for you. 
a very common (if not utterly foolproof) way to check for an interactive terminal is to check whether ps1 is set:  if [[ -z "$ps1" ]]; then     echo "probably run as a script." else     echo "probably interactive." fi   another alternative is checking for the i option in $-:  case "$-" in    *i*)        echo "probably interactive"        ;;    *)        echo "probably scripted"        ;; esac   there is also the -t option for test (aka [ and its cousin, [[):  fd=0 # stdin if [[ -t "$fd" ]]; then     echo "interactive" else     echo "scripted" fi   tip of the hat to the linux documentation project.  dash and sh may not have [ and [[ available, so you might have to explicitly use test, e
you can observe in /sys the block device for a given partition name
if you want to decrease the likelihood of vfs caching, increase the vfs cache pressure by tuning the value of /proc/sys/vm/vfs_cache_pressure (the default is 100)
the .profile dates back to the original bourne shell known as sh
-ne only means "not equal" when it's in an if [ … ] statement
try cut:  &lt; bigfile cut -c 1-50 | head -n 10  
after a process is sent to the background with &amp;, its pid can be retrieved from the variable $!
i don't have a mate environment to test on but in general, this type of thing can be set using gsettings
posting as an answer, as requested.  just don't use info to browse info pages
to disable them via xkb you could comment them out in your x keycodes file (the one that corresponds to your keyboard - linux uses /usr/share/x11/xkb/keycodes/evdev)
using a broad definition of "file"  ls | wc -l   (note that it doesn't count hidden files and assumes that file names don't contain newline characters).  to include hidden files (except . and ..) and avoid problems with newline characters, the canonical way is:  find 
if i understand you correctly, you have a regex pattern in a variable and you would like grep to use it without giving any special meaning to regex metacharacters
whether a kernel is preemptive or not depends on what you want to preempt, as in the linux kernel, there are various things that can have preemption enabled/disabled separately.  if your kernel has config_ikconfig and config_ikconfig_proc enabled, you can find out your preemption configuration through /proc/config.gz (if you don't have this, some distributions ship the kernel config in /boot instead):  $ gzip -cd /proc/config.gz | grep preempt config_tree_preempt_rcu=y config_preempt_rcu=y config_preempt_notifiers=y # config_preempt_none is not set # config_preempt_voluntary is not set config_preempt=y config_preempt_count=y # config_debug_preempt is not set # config_preempt_tracer is not set   if you have config_ikconfig, but not config_ikconfig_proc, you can still get it out of the kernel image with extract-ikconfig. 
another option is to check nf, eg:  awk '!nf || !seen[$0]++'  
if your hardware is from a big vendor, say hp, dell and so, they might have specific tools for what you're looking
maybe like:  vicmd-accept() { prev_mode=vicmd; zle .accept-line } viins-accept() { prev_mode=viins; zle .accept-line } zle-line-init() { zle -k ${prev_mode:-viins} } zle -n viins-accept zle -n vicmd-accept zle -n zle-line-init bindkey -m viins \\r viins-accept bindkey -m vicmd \\r vicmd-accept   or even simpler:  accept-line() { prev_mode=$keymap; zle .accept-line } zle-line-init() { zle -k ${prev_mode:-viins} } zle -n accept-line zle -n zle-line-init  
before doing your first change you must note the keycode you are changing
well, actually mint petra uses ubuntu repositories for stuff and only installs some extras
you can do it with single command with   sed 's/\(.*\)-/\1 /'   the point is that sed is very greedy, so matches as many characters before - as possible, including other -.  $ echo 'swp-redhat-linux-os-5.5.0.0-03' | sed 's/\(.*\)-/\1 /' swp-redhat-linux-os-5.5.0.0 03  
when prompted for the pid to renice, entering any value that isn't a positive integer will exit the renice mode with an error message
looking to xinput --list as suggested by alexander barakin shown that my gamepad isn't handled by xorg.  games directly communicate with /dev/input/js* so xorg doesn't know any activity through gamepad.  possible solutions:   wrapper scripts around commands that xset -dpms s off; command; xset +dpms s on detecting x properties, like class/resource pattern names and running xset ...
at the moment, incoming traffic is blocked unless explicitly allowed (that's what policy drop means)
you can check the current state of the array with cat /proc/mdstat
if you start the program from rc.local, then you cannot login to a shell and type ctrl-c to stop it
i just found this much simpler answer on this other question:  output=`mycommand 2&gt;&amp;1` || echo $output   works like a charm! 
yep, lots of differences
easiest is probably to run xset q or xdpyinfo, redirecting the output to /dev/null so that it doesn't puke on your display.  edit:  this will run a screensaver, then kill it (change the path and delay as needed):  /usr/libexec/mate-screensaver/popsquares &amp; { sleep 0.01 ; kill $! ; }  
filesystem hierarchy standard: http://www.pathname.com/fhs/  gnu coding standards: http://www.gnu.org/prep/standards/ also has policies on directory usage, and sometimes disagrees with fhs  "folder" is a term used by mac and windows people to refer to directories
i get the same behavior that you describe
expansion by the shell  the quotes around "$i*.csv" make the difference
from the man page:-  virsh list --autostart   should do it. 
@cas was correct in his assumption that "it's simpler for fsck to just create a lost+found directory with more reserved space for found files than to expand it if/when needed
put the following code into : /etc/init.d/rc.local:  /home/pi/cgminer-4.5.0/cgminer -o http://xxxxxxxxxxx -u xxxxxxxx -p xxxxxxxxxx  
export foo=bar will set the global variable  $foo to bar
rethink your application
compression takes advantage of the fact that there are patterns in data that can be optimized out and indicated in a different way
cd is a shell builtin
initial research  at first sight it would appear that the answer would be "no" the specification for elf only allows the following sections.  c32/kernel/bin/.process.o architecture: i386, flags 0x00000011: has_reloc, has_syms start address 0x00000000  sections: idx name          size      vma       lma       file off  algn   0 .text         00000333  00000000  00000000  00000040  2**4                   contents, alloc, load, reloc, readonly, code   1 .data         00000050  00000000  00000000  00000380  2**5                   contents, alloc, load, data   2 .bss          00000000  00000000  00000000  000003d0  2**2                   alloc   3 .note         00000014  00000000  00000000  000003d0  2**0                   contents, readonly   4 .stab         000020e8  00000000  00000000  000003e4  2**2                   contents, reloc, readonly, debugging   5 .stabstr      00008f17  00000000  00000000  000024cc  2**0                   contents, readonly, debugging   6 .rodata       000001e4  00000000  00000000  0000b400  2**5                   contents, alloc, load, readonly, data   7 .comment      00000023  00000000  00000000  0000b5e4  2**0                   contents, readonly   source: http://wiki.osdev.org/elf  other sources such as wikipedia also show only the most basic section names, leading you to believe that these are all that are allowed
try checking on /media,  on my system (i'm running kubuntu 11.04) all the floppy, cdrom and usb gets mounted on /media so you'd like to check there 
the following bash code is set to work with the byte being representred in binary
it is known issue, described in red hat bugzilla:     systemd's lack of random delay functionality of cron is hitting us
for columns of size 10 distant of 20 characters  paste &lt;(fold file1 -w 10) &lt;(fold file2 -sw 10)  | pr -t -e20    fold options   -w is the column width -s avoid having separated words from line to line  pr options   -t  leads to omit header and footer (date, time and page number) -en set n to be the number of spaces replacing the tab produced by paste   
besides of the official repositories of the distributions, an user can add a repository for software outside of the regular packages of the distribution
you can do this from bash using a 0 timeout to read.  if read -t 0 then read data fi   to test a file descriptor other than stdin, say 3, use -u 3
file will tell you if there is a bom
if the tunnel terminates for any reason, screen won't restart it
by default, if your fstab entry is:  uuid=913aedd1..
the 050 should be clear, that sets read and execute bits for the group  the first 6 sets the set-user-id and set-group-id bits (see man 2 chmod). effectively this means that executing container-extractor can only be done by root or members of the group hadoop and that the executable runs with effective uid being root and effective gid being hadoop. 
load average doesn't mean what you think it means
ooopps, gunicorn runs as:  $ gunicorn [options] app_module   and you did  $ gunicorn app_module [options]   the last part of your gunicorn_start.sh script shall be:  exec /html/public_html/yogavidya/venv/bin/gunicorn \     --name $name \     --workers $num_workers \     --user $user \     --bind=unix:$sockfile \     ${django_wsgi_module}:application     on a side note, i also strongly suggest to change:  sockfile=/html/public_html/yogavidya/run/gunicorn.sock   to  sockfile=/var/run/yogavidya_gunicorn.sock   on arch (and a couple of other distros too) /run is a tmpfs, which is set solely in memory
see this file for your kernel (probably most hasn't even changed over the major kernel versions):  http://www.mjmwired.net/kernel/documentation/devices.txt 
you have three options:   1) emulation (wine, crossover linux, bordeaux)  2) virtualization (vmware player or vmware workstation, parallels desktop, oracle virtualbox)  3) dual boot  for c# development on linux, mono project is the way to go
you can use proot almost the same way as in your example:  proot -b /fake-home:/home ls /home   unlike bindfs/fuse, proot is able to bind over files and directories you don't own. 
"ip forwarding" is a synonym for "routing."  it is called "kernel ip forwarding" because it is a feature of the linux kernel.  a router has multiple network interfaces
find out if the rpm's files have been installed:  rpm -ql dos2unix   regarding your installation, it looks good, the rpm expects a group (mockbuild) and a user that you do not have
best would be to use the timeout command if you have it which is meant for that:  timeout 86400 cmd   the current (8.23) gnu implementation at least works by using alarm() or equivalent while waiting for the child process
solution a: use arm  find and download proper packages here (also dependencies) , and use pacman -u xx.xz to rollback  http://arm.konnichi.com/search/index.php?a=32&amp;q=xorg-server&amp;core=1&amp;extra=1&amp;community=1  solution b:  bulid from source  clone this repository:  git://pkgbuild.com/aur-mirror.git  and find the old version of package you need , and use makepkg to build the arch package , and install them with pacman -u xx.xz  get ready for damaging your system ;-p 
you can still run a talk variant on modern unices
this looks somewhat problematic if you do not have experience of advanced iptables manipulation and overview of how linux filters traffic for local processes.  in your mode qemu runs an emulated nat: all calls to nic from guest will be translated as socket/connect/send/recv calls by qemu process itself
just don't use set -e and add an exit to your if fail branch
try,  chown manuel:manuel /home/manuel/subdir/    above command will give your account ownership over the folder subdir, if there's more directories owned by root under subdir (you can check with ls -rl /home/manuel/subdir/) you could add the recursive option -r to the earlier chown command like this chown -r manuel:manuel /home/manuel/subdir/
it's usually used as a quick and dirty way to provide answers to an interactive script:  yes | rm -r large_directory   will not prompt you about any file being removed
i can think of at least 2 options you can choose from:   change ~/.gtkrc-2.0 and ~/.config/gtk-3.0/settings.ini directly (the former for icons in gtk2 applications, the latter for gtk3 applications) - the setting you're looking for is gtk-icon-theme-name in both cases
%wheel all = (postgres) /usr/bin/psql  
i found a package in this link
you may want to try :  eval rm foo.{$ext0..$extn}   not sure whether this is the best answer, but it certainly is one. 
the below works in bash
some programs are not designed to be run with continuous user input and disconnect from the terminal at the first opportunity
due to the fact that control+g has to interrupt emacs while it's doing other things (and not reading normal input), it's hardcoded into the emacs core and can't be rebound using normal methods
i think the best bet is for you to acquire another sgi machine, unfortunately
a couple of other ways to look at this
i haven't got the time for all details now, but see the gnome power manager's faq "how do i make my application stop the computer auto-suspending" which points to the inhibit() and uninhibit() dbus-calls.  a caveat: if the process calling inhibit() exits, the inhibition is ended - dbus-send in a shell script thus won't do, but some wrapper script (e.g
well, it's plain and clear in the log …  can't access lock files' directory /tmp/firebird   your problem description does not indicate that you did indeed check the basic things, such as permissions on the directory sufficient for the user and groups the firebird server is running under
you can do:  find 
du uses stat(2) to find the number of blocks used by a file
 generally, unix prefers lowercase, definitely not all caps, readmes are a special case and are uppercase (as with other special files like copying, license, etc..) - but otherwise, general (or "regular" as you call them) text files should not use uppercase. either hyphens or underscores, avoid spaces - even escaped somewhere in the middle: short enough that you can read it quickly and not waste space on your screen, but not so long that it will wrap around in a gui..  
nope, never have been able to read blue on black (and life is far too short to fiddle with colour customizations in every terminal or console combination i might use), so i disable colors by default
bash(1) will call the command_not_found_handle() function if defined and the command to be executed is not found
try this command:  sudo -i bash  
in my .bashrc, my ps1 is configured to display the last component of my current working directory
i was in the process of writing the following answer to the other, related question here when it was deleted
the code that generates this file is in the unix_seq_show() function in net/unix/af_unix.c in the kernel source
if your on screen keyboard is appearing at your login screen, find the circle with the little guy in it and click on him
they're device nodes:     in unix-like operating systems, a device file or special file is an   interface for a device driver that appears in a file system as if it   were an ordinary file
use script /tmp/output to start recording in a new shell, then type your commands and look in the /tmp/output file, e.g
both gksu and gksudo pass your password to sudo
most packages are installed in places and with permissions so they are accessible by multiple users
what you're actually doing is asking how to set the ports used postfix so that it is also listening on tcp/587, which is the "submission" port.  i have the following in my /etc/postfix/master.cf:  submission inet n       -       n       -       -       smtpd   -o smtpd_tls_security_level=encrypt   -o smtpd_sasl_auth_enable=yes   -o smtpd_client_restrictions=permit_sasl_authenticated,reject   -o milter_macro_daemon_name=originating   the first column of the first line specifies the service (e.g., the port from /etc/services), listening as an internet service, using the smtpd command
a=('1' '2') &amp;&amp; echo "${a[0]}" would be better like this
use inline echo:  $ echo -e "line1\n\nline2\nline3" line1  line2 line3  
variables are not expanded within single quotes, they are treated literally then.  use double quotes instead:  sed -i "s/wordtoreplace/$the_word/g" thefile.sh  
that's it, finally managed to enable it, took 6 hours researching
sda0, sda1 are the hard drives attached to your machine.  dm-0 &amp; dm-1 are the logical volume managers' logical volumes you would have created while installing or configuring your machine  you can read more about it at wiki 
the only answer is no
*.* only matches filenames with a dot in the middle or at the end
background or foreground ?  if the code you show is full code, i do not see why you run nohup .
if you are using rsyslogd you should be able to write a filter to remove it as shown here. 
you will need to pass the static ip options to the kernel so that the kickstart process can locate your ks.cfg
  you can put the following lines in your vimrc to quit vim if any of its arguments are a directory:  for f in argv()   if isdirectory(f)     echomsg "vimrc: cowardly refusing to edit directory " 
you create a directory called /swapfile and a file called swap but in the /etc/fstab you refer to /swapfile/swapfile instead of /swapfile/swap 
you can use the following string literal syntax:  &gt; echo $'\'single quote phrase\' "double quote phrase"' 'single quote phrase' "double quote phrase"   from man bash     words of the form $'string' are treated specially
you need to escape the space, less than and greater than characters using a backslash:  mv \&lt;oracle\ path\&gt;data2.dbf data2.dbf   should work. 
if you are refering to the font size in the terminal in general, add these lines to your ~/.xdefaults file:  mrxvt*fontname: dejavu sans mono:pixelsize=13 mrxvt*facename: dejavu sans mono:pixelsize=13 mrxvt*font: xft:dejavu sans mono:pixelsize=13   replace my font example (dejavu sans mono) with your desired font and size.  keep in mind that you can use * to define the font in all terminals (vt ones like aterm, *rxvt, xterm, etc.) with code like this:  *fontname: dejavu sans mono:pixelsize=13 *facename: dejavu sans mono:pixelsize=13 *font: xft:dejavu sans mono:pixelsize=13   personally i use the second method, but you can define different fonts in different terminals if you like. 
you can set the position and size of the gvim window through the -geometry command line option
an alternative to sed for simple things like this is tr:  top -p $(pidof program | tr ' ' ',')   tr can also easily handle a variable number of spaces:  tr -s ' ' ','   additionally, if you have it available, pgrep can work well here:  top -p $(pgrep -d , program)   make sure that you leave a space between -d and , as the comma is the argument (the deliminator).  also, note that pgrep will return every result of "program" so if you have a process called "program-foo," then this will also be returned (hence the name pgrep). 
if perl solution is okay
if you only want to delete a file in /home/charlesingalls (and not a file in a subdirectory) then it's easy: just check that the argument doesn't contain a /.  case "$1" in   */*) echo 1&gt;&amp;2 "refusing to remove a file in another directory"; exit 2;;   *) rm -f /home/charlesingalls/"$1";; esac   this runs rm even if the argument is . or .. or empty, but in that case rm will harmlessly fail to delete a directory.  wildcards are not relevant here since no wildcard expansion is performed.  this is safe even in the presence of symbolic links: if the file is a symbolic link, the symlink (which is in /home/charlesingalls) gets removed, and the target of that link is not affected.  note that this assumes that /home/charlesingalls cannot be moved or changed
there is no scheme, screen, like any terminal application, doesn't deal with keystrokes, but with characters or sequences of characters which it reads from a terminal device.  it's the terminal (or terminal emulator like xterm) that transforms a keystroke into a character or sequence of characters which it sends over a wire (the wire being virtual in the case of a terminal emulator) to the system
this is generally considered a very dangerous idea because it introduces the possibility that you will be tricked into executing something thinking it is something else
changing xft.dpi from 96 to 100 solved the problem for me
since you installed from source code (i'm guessing with ./configure; make; make install), the rpmdb (rpm database) didn't get updated, so rpm thinks you still ahve the old version installed
most display managers let the user choose a session type when logging in
you need to run make as follow:   make 2&gt;&amp;1 | tee make.txt  
many answers found on the internet (including those in tnw's comment) rely on /sys/bus/usb/devices/2-2/power/level or /sys/bus/usb/devices/2-2/power/control which are both deprecated since 2.6.something kernel
thanks for the tip wag
get rid of the &amp;
try:  $ perl -00pe 's/\n(?!\d+,\d+)//g' file 1407233497,1407233514,bar 1407233498,1407233515,foomingstats&amp;fmt=n 1407233499,1407233516,foobar   perl read file line by line by default with -p option, so your regex can not work.  -00 option turns paragraph slurp mode on, your regex now can work on multiline.  from perldoc perlrun:     -0[octal/hexadecimal]      specifies the input record separator ($/ ) as an octal or hexadecimal   number
at is excellent tool for one-off commands
the hostname is stored in three different files:   /etc/hostname used as the hostname /etc/hosts helps resolving the hostname to an ip address /etc/mailname determines the hostname the mail server identifies itself   you might want to have a deeper look with grep -ir hostname /etc  restarting affected services might be a good idea as well. 
one fairly good way is to check the routing table to see where the default routing goes  ip route list | grep default  
since the same key has bugged me both in windows (inconveniently switching out of games at the wrong time), and linux, i have levered off the keycap itself so i will never accidentally hit it
well, that's easy
the tool you're looking for is called exiftool
:set list  this will show you whitespace characters like tabs and eols
thanks to the tip from captcha about ssh from the console, i found out (from the console information) i was trying to ssh using an incorrect ip address
to view the content of that file you could rename it - e.g
so where points that address you typed in a gateway field? i've never configured openvpn using networkmanager but i suppose that is the place where you should provide the address of your router
the /dev tree contains device nodes, which gives user space access to the device drivers in your os's running kernel.¹ all posix type oses have a /dev tree.  the /proc tree originated in system v unix, where it only gave information about each running process, using a /proc/$pid/stuff scheme
this is related to a new driver introduced in fedora 20 that does not need more than those two governors
personally, i use wtfismyip.com which returns pure text and does not need parsing:  $ wget -qo - http://wtfismyip.com/text 123.456.78.9  
this is a well known problem, currently without solution.  on debian (and other systems), systemd fails to assemble an encrypted btrfs array, because of the parallel processes and various tests
you can prepare a minimal install inside a qemu kvm instance and then transfer the image to the remote system.  for example to install a raid-1 centos 7 system:  on you local workstation:  $ truncate --size 5g disk1.img $ truncate --size 5g disk2.img $ qemu-system-x86_64 \     -cdrom centos-7.0-1406-x86_64-dvd/centos-7.0-1406-x86_64-dvd.iso \     -hda disk1.img -hdb disk2.img -m 2g -boot d -enable-kvm \     -net user,hostfwd=tcp::10022-:22 -net nic # enable net, ssh portforwarding   inside the qemu instance, you can install centos 7 using the offical recommended installer - i.e
crontab should be used for jobs that you want to have repeated regularly
the standard way of indicating that a .deb package requires a java runtime environment (the jvm, not the jdk) is to specify a dependency on default-jre or default-jre-headless (the former for programs with guis, the latter if no gui is necessary), with alternative dependencies on the appropriate versions of java-runtime (java6-runtime if your application uses java 6 or later, java7-runtime for java 7 or later, etc.):  depends: default-jre | java6-runtime   or  depends: default-jre-headless | java6-runtime-headless | java6-runtime   etc.  this handles all the debian-provided jres (or debian derivatives), and the oracle jres if they were processed using java-package
the best place to put your own system-wide-scripts is at /etc/profile.d they need an ".sh" suffix to work
line=$(/bin/wstalist | grep 'uptime') sec=${line##* } sec=${sec%%,} h=$(( $sec / 3600 )) m=$(( $(($sec - $h * 3600)) / 60 )) s=$(($sec - $h * 3600 - $m * 60)) if [ $h -le 9 ];then h=0$h;fi if [ $m -le 9 ];then m=0$h;fi if [ $s -le 9 ];then s=0$h;fi echo $h:$m:$s  
why not simply use the proper commands:  echo "&lt;?php" &amp;&amp; cat test.php  
most linux distributions include the config parameters used to compile the kernel in /boot/config-&lt;kernel-version&gt;.  so  grep -x 'config_packet=[ym]' "/boot/config-$(uname -r)"   should tell you if af_packet socket support is included (m for as a module).  otherwise, you can just try and create a socket (using socket(2), see packet(7) for how to do it) in the af_packet family and check if reports an error. 
option --domains specifies a list of domains to be followed
i think it's possible to start whatever you want from /etc/inittab   e.g
well, we did code reading as it was being suggested in the comments and found the section of the patch where system may go into infinite loop(in irq) and won't come out of it
entropy_avail does not indicate the number of bits available in /dev/random
the linux terminal type is for the virtual consoles (also called virtual terminals or consoles), the text-mode consoles provided by linux on pc-style hardware and reached by alt+f1 or ctrl+alt+f1 and so on
you can do this with perl, using the excellent xml::twig module
the pseudo-terminal slave, e.g.,/dev/pts/1 is allocated each time you open a terminal
basic commands will be the following:  # cat /etc/gentoo-release  gentoo base system release 2.1  # uname -r 3.1.6-gentoo   also you can obtain this information in a "gentoo-way" using app-portage/gentoolkit package utils:   # equery list baselayout  * searching for baselayout ... [ip-] [  ] sys-apps/baselayout-2.1:0  # eselect kernel list available kernel symlink targets:   [1]   linux-3.1.4-gentoo   [2]   linux-3.1.5-gentoo   [3]   linux-3.1.6-gentoo *   [4]   linux-3.1.7-gentoo   [5]   linux-3.2.0-gentoo   [6]   linux-3.2.0-gentoo-r1  
you can use virtualenv
that's not a conflict, its a reflection of the fact that the new version of x (1.16) has hit the repos and, as the news makes clear, glamour-egl is deprecated.  follow pacman's advice and select y. 
first, find the keysym which corresponds to insert  $ xmodmap -pke | grep -i insert   this is probably key 118
gnouc's answer explains my first question: "why does it make a difference when i call bash's source command from the _import function as opposed to directly?"  regarding my second question: "how can i normalize the behavior of bash's source command?"  i think i found the following answer:  by changing the _import function to:  function _import {   local -r file="$1"   shift   source "$file" "$@" }   i get the following output when running the foo bash script, i.e
the answer you cite proposes to count how many terminal windows are open by counting the number of extant pseudo-terminals
they look like the same command but the reason they differ is the system state has changed as a result of the first command
in virtual-replace-mode the buffer is harder fixed to its origin position.  1
you can configure this with the repeat-time option:  repeat-time time                      allow multiple commands to be entered without pressing the prefix-key again in the specified time                      milliseconds (the default is 500)
try this,  sed -e '/[/]/common s/^/#/' /etc/fstab sed -e '/[/]/share1 s/^/#/' /etc/fstab  specifying this /[/]common/ will select only lines that contain /common.  if this works then replace -e with -i for executing the changing into the file.  you can do this with awk   awk '/[/]common/{$0="#"$0} 1' /etc/fstab &gt;/etc/fstab.tmp &amp;&amp; mv /etc/fstab.tmp /etc/fstab  awk '/[/]share1/{$0="#"$0} 1' /etc/fstab &gt;/etc/fstab.tmp &amp;&amp; mv /etc/fstab.tmp /etc/fstab    specifying this /[/]common/ {$0="#"$0} will chose those lines containing /common and place a # at the beginning of the line. 
httpd has a list of files to try to display when you give a url that points to a directory, which can be configured with the directoryindex directive
leave the password field blank
in the bash_completion mechanism it's the bash function _filedir_xspec() that is responsible for filename and dirname completions
i would add an entry to your /etc/aliases file like so:  no-reply: /dev/null   be sure to rebuild the aliases database with the newaliases command afterwards.  references   how can i point an email alias at /dev/null?  
it's a trick to prevent the grep command itself from appearing in the ps output.  [...] is a character class specification, i.e
gcc4x is no longer needed as the amd crimson driver was released a few days ago, it supports the newer kernels out of the box.  however since you are on f23, that ships with x.org 1.18 which is incompatible with the amd driver
i am not sure what shell sh.exe provides (since there are multiple shells that use that name for their windows executables), but if it is bash or similar, you can use the $pipestatus array
with sed you can select ranges and delete them:  sed '/&lt;script/,/&lt;\/script&gt;/d' inputfile  
you are absolutely sure in the a pure config as proxypass fail2ban wont work here because of  several reasons
unfortunately i don't believe openssl can do that
there is a utility called sponge that is a part of the moreutils suite
if i understand your question you're asking how one would go about installing 32-bit packages under a 64-bit system
the word "open" does not mean the same thing everywhere.  random access  for a typical text editor, the reason to open a file is to load it for editing
not sure exactly what your question is
yes, according to man df you can:   -t, --print-type      print file system type    another way is to use the mount command
you don't
here is a script that i wrote a while back to fix permissions on files copied from a fat system
do not ever parse the output of ls
i'm not sure how you can examine any particular superblock, but you can use this command to examine the general contents that all the superblocks share like so, using dumpe2fs.  $ sudo dumpe2fs /dev/mapper/fedora_greeneggs-home | less   example  $ sudo dumpe2fs /dev/mapper/fedora_greeneggs-home | less filesystem volume name:   &lt;none&gt; last mounted on:          /home filesystem uuid:          xxxxxxx-xxxx-xxxx-xxxx-88c06ecdd872 filesystem magic number:  0xef53 filesystem revision #:    1 (dynamic) filesystem features:      has_journal ext_attr resize_inode dir_index filetype needs_recovery extent flex_bg sparse_super large_file huge_file uninit_bg dir_nlink extra_isize filesystem flags:         signed_directory_hash  default mount options:    user_xattr acl filesystem state:         clean errors behavior:          continue filesystem os type:       linux inode count:              26722304 block count:              106857472 reserved block count:     5342873 free blocks:              67134450 free inodes:              25815736 first block:              0 block size:               4096 fragment size:            4096 reserved gdt blocks:      998 blocks per group:         32768 fragments per group:      32768 inodes per group:         8192 inode blocks per group:   512 flex block group size:    16 filesystem created:       sat dec  7 20:41:58 2013 last mount time:          sun dec 22 21:31:01 2013 ...   references   superblock definition  
there are pretty good directions on doing it here, titled: disable / enable keyboard and mouse in linux.  example  you can list the devices with this command.  $ xinput --list "virtual core pointer"  id=0    [xpointer] "virtual core keyboard" id=1    [xkeyboard] "keyboard2"     id=2    [xextensionkeyboard] "mouse2"        id=3    [xextensionkeyboard]   and disable the keyboard with this:  $ xinput set-int-prop 2 "device enabled" 8 0   and enable it with this one:  $ xinput set-int-prop 2 "device enabled" 8 1   this only works for disabling the keyboard through x
i tried the steps below, which should work, but does not work on mac (forwards port 20 udp text messages to port 29), but you might want to try it anyway:   cd /tmp mkfifo backpipe sudo nc -ulk 20 0&lt;backpipe |sudo nc -ulk 29 | tee backpipe on another terminal - test it with echo -n “this is a test” | sudo nc -4u -w1 localhost 20   it's possible the usage is mangled or the fifo special file isn't working
the problem is that the direct call makes the script name the command name, see  cat /proc/$pid/comm   that causes pgrep to match
my suggestion on this was, make a backup of whole root fs (including /usr/local), then re-partition, mount all partition, and extract everything
to take control of a running x session you will need to configure your vnc server to connect to the same display as x
you should use winetricks to install the files instead, some files needs specific changes to wine registery which winetricks handle. 
you could eg.: check what's inside your folder :   ls -la /usr/share/applications/   find a similar entry for an other text editor eg.:  # cat /usr/share/applications/sublime.desktop  [desktop entry] encoding=utf-8 name=sublime text comment=sublime text 2 exec=sublime_text icon=/opt/sublime/icon/256x256/sublime_text.png terminal=false type=application startupnotify=true categories=gnome;gtk;development;texteditor;   copy and fix the content per your requirements eg:   cp -p /usr/share/applications/sublime.desktop /usr/share/applications/lighttable.desktop     eg.:  # cat /usr/share/applications/lighttable.desktop [desktop entry] encoding=utf-8 name=light table comment=light table exec=/path/to/your/executable/script/lighttable icon=/path/to/your/icon/light_table.png terminal=false type=application startupnotify=true categories=gnome;gtk;development;texteditor;   note: make sure your gui user has execute permissions on the lighttable script 
i looked at it once, it's quite painful, because all is defined statically in the c++ source code.  you have to define a certain number of rules among the one already existing in scintilla, for things like..
it should be possible in theory, as the swapon manpage states:  [...] the swap file implementation in the kernel expecting to be able to write to the file directly, without the assistance of the file system [...]  so when you have a swap file, the kernel likes to treat it more like a partition, i.e
ok, the summary is that nautilus uses gvfs and you need to tell udev to use gvfs too when reading the fstab entries, you can do this using:  /dev/block-device /mount/point auto x-gvfs-show,ro 0 0   x-gvfs-show will tell udev and anyone interested to use the gvfs helper to mount the filesystem, so gvfs has all the control mounting, umounting, moving mount points, etc.    lets see if we understand how are drives mounted in modern linux systems with gui's (specifically nautilus):  nautilus uses gvfs as backend to mount ftp, smb, block devices, among other things into the file system
there is no simple answer where the backdoor is, but you can find some information which can lead to closer identification.  fist:  the best idea is to drop the vps and deploy a new one.  processes run under root user and someone accessed as root (possible simly guess right your password), so:   change root password (and use a strong one) change ssh key (remove all old/unknown keys from /root/.ssh/authorized_keys) allow access to ssh from your ip only last but no least, update kernel (there can be a security problem).   also check all users on the server and do the same
you have policykit.  policykit is a client-server system for controlling who is authorized to do what
if you need to write portable scripts, you should stick to features in the posix standard (a.k.a
just grep for non-blanks:  grep '[^[:blank:]]' &lt; file.in &gt; file.out   [:blank:], inside character ranges ([...]), is called a posix character class
that is lsb related functions
you can't place it in rc.local because it will require a running x session and rc.local is usually executed before or during starting x
archbang and manjaro both are distroes based on arch-linux with an easy to use install script, both have ability to be used as a live system using a cd/dvd drive or any usb drive;  in usb mode there are some way to install archbang as a persistent system.  here is a tutorial on how to make a live persistent distribution
grub can only boot from linux raid 5 since version 1.99, if i read the changelog correctly
try to define it in the sudo configuration (/etc/sudoers) for your script:  ortega all=(all) nopasswd: /path-to-your-script  
it's simply a warning, you can just ignore it
you can use tee and process substitution &gt;(...) for this:  zcat my_data_file.gz |  # count number of lines in stream tee &gt;(wc -l &gt; /tmp/linecount) |  # further processing process_data.py   note that pipes can be used for line continuation and that comments may be interspersed between commands, a nice feature when building complicated pipelines
you can find out the mac address of a recently contacted device by its ip address using the arp table:  ping -c1 -w1 10.0.2.2 ping 10.0.2.2 (10.0.2.2) 56(84) bytes of data. 64 bytes from 10.0.2.2: icmp_seq=1 ttl=63 time=0.785 ms  --- 10.0.2.2 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.785/0.785/0.785/0.000 ms  arp -n 10.0.2.2 address                  hwtype  hwaddress           flags mask            iface 10.0.2.2                 ether   52:54:00:12:35:02   c                     eth0   you could merge this into a little function:  iptoarp() {     local ip="$1"     ping -c1 -w1 "$ip" &gt;/dev/null     arp -n "$ip" | awk '$1==ip {print $3}' ip="$ip" }  iptoarp 10.10.0.2    # --&gt; 52:54:00:12:35:02   i know of no easy way to get an ip address or netbios name from a mac address
on my deepin linux (a variant of ubuntu), i know two ways to start the virtualbox services.   in the terminal type service --status-all -- it will list the services registered in system with the status mentioned in output
in midnight commander go to options menu / configuration..
for colourizing the output of command or contents of a file, i can think of two easy methods that may work well:   grep - it can be made to show the rest of the file as well, and do multiple matches with a few advanced options - for example:  grep --color -ie 'log|kernel' -c 999 grep --color -ie 'log|kernel|$'   the first searches for log and kernel case-insensitively, and shows the surrounding 999 lines
you can't use capture groups from the regexp in the command to execute
edit your /etc/wpa_supplicant.conf configuration file as follow:  at least you need to add the following line :  ctrl_interface=/var/run/wpa_supplicant ctrl_interface_group=0 update_config=1 config_driver_nl80211=y   you can enable some others support:   ctrl_interface=/var/run/wpa_supplicant  ctrl_interface_group=0  update_config=1  config_driver_nl80211=y  config_wps=y  config_wps2=y  config_wps_er=y  config_wps_nfc=y  uuid=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx    get the uuid through status command from wpa_cli  to connect   run wpa_cli from the interactive mode, run wps_pbc and  push the wps button. once connected run dhclient wlan0 (change wlan0 with your interface wifi)  
here is a script to print the total cpu usage for each user currently logged in, showperusercpu.sh:  own=$(id -nu)  for user in $(who | awk '{print $1}' | sort -u) do     # print other user's cpu usage in parallel but skip own one because     # spawning many processes will increase our cpu usage significantly     if [ "$user" = "$own" ]; then continue; fi     (top -b -n 1 -u "$user" | awk -v user="$user" 'nr&gt;7 { sum += $9; } end { print user, sum; }') &amp; done wait  # print own cpu usage after all spawned processes completed top -b -n 1 -u "$own" | awk -v user=$own 'nr&gt;7 { sum += $9; } end { print user, sum; }'   and here is a slightly modified version for printing the cpu usage of all available users (but skipping the ones with a cpu usage of zero), showallperusercpu.sh:  own=$(id -nu)  for user in $(getent passwd | awk -f ":" '{print $1}' | sort -u) do     # print other user's cpu usage in parallel but skip own one because     # spawning many processes will increase our cpu usage significantly     if [ "$user" = "$own" ]; then continue; fi     (top -b -n 1 -u "$user" | awk -v user=$user 'nr&gt;7 { sum += $9; } end { if (sum &gt; 0.0) print user, sum; }') &amp; done wait  # print own cpu usage after all spawned processes completed top -b -n 1 -u "$own" | awk -v user=$own 'nr&gt;7 { sum += $9; } end { print user, sum; }'   there is also a related script for showing the total memory usage for each user: showperusermem.sh  for live-monitoring just execute these scripts periodically via the watch command. 
okay, your main problem doesn't appear to be the way you execute this
there are a lot of ways to do this
apt-get is like an advanced version of dpkg
you have some choices
flock - manages locks from shell scripts  man flock  eg   flock -x lockfile -c command 
most posix utilities specify that -- can be used to terminate option arguments:  cp -- '-file 1' '-file 2'   you can also reference the current directory using the . hard link to the current directory:  cp './-file 1' './-file 2'  
posix defines the utility umask which sets the file mode creation mask, either for the current instance (without subshells), or for every newly invoked shell (over .bash_profile, .bashrc, etc.).  show the currently set mask in octal or symbolic form:  $ umask 0022 $ umask -s u=rwx,g=rwx,o=rx   the octal numbers indicate the values which are getting removed from the full access:  $ umask 0002     # or: umask g+w $ touch testfile $ stat -c'%a %a' testfile 664 -rw-rw-r--  
when the * is not quoted the shell expands the argument list before running the command
it might be a side effect of sound chip powersaving (switching on and off)
i found the answer myself with the help of another similar answer.  go to settings, settings editor, keyboard-layout and under xkboptions, i added numpad:microsoft to the group string.  now it's working as it used to do in gnome. 
all processes are a line of instructions fed to the processor through memory, which can jump to other parts of memory and manipulate parts of memory as data
if you have a need for specific versions of python, perl, ruby etc
i'm assuming you're on linux by how you phrased your question
most modern applications, including all gtk (→ gnome) and qt (→ kde) applications, use xft, which performs the rendering client-side and sends an image to the server
$ shopt -s extglob $ ls abbc  abc  ac $ echo a*(b)c abbc abc ac $ echo a+(b)c abbc abc $ echo a?(b)c abc ac $ echo a@(b)c abc  
there's a couple ways
you may want look into gnu screen or tmux
following the unix philosophy, you have a tool that lists processes using a given gpu, and a tool that kills processes
intel core 2 (i5) is a 64-bit processor supporting intel 64, intel 64 is intel's implementation of x86-64 
ssh-agent does not support private keys in ppk format (putty)
after having a look at the source code, it seems that consolekit(ck) uses a short script to do shutdown and reboot
sestatus is showing the current mode as permissive.  in permissive mode, selinux will not block anything, but merely warns you
live image creation is a big work  live image have to detect and conforme to hardware while booting!  you have to pre-install all drivers and firmwares...  it's a not so simple job!  i know live-systems.org where you could customize your debian live, but it's debian, not gentoo based, so not sabayon. 
after changing the file mode, and before doing any edit, run m-x revert-buffer to reload the file
i've written a quick guide on backporting the openssl 1.0.1 rpm from fedora core to support rhel6 and variants by replacing the bundled 1.0.0 version to add tlsv1.2 and ecc support
the static-text part displayed before prompt is found in /etc/motd
on the current dir
using cat  since your file is short, you can use cat.  cat filename   using less  if you have to view the contents of a longer file, you can use a pager such as less.  less filename   you can make less behave like cat when invoked on small files and behave normally otherwise by passing it the -f and -x flags.  less -fx filename   i have an alias for less -fx
it sounds like you want to use two different sets of keypairs
#**parallel_scaller.sh** # script to async run scanner.sh # usage: $&gt; bash parallel_scanner.sh "flags for instance 1" ..
you can simulate your command as,   rsync -vrzo --delete -e ssh &lt;remote_host&gt;:'&lt;remote_dir&gt;/file1 &lt;remote_dir&gt;/file2' &lt;destination_dir&gt;/  i.e
the problem is probably that the gdb server output is being blocked because no one reads it, so the gdb client is also blocked
try  find 
there is no need to use awk:  for pr in $(pgrep $name); do      elapse=$(ps -o etime= -p $pr)     [ "${elapse%-*}" -gt "$alter" ] &amp;&amp; echo $pr done   or according  stéphane chazelas' comment  ps -c $name -o pid=,etime= | awk '$2 + 0 &gt; a &amp;&amp; /-/ {print $1}' a="$alter"  
   the idea is for my application to know not to color the output if the program can't print, say, logging output from through a cron job to a file, no need to log colored output, but when running manually, i like to view the output colored   what language are you writing your application in?  the normal approach is to check if the output device is a tty, and if it is, check if that type of terminal supports colors.  in bash, that would look like  # check if stdout is a terminal... if test -t 1; then      # see if it supports colors...     ncolors=$(tput colors)      if test -n "$ncolors" &amp;&amp; test $ncolors -ge 8; then         bold="$(tput bold)"         underline="$(tput smul)"         standout="$(tput smso)"         normal="$(tput sgr0)"         black="$(tput setaf 0)"         red="$(tput setaf 1)"         green="$(tput setaf 2)"         yellow="$(tput setaf 3)"         blue="$(tput setaf 4)"         magenta="$(tput setaf 5)"         cyan="$(tput setaf 6)"         white="$(tput setaf 7)"     fi fi  echo "${red}error${normal}" echo "${green}success${normal}"  echo "${green}0.052${normal} ${bold}${green}2,816.00 kb${normal}" # etc.   in c, you have to do a lot more typing, but can achieve the same result using isatty and the functions listed in man 3 terminfo. 
you can break long lines by escaped newlines, that is \ immediatelly followed by a newline:  ls_colors_parsed=${${(@s.:.)ls_colors}/(#m)\**=[0-\ 9;]#/${${match/(#m)[0-9;]##/$match=$match=04;$matc\ h}/\*/'=(#b)($prefix:t)(?)*'}}   warning  while you can break a line that way nearly everywhere, there are exceptions
this is normal behaviour
if your busybox installation has the uuencode utility, forget all this and use uuencode -m.  base64encode () {   uuencode -m | tail -n +2 }   if you really need to use awk, i think it just can't cope with null bytes
yes, of course it's possible
you could just exec zsh, which will give you a fresh zsh and re-run the init functions
this already has an answer on su:  bash: lookup an ip for a host name, including /etc/hosts in search  basically, you use  getent ahosts host_name   where host_name can either be an entry in your /etc/hosts, in which case it will resolve to that, or a host that your dns can resolve.  quoting the getent(1) man page:     ahosts                  when no key is provided, use sethostent(3), gethostent(3),                       and endhostent(3) to enumerate the hosts  database
it sounds like you downloaded the samba source, and that's not what you want right now
this depends on the specific system calls a process uses; read(2) on a file descriptor returns 0 on end-of-file, while stream i/o will probably use the feof(3) call
i don't know how to do it with a single command, but it works with this loop in bash:  cat data.dat | while read line do   if echo "${line}" | grep -q '[[:alpha:]],[[:alpha:]]'   then     letters=`echo "${line}" | grep -o '[[:alpha:]],[[:alpha:]]' | head -n 1`     for letter in `echo ${letters} | sed 's/,/ /g'`     do       echo "${line}" | sed 's/'"${letters}"'/'"${letter}"'  /g'     done   else     echo "${line}"   fi done  
you would be well advised to convert the static configuration to dhcp until you have proven connectivity
i suppose (but not tried) that the fuse option -o allow_other, also shown in the example in the unionfs-fuse's man page, could be of help.  edit  try this  sudo mount -t aufs -o br:/mnt/disk1-pool=rw:/mnt/disk3-pool=rw \     none /mnt/union-pool   that seems to work also without aufs-tools package. 
if you are maintaining the program, then make it store the history
there is no gimp2.8 in backports, therefore the easiest way is to add testing repositories to your machine:  echo "deb http://ftp.de.debian.org/debian/ testing main" | sudo tee -a /etc/apt/sources.list   then you need to configure apt pin priorities to make testing version as additional to prevent distributive upgrade. for that do  echo "package: *       pin: release a=stable       pin-priority: 700        package: *       pin: release a=testing       pin-priority: 650" | sudo tee -a /etc/apt/preferences   after that you can update you packages list:  aptitude update   and install gimp2.8 from testing with:  aptitude -t testing install gimp   it will resolve dependencies and upgrade all necessary packages automatically.  also you can backport gimp yourself, but it is much harder (: 
at shutdown, i saw an error:     syntax error on line 230 of /etc/apach2/apache.conf   ....   /etc/apache/sites-enables/mysite: no such file or directory   the thing was, mysite was symlinked to a file in my home folder.  that normally shouldn't be a problem, i thought.  but as far as i know, my home partition is encrypted
most top implementations have a way to turn the display of threads on or off.   htop: in the “setup / display options” menu, “hide userlands threads”. linux top: press h to toggle the showing of threads (but they're off by default). openbsd top: press t to toggle the showing of threads (but they're off by default).   note that memory mappings, and hence memory occupation, is a property of a process, so you'll always see the same numbers for every thread in a process
via wikipedia:     esp (efi system partition) contains the boot loader programs for all   installed operating systems (which are contained in other partitions   on the same or other storage device), device driver files for devices   present in a computer that are used by the firmware at boot time,   system utility programs that are intended to be run before an   operating system is booted, and data files such as error logs.   further, relating it to bios-mode booting:     uefi provides backward compatibility with legacy systems by reserving   the first block (sector) of the partition for compatibility code,   effectively creating a legacy boot sector
no
unless the screen session in question is created with multiuser on, you can't
the ports system provides a make target to display runtime and buildtime dependencies see the ports man page.  so you should be able to use make pretty-print-run-depends-list pretty-print-build-depends-list to get a list of dependencies.  run-depends-list, build-depends-list                   print a list of all the compile and run dependencies,                   and dependencies of those dependencies, by port direc-                   tory.   all-depends-list                   print a list of all dependencies for the port.   pretty-print-run-depends-list, pretty-print-build-depends-list                   print a list of all the compile and run dependencies,                   and dependencies of those dependencies, by port name and                   version.   missing          print a list of missing dependencies to be installed for                   the port.   you can use these targets to make a shell script to follow the dependencies (this was a stupid quick hack so there is probably a better way).  #!/bin/sh  printdeps() {   local ni   local dep   local thisdir    dir=$1   port=`basename $dir`   i=$2   ni="${i}${port}-&gt;"    thisdir="$dir"   cd "$dir"   echo ${i}$dir   for dep in `make build-depends-list` ; do     printdeps $dep "$ni"   done   cd "$thisdir" }  printdeps $pwd   for webalizer you will find at least this build dependency path to python webalizer->gd->tiff->freeglut->libglu->libgl->/usr/ports/lang/python 
from wikipedia:     ipv4 network standards reserve the entire 127.0.0.0/8 address block for loopback purposes
you are losing the spaces when you expand $line
in the end i couldn't find a suitable solution to my problem and so i wrote my own program to solve it
you don't need the second !
deleted /etc/x11/xorg.conf, restarted in recovery mode and then it worked. 
if all you want is an lsblk that shows you primary/logical partitions, you should be able to do this with a combination of fdisk and parsing
one easy way is to use a named pipe:  # choosing a unique, secure name for the pipe left as an exercise pipe=/tmp/feed-data-to-program  # create the named pipe mkfifo "$pipe" # start the python program in the background myprogram &lt;"$pipe" &amp; # now grab an open handle to write the pipe exec 3&gt;"$pipe" # and we don't need to refer to the pipe by name anymore rm -f "$pipe"  # later, the shell script does other work,... # ...possibly in a loop? while :; do     ...     ...     # now i've got something to send to the background program     echo foo &gt;&amp;3     ...     ... done   it would be nice to avoid the need for a temporary entry in the filesystem, and i know that some shells like zsh provide a way to do that, but i don't know of a portable way. 
depends on the platform.  deb based:  apt-file search info2html   rpm based:  yum whatprovides info2html   ips (solaris 11, openindiana, omnios, etc) based:  pkg search info2html   freebsd (openbsd?):  cd /usr/ports make search key=info2html   netbsd, smartos:  pkg_search info2html   gentoo linux:  emerge --search info2html  
why the old versions?  the primary reasons are stability and compatibility
nutshell:  yes exhibits similar behavior to most other standard utilities which typically write to a file stream with output buffered by the libc via stdio
package_ver=1.2.3 use_version_from=package_ver version_to_use=${!use_version_from} echo $version_to_use     1.2.3   this is "indirect parameter expansion" as described in the bash manual  note, it's not strictly necessary to provide quotes on a variable assignment a=$b vs a="$b" -- word splitting is not performed during an assignment (can't find the reference for that just now) 
thanks for @siyuanren 's suggestion. convmv can deal with the mess situation keeping ascii unchanged which avoid being garbled.  command convmv -f gbk -t utf8 * works fine under this circumstance.  by the way, another solution is use -o loop,utf8 while mounting image files, or just use udisksctl which can automatically deal with filename encoding.  p.s
since posting this question i have found a partial solution
   why does systemctl think my application is not running?    because, as tom hunt says, it isn't running.     could it be that systemctl is not calling the stop function because it thinks my application is already stopped?   no
i looked for sometime into top and there is no straight forward way to do this
case 1:  awk '!nf {if (++n &lt;= 2) print; next}; {n=0;print}'   case 2:  awk '!nf {s = s $0 "\n"; n++; next}      {if (n&gt;1) printf "%s", s; n=0; s=""; print}      end {if (n&gt;1) printf "%s", s}'  
since you're not actually changing the "cast" line:  sed '/cast \$recv \$ue_capability_enquiry/{a\                 set trans_id 1 n;d}' file   as kusalananda comments, this command:   when one of the wanted "cast" lines is found:   append the new line take the next line from the file (the unwanted "set" line) and delete it    in hindsight, this does not confirm that the delete line is the one you want to delete
there is a standard for desktop entry which is specified in these pages. you can specify what action to take when you open (effectively click) that desktop item
if you want to extract the downloaded zip in each of the three directories the  middle part of the script should be:  mkdir -- "$@" || exit  wget -q http://foundation.zurb.com/cdn/releases/foundation-latest.zip &amp;&amp;   for d do      (        cd -- "$d" &amp;&amp;          unzip -q ../foundation-latest.zip      )   done &amp;&amp;   rm foundation-latest.zip  
here is their documentation on interface creation, titled: red hat enterprise linux 3: reference guide - chapter 8
if you are just doing a video as you said, you dont need the real ifconfig to show the information.  you can create a text with the false ifconfig output, and create a temporary alias like this:  alias ifconfig='cat ifconfig_tutorial_modified_text.txt'    then when you call ifconfig the ifconfig_modified_text will show on the screen so the video will look like real
yes, you can do this by using symbolic notation in chmod:  chmod -r go=u /path/to/directory   typically the mode specifiers following the operator consists of a combination of the letters rwxxst, each of which signifies the corresponding mode bit
b43-lpphy-installer is the name of the package for ubuntu, not for debian.  you install it with the command in jessie (debian 8):  sudo apt-get install firmware-b43-installer   by the kernel version, you seem to be using debian 8.  to find out details about debian packages, you can search packages by name or their files at:  https://packages.debian.org/  for instance, the package in question can be consulted here:  https://packages.debian.org/jessie/firmware-b43-installer  from our dialogue, i have seen you still have no apt sources configured.  to be able to install the packages, and also download security updates from the internet, you would better comment out the line from /etc/apt/sources.list to install from cd/dvd:  #deb cdrom:[debian gnu/linux 8 _jessie_ - official snapshot amd64 live/install binary 20150908-22:02]/ jessie main   and add this two lines, one to install the official packages, and another to install the updates:  deb http://ftp.us.debian.org/debian/ jessie main contrib  non-free deb http://security.debian.org/ jessie/updates main contrib non-free   after inserting this lines, you do an  sudo apt-get install update   and  sudo apt-get install upgrade   to install the latest security upgrades
open vswitch (ovs) has a git repository and everything about that is located there. so, when a new stable version of ovs releases, related packages will be updated in openstack repository, so by entering "apt-get upgrade" or "apt-get update", you can upgrade open vswitch's packages.  if you want to use unstable releases , you can download them from here. 
part of your problem is that you have the &gt;&gt; trap.log outside the (quoted) command arg, so all you’re getting in the trap.log file is the output from the trap command itself – which is nothing. i’m not sure what you mean by saying “trapped &amp; ready” when your script is terminating, but it looks like what you mean is    trap 'rm -f filename; echo "message" >> trap.log' sigspec …   and i agree with karlo: if you are “just killing the servers which are being used by the script,” then the script is quite probably exiting (rather than being killed by a signal) and you should use the exit (or, equivalently, 0) sigspec (possibly in addition to 1, 2, and 15).  p.s
that should be because upon logging into the remote shell session, that server's ps1 is sending you back the same \033]0;title\007 command sequence which makes your terminal program intercept and display accordingly
 over simple ssh, you will not see fedora desktop. if you want to operate on desktop, probably only reasonable solution is vnc. not having static ip is not a disaster
usually the location of the usb port (bus/device) determines the order it's detected on
to translate what you wrote directly into specfile macros:  %if 0%{?fedora} == 4 buildprereq &gt;= apr0.9 %endif  %if 0%{?fedora} == 10 buildprereq &gt;= apr2.0 %endif   you could probably change the first %endif to an %else but i wanted to keep my rewrite as similar as possible in case there are other circumstances involved.  if you want to support versions of fedora between fc4 and f10 or later, you can use >= and &lt;= as well
i am not aware of a ssh option that can accomplish this, it seems like a routing problem
you could create two ~50gb files, one per disk
i guess there isn't an easiest way than creating an alias, but if you want to simplify this you could do ctrl+r and type update, then you could be able to see that line you executed in a certain time, then press return to execute it again.  prompt:~$    ctrl+r  (reverse-i-search)`upda': sudo apt-get update; sudo apt-get upgrade  
just my luck, right after i posted this question i found an answer.  make fetch-recursive   here's the applicable info from the handbook:     for users who cannot be connected to the internet all the time, make   fetch can be run within /usr/ports, to fetch all distfiles, or within   a category, such as /usr/ports/net, or within the specific port   skeleton
sounds like you have to build your own repository.  put your rpms in your desired version into that repository
you can use python poppler for getting annotations.you can download it from this website 
i would try  awk '{print &gt;&gt; $1 ".txt" ;}'    where    print print the whole line. &gt;&gt; $1 ."txt" write (append) this line to the file indicated by $1, with .txt added.   edit:  in case you have comment lines, lines with dots, etc  try  awk '$1 ~ /cha/ {print &gt;&gt; $1 ".txt" ;}'    which would only fill file begining with 'cha'. 
you do it with x resources
you don't specify any tools, so i use perl as example:  $ echo pty[r=4]@id | perl -nle '     print "$1\n$2\n$3\n$4"         if /^([a-za-z0-9]*)(\[([a-za-z0-9=]*)\]){0,1}@([a-za-z0-9]*)$/ ' pty [r=4] r=4 id  $ echo pty@id | perl -nle '     print "$1\n$2\n$3\n$4"         if /^([a-za-z0-9]*)(\[([a-za-z0-9=]*)\]){0,1}@([a-za-z0-9]*)$/ ' pty   id   with regular expression capture group, you can use backreferences to get the previous matches
the file which was the source for t was created using notepad on windows 8 and copied by ubuntu 13.04 into my home directory
the difference between sudo and su is how they perform authentication:   su prompts for the target user's password. sudo checks whether the source user is authorized to run the command (the authorization is specified in /etc/sudoers)
notes   nic device handles  the examples below assume that the network interface is a wireless card named wlan0
man section 5 is "file formats and conventions" and is not installed by default
i simply forget about default config and start defining things on my own
the exit code is contained in $?:  fun 2 a=$?  
the easiest and cleanest solution is probably to use sudo.  you can configure it to allow a given unix group to run exactly this script as root.  %iptablegroup all = (root) nopasswd: /path/to/script    then all you have to do is add the needed users to that group and everything should be fine. 
   what are -xms and -xmx?   xms256m ---> selects a low initial jvm heap size for an application
if you want to schedule a task using cron, an alternative to crontab in many distributions is to add a file to /etc/cron.d, in the traditional system crontab format (the variant which specifies the user)
i posted this question to the centos 6 networking forum and the response there was that using hwaddr is the only supported method (at least for networkmanager)
using any mount system, you want to avoid situations where nautilus lists the directory containing a mount that may or not be mounted
if you really have enough ram available again you can use this sequence (as root):  $ swapoff -a $ swapon -a   (to force the explicit swap-in of all your applications)  (assuming that you are using linux) 
perhaps you're getting confused with the -t # switch
if you want to run the script on a specific device, you can use the vendor and product ids   /etc/udev/rules.d/test.rules:  attrs{idvendor}=="152d", attrs{idproduct}=="2329", run+="/tmp/test.sh"   test.sh:  #! /bin/sh  env &gt;&gt;/tmp/test.log file "/sys${devpath}" &gt;&gt;/tmp/test.log  if [ "${action}" = add -a -d "/sys${devpath}" ]; then     echo "add ${devpath}" &gt;&gt;/tmp/test.log fi   with env, you can see what environment is set from udev and with file, you will discover the file type.  the concrete attributes for your device can be discovered with lsusb   lsusb   gives      ...   bus 001 device 016: id 152d:2329 jmicron technology corp
if you have a copy of xargs that supports parallel execution with -p, you can simply do  printf '%s\0' *.png | xargs -0 -i {} -p 4 ./pngout -s0 {} r{}   for other ideas, the wooledge bash wiki has a section in the process management article describing exactly what you want. 
in light of further research of mine, this machine may have been infected by a trojan, we need to exercise caution now.  before any upgrade procedures, i.e
on any posix-compliant system, you can use the etime column of ps.  lc_all=posix ps -o etime= -p $pid   the output is broken down into days, hours, minutes and seconds with the syntax [[dd-]hh:]mm:ss
the only chance i see is configuring xkb to map your keys accordingly. a few applications like games might directly listen to the actual keys pressed, but usually everything else uses just the xkb mapping.  there are two different tools for configuring: setxkbmap and xmodmap. in theory xmodmap is deprecated and should be replaced by setxkbmap, but sometimes good old xmodmap is handy, too.  you are limited to the features supplied by xkb, but even xmodmap supplies a limited set of modifiers
 -inet6          disable inet6(4) on the given interface and remove all                  configured inet6(4) addresses, including the link-local                  ones
in debian 7 is not possible to use   apt-get install firmware-ralink  by default.  the solution is here  you have to download firmware-ralink and after use dpkg -i in this file
g/somepattern/+d  in the following example baz was removed
you can set global parameter in your .vimrc  set hidden   or specify hidden attribute for selected buffer using bufhidden. when the buffer is hidden (not abandoned like default) when you modify it outside vim you will be noticed that some changes occured and you can load new content or discard this changes. 
it may be the case that your colleague, while creating the account, created the home directory "by hand" which resulted in it being owned by root
rhythmbox needs the mpris plugin enabled (use the plugins window to enable the plugin)    modern rhythmbox versions (2.90.1 and later) exposes a session dbus entry called "org.gnome.rhythmbox3" when rhythmbox is actually running
you can test this quickly by trying to create a file of the appropriate size
red hat family distributions (including centos and fedora) use /var/log/messages and /var/log/secure where debian-family distributions use /var/log/syslog and /var/log/auth.log.  note that in newer fedora (or rhel/centos 7 if someone has gone out of their way to configure it this way), you may have no traditional syslog daemon running
you need to declare the escape sequences sent by your usual terminals in your ~/.vimrc
@deroberts answer is great, though i want to share some other information that i have found.  gzip -l -v  gzip-compressed files contain already a hash (not secure though, see this so post):  $ echo something &gt; foo $ gzip foo $ gzip -v -l foo.gz  method  crc     date  time           compressed        uncompressed  ratio uncompressed_name defla 18b1f736 feb  8 22:34                  34                  10 -20.0% foo   one can combine the crc and uncompressed size to get a quick fingerprint:  gzip -v -l foo.gz | awk '{print $2, $7}'   cmp  for checking whether two bytes are equal or not, use cmp file1 file2
tl;dr  the 3rd attempt actually works! i'm leaving the first 2 attempts so that others that may come across this q&amp;a in the future will hopefully gain some insight into how non-trivial a problem it is to parse rpm version information and determine the lineage of which came first, second, etc.  attempt #1 (op said didn't work)  this command will sort the output and give you them in version order:  $ rpm -q kernel --queryformat "%{version} %{release}\n"|sort -n 2.6.18 238.12.1.el5 2.6.18 238.19.1.el5 2.6.18 274.12.1.el5 2.6.18 308.8.2.el5   why it didn't work: a naive person would think that you can use some variant of the sort command to perform this task, but there is enough variability and inconsistency in the formatting of the actual version information for a given rpm that it just isn't up to the task.  attempt #2 (op said didn't work)  $ rpm -q --last kernel | head -n 1 | cut -d' ' -f1 kernel-2.6.35.14-106.fc14   why it didn't work: i had high hopes that this approach would yield the results the op was looking for, but the issue with this one as @joel pointed out in the comments, is that the --last switch is merely returning the results sorted by the date the rpms were installed.  attempt #3  this one will definitely do the job
jasonwryan pointed me in the right direction
oh yes, you can!   open your ~/.bash_aliases file and type the following to the end of the file(create a new ~/.bash_aliases if it doesn't exist):  alias mycp='cp ~/.bashrc ~/dropnot/level1/setups/bash1'   this will create an alias mycp(you can give a different name for mycp)which will copy your ~/.bashrc file to the desired location. you could create a shell variable which contains the long path and then use the variable in place of the long path
i am using fedora linux
 #!/usr/bin/sh    the normal location of sh, in almost every unix out there, is /bin/sh
it appears that the stack memory limit is not allocated (anyway, it couldn't with unlimited stack)
you can do this:  #!/bin/bash  declare -a site=() theme=()  add_site() {     local shortcut=$1     site[$shortcut]=$2     theme[$shortcut]=$3 }  while ifs= read -r line; do     case "$line" in     shortcut=*)         # ifs== read -r __ shortcut &lt;&lt;&lt; "$line"         _shortcut=${line#*=}         ;;     site=*)         # ifs== read -r __ site &lt;&lt;&lt; "$line"         _site=${line#*=}         ;;     theme=*)         # ifs== read -r __ theme &lt;&lt;&lt; "$line"         _theme=${line#*=}         add_site "$_shortcut" "$_site" "$_theme"         ;;     esac done &lt; file.ini   test output with added echo "$@" on function:  x1 example1.com alpha x2 example2.com beta  
put an echo in front of the command to run?  $ echo a b c d e | xargs -n2 echo rm rm a b rm c d rm e  
what you have is in fact ascii (in its usual encoding in 8-bit bytes) with a bit of ucs-2 (unicode restricted to the basic plane (bmp), where each character is encoded as two 8-bit bytes), or perhaps utf-16 (an extension of ucs-2 that can encode all of unicode by using a multi-word encoding for code points above u+d7ff).  i doubt you'll find a tool that can handle such an unholy mixture out of the box
according to the documentation, the default /bin/sh shell is dash, but the default interactive shell is bash:  the default interactive shell is bash (it's defined in /etc/adduser.conf then copied to the user profile, see chsh(1) manpage).  system scripts with the posix shebang will be run by dash, but when you--the user--open an interactive shell, it will be /bin/bash unless you elect to change it. 
cd parent_directory/  for i in {-11..-10} do    for j in -2 0    do       (       cd  "e${i}_g/e${j}_u/"       ls -l ander ander.band ander.data       cat ander.in       cat ander.log       pwd       )    done done   notes:   you can loop over a range of numbers by using the braces notation:  for i in {-11..-10}  you can also loop over an explicit list of items:  for j in -2 0  you can change the directory so some place that depends on variables:  cd  "e${i}_g/e${j}_u/"  the argument to the cd command is a directory specified relative to the current directory
many people get confused because they see the computer as a single entity when in actuality a computer is several systems working together to give the illusion that it's one cohesive object.  multiple subsystems  the bios is one of of these such subsystems
you have to look at sockets and cores per socket
according to heirloom mailx's documentation:     resend: takes a list of messages and a user name and sends each message to the named user
you can't run firefox without all the gtk libraries it requires, but that's easily solved by installing the libraries
each deb package have list of dependencies that should be met before installation
it looks like your array syntax is off just a bit
 pause display / freeze order    p will pause the current display.    o will freeze the current screen order. this has the side effect that traffic between hosts not shown on the screen at the time will not be shown at all, although it will be included in the totals at  the bottom of the screen. scroll display    j and k will scroll the display of hosts. this feature is most useful when the display order is frozen (see above).         -t text output mode use text interface without ncurses and print the output to stdout.   
in p=$(cd ~ &amp;&amp; pwd):   the command substitution, $(), runs in a subshell cd ~ changes directory to ~ (your home), if cd succeeds (&amp;&amp;) then pwd prints the directory name on stdout, hence the string saved on p will be your home directory e.g
the reason that apache needs a reload is that once it's opened a file, it gets a filehandle to it, and it will keep writing to that filehandle
search for packages that are manually installed, and that are a mandatory or recommended dependency of an installed package
silly me, i've been seating on a script that makes this far faster and easier:    #!/usr/bin/python3  import os import gzip import apt_pkg  repo1 = "~/.repo_local/dists/cache/main/binary-i386/packages.gz" repo1 = os.path.expanduser(repo1) repo1 = apt_pkg.tagfile(gzip.open(repo1, "rb")) repo1 = dict([(pkg["package"], pkg["version"]) for pkg in repo1])  repo2 = "~/.repo_bin/dists/squeeze/main/binary-i386/packages.gz" repo2 = os.path.expanduser(repo2) repo2 = apt_pkg.tagfile(gzip.open(repo2, "rb")) repo2 = dict([(pkg["package"], pkg["version"]) for pkg in repo2])  apt_pkg.init_system() found = false  for pkg in repo1:     if pkg in repo2:         vc = apt_pkg.version_compare(repo1[pkg], repo2[pkg])         if vc == 0:             print("{:&lt;30}{:&lt;30}({})".format(repo1[pkg], repo2[pkg], pkg))             found = true  if found:     print("=" * 90)     print("{:&lt;30}{:&lt;30}({})".format("custom", "official", "package name")) else:     print("nothing matching search criteria found")  
it looks like pacaur supports --noconfirm:  --noconfirm      do not prompt for any confirmation   the following may also be useful:  --noedit         do not prompt to edit files  
let me to respond to your question with a alternative answer
the madwifi driver is deprecated nowadays in favor of ath5k and ath9k
   why doesn't the below work?   # in one terminal: echo "asdf" &gt; /dev/ttyusb0  # in another terminal, this hangs and does nothing cat &lt; /dev/ttys0   because, as a rule, serial ports don't buffer data
there is a memory bandwidth benchmark available in open source
actually, postfix turned out to be irrelevant to my problem
did you do echo $tmux, while in a tmux session? because tmux is only set, when in a session.  try that instead:  [ -z "$tmux" ] &amp;&amp; command -v tmux &gt;/dev/null &amp;&amp; term=xterm-256color exec tmux  
authentication can be handled in many different ways in linux
i figured i can use the following
i believe the signal level is in decibel (dbm).  excerpt     dbm (sometimes dbmw) is an abbreviation for the power ratio in decibels (db) of the measured power referenced to one milliwatt (mw)
the removal wants to start dovecot for some reason, and that fails due to a configuration error (user postfix is referenced but apparently that user doesn't exist).  if dovecot is not running and you simply want to remove it, then i suggest in this case to add a line to /etc/init.d/dovecot, just below the first #! /bin/sh line:  exit 0   that way the script won't do anything but exit successfully
the system hostname is not set using the file /etc/hosts.  the hostname is set using the system configuration management system
i seem to remember having a similar problem when setting up ganglia many moons ago
at the heart of backlighting is this linux kernel parameter that's exposed to you through here under /sys
gnu info was designed to offer documentation that was comprehensive, hyperlinked, and possible to output to multiple formats.  man pages were available, and they were great at providing printed output
you can access the array index using ${!array[@]} and the length of the array using ${#array[@]} e.g.  #!/bin/bash  array=( item1 item2 item3 ) for index in ${!array[@]}; do     echo $index/${#array[@]} done   note that since bash arrays are zero indexed, you will actually get  0/3 1/3 2/3   if you want the count to run from 1 you can replace $index by $((index+1))
it's nothing to do with smbfs, cp always requires the -r (recursive) flag to copy a directory
the problem is that you're telling your machine that both interfaces should be handling traffic to the rest of the world
maybe this solution can work for you too: http://stackoverflow.com/questions/6276752/can-i-split-already-splitted-hunk-with-git  edit the hunk and add \ no newline at end of file at the end of the + lines.  edit: now that i understood your requirement: use git add -p to get into interactive mode, delete the +/- lines you don't want to be included in the add and save it then. 
that's typically what expect was written for:  expect -c 'spawn -noecho vi; send "ihello world!\r\33"; interact'   while expect was written for tcl in days prior to perl or python being popular, now similar modules for perl or python are also available.  another option is to use the tioctsi ioctl to your tty device to insert characters in the input queue of the terminal device:  perl -le 'require "sys/ioctl.ph";           ioctl(stdin, &amp;tiocsti, $_) for split "", join " ", @argv          ' $'ihello world!\r\e'; vi   that has the benefit of avoiding an extra pseudo-terminal layer in between your terminal emulator and the application (here vi). 
run it through your shell:  sudo bash -c 'source /home/reachus/.bashrc; custom_cmd 80'   alternatively, write a script which sources .bashrc for you, say /usr/local/bin/my:  #! /bin/bash source /home/reachus/.bashrc "$@"   then do:  sudo my custom_cmd 80  
if you use the env command to display the variables, they should show up roughly in the order in which they were created
sorry, i totally forgot this question.  the solution back then was to use the saucy (ubuntu 13.10) kernel, which is based on 3.11, instead of the vanilla/mainline one
using tcpdump which is installed by default on many distributions:  tcpdump -n -i eth0 icmp6   will show you all icmpv6 packets of which - under usual conditions - almost all are neighbor discovery packets
the problem is that the redirection is done from the shell before running the command, as the current user, so sudo do not come into play.  use instead  md5sum my.iso | sudo tee my.iso.md5  
given the passwd and group files that you've posted, there is no group called core on your system
it doesn't seem to be able to handle the -y switch which does the side-by-side style of diff, but you can use the unified diff (-u)
you only need one eval.  [ -n "$zsh_version" ] &amp;&amp;   eval '     lss() l -l ${1:-.}/*(s,s,t)     laf() l ${1:-.}/.*(.)     lad() l -d ${1:-.}/.*(/)     lsw() l -ld ${1:-.}/.*(r,w,x.^nd/)   '   (note that zsh contrary to bash does support the bourne function syntax)  or:  [ -n "$zsh_version" ] &amp;&amp; 
the device name of a disk depends on what type of disk it is (more precisely, on what type of bus and controller the disk is connected to, and what driver handles them)
managed to solve my own problem by simply assigning the specific line and column as a variable, and concatenating them using echo, simple when you know the answer!  #!/bin/bash  cd freq/hf rm hessian.log   for i  in *.out do grep -h -a16 "force constants (second derivatives of the energy)" $i | tail -n +1 &gt;&gt; hessian.tmp  x=`awk ' nr == 2 {printf "     "" %10s %10s %10s %10s %10s \n", $2,$3,$4,$5,$6}' hessian.tmp` y=`awk ' nr == 12 {printf "%10s %10s %10s %10s \n", $2,$3,$4,$5}' hessian.tmp` a=`awk ' nr == 8 { printf "%5s %10s %10s %10s %10s %10s\n", $2,$3,$4,$5,$6,$7} ' hessian.tmp` b=`awk ' nr == 9 { printf "%5s %10s %10s %10s %10s %10s\n", $2,$3,$4,$5,$6,$7} ' hessian.tmp` c=`awk ' nr == 10 { printf "%5s %10s %10s %10s %10s %10s\n", $2,$3,$4,$5,$6,$7} ' hessian.tmp` d=`awk ' nr == 11 { printf "%5s %10s %10s %10s %10s %10s\n", $2, $3,$4,$5,$6,$7} ' hessian.tmp` e=`awk ' nr == 13 { printf "%10s", $3} ' hessian.tmp` f=`awk ' nr == 14 { printf "%10s %10s", $3, $4} ' hessian.tmp` g=`awk ' nr == 15 { printf "%10s %10s %10s", $3, $4,$5} ' hessian.tmp` h=`awk ' nr == 16 { printf "%10s %10s %10s %10s", $3, $4, $5,$6} ' hessian.tmp`  echo "$x $y" &gt;&gt; hessian.log awk '  nr == 3, nr == 7 {printf "%5s %10s %10s %10s %10s %10s\n", $2,$3,$4,$5,$6,$7} ' hessian.tmp &gt;&gt; hessian.log echo "$a $e" &gt;&gt; hessian.log echo "$b $f" &gt;&gt; hessian.log echo "$c $g" &gt;&gt; hessian.log echo "$d $h" &gt;&gt; hessian.log rm hessian.tmp echo "" &gt;&gt; hessian.log done  
i think your "number of bytes" metric is the wrong one
if the file(s) in question contain really lots of data sending the signal can actually get to cat before it finishes
here is how it does it:  static int getdestaddr_iptables(int fd, const struct sockaddr_in *client, const struct sockaddr_in *bindaddr, struct sockaddr_in *destaddr) {         socklen_t socklen = sizeof(*destaddr);         int error;          error = getsockopt(fd, sol_ip, so_original_dst, destaddr, &amp;socklen);         if (error) {                 log_errno(log_warning, "getsockopt");                 return -1;         }         return 0; }   iptables overrites the original destination address but it remembers the old one
if you are using bash, the easiest way to save a command exactly is to put it in an array
if i understand you correctly, you want to change the prompt when you start the current command
ifconfig is not the correct command to do that
with gnu ls (as found on most linux distributions), you can use ls -v, where -v, from the man page    -v     natural sort of (version) numbers within text   
this sed script prints the line number of the line matching /^};/ in the range of lines from /xkb_symbols "dvorak" {/ to the next /^};/ (which will be the same }; as the one we get the line number for):  /xkb_symbols "dvorak" {/,/^};/{         /^};/= }   if you need both start and end line numbers:  /xkb_symbols "dvorak" {/,/^};/{         /xkb_symbols "dvorak" {/=         /^};/= }  $ sed -n -f tiny_script.sed /usr/share/x11/xkb/symbols/us 192 248   alternatively:  $ sed -n -f - /usr/share/x11/xkb/symbols/us &lt;&lt;end_sed /xkb_symbols "dvorak" {/,/^};/{         /xkb_symbols "dvorak" {/=         /^};/= } end_sed   edit: to get these two numbers in a variable, assuming you're using bash:  pos=( $( sed -n -f - /usr/share/x11/xkb/symbols/us &lt;&lt;end_sed         /xkb_symbols "dvorak" {/,/^};/{                 /xkb_symbols "dvorak" {/=                 /^};/=         } end_sed ) )  echo "start = " ${pos[0]} echo "end   = " ${pos[1]}   also, hi! another dvorak user! 
you can use this syntax:  "${var:-word}"   this will substitute the value of the variable $var if it is set and not empty and, if not, will substitute with whatever is given by as word
you can use route to find your default route:  $ route kernel ip routing table destination     gateway         genmask         flags metric ref    use iface 192.168.1.0     *               255.255.255.0   u     1      0        0 eth0 link-local      *               255.255.0.0     u     1000   0        0 eth0 default         192.168.1.1     0.0.0.0         ug    0      0        0 eth0   the iface column in the line with destination default tells you which interface is used. 
there is another, and suprprisingly not well-known source of the unneeded disk writes in the linux world
i usually use the little utility beep installed on many systems. this command will try different aproaches to create a system sound.  3 ways of creating a sound from the beep manpage:     the traditional method of producing a   beep in a shell script is to write an   ascii bel (\007) character to standard   output, by means of a shell command   such as ‘echo -ne '\007'’
try using yum's shell transactions:  # yum shell &gt; &gt; remove &lt;package&gt; &gt; repo disable &lt;repo id of not required package&gt; &gt; install &lt;package&gt; &gt; run &gt; exit  
most obvious would be a deep search for partitions via testdisk. see their general guide on how to run it and/or the step-by-step documentation  then compare the partition table that testdisk found with what you see currently, without changing anything, and maybe post it here.  another option, at least for ext2/3/4 would be using debugfs command but this is way more complex and not as straightforward as testdisk.  in any case, if you want to recover what was on that disk, it's probably a good idea to create an image from it, and only work on that image, so you don't risk losing more data
centos at configuration file is in /etc/sysconfig/atd  according to the man page, the mail notification is as follows:     if  the file /var/run/utmp is not available or corrupted, or if the   user is not logged on at the time at          is invoked, the mail is sent to the userid found in the environment variable logname
i would just use the color picker tool from gimp, which will let you click anywhere on the screen and will give you the rgb value for the color at that point. 
as described in this announcement, this is not directly related to either mutt or openssl but effects all non-oauth mail clients equally
you can use ps:  ps axo pid,args,pmem,rss,vsz --sort -pmem,-rss,-vsz | head -n 5  
you could add a trace rule early in the chain to log every rule that the packet traverses
if you've installed this yourself from source then i think there are some additional steps you need to do to complete your installation.  specifically the following guides need to be followed:   2.18.1
why would you need 3 partitions? you only need one
the graphical user interface on traditional unix systems, as well as most modern unix systems other than mac os x, is built on the x window system
you can use a small hack with redirections:  bytecount=$( exec 3&gt;&amp;1 ;       dd if=$file  bs=1  skip=$skippedbytes | tee -a &gt;(wc -c &gt;&amp;3) $file.output |\      $($exportcommandstring $file) &gt; /dev/null ;  3&gt;&amp;1   )   it redirects all output to 3, that you've created with exec, and then returns it back to one at the end.  you also need to redirect all output from $exportcommandstring to /dev/null, otherwise it will be mixed with wc output
the following command does the trick: pacman -s ipw2200-fw  the wifi is now working but there is still issues with led
q1: add spaces to the end of any of the options to make it longer than 40 characters, for example:  options=(         "quit/exit"     "new rational db"     "run php for rational codebase"     "run php for playground codebase                       "    )   q2: not sure if there is a more elegant way (didn't see in help select), but this should work:  finished= while test ! "$finished"; do     select option in "${options[@]}"; do       case "$reply" in            1) finished=1;;            2) sudo -i -u db2inst1 bash -c "db2stop force;";;            3) rm /tmp/createdb2*;;            4)  ;;                      esac       break     done done  
resolvconf prioritizes nameserver addresses according to interface type
cd /my/directory mono --debug /path/bin &amp;  
find and change the following line in /etc/hosts:  127.0.0.1       localhost   change it to  127.0.0.1       localhost    mysite.com   this is client side
after doing yum update, you need to restart the machine: reboot now  then you'll be able to see the new kernel with uname -r 
use zypper from root shell:  zypper in gcc-c++  
since you don't mention, i'm assuming this is on linux.  dmidecode -t memory     dmidecode -t 16     lshw -class memory  
the general solution to test memory is to write a specific pattern like 0xffffffff to your memory and read it afterwards and compare the result
with aptitude, search for the ?obsolete pattern, possibly with a custom display format.  aptitude -f '%p' search '?obsolete'  
in case of a software raid setup on windows this is probably a fake-raid
the easiest way to set this up would be to have a cleartext system partition (on the sd card, i presume) and an encrypted data partition
as suggested, you can add some udev rules
usually, we see that when we have stopped a download and the continued/resumed with it again
not a direct answer, but in case pico can't do this, how about nano?  quoting its man page:     nano  is  a small, free and friendly editor which aims to replace pico,          the default editor included in the non-free pine package
because that's how the developers wanted it
there's more than one way to skin this cat, but i think the simplest overall is to use apt preferences to pin the r packages.  create a file in /etc/apt/preferences.d containing  package: r-* pin: version 3.0.3-* pin-priority: -1   run apt-get update or aptitude update to take any changes in /etc/apt/preferences or /etc/apt/preferences.d into account.  with the version above, any version of the form 3.0.3-something of a package whose name begins with r- is forced to a priority of -1, which means “do not install”.  another method would be to give the 3.0.2 such a high priority that apt would even downgrade towards them.  package: r-* pin: version 3.0.2-* pin-priority: 1001  
you can use ntp (network time protocol) if this machine is internet connected
here's what i would set in sip.conf  register =&gt; username:password@sip10.provider.com  [myprovidername] host=sip10.provider.com outboundproxy=sip10.provider.com:5090 type=friend fromuser=username defaultuser=username secret=password context=myproviderinbound    regarding "register =>" i don't know if your sip provider requires it, but..
a password agent (also known as a keychain/keyring or secrets store) is the tool for this
xdpyinfo gives you this information
originally you had just dumb terminals - at first actually teletypewriters (similar to an electric typewriter, but with a roll of paper) (hence /dev/tty - teletypers), but later screen+keyboard-combos - which just sent a key-code to the computer and the computer sent back a command that wrote the letter on the terminal (i.e
the "definitive" answer is of course brought to you by the useless use of cat award.     the purpose of cat is to concatenate (or "catenate") files
please do not run wireshark as root
how about using sed:  ps -e -o args | grep -e 'destiny.*unix' | sed -e 's/.*-t\s\([a-z0-9]*\).*/\1/' ps -e -o args | grep -e 'destiny.*unix' | sed -e 's/.*-p\s\([a-z0-9]*\).*/\1/' ps -e -o args | grep -e 'destiny.*unix' | sed -e 's/.*-m\s\([a-z0-9]*\).*/\1/'   sed -e 's/.*-t\s\([a-z0-9]*\).*/\1/'   s/search for/replace with/options s is to search. .* matches any/all character(s) until we get to the "-t". \s matches any whitespace. ( begins a capture. [a-z0-9]* matches any capital letter and any number of any length. ) ends the capture. .* matches the remainder of the characters in the line (if there are any). \1 replaces everything with the capture.  
this uses cli commands to enlarge a mounted non-lvm partition containing ext[234] filesystem
i'd use perl, and run it as oneliner like this:  perl -wne 'sub parseline { ($id,$v) = split; return split //,$v };     @a = parseline();     print "$id\t";     $_ = &lt;&gt;;     @b = parseline();     for ($i=0; $i&lt;@a; $i++) {       print "$a[$i]  $b[$i]\t"     };     print "\n"' &lt; input  &gt; output   explanation:   perl -wne runs the rest of command for each line of input sub parseline { ...
replace:  if [ -z `cat rvm_check.txt | grep not` ]   with:  if ! grep -q not rvm_check.txt   the reason to use test in an if statement is because it sets an exit code that the shell uses to decide to go to the then or else clause
it's probably easiest to just use a for loop:  for char in {a..z}; do     mkdir $char done  for num in {1..100}; do     mkdir $num done   you need at least bash 3.0 though; otherwise you have to use something like seq 
i always use bash within tmux (was screen till recently)
grep is a program that searches for regular expressions
it works if i add  video=lvds-1:d   to the kernel parameters. 
you need to ask qtcreator to load libraries provided by kde, e.g  qt_plugin_path="$qt_plugin_path:/usr/lib/qt4/plugins/:/usr/lib/kde4/plugins" qtcreator  if that doesn't work, try set a different color scheme directly,   
yes, but easier would be to decompress it to stdout and then redirect it.  gunzip -c -s atz file1.atz &gt; file1.ats  
assuming that you have the disk/partition already prepared (disk is partitioned fs created) you need to add a new /home mount point to /etc/fstab it should be something like that:   (your new disk partition)  (fs type) /dev/sdx[1-9]   /home    ext4          defaults       0  2   then mount the partition to /mnt with:   mount /dev/sdx[1-9] /mnt    copy your /home to /mnt
man libc covers standard c libraries (glibc, linux libc) on linux
you have a few possible solutions:  simply  $ ./script *g.log &gt;output   ..
   why can't a user chmod a file they have write access to?   for the normal access rights this is a design decision
sadly, the aur packages have been very broken for some time
if you press ctrl+\ while ping is running it will display the stats  check ping statistics without stopping 
apparently you've misread the manual
this is specific to openssh from version 3.9 onwards.  for every new connection, sshd will re-execute itself, to ensure that all execute-time randomisations are re-generated for each new connection
in the if condition give the $line in the double quotes it will work fine   #!/bin/bash line="hello welcome "  if [ -z "$line" ] ; then         echo "string null" fi  
nl -v "$((1+$(wc -l &lt; file1)))" file2 &gt;&gt; file1   nl is a tool to number lines of a file
du -sh file_path  explanation   du command estimates file_path space usage the options -sh are (from man du):    -s, --summarize          display only a total for each argument    -h, --human-readable          print sizes in human readable format (e.g., 1k 234m 2g)   to check more than one directory and see the total, use du -sch:    -c, --total          produce a grand total   
if i understood you correctly you need  for i in *; do echo "name:$i" &gt;&gt; $i; done  
first of all, you should use straight single quotes ('), not the inclined ones (`).  the awk inline script could be as follow:  ls -lrt | awk '{ total += $5 }; end { print total }'   so, no need to initialize total (awk initializes it to zero), and no need to loop, awk already executes the script on every line of input. 
if you're on linux you could use lsblk (which is part of util-linux):  lsblk -no pkname /dev/sda1  
the current directory (i.e., .) is not in your path
you don't need to change your subnets to match or anything fancy like that
just combine the two tests with &amp;&amp;:  if [[ -l "$file" &amp;&amp; -d "$file" ]] then     echo "$file is a symlink to a directory" fi  
use getent to enumerate the home directories.  getent passwd | cut -d : -f 6 | sed 's:$:/.bash_history:' | xargs -d '\n' grep -h -e "$pattern"    if your home directories are in a well-known location, it could be as simple as  grep -e "$pattern" /home/*/.bash_history   of course, if a user uses a different shell or a different value of histfile, this won't tell you much
you should first try one available from k-team
this is cannot be achieved without source modification according to:  http://icculus.org/pipermail/openbox/2013-may/007960.html  however there are 2 walkarounds:   one above from varl0ck one with wmctrl + xbindkeys apps, like: http://icculus.org/pipermail/openbox/2013-may/007963.html  
the first issue is that $directory contains slashes which are also being used as the delimiter for the substitution operator (s///)
the cat utility concatenates all its inputs into one data stream.  giving it two files, it produces output consisting of the complete contents of the first file, followed by the complete contents of the second file, in that order.  in your case:  $ cat file1 file2 &gt;file-1-and-2  
you can press ctrl+a followed by a to go to the beginning of the line
perl to the rescue!  #!/usr/bin/perl use warnings; use strict;  my $group_size = 3;  my @first = split ' ', &lt;&gt;;  my @groups; my $start_index = 0; while ($start_index &lt; @first) {     my $step = 1;     while ( $step &lt; $group_size             &amp;&amp; $start_index + $step &lt; @first             &amp;&amp; $first[$start_index] == $first[ $start_index + $step ]           ) {         ++$step;     }     push @groups, $step;     print $first[$start_index], ' ';     $start_index += $step; } print "\n";  my @numbers = split ' ', &lt;&gt;;  my $last; for my $size (@groups) {     my @group = splice @numbers, 0, $size;     my $value = $group[-1] - $group[0];     $value = $group[0] - $last if 1 == $size;     $last = $group[-1];     print $value, ' '; } print "\n";   you haven't specified what should happen if the very first group has just one member. 
there's some files in /etc/init.d/ directory:  $ ls -al /etc/init.d/ | grep -i depend -rw-r--r--   1 root root  2739 feb 17 05:20 .depend.boot -rw-r--r--   1 root root  2221 feb 17 05:20 .depend.start -rw-r--r--   1 root root  1855 feb 17 05:20 .depend.stop   whenever you run update-rc.d the files will change
the entire format string is to be preceded by the +:  $ date +"so this is week: %u" so this is week: 19 $ date +"so this is week: %u of %y" so this is week: 19 of 2016  
i can think of three hurdles:   the os itself
your awk syntax is a little wrong.  #!/bin/bash awk -f: -v keyword="$1" '$1 == keyword {$1=$1; print}' myfile.csv   the trick here is reassigning the value of one of the fields forces awk to recalculate $0 using the output file separator
on linux, try:  find /my/path -maxdepth 1 -type f -printf '%ty-%tm %s\n' | awk '{b[$1]+=$2} end{for (date in b) print date, b[date]}' | sort   how it works   find /my/path  this looks for files in in /my/path. -maxdepth 1  this tells find not to look into subdirectories
thanks for the comments, i was able to use reprepro to add the .deb package to my private repository
i got a bit curious reading this questoion, so let’s do some “forensics”:  first trying the opposite:  how is åäöåä encoded in base64?  $ echo åäöåä | base64 w6xdpmo2w6xdpao=   this clearly looks a lot like the 0sw6xdpmo2w6xdpa== that you’ve got
start by using time as per jon lin's suggestion:  $ time ls test test  real    0m0.004s user    0m0.002s sys     0m0.002s   you don't say what unix your scripts are running on but strace on linux, truss on solaris/aix, and i think tusc on hp-ux let you learn a lot about what a process is doing
i found the solution here: http://www.g-loaded.eu/2006/11/24/auto-closing-ssh-tunnels/  the best way – tunnels that auto-close  as it has been mentioned previously, instead of using the -f -n switch combination, we can just use -f alone, but also execute a command on the remote machine
let's try and stop and ignore upon the first find of brigthness
you cannot show hovering view of keybindings in gnome 3.14
cached memory is memory that linux uses for disk caching
just change the value of the $ps1 environment variable:  ps1="\h$ "   where \h is replaced with the hostname
the program powertop should help you identify the problem.     $ sudo yum -y install powertop    $ sudo powertop   look at the various output, and then arrow-key over to the rightmost "tab", tunables
you could simplify it a bit by using the number values directly as loop arguments:  for i in 1 2 8   do handbrakecli (...) --title $i -o "$i.mp4" done   or if you need to loop over a specific number range, use the {n..m} construct:  for i in {1..8}   do handbrakecli (...) --title $i -o "$i.mp4" done   also, in shell scripts you don't need a semicolon after expressions unless you have multiple expressions on the same line. 
i did a bit of digging on this, after getting interested in it again, and i found this artice that explains how to auto-start and run a program on the raspberry pi and it works for me.  i wrote a web server in php so i can do some things with the screen now.  hope it helped
flags are correct the error was to put external headers 
as far as i know, there are only limited ways in which release (uname -r) andmachine(uname -m) can be customized per process, all exposed through the [setarchcommand](http://man7.org/linux/man-pages/man8/setarch.8.html), andsysname(uname -r`) cannot be customized at all.  $ uname -rsm; setarch i386 --uname-2.6 --32bit uname -rsm linux 3.16.0-4-amd64 x86_64 linux 2.6.56-4-amd64 i686   if you want to spoof uname in a different way and the program is dynamically linked, you can use ld_preload to override the uname function; see redirect a file descriptor before execution for an example of function overload through ld_preload
./ is not a command
i found a possible solution from another question
i don't think ssh is playing a part in this problem
use lsof | grep /media/whatever to find out what is using the mount.  also, consider umount -l (lazy umount) to prevent new processes from using the drive while you clean up. 
scroll down…     the filenames . and .. are always ignored when globignore is set and not null.   most of the time, it is not desirable to include . and .. as wildcard matches, since they don't represent files inside the directory — they're hacks to make directory navigation work
when bash is run as a non-interactive shell it will not source the .bashrc file and if you use a graphical display manager then the login shell used to run the gui launcher commands might not have sourced the .profile file
you are right in that echo &amp; company don't seem to handle binary that well
ubuntu ships the kernel configuration in /boot/config-$version (in the same package as the kernel image /boot/vmlinuz-$version)
centos 5 updates continue through mar 31, 2017.  unless some special case applies, the best (and easiest!) general policy is to apply all updates your distro releases
here's a snippet from .zshrc i've been using:  my-backward-delete-word() {     local wordchars=${wordchars/\//}     zle backward-delete-word } zle -n my-backward-delete-word bindkey '^w' my-backward-delete-word   i recall this was the original source: http://www.zsh.org/mla/users/2001/msg00870.html 
you can put it in your .bash_profile, which gets executed everytime you log in
you can use printenv or env
get into shell scripting.  find simple tasks like copying directories, searching for files, testing for conditions, etc.  get a book on useful shell scripts - there are many out there - and try them out and try adapting them.  aliases, aliases, aliases  every time you repeat typing something that is more than 3 or 4 characters, aliases are your friend.  some examples:   alias a='
in bash you can export function definitions to sub-shell with  export -f function_name   for example you can try this simple example:  ./script1:      #!/bin/bash      myfun() {         echo "hello!"     }      export -f myfun     ./script2   ./script2:      #!/bin/bash      myfun   then if you call ./script1 you will see the output hello!. 
execute xfce4-settings-manager, in session and startup -> application autostart, add an entry, which executes xmodmap ~/.xmodmap  or rename the file to ~/.xmodmap 
it's not possible because ctime is changed always if there is a change of mtime
;/@/{h;s/test/next/g;x;g}?   /@/  search for an `@` sign {}   for the lines where that is true do this 'block' of code h    put the pattern match in the hold space s/   substitute test for next everywhere in the space g    do the previous substitution for all matches on the line x    swap the hold with the pattern space g    add a new line with the contents of the hold space.  
you might try using testdisk to recover the partition table
from the bash manual:  trap [-lp] [[arg] sigspec ...]      ..
you might use this syntax which doesn't require the $ to be escaped unlike your here document attempt.  #!/bin/bash  bash -c ' imports=$(find /tmp/foo -type f -name .project)  for item in ${imports[*]}; do    import="$(dirname $item)/"    echo $import done '   here is a more robust way (thanks to gilles' comment suggesting it), that has the advantage to allow single quotes to be present in the embedded script:  #!/bin/bash  bash &lt;&lt;"%eof%" imports=$(find /tmp/foo -type f -name .project)  for item in ${imports[*]}; do    import="$(dirname $item)/"    echo $import done %eof%   note: there is no way to prevent someone to use a different shell than the one specified with the shebang
firefox stores the size of the last window in the profile
system calls aren't handled like regular function calls
i can't see how that can apply to sudo.  for the setuid scripts, the idea is this:  assume you have a /usr/local/bin/myscript that is setuid root and starts with #! /bin/sh
i found the following solution that works but i'm open for other suggestions.  pam_exec can be used to call external commands
you can use yum rep which updated version of mysql, as in here:http://www.webtatic.com/packages/mysql55/ 
i use the following function to say that a function or alias or wrapper script (e.g
 it's difficult to determine exactly how many containers you can run because you won't know until you've run them and they've started using ram
ubuntu's wiki  as @hippo mentioned you can look at the lts page which has this chart:    wikipedia page  also wikipedia has a nice chart:    ubuntu ec2 list  finally, ubuntu provides a directory of their ec2 images:  http://uec-images.ubuntu.com/releases/  and a list of official ubuntu ami images:  http://cloud.ubuntu.com/ami/ 
root@vio # fcstat fcs1 error opening device: /dev/fscsi1  -->> it turned out the cable is/was bad
the following prints the current date with a reversed field which is replaced in cal by sed.  ptd=$(date -j +%d) ctd=$(printf "\033[0;7m"$ptd"\033[0m") cal | sed 's/'"$ptd"'/'"$ctd"'/'  
try isomaster, althrough it lacks the support of non ascii characters 
any code that runs before the main operating system is started, and that's involved in starting other programs, is a bootloader
i would expect these messages to be coming from your shell initialisation - either it is produced always by your shell init script or only in some mode, e.g
use        bar1+=($(echo $foo | awk '{print$1}'))   i.e., variable+=( value ) to add a value to an array.  of course the code to use the bar1 array has to look something like  for foo in "${bar1[@]}" do     echo "$foo" done   of course you should always quote shell variables (e.g., "$foo" and "${bar1[@]}") unless you have a good reason not to, and you’re sure you know what you’re doing.   
if you really want return just the first word and want to do this with grep and your grep happens to be a recent version of gnu grep, you probably want the -o option
i think what you should really be asking is:   "..
i ended up modifying the busybox config., which was automatically adding the '-n' option when launching the dchp client
to set location of core dumps in centos 6 you can edit /etc/sysctl.conf
(command1; command2)&amp; - should do it, works in bash.  this creates a subshell (the two parenthesis) and runs the whole subshell in the background. 
it depends on what the route_linux_machine is.  route_linux_machine is a router  if it's only a router (means, no ssh service/account there): then you should add some iptables rules to redirect network traffic
it depends on your $path
make assumes that an exit code of 0 means success, anything else means failure
   this yum plugin adds the "--merge-conf" command line option
using acl's this can be done (red hat - setting access acls) -   $ setfacl -m u:gourav:rwx,d:u:gourav:rwx,d:u:tiger:rwx,m:rwx /tiger_gaurav   u:gourav:rwx - grants user gourav read,write, and execute to the directory d:u:gourav:rwx - sets the default rule that will grant user gourav read,write,execute permission to files created in the directory d:u:tiger:rwx - sets the default rule that will grant user tiger read,write,execute permission to files created in the directory m:rwx - sets the mask, this value is unioned with the owning group and all other users/groups.   that said, creating a group is likely much simpler to maintain in the long run
sed expects a basic regular expression (bre)
well, this is my very personal way to read manpages:  have in mind what you want to do.  when doing your research about xargs you did it for a purpouse, right? you had a specific need that was reading standard output and executing commands based on that output.  but, when i don't know which command i want?  use man -k or apropos (they are equivalent)
   i can try to trap the interrupt at a lower level and inform the gtkmm application.   no, that is a kernel space activity
in many systems, your only entry point into the system is via ssh
if the terminal you launched the command from is still open, you can get it back by running fg.  if it is not, identify the process id by running ps aux | grep yum  or just pgrep yum and then use kill pid
you can view if a file called /etc/debian_version exists.  $ cat /etc/debian_version wheezy/sid   if it exists, you also can see the version of debian
it seems the most kernels(post v1) do support multicast by default or have config_ip_multicast enabled while compiling
to questions 1 and 2: yes, windows is able to access the data from the swap partition
you can use port directive:  port &lt;port number&gt;   a note that if you set port to n, then you must let port n-1 available too
grep -l word * | xargs grep word2   xargs will run the second grep over each file from the first grep.  regards. 
the netmeta package imports the rgl package
it's the process id of the current shell.  source:     expands to the decimal process id of the invoked shell
for zsh, which is shorthand for whence -c, and supports other whence options
you can add this to your .vimrcfile, or temporarily while in vim.   vimrc - set laststatus=2 in vim - :set laststatus=2   to get the full path you can add this command, again to either your .vimrc or while in vim.   vimrc - set statusline+=%f in vim - :set statusline+=%f   examples  normal mode  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  command line mode  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  for more info than you care to read through there's additional info on both of these available in vim.  :help laststatus :help statusline   references   displaying status line always 5
you can not do it directly in python, as you need a kernel module to do that (and root rights to load that module).  see http://lxr.free-electrons.com/source/arch/arm/mm/cache-v7.s#l21 for what it takes to invalidate the l1 cache (invalidate, not disable).  different cpu architectures (e.g x86 vs arm) require different assembly code (cpu instructions) to disable the cache
you can use find  find 
sort | uniq existed before sort -u, and is compatible with a wider range of systems, although almost all modern systems do support -u -- it's posix
the second node-dev is not executable, and the symlink points to that
from "help continue":  continue: continue [n]     resume for, while, or until loops.      resumes the next iteration of the enclosing for, while or until loop.     if n is specified, resumes the nth enclosing loop.      exit status:     the exit status is 0 unless n is not greater than or equal to 1.   so you want continue or continue 1 to go to the next iteration of until, or continue 2 to go to the next iteration of while. 
to change the hostname permanently, you need to change it in two places:  vi /etc/sysconfig/network networking=yes hostname=newhostname   and: a good idea if you have any applications that need to resolve the ip of the hostname)  vi /etc/hosts  127.0.0.1 newhostname 127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6   and then   rebooting the system  
you can look in /sys/block:  -bash-3.2$ ls -ld /sys/block/sd*/device lrwxrwxrwx 1 root root 0 jun  8 21:09 /sys/block/sda/device -&gt; ../../devices/pci0000:00/0000:00:1f.2/host0/target0:0:0/0:0:0:0 lrwxrwxrwx 1 root root 0 jun  8 21:10 /sys/block/sdb/device -&gt; ../../devices/pci0000:00/0000:00:1f.2/host1/target1:0:0/1:0:0:0 lrwxrwxrwx 1 root root 0 jun  8 21:10 /sys/block/sdc/device -&gt; ../../devices/pci0000:00/0000:00:1f.2/host2/target2:0:0/2:0:0:0 lrwxrwxrwx 1 root root 0 jun  8 21:10 /sys/block/sdd/device -&gt; ../../devices/pci0000:00/0000:00:1f.2/host3/target3:0:0/3:0:0:0   or if you don't have /sys, you can look at /proc/scsi/scsi:  -bash-3.2$ cat /proc/scsi/scsi  attached devices: host: scsi0 channel: 00 id: 00 lun: 00   vendor: ata      model: st31000340as     rev: sd1a   type:   direct-access                    ansi scsi revision: 05 host: scsi1 channel: 00 id: 00 lun: 00   vendor: ata      model: st31000340as     rev: sd1a   type:   direct-access                    ansi scsi revision: 05 host: scsi2 channel: 00 id: 00 lun: 00   vendor: ata      model: st31000340as     rev: sd1a   type:   direct-access                    ansi scsi revision: 05 host: scsi3 channel: 00 id: 00 lun: 00   vendor: ata      model: st31000340as     rev: sd1a   type:   direct-access                    ansi scsi revision: 05 host: scsi4 channel: 00 id: 00 lun: 00   vendor: pepperc  model: virtual disc 1   rev: 0.01   type:   cd-rom                           ansi scsi revision: 03  
seems that the at command doesn't work out of the box.  in my test, for example:   raspbian needed:  sudo apt-get install at (which will install and run atd, at daemon)  arch linux had at installed, but again needed the daemon to be started manually:  sudo systemctl start atd sudo systemctl enable atd  osc, according to this su answer needs:  launchctl load -w /system/library/launchdaemons/com.apple.atrun.plist   
it looks like they need not be added, as they are there already.  as indicated here, the commands are very simple:  for us english:  setxkbmap us   for french:  setxkbmap fr   for romanian:  setxkbmap ro   for the same with a variant:  setxkbmap ro std_cedilla   a list of all possible keyboard layouts and other parameters can be found in: /usr/share/x11/xkb/rules/xorg.lst. 
no
there is no shorter :t_ command, but you can make your own:  put the following in your .vimrc file:  :com! -nargs=? t tabedit &lt;args&gt;   recall that e183: user defined commands must start with an uppercase letter. 
sshd does not ban ip addresses
since the problem seems isolated to just one interface -- i assume you're using plain old class c masks for these two networks -- i'd just quickly bounce it:  # ifconfig en0 down # ifconfig en0 up   obviously you need to substitute the correct interface name here for en0.  you may have to restart any servers listening on that interface, and any established tcp connections using it will drop when you do this
from (gnu) grep(1) man page:     -w, --word-regexp      select only those lines containing matches that  form  whole  words
you need to use cat /proc/meminfo, not execute /proc/meminfo directly.  the reason you get "permission denied" is because you're trying to execute /proc/meminfo, and /proc/meminfo has no executable bit set (because it's not an executable, it's a file that you have to read).  reading /proc/meminfo itself should not require any special permissions.  you might find it easier to find the total memory using the free command, though. 
why? because no one has written a tool that does it
all you have to do is install virtualbox-guest-utils with pacman
if [ "$(cp -uv source destination)" != "" ]; then echo copied; else echo not copied; fi   update  match "->" in cp's verbose output
you need to patch the right file.  the way you call it, it will try to patch the new file and thus correctly assumes a reversed patch.  try to copy an old version of the file to your current directory and the patch will apply.  regarding your -p0 test: do you have permission to modify /usr/bin/gradle? do you have permission to create files in /usr/bin?  also note that there are deviating rules for getting the filename to patch.  the rules used by gpatch are different from both the original patch and the posix patch standard.  note that the "not a regular file" message is specific to gpatch
the recommended approach would be to have udev start a systemd service, which itself depends on your device.  the service file should look something similar to the following:  my.service - to be placed in /etc/systemd/system  [unit] description=&lt;description here&gt; bindsto=&lt;device unit here&gt;.device after=&lt;device unit here&gt;.device  [service] execstart=&lt;call to script here&gt;   note: to get a list of the available device units use    list-units --all --full | grep ".device"   and the udev rule should be something like the following:  90-my.rules - to be placed in /etc/udev/rules.d  kernel=="tty*", attrs{serial}=="&lt;device serial here&gt;", tag+="systemd", env{systemd_wants}="my.service"   note: to get a list of the attributes of your specific device, including its serial number, use    udevadm info -a -n /dev/tty*   this question, though fairly different, might also be of interest. 
virtualbox will have no trouble reading that as-is:   just rename cdrom30.fs to cdrom30.iso (virtualbox will error without this) open settings -> storage use the icons below the tree to add new storage controller if not asked, click add floppy device on the floppy controller tree entry select your iso (cdrom30.fs)
 ps aux | grep java you look for the process id(pid) of the process you want and then you use kill command (for how to use kill read my post here)    also read: here and here and here  an alternative: ps -fp $(pgrep -d, -x java) or you might use htop or top and search for java 
you can move around the screen lines by using g in front of the commands:  gj gk g$ g0 g^   you can also map the original commands to the g commands like this:  :map j gj   j moves by screen lines now. 
assuming that there is 512-byte dos-like mbr, and you have replaced first 446 bytes of it with some crap (zeros or just /dev/urandom output), or damaged the bootcode some other way
use a .netrc file in your home directory.  the content is:  # machine &lt;hostname&gt; login &lt;username&gt; password &lt;password&gt; machine ftp.example.com login myuser password $ecret   if this is something you're doing programmatically, write the .netrc before connecting, delete it when you're done. 
man grep:  -f file, --file=file           obtain patterns from file, one per line
mv a b attempts to move a into b if b is a directory or a symlink to a directory
the output of alias is lines starting with alias
i poked around and couldn't find anything either, so i asked on irc   mamarok: xenoterracide: this is addition tag info, it can't be disbled currently, there already is a bug report for it   so maybe it'll be disable-able in 2.5. 
if your computer actually keeps track of power (e.g
if the usb device is listed as a sound card in the system, you may want to check man amixer and use the unmute parameter
you're probably cutting and pasting the command (or parts of it) from a document instead of typing it in manually
here you are:  $ uniq inputfile &gt; outputfile   but notice uniq only removes those repetitive lines coming after each other and sequently
first thing to do before buying unknown new hardware, is to look at the vendor site for the product
ctrl+l is also bound in vi command mode but not in insert mode
cd into /etc/sysconfig/network-scripts
it's common for programs with colorized output to disable it if they're not being run directly in a tty, since you might be piping the output to a log file or to another process that expects plain text
try this :  in ~/.cshrc put  set filec set autolist  
apt-get upgrade plays it safe: it upgrades all the packages that can be upgraded without breaking other packages
the first argument inside the quotes of the rule you created is the rule name
run the below commands inside /psds directory.  for f in ./*; do     if [ -d "$f" ] ; then         cd "$f"         mv *.jpg "$f.jpg"         cd ..     fi done   if you have 3 folders inside /psds directory like below,  /psds/folder1/image1.jpg /psds/folder2/image2.jpg /psds/folder3/image3.jpg   after you run the above command, the files would be renamed as,  /psds/folder1/folder1.jpg /psds/folder2/folder2.jpg /psds/folder3/folder3.jpg  
you can use unix2dos (which found on debian):  unix2dos file   note that this implementation won't insert a cr before every lf, only before those lfs that are not already preceded by one (and only one) cr and will skip binary files (those that contain byte values in the 0x0 -> 0x1f range other than lf, ff, tab or cr).  or use sed:  cr=$(printf '\r') sed "s/\$/$cr/" file   or use awk:  awk '{printf "%s\r\n", $0}' file   or use perl:  perl -pe 's|\n|\r\n|' file  
when you run a program from a shell (e.g
olaf kirch originally developed both the user space and kernel based version of the nfs server
it is apparent that the /root directory on your system does not have (at least) 'execute' permisions for the user 'yu', either through group membership or the 'other' bits
yes there are a variety of ways to do this
there are a few methods.  the simplest way if you're just transferring a file once in a while.  scp myfile.txt user@example.com:/home/user/   scp stands for secure copy and it transfers over ssh. there is also sftp  sftp user@example.com &gt; cd /home/user/ &gt; put myfile.txt   i guess the only real advantage to using this is that you can transfer multiple files without typing in your ssh password all the time
i wasn't able to find it inside the preferences
make sure following line to /etc/fstab:   nfs-server:/   /mnt   nfs4    _netdev,auto  0  0   about _netdev:     where the auto option mounts on startup and the _netdev option can be   used by scripts to mount the filesystem when the network is available.   under nfsv3 (type nfs) the _netdev option will tell the system to wait   to mount until the network is available
as a short script:  for source in $(dpkg-query --show -f '${source:package}\n' | sort -u); do bts select source:${source} tag:patch; done   this uses dpkg-query to list the installed source packages, and bts (from the devscripts package) to list all bug numbers corresponding to an open bug with a patch filed against any of the source packages
the data pool is a lofi encrypted zfs container; this is the problem.  i'm able to confirm that it's a performance issue with lofi's "virtual" controller because of the following:   lofi + zfs + encryption has a throughput of about 10-25mb/s lofi + zfs + no-encryption has a throughput of about 30mb/s no lofi with plain old zfs has a throughput of about 250mb/s the data controller reports 100% utilization whereas the real controller has virtually none. tested on multiple machines with the same setup and the results were largely identical.   the issue here is lofi; and not the disk controller. 
debian jessie and later (2014-)  as pointed out by @voltagex in the comments, it can now be found in the software-properties-common package:  sudo apt-get install software-properties-common     debian wheezy and earlier:  the program add-apt-repository is available in debian
here is a list of all possible boot parameters:  i've never used it, but try adding ignore_loglevel.  i previously mentioned verbose, but actually that only applies to other specific kernel options like acpi, as you can read, above
add in global section of your /etc/rsyslog.conf    $template customformat,"%hostname% %syslogtag%%msg%\n" $actionfiledefaulttemplate customformat   also man rsyslog.conf 
i didn't find the cause of the slow booting with grub 2.  i ended up using extlinux instead, which is compact and fast, and better-suited if you don't need all the fancy grub 2 things.  http://www.syslinux.org/wiki/index.php/extlinux 
the pattern you want is not a regex, it is a bash glob and you need the -f to tell it you are completing files
if you are sure there are no " characters in the data you're looking for and if there's only one line containing a "customfield_10701" entry in the file, then  sed -n 's/.*"customfield_10701":"\([^"]*\)".*/\1/p'   e.g.,  $ cat x ..
about your performance question, pipes are more efficient than files because no disk io is needed
i think /opt is more standard in this sort of context
in the script:  echo "${1//$/\\$}"   this is a simple string replacement build into the shell
while all the answers about sudo vs su are correct, they don't address the &amp; part of the question.  the issue with trying to do something like sudo somecommand &amp; is that it backgrounds sudo (which happens before it gets a chance to prompt for the password)
the messages you mention are not printed to standard output but to standard error
short answer: understand what exactly this alias does, you can check out the ~/.bashrc file and search for the term "alias l="
you can remove hidden directories (with . at the beginning of the name) like normal directories:  rm -rf .directory_name   (r for recursive, f for force).  to display hidden directories use -a option for ls:  ls -a   you can also use mc or some other file manager to remove them
accepting command options arguments after file operands is not standard and isn't often supported in non-gnu system, you need:  ls -d1 sel*     a note that -d1 isn't depth 1 like you think.   -d tell ls list directories themselves, not their content -1 tell ls list one entry per line  
use workdir="/dev/"; sudo su -c tcsh -c "cd $workdir; echo \$pwd" to change the folder during script.  just remember to escape all $.  edit  why wouldn't you do so:  sudo ./tcsh.csh  and inside tcsh.csh contains:   #!/usr/bin/tcsh cd $workdir  # need to set $workdir somewhere, depends on you blabla  
this is because your function is printing to stdout not stderr, try  nameoffunction ${var1} ${var2} &gt;/dev/null   or redirect both stderr and stdout:  nameoffunction ${var1} ${var2} &gt;/dev/null 2&gt;&amp;1   note it's good style to print errors to stderr, so instead of my answer above you should better change your function, like this:  echo -e "\e[31m[ error ]\e[39m more text..." 1&gt;&amp;2  
common mistake, wrong order of redirection, try this:   … sendmail_alive.sh &gt;/tmp/sendmail_alive.log 2&gt;&amp;1   it works like this:   file descriptor stdout to /tmp/sendmail_alive.log file descriptor stderr to the value of stdout (/tmp/sendmail_alive.log)   with your order, you first point the stderr where originally was stdout and you get the stderr message "connection closed by foreign host." there as a result. 
https://wiki.ubuntu.com/x/config     to create an initial /etc/xorg.conf file, you can have xorg's autoconfiguration output a full blown static one for you:  sudo xorg -configure       or create an /etc/xorg.conf containing only those sections and options that you need to override xorg's autoconfigurated settings.  
first a misconception:     any selected text is immediately sent to the clipboard   actually text is never "sent" anywhere until it is requested by a receiving application
basically, it sounds like you want general advice on profiling an application's i/o at runtime
there exists several variants of a watch command, some that spawn a shell to interpret a command line made of the concatenation of the arguments passed to watch (with space characters in between)
try java virtual machine process status tool(jps):  [tue aug 30@17:02:14][prince@localhost ~]$ jps -l 30207 sun.tools.jps.jps 29947 org.netbeans.main  
the command is:  sudo updatedb   see man updatedb for more details. 
xinput controls input settings
 /dev directory contains special files (device files) corresponding to physical devices or system components /media is a regular directory which by common practice is used to mount removable media like cd-roms, floppy disks, etc. /mnt is a regular directory which by common practice is used to mount other filesystems, usually for a short period of time   /dev is essential to the operating system and it cannot be removed  /media and /mnt are only a placeholder directories; removing them won't influence the operating system core operation, but might cause errors with certain applications; for example when a removable media is inserted, or when a process tries to mount a filesystem.  as an example of the difference: /dev contains a reference to a physical cd-rom drive, /mount might contain a subdirectory through which you can access the files stored on the disc inserted to the same cd-rom drive. 
you can wildcard and use %h in your config  eg  host *.eng   hostname %h.domainname.com   now when you do ssh foo.eng it will try to connect to foo.eng.domainname.com.  you can add other options to this config as well; eg forcing the username  host *.eng   hostname %h.domainname.com   user me   now when you do ssh foo.eng it will try to connect to foo.eng.domainname.com as the user me.  % ssh foo.eng ssh: could not resolve hostname foo.eng.domainname.com: name or service not known   (well, obviously i get an error before it's not a valid hostname for me!)  so now you only need one rule per country. 
go to access.redhat.com/downloads/content/package-browser, log in with your red hat account, and search the packages.  if you don't have an account, you can register for free at developers.redhat.com. 
paste is probably the best tool for this job:  $ paste -sd ' ' file 111 222 333  
those are fairly specific requirements
no, because the contents of the first directory itself are only 1mb
your script is not failing - it's working just fine
there are a couple tools capable of writing to the clipboard; i use xsel
another answer, a little simpler than the others:  #!/bin/bash fields=$(sed -r -e 's/-1/ /g' -e 's/,/ fs /g' \   -e 's/([0-9]+)/\$\1/g' control_file.txt) awk -f, "{print ${fields}}" $1   the first command converts control_file.txt into a suitable awk command:  $1 fs $3 fs $5 fs fs $8 fs fs $4   to run it:  $ ./script.sh input.csv col1,col3,col5,,col8,,col4 1,3,5,,8,,4 9,11,13,,16,,12   on your other sample:  $ ./script.sh sample.csv bp id,currentmonetary balance ,provider contract id,,end date,,charge plan names  1100001538,251,00000000000000000141,,18-oct-12,,[b2] r2 lte charge plan  1100003404,45.22,00000000000000009349,,23-nov-13,,b0.3 ecs_charge_plan drop1 v3  
when you use dd on /dev/sdb instead of /dev/sdb1 or /dev/sdb2, you copy all the partitions from the said drive into one file.  you must mount each partition separately
you need to change the dpms settings, which are controllable with xset
that is a bit complicated due to linux being a "weak end system" design
with :e! you can reload the same file and dismiss any changes that you did until that point, after the last save.  if you did not do anything in vim, but changed the file externally, you can reload by just type :e. 
you can easily extract the encrypted password with awk
sudo apt-get install libgd-perl   will install gd and gd::polyline. 
the string comes from strerror(3), which maps error numbers to messages
you need to do:  sudo find /var/lib/foo -name '.snapshot' -prune -o -print   it will print whatever is not named ".snapshot", and if ".snapshot" is a directory it will also not descend into it.  why ?  because "-prune" is an action (as '-print' is also another action), doing nothing except preventing to go further down in the subdir
you can use awk commands:  # awk -f, '{print $1 "\t" $2 "\t" $3}' customers   or :  # awk 'begin{fs=","; ofs="\t"} {print $1, $2, $3}' customers   or :  # awk 'begin{fs=","; ofs="\t"} {print}' customers   all of them will work for you. 
xkeycaps seems to do what you want, if i understand you correctly. 
add these lines to your .vimrc:  set tabstop=4 set shiftwidth=4 set expandtab   after that, each new tab character entered will be changed to 4 spaces, old tabs don't
   openssl req -x509 -days 365 -newkey rsa:2048 -keyout /etc/ssl/apache.key -out /etc/ssl/apache.crt   you can't use this command to generate a well formed x.509 certificate
it turns out that i didn't know that gparted defaults to saving 5% of the partition's space for super-user
some versions of find (non-embedded linux, cygwin, osx, freebsd) allow you to compare a file's modification time with a reference date with the -newermt operator.  find /storage/backup/rman -newermt '2012-12-01' ! -newermt '2013-01-01'   you can't use -mtime to tell whether a file was modified at a particular date, because this operator is relative to the time you run the find command
what you're looking for is the upstream/parent/forward server
many gnome 3.6.x apps have been ported to gmenu and as such the "menu" is only available from the main toolbar (it changes according to the focused app) , e.g
you can run matlab with the -nodesktop option.  example  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  source: launching matlab without the desktop 
note: as a fair warning, you need to be careful when having logical volumes span across multiple disks
grep has the -f flag exactly for this, use:  grep -f patternfile somefolder/*.txt   where in the patternfile the search patterns are separated line by line. 
probably easiest method: cat some_file | grep '?' | cut -d'-' -f1   cat somefile => feed the contents of some_file into the pipe grep '?' => filter only lines containing a ? cut -d'-' -f1 => divide the string into fields with - as field separator, then print field #1  
i found the solution here
as per this question, you can use:  cp /long/path/to/file{,-copy}   this a shell expansion done by bash (not sure about others), so it will work with any command. 
what about   cat url_list.txt | while read line; do  if curl  -d  tmp_status.txt -l  $line -o tmp_file.html  then    mv tmp_file.html $(awk '/http/  { print $2}' tmp_status.txt)_$(basename $line) else    echo $line &gt;&gt;error.txt    # processing from tmp_status fi  done    only one call of curl, but a post processing ...  
the one explanation that comes to mind is that you have stuff hidden behind a mount point, out of the reach of du.  on linux, you can make a bind mount of the root filesystem so as to be able to see all of it on a different mount point
you can run a process that will send a signal (e.g
apparently virtualbox wasn't able to start vboxnet0/vboxnet1, which i noticed when i did:  $ ping -i vboxnet1 puffin connect: network is unreachable   the problem could be found with  $ip link (...) 5: vboxnet1: &lt;broadcast,multicast&gt; mtu 1500 qdisc pfifo_fast state down mode default group default qlen 1000     link/ether 0a:00:27:00:00:01 brd ff:ff:ff:ff:ff:ff   the following fixed the issue:  sudo ip link up vboxnet1   and now i get:  $ip link (...) 5: vboxnet1: &lt;broadcast,multicast,up,lower_up&gt; mtu 1500 qdisc pfifo_fast state up mode default group default qlen 1000     link/ether 0a:00:27:00:00:01 brd ff:ff:ff:ff:ff:ff   more details can be found:   https://bbs.archlinux.org/viewtopic.php?id=131711 https://bbs.archlinux.org/viewtopic.php?pid=1178607  
   why can i rest assured that gnu parted has not corrupted a single bit   after shrinking my partition?   you can't, in fact,  gparted man page clearly says (under notes):  editing partitions has the potential to cause loss of data. ...... you are advised to backup your data before using the gparted application.   reboot your system after resizing the partition and run fsck
from the manpage of the syscall chflags(2):   sf_immutable   the file may not be changed. sf_nounlink    the file may not be renamed or deleted. [...] uf_immutable   the file may not be changed. uf_nounlink    the file may not be renamed or deleted.    the flags prefixing with sf_ may only be set or unset by the super-user
it was so easy, if your nsswitch is files ldap, you could just add an entry to /etc/passwd and modify their shell to whatever value
using sed:  sed '/[0-9]/!s/ //g' filename   this would remove spaces on all lines that do not contain a digit.  using awk:  awk '!/[0-9]/{gsub(" ", "", $0)};1' filename   for removing the space only between the first two words (here using gnu sed for -r, use -e instead on bsds):  sed -r '/[0-9]/!s/([^ ]+) ([^ ]+)/\1\2/' filename  
i solved it by following the advice described here: https://bugs.launchpad.net/ubuntu/+source/util-linux/+bug/367782 
in general, you can use open from the terminal to open any file with its default application (see this so question)
awk -f: '/^[^#]/ { print $2 }' /etc/oratab | uniq  
press ctrl+shift+u and an underlined u will appear
the command 'chmod +x filename' does not install anything, it just sets the "executable" attribute on file.  if you write a shell script with the filename 'myscript' and then you do 'chmod +x myscript' then instead of doing 'sh myscript' to run it, you will be able to do so with only 'myscript' (assuming the file is in a directory in your path).  that being said, 'chmod' is a common utility found on virtually every unix(-like) os out there, and ubuntu is merely a highly customised version of debian, which is a distro of linux, which is a unix clone. 
you can't, as it has been already said, if the files have been compressed with standard gzip
if bash is in the different location you can hash bang it as follows:  #!/usr/bin/env bash   location for env is pretty standard across the variants. 
i am not a fan of overriding built-in commands, but in my .bashrc (part of tilde, my "dot files") i explicitly do this:  alias rm='rm -i';   this makes rm ask for permission before deleting
to list packages providing mail-transport-agent:   $ aptitude search '~pmail-transport-agent' p   citadel-mta                     - complete and feature-rich groupware server p   courier-mta                     - courier mail server - esmtp daemon         p   dma                             - lightweight mail transport agent           p   esmtp-run                       - user configurable relay-only mta - the reg p   exim4-daemon-heavy              - exim mta (v4) daemon with extended feature p   exim4-daemon-light              - lightweight exim mta (v4) daemon           p   masqmail                        - mail transport agent for intermittently co p   msmtp-mta                       - light smtp client with support for server  p   nullmailer                      - simple relay-only mail transport agent     i   postfix                         - high-performance mail transport agent      p   sendmail-bin                    - powerful, efficient, and scalable mail tra p   ssmtp                           - extremely simple mta to get mail off the s p   xmail                           - advanced, fast and reliable esmtp/pop3 mai   make that aptitude search '~pmail-transport-agent ~i' to only list installed packages (if any).  to list all virtual packages provided by currently installed packages:   aptitude search '~rprovides:~i ~v'   see the aptitude manual for an explanation of the search patterns. 
that is not a multi-line comment
use your distro's package manager and verify the package to see if the file is original
from a debugging perspective, the kernel is a special "process", distinct from the user space processes, which communicate with the kernel via a sort of rpc mechanism (syscalls) or mapped memory.
there are many higher level commands that will almost do what you want to do, but this is a good demonstration of how to do the same thing in a shell script
 update your ports tree  portsnap fetch update navigate to the pkg directory  cd /usr/ports/port-mgmt/pkg build and install the pkg package  make config-recursive install distclean  
i recommend using --mime instead of the default output
   there is no complete documentation for hp-info command
try  ls | awk -f_ 'p[$1]++ { printf "rm %s\n",$0;}' | bash   where   -f_ use _ as separator p[$1]++ count and test prefix { ..
3
sed g  # option: g g    copy/append hold space to pattern space.   g is not often used, but is nice for this purpose
the program will exit as soon as the rc.local script is finished
use xev to find the keycode for the key you want to remap
no
i posted this question on the help-bash mailing list and got a response from chet ramey, the maintainer of bash.  he suggested adding either of the following before the history -s command:  set -h    # aka set -o histexpand   or  histchars='!^#'   i tried each of them and they both work
to disable wireless n in the module echo "options iwlwifi 11n_disable=1" | sudo tee /etc/modprobe.d/iwl-opt.conf  reboot  but i would suggest enabling wireless n on the router and trying this option echo "options iwlwifi 11n_disable=8" | sudo tee /etc/modprobe.d/iwl-opt.conf  this command enables aggressive tx on wireless-n and fixes a lot of issues 
you can do all the users' r and x permissions use a+rx and then you'll just need to add u+w for the owner's permissions to grant write access.  $ chmod a+rx,u+w ...   this will grant r and x to every one, and just u+w to the owner. 
you pressed ctrl+alt+fn for some n, and you need to press alt+f7 (usually) to get back. 
shared memory is using the 12gb.  on your linux release /dev/shm part of the /dev filesystem (on some releases, it has its own a dedicated file system mounted there).  as shown by lsof, the sum is 12 gb:  /dev/shm/foo5.44m is 6269616128 bytes    /dev/shm/kdfoo.a4o is 6269616128 bytes   neither find nor ls can display theses files because they are unlinked (= their names have been deleted). 
bash --version  alias ejectall=$'osascript -e \'tell application "finder" to eject (every disk whose ejectable is true)'\'  
the -f option does not display the full path to the executable, it displays the command line used to invoke the executable
you can do:  zgrep -b1 -a2 'pat_1\|pat_2' in.gz | tee &gt;(grep -b1 -a2 'pat_1' | \   grep -v '^--$' | gzip &gt;out1.gz) | grep -b1 -a2 'pat_2' | \     grep -v '^--$' | gzip &gt;pat_2.gz   here tee will send the initial output of zgrep -b1 -a2 'pat_1\|pat_2' in.gz two-ways:   the commands within process substitution &gt;() will work on one pattern (pat_1) the output sent to stdout will be catched by next piped grep and will be worked on to get the output for second pattern (pat_2).  
i ended up recompiling ruby
if only integers need to be handled and -0 is not need to be handled correctly, the following works:  case "$input" in ''|*[!0-9-]*|[0-9-]*-*)   echo "invalid input"         ;; [0-9]*)   echo "input &gt;= 0"   ;; -[1-9]*)  echo "input &lt; 0"  ;; *)  echo "invalid input"  ;; esac   but it is usually better to use if .
although the question assumes opinions poll which contradicts with stackexchange question policies, i will try to give some reasons, which are biased of course.   it's free (of course you may buy an enterprise-level support services from different companies if you wish); it's opensource it's much less prone to virus infections (there are much less vectors to attack so you need not to run a/v software that monitors programs activity at runtime) compare to some other oses and associated software. it's very well manageable, scaleable and extensible.   and finally, an answer for the last question you have highlighted with bold.  it is not preferred
assuming you're talking about x, you can add a customedid option to the monitor section of your /etc/x11/xorg.conf
you can set system-wide dconf settings by storing them in a text file under /etc/dconf/db/local.d and running dconf update.  if you've set up things on a user's account, you can print out the settings in text form with the dconf command line utility
i typically use true in loops; i think it's more clear:  while true; do     ... done   the one place i've found that : is really handy is in case statements, if you need to match something but don't want to actually do anything
loop devices with backing file less than 512b are not listed in /proc/partitions, which losetup uses to look up loop devices
bind mirrors a filesystem (among other situatons, it's useful when setting a chroot inside which you need to have a "complete" system (like when unpacking/installing gentoo).  just simply like that, it mirrors a tree from a into b
i found the answer from nick holland on openbsd misc mailing list:   so...today, you take a couple disks, zero the first 10mb, put a 1g boot partition and make the rest raid, then build a mirrored set, do your testing, and call it done.  tomorrow, you take the same disk, zero the first 10mb, put a 1gb boot partition on it, and make the rest raid, and intend to build a crypto raid partition on it
the most complete is by far ms office in a virtual machine: this is what i do.  if you will again be distributing those files you edited, it's pretty much necessary to use ms office, because anything else can have unpredictable effects on the document.  if it is for your own use, openoffice (or libreoffice or go-oo, etc) is just about as good as ms office and is the most feature-rich.  if you are in a kde environment and the oo.o-derived products feel awkward or clumsy, then koffice is an excellent alternative, although i find the .doc compatability less-suitable.  if you require a minimal install size, abiword is quite good
the easiest way to edit network configuration from a shell on centos is to use the tool /usr/sbin/system-config-network-tui
if you suspect that someone has correctly guessed your password and got in, you can check this via the console
if you want to read all of stdin into a shell script, usually you just capture it into a temp file:  tmpfile=$(mktemp /tmp/$0.$$.xxxxxx) cat &gt; "$tmpfile" # script works with $tmpfile and its contents, # ultimately writing everything to stdout. rm -f "$tmpfile"   even system utilities do things very much like this
it appears you are trying to run input files through awk and save the results as a different file name
qemu supports icmp on the slirp backend
to quote the emacs manual on the init file:     when emacs is started, it normally tries to load a lisp program from an initialization file, or init file for short
source tmp.txt export a b c ./child ...     judging by your other question, you don't want to hardcode the variable names:  source tmp.txt export $(cut -d= -f1 tmp.txt)   test it:  $ source tmp.txt $ echo "$a $b $c" 123 hello world one more variable $ perl -e 'say "@env{qw(a b c)}"'  $ export $(cut -d= -f1 tmp.txt) $ perl -e 'say "@env{qw(a b c)}"' 123 hello world one more variable  
if you want an md5 checksum specifically, you could pipe the content to a file and checksum that, then pipe the file and the checksum (with a delimiter) to mail.  using md5  if you want to use an md5 sum, you could edit your script to the following which will write to a temporary file, generate the checksum, append it, then send the mail.  #!/bin/sh  outfile=$(mktemp) echo -e "\nuptime"                                    &gt; $outfile 2&gt;&amp;1 uptime                                               &gt;&gt; $outfile  2&gt;&amp;1 last -x --since yesterday                            &gt;&gt; $outfile  2&gt;&amp;1  md5=$(md5sum $outfile | cut -f1 -d' ') echo-e  "\n==============================\n${md5}\n" &gt;&gt; $outfile 2&gt;&amp;1 cat $outfile | mail -s "info" user  rm $outfile  # don't forget this - clean up your /tmp!   this will capture all the stderr and stdout messages into the logfile and email it to you with the md5 checksum added to the bottom, so you could put the output back into a file and re-checksum it to make sure it matches.  using gpg  alternatively, you could create (or use an existing) a gpg key that you can use to sign messages coming from your server
the p.s. strikes me as a bad idea given the way bt works*, but a proper event hook should do the trick:     let's see an example of how arguments are passed to command:  $ cat hook.sh #!/bin/sh echo "called with [$1] [$2] [$3]" $ aria2c --on-download-complete hook.sh http://example.org/file.iso called with [1] [1] [/path/to/file.iso]    the --seed-time and --seed-ratio options kind of automate many use-cases, too.  (* better check your settings and read up on bittorrent) 
there are no relations between a pid and a job id on shells i have used (bash, dash and zsh).  however, a shell job is a child process of the shell, whereas pid 1 (init) is the ancestor of all processes, including the shell
its handled in the init scripts, in particular /etc/init.d/checkroot.sh
i think it's to make the checkhostip work.     if this flag is set to “yes”, ssh(1) will additionally check the host ip address in the known_hosts file
after quite a bit of trial and error on the commandline, i think i've found the answer
   {}            { list; }       placing a list of commands between curly braces causes the list to be executed in the current shell context
it's a little hard to diagnose, as you don't give source for myproc, but i suspect that your problem has something to do with "controlling tty"
you can do this using a negated -regex, too:-   find ./ ! -regex  '.*\(deb\|vmdk\)$'  
apt-get update just updates the list of available packages
it's not broadcasting anything
if you type history you will get a history of the commands you issued
type ctrl-a then v
that's an lxterminal bug.  it doesn't show in other shells because zsh is nice enough to try and show you hidden characters showed by the previous command when you don't include a trailing newline before issuing a prompt.  if you type echo -n foo, you'll see foo%
user@host is how ssh defines who it attempts to authenticate as (user) and where it should do that (host)   the user  this can be any local user account on the desktop and/or laptop you are connecting to
you need to filter the list by the current argument, so:  compreply=( $(compgen -w "$(ls ~/special)" -- "$2") )  
on an old distribution without du --inodes,  find 
think i figured out something that works.  i used a program called launchcontrol to create a file called enable core dumps.plist at /system/library/launchdaemons with the following contents:  &lt;?xml version="1.0" encoding="utf-8"?&gt; &lt;!doctype plist public "-//apple//dtd plist 1.0//en" "http://www.apple.com/dtds/propertylist-1.0.dtd"&gt; &lt;plist version="1.0"&gt; &lt;dict&gt;     &lt;key&gt;groupname&lt;/key&gt;     &lt;string&gt;wheel&lt;/string&gt;     &lt;key&gt;initgroups&lt;/key&gt;     &lt;true/&gt;     &lt;key&gt;label&lt;/key&gt;     &lt;string&gt;core dumps launchctl&lt;/string&gt;     &lt;key&gt;programarguments&lt;/key&gt;     &lt;array&gt;         &lt;string&gt;launchctl&lt;/string&gt;         &lt;string&gt;limit&lt;/string&gt;         &lt;string&gt;core&lt;/string&gt;         &lt;string&gt;unlimited&lt;/string&gt;         &lt;string&gt;unlimited&lt;/string&gt;     &lt;/array&gt;     &lt;key&gt;runatload&lt;/key&gt;     &lt;true/&gt;     &lt;key&gt;username&lt;/key&gt;     &lt;string&gt;root&lt;/string&gt; &lt;/dict&gt; &lt;/plist&gt;   with these permissions:  $ ls -al enable\ core\ dumps.plist  -rw-r--r--  1 root  wheel  582 dec 30 15:38 enable core dumps.plist   and this seemed to do the trick:  $ launchctl limit core     core        unlimited      unlimited  $ ulimit -a core core file size          (blocks, -c) unlimited ... &lt;output snipped&gt; ...   i created a little test program that just crashes:  $ ./a.out  segmentation fault: 11 (core dumped)   and, voila, a core dump was generated:  $ # ls -al /cores/ total 895856 drwxrwxr-t@  3 root  admin        102 dec 30 15:55 . drwxr-xr-x  31 root  wheel       1122 oct 18 10:32 .. -r--------   1 root  admin  458678272 dec 30 15:55 core.426  
for your concrete example, there is a function cd_builtin, which is defined in builtins/cd.def (in the bash source code)
on my system (cinnamon 1.8.8 on linux mint debian edition) i can disable it in the gnome control center
you can use this:  ls -dt */ |head -n 6| xargs -i{} rm -vr {}   or you can use:  find ./* -type d  -printf "%t+\t%p\n" | sort | head -n 6 | awk -f "/" '{print $nf}'  | xargs -i{} rm -vr {}   this will work with folders which has spaces in there names  for removing all directories but first 6  find ./* -type d  -print | sort | tail -n +7 |  awk -f "/" '{print $nf}' | xargs -i{} rm -vr {}  
to snip the major version component, simply do:  ..
in bash for example you can use utf-8 like this:  echo $'\xe2\x95\xb1'   which prints this:  ╱   or you can use unicode characters like this:  echo -e "\u2571"   which prints this:  ╇  
first of all your question has nothing to do with bash but with the terminal
assuming you are using bash_aliases (it is not necessary, you can also have aliases defined in .bashrc among other places), you can simply add a line to the file:  printf "alias foo='bar'" &gt;&gt; ~/.bash_aliases   alternatively, if you only want this alias for the current session, use the alias command directly:  alias foo='bar'   important  bash does not allow aliases to be expanded (to work) in scripts by default, you will need to activate the expand_aliases option:  #!/usr/bin/env bash  alias foo='echo "it works!"' echo "  alias defined, attempting to use without expand_aliases" foo  shopt -s expand_aliases echo "  attempting to use with expand_aliases" foo   if i run the script above, the alias foo will only work after i have activated the expand_aliases option:  $ a.sh   alias defined, attempting to use without expand_aliases /home/terdon/scripts/a.sh: line 5: foo: command not found   attempting to use with expand_aliases it works!  
the tty command will tell you which pseudo-terminal session you are running
well of course it won't, because you won't have a c library anymore.  all prelink does is to try and calculate an optimal load address for each library so that no program will have overlapping libraries, then update the libraries so that they default to loading at that address.  then when a program is run the libraries it uses are unlikely to need to be relocated as they can probably be loaded at their default address. 
it's more a job for perl like:  perl -mtime::piece -pi -e 's/\d{4}-\d\d-\d\dt\d\d:\d\d:\d\d/ (time::piece-&gt;strptime($&amp;,"%y-%m-%dt%t")+2*3600)-&gt;datetime/ge' file1 file2...  
previously i tried to completely uninstall in synaptic but since i had already standard-uninstalled it, the complete uninstall option was a deadlink and synaptic would not allow me to follow through with a complete uninstall
that's because you're spawning a sub-shell every time:  if ([ $remainder == 0 ] &amp;&amp; [ $is_prime == true ]); then   just remove the parentheses  if [ $remainder == 0 ] &amp;&amp; [ $is_prime == true ]; then   if you want to group commands, there's syntax to do that in the current shell:  if { [ $remainder == 0 ] &amp;&amp; [ $is_prime == true ]; }; then   (the trailing semicolon is required, see the manual)  note that [ is_prime ] is not the same as [ $is_prime == true ]: you could write that as simply $is_prime (with no brackets) which would invoke the bash built-in true or false command. [ is_prime ] is a test with one argument, the string "is_prime" -- when [ is given a single argument, the result is success if the argument is non-empty, and that literal string is always non-empty, hence always "true".  for readability, i would change the very long line  [ $is_prime == true ] &amp;&amp; echo "${number_under_test} is prime!" || echo "${number_under_test} is not prime (factors= $factors)"  [ $is_prime == true ] &amp;&amp; largest_prime=$number_under_test   to  if [ $is_prime == true ]; then   echo "${number_under_test} is prime!" else    echo "${number_under_test} is not prime (factors= $factors)"   # removed extraneous [ $is_prime == true ] test that you probably   # didn't notice off the edge of the screen   largest_prime=$number_under_test fi   don't underestimate whitespace to improve clarity. 
the problem turned out to be redirection of stdout (and presumably stderr).  by adding > logfile.log 2>&amp;1 &amp; to the end of the xinit line, the ssh session closes out safely and the x session and graphics programs continue to run.  so the final startgraphics.sh looks like:  #!/bin/sh #startgraphics.sh  #starts x and runs the graphics program  xinit /opt/common/graphics/bin/launchgraphics.sh &gt; /dev/null 2&gt;&amp;1 &amp; sleep 10 ;  echo "successfully launched graphics program!"  
setting a password actually did work, the secure boot entry has been removed
this warning is built into save-buffers-kill-emacs
short answer: the internet doesn't work that way  longer answer: ip address blocks are not neatly demarcated per country
you can use sfdisk for this task.  save:  sfdisk -d /dev/sda &gt; part_table   restore:  sfdisk /dev/sda &lt; part_table   for gpt partition tables, this requires sfdisk from util-linux 2.26 or later
you could use the audit system:  sudo auditctl -a exit,always -s execve -f ppid="$pid"   would cause audit entries to be generated each time a child of $pid executes a command
jason huggins  gave a fantastic talk at pycon 2012 that described, in great detail, a robot that could play "angry birds" on the phone:    worth watching the talk, it was very entertaining
just install glib.  $ wget http://ftp.gnome.org/pub/gnome/sources/glib/2.46/glib-2.46.2.tar.xz  $ tar xpvf glib-2.46.2.tar.xz  $ cd glib-2.46.2  $ ./configure --prefix=/usr --with-pcre=system &amp;&amp; make  $ make install  the dependencies, install &amp; user guide can be found here:  http://www.linuxfromscratch.org/blfs/view/svn/general/glib2.html 
i suggest you autocreate /dev symlinks using udev, using unique properties (serial number? port number?) of your usb cameras
solved by compiling the application from its source code. 
its simple, lets say your user is user1 and home directory is /home/user1/:  [user1@node2 ]$ export ldir=/home/user1/desktop/letters [user1@node2 ]$ cp f1.txt $ldir [user1@node2 ]$ cd ~/desktop/letters/ [user1@node2 letters]$ ls f1.txt  
to check available locale run locale -a , to change the locale e,g: eng , add the following line to your ~./bashrc:  export lang=en_us.utf-8   then run:  dpkg-reconfigure locales   and select us.utf-8  edit  iceweasel is deprecated , you should use firefox : apt-get install firefox-esr   then you can change the language from about:preferences#content  
with for and ifs:  #!/bin/bash  ifs=$'\n'       # make newlines the only separator set -f          # disable globbing for i in $(cat "$1"); do   echo "tester: $i" done   or with read (no more cat):  #!/bin/bash  while ifs= read -r line; do   echo "tester: $line" done &lt; "$1"  
 egrep is 100% equivalent to grep -e fgrep is 100% equivalent to grep -f   historically these switches were provided in separate binaries
if you add the -t switch you can specify how many writers you want iozone to make use of
rm's stdin (where it reads the prompt answer from) is /dev/null (set by gnu xargs, some other xargs implementations would keep it as the pipe from ls).  your sh is getting many arguments at once, but you're only processing one ($1).  also note that the newline character is as valid as any in a file name which is why you generally can't process the output of ls reliably.  with zsh:  for dir (*(nd/)) {   flacs=($dir/*.flac(nd.))   (($#flacs)) || rm -ri -- $dir }   otherwise, you could do:  find 
you can only return an integer between 0 and 255 from a shell function
try this, fixes the cp parameter order and limits to just root filesystem rather than trying to traverse /proc and the like.  find / -xdev -type f -perm a+r -exec cp {} /home/student/abc \;  
you can use !!:* to refer to all the words but the zeroth of the last command line.  !! refers to the previous command, : separates the event specification from the word designator, * refers to all the words but the zeroth.  this is from the history expansion section of bash(1).  wieland@host in ~» cat foo | grep bar bar wieland@host in ~» tail -f !!:* tail -f foo | grep bar bar   you could also use quick substitution where ^string1^string2^ repeats the last command, replacing string1 with string2:  wieland@host in ~» cat foo | grep bar bar wieland@host in ~» ^cat^tail -f tail -f foo | grep bar bar  
http://mywiki.wooledge.org/bashfaq/050  user_agent='--user-agent="mozilla/5.0 (windows nt 6.1; wow64; rv:27.0) gecko/20100101 firefox/27.0"' cookies_file="/tmp/wget-cookies.txt" save_cookies_opts=( --save-cookies "$cookies_file" --keep-session-cookies ) load_cookies_opts=( --load-cookies "$cookies_file" --keep-session-cookies )  function mywget {     log "#!!!!!!!!!# wget #!!!!!!!!!# wget $quiet $useragent $load_cookies_cmd $@"     wget "$user_agent" "${load_cookies_opts[@]}" "$@" }   note that in the wget call , "$user_agent" is quoted
there appears to be absolutely no way to disable font fallback
$ mysql -p$pass -u$user -h$otherhost $db &lt; dumpfile   this assumes dumpfile is text from mysqldump, containing raw sql statements.  it is important that there be no space between -p and the password
the message is printed by cpio, this avoids it:  find | lc_all=c sort | cpio -o 2&gt; /dev/null | md5sum | awk '{print $1}'   as gilles points out though, you'll lose any error messages printed by cpio if you use this approach
if the cctv dvr is *nix based, it might have a filesystem you can know about; for that you may get some good results just running:  file -s /dev/xxx   on the device file of the partition
cut -d: -f6 /etc/passwd |    while read oneuserraw; do     if [ -s "${oneuserraw}/.ssh/authorized_keys" ]; then       echo "${oneuserraw}/.ssh/authorized_keys"     fi   done |   perl -pe 's/\/\//\//g' |   while read oneuser; do     echo checking: "$oneuser"     cat "$oneuser" | while read oneline; do       if [[ "$oneline" == from* ]]; then         key=$(echo "$oneline" | cut -d' ' -f3)       fi       if [[ "$oneline" == ssh* ]]; then         key=$(echo "$oneline" | cut -d' ' -f2)       fi       length=$(echo "$key" | awk '{ print length }')       if ! (( $length % 4 == 0 )); then         echo "$oneline"       fi     done   done   i wrote a checker myself too
edit /etc/systemd/logind.conf and make sure you have,  handlelidswitch=ignore   which will make it ignore the lid being closed
this has nothing to do with unix
zstyle -l lists all the styles that have been defined, with their values
you could use the run-shell option, but the critical thing is to separate the commands with \;  in this case, something like:  bind r source-file ~/.tmux.conf \; run-shell "echo 'reload'"     run-shell shell-command   (alias: run)   execute shell-command in the background without creating   a window
two things should be noted:   "match opposite" does not mean "reverse the sense of the filter"
umask doesn't enforce rights, it forbids them
either  compreply=($(compgen -w '$(pwd)' -- "$cur") $(compgen -w '$(hostname)' -- "$cur"))   (you want a bigger array, just make one) or  compreply=($( compgen -w '$(pwd; hostname)' -- "$cur" ) )   (still autocompleting one command). 
if you've already started something somewhere, backgrounded it, and now need to attach it to a new terminal, you can use reptyr to re-attach it
the --from-file option allows you to compare one file against many files (rather than something like tar --files-from which reads a list of files to operate on from a file)
the default behaviour of wine is to create a "wine prefix" containing a virtual "drive c:" with links to ~/desktop, ~/documents, ~/music etc
you need to select a colorscheme prior to adding any highlight commands in your .vimrc file.  example  colorscheme desert highlight colorcolumn ctermbg=235 guibg=#2c2d27   references   how do i change my vim highlight line to not be an underline?  
for freebsd 8.4, you may be able to upgrade to the final patch level as noted in a forum thread issues with pkg commands:     upgrade first to the latest patch level of 8.4 that is 8.4-release-p9 at the moment and see if that fixes the issue
recordscreen.py  recordscreen.py sounds like what you're looking for
use this:  find -name "* *" -print0 | sort -rz | \   while read -d $'\0' f; do mv -v "$f" "$(dirname "$f")/$(basename "${f// /_}")"; done   find will search for files and folders with a space in the name
you can tune this script a little to produce a nicer output:  app='coreutils' for x in $(dpkg -l "$app"); do   test -f "$x" &amp;&amp; df "$x" |\   grep -v '^filesystem' |\   awk '{printf "block_dev: %s, mount_point:%s\n", $1, $nf}' done | sort -u  
in short: no
run chkdsk /f on windows
i found the answer
pass the -o and -g options to omit the user and group columns
i find if you maintain multiple kernels with different options its easier to roll your own /boot/grub/grub.cfg rather than use grub2-mkconfig.  an example entry is:  menuentry 'linux 3.10.17 (sde) kernel-3.10.17-g' {     root=hd0,1     linux /boot/kernel-3.10.17-g domdadm dolvm root=/dev/md3     initrd /boot/initrd-3.10.17-g }   where everything after the name of your kernel on the linux line are the boot options you want to pass to that specific kernel
with zsh:  vim ./**/*(.)   other shells:  find 
open exactly that menu -> system -> preferences -> keyboard shortcuts -> desktop -> show the panel's main menu and use backspace to delete the shortcut (or assign any other shortcut). 
total size in bytes of all files in hourly.2 which have only one link:  $ find ./hourly.2 -type f -links 1 -printf "%s\n" | awk '{s=s+$1} end {print s}'   from find man-page:     -links n           file has n links.   to get the sum in kilobytes instead of bytes, use -printf "%k\n"  to list files with different link counts, play around with find -links +1 (more than one link), find -links -5 (less than five links) and so on. 
you can start by setting vcpus in the guest.  vpus = &lt;number of virtual cpu cores&gt;   you could also consider pinning some vcpus to the guest.  vcpu-set domain-id vcpu-count   enables the vcpu-count virtual cpus for the domain in question
ok, from the comments, it seems like it'll fall into one of these suggestions:   you're making and deleting a bunch of temporary files, taking relatively little disk space
like many commands, md5sum has the ability to read from the standard input if an option's value is - (from man md5sum):     print or check md5 (128-bit) checksums
bakytn, don't worry, i do this all the time! i'm always making huge vms and then wanting to shrink them later
the problem is that this is a bash script, but you are running it with sh
as others have noted, if this is a dynamic web application, you're much better off using php's functions for accessing file size.  but if you're going to get it by executing a shell command, don't use ls
every account on a unix/linux system has a numeric identifier, the "user id" or uid
this is gilles' answer, saving it here so it doesn't get lost.  if you use the sync mount option on the removable drive, all writes are written to the disk immediately, so you won't lose data from not-yet-written files
i had a similar issue on freenas 9.3 and could not find a remove button
3.2.0 is the version of the source code used to compile this kernel
with zsh:  grep -- foo **/*(d.om)   with gnu tools:  find 
in zsh, the function search path ($fpath) defines a set of directories, which contain files that can be marked to be loaded automatically when the function they contain is needed for the first time.  zsh has two modes of autoloading files: zsh's native way and another mode that resembles ksh's autoloading
no it is not possible to modify tools such as kill via configurations in a manner that you're asking for
you can do  openssl smime -encrypt -text -in &lt;file&gt; smime.p7s   where &lt;file&gt; is the file you want to encrypt
it is harmless
a pending unreadable sector is one that returned a read error and which the drive has marked for remapping at the first possible opportunity
ha, i already found it; it's rpm -ql bind-utils as jeff schaller noted in the comments.  a slightly more polished version that filters out non-executables from the list is:  for file in $(rpm -ql packagename) ; do test -x $file &amp;&amp; test -f $file &amp;&amp; echo $file ; done 
the rationale given in the posix specification is:     the "-exec ..
there is screen to do that with (virtual) terminal applications, and there is xpra for x11. 
you should not have to do anything special, ssh does not terminate a connection because of inactivity
i prefer badblocks in destructive write mode for this
the cd should not be required
should be by default at the interface level, unless you've done something to disable multicast.  # ip a | fgrep multicast 2: ens3: &lt;broadcast,multicast,up,lower_up&gt; mtu 1500 qdisc pfifo_fast state up qlen 1000   ip link set ens3 multicast on could turn it on manually, if it's been somehow disabled, though that would likely better be done via the network-scripts.  otherwise, you'll probably need to delve around in ip-maddress(8) if there's a specific link-layer multicast address you need to listen for on an interface; ip maddress show should list the default ones. 
you should not cd into /root/teamspeak3-server_linux-x86
under kde you can hit shift+del to directly delete selected files (or directories)
since the shell performs glob expansion before the arguments are handed over to the command, there's no way i can think of to do it transparently: it's either controlled by the user (quote the parameter) or brute-force (disable globbing completely for your shell with set -o noglob).  you're looking at the problem from the wrong end
dolphin makes use of the solid namespace to detect devices
use the -j option
one is probably a symlink (or hard link) to the other.....but they are the same file. 
two suggestions:   file a bug report against mailman, so the developer can fix the bug for everyone. change the synch_members call to synch_members | egrep -v "nothing to do." that will eliminate the "nothing to do." messages.  
variables aren't expanded in single quotes
you can use who command to find out all the logged in users
the second solution (create/split/move) seems good. i tried to come up with some short guide, but be careful
you can send dd a certain signal using the kill command to make it output its current status
here's a very basic proof of concept
in sed, you must escape the parentheses and |.  /\.to\( \|_not \)&lt;\=/ s/&lt;\=/be &lt;\=/   alternatively, in your example you could use ? (also escaped):  /\.to\(_not\)\? &lt;\=/ s/&lt;\=/be &lt;\=/  
you only really need to take ownership of directories
to act on multiple files at once with find, use + instead of \;:  find 
you are, most likely, abusing lxdialog. that is supposed to be used only together all other configuration stuff.  if you really need a configuration tool to be used at compile time (i.e.:"make menuconfig &amp;&amp; make all") then you will find documentation to make kconfig work for you in kernel/documentation/kconfig directory (and other places, but you need to search for kconfig, not lxdialog!).  if you need a generic dialog interface instead (e.g.: as found in various debian configurators) you would be much better off using plain dialog available in all major distributions. you will find a lot of documentation for dialog (including at "http://invisible-island.net/dialog/dialog.html"). 
you can use the read command:  read -p "press enter to continue"   as mentioned in the comments above, this command does actually require the user to press enter; a solution working with any key would be:  read -n 1 -s -p "press any key to continue"  
you can add a capability to a binary file
look in /usr/lib and /usr/lib64 for those libraries
this shell script will get you the difference in seconds between the timestamps in column two of the first two rows:  ( ifs=, read -r _ a _; ifs=, read -r _ b _; a=$(date --date $a +%s); b=$(date --date $b +%s); echo "$a - $b" | bc | tr -d - ) &lt;filename   it can be broken down like this, too, if you prefer:  (     ifs=, read -r junk a junk        # get second comma separated field     ifs=, read -r junk b junk     a=$(date --date $a +%s)          # convert to seconds since the epoch     b=$(date --date $b +%s)     echo "$a - $b" | bc | tr -d -    # compute signed difference, then discard unary minus sign ) &lt;filename  
not having root privileges prevents you from listening on ports below 1024 on typical linux systems.  thus, squid should work ok as non-root listening on 8080 as long as the system you are on hasn't blocked incoming traffic on that port via a firewall or iptables.  not sure how many file descriptors squid uses typically but if your admin has set a limit for that, that could be an issue, as well as other things
i solved this by installing kx studio
allow-hotplug &lt;interface&gt;, is used the same way auto is by most people
you must have used a wrong command somewhere..
&gt; echo "50853718  50853807  50859414" | xargs -n 1 echo xdotool getwindowname xdotool getwindowname 50853718 xdotool getwindowname 50853807 xdotool getwindowname 50859414   if that's what you need then remove the echo.  xdotool search --name "a_program" | xargs -n 1 echo xdotool getwindowname  
--direct commands cannot be made permanent
you can't expect a 1:1 mapping here
ps lists bash as the running process because the bash process is blocked trying to open the fifo /tmp/in2 before spawning the cat command
i have investigated that topic since i asked my question and it turns out that the ranges of sub-gids/sub-uids are indeed used as file-group/-owner for the files
i'd strongly suggest not to use find -l  for the task (see below for explanation)
when you invoke python3.5 -m site then python searches for a file site.py in your sys.path
you will need to reinstall the affected packages because the local image won't have any content to let to repair.  however you can potentially minimise the amount of repair needed.  you can determine which packages have files in /usr/share/man with a loop such as  for pkg in $(dpkg --get-selections | awk '$2=="install" { print $1}') do   f=$(dpkg -l $pkg | grep /usr/share/man)   if [ -n "$f" ]   then     echo $pkg has files in /usr/share/man   fi done   you can then reinstall those packages.  we can potentially even limit further to those that are missing by looking at /var/lib/dpkg/info/$pkg.info for the man files and compare to what is missing and only reinstall those.  however, at the end of the day, i think you're going to reinstall a lot of packages
the problem is that you have a sudo configuration which allows running a login shell, but not directly running an arbitrary program.  if the user has a restricted account, i.e
   how do i modify the inotifywait command to report only when a file of   certain type/extension is created   please note that this is untested code since i don't have access to inotify right now
actually, the source package has been installed successfully in /usr/src/package folder
so, the core problem there is that it's looking for the kernel header files needed to compile new kernel modules
you should use grep --line-buffered percentage or else it will take a very long time for the grep stdout buffer to be filled by its output. 
first of all, systemd is not a traditional unix init
below is an updated textclock.lua widget that responds to timezone changes at runtime
from your github link, follow "audit event parsing library" which has a link the the dictionary at https://github.com/linux-audit/audit-documentation/blob/master/specs/fields/field-dictionary.csv  the raw csv version is at  https://raw.githubusercontent.com/linux-audit/audit-documentation/master/specs/fields/field-dictionary.csv 
you can not modify the variable inside the for cycle like this in bash
the following should work:  for x in `find &lt;dir&gt; -type f -mtime +14`; do lsof "$x" &gt;/dev/null &amp;&amp; echo "$x in use" || echo "$x not in use" ; done   instead of the echo "$x not in use" command, you can place your rm "$x" command.  how does it work:   find files, last modified 14 days or longer ago:   find &lt;dir&gt; -type f -mtime +14   loop over items in a list:   for x in &lt;list&gt;; do &lt;command&gt;; done   execute command 2 if result of lsof is 0, else execute command 1:   lsof "$x" &amp;&amp; &lt;command 1&gt; || &lt;command 2&gt;  this relies on the lazy evaluation of bash to execute command 1 or command 2.  on my system (ubuntu 14.04) this works with file names with spaces in them and even for file names with ? and * in them. this is however no guarantee that it will work with every shell on any system
if you're reinstalling the os on your computer, but you consider that it's still the “same” computer, then you must back up the ssh private key and restore it after the installation
if the connection is really restricted to pure http, httptunnel is meant to tunnel tcp connection through http requests.  though performance-wise, you'd do much better if the proxy supports connect, or if the firewall allows other kinds of traffic - e.g
this seems to be exactly what networkmanager was designed for.  make sure networkmanager is installed and the service running and stop the old network service.  by the way even with the network service rebooting is not necessary
there are many questions here, and let me try to answer them in order of importance to your situation:   extracting a database from a hard drive image i am assuming you are interested in the actual data, i.e., various tables, its rows, and columns, etc
because your service file is in /usr/lib/systemd/user, it is treated as a user service, and is started by your own instance of systemd (run as systemd --user)
from the gnu tar doc's (man tar)   -c, --directory dir        change to directory dir   so you command should be:  tar -c / -xvf list.tar   if you don't have -c  # /var/tmp (x=$pwd;cd /;tar xvf $x/list.tar)  
nothing new at all
if i understand you right then there is some file system on /dev/sdb that you have mounted
the man page for gnu find describes -execdir in part thusly:     like -exec, but the specified command is run from the subdirectory containing the matched file, which is not normally  the directory  in  which you started find.   so there is no real subtlety involved
umaks on all unix based systems that i know of are process specific, not directory specific
gnome 3.20 is only available in debian testing, so you can:   update to testing (which isn't recommended as it isn't stable) install only gnome from testing (which can create new problems as gnome has many dependencies and mixing releases isn't recommended (see debian wiki) use a different distribution which is using a newer gnome version. try to find out if you really need gnome 3.20 or you can resolve your problems with 3.14 wait until the current debian testing (stretch) becomes stable  
 some programs like gnuplot accept a command file, it may be easier to generate on and then pass it as argument. some programs don't depend on interaction, for them piping to stdin may work   (     printf "my command\n"     printf "my other command line\n" ) | theprogram and its args  other depend on interaction and mandate that their standard input is a terminal, you have to use expect or equivalent.  
as noted, this was originally done to reduce size
the device tree is exposed as a hierarchy of directories and files in /proc
openssl s_client -cafile /etc/ssl/certs/ca-certificates.crt -verify 12 -showcerts -connect mail.google.com:443   that will work on debian or its derivatives where the list of trusted cas (of the system which may not be the same as firefox's) is in /etc/ssl/certs/ca-certificates.crt
the new openssh 7.3 provides the switch -j which allows you to create your desired one-liner:  scp -oproxyjump=userb@hostb,userc@hostc infile.txt userd@hostd:"~/outfile.txt"   from manual page:     proxyjump      specifies one or more jump proxies as [user@]host[:port]
you can use audacity for that
solution found here : the stable 2.4 doesn't support ppc plugins,upgraded to latest devel will work. 
freeing up resources should generally return the system to a normal functioning state, so it sounds to me like the system is still struggling to free up resources or, hasn't fully followed through on killing these processes
you can force fsck at boot time by passing fsck.mode=force as a kernel command line parameter (as of systemd v
add the user to the wheel group:  gpasswd wheel -a username   i use gpasswd because not all versions of usermod have an easy way to add the user to a group without changing all the users' groups
to understand what's going on at this level of detail, i think you have to reach for the source code
pure-ftpd has something like mysqlgetuid and mysqlgetgid for specifying queries to get uid/gid
no, there's no keyhold event, only keypress and keyrelease
your nvidia module is perfectly loaded and working
it is explained in practical unix &amp; internet security as a security feature:  uucp has to log in to issue commands, and uucico is a limited-functionality shell, with a separate login/password from regular accounts. 
dropbox apparently doesn't support symlinks
i have solved the issue
try something like this:  dd if=/dev/device of=output-file bs=1 count=10 skip=&lt;offset of data&gt;  it does exactly what it says on the tin; read 10 bytes starting from the given position on the device to output-file
it is now in system settings =&gt; window tiling and edge flip which, really, should have been evident from the name:   
one of the various arm-based plug computers will serve you well
if you run the set command without any arguments, it will output all the variables and functions that where set for the session, with that in mind is just a matter of filtering the variables and then filtering the "string" you want from those variables, assign that to an array and then pass the array to the function.  all_variables=( $(set | grep -ea '^variable.*=' | cut -d = -f 2) ) randomfunction "${all_variables[@]}"   basically you will get all the output from set and grep for any line that starts with variable followed by any characters and an equal sign, then you will pass it to cut to separate name and value, and assign all the values to the all_variables array, which then will be expanded and passed as arguments to randomfunction 
try this:  rpm -qf /etc/cron.daily/apt.cron   that's the rpm command which tells you which package a file comes from (if any)
in bash you can do :  while ifs= read -r dir; do [[ -d $dir ]] &amp;&amp; mv -i "$dir" "${dir%???}"; done &lt;all.txt   this will read the file all.txt line by line and check if the directory represented by the line exists, if so then renaming will be done accordingly.  edit :  to remove only one character, make the parameter expansion pattern ${dir%???} as ${dir%?}, the metacharacter ? represents single character in bash
vipe is a program for editing pipelines:  command1 | vipe | command2   you get an editor with the complete output of command1, and when you exit, the contents are passed on to command2 via the pipe.  in this case, there's no command1
you don't need source code, to install less packages
on linux with the ps from procps(-ng) (and most other systems since this is specified by posix):  ps -p "$$" -o etime=   where $$ is the pid of the process you want to check
your syntax isn't compatible with the freebsd implementation
just pipe the command into a while loop
figured out now how to get the trailing data.  i created perl script which creates a file with the trailing data, it's heavily based on https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=604617#10:  #!/usr/bin/perl use strict; use warnings;   use io::uncompress::gunzip qw(:all); use io::file;  unshift(@argv, '-') unless -t stdin;  my $input_file_name = shift; my $output_file_name = shift;  if (! defined $input_file_name) {   die &lt;&lt;end; usage:    $0 ( gzip_file | - ) [output_file]    ..
this tweak should get rid of your problem
the process you noticed is the master process, the process that starts all other nginx processes
the first place to look is your distribution's package list
there is a readline command, called edit-and-execute-command tied to the sequence c-x c-e, that invokes your editor with the current content of the command line for editing.  when you exit the editor the command is executed
you can specify it (loaded on reboot anyway) in /etc/sysconfig/network with a hostname= line (see the documentation here)  you should specify it as a fully qualified name there generally.  if the host doesn't have a name already, and you're using dhcp it will often pick its name up that way. 
it sounds like you're either booting windows 8.1 in legacy/bios/mbr mode (as opposed to efi/gpt mode), or yast is buggy and thinks that you have efi booting enabled even though you don't
   are there any secure unix tools to recover data, that was removed with rm, from a usb flash drive?   yes and, by the way, recovery of photos is one of the most common scenarios.  the conditions you described are actually optimal because:   you directly deleted the files the file system is not damaged you did not use the drive anymore   these conditions lead to two available options.  if you care about the file names (or have fragmented files)  when you write a lot of pictures sequentially on a drive, the risk of fragmentation is actually very low, but still
the postfix command exists in /usr/sbin/ if postfix is installed, and regular users do not have the /sbin/ directories in their path variable by default
you cannot 'uninstall' grub
aptitude install kde-desktop should do the trick  http://pkg-kde.alioth.debian.org/kde3.html  and if i am correct aptitude install xfce-desktop would do this for xfce
it isn't encrypted, you can use the off-the-record plugin that's available as a third-party plugin for pidgin
use the jobs built-in to see running tasks for your current shell.  $ ping google.com &gt;/dev/null 2&gt;&amp;1 &amp; [1] 32406  $ jobs [1]+  running                 ping google.com &gt; /dev/null 2&gt;&amp;1 &amp;  $ ping google.com [...] ^z [2]+  stopped                 ping google.com  $ jobs [1]-  running                 ping google.com &gt; /dev/null 2&gt;&amp;1 &amp; [2]+  stopped                 ping google.com   to kill all running jobs, you can leverage jobs -p which lists the pids of all jobs.  $ for job in $(jobs -p); do kill $job; wait $job; done   further reading: http://www.tldp.org/ldp/abs/html/x9644.html 
you need to install at least gsl-devel, which contains the gnu scientific library
the shell's parent process is su, so you need to find out the user running su's parent process:  ps -o user= $(ps -o ppid= $ppid)   but you shouldn't be doing sudo su - if your version of sudo is not too old to have sudo -i
most keyboard layouts outside the u.s
you could use sed
after telnet connects type: get /  telnet stackoverflow.com 80       trying 104.16.36.249... connected to stackoverflow.com
append line after match   sed  '/\[option\]/a hello world' input   insert line before match   sed  '/\[option\]/i hello world' input   additionally you can take backup and edit input file in-place using -i.bkp option to sed 
you can use tar or cpio or pax (if any of these is available) to copy certain files, creating target directories as necessary
rsync -a should work if you simply do:  rsync -av /data/backup /media/usb_hdd_3   if it isn't preserving directory timestamps, this is probably a bug in the rsync version
you need to pick a class aware qdisc like hfsc or htb.  then you'll have to build a class tree like this:  root class (10mbit) | \--- xyz class (rate 3mbit ceil 3mbit) |    | |    \--- client 10 (rate 1.5mbit ceil 3mbit) |    \--- client 11 (rate 1.5mbit ceil 3mbit) | \--- client 30 (rate 3.5mbit ceil 10mbit) \--- client 40 (rate 3.5mbit ceil 10mbit)   and that on both interfaces (for upload and download shaping).  with htb to get predictable results you should make sure that the sum of children is always equal to parent
okay, so here's what i ended up doing
scp will read your ~/.ssh/config and /etc/ssh/ssh_config
solaris tar and gnu tar have different interpretations of posix but both support ustar, which in turn supports long(ish) pathnames.  using gnu tar on cygwin:  $ tar -c --format=ustar -f dir.tar dir   this creates a tarball which is happily extracted on solaris 9 without errors
here it is: the fhs 2.3 specification 
while they are similar (more similar than bash and tcsh, for example) they are different enough to force you to read documentation before doing nontrivial configuration.  it is not hard at all to start using it though, just grab someone's .zshrc and modify it to suit your taste.  additional reading:   http://grml.org/zsh/zsh-lovers.html http://zshwiki.org/  
when you configure a wired network using /etc/network/interfaces, you tell network manager not to touch it
with awk:  echo 5 | awk '{$0=int($0/4+1)*4}1'   explanation:   $0/4+1 the value is divided by 4 and the result incremented by 1. int(n) this is then rounded down by awks int(). n*4 now we only have to multiply that with 4 to get the next higher number divisible by 4. {...}1 the 1 at the end will just print the value.   this will print 16 for the value 12.    if you want the value to stay when it is divisible by 4, then use this awk instead:  awk '{$0=int($0/4+.75)*4}1'  
the machine store keys and certificates are stored in the root user's home directory:  /root/.config/.mono/   however, when i chmod'd the subdirectories there to provide access to the user in question, it didn't work, i still got permission denied.  instead, i'm taking dave_thompson_085's tip
you could also use find in a sub process and feed the output to cat :)  cat $(find 
i did not see any official packages for this in any of the normal centos repositories so you'll likely have to download the source package and attempt to rebuild it yourself.  i would start with the fedora 21 version of the package available here:   http://dl.fedoraproject.org/pub/fedora/linux/development/21/source/srpms/p/python-pyside-1.2.2-2.fc21.src.rpm   once downloaded you can use rpmbuild to rebuild it, assuming you have the necessary compilation environment stood upon a centos 7 system. 
start a subshell:  (umask 22 &amp;&amp; cmd)   then the new umask will only alter that subshell.  note that zsh executes the last command of the subshell in the subshell process instead of forking another one, which means that if that command is external, you're not even wasting a process, it's just that the fork is done earlier (so the umask is done in the child process that will later execute your command). 
using one type of quote is more simple and solves that issue;  curl -h "content-type: application/json" -x post -d "{\"uptime\": \"$(uptime)\"}" "http://sitename.com/update.php"   or you can use 2 quote types but it's less elegant;  curl -h 'content-type: application/json' -x post -d '{"uptime": "'"$(uptime)"'"}' 'http://sitename.com/update.php'  
jobs is shell builtin,so no man but  help jobs   the use is simply  vi&amp;  #vi goes in background(i know,is useseless)  jobs  #return status jobs -p #return status and pid %     #resume first job, vi in this case %2    #resume second job ctrl-z #suspend job   for more options and use help jobs  if you want to see processes  ps     #show process ps -ef #sv style,all processes ps aux #bsd style,all processes man ps #better read  
you can use cheese (gnome) if you just need just that, or vlc for more advanced features. 
the debian wiki has an excellent entry describing what i required
use single quotes (') so $nnn isn't treated as a variable
the answer is found here: https://www.kernel.org/doc/gorman/html/understand/understand014.html  it says "..
it's not the --context, but the \s* at the start of your regex pattern. it seems ag doesn't search line-by-line like normal grep, but looks at the whole file in one go (or at least several lines at a time)
your question is not very clear, for example in the code you write ims00 and later on refer to it as ims.00, with dot
because the shell was not originally supposed to be a full programming language.  it is quite difficult to remove a trailing \n from some command output. however, for display purposes almost all commands end their output with \n, so… there has to be a simple way to remove it when you want to use it in another command
well, it really depends on how read-only you want the pool to be
dig into /sys
modify /etc/x11/xorg.conf with the following
yes, thats a setup using by nfs with netapp storage (see library.netapp.com/ecmdocs/ecmp1154894/html/…) this setup is used when you shared volumes, but you should use quota, so that one user/customer can not use the full space and stop others from working (avoid disk full error)
the way to change the dead keys without changing the keyboard layout is to set the lc_ctype environment variable to pt_br.utf8
apparently it's not possible to keep the pdf metadata when using ghostscript
you can stop apt-get temporarily with ctrl-z and then restart the job in the background with the bg command.  $ apt-get foo bar ... ^z bash: suspended apt-get $ bg bash: continued apt-get $   however, when you do you'll continue getting the output from apt-get on the terminal
zdump reports an extra fake "transition" at the beginning and end of the range of 32-bit time_t
if you are need to make changes to both you can use loop  #!/bin/sh for id in $(xinput --list | \             sed -n '/corsair corsair m65 gaming mouse.*pointer/s/.*=\([0-9]\+\).*/\1/p') do   xinput --set-prop $id "device accel profile" 6   ...   whatever you want to do   ... done  
the packages are grouped in the groups, that can be installed and removed together
rsync has code which specifically checks if a file is truncated during read and gives this error — enodata
if you need to create the mint menu entry yourself, just run the following command:  sudo mate-desktop-item-edit /usr/share/applications --create-new   a window will appear, just give it a name, then type the command to use a web-browser to open the website url
i am running the saucy kernel on both my development machine and my in-house server without problems
since you are programming in c i thought of posting a little snippet which shows you if the port is open or not, i have programmed to output a string
provided there are fewer than 999,999 lines:  grep -a 999999 '19/jan/2016:22:' access_log   but this would be a better solution as it doesn't restrict the number of lines after the match:  sed -n '/19\/jan\/2016:22:/,$p' access_log  
you were almost there, try this:  sudo sed 's/,\([0-9]\{1,2\}\)/,\1\)/g' filename   here in addition to your command i have just added \{1,2\} which matches the previous regex between one to two times i.e
how about  perl -alne 'print join " ", $f[0], split("", $f[1])' data id01 1 2 0 1 2 0 1 0 1 id02 1 0 1 0 1 0 1 0 1 id03 2 1 0 2 1 0 2 1 0 id04 5 0 5 0 5 2 1 2 0   if you want (fully) tab separated output, change to  perl -alne 'print join "\t", $f[0], split("", $f[1])' data   or if you want to preserve a tab after the id but space-separate the digits of the second field,  perl -alne 'print join "\t", $f[0], join " ", split("", $f[1])' data  
firstly, double quotes are required for interpolation:  $ sed "s/2/${red}2${blue}/" hello.txt 1233[0;31m2233[0;34m53125213 233[0;31m2233[0;34m13532135 233[0;31m2233[0;34m3513125215   however, the ascii escape sequences contain characters that affect sed, so you have to convert the escape character sequence into the actual control characters
find 
the reason yum is asking for a key is that it is not present in /etc/pki/rpm-gpg  ls /etc/pki/rpm-gpg/ | column rpm-gpg-key-centos-6        rpm-gpg-key-centos-security-6    rpm-gpg-key-centos-debug-6 rpm-gpg-key-centos-testing-6    rpm-gpg-key-puppetlabs   you can import the key in one of 4 ways:    use rpm --import http://download.fedoraproject.org/pub/epel/rpm-gpg-key-epel-6  (as suggested by slm) install a package and then wait for the prompt (like i was doing) use the rpm package provided by epel, it installs the repo and the key simultaneously
use the -l option to ssh-add to list them by fingerprint.  $ ssh-add -l 2048 72:...:eb /home/gert/.ssh/mykey (rsa)   or with -l to get the full key in openssh format.  $ ssh-add -l ssh-rsa aaaab3nzac1yc[...]b63sq== /home/gert/.ssh/id_rsa   the latter format is the same as you would put them in a ~/.ssh/authorized_keys file. 
this is a form of parameter expansion (i.e
under freedesktop-compliant environments, including xfce4, sleep inhibition is communicated via d-bus on the org.freedesktop.powermanagement bus
generally people do not use graphical install wizards in gnu/linux environments
rs232 has no "cable presence" indicator of any kind
the rule is rather simple
installing emacs-nox instead of emacs should do the trick. 
there are two s commands there: sed can take a list of commands seperated by semicolons
here are the relevant excerpts for the same question which have been answered already at how do i choose the right parameters when using badblocks? and using badblocks on modern disks.  there is a badblocks benchmark script available that should suit your purpose.  with regards to the -b option: this depends on your disk
* only includes visible files
gpt can have as many partitions as you want*
this is fairly easy to do with iptables
bahamat and alan curry have it right: this is due to the way your shell buffers the output of echo
$ printf '%s\n' 10.0.{100..224}.\* 10.0.100.* 10.0.101.* 10.0.102.* 10.0.103.* 10.0.104.* 10.0.105.* [...snip...]  
instead of your script calling yum to do the download and install, i would just make the script download the file (with e.g
this is, at least in part, governed by the servertokens directive, so you could set   servertokens prod   which will reveal only that the server is an unspecified version of apache, but even the manual itself suggests this is not a security measure. 
if you want a single expression, you can do:  sed -i 's#/client/[^/]*#/client/12x_64#g' config*   i've used /client/[^/]* as the marker to find what we want to replace (ie whatever is after /client/ but before the next /) , but we could have done client/[^/]*/instance instead if that avoids matching other items in the file. 
when you press enter at the end of:  for variable in file1 file2 file3   the shell can't execute anything since that for loop is not finished
since the other responses here do not answer all the questions asked...    "why is this happening?"  several coreutils developers decided they knew better than decades of de facto standards.    "how do i stop it properly?"  http://www.gnu.org/software/coreutils/coreutils.html:     bug reports      if you think you have found a bug in coreutils, then please send as   complete a bug report as possible to &lt;bug-coreutils@gnu.org>, and it   will automatically be entered into the coreutils bug tracker
you cannot change existing processes' group id, which means one way is to restart them
just use the -w flag of the test utillity:  [ -w /path/to/file ] &amp;&amp; echo "writeable" || echo "write permission denied"   note that if you're going to write to the file later, it's still possible that you won't be able to write to it
in the shell script, simply include the following:  path="$path:/usr/local/proc_mt/bin:usr/local/matlab/matlab_production_server/r2015a/bin"   if there are executables with the same name as other executables in your $path, and you wish to give the matlab executables preference over the others, put it before your current environment $path like so:  path="/usr/local/proc_mt/bin:usr/local/matlab/matlab_production_server/r2015a/bin:$path"   in some scenarios you may need to export this environment variable by doing  export path=[the solutions i listed above]  ...which can never hurt (and in some cases may make obscure issues easier to troubleshoot)  the issue you are probably experiencing is that you are setting the $path in your shell, and the actual script is defaulting to the default environment $path
on machine a:  iptables -a postrouting -t nat -j masquerade  
this is scarcely explained in implementing selinux as a linux security module     this results in a populated selinuxfs filesystem and sets up the special null   device node used by selinux when it closes unauthorized files upon a   context-changing execve.   apparently programs cannot use /dev/null directly while in selinux-context and they needed their own version
you cannot pull the command that generated the variable because the information is not there anymore
there are 2 libraries that normally handle this
no, it doesn't change the timestamps of contained files and directories, only on the directory itself
when writing cron jobs you should use the absolute path to the binary, if you haven't already done a export of your path in crontab.  find out where lsyncd is located with:  $ command -v lsyncd   example output: /bin/lsyncd
tr is fine for this job:  tr -d 0 &lt;file   [:0:] is invalid because you need to use a character class between [: and :]. 
it quits as soon as its input ends
you can change the key bindings of the line editor prompt to make space insert a space
the command tee, when passed a non-existing file as parameter, will create that file before writing the output to it
see the blog below for more details
a regex in python, either the search or match methods, returns a match object or none
the linked sources refer to the on-disk format
with help from this answer  awk 'fnr==nr &amp;&amp; fnr&gt;1 {a[$2] = $5; next}      fnr &gt; 1 &amp;&amp; ($2 in a) &amp;&amp; $3 == "all" {          print $1 "    " $2 "    "  a[$2] "    "  $9      }' file2 file1   to get the header as well, just add this to the beginning of the script:   begin{print "chr snp maf p"}   explanation:  first of all, when two files are passed to awk, they are processed one after another
you call your script with  ./script file_*.jpg jpg bak   but * gets expanded before it is passed to the script
in the replacement side of vim substitution, a newline is represented by \r
i managed to kill it using  pkill -f restart.py   from the man page:     -f     the pattern is normally only matched against the process name.           when -f is set, the full command line is used.  
with globs :  for dir in */; do mkdir -- "$dir/tmp1"; done   note   i treat only dirs (including symlinks to dirs) with the little hack of using */ as a glob if you want to create multiple subdirs at once :      for dir in */; do mkdir -- "$dir"/{tmp1,foo,bar,qux}; done  
check out flashrom, it can read the contents of most motherboard flash chips
the apt-get upgrade command you have used will only upgrade packages that need no new packages as dependencies.  you can use apt-get dist-upgrade to include new packages in the set of candidates
you have a lot of options.   you could create multiple vio servers and run dev and uat off different vios you can create multiple sea's on vio servers and assign different physical adapters to each of the seas you can assign multiple vlans to the same sea as long as the network side is set up for it (referred to as vlan tagging usually) other stuff i've not thought of straight away   there's no single right answer, it depends on a number of other factors
put this in .bashrc: export timeformat=%rs  then source ~/.bashrc.  run type time to find out that time is a shell keyword
the &gt;&gt; /tmp/output already sends all output to the file, leaving nothing to be sent to tee. so the command should read node test.js 2&gt;&amp;1 | tee --append /tmp/output. 
yup, i found where is that install path
here you are:  sed 's/\(.\{1\}\)/\1 /g' input &gt; output   and if you want to save the changes in-place:  sed -i 's/\(.\{1\}\)/\1 /g' input   how it works:  s/\(.\{1\}\)/\ /g will add a space, after each 1 character.  for instance, if you wanted an output file like:  12 12 10 31 22 12 33 32 12 12 00 00 02 22 21   you could edit my answer to:  sed -i 's/\(.\{2\}\)/\1 /g'   so it will add a space, after each 2 characters.  in addition, /\1 / is the same as /&amp;, and will add one white-space. for instance, to add three: /\1   / or /&amp;   /
assuming that they are always the same amount of lines, you could do something like this: sed '/connect\s*user@localhost on/,+7d' log.file this will remove the line containing connect   user@localhost on and the following 7 lines from the file "log.file" in your current directory.  edit: final solution (well, at least good enough for the op to alter to his liking) can be found in the comments. 
i find a solution via mkfifo, that creates a named pipe, or fifos. simple as to create a symbolic link and it's possible to use all the redirection allowed from the shell.  mkfifo myoutput   ls -l gives  0 prw-r--r-- 1 my_username my_username  0 may 11 17:45 myout|   i can launch the program with redirection to that link  ./execute_program &gt; myoutput  &amp;  cat myoutput    and the output starts to flow on the terminal
under linux, you can use the inotify kernel subsystem to efficiently wait for the appearance of a file in a directory:  while read i; do if [ "$i" = sleep.txt ]; then break; fi; done \    &lt; &lt;(inotifywait  -e create,open --format '%f' --quiet /tmp --monitor) # script execution continues ...   (assuming bash for the &lt;() output redirection syntax)  the advantage of this approach in comparison to fixed time interval polling like in  while [ ! -f /tmp/sleep.txt ]; do sleep 1; done # script execution continues ...   is that the kernel sleeps more
arch linux' kernel has the swap accounting disabled by default (cf
i was able to get it running by creating an app specific password (as noted in the question)
as long as you do not want to search for some special characters (like &amp;), one of the most easy way to start a search is to put the following function  googleit() {    xdg-open "http://google.com/search?q=$*" }   into your $home/.bashrc.  after re-login or restarting the shell or sourcing this file, you can then simply type  $ googleit the phrase i want to search for   and your default browser should start with the corresponding search result. 
take a look at this: http://www.kernel.org/doc/menuconfig/drivers-base-kconfig.html  in particular:   extra_firmware "allows firmware to be built into the kernel, for the cases where the user either cannot or doesn't want to provide it from userspace at runtime" extra_firmware_dir "controls the directory in which the kernel build system looks for the firmware files listed in the extra_firmware option. the default is the firmware/ directory in the kernel source tree, but by changing this option you can point it elsewhere, such as the /lib/firmware/ directory or another separate directory containing firmware files".   by the way, as far as getting your wireless card working, have you taken a look at these pages?:   http://en.gentoo-wiki.com/wiki/tl-wn821n http://bugs.gentoo.org/278385  
assume there is command1 &amp;&amp; command2.  in this case command2 will be executed if and only if command1 returned zero exit status.  ; is just a command separator
there's an option for youtube-dl to do what you're looking for, it is the--match-title regex operand 
udp cannot have state - try without the state clause.  also, be aware that if you are checking incoming traffic with tcpdump, this listens outside the firewall. 
you are looking for   fold -w 80 -s text.txt    -w tells the width of the text, where 80 is standard. -s tells to break at spaces, and not in words.   this is the standard way, but there are other systems, which need "-c" instead of "-w". 
it is because of nptl
i've used these steps in the past to sign my rpms
there are several useful ways to achieve this (in bash):  two checks  echo -n "enter test: " read test  if [[ $test == "a" || $test == "a" ]]; then     echo "worked" else     echo "failed" fi   make the input lower case  echo -n "enter test: " read test test="${test,,}"  if [[ $test == "a" ]]; then     echo "worked" else     echo "failed" fi   regex for both cases  echo -n "enter test: " read test  if [[ $test =~ ^[aa]$ ]]; then     echo "worked" else     echo "failed" fi   make the shell ignore the case  echo -n "enter test: " read test  shopt -s nocasematch if [[ $test == a ]]; then     echo "worked" else     echo "failed" fi  
when you do:  nohup echo "45" &gt; my_named_pipe &amp;   the shell forks itself
usually (i'm talking about standard tools with --color=auto), colors are echo-ed only on terminal
the answer turned out to be xp, just not the windows kind ;)  if you are working on your vim skills generally you may also find this useful:  vi / vim - how to automatically strip trailing spaces on save? 
to specify the ip address 1.1.*, you would use 1.1.0.0/16
it's because the time in the first command is a shell keyword
no you should not be using resize on an partition that is part of a raid and no you should not do so while mounted.  you probably should not use the parted that you have at all
% toggles the file filter in any view and does what you're asking for
if for some reason you must read the block device using a block size of 16k:  dd if=/mnt/nfs bs=16k | pv -l &lt;rate&gt; &gt; /dev/sda   where &lt;rate&gt; is the maximum allowed amount of bytes per second to be transferred, or the maximum allowed amount of kibibytes, mibibytes, gibibytes, [...] per second to be transferred if k, m, g, [...] is specified.  however if you don't really have to read the file using a block size of 16k, just use pv, which can read block devices:  pv -l &lt;rate&gt; /mnt/nfs &gt; /dev/sda  
the best commands you could try are not to use in a terminal but in a web browser..
in most systems, /root is the home directory of the root user, and /home is the parent directory for the home directories of other (non-root) users
-&gt; is being interpreted as an option that grep should interpret for its own use due to the leading -
use pgrep like this:  if ! pgrep -u $user top &gt;/dev/null 2&gt;&amp;1; then     exec top fi   explanation:   the pgrep utility exits with a zero exit code if the command can be found running
the code calls a function called clone_file if the reflink option is set to “always” or “auto”, and falls back to copying if reflink is “always” (and goes directly to copying if reflink is off)
note: edited after @stephanechazelas comment  the first number of the ls -l output after the permission block is the number of hard links.  it is the same value as the one returned by the stat command in "links".     this number is the hardlink count of the file, when referring to   a file, or the number of contained directory entries, when referring   to a directory.   a file typically has a hard link count of 1 but this changes if hard links are made with the ln command
harry,  i would try this first:  rpm -ivh http://download1.rpmfusion.org/free/fedora/releases/12/everything/i386/os/rpmfusion-free-release-12-1.noarch.rpm  that's the only installer for fedora 12 i see on the rpmfusion page.  then try to install vlc if the install of the repo worked
yes! this is a big deal, and incredibly common
actually dialog provides the ability to navigate around the file system, going up to parent directories or down to subdirectories
try  sync; echo 1 &gt; /proc/sys/vm/drop_caches. 
the closest equivalent to a human-readable (and human-chosen) name for a computer running linux is the default hostname stored in /etc/hostname
nixos supports upgrade rollbacks, although as i understand it, it doesn't go quite as far as you'd like: if you upgrade a, b and c in one operation, you can roll that entire operation back, but not just a and b
the simplest way i can think of is simply creating a new user partyuser, and assigning it read permissions to a 'public' music directory
you can indent the region, to do this for the whole buffer:   mark whole buffer with c-x h (or m-x mark-whole-buffer) run indent region with c-m-\ (or m-x indent-region)  
you can change your code a bit:  is_xyz_node() {   host="$1"   for xyznode in $xzy_nodes; do     if [ -n "$xyznode" ] &amp;&amp;        [ "$host" = "$xyznode" ]; then       return 0     fi   done   return 1 }  if is_xyz_node "$1"; then   printf '%s is a xyz node\n' "$1" else   printf '%s is not a xyz node\n' "$1" fi   there are some things to note:   return in bash requires an integer type in its optional argument; it causes the function to exit with that integer as its status or with the value of $? if it is not provided
these are so-called core dumps
to end up a match block with openssh 6.5p1 or above, use the line: match all  here is a piece of code, taken from my /etc/ssh/sshd_config file:  # change to no to disable tunnelled clear text passwords passwordauthentication no  match host 192.168.1.12     passwordauthentication yes match all  x11forwarding yes x11displayoffset 10   a line with a sole match won't work
shell variable $3 is undefined
if you're not worried about the timing of data passing from foo to bar, and you're okay with a tempfile which will need to be handled in your clean target, then simply:  rcheck:         foo | tee sometempfile         -bar &lt; sometempfile &gt;/dev/null 2&gt;/dev/null   if on the other hand you care a lot about timing then you could make bar repeat its input to stdout and try something like:  rcheck:         -(foo; echo $$? &gt; sometempfile) | bar         exit $(cat sometempfile)   i'm sure there'll be cleaner ways, but the above came to mind
this should do it:  join -j 2 -o 1.1,1.2,1.3,2.3 file1 file2   important: this assumes your files are sorted (as in your example) according to the snp name
i think you have to add:  my $q = cgi-&gt;new(); my $username = $q-&gt;param('username'); ...   so the whole should look like:  #!/usr/bin/perl -wt use strict; use warnings; use cgi;  my $q = cgi-&gt;new(); my $username = $q-&gt;param('username');  print $q-&gt;header(); print $q-&gt;start_html("perl page"); print $q-&gt;h2("hello, $username!\n"); print $q-&gt;end_html;   more info you can here. also in your file you are missing "/":  #!usr/bin/perl -wt   i think should be:  #!/usr/bin/perl -wt  
that's easy
assuming none of your files have spaces:  for i in *k120*; do     mv -- "$i" "$i.dat" done  
try using single quotes.  echo -e '#!/bin/bash \n /usr/bin/command args'  &gt; .scripts/command  echo '#!'  echo '#!/bin/bash'   the problem is occurring because bash is searching its history for !/bin/bash
take away group and other's write permissions on the files, but give them write permissions on the directories so that everyone can delete files
add this line to .bashrc:  export prompt_command="history -a; history -n"   open new termial and check.  explanation   history -a append new history lines to history file. history -n tell bash to read lines that is not read from history file to current history list of session. prompt_command: contents of this variable is run as regular command before bash show prompt
while brace expansion like {1,2} originates in csh in the late 70s, and found its way to bourne-like shells in ksh in the late 80s, the {n1..n2} variant came a lot later first in zsh in 1995 (2.6-beta4).  bash copied it in 2004 (3.0) and ksh93 in 2005 (ksh93r).  probably the shell you're trying this in is neither of those or is an older version of bash and ksh93. 
the only way to do this that i know of would be to write a new filesystem, probably at the user-level using fuse or similar
you can use -i to define a place-holder which will be replaced with each value of the arguments fed to xargs
not at all
yes, you can
the s/// command expects the "search" parameter to be a regular expression
just use sed p.  echo foobar | sed p   you don't need cat, either:  sed p input.txt # or sed p input.txt &gt; output.txt     explanation  p is the sed command for "print."  print is also sed's default action
re: "brute-forcing my server":  you can take a look at what sshd is logging, usually somewhere below /var/log
i tested this on linux mint 17.2 'rafaela' cinnamon 62-bit.   install the package ibus-m17n  select keyboard input methods from the startmenu or which starts ibus-setup
from the page at http://www.go-mono.com/mono-downloads/download.html, it seems like they used to have downloads for other distros for 2.10.x, under "other", however it is stated that they are supported by their own communities
this means that you don't have a red hat subscription and are unable to get updates from red hat without one.  see this answer on serverfault for more details.  if this is a licensed version of red hat, then this information on the red hat website shows you how to register your subscription.  if this is a new server installation you may want to consider switching to centos, which is the community supported version of red hat enterprise linux, or fedora server. 
the shebang line is very limited
at least in debian and ubuntu, you can install the trash-cli package
with brace expansion.  mkdir gallery{1..50}  
yes, there is a kernel facility: the audit subsystem
linux systems programming  you can refer this also link 
color output for ls is typically enabled through an alias in most distros nowadays.  $ alias ls alias ls='ls --color=auto'   you can always disable an alias temporarily by prefixing it with a backslash.  $ \ls   doing the above will short circuit the alias just for this one invocation
you are searching for at (at@wikipedia)?  usr@srv % at now + 15 min at&gt; your command here   you can define multiple commands that should be executed in 15 min, seperate them with a return. confirm all commands with control+d. 
well, you probably don't need to unmount /proc
i assume wpa_supplicant and iw is installed .  1) to connect to wifi through wpa_supplicant you need to create a wpa_supplicant.conf file   nano /etc/wpa_supplicant.conf   with the following lines:  network={          ssid="wifi_name"          psk="wifi_key" }   or you can use wpa_passphrase to create the configuration file:  wpa_passphrase your_ssid your_passwd    to connect type the following command:  ip link set wlan0 down ip link set wlan0 up wpa_supplicant -b -iwlan0 -c/etc/wpa_supplicant.conf -dwext sudo dhclient wlan0   2) you can connect through nmcli :  nmcli d wifi connect your_ssid password your_psswd_here iface your_interface   example:  nmcli d wifi connect myssid password 12345678 iface wlan0   3)also you can connect through wpa_cli   open the terminal and type wpa_cli  to scan type:  scan scan_results   create a network:  add_network   this will output a number, which is the network id , for example 0 next, we need to set the ssid and psk for the network.  set_network 0 ssid "ssid_here" set_network 0 psk "passphrase_here"   once the wireless has connected, it should automatically get an ip address. if it doesn’t you can run the dhclient  to  get an ip address via dhcp 
press: ctrl+alt+f1  then login and restart your gdm, kdm , or so on
single square brackets in the shell is a synonym for test (either the separate command or the shell built-in), so [ 0 ] means the same thing as test 0
no
to answer the second part of your question
centos is a repackaging of red hat enterprise linux (rhel)
you may be looking for rtcwake, which (at least on debian) comes in package util-linux and makes use of your computer's real-time clock alarm
from man awesome there doesn't seem to be a default key binding to close all windows of an application
the argument to the package manipulation command is a regular expression, not a shell wildcard pattern
the time to resolve your request will only be incurred doing the dns query to the dyndns dns servers
  if which node &gt; /dev/null     then         # add deb.nodesource repo commands          # install node     else         echo "node is installed, skipping..."     fi  
it's as simple as a=0"$a" which precedes the content of $a with a '0'. 
the sftp server is indeed trying to stat() the file before removing it
if i understand your question this articled sounds like what you're looking for
if you're sure that the fields between the commas do not contain any whitespaces than you could do something like this:  for job in $(echo $all_jobs | tr "," " "); do     sendevent -verbose -s nyt -e job_off_hold -j "$job" --owner me done   if you need something more robust, take a look at the tools needed to deal with csv files under unix. 
after looking into /etc/profile
dmenu doesn't have built in logging, but it is a very simple program and it is not difficult to have it log it's output to a file.  first, determine where pacman has placed the dmenu files with pacman -ql dmenu
to control running services with systemd, use the systemctl utility
it's not possible to switch to an arbitrary user / group without superuser access
there are always a potential risks
you can export the calendar data from thunderbird in ical format
enlarge the partition: fdisk -u /dev/sda.  p to print the partition table, take note of the number, start, end, type of sda1.  delete it: d:  recreate it with same number (1), start and type but with a bigger end (taking care not to overlap with other partitions)
when you press tab in your terminal with no other arguments, you're completing entries from your path, not the current directory
the values are given in khz (see the documentation)
i don't know if you'll ever find a precise definition that everyone agrees on
the only way i know to remount / (root) partition is to restart the computer
qemu's -kernel, -boot, and -initrd are bios only
you can do it with command line version of put:  :put z   the full syntax is :[line]pu[t] [x]
you have several problems:   you print a square of j, not j power of 2;  there is no power of two that is equal to zero;  you need to print a space to separate figures; the initial value in loops should be not 1, but 0 to print 2**0 for completeness   thus  for (( i=0; i&lt;=5; i++ )) do     for (( j=0; j&lt;=i;  j++ ))     do      echo -n "$((2 ** j)) "     done     echo "" done   produces  1  1 2  1 2 4  1 2 4 8  1 2 4 8 16  1 2 4 8 16 32  
debian is built from scratch in the sense that each package maintainer builds his package from the source, so that you don't have to
when u-boot executes the boot command, it provides a memory address for the kernel and a memory address for the device tree blob
when you run:  ping -q -c 1 google.com &gt; /dev/null &amp;&amp; echo online || echo offline   you are essentially only redirecting the output of stream 1 (i.e
you can use rsync to achieve what you want.  rsync -r --delete-during /backup/location/ /production/directory   for more on see man rsync 
nix expressions  a nix expression is like any programming language expression: anything that evaluates to a value or a function
cd is a shell builtin, and sudo only works with programs
run 
i believe what you're looking for is steganography, a way to hide a message in otherwise innocent-looking content.  there doesn't seem to be a wealth of tools out there for this on linux, but outguess1 and steghide2 would do what you want
as of now, your question is "how do i extract from string '-ip ' to next space?"
it's rather easier with zsh
using awk  awk implicitly loops through lines and separates each line into fields:  $ awk '{printf "some text before %s %s\n",$2,$3}' file.out some text before 100500 1446043920 some text before 100501 1446043921 some text before 100502 1446043922 some text before 100503 1446043923   if we know that the input file will always only have three columns, then this command can be shortened to (hat tip: don crissti):  $ awk '{$1="some text before"} 1' file.out   using shell  lines can be broken into fields using the shell's read statement:  $ while read a b c d; do echo "some text before $b $c" ; done &lt;file.out some text before 100500 1446043920 some text before 100501 1446043921 some text before 100502 1446043922 some text before 100503 1446043923  
why shc?  first of all, why are you using shc, given your "hobbyist" motivations? here is an excerpt from their own description:     upon execution, the compiled binary will decrypt and execute the code with the shell -c option
in order to cross compile, you must have (or build) a cross-compiler; gcc cannot, by default, just build for any target that it could be configured for
set   ./file[123]            ### set an arg array of the glob resolution while [ "${2+:}" ]           ### while there are at least 2 args do    [ "$1" -nt "$2" ] &amp;&amp;   ### if $1 is newer than $2 then ...       set "$@" "$1"; shift   ### reset the array to itself + $1; shift regardless done; cat &lt;"$1"              ### after loop cat $1 or report no glob match  
as you know, the difference is due to the different umask values
by default rsync compares files by size and timestamp, but a device does not have a size so it must calculate differences using the delta algorithm which is described in this tech report.  loosely, the remote file is divided into blocks of a chosen size, and the checksums of these are sent back
to prevent python from writing ~/.python_history, disable the hook that activates this functionality:  import sys # disable history (...but also auto-completion :/ ) if hasattr(sys, '__interactivehook__'):     del sys.__interactivehook__   if you would like to enable tab-completion and disable the history feature, you can adapt the site.enablerlcompleter code
awk substitution capabilities are quite limited
pax can do this all at once
you can usually query your distribution to see where sources come from
thanks to sr_, i used driftnet:  sudo driftnet -i eth0 -a -d ./browserpic  
in these cases you can check the return value of cpp directly:  have_ubsan=$(cpp -dm -fsanitize=undefined &lt; /dev/null &gt; /dev/null 2&gt;&amp;1 &amp;&amp; echo 1) if [ "$have_ubsan" = 1 ] 
i had posted this question to the ti forums as well, and got a response.  enabling config_netfilter_xt_match_conntrack in the kernel config solved this issue. i just set config_netfilter_xt_match_conntrack=y in the config, rebuilt with the sdk (instructions here).  after installing the new kernel and modules, the -m conntrack command doesn't complain anymore. 
you can
the original dhcp specification (rfc 2131 and 2132) defines an option (33) that allows the administrator of the dhcp service to issue static routes to the client if needed.  unfortunately, that original design is flawed these days as it assumes classful network addresses, which is rarely used.  the rfc3442-classless-static-routes option allows you to use classless network addresses (or cidr) instead.  cidr requires a subnet mask to be explicitly stated, but the original dhcp option 33 doesn't have space for this
the standard openssh implementation of ssh has a line, in /etc/ssh/sshd_config which states:  authorizedkeysfile     %h/.ssh/authorized_keys   which may have been modified in your case
the process will depend on what type of files you have (image, text file, etc.) and what file system is in use
as root, type in a shell:  # cfdisk /dev/sdx  #where /dev/sdx is the device    it will show you something like this:  cfdisk (util-linux-ng 2.18)                            disk drive: /dev/sdb                     size: 3926949888 bytes, 3926 mb           heads: 255   sectors per track: 63   cylinders: 477  name        flags      part type  fs type          [label]        size (mb)     sdb1                    primary   vfat             [abdel]          1998.75 sdb2        boot        primary   ext3             [linx]           1924.72   if the device has free space it will be shown.  note: cfdisk in fact is a terminal based partition editor. 
if all you want is elapsed time, then with zsh or ksh93:  $ typeset -f seconds=0; sleep 1; print "$seconds" 1.0012850761   now, whether that kind of precision makes sense is another matter. 
with gnu awk 4.1.3 in bash on cygwin:  $ cat tst.sh #!/bin/awk -f begin { print "executing:", environ["_"] }  $ ./tst.sh executing: ./tst.sh   idk how portable that is
you need to update your copy of winetricks, this issue has been fixed. 
change its execute permission bits
sure there is,  wrapped_function "${@#prefix}"   the $@ represents the collection of all parameters $1, $2, ..
you want to use screen on the remote and then when you ssh back in you reconnect to that instance of screen.  but no you can't reconnect to an ssh session in and of itself, you have to use screen (or something else like it to facilitate that).  look at this question for at least one other option and some differences between it (tmux) and screen
the problem is unrelated to the public key authentication you have set up
$ grep -oe '".*"' demo.txt | grep -oe '\w+' | sort -u 02 05 06 0698 07 abc    -o print  only  the matched (non-empty) parts of a matching line, with each such part on a separate output line -e interpret pattern as an extended regular expression ".*" gets all values within quotes \w+ 1 or more of letters/digits/underscore characters sort -u to get unique values  
in the case where the user entered "y", you can exit both while and case:  break [n]        exit from within a for, while, until, or select loop
you could use \ before the character ? so it is consider as a normal character in the name of the file and not a special character to be interpreted.  the command would then be:  mv giko\ suzo\ san\?e\ -\ ep1.avi 'giko suzo sane - ep1.avi'   edit: following discussion in comments, this line did the trick:  mv giko\ suzo\ sa*\ -\ ep1.avi 'giko suzo sane - ep1.avi'  
   but how do i find out what commands are provided by a certain package?   there is nothing as "commands" in linux
if you need to rename files in subdirectories as well, then you can do  find /search/path -depth -name '* *' \     -execdir bash -c 'mv "$1" "${1// /_}"' _ {} \;   thank to @glenn jackman for suggesting -depth option for find and to make me think. 
os x can do this now, as of snow leopard
the difference is exactly that you wrote
linux is not windows and thus "patches" are actually totally re-compiled/re-loaded from the base code after source code modifications and distributed as a package
what i think is a better answer is to download the longtail ssh honeypot which is a hacked version of openssh to log username, password, source ip and port, and client software and version.  the install script is at https://github.com/wedaa/longtail-log-analysis/blob/master/install_openssh.sh  i also do analytics at http://longtail.it.marist.edu                 ericw          
here's one take on the issue with awk:  awk '   /&lt;machine.*name=/ { f=1 ; m=0 ; res="" }   f { res = res $0 ors }   f &amp;&amp; /pattern/ { m=1 }   /&lt;\/machine&gt;/ { f=0 ; if (m) print res $0 } ' your_xml_file   it's implementing a fsa
first of all, you need to end the -exec action with {} \;.  second, awk do not modify the file in place as sed do (with the -i option), so you should send the output to a temporary file, then move this to the original file.  create a script (say we call it replace) with the following content:  #!/bin/sh tfile=$(mktemp) awk '/&lt;!-- startreplace1 --&gt;/{p=1;print;print "a whole new world!"}       /&lt;!-- endreplace1 --&gt;/  {p=0}' "$1" &gt;"$tfile" &amp;&amp; \   mv "$tfile" "$1"   give it executable permissions  chmod +x ./replace   then run  find "$dir" -type f -iname '*.html' -exec ./replace {} \;  
edit or create (if not present) /etc/screenrc and add below code      autodetach on    startup_message off    hardstatus alwayslastline    shelltitle 'bash'      hardstatus string '%{gk}[%{wk}%?%-lw%?%{=b kr}(%{w}%n*%f   %t%?(%u)%?%{=b kr})%{= w}%?%+lw%?%? %{g}][%{d}%l%{g}][ %{= w}%y/%m/%d   %0c:%s%a%{g} ]%{w}'   shelltitle 'bash' can be changed once the screen is created
as stated by jpkotta, network-manager is likely the culprit.  you can see its status by running ps -aux | grep network-manager | grep &lt;username&gt;
you can use two files:  if [ -e checkfile ]; then   lines=$(wc -l &lt;checkfile) else   lines=0 fi # read all new lines from source file and append them to target file sed -n $((lines+1)),\$p file &gt;&gt;checkfile awk '...' checkfile  
in addition to stephane's answer i'd like to point out that there is ftps, too
this should be default behavior, so you may be doing something at user creation that is causing the prompt to happen
this should do the work:  #!/bin/bash  ezstream -c $1 &gt;log.txt 2&gt;error.txt &amp;  ezpid=$! echo $ezpid sleep 2 if ps | grep $ezpid ; then     echo ezsteam is still running!     cat log.txt     exit 0 else     echo ezstream is dead     cat error.txt     exit 1 fi  
if you change the mountpoint name all your symlinks will break
here are some points you could start with:   have a look at the packages installed on your system with pacman -q and remove the ones you don't need
i've found a reasonable working solution which allows both audio and video to be processed in a (normal) single pass of the avisynth script..
it doesn't sound like 'bridging' is what you're looking for, it sounds like you want your pi to act as an access point and share the internet it sees on wlan0 via a new ssid on wlan1.  see this guide for details on how to set that up:   http://www.maketecheasier.com/set-up-raspberry-pi-as-wireless-access-point/ 
i agree with ulrich, that this doesn't sound like an ipv6 problem
agreeing with the comment by @meuh, terminals don't generate a distinct code for control; (normally).  the link suggested by @tijagi is for xterm and does not apply to urxvt
you can sort it numerically on the [ delimiter:  sort -t\[ -nk2,2 &lt;&lt;\in int array[0] int array[1001] int array[1002] int array[1003] int array[2] int array[2001] int array[2002] in    output  int array[0] int array[2] int array[1001] int array[1002] int array[1003] int array[2001] int array[2002]  
i do not believe this is possible
just, eg:  git clone http://evilpiepirate.org/git/linux-bcache.git   this creates and populates a directory
that su is why it fails, that launches an interactive shell
linux-image-amd64 is a generic metapackage, which depends on the specific default kernel package
   regex(3)       name    regcomp, regexec, regerror, regfree - posix regex functions   works fine here on arch linux and also on the internet...  you might need to (re)install them:  sudo apt-get install manpages manpages-dev manpages-posix manpages-posix-dev 
you'll want to use uuids to identify the disks and boot via that.  run blkid on your machine to get a list of drives and their uuids.  then modify your lilo.conf and use root=uuid=&lt;disk uuid&gt; rather than root=/dev/sda etc.  assumes you have a kernel version that supports uuids - check first by looking in /dev/disk/by-uuid
for the first one:  ndd -set /dev/tcp tcp_time_wait_interval 90000   as per the oficial manualyou should not set this under 60000 = 60 seconds.  for the second one  ndd -get /dev/tcp tcp_smallest_anon_port tcp_largest_anon_port   no need to restart the network
write a udev rule which first mounts the usb-drive and second runs my-script  # cat /etc/udev/rules.d/11-media-by-label-with-pmount.rules  kernel!="sd[a-z]*", goto="media_by_label_auto_mount_end" action=="add", program!="/sbin/blkid %n", goto="media_by_label_auto_mount_end"  # get label program=="/sbin/blkid -o value -s label %n", env{dir_name}="%c"  # use basename to correctly handle labels such as ../mnt/foo program=="/usr/bin/basename '%e{dir_name}'", env{dir_name}="%c" env{dir_name}=="", env{dir_name}="usbhd-%k"  action=="add", env{dir_name}!="", run+="/bin/su yourusername -c '/usr/bin/pmount %n %e{dir_name}'", run+="/etc/udev/scripts/my-script.sh" action=="remove", env{dir_name}!="", run+="/bin/su yourusername -c '/usr/bin/pumount /media/%e{dir_name}'" label="media_by_label_auto_mount_end"   note: the drive is mounted by root but can be unmounted by the given user
an older version (0.6.4?) was ported to netbsd and many or all of the changes were taken upstream, but the netbsd porter didn't seem to continue it
i'd not offer to use eval if there are many other ways to do the task  red='\\033[0;31m' nc='\\033[0m' # no color echo -e "$(sed "s=[^/]\+$=${red}&amp;${nc}=" &lt;&lt;&lt;$var)"   due to use \ inside sed you should escape escape character - \\ or use esc by itself to press ctrl + v followed esc 
you can just use debian's column
the docs packages contains the documentation set for the related package
what you probably is want is pipestatus (from man bash:)  an array variable (see arrays below) containing a list of exit status  values from the processes in the most-recently-executed foreground pipeline  (which may contain only a single command).  
just try do append / to the directory name just as:  unzip -oq vqmodmanager.zip upload/ -d temp/  
you must first fix the dependency problem, before upgrading
define this function (say, in your .bashrc):  function permalias {     alias "$@"   # set the alias(es) in this session     printf 'alias %q\n' "$@" &gt;&gt; ~/.bash_aliases  # set it for all sessions }   then use it the same way you would make a normal alias:  % permalias foo='/path/to/command -some --options=here'   note: this isn't the most robust solution in the universe
the following works:  sed -i 's/\(&lt;[^0-9&gt;]*\)[0-9]*\([^0-9]*&gt;\)/\1\2/g' filename  
there is no specific command that may stop the file to be mounted several times with different mountpoints, but you may use this script to not mount it if it is already mounted:  #!/bin/bash mount |grep -qf "$1" || mount "$1" $2 -o loop   the first parameter is a file to mount, and second is a mount point to use. 
you can use lkml.org to search through the archive
this is mostly a comment but could become an answer
man xdotool says it can get/set the viewport:     get_desktop_viewport [--shell]        report the current viewport's position
gilles is exactly right, ls is a really bad example because file name glob expansion can be done much easier on the command line without having to use ls at all! if your so called "text files" have file name extensions to identify them, you could do something like this:  editor-command *.txt   for the sake of demonstrating a technique, lets use a more complicated example that could not be done with just a filename match and open files based on the content instead of just the file name
try single quotes:  wget 'http://xxxx/sankarea - 6 - it`s because i..
if you have vixie cron installed, you can add a @reboot entry in your crontab file:   instead of the first five fields, one  of  eight  special  strings  may appear:         string         meaning        ------         -------        @reboot        run once, at startup.   there you can take some action (i.e
normally you would alt-f2 to run gnome-session-properties, and select "automatically remember running applications when logging out" under the options tab.  however, it is broken at the moment
i think i found it.  contrary to what i first thought, the sd card is mounted at boot by udev, not by systemd
i asked a similar question once
i found a discussion on serverfault that discusses this
echo print newline (\n) at end of line  echo abcd | xxd 0000000: 6162 6364 0a          abcd.   with some echo implementations, you can use -n :     -n do not output the trailing newline   and test:  echo -n abcd | wc -c 4   with some others, you need the \c escape sequence:     \c:  suppress the &lt;newline&gt; that otherwise follows the final argument in the output
you can try using apachetop. it shows out output like this:   
&gt; logfile   or  cat /dev/null &gt; logfile   if you want to be more eloquent, will empty logfile (actually they will truncate it to zero size)
most importantly, you can't have an lv spanning two different vgs.  also, there's no tool to move a logical volume to a different volume group
-l, --listfiles   dpkg -l package-name  
the command you ran created a symbolic link in the current directory
i think this wiki page is what you are looking for. 
you don't have to.  kdir := /lib/modules/$(shell uname -r)/build   presumes you are building a module for the currently running kernel, since it uses $(shell uname -r) to complete the path
as you want to authenticate without prior key exchange, i see no other option than using password authentication (at least the first time).  so you need to hard-code the password in your script
l is probably a shell alias
this problem was posted as a bug almost 10 years ago
you can use chpasswd     the chpasswd command administers users' passwords
i found 2 ways of doing this
the only point of entry for filesystem interactions is the mechanism of system calls, which, in turn, relies heavily (if not exclusively) on vfs.  if someone wanted to create a filesystem that is not relying on vfs, that person would be forced to implement a new set of i/o system calls which would directly interact with the linux block level.  this is neither elegant nor portable
you can use multiple scripts:  sed -e '/^\./d' -e '/^&gt;/d' &lt;file   or using characters class:  sed -e '/^[.&gt;]/d' &lt;file  
only root privileged programs can gracefully shutdown a system
thanks for the answers.  after googling around, i found resty, which is a shell script wrapper around the curl tool
first of all, hitting tab in bash is even better since it autocompletes all executables in your path irrespecitve of whether they're in the history
ǝʃƃoo⅁ ɹɐǝ◖  while i'm not aware of anything that fits your description, you could have a look at the mozilla project's "chromeless":     instead building a whole new platform, we suggest that the web itself should be the platform
the current solution is as follows:  bind -p | grep -ve '^$' -e '^#' -e 'self-insert$' | sed -e "s/\(.*\)/bind '\1'/" | tr -s '\n' ';'   this produces a single line like this:  bind '"\c-g": abort';bind '"\c-x\c-g": abort';[...];bind '"\e\c-y": yank-nth-arg';bind '"\ey": yank-pop';   this seems to work, but i'm not sure if it's portable. 
there are a few ways.  the modern way: use ip.  ip -s link   the output is pretty self-explanatory.  the old way: use ifconfig.  ifconfig -a   also self-explanatory, but not as trivial to parse.  the /proc way:  cat /proc/net/dev   look at the proc(5) man page for more information (there really isn't much)
journal logs  yes you can delete everything inside of /var/log/journal/* but do not delete the directory itself
there is no issue with the \n
you can enable ksh-style extended globbing with:  shopt -s extglob   and then write something-!(*-foobar).txt 
the structure of awk execution is: pattern { action statements }     actions   &emsp;&emsp;&emsp;&emsp;action statements are enclosed in braces, { and }
this is a known bug in bash; see the man page and search for "bugs":   bugs        it's too big and too slow.    ;)    for an excellent primer on the conceptual differences between shell scripting and other programming languages, i highly recommend reading:   why is using a shell loop to process text considered bad practice?   the most pertinent excerpts:     shells are a higher level language
you can reboot the computer with a terminal command, but you can't give it a terminal command that tells it what device to reboot into
well...all you have to do is basically to chmod your file to have executable permissions
~ is your home directory, usually /home/username
it could be a missing dependency
this below is the entry point to a multi-input script.  #!/bin/bash [ $# -ge 1 -a -f "$1" ] &amp;&amp; input="$1" || input="-"  # your script's payload here   the #! line is self explanatory i hope  on the second line   $# -ge 1 and is testing for at least one command line argument    -a  is the boolean and operator  -f "$1" is testing if the first argument is a file  &amp;&amp; is followed by the directive to be executed if the previous condition holds true  || is followed by what happens if the test condition is not true  nc -k -l 127.0.0.1 4444 &gt; filename.out my_processing_script filename.out   -or-  nc -k -l 127.0.0.1 4444 | my_processing_script   so, if i have an argument and it is a file, my input is this file, if not, my input is coming from the pipe, i.e
nslookup is a bit of a deprecated command, in favour of the dig command by the isc.  with dig, you would write it:  dig -x 127.0.0.1 +short   alternatively, you could do:  perl -msocket -le 'print((gethostbyaddr(inet_aton("127.0.0.1"), af_inet))[0])'   which would use the system's resolver to get you the info (which in turn might use /etc/hosts, dns, nis+, ldap..
if i understand correctly you'd like to change your user name.  usermod -l thenameiwanttochange -d /home/thenameiwanttochange -m currentname   usermod : modify an account -l : change the name -d : chnage the location (name) of the home directory -m : move the contents of the current home dir to the new one    e.g
hello googler from the future! i have found a fix with the help of this post , hopefully it will work for you:   open up your system settings then go to languages → input methods. on the dropdown menu in the "input method" section select "ibus"
to add eric's answer (don't have rep to comment), permissions are not stored in file but file's inode (filesystem's pointer to the file's physical location on disk) as metadata along with owner and timestamps
all you can do is set targetpw as default, but this won't require root to enter any password
to begin with, note that argv[0] is not necessarily the program name
every element combination of a rgb, if you want to retrieve a rgb of red , blue or another color, you can open gimp, and choose color and retrieve the given  rgb. 
i can't say that my own 19 year experience of running linux supports your assertion that windows boots more stably, but here are some things that will effect what you are seeing:   filesystem caching  linux uses caching on all filesystems unless told otherwise
ub=1000 # replace this with the largest existing file's number. seq "$ub" | while read -r i; do     [[ -f "$i.txt" ]] || echo "$i.txt is missing" done   you can easily find the proper value for ub by doing ls | sort -n or similar
you are pretty close
add -q to the command you use to run ssh, from the man page:  -q      quiet mode
you need to associate a loopback device with the file:  sudo losetup /dev/loop0 /home/user/harddriveimg   then run gparted on that. 
after much testing, i found out that having a default drop policy is not enough,  *filter -f -x :input drop [0:0]   it is very important not to assume that it would be followed
two pieces to this answer (actually, networking is trivial in *nix)
to use specific subkeys, and not have gnupg to resolve the subkey to a primary key, attach ! to the key
make sure you have a usb kernel module loaded using kldload or compile the module into the kernel using the kernel config script in /usr/src/sys/&lt;type&gt;/conf
you can actually do this using tramp:     tramp stands for `transparent remote (file) access, multiple protocol'
when using the rsync daemon, the first part of the path is not considered a folder, but more of a repository
you can use ctrl+j or ctrl+m as an alternative to enter
pidof command returns the pid and introduced by a given process name.  according entiend, you want to get a list of pids separated by commas, corresponding to potential pids as a process name
from file linux/include/trace/events/regmap.h, you can see:  195 define_event(regmap_block, regmap_async_write_start,                             196                                                                                  197     tp_proto(struct device *dev, unsigned int reg, int count),                   198                                                                                  199     tp_args(dev, reg, count)                                                     200 );   according to this, it seem that it add tracepoints when we start async i/o. 
not sure about gnome/xfce specific options, but [xbindkeys] (https://wiki.archlinux.org/index.php/xbindkeys) can do this
it does not answer the question in your title, but maybe there's a chance to fix the files without reencoding
as far as i know, there is no way of making bash autocomplete *pictu, but here are some workarounds:   don't use tab, just cd directly using wildcards before and after the pattern:  $ cd *pictu*   that will move you into the first directory whose name contains pictu. use two wildcards and then tab:  $ cd *pictu*&lt;tab&gt;   that should expand to cd 1122337\ pictures\ of\ kittens/ use another shell
looks like qdaemon is spamming messages
   from my linux workstation, the only application that can access the   internet are a) firefox (using its own proxy configuration and   authentication stored in firefox), as well as applications running in   a windows vm (note - the windows vm is a domain member and the user   authenticates against the domain when logging in)   solution option: run a web proxy on your windows vm
assuming the package has already been installed you can see the contents of it using dpkg -l, for list.  example  $ dpkg -l lzma-dev /. /usr /usr/include /usr/include/lzma /usr/include/lzma/lzhash.h /usr/include/lzma/types.h /usr/include/lzma/lzmaenc.h /usr/include/lzma/lzfind.c /usr/include/lzma/lzmaenc.c /usr/include/lzma/lzfind.h /usr/include/lzma/lzmadec.h /usr/include/lzma/7zversion.h /usr/include/lzma/lzmadec.c /usr/share /usr/share/doc /usr/share/doc/lzma-dev /usr/share/doc/lzma-dev/lzma.txt.gz /usr/share/doc/lzma-dev/methods.txt /usr/share/doc/lzma-dev/7zc.txt.gz /usr/share/doc/lzma-dev/changelog.debian.gz /usr/share/doc/lzma-dev/7zformat.txt.gz /usr/share/doc/lzma-dev/copyright   packages that are named &lt;something&gt;-dev are typically just the c header files (.h files), this package is a bit unusual in that it includes (.c and .h files)
if you want only to compare lists of file- and directory-names, the -d option is not helpful
i want to add that i have the effect decreased right after i have kernel which supports my processor series (baytrail); so probably the effect is really depends on kernel version; p.s
you can easily grep these files by providing the -a option to interpret the files as ascii:  grep -a "author" *.epub *.mobi   the above works on all of my 1000+ epub and mobi files, giving the expected results.  epub and mobi are both container formats
directfb might be what you are looking for
try service tightvncserver start (as root) in the running system, it may give you some hints
what i would do is to redirect the output of wvdial to a file, and separately print out “interesting” lines from the file as they appear.  wvdial &gt;wvdial.log 2&gt;&amp;1   here's one way to filter the file
the program you are looking for is /usr/bin/sol, part of package aisleriot
the 'pts' unit used by pdfinfo denotes a postscript point
these different segfaults are more likely an indication of something wrong with memory or with your disc connection than with corruption of the filesystem
since this got no response i asked this question and got an answer on stack overflow from michaelmichael.     make sure you've updated rvm with the rvm update command
do following  vim /home/&lt;username&gt;/.gconf/apps/panel/toplevels/bottom_panel/%gconf.xml   or  vim /home/&lt;username&gt;/.gconf/apps/panel/toplevels/top_panel/%gconf.xml   if you renamed your panel, change top_panel or bottom_panel accordingly.  look for orientation section  &lt;entry name="orientation" mtime="1356417211" type="string"&gt;     &lt;stringvalue&gt;bottom&lt;/stringvalue&gt; &lt;/entry&gt;   change bottom to top, left or right. 
the normal way to do this is to let your program exit, and use a monitoring system to restart it
this should work.      for fname in conv2015_10_logicalcomponent_cosprofile.csv        do        cat $fname | sed 's/.$//' &gt; tmp.tmp        mv tmp.tmp $fname     done   another option is if you use gnu sed "-i" option:  then you only need to do this:  sed -i 's/.$//' filename   additionaly to clarify why "." is used there instead of ","
the proper way to do this is to use an alias:  since i wanted to turn some stuff off when gimp starts and on when gimp ends, i would execute  alias gimp="toggle-input off; gimp; toggle-input on"   now, when gimp is executed, it will first execute toggle-input off, then it will run gimp, then after gimp is finished being used it will execute toggle-input on. 
tcl-doc recommends tcl-8.5-doc on wheezy or later and tcl8.4-doc on squeeze which contains the manpages
try something like this:  #! /bin/bash  # config variable(s) parentfolder="~/filingcab"  # arg processing (minimalist :) filetomove="$1"  # use sed to extract folder number from filename. folderno=$(echo "$filetomove" | sed -r -e 's/.*zz([0-9]+)\.pdf/\1/')  # use find to search for subdirectories of parent folder that begin # with the folder no followed by a '.' targetfolder=$(find "$parentfolder" -maxdepth 1 -type -a -d -name "${folderno}.*")  numfolders=$(echo "$targetfolder" | wc -l)  if [ "$numfolders" -eq 1 ] ; then   mv "$parentfolder/$filetomove" "$targetfolder/"  else   echo "error: $numfolders beginning with "$folderno." found" &gt;&amp;2   exit 1 fi   note the double-quotes around all the variable names
you can use -exec option:  find -regex '.*.(com\|org\|net\|biz\|info)' -mmin -1 \     -exec tail -n 1000 "{}" &gt;&gt; logs.txt +   now all last 1000 lines of each files in domlogs is written to file logs.txt, separated by filename.  -exec command {} + tells find to run command with files found, the command line is built by appending each filename at the end
i recently came across this problem with selinux on amazon linux with php7
this works (in the .vimrc file) for all files:  autocmd bufwritepre * :%s/\s\+$//e   this works for just ruby(.rb) files:  autocmd bufwritepre *.rb :%s/\s\+$//e  
this is probably a duplicate (i recall it being answered)
using less -x:     disables sending the termcap initialization and deinitialization strings to the terminal.   that will leave any text on-screen behind before and after paging
stephane chazelas wrote:     you can't suspend with ctrl+z, but you can suspend with the suspend builtin (or kill -s stop "$$" if your shell doesn't have such a builtin).   thank you very much, this appears to work like a charm
which licenses portage accepts is governed by the accept_license variable in make.conf
a saner version of @slm's:  find-grep() {   cmd=(find 
in the community repo, there's a package called audio-convert. install it with pacman -s audio-convert and it should do the trick.  remember to also install the optional packages: mplayer (needed for wma support) and vorbis-tools (for ogg). 
with bash:  unset password # make sure it's not exported set +a         # make sure variables are not automatically exported ifs= read -rs password &lt; /dev/tty &amp;&amp;   printf '{"username":"myname","password":"%s"}\n' "$password" | cmd   without ifs=, read would strip leading and trailing blanks from the password you type.  without -r, it would process backslashes as a quoting character.  you want to make sure you only ever read from the terminal.  echo can't be used reliably
yes, segregating root privileges protects you from yourself
you have to add -wl,-r/usr/local/lib to the ldflags when compiling your program.  -r is a linker option (for specifying a runtime linker path) - -wl instructs gcc to pass it to ld.  with shared libraries you have to make sure that they are found by the linker during compile and during runtime (cf
you are asking five questions here, and might be better asking five questions ☺ but i'll jump in:   x is a server and can be compared to a "web server" in that it is a process that listens for incoming connections that speak a particular protocol (the x protocol) and it issues answers
researching the undocumented feature  you're right the ntldr command (it is command, not module) is not documented
looking at the versions reveals the problem:  % gpg-agent --version gpg-agent (gnupg) 2.1.7  % gpg --version                                                                gpg (gnupg) 1.4.19   the components come from different packages (gnupg2-2.1.7-1.fc22.x86_64 and gnupg-1.4.19-2.fc22.x86_64 in my case)
it is largely historic, partly a matter of control from a system administration aspect, partly a portability issue, partly a debugging issue.  "back in the day", there was no autoconf, dpkg, rpm
i haven't done much fuzz testing either, but here's two ideas:  write some zeroes into the middle of the file
the com2sec security model is not mandatory anymore.  in snmpd.conf it should be enough to do:  rocommunity "#randomsometinh$"  2.2.2.2   where 2.2.2.2 is the monitoring ip address allowed to connect. i often prefer to assign a single ip, than giving access to a whole /24
you can use applescript like so:  on run args     set home to (posix path of (path to home folder)) as string     tell application "iterm"         activate         set myterm to (make new terminal)         tell myterm             repeat with i from 1 to 6                 set newtab to (make new session at the end of sessions)                 tell newtab                     set name to "my tab " &amp; i                     exec command "/bin/bash"                     write text "cd " &amp; home &amp; "/desktop/projects/mynodeapp"                 end tell             end repeat         end tell     end tell end run  
sudo has some special options in it's permissions file, one of which allows a restriction on it's usage to shells that are are running inside a tty, which cron is not.  some distros including the amazon linux ami have this enabled by default
su is running with elevated privileges, and you are not seeing it respond to ^c (which sends a signal with your privileges)
assuming you're talking c/c++, use setsockopt() and so_reuseaddr
according to the documentation,  sudo debian-installer-launcher --text   will launch the text-mode installer in a new terminal window. 
the shebang expects a full path to the interpreter to use so the following syntax would be incorrect:  #!python   setting a full path like this might work:  #!/usr/local/bin/python   but would be non portable as python might be installed in /bin, /opt/python/bin, or wherever other location
the linux version of the adobe reader has reached eol
it's not possible in general, because a script can contain something like  read $command "$command" -rf /   in real life, the command would be sanitized or picked from a list, but still, it's not possible to know in advance what commands are possible. 
what controls whether other computers have access to a server running on your computer is not the name: that's a matter of convenience only
using sed:  sed -i.bak -e '/^[0-9]\{1,9\}$/d' file   using perl:  perl -i.bak -nle 'print unless /^[0-9]{1,9}$/' file  
it took me a while to work this out, so i wanted to share it with others
turns out there's a solution found in keychain.  $ ps aux | grep "[f]nord"   by putting the brackets around the letter and quotes around the string you search for the regex, which says, "find the character 'f' followed by 'nord'."  but since you put the brackets in the pattern 'f' is now followed by ']', so grep won't show up in the results list
link used solely for hard links, calls the link() system function and doesn't perform error checking when attempting to create the link  ln has error checking and can create hard and soft links 
what's an array?  arrays are indexed using numbers, they usually start at 0 and go to n-1 the number of elements in an array.   https://en.wikipedia.org/wiki/array_data_type   what's an associative array?  associative arrays are a key value pair, often times called a hash
with any posix shell:  tab=$(printf '\t') # or tab='   ' # (a real tab character) case $outline in   ("#${tab}modified:"*) ... esac   with ksh93, zsh or bash:  case $outline in   ($'#\tmodified:'*) ... esac   or:  if [[ $outline = $'#\tmodified:'* ]]; then...   the key is:   * must not be quoted, otherwise it's taken literally. \t is only expanded in the $'...' type of quote (or by printf in the format argument)  
the plugin name is skypeweb  its github page is https://github.com/eionrobb/skype4pidgin/tree/master/skypeweb  on most linux distributions its compilation and installation should be simple, just follow:  sudo apt-get install libglib2.0-dev libjson-glib-dev libpurple-dev git clone git://github.com/eionrobb/skype4pidgin.git cd skype4pidgin/skypeweb make sudo make install   tested and working with pidgin 2.10.12 and skypeweb plugin 1.1. 
in bash, different commands have different notions of words
if you have an ext3 or ext4 filesystem, then you can use this in the [options] stanza of /etc/e2fsck.conf (see man e2fsck.conf)  [options] allow_cancellation = true defer_check_on_battery = true   the first means     if  the    user  interrupts  e2fsck  using  ^c,  and  the filesystem is not    explicitly flagged as containing errors, e2fsck will  exit  with    an  exit  status  of  0 instead of 32.   so the filesystem is considered mountable after the interrupt.  the second line (which is true by default, so not needed) means      the  interval    between  filesystem  checks  (either  based on time or number of    mounts) should be doubled if the system is running  on  battery.   so, if you have a laptop with battery, unplug the power to avoid a periodic fsck
config.sub is one of files generated by autoconf
the kernel keeps the partition table in cache permanently (unless explicitly told to reload, and that can't be done if some of the partitions are in use)
because jasonwryan hasn't posted an answer that i could check as the right one, i'm aswering my own question with his comment-answer
like every unix program that occasionally has cause to send email notifications, mail assumes that there is a functioning mta on localhost that is 1) capable of accepting mail and 2) knows how to pass it on.  to find out what mail server you're running, try telnet localhost 25 and look at the identifier string.  the command mailq, if it exists for you, will show you what messages are currently in the local mail server's queue, possibly with an explanation as to why it hasn't been passed on to its destination yet.  in addition, most distributions by default configure mtas and syslog to report mail log messages to either /var/log/mail.log or similar
i guess i found my answer, it is indeed added by libcap as a pseudo protocol  linktype_sll header format  wireshark description of sll 
other answers have been given which will work, but in the spirit of helping you do it exactly the way you were trying to (since it's a totally fine way to do it):  here is the original:  printf "function ps_mem {\n python /home/vagrant/ps_mem/ps_mem.py -p $@ \n}" &gt;&gt; ~/.bashrc   here is a version that works:  printf 'function ps_mem {\n python /home/vagrant/ps_mem/ps_mem.py -p $@ \n}' &gt;&gt; ~/.bashrc   i recommend adding double quotes around $@ also:  printf 'function ps_mem {\n python /home/vagrant/ps_mem/ps_mem.py -p "$@" \n}' &gt;&gt; ~/.bashrc   variable expansion is enabled in double quotes; disabled in single quotes. 
success! i managed to get hold of an old pci network card with an intel chip on it that worked with the omv kernel drivers
this question has been answered in this super user question:   what is the purpose of the magic numbers in linux reboot?   basically, a bit flip in an address can cause a program to think it is calling one system call when, in fact, it's calling the reboot() system call
$@ expands to separate words (whereas $* expands to a single word), as explained in the bash manual
killing by process group id is atomic
i'm not the expert in x11 and even linux, but i heard that os x implementation of xorg server doesn't support some required extensions for visually rich ui
as you can see in your ps output, the xvfb server is run with parameter -auth followed by the name of a temporary file
according to flush dnsmasq dns cache:  dnsmasq is a lightweight dns, tftp and dhcp server
well, here you find some information, i don't know if accurate or not, i suspect not too much.  anyway, each major linux distribution has almost everything one can ever need
$term is read and interpreted by the terminfo system
as jasonwryan notes this is not generally a wise approach, but simply pacman -s &lt;pkg name&gt; will install the latest version and anything that it depends on, though i'm not sure what your meaning:      without uninstalling it   are you attempting to keep multiple versions of the same package? if so, then no i do not think archlinux will support this ootb
in general, ./configure &amp;&amp; make &amp;&amp; make install without any parameters sticks everything under /usr/local, which would place foo.pc in /usr/local/lib/pkgconfig/foo.pc  to make use of this, you'd need to do basically pkg_config_path=/usr/local/lib/pkgconfig:${pkg_config_path} pkg-config --cflags foo, or, compile in this manner:  ./configure --prefix=/usr #places built binaries under /usr instead of /usr/local make make install   now the foo.pc file will be where its expected.  note: this places stuff in system folders, so realize you can overwrite important things if you're not careful.  and to answer regarding the dpkg question, no
following the comments,i have done this, and am satisfied that i am up-to-date
the long way around
issue with nic?  you can use the ip_route2 tool ip to display the statistics about a particular network interface.  $ ip -s link show wlp1s0 3: wlp1s0: &lt;broadcast,multicast,up,lower_up&gt; mtu 1500 qdisc mq state up mode dormant group default qlen 1000     link/ether c8:f7:33:15:0b:12 brd ff:ff:ff:ff:ff:ff     rx: bytes  packets  errors  dropped overrun mcast        2080111115 7611725  0       0       0       0           tx: bytes  packets  errors  dropped carrier collsns      727520431  6328004  0       0       0       0         the above shows packets received (rx) and sent (tx) along with any errors that occurred as packets traveled in/out of the nic
the proper solution to something like this in puppet is to create a defined type:  define folder_link (  $link_map = $name, ) {  $link_map_split = split($link_map, ':')  $origin = $link_map_split[0]  $link_name = $link_map_split[1]  $link_path = "/folders_1_to_x/yy/$link_name"   file { $link_path:   ensure =&gt; link,   target =&gt; $origin,  } }   class foo {  folder_link { ["/aa/bb/folder_to_link:foo", "/cc/dd/folder_to_link:bar"]: } }   this will symlink /folders_1_to_x/yy/foo to point at /aa/bb/folder_to_link, and /folders_1_to_x/yy/bar to point at /cc/dd/folder_to_link.  i think it's pretty straightforward how this works, but i can clarify if needed. 
add this to your .bash_login file
yes, it is
you can fix it (each time it happens) with this command:     find local_directory_name -depth -exec sh -c 'dir="$(dirname "$0")"; file="$(basename "$0")"; lowfile="$(echo "$file" | tr "a-z" "a-z")"; if [ "$lowfile" != "$file" ]; then mv "$0" "$dir/$lowfile"; fi' {} ";"   type this all as one line (replacing local_directory_name with the name of the directory to which you copied the files).  you can break it into multiple lines by inserting backslashes.  or you can put the part after sh -c into a script file.  this enumerates all the files in the directory (including subdirectories, recursively) and executes the given commands on each one.  -depth makes it work "bottom-up", so it processes all the entries in a directory before it processes (renames) the directory itself.  each filename (relative path starting from local_directory_name) is broken down into a directory portion and a plain filename (just the bottom component).  then the filename is converted from upper case to lower case.  if this is different from the existing filename, it renames the file to the lower-case name.  i added this check to prevent the diagnostic messages you would otherwise get from trying to rename a file to itself, which would happen if you had a file whose name contained no letters (i.e., was numerals and special characters only).  or, for that matter, if you had a file whose name contained no capital letters.  afterthought: another way to avoid mv 123 123 errors is to add -name "*[a-z]*" after -depth, which tells find to process only names that contain at least one capital letter. 
on linux, you can find the maximum pid value for your system with this:  $ cat /proc/sys/kernel/pid_max   this value can also be written using the same file, however the value can only be extended up to a theoretical maximum of 32768 for 32 bit systems or 4194304 for 64 bit:  $ echo 32768 &gt; /proc/sys/kernel/pid_max   it seems to be normative practice on most 64 bit systems to set this value to the maximum 32 bit value, but this is by convention rather than a requirement.  from man 5 proc:   /proc/sys/kernel/pid_max     this file (new in linux 2.5) specifies the value at which pids wrap around   (i.e., the value in this file is one greater than the maximum pid)
if outgoing ssh works, you can use ssh tunneling to set up a socks proxy which will effectively bypass the firewall
you can also find out your interface's names with  pactl list sources | grep name:   in your case it is "alsa_output.usb-focusrite_scarlett_2i2_usb-00-usb.analog-stereo.monitor".  then record audio with avconv by using exactly that name after the -i switch  avconv -f alsa -ac 2 -ar 48000 -f pulse \ -i alsa_output.usb-focusrite_scarlett_2i2_usb-00-usb.analog-stereo.monitor \ -acodec libvorbis -aq 6 test.ogg   in essence ommit the greater-than and smaller-than signs around the identifiers in your example and it should work.  here is a tutorial about the usage and meaning of these commands:  http://meshfields.de/linux-usb-audio-stream-recording/ 
the /proc file system will list exactly this information:  $ ls -l /proc/self/fd total 0 lrwx------ 1 michas users 1 apr  6 04:44 0 -&gt; /dev/pts/0 lrwx------ 1 michas users 1 apr  6 04:44 1 -&gt; /dev/pts/0 lrwx------ 1 michas users 1 apr  6 04:44 2 -&gt; /dev/pts/0 lr-x------ 1 michas users 1 apr  6 04:44 3 -&gt; /proc/6934/fd $ ls -l /proc/self/fd 2&gt;/dev/null &lt;&lt;&lt;foo |cat total 0 lr-x------ 1 michas users 1 apr  6 04:45 0 -&gt; /tmp/sh-thd-361068043 (deleted) l-wx------ 1 michas users 1 apr  6 04:45 1 -&gt; pipe:[136729] l-wx------ 1 michas users 1 apr  6 04:45 2 -&gt; /dev/null lr-x------ 1 michas users 1 apr  6 04:45 3 -&gt; /proc/6952/fd   if you are interested in some other process just replaces "self" with the corresponding pid. 
did you look at auditd? if not see this slideshow about linux audit system
you can't, not really, without doing an extensive audit of the code and observing it in action "from the outside", for example using a virtual machine
port 25 is the standard port that is used over the internet for smtp communication
i have solved it: actually it needs a key: creating the key:  dnssec-keygen -a hmac-md5 -b 128 -n host example.com.   editing conf
go to settings->edit current profile
dissecting the acronym, i get that mch stands for 'memory controller hub' with is an older name for the northbridge
with sed:  sudo netstat -4tln | sed '1d;2d;s/[^:]*:\([0-9]\+\).*/\1/' | sort -n  
the 'spellfile' option is what you're looking for:  :set spellfile=~/.vim/spell/techspeak.utf-8.add   note: avoid special characters like _; as it separates the region name in vim.  you can then add your custom words to it with zg
you can pause any program by sending it a tstp (polite) or stop (forcible) signal
libcdio contains a collection of command-line which are cd-text aware
generally, you should use kill -15 before kill -9 to give the target process a chance to clean up after itself
lsusb  first thing to try is make sure that the device shows up when plugged in.  example  i have a logitech headset.  $ lsusb bus 002 device 006: id 046d:0a01 logitech, inc
a little bit of google-fu would have helped here
check the folder permissions on both sides in regards to the user you are utilizing
you should use telnet in order to check if the port forwarding works:  telnet localhost 1234   it's probably not working as you use the wrong ssh options (twice):  ssh -l localhost:1234:remoteip:5634 user@remoteip   or (depending on it on which interface(s) the server is listening:  ssh -l localhost:1234:localhost:5634 user@remoteip  
i have not managed to complete the solution with ryder's answer
it's possible, but not easy...  first, you have to bind mount tty2 and modules, so spawn the container using:  systemd-nspawn -bd /system/arch --bind /dev/tty2 --bind /lib/modules   of course, spawn the container in tty2 terminal... then, you need to start an x-server in another tty, which somehow is failing in my device  startx -display :1 -- :1 vt2 &amp;   besides, you've better just freeze one server and start another in tty2, as both running would conflict and would be resource waster.  p.s.: there is also a guy that ran a container's program under host's xserver, here http://dabase.com/e/12009/ 
the * means zero-or-more matches, and it matches as soon as possible
i couldn't figure out how to get this done using only curly braces
globbing (which is what you're doing with your wildcard matching) will expand the current command line.  for example:  ls [abc]1   gets expanded to:  ls a1 b1 c1   globbing only works where the command allows multiple arguments
you cannot do this using traditional unix permissions, you'll have to use acls, that's access control lists
the best answer i could find is http://www.debian.org/cd/faq/#search-for-package  the following question is also relevant http://www.debian.org/cd/faq/#list-image-contents  maybe you could just download the jigdo files and look at them
env | grep xdg_current_desktop returns the desktop environment currently in use
from debconf, each of them is different in some subtle way:  keyboard-configuration keyboard-configuration/layoutcode string de   here, layoutcode only accepts short strings, like "en", "es", "es-la", etc
the hardware power button triggers an acpi event that acpid (the acpi daemon) notices and reacts to; in this case by shutting down the system, although you could have it do whatever you want
to load a specific module to the pa server, you add it to /etc/pulse/default.pa:  load-module module-device-manager  changes can also be made during runtime using pacmd. 
nvidia-settings allows you to set individual options on the command line without opening the gui
in linux you can use free to see the amount of memory used
wakoopa (http://social.wakoopa.com) and rescuetime (http://www.rescuetime.com) seems to do what you want
wikipedia isn't as good a reference as the man page
use single quotes:  alias gpgagentexport='eval $(cat ~/.gpg-agent-info) ; export gpg_agent_info'  
run this:  cp -p "`ls -dtr1 /users/me/documents/coffi\ work/ftp\ backup\ shell\ script/original/* | tail -1`" /users/me/documents/coffi\ work/ftp\ backup\ shell\ script/backup1/   here we have added -d option os ls to get the absolute path.  in your command, as ls is not returning absolute paths, you must run that from the source directory to get the file copied
with some shells, you could use extended globbing+certain flags to match only files in class one. with bash:  shopt -s extglob for one in +([0-9])-+([0-9])-+([0-9])-+([0-9])-+([0-9])     do         [[ -f $one ]] &amp;&amp; mv -- "$one" first-class     done   +(&lt;pattern&gt;) matches one or more occurrences of the given pattern, [[ -f ..
typically "normal users" are assigned user id's >= 1000
the problem is that curl expects some normal terminal settings and zle doesn't expect you change the terminal settings
your @reboot job is in root's crontab
i figured it out eventually:    yum install system-config-keyboard run system-config-keyboard as root select norsk (aka norwegian)   now the correct keyboard layout shows up in the settings gui. 
the point of tail -f is to run forever until explicitly killed, so you'll have to arrange to kill it.  if there is some logic that determines when the tail process is to be killed, obtain the process id of tail and arrange to trigger its killing when desired
yes
your understanding is correct; these options match the same options in find.  thus  chown -r .   or  chown -r -p .   changes the owner recursively without de-referencing any symlinks;  chown -r -h *   changes the owner recursively, de-referencing any symlinks in the current directory (since they end up being part of the arguments) but  chown -r -h .   still doesn't de-reference any symlink, and finally  chown -r -l . chown -r -l *   both de-reference syminks.  (as an aside for the examples above, note that . and * don't necessarily result in the same outcome, depending on your shell's globbing options — * typically doesn't match dotfiles.) 
you can use a third-party tool, devilspie2 to control the behavior of application windows as they are created
cat file | grep -v "\.png" &gt;new_file_without_pngs   updated for comment:  egrep -iv "\.(png|jpg|jpeg|gif|etc)" file &gt;new_file  
if the scanner's buttons are supported by sane you can use scanbd to make them functional
du -s directory_name   or to get human readable output:  du -sh directory_name   the -s option means that it won't list the size for each subdirectory, only the total size. 
this is answer       cat /sys/block/sda/size   above file will returns some number like 312581808, then this number need to multiply by 512 standard block size then u ll get long int value in bytes, then u can convert to gb. 
the traceroute manpage says !x indicates one of the icmp error responses (other than the desired "ttl exceeded")
@gelraen your answer gave me what i needed
you can use perl:  $ perl -le 'print((stat shift)[9])' test.txt 1402577190   or gnu date:  $ date -r test.txt +%s   you can install gnu date on aix refer to this link. 
sudo iwlist wlan0 scan   assuming your wireless is wlan0, of course
you can use xargs:   cat /path/to/file | xargs apt-mark auto   this should work if there is one package name per line in the text file /path/to/file.  another option would be to use a for loop:   for pkg in `cat /path/to/file`; do apt-mark auto $pkg; done   the second way might be useful if you have a similar problem where the command can't be called with a list of parameters but you have to call it once for each parameter you have
you can use the globignore variable to hide the . and .. directories
using hostnamectl set-hostname nodename.domainname is the correct way to set the system hostname (and domain name) for rhel 7
i actually fixed this by installing rpmforge, which just so happens to aim at dag repository, and then all yum commands to install nagios worked great.  try yum remove nagios-nrpe (etc), then see this page, install the update, then try the command yum install nagios-nrpe again and see if that works. 
the issue here is that there's a container, 4ac3a09ab4d3, that's still utilizing this image.  $ docker ps -a container id        image                command                created             status                       ports               names 4ac3a09ab4d3        04251cf7a8b9         /bin/sh -c ./git_che   2 minutes ago       exited (128) 2 minutes ago                       trusting_hawking 02c14db1bc65        pg-image:latest      /usr/lib/postgresql/   5 minutes ago       up 5 minutes                                     postgres 6a022281382f        redis-image:latest   /usr/bin/redis-serve   8 minutes ago       up 8 minutes                 6379/tcp            redis-db   you need to remove this container first so that you can remove this image.  # removes container 4ac3a09ab4d3 $ docker rm 4ac  # removes image 04251cf7a8b9 $ docker rmi 042 deleted: 04251cf7a8b9efd81b8de6fbc0099f12a7933307bd4ecdadbaa9f1672b4a5f8f deleted: 7f76b7a22ef2c66a148714980716e7d01d97455b303cbeb7cc371ccba8bb5153 deleted: bb7221a7b4a01573b0e3a175f3242f5e0ef58371c89a59dec7831146d6102bf8 deleted: 493a63262d20f2a3ffc050c85d30528ab8a93c9dd2718fdb27dbbaac1a551c06 ...   and with that both the container (4ac3a09ab4d3) and image (04251cf7a8b9) have been removed from your system. 
from the list of kernel parameters:  resume=     [swsusp]         specify the partition device for software suspend   where  swsusp  software suspend (hibernation) is enabled.   so yes, it's used for hibernation. 
you can count words and lines inside vi using vi's own counter:  press g and then ctrl-g
if by running you mean "up", the command is:  ip link set dev tun0 up  
i think you were missing the "recursive" parameter:     setfacl -rm g:developer:rwx /opt/spago41/  
since you don't know what -c (compile object file) and -o (specify output file) do, i would suggest to start with a simple executable compilation
simply pipe bash to tee
assuming the file is syntactically correct, you could format it with indent and make the process for finding and extracting the function much simpler:   with indent, you can make the function name in the first column of a line, followed by a left-parenthesis, and after that, the next right-brace '}' appearing in the first column would end the function.   here is a simple example using gnu indent and awk:  #!/bin/sh # $1 = file name # $2 = function name indent -st -orig "$1" | awk ' begin { state = 0; last = ""; } $0 ~ /^'$2'\(/ { print last; state = 1; }         { if (state == 1) print; } $0 ~ /^}/ { if (state) state = 2; }         { last = $0; } '  
i tried sourcing .profile on fish startup and it worked like a charm for me.  just do :   echo 'source ~/.profile;clear;' &gt;  ~/.config/fish/config.fish   quit terminal or iterm2 followed by firing up an alias from .profile to test. 
you can examine the package list file(s) from that repository, they'll be in the /var/lib/apt/lists directory with names that start with the domain for the repository and end with _packages.  it doesn't look like that repository supplies a release file
you should try and wait until the mousemove has completed, sometimes things get out of sync if your system is slow
you should source your script, with  
there's no need to use cat in this case:  sort /home/emerg/wedbackup.txt   the problem with your example is that your file is being passed as the command line to sort, which is not what you want
what you are trying to do is to add multicast dns to the name searching on raspbian.  install the package libnss-mdns (ie: sudo apt-get install libnss-mdns)
$ awk '$2&lt;20100101' file id1 19501112 id2 19831207 1d3 20001212 id6 20000101 id10 20061213 id11 20081212   a typical awk program consists of commands that look like:  condition { action }   in our case, the condition is that the second column be less than 20100101
in your example  export path=./ndk_tools/bin/:${path} export cc=arm-linux-androideabi-gcc export cxx=arm-linux-androideabi-g++ echo \ "$cc" cc --version   the last line uses the literal name cc (which is conventionally a c++ compiler) rather than a shell variable $cc (which would use the environment variable that you exported).  perhaps you meant  export path=./ndk_tools/bin/:${path} export cc=arm-linux-androideabi-gcc export cxx=arm-linux-androideabi-g++ echo \ "$cc" $cc --version   you might also want to simply make cc the one from ndk_tools by making a symbolic link to that (named "cc") on your path, but that would interfere with native use of the compiler
i think the easiest path would be to simply install a second hard drive in the computer, for exclusive use by ubuntu.  the problem is that opensolaris uses the zfs filesystem by default, and as far as i know, there are no partition editing tools that know how to resize a zfs partition on the fly
   what does it mean? what is "exit 2"?   it is exit status of ls
the solution is to scale the area parameter
using sgdisk  you can use sgdisk to print detailled information:  sgdisk --print &lt;device&gt;  […] disk /dev/sdb: 15691776 sectors, 7.5 gib logical sector size: 512 bytes […]   when you multiply the number of sectors with the sector size you get the exact byte count that should match the output of dd.  using /sys directly  you can also get those numbers directly from /sys:  number of sectors: /sys/block/&lt;device&gt;/size sector size: /sys/block/&lt;device&gt;/queue/logical_block_size  here's a way of calculating the size:  sectors=$(cat /sys/block/sdb/size) bs=$(cat /sys/block/sdb/queue/logical_block_size) echo $(( $sectors * $bs ))        --- or ---        echo "$sectors * $bs" | bc   using udisks  udisks outputs the information directly
you can see where httpd is configured to look for it's configuration files using the -v switch:  $ httpd -v server version: apache/2.2.15 (unix) server built:   feb 13 2012 22:31:42 server's module magic number: 20051115:24 server loaded:  apr 1.3.9, apr-util 1.3.9 compiled using: apr 1.3.9, apr-util 1.3.9 architecture:   64-bit server mpm:     prefork   threaded:     no     forked:     yes (variable process count) server compiled with....  -d apache_mpm_dir="server/mpm/prefork"  -d apr_has_sendfile  -d apr_has_mmap  -d apr_have_ipv6 (ipv4-mapped addresses enabled)  -d apr_use_sysvsem_serialize  -d apr_use_pthread_serialize  -d single_listen_unserialized_accept  -d apr_has_other_child  -d ap_have_reliable_piped_logs  -d dynamic_module_limit=128  -d httpd_root="/etc/httpd"  -d suexec_bin="/usr/sbin/suexec"  -d default_pidlog="run/httpd.pid"  -d default_scoreboard="logs/apache_runtime_status"  -d default_lockfile="logs/accept.lock"  -d default_errorlog="logs/error_log"  -d ap_types_config_file="conf/mime.types"  -d server_config_file="conf/httpd.conf"   you can also use the command lsof to see what files a unix process is accessing
just use ", not '
i don't have direct answer to your question other than backing up the whole /etc directory.  however, you should consider upgrading to new release
so how i opted to do this was by editing the root subvolume (0):   mount the root subvolume: mount -t btrfs -o subvolid=0 /dev/sdxx /mnt created the snapshot subvolume: cd /mnt; btrfs subvolume create @snapshots   did a preliminary ls / and noticed i didn't see the subvolume; great, now onto next step; a test!  to create isolated snapshots that aren't visible from the original subvolume mount the created subvolume (@snapshot), create the snapshot, and then unmount it.   mount the snapshot subvolume; get the subvolume id with btrfs subvolume list / and then mount it: mount -t btrfs -o subvolid=&lt;id&gt; /dev/sdxx /mnt create the snapshot of / into /mnt with: btrfs subvolume snapshot -r / /mnt/snapshot_$(date +%s)  
i don't think there's a way to download keys securely, rather you can download them and confirm that they're legitimate using the steps outlined on their "keys" webpage.   trusting package integrity   excerpt     verify      if you have newly installed the rpmfusion-*-release.rpm repo packages, and wish to verify its keys, check the fingerprints below.      if you want to verify the key before to install the rpmfusion-*release.rpm, you can use    $ gpg --keyserver pgp.mit.edu --recv-keys key_id        where key_id is 172ff33d in the case of rpm fusion free for fedora 19.  
depending on your linux distribution and the kind of installation (minimal, desktop-centric, etc.) at  (and atd the at job scheduler daemon) is installed by default or not.  to verify it you can issue commands like:  $ which at /usr/bin/at $ which atd /usr/bin/atd $ yum whatprovides atd # to get the package name  $ yum info pkg-name # to see if it is installed   (assuming yum is available on suse - using a fedora system here)  if the package is not installed you can install it via your package manager, e.g
if it worked with the last release and doesn't with the latest, i'd say it's a bug
not with ls no
gnu sort (which is the default on most linux systems), has a --parallel option
change the pattern so it is a regular expression that will not match the literal text.      ps -ef | grep [s]shd  
not with chmod alone
.bak generally designates that the file is a backup copy of something, but other than that it gives preciously little information as to the actual file type.  try looking at the output of the file command, which studies the first few bits of the file to see if it recognizes it as a known filetype:  caleburn: ~/ &gt;file image001.jpg  image001.jpg: jpeg image data, jfif standard 1.01 caleburn: ~/ &gt;file oops.png  oops.png: png image data, 935 x 546, 16-bit/color rgb, non-interlaced caleburn: ~/ &gt;file zones.zip  zones.zip: zip archive data, at least v2.0 to extract caleburn: ~/ &gt;file eth2.pcap  eth2.pcap: tcpdump capture file (little-endian) - version 2.4 (ethernet, capture length 96)   and so on, and so on
did you try to re-enable the service in order for the changes to take effect ?  systemctl reenable docker.service  
there is  ip route get 74.125.137.100   but it doesn't do hostname resolution (which i think is a good thing)
without seeing the policy file, one can only guess, but it's probably because the policy is somewhat far-reaching in what it affects
to list only hidden files:    ls -ap | grep -v / | egrep "^\."     note that files here is everything that is not a directory
one of the reasons for zombie process are 'parent process' not waiting for the 'child process' - executed ps -l which shows the parent process id, with that you can find exactly which process is responsible for zombies in the machine. 
another way to do this is to use here documents:  #!/bin/sh  cat &gt; /etc/pam.d/xxx &lt;&lt; 'eof' place whatever should go in the file here eof  chown root:root /etc/pam.d/xxx  # or whatever floats your boat chmod u=r,go= /etc/pam.d/xxx    # ditto  
you should use ssh and do:  ssh myacc@remove.server "cp /folder_a/*myfiles* /folder_b"  
i wrote a comprehensive blog post about linux network tuning which explains everything about monitoring, tuning, and optimizing the linux network stack (including the napi weight)
use the -h tar option
this can be found in the file /var/log/dpkg.log.  use this command to generate a list:  awk '$3=="upgrade"' /var/log/dpkg.log*   example output:  2015-12-30 15:33:15 upgrade firefox 38.0+build3-0ubuntu0.12.04.1 43.0+build1-0ubuntu0.12.04.1  
here is my workaround, the function palias (aka permanent alias):  function palias ()  {      if [ $# -ne "2" ] ; then         error "usage: palias short-alias \'long-alias\'"         return     fi      alias $1="$2"     alias $1 &gt;&gt; ~/.bash_aliases }  
according to http://homepage.smc.edu/morgan_david/cs40/lilo-readme.txt:  lilo always passes the string  boot_image=&lt;name&gt;  to the kernel, where  &lt;name&gt; is the name by which the kernel is identified (e.g
ext4 mount options  meta data only journaling (this is default)  data=ordered   to completely disable ext4 journaling (not recommended)  norecovery noload   to change commit time  commit=&lt;second&gt;   commit has a default and minimum value of 5
try adding:  --no-parent   "do not ever ascend to the parent directory when retrieving recursively
use double quotes on sed instead of single quotes;  $ bob="cool"; echo "bob is sad" | sed "s/sad/$bob/" bob is cool  
simply append a '/'
well first off, keys are supposed to identify the client, not the remote server
i believe you can check what has been installed or uninstalled etc via the aptitude logs
if you (as root) don't have permission to create /home/smrtanalysis, it probably means that /home is served from some other system on which you don't have root access.  can you ask the administrator of that system to create the smrtanalysis account for you?  if not, you can probably use the adduser --home option to put the new account's home directory somewhere else; pick a location where you do have permission to create a directory (and that has enough available disk space)
despite the fact that both distributions are built from mostly the same sources the installed binaries are not the same.  for copyright reasons the centos team (just like the unbreakable linux team at oracle) has to remove certain red hat owned material (logos etc.) and recompile.  so even if your install the necessary packages to make the system "look" like a rhel system (package redhat-release is an obvious one) i doubt red hat would consider it a supported system.  it may not be the answer you're looking for but i suggest you do reinstall in order to avoid support issues at a time you need it.  you should be able to start from the kickstart file created by anaconda (/root/anaconda-ks.cfg) to quickly set up a new system identical to the existing system. 
eval is part of posix
the isa dma controller is still included on any system that has an isa bus, which your typical desktop system still has these days, mostly to support floppy disk and ide disk controllers ( which ahci sata controllers can still emulate for backward software compatibility )
if your program is cutting the lines, you will need to join them before running your sed
tmpfs uses swap if sufficient ram is not available
you can find out which package it belongs to by using dpkg:  dpkg -s /usr/bin/play   this will give you output that looks something like this:  $ dpkg -s /usr/sbin/sshd openssh-server: /usr/sbin/sshd   if you have no use for this package, you can then remove that package with apt-get remove, or apt-get purge if you want to purge the configuration files, too.  if you instead get "no path found matching pattern", this file is not owned by any package, in which case you should carefully consider your options
you could use head:  command | head -c-10   would remove the last 10 bytes from command output.  quoting from man head:     -c, --bytes=[-]k           print the first k bytes of each  file;  with  the  leading  `-',           print all but the last k bytes of each file     since you specifically mention that the 10 characters to be removed would occur on one line, you could use sed too
i was able to achieve the desired aim with the following xorg.conf:  section "monitor"         identifier      "laptop panel"         option  "ignore"        "true" endsection section "monitor"         identifier      "big display" endsection     section "device"         identifier      "onboard"         option  "monitor-lvds1" "laptop panel"         option  "monitor-dvi1" "big display" endsection   the critical element being option "ignore" "true"
this isn't working because the command date returns a string with spaces in it.  $ date wed oct 16 19:20:51 edt 2013   if you truly want filenames like that you'll need to wrap that string in quotes.  $ touch "foo.backup.$(date)"  $ ll foo* -rw-rw-r-- 1 saml saml 0 oct 16 19:22 foo.backup.wed oct 16 19:22:29 edt 2013   you're probably thinking of a different string to be appended would be my guess though
for stopping and starting from cron, you should be able to start it if you set the display environment variable appropriately:  env display=":0.0" transmission-gtk &amp;   and if you send it sigint it will close down the same way as if you chose quit from its menu, properly closing connections and uploading totals to trackers:  killall -int transmission-gtk   in "transmission preferences" under "speed" there is a section "alternative speed limits" that lets you set a different set of speed for a certain time
sudo apt-get remove ipython sudo apt-get install python-setuptools sudo easy_install ipython[all]   you are using your linux distribution's package manager, and your linux distribution does not have the latest version in its repository
the disk space used by a file includes more than the size of the contents
the kernel is telling you that when the segfault occurred, the instruction pointer 0x7f3c7c523770 was in a sysv ipc shm segment
you should add the following in your .bashrc:  complete -f -x '!*.tex' texmaker   check debian-administation.org and bash manual for more info on the complete command. 
since you have the wireless tools and wpa supplicant installed, you have all you need
under ubuntu, another way of jailing is apparmor!  it is a path based mandatory access control (mac) linux security module (lsm)
i solved the issue by adding this pre-install script to the rpm:  # check that mysql version is not 5.1 rpm -qa | grep -i mysql-server.*5.1 &gt; /dev/null if [ $? -eq 0 ] then     echo "flux can not be installed because mysql 5.1 is still installed
openvpn requires an ssl cert, even if you don't want to have certs for user auth, or for tls firewall.  import the ssl cert from openvpn, then you can save the profile.  openvpn certs;  ca.crt (must have) user.crt (optional: user auth) user.key (optional: user auth) ta.crt (optional: firewall)   sample config using all 3x cert:  client dev tun proto udp remote 192.168.0.2 persist-key persist-tun ca ca.crt cert user.crt key user.key auth-user-pass tmp.ovpn comp-lzo yes nobind auth-nocache script-security 2 reneg-sec 21600 tls-auth ta.key 1 cipher aes-256-cfb8 tls-cipher tls-dhe-rsa-with-aes-256-cbc-sha remote-cert-tls server auth sha512  
standalone printf  part of the "expense" in invoking a process is that several things have to happen that are resource intensive
if you wouldn't have a superuser, you would need to be able to execute all  tasks, that now require privilege elevation, as a normal user
i saw no way to do this using the :print command
this is a issue with vlc's output module, you need to choose one that works with your x server/desktop environment
try using hexedit i haven't tried it on hp-ux but it should work
i solved it by making my own install-info command and putting it before /usr/bin in $path
the creation of an iscs target lun links the previously-defined storage objects with the target and defines which number the device will use.  therefore, if you want the lun (lun0) to be expanded, then the underlying storage object (disk01) needs to be expanded.  one method to do this is to create a logical volume from the two disks as follows (although this will require an outage):  delete the unused storage object disk02 and create a logical volume from it:  /backstores/block&gt; delete disk02 deleted storage object disk02. /backstores/block&gt; ls o- block .....................................................................................................
i got the answer here.  this would be the script to maximize it to the right half of the screen:  #!/bin/bash # resizes the window to full height and 50% width and moves into upper right corner  #define the height in px of the top system-bar: topmargin=27  #sum in px of all horizontal borders: rightmargin=10  # get width of screen and height of screen screen_width=$(xwininfo -root | awk '$1=="width:" {print $2}') screen_height=$(xwininfo -root | awk '$1=="height:" {print $2}')  # new width and height w=$(( $screen_width / 2 - $rightmargin )) h=$(( $screen_height - 2 * $topmargin ))  # x, change to move left or right:  # moving to the right half of the screen: x=$(( $screen_width / 2 )) # moving to the left: #x=0;   y=$topmargin  wmctrl -r :active: -b remove,maximized_vert,maximized_horz &amp;&amp; wmctrl -r :active: -e 0,$x,$y,$w,$h   to move to the left, just change the x-line to x=0
you often see this in case of utilities like busybox, a program that can provide most of the common unix utilities in one executable, that behaves different depending on its invocation/  busybox can do a whole lot of functions, acpid through zcat.  and it commonly decides what it's supposed to be doing by looking at it's argv[0] parameter to main()
have you tried using the double quote?  inside single quotes, bash will not expand the variable $username.  for example, if $username=bob, then this command will expand the variable:  ssh user@hostname "useradd $username; mkdir /home/$username;"    the quoted portion will expand to:  useradd bob; mkdir /home/bob;   but if you use single quotes, like this:  ssh user@hostname 'useradd $username; mkdir /home/$username;'   then the quoted portion remains unchanged
as you have used positional parameter (argument) 1 ($1) inside the script, use command substitution to pass the ip address from curl as the first argument:  bash starttelem2.sh "$(curl -s http://silvo.uk.to/ipreg.dll/getip)"   $(curl -s http://silvo.uk.to/ipreg.dll/getip) is command substitution, which will be replaced by the standard output of the curl command inside. the -s option causes curl to not show any progress info on stderr.  note that, you have used the shebang as sh but running the script as an argument to bash, as bash is a superset of sh, you should consider making the shebang as bash too, if you don't have any specific reason not to. 
if the application is called tcpa, try:  ps -c tcpa   you can restrict which processes top shows by passing it a pid, or list of pids, eg:  top -p 1154, 761   will show just procesess 1154 and 761
to improve power management on your laptop enable all feature of lmt  from /etc/laptop-mode/laptop-mode.conf or using the gui by runing:gksu lmt-config-gui      many authors ignore ac97-powersave.conf - - why?   this feature is useful , only if you have ac97 sound card, you can enable it form ac97-powersave.conf file:  nano /etc/laptop-mode/conf.d/ac97-powersave.conf   set the value as bellow :  # control ac97 audio chipset power? control_ac97_power=1  
the low level page fault handler in the os (that is listed in the trap table from the cpu) get's the fault address from the cpu and uses this fault address to check the entries in process's address space description table. this table contains a list of segment descriptors that each contain a base address and a size
it seems that this serverfault answer outlines how this can be achieved by connecting the router as a client and then creating a sub-interface to broadcast a different ssid. 
most unix tools are designed to work well with text files
echo    an echo implementation which strictly conforms to the single unix specification will add newlines if you do:  echo 'line1\nline2'   but that is not a reliable behavior
one way is explicitly dropping out and back into insert mode before the paste
i found two possible solutions
like this:  echo $(( 0xa ^ 0xf ))   or if you want the answer in hex:  printf '0x%x\n' $(( 0xa ^ 0xf ))   on a side note, calc(1) does support xor as a function:  $ calc base(16)     0xa xor(0x22, 0x33)     0x11  
use lpoptions with the -o options you want
technically, "process1" doesn't know this
it looks like a bug in zenity
run df -h / and note the space used
this is not an issue for openssh since it doesn't make use of ssl
x11 forwarding needs to be enabled on both the client side and the server side.  on the client side, the -x (capital x) option to ssh enables x11 forwarding, and you can make this the default (for all connections or for a specific conection) with forwardx11 yes in ~/.ssh/config.  on the server side, x11forwarding yes must specified in /etc/ssh/sshd_config
i renamed your script, but here's an option:  $ ./myscript.sh xxx.xxx.xxx.xxx:8080/code -c code1 -t query   after executing the script, use:  $ ^code1^code2   ..
ntp is a time synchronisation protocol; by default, participants (including your systems running ntpd) exchange messages regularly to keep their clocks in sync
well, it was published on april 1, 2015 - april fools' day
apt-get and aptitude have different dependency resolvers
apt-cache dumpavail reads from /var/lib/apt/lists — essentially, it does cat /var/lib/apt/lists/*_packages
i found these 2 method via google, in this thread titled: re: flattening pdf files at the unix command line.  method #1 - using imagemagick's convert:  $ convert orig.pdf flattened.pdf    note: the quality is reported to be so so with this approach.  method #2 - using pdf2ps -> ps2pdf:  $ pdf2ps orig.pdf - | ps2pdf - flattened.pdf    note: this method is reported to retain the image quality. 
i believe @derobert (who commented on the original question) is likely correct
you can use a temporary sentinel character to delimit the number:  $ sed 's/\([0-9]\)/;\1/' log | sort -n -t\; -k2,2 | tr -d ';'   here, the sentinel character is ';' - it must not be part of any filename you want to sort - but you can exchange the ';' with any character you like
it is possible that one of the chrome instances is ignoring the sigterm signal, waiting for a second to confirm? killall -9 chrome may do what you want. 
i have currently resolved this by:   creating a new group and add my user to the new group chgrp the mounts /media/data and /media/backup to created group chmod 775 to both mounts   i can now access said mount points as my user and any user added to the new group i've created. 
if you grant a user access to login to an account, you grant full access to that account and any means you try to detect the difference can easily be overcome with basic environment manipulations
you could try inspecting run-time logs following rsync
from your example, i think what you need is:  find 
this does the job:   put the card in a card reader on your machine. see the end of dmesg to find the device path (for example /dev/sdx). if the device has any data on it, now is the time to back it up! if the device was auto-mounted, sudo umount /dev/sdx. run sudo gparted /dev/sdx (or gksudo/kdesu if you have one of those). if you have any partitions, delete them. create a new, unformatted partition taking up the full disk (this is the default), and with the label "msdos"
use less --follow-name if your version of less supports it
i would execute a find inside another find
you can substitute the value of $i in to see the exact command you're trying to run:  app4/ | sed -e "s/^.*\(.\)$/\1/"   this doesn't work because app4/ isn't a command
the line in /etc/fstab i eventually used was:  //10.1.0.15/g4\040320h   /media/g4   cifs   username=master,user   0   0   what solved the issue of not being prompted for the password as well as credentials= not working was installing mount.cifs via:  sudo apt-get install cifs-utils   just like michael mrozek i assumed i had mount.cifs installed or else i wouldn't be able to mount cifs shares, but apparently the kernel will use it's own internal code to mount unless it finds mount.cifs 
using the -c switch (2mb = 2 * 1024 * 1024 = 2097152 bytes):  tail -c 2097152 myapp.log     thanks to petr uzel for the suggestion
do not use kill -9 if not absolutely necessary, and most of the time it is not absolutely necessary
i found out that i need to send an eviocgrab ioctl to the device, which grabs it for exclusive use.  here's how to do it in ruby:  #!/usr/bin/env ruby barcode_scanner = "/dev/input/by-id/usb-metrologic_metrologic_scanner-event-kbd"  require 'rubygems' require 'libdevinput' require 'ffi' require 'ffi/tools/const_generator'  # we need access to the file devinput.class_eval { attr_reader :dev }  # look up value of eviocgrab constant cg = ffi::constgenerator.new('input') do |gen|   gen.include('linux/input.h')   gen.const(:eviocgrab, '%u', '(unsigned)') end eviocgrab = cg['eviocgrab'].to_i  scanner = devinput.new(barcode_scanner) # send eviocgrab to scanner, which grabs it for exclusive use by our process scanner.dev.ioctl(eviocgrab, 1)   puts "waiting for events..." scanner.each do |event|   # ignore everything except key press events   next unless event.type == 1 &amp;&amp; event.value == 1   puts "key: #{event.code_str}" end   note: you'll need to install the libdevinput gem, ffi, and linux headers
the tool you think you're looking for is zerofree, as described in this duplicate question clear unused space with zeros (ext3,ext4), and already available in most distributions.  however, you seem to be asking how to take an image backup of a filesystem that excludes unused blocks
rpmlint is a tool to check rpms against some sort of packaging policy
wget and curl only parse links within the anchor tags on a html document. the page you are referring to, uses a post method with the link to the document to download it.  you will have to download the file and parse it manually for all links
create a file ~/.ssh/config, with contents:  host test01     hostname 192.168.3.1   then chmod it to 0600 and enjoy
yes, you need to make the full-fledged web server executable a service
the glob * can be used to match not only plain files, but also directories, so the command you are looking for is  mv ./*/*.avi .  
a lot of linux routing and networking capabilities can be found in the linux advanced routing &amp; traffic control howto.  in particular, your specific question is addressed in 4.2 routing for multiple uplinks/providers. 
it's impossible to attach latrace to a running process
install the yum-plugin-priorities package, which lets you add a priority parameter to your repo files
renaming directories requires write permission in the parent directory, so let's say you have  base base/mantenimientos base/mantenimientos/fiscio base/mantenimientos/logico   the mantenimientos directory would be made r-x, and the fiscio and logico directories would be rwx permission.  e.g.  $ ls -ld mantenimientos                                                         drwxr-xr-x 4 root root 4096 aug 30 13:04 mantenimientos/  $ cd mantenimientos $ ls -al total 4 drwxrwxrwx 2 root root 4096 aug 30 13:04 fiscio/ drwxrwxrwx 2 root root 4096 aug 30 13:04 logico/   so i can write to the two directories, but not to the mantenimientos directory
don't do that..
you may have luck to see more information including partitions using  file -k # don't stop at the first match, keep going.   though on my systems it also does not show the partition table
apt will always install the latest version that isn't excluded by preferences
what you're describing is a tor middlebox
notice that libapache2-mod-php5 is being removed by your purge
not possible.  this is why people have been decrying flash and it's closed source nature for years
neither dns resolver lists nor ns record sets are intrinsically ordered, so there is no "primary"
there are a few references to this on stackoverflow in the context of using dpkg which is the underlying tool behind apt-get: 1, 2 an 3
here are two oneliners
use something like this (bash):  mv myfile myfile.$(date +%s)   or alternatively:  mv myfile myfile.`date +%s`   if your shell doesn't do the $(command) thing. 
 why it is installed:    aptitude why libplrpc-perl what depends on this package:  aptitude search '~i~dlibplrpc-perl' what would happen, if libplrpc-perl is removed:  aptitude -s purge libplrpc-perl    
i quite like tcpdump for recording network connections
as in my comment:     probably won't help but try "echo 3 > /proc/sys/vm/drop_caches" before   each invocation of tt   questioner's response:     yes, echo 1 | sudo tee /proc/sys/vm/drop_caches does exactly what i   want (echoing 3 instead gives a weird result)
page handling is determined by the application, not the printer
the vmware application includes a kernel extension (kext)
okay, i am using awesome for several months now on my notebook
use this:  find 
you can't add them both in the same command line, as far as i can see &ndash; from the man page i interpret the functionality to include:   compressing files into the archive using various compression methods &ndash; this would have to be done individually, or in groups decompressing them no matter whether they are in the same format or not   so you can have an efficient archive which only requires one command to extract all the contents. 
the direct answer to your question is "use double quotes" because single quotes prevent all expansions:   right=$(echo "$wrongpath" | sed "s|$oldtargetdir|$goodtargetdir|")   there's no need for the trailing semicolon; they're only necessary when something follows on the same line (so the one before done is not redundant, though the layout is unorthodox and the done should usually be on a line on its own).  you can also use:  right="${wrongpath/$oldtargetdir/$goodtargetdir}"   which avoids the overhead of sub-processes. 
i suppose term is set to linux for the init process (pid 1) by linux kernel here and there
please note that chmod 777 filename is the equivalent of chmod 0777 filename in this example.  the first octal digit sets the setuid, setgid and sticky bits (see this article for more details on setuid/setgid)
you can use something like this in your ~/.vimrc to adjust to use spaces/tabs as appropriate:  " by default, use spaced tabs. set expandtab  " display tabs as 4 spaces wide
the misunderstanding is that the numbers don't mean what you expect.  a leading zero denotes a number with base 8
i found a solution that works for my network, but your mileage may vary
:set shiftwidth=4   and then use 3>> as normal 
$&amp; is not a single token/special variable, it is simply $ and &amp;.  the command echo $&amp; is treated as echo $ &amp;, which echos a literal $ in the background.  $_ on the other hand is a special variable that expands to the last argument of the most recent command executed. 
sed uses $ for the line end:  sed '/^},$/ d'   ^ means the line beginning
so i found it out myself by scouring the web
specific definitions (filetype-specific, project-specific, ...) shall always be declared local to the current buffer
you can use acls on /srv/nfs/rootfs to give additional user(s) write access - see man setfacl / man getfacl for more info
you can find this option yourself:  press / in the menu menuconfig interface , and put config_apm there , if you find anything , it's supported  i can only give you output from 3.3.7 version:    but anyway , you could edit the .config file yourself , and append config_apm=y , then redo make menuconfig ,  
on ubuntu (until 14.04, 16.04 and later use systemd) can use upstart to do so, better than a cron job
i don't think that it is so hard to find out:  https://en.wikipedia.org/wiki/page_fault  also the 3rd result in google is exactly your question answered:  http://www.careerride.com/os-page-fault.aspx 
you can use  sed -e 's|&lt;tag1&gt;false&lt;/tag1&gt;|&lt;tag1&gt;true&lt;/tag1&gt;|g' -i file   although i recommend doing the edit to a copy of the file,  sed -e 's|&lt;tag1&gt;false&lt;/tag1&gt;|&lt;tag1&gt;true&lt;/tag1&gt;|g' file &gt; newfile   and using less to check if the new contents are acceptable; i.e.  less newfile   edited: note the g modifier at the end of the pattern
you could just disable your keyboard and mouse for the duration
your root file system (which by the way is extremely small, even considering that you have /home, /tmp, /usr and /var elsewhere) is practically full; that exact df invocation reports 24 mb free on /, which adds up well with the 23.87 mib reported by the wizard.  i'm guessing this is because parts need to go into locations outside of the supposed installation directory
it is possible to do that using the env command, however you have to use a little work around and call sh, see the following code snippets:  # env var=bla echo $var &gt; # env var=bla sh -c 'echo $var' &gt; bla # echo $var &gt;   you can find more information using on info coreutils 'env invocation'  unfortunatelly i can't give you any further explanations why it only works using sh -c ''.  it seems env has a rather non-intuitive behavior...  # env path= echo $path &gt; env: echo: no such file or directory # env path= /bin/echo $path &gt; /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin  
i think you're looking for a jail
the command line switch -h forces grep to print the file name, even with just one file.  % grep -n 7 test.in 7:7 % grep -hn 7 test.in test.in:7:7        -h, --with-filename           print the filename for each match.   note that as kojiro says in a comment, this is not part of the posix standard; it is in both gnu and bsd grep, but it's possible some systems don't have it (e.g
normally bash knows that it's a login shell because when the login program invokes it, it tells bash that its name is -bash
what is possible depends on what the firewall allows.  if the firewall allows arbitrary traffic on port 443  some firewalls take the simple way out and allow anything on port 443
zabbix-agent package is only available in the wheezy-backports repository, you should enable this repository if you want the software in wheezy (stable).  http://packages.debian.org/wheezy-backports/zabbix-agent  the package is also available in jessie (testing) and sid (unstable).  the procedure to enable the wheezy backports is adding:  deb http://yourmirror.debian.org/debian wheezy-backports main   (replacing yourmirror with your real mirror)  to your sources.list, then run apt-get update to update your repositories then installing the packages using your preferred apt method.  sudo apt-get install zabbix-agent   normally to install packages from backports you need to specify that you want them with the -t switch, since all backports are deactivated by default (i.e
here are some suggestions:  itunes alternatives - linux itunes open source alternatives 
you just need to change your shell
if your bash script is called my_script.sh, then add this at the top:  #!/bin/bash for pid in $(pidof -x my_script.sh); do     if [ $pid != $$ ]; then         exit 1     fi  done python python_app.py   it will list all the pids related to my_script.sh and verify if they are the same of the process we are currently running
i found that this is possible by editing the slim.conf file available in /etc
i would try it like this   add a new disk at least as big as the missing one (say  /dev/sdx). create a pv with same uuid as the missing one.  pvcreate --restorefile your-file --uuid j7dxl-2m2j-d0oc-bczy-fqak-yoj7-ohrllw   /dev/sdx try again your restore command:  vgcfgrestore  --restorefile your-file my_vol_group   see also man vgcfgrestore:     replacing physical volumes          vgdisplay --partial --verbose will show you the uuids and sizes of any pvs that are no longer present
i hope you're aware there are already a lot of system monitoring widgets
if the ch must occur at the beginning of the line, the order of ch and au is fixed, so you can look for ^ch.*au.  $ echo -e 'ch12\nch23au' | sed '/^ch.*au/s=^=&lt;b&gt;=' ch12 &lt;b&gt;ch23au $   if the order of the two patterns is not fixed, one could do something like  sed -e '/pattern1/{;/pattern2/s/old/new/;}'   but the perl solution  perl -pe 'if (/pattern1/ &amp;&amp; /pattern2/) {s/old/new/;}'   is probably more readable. 
there are several things you can do to improve the title bars in gnome 3.  1
as the other answers have indicated, you can do part of what you've asked for using named pipes
to call a program by its name, shells search the directories in the $path environment variable
/var/log/messages   that is the main log file you should check for messages related to this
nohup your-command-here &amp;&gt; output.txt &amp; tail -f output.txt  
it doesn't.  the main process handles the death of its children, in the normal way.  this is the posix world
you can check checkboxes using spacebar in most of the interfaces.  i would rather write an answer than to close this question as off-topic (in which queue i found it), because there is nothing wrong in it. 
grep -x '.\{3,10\}'   where   -x match pattern to whole line . any symbol {3,10} quantify from 3 to 10 times previous symbol (in the case any ones)  
in addition to gilles answer there is cpulimit tool that does exactly what you want - including modifing in runtime
in bash, numbers with leading zeros are considered as octal.  you can use:  next_number=$(printf %06d "$((10#$current_number + 1))")   to tell bash to consider it as decimal.  see also:  $ printf 'a%06d\n' {5..12} a000005 a000006 a000007 a000008 a000009 a000010 a000011 a000012   or:  $ printf '%s\n' {a..c}{00008..00012} a00008 a00009 a00010 a00011 a00012 b00008 b00009 b00010 b00011 b00012 c00008 c00009 c00010 c00011 c00012   or:  $ seq -f a%06g 5 12 a000005 a000006 a000007 a000008 a000009 a000010 a000011 a000012  
when you use the -r switch to chmod, you're saying that you want to apply the permissions change in question to files and folder recursively
there is the explanation by digital ocean (since i think that's where you got the screenshot from):  what is mean on ubuntu     it's an application stack based on nodejs and mongodb
first determine where is apt-get using whereis apt-get or which apt-get; i will assume it's in /usr/bin/apt-get  then create a file in /usr/local/bin/apt-get with this content:  #!/bin/bash # (commands to run before apt-get) /usr/bin/apt-get "$@"   now chmod +x /usr/local/bin/apt-get.  this should survive all upgrades of the distribution but it should not change the behavior of apt-get (aside from running the command before doing anything else)
a terminal emulator provides a standardised character based interface for text mode applications, it emulates the behavior of real or idealised hardware
pay attention to the tags on this question
to view only the processes owned by a specific user, use the following command:  top -u [username]   replace the [username] with the required username  if you want to use ps then  ps -u [username]   or   ps -ef | grep &lt;username&gt;   or  ps -efl | grep &lt;username&gt;   for the extended listing  check out the man ps page for options  another alternative is to use pstree wchich prints the process tree of the user  pstree &lt;username or pid&gt;  
make sure your paths on the remote are correct
as noted by yasouser, middle-click is the standard way to paste the selection buffer in linux
you could do it with a shell loop like:  for f in *.jpeg *.png do  printf "mv '%s' pic%05d.%s \n" "$f" $((++c)) "${f##*.}" done | sh   this program creates a single sequence with one run of a serial number and retains the original file extension.  note: the technique to create the commands or command sequences and piping the result in a shell is a standard coding pattern
from the gnu grep man page:   -f file, --file=file        obtain  patterns  from  file,  one  per  line
you can find all the symbolic links using:  find / -type l    you might want to run this as root in order to get to every place on the disc.  you can expand these using readlink -f to get the full path of the link and you should be able to grep the output against the target directory that you are considering for deletion:  find / -type l -exec readlink -f {} + | grep -f /dir2   using find / -type l -printf '%l\n' doesn't work as you get relative links like ../tmp/xyz which might be pointing to your target dir, but are not matched because they are not fully expanded. 
from the man-db package.  just remove the symlinks, and run:  apt-get purge man-db apt-get install man-db  
uid gid dmask fmask is mount's way of letting you specify owner, group and access permissions
(update: 2015-12-16)  these last few days i had occasion to use-up the remaining mb-s on the usb modem
maybe something like this:  $ cat t.awk nr==1 {     for (i=1; i&lt;=nf; i++) {         ix[$i] = i     } } nr&gt;1 {     print $ix[c1], $ix[c2] } $ awk -f t.awk c1=id c2=name input  1 ed 2 joe $ awk -f t.awk c1=age c2=name input  50 ed 70 joe   if you want to specify the columns to print on the command line, you could do something like this:  $ cat t.awk  begin {     split(cols,out,",") } nr==1 {     for (i=1; i&lt;=nf; i++)         ix[$i] = i } nr&gt;1 {     for (i in out)         printf "%s%s", $ix[out[i]], ofs     print "" } $ awk -f t.awk -v cols=name,age,id,name,id input  ed 1 ed 50 1  joe 2 joe 70 2    (note the -v switch to get the variable defined in the begin block.) 
tcpdump usually comes as standard on linux distros
i would preprocess the data with xmlstarlet:  $ xml sel -t -c '/datas/data' -nl data.xml &lt;data&gt;   &lt;name&gt;name1&lt;/name&gt;  &lt;/data&gt;&lt;data&gt;   &lt;name&gt;name2&lt;/name&gt;  &lt;/data&gt;   then it depends on how you python script wants to read this data
it's reading from stdin, i.e
xrandr -q should give you all the possible resolutions supported by your screen (based on current driver)
read returns a non-zero exit status if it doesn't find a delimiter, which is always the case when the delimiter is an empty string. 
you can do this the same way you'd do it in your shell: use '\''.  read that as: exit from the initial single-quote ', then \' (i.e
bind9 on wheezy doesn't allow for that option
i have managed to do it myself
to copy all lines between %packages and %end from file1 into file2:  awk '$1=="%end" {f=0;next} f{print;next} $1=="%packages" {f=1}' file1 &gt;&gt;file2   this solution is designed to remove the lines %packages and %end
alt+space, x is the default shortcut for maximize/unmaximize in most window managers
you would typically do this with a makefile something like this:  in = $(wildcard inputs/*.txt) out = $(subst inputs/,outputs/,$(in))  outputs/%.txt: inputs/%.txt         cp $&lt; $@  default:  $(out)   this makes the default target (the first one in the file), depend on out which is the glob expansion of the existing files in in with the directory string changed from inputs to outputs.    if you want to change the suffix there are lots of other builtin functions to manipulate the targets
use for example the -f switch to have ps display more information
it's b (shift-b)
rsyslog has a mail module, which i suppose you could use in conjunction with the file monitor, and probably learn some stuff about configuring rsyslog in the process, lol
not all openbsd mirrors support ftp—ftp is depreciated in favor of http
you don't need to force man's output via process substitution
once you are done saving the file, you could always split the file into file pieces or multiple files based on the number of lines.  split -l 1000 output_file  or even better just try  command | split -l 1000 -  this will split the output stream into files with each 1000 lines (default is 1000 lines without -l option).  the below command will give you additional flexibility to put or enforce a prefix to the filename that will be generated when the output is generated and splitted to store into the file.  command | split -l 1000 - small- 
if you want to apply a relative offset to the modification time of a file, you can do it with a combination of touch(1) and stat(1)
 pass uses gpg to encrypt your passwords
netcat springs to mind; it may be the more sensible choice (given the no-overhead, no compression approach to network communications) on your low-spec receiving machine.  a nice usage example can be found here: http://stackoverflow.com/questions/4113986/example-of-using-named-pipes-in-linux-bash 
a iptables rule like this works fine  *filter :input drop [0:0] :forward drop [0:0] :output accept [1:156] -a input -m state --state related,established -j accept  -a input -i lo -j accept  -a input  -p tcp -m state --state new -m tcp --dport 22 -j accept  -a input  -p tcp -m state --state new -m tcp --dport 587 -j accept  -a input -j reject --reject-with icmp-host-prohibited  -a forward -j reject --reject-with icmp-host-prohibited  commit   the first rule drop by default all incoming connection the second drop by default all forwarding the third accept the output,why accept?is not too unsafe imho to make open the output connections,close it can make the firewall configuration a little difficult.  -a input -m state --state related,established -j accept    accept the connection with state related and established state  the rest is easy      -a input  -p tcp -m state --state new -m tcp --dport 22 -j accept      -a input  -p tcp -m state --state new -m tcp --dport 587 -j accept      -a input -j reject --reject-with icmp-host-prohibited      -a forward -j reject --reject-with icmp-host-prohibited      commit   accept 22 tcp,accept 587 tcp and forbid all the other connections, you can save on file and then do  iptables-restore &lt; firewall.file   and check it with nmap -ss your host 
you can use mencoder (in your distribution, it should come in the package mplayer)
try using tee?  | tee log.txt   instead of   &gt; log.txt  
if you have the command line utility from openssl, it can produce a digest in binary form, and it can even translate to base64 (in a separate invocation).  echo -n foo | openssl dgst -binary -sha1 | openssl base64  
i found it!     history [n]      an argument of n lists only the last n lines.   $ echo "hello how are you" $ history 2 1060  echo "hello how are you" 1061  history 2  
quoting from the man page:     free  displays the total amount of free and used physical and swap   memory in the system   and your -m flag displays those amounts in megabytes. 
tune2fs -l /dev/sda1 **or** /dev/sdb1*  | grep 'filesystem created:'   this will tell you when the file system was created.  * = in the first column of df / you can find the exact partition to use. 
put this block of code in your ~/.tmux.conf
you can do this with a simple shell loop:  for x in ./*_*_*_*; do mv -i "$x" "${x%_*}"; done   i.e
here you go:  sed -i -e '$a\' file   and alternatively for os x sed:  sed -i '' -e '$a\' file   this adds \n at the end of the file only if it doesn’t already end with a newline
nautilus uses gvfs internally
the group id number (gid) is not specifically hard-coded to a particular group
top is a full screen interactive console application
use ${ } to enclosure a variable.  without curly brackets:  var="foo" echo $var echo $varbar   would give  foo   and nothing, because the variable $varbar doesn't exist.  with curly brackets:  var="foo" echo ${var} echo ${var}bar   would give  foo foobar   enclosing the first $var is not necessary, but a good practice.  for your example:  #!/bin/sh website="danydiop"  /usr/bin/mysqldump --opt -u root --ppassword ${website} &gt; ${website}.sql   this works for bash, zsh, ksh, maybe others too. 
since you have super user access, you can just change /bin/sh
as you seem not interested in useful volume group and volume names (currently your vg is named volgroup00 and your lv logvol01), i'll leave these untouched.  so the only need is to change the mount point, so you edit /etc/fstab and change the respective line from pracle to oracle
if you can get your list of files as a set of arguments to perl's rename this can be done quite easily:  rename 'no warnings; $a++; s!^(.*/)?(.*)!$1$a-$2!' "$@"   variables $a and $b are predeclared globals in perl, so although the entire expression should be considered to be within a loop (and scoped accordingly), they will keep their values throughout the lifetime of the execution
if your bios supports booting from usb, you can use one of the -memstick.img image files, located in the same area as where you got the .iso
when the kernel is tainted, it means that it is in a state that is not supported by the community
as you stated in your question, the main difference is the environment.  sudo su - vs
zsh doesn't have anything like closures or packages or namespaces
the common way of upgrading linux mint is the update manager, but there is always the lesser known alternative, using the command line
for:    add this to the .bashrc file  host='\033[02;36m\]\h' host=' '$host parse_git_branch () { git branch 2&gt; /dev/null | sed -e '/^[^*]/d' -e 's/* \(.*\)/\1/'; } time='\033[01;31m\]\t \033[01;32m\]' location=' \033[01;34m\]`pwd | sed "s#\(/[^/]\{1,\}/[^/]\{1,\}/[^/]\{1,\}/\).*\(/[^/]\{1,\}/[^/]\{1,\}\)/\{0,1\}#\1_\2#g"`' branch=' \033[00;33m\]$(parse_git_branch)\[\033[00m\]\n\$ ' ps1=$time$user$host$location$branch ps2='\[\033[01;36m\]&gt;'   this will work on both ubuntu and osx. note that i have to have the host 'built' on two lines to show the same way in both linux and osx
arcfour128 and arcfour256 are not supported by sun ssh on solaris 10.  try:  ssh -c arcfour256 somehost   you'll likely get: unknown cipher type 'arcfour256'  you will need to remove them from your ciphers list
it seems the virtual interface will not be running until a software is attached to it. as soon as my program (the simpletun.c example) attached to the interface, every thing became ok. 
you can't give a user access to “everything except for a few files”
looks like nobody knows a way of doing this, then.  instead, i just did what tomcat basically does; write a shell script and invoke this from my service instead of invoking java directly.  this shell script also takes care of creating the pid file using echo $! after starting the jvm
if your application is not interactive, you might launch a virtual x11 server and set the display variable for your application to use it.  possible x11 servers that can be used that way are:   xvfb xdummy xvnc   the latter allows you to connect later to see and interact with the screen with a vnc client (vncviewer).  if you raspberry pi (or similar) is configured to autologin the pi user under a graphical environment, you can start your application as the pi user and use the :0 display
$ ffmpeg -i source-file.foo -ss 0 -t 600 first-10-min.m4v $ ffmpeg -i source-file.foo -ss 600 -t 600 second-10-min.m4v $ ffmpeg -i source-file.foo -ss 1200 -t 600 third-10-min.m4v ...   wrapping this up into a script to do it in a loop wouldn't be hard.  beware that if you try to calculate the number of iterations based on the duration output from an ffprobe call that this is estimated from the average bit rate at the start of the clip and the clip's file size unless you give the -count_frames argument, which slows its operation considerably.  another thing to be aware of is that the position of the -ss option on the command line matters
du is disk usage, and it counts that amount of disk allocated to the file
root user is superuser on a unix/linux system
if you type a after g you will enter insert mode at the end of the last line.  if you just want to go to the last character, then g-end will suffice 
assuming you are using a linux distribution with udev support and you have root/administrator access to it then you can use udev rules to trigger on specific operations.  if the following example is added to a /etc/udev/rules.d/example.rules then it will run the specified script when a block device is added with the specified parameters.  action=="add", subsystem=="block", attrs{manufacturer}=="hitachigst", attrs{serial}=="31001206110000000000", run+="/a/script/to/run.sh"   that particular rule executes when my usb harddrive is inserted and attaches to the block system
the simplest way is to fill /tmp, assuming it is using tmpfs which is the default
looking at the developer documentation it doesn't look as if it was possible to use other directories than the default
find out the interface name, by running iwconfig  $ iwconfig eth0      no wireless extensions.  lo        no wireless extensions.  wlan0     ieee 802.11bgn  essid:"evancarroll"             mode:managed  frequency:2.437 ghz  access point: d8:50:e6:44:b2:c8              bit rate=19.5 mb/s   tx-power=15 dbm              retry  long limit:7   rts thr:off   fragment thr:off           power management:off           link quality=61/70  signal level=-49 dbm             rx invalid nwid:0  rx invalid crypt:0  rx invalid frag:0           tx excessive retries:1  invalid misc:80   missed beacon:0   in this case it is wlan0, then run iwlist &lt;interface&gt; freq,  $ iwlist wlan0 freq wlan0     13 channels in total; available frequencies :           channel 01 : 2.412 ghz           channel 02 : 2.417 ghz           channel 03 : 2.422 ghz           channel 04 : 2.427 ghz           channel 05 : 2.432 ghz           channel 06 : 2.437 ghz           channel 07 : 2.442 ghz           channel 08 : 2.447 ghz           channel 09 : 2.452 ghz           channel 10 : 2.457 ghz           channel 11 : 2.462 ghz           channel 12 : 2.467 ghz           channel 13 : 2.472 ghz           current frequency:2.437 ghz (channel 6)   none of these channels are outside of 2.4 ghz
if you wonder about the home directory, it should not matter that much, because it will probably not change the behavior of apache at all
your post-receive hook has some pretty dire caveats imo!  i have a similar setup, but server b has two copies of the repo
ok, this is relatively simple to solve.  you access your server with   ssh -l 5580:localhost:80 www.servername.tld   and you access your phpmyadmin via   http://localhost:5580/phpmyadmin/      because debian has placed it   if you would have m$, you can say this, but you have debian, so you can change the defaults as you need
debian (and hence probably ubuntu, too) has been known to ship a kernel with such a restriction of user_namespaces, and there the way to enable it was/is:  sysctl -w kernel.unprivileged_userns_clone=1   (source: https://blog.mister-muffin.de/2015/10/25/unshare-without-superuser-privileges/.)  alt has such a restriction in kernel-image-std-def, too
a hard link means you simply add a second name for exactly the same file
this is a history expansion problem
there're two reasons:   auto insert comment auto indenting   for pasting in vim while auto-indent is enabled, you must change to paste mode by typing:  :set paste   then you can change to insert mode and paste your code
#!/bin/sh #this is a process with an id of $$  ( sleep 1000 )&amp;               #this creates an idle child ( (sleep 1000)&amp; sleep 1000 )&amp; #this creates an idle child and grandchild wait                          #this waits for direct children to finish   running the above as ./1.sh &amp; on my system created the following process tree:  $ command ps -o pid,ppid,pgrp,stat,args,wchan --forest   pid  ppid  pgrp stat command                     wchan 24949  4783 24949 ss   /bin/bash                   wait 25153 24949 25153 s     \_ /bin/sh ./1.sh          sigsuspend 25155 25153 25153 s     |   \_ sleep 1000          hrtimer_nanosleep 25156 25153 25153 s     |   \_ sleep 1000          hrtimer_nanosleep 25158 25156 25153 s     |       \_ sleep 1000      hrtimer_nanosleep   you can notice that the tree has the same process group (pgrp) of 25153, which is identical to the pid of the first process. the shell creates a process group whenever you start a new command in interactive mode (or with job control explicitly turned on).  the pgrp mechanism allows the shell to send a signal to the whole process group at once without creating a race condition
i tried the following in my .bashrc:  echo -ne "$ps1" while ifs= read -er line;do     eval "time $line"     echo -ne "$ps1" done   this roughly does what you want with several caveats:   your prompt is practically ruined (the shell usually interprets sequences like \w and so on in your prompt before echoing it). you lose command line editing capabilities (e.g
use pushd and then the special names for the directories in your directory stack: ~1, ~2, etc.  example:  tmp $ dirs -v  0  /tmp  1  /tmp/scripts  2  /tmp/photos  3  /tmp/music  4  /tmp/pictures tmp $ cd ~3 music $ dirs -v  0  /tmp/music  1  /tmp/scripts  2  /tmp/photos  3  /tmp/music  4  /tmp/pictures music $ cd ~2 photos $ cd ~4 pictures $ cd ~3 music $ cd ~1 scripts $    the most effective way to use pushd in this way is to load up your directory list, then add one more directory to be your current directory, and then you can jump between the static numbers without affecting the position of the directories in your stack.    it's also worth noting that cd - will take you to the last directory you were in
what you have read is true
i was able to delete these snapshots by first mounting the whole btrfs volume (not the @ subvolume) and then working from there:  # mount /dev/mapper/whatever /mnt -o subvol=/ # ls /mnt @ @apt-snapshot-2013-04-17_21:44:30 ...   so at this point, all subvolumes (including the funky apt-snapshot ones) are visible in /mnt, so we can delete them:  # btrfs subvol delete /mnt/@apt-snapshot-2013-04-17_21:44:30 # umount /mnt  
you need to make sure that the service starts at boot
i guess the problem is execstart=~/landportsserver
sudo sh -c 'echo "some words" &gt;&gt; /etc/apt/source.list'  the reason sudo echo "some words" >> /etc/apt/source.list doesn't work is because sudo is raising the privileges of the 'echo' command, and not the redirection.  the >> redirection causes the current shell to create/append to the file
function  they mean different things
this is described in the arch wiki:     create a new service file similar to getty@.service by copying it to /etc/systemd/system/  cp /usr/lib/systemd/system/getty@.service /etc/systemd/system/autologin@.service    this basically copies the already existing getty@.service to a new file autologin@.service which can be freely modifed
~/.screenrc is the user-specific configuration file for gnu screen
to change the partition table you can use fdisk;   fdisk /dev/sdb d = delete (delete until all current partitions are gone) n = new p = primary 1 = 1st partition just hit enter twice for the size (it will use the whole space) t = type (change parition type) 1 = partition number to change b = win32 fat w = write (write parition table to disk)   to create a new filesystem on the disk (this bit is the format / overwrite), use mkfs.  $ mkfs.fat /dev/sdb1   edit: changed from ext4 as an example to fat32
there are three ways to do it    ctrl + a + " will give you a graphical list of your windows that you can scroll around in. ctrl + a + ' will give you a prompt to type a screen number. ctrl + a + n (or p) will take you next window, let us say you are on window 9 and if you press this, it will take you to next (or previous) window  
ok after fiddling around the system i found that startlxde-pi exists so and it is actually what launches the default raspbian session (with openbox)
if you'd put the / partition at the end of sda, you'd have a trivial upgrade process:   shut the vm down, and resize the raw disk drive in the vm management interface. boot into single user mode, resize the last partition to extend over the new space. resize the filesystem.   doing this to a partition sandwiched between two others is probably more trouble than it's worth.  therefore, i recommend that you move part of the contents of your / partition to a new disk:   shut the vm down, and add another virtual disk.  size it to hold the existing contents of / that you want to move to the new disk, plus however much space you want left over
there are too many sources of information to list in this page:   the command echo -e uses an extension to render \e as ascii 27 (octal 33 or "\033")
libgcc is even more fundamental than libc
for a start, you've got the vm configured to be emulating an ide bus, which is pretty slow
gnuly:  s1='token1, token2, token3, token4, token5, token6, token8, token9, token10' s2='token2, token7, token4, token3, token5, token6, token8, token10, token9' comm &lt;(grep -oe '\w+' &lt;&lt;&lt; "$s1" | sort) &lt;(grep -oe '\w+' &lt;&lt;&lt; "$s2" | sort)   gives:  token1                 token10                 token2                 token3                 token4                 token5                 token6         token7                 token8                 token9   the columns are:   tokens only in s1 tokens only in s2 tokens in both.   you suppress a column by passing the corresponding option (like -3 to suppress the 3rd column). 
the switch to touch, -r uses whatever file you provide it as a reference for what timestamp to use
you can test it (and operate on the file if test holds true) in this way:  if [ $(((`date +%s` - `stat -c %y iostatdisk2.log`) / 60)) -ge 55 ] then     echo "file was modified more than 55 minutes ago"    # do something with the file... fi  
i don't think there's a single-step way to do it with klipper alone
your question doesn't explicitly say what you want to do, but i guess you want to use that spare 11gb of space to expand /dev/sda6
using xrandr  overlapping screens can be achieved by changing their position using the following command:  xrandr --output (screen indicator) --pos (x coord)x(y coord)   example:  xrandr --output dvi-d-0 --pos 0x0 xrandr --output hdmi-0 --pos 0x768 xrandr --output dvi-i-0 --pos 0x768   this results in dvi-d-0 screen being at the top and hdmi-0 with dvi-i-0 being at the bottom, overlapping.  you can find out screen's indicator using:  xrandr -q   nvidia x server settings  the required behaviour can also be achieved using nvidia x server settings. simply drag and drop the screen's box onto each other for them to operate in a mirror mode.   
it sounds to me like the problem host does not have a correctly configured nsswitch.conf.  the hosts line of /etc/nsswitch.conf should look something like this:  hosts:  files nisplus nis dns   however, the exact contents will vary due to your environment
it turns out the sound stack developers have anticipated me and written a workaround specifically for situations like mine - i just wasn't able to find it at first
a partition can be mounted in multiple paths, but the lsblk will only show one
this was a very basic mistake
hard links to directories aren't fundamentally different to hard links for files
from wikipedia:     on unix and unix-like computer operating systems, a zombie process or defunct process is a process that has completed execution but still has an entry in the process table
if you want to use perl-like regular expressions, why not use perl (which is found on 99% of non-embedded unices)?  like:  perl -lne 'print for /(http.*?)\$/'  perl -lne 'print for m{database\s*=\s*mysql://([^:@]+):([^@]+)@([^/]+)/(\s+)}i'   /.../ is the shorter form of m/.../
in your terminal, klick edit > profile preferences > colors  see the text and background color uncheck the use colors from system theme and set the build-in schemes: to: gray on black   
not sure about osx, but hopefully it's unix-y enough...  in your $home/.bashrc add the following line:  export manpager=cat   if you want all of your paging programs to act in this way, set pager instead
   can i list the filesystems a running kernel can support?   well, answer /proc/filesystems is simply wrong — it reflects only those fses that are already brought in use, but there're usually a way more:  ls /lib/modules/$(uname -r)/kernel/fs  another source is /proc/config.gz which might be absent in your distro (and i always wonder «why?!» in case). 
one simple solution is to go to about:preferences#advanced and in the advanced page, tab general,  accessibility, select search for text when i start typing
your error is here:  if [ dir eq $1 ]   you are not using the variable, that's the simple string dir
launch sudo nano /etc/default/grub  find the line which now says  grub_cmdline_linux_default=”quiet splash”    and revise it to read  grub_cmdline_linux_default=”quiet splash text”    then run sudo update-grub  your next boot will bring you to the command line interface (cli). 
non-chroot access  if you don't have a ftp server setup, and you trust the user that will be logging in, not to go poking around your server too much, i'd be inclined to give them an account to sftp into the system instead.  the centos wiki maintains a simple howto titled: simple sftp setup that makes this pretty pain free.  i say it's pain free because you literally just have to make the account and make sure that the firewall allows ssh traffic, make sure ssh the service is running, and you're pretty much done.  if sshd isn't already running:  $ /etc/init.d/sshd start   to add a user:  $ sudo useradd userx $ sudo passwd userx ..
what you are seeing when you rerun a du command is the effect of disk buffering
you can access this via the forward-search-history function which is bind per default to ctrl+s
in your first example, what i think you are referring to is the "media wearout indicator" on intel drives, which is attribute 233
probably, you can not
i am sorry, i failed to mention that i was using oracle solaris 11.  in this release, none of these come installed by default (used the text installer)
command substitution removes trailing newlines, so $(printf '\n') is the same thing as $(printf '\n\n\n\n'), namely the empty string.  to include a newline in a string, put it bewteen single or double quotes.  for i in 1 2 3; do   foo="$foo $i" done   you may find it less ugly to define a variable to store just a newline.  nl=' ' for i in 1 2 3; do   foo="$foo$nl$i" done   in ksh93, bash, freebsd sh, mksh and zsh, but not plain sh (yet), you can also use dollar-single-quote, which allows backslash escapes.  for i in 1 2 3; do   foo="$foo"$'\n'"$i" done  
you can use the command vorbiscomment to read, modify and delete the metadata on a ogg vorbis file
the only difference between using copy and run are the permissions on the /etc/crontab file: with copy this is 664 and with run 644
by default, grep uses basic regular expressions, you need to escape the braces to make grep match multiple characters:  grep 't\{2\}' textfile   alternatively, you can use the -e option (or -p option for gnu grep, which uses perl compatible regular expressions) making grep use extended regular expressions, which can use braces without escaping them:  grep -e 't{2}'  
an awk solution:  awk '!a[$0]++'  
there is a setting /desktop/gnome/lockdown/disable_user_switching in gconf that allows you to disable the user switching.  you can change this setting by running gconf-editor from the alt+f2 "run" dialog (depending on your distro, it might also be available somewhere in the menus). 
i could fix it on my machine by sourcing /etc/x11/xinit/xinitrc.d/50-systemd-user.sh from ~/.xinitrc. the solution was found on https://bugs.archlinux.org/task/46374 because journalctl --this-boot --no-pager | grep -i warning showed, that 'org.gnome.keyring.systemprompter' failed.  reference 
use the escape character \ like this:  ./mjpg_streamer -i \"./input_uvc.so -r 320x240\" -o \"./output_http.so -w ./www\"  
seeing that any command you type takes more keystrokes i recommend ctrl d , ctrld, which takes you out of both sessions. 
you want the -r switch to less.  from the less man page:     -r or --raw-control-chars         like -r, but only ansi "color" escape sequences  are  output  in         raw" form
no: it is unspecified which of the two normal results would be returned
   what are these files?   the $project/t directory is the canonical place for a project to keep its automated unit tests.     how come the folder doesn't have a more descriptive name?   by adhering to what is basically a standard naming convention, it is perfectly descriptive of what files go into this directory.  other programmers will expect to find a /t subdirectory containing unit tests
using grep + sed  this will parse the contents of those 2 strings:  $ grep -o '".*"' somefile | sed 's/"//g' arch arch2   the above looks for a string matching the pattern ".*"
yes, it's always a very good idea to have an unprivileged account on the system to use when you do not need admin privileges
$ tr ' ' '\n' &lt; file | grep word | wc -l   where tr replaces spaces with newlines, grep filters all resulting lines matching word and wc counts the remaining ones.  one can even save the wc part using the -c option of grep:  $ tr ' ' '\n' &lt; file | grep -c word   the -c option is defined by posix.  if it is not guaranteed that there are spaces between the words, you have to use some other character (as delimiter) to replace
reading through man 5 systemd.unit and man 5 systemd.target tells us that unit files are used to define targets as well as everything else systemd
this is actually a good idea when you have more than one nameserver set in your resolv.conf
i (finally) tested it in fedora rawhide
you have to export $(dbus-launch) and set the gsettings backend (tested  on archlinux with gdm 3.18.2):   switch to a vt (e.g
as long as you've edited a history entry but not pressed enter yet, to go back to the original entry, repeatedly press ctrl+_ — the undo command — until it doesn't make any further change
ok first you want to open your activities (super ( windows )+q) unlock widgets, and create at least one other activity
only interactive shells read a file that may contain alias definitions
iptables -l -n -v  see also this article: http://greenmice.info/en/node/127, there are some other tips. 
try going to /home/@user/.config/ and remove the whole deadbeef folder to reset
the "root" group doesn't serve a special purpose so much as it serves a general purpose - every file has to be owned by a user and a group, and "root" is there as sort of a default group for root user owned files that don't fall into other categories such as wheel (semi-old school) or bin
there are two traditional printing interfaces in the unix world: lp (the system v interface) and lpr (the bsd interface)
as per the grub manual:     ‘grub_default’      .................      if you set this to ‘saved’, then the default menu entry will be that saved by ‘grub_savedefault’, grub-set-default, or grub-reboot.        ‘grub_savedefault’      if this option is set to ‘true’, then, when an entry is selected, save it as a new default entry for use by future runs of grub
yes, the minimum size is one physical extent
there's a command called file that makes (good but not always perfect) guesses about the file type
dhag was on the right lines
i usually get this when i've used pip to install/upgrade dnspython
if you have gnu uniq, you can sort case insensitively (-i), and use -d to print only duplicate lines:  find 
you can touch a hidden  file, eg.filename, after formatting the filesystem and use the unless parameter of exec, cat .filename in your unless parameter
you can't use yum command with regular user like tom, yum command just can be used by root power and if you have install a package with yum, every user can use it
just right click on the icon, choose properties and then click on the icon's image and browse to select the icon you want to use
trim does at least three things:   minimize write amplification prevent long-term performance degradation irrecoverably delete your data   now it depends where your priorities are.  for 1), you should not be using fstrim at all, but make use of the discard option of your filesystem
this is actualy far easier than you'd think
when you close a gnome terminal window, a sighup is sent to the shell that it was running
date +%s.%n will give you, eg., 1364391019.877418748
from here (centos.org)   useradd (which is the actual binary the runs when you call adduser, it just behaves differently
you can use gconftool-2 - gnome configuration tool
you lack the make command
you can do this using bsdtar:  ire@localhost: bsdtar -cvf pax.tar --format=pax @gnu.tar ire@localhost:file gnu.tar gnu.tar: posix tar archive (gnu) ire@localhost:file pax.tar pax.tar: posix tar archive   @archive is the magic option
because you don't use -t option (or -b with gnu sort), so you must count from beginning of leading spaces
you might be interested in jwz's kiosk hack - at the very least, it's an interesting read. 
the problem is that while doing bash -c '....', you are spawning a non-interactive (and non-login) session of bash, which will not source any runtime configuration file e.g
the simplest way to do this would be to overwrite the entire drive with zeros.   dd if=/dev/zero of=/dev/sdx bs=1m   just know that once you execute that, there's no going back
as stated in the manual sort "sort[s] lines of text files"
i did find the answer
ls does not directly support sorting by permissions, but you can combine it with the sort command:  ls -l | sort   you can use the -k option to sort to start matching from a specific character, the format is -k field.char, the permissions are the first field in the ls output
the following rules will allow all outgoing connections, but block any incoming connections
libncurses-dev is what you want.  additionally, you may be interested to know that you can install all the current prerequisites with contrib/scripts/install_prereq
you should try goobook, it supports oauth2 and also has a query command which prints what you've searched to stdout  $ goobook query foo foo@bar.com     joe 'foo' smith      group name   it also creates a cache file with i don't know which format which dumps all the address book in a one place whenever you want.  it's probably worth adding that goobook dump_contacts seems like the best answer for an automated backup, it dumps all information about all contacts to stdout in some form of atom feed. 
you can try running zypper in the verification mode:  zypper verify -d   that should report any inconsistencies in package dependencies
you can get a list of these interfaces on most systems from the following:  ls -a /sys/class/net   but beware of parsing the output from ls in your script
first of all, sed 's/\us/…/' doesn't search for \us; it searches for us.  to search for \us, you need to use sed 's/\\us/…/'.  if you're searching for a string with special characters in it, and then adding something to it, a useful technique is to use the &amp; character to refer to the string that you searched for.  so, for example,  $ sed -i 's/\\us/&amp;x/' test   in general, &amp; (sometimes called the "find what") represents that portion of the pattern space that matched your search string.  this is more useful when the search string is a non-simple regular expression; e.g.,  $ echo you say goodbye and i say hello
generally speaking, don't install locally-built stuff directly under /usr, only under /usr/local
pretty sure the base64 string is just a cover up and is never run
in my experience the proprietary linux driver that nvidia offers can cause terrible performance issues with certain cards (especially older ones)
to quote my own post from meta:  linking to man pages  i already have a favored method for this, which you can read about in the less man page in two places:  less='+/\+cmd' man less   and  less='+/less[[:space:]]*options' man less   (see what i did there?) 
typically a linux kernel crash would be visible on the system's console
[test1@jsightler ~]$ id -z unconfined_u:unconfined_r:unconfined_t:s0:c2   not an expert, but that doesn't look like a confined user to me
use -n for no-recurse:  $ ack -n foo   grep is not recursive by default, and you should use the -r flag only if you want a recursive search
use negative increment  seq -s, 10 -2 1 10,8,6,4,2  
atom uses the stable branch for its stable release builds, so to find the latest tag for a release you need to check that branch:  $ git describe --tags stable v1.4.2-1-ge9db64c   to retrieve the corresponding tag, keep everything up to the first -:  $ git describe --tags stable | cut -d- -f1 v1.4.2   to get the version without the leading v, strip that off:  $ git describe --tags stable | cut -d- -f1 | sed 's/^v//' 1.4.2  
since you have two commands, it would be better to use:  { make clean &amp;&amp; make disable_id3tag=1 cflags="-o2 -dndebug -w64"; } 2&gt;&amp;1 | myprogram   or  ( make clean &amp;&amp; make disable_id3tag=1 cflags="-o2 -dndebug -w64" ) 2&gt;&amp;1 | myprogram   the make clean is not directing its output to the pipe, you will want to use either of the two above to let the shell redirect the output of both make calls as one. 
(where input is a file containing the text to repeat)  with gnu awk (and assuming the input doesn't contain nul bytes):  awk -v n=100 -v rs='\0' -v ors= '{while (n--) print}' &lt; input   portably:  awk -v n=100 -v ors= '   {all = all $0 rs}   end {while (n--) print all}' &lt; input   (note that if the input didn't end with a newline character, one will be added).  you can also do things like:  set -- n=100; while [ "$n" -gt 0 ]; do   set -- "$@" input   n=$((n - 1)) done cat "$@"   that one will work regardless of what byte input contains
you can use :file newname to change the buffer name.  from :help :file_f:     sets the current file name to {name}
i'm not sure how standard it is, but at least in ubuntu systems sudo sets the following environment variables (among others - see the environment section of the sudo manpage):     sudo_uid        set to the user id of the user who invoked sudo     sudo_user       set to the login of the user who invoked sudo   for example,  steeldriver@lap-t61p:~$ sudo sh -c 'whoami' root steeldriver@lap-t61p:~$ sudo sh -c 'echo $sudo_user' steeldriver  
the set command shows all variables (and functions), not just the exported ones, so   set | grep euid   will show you the desired value
it does not really make sense to bind the command prefix to another key in such a way that it goes away (changing the prefix, however, is common; many people prefer c-a)
it will not make a real difference, in the sense that if you run screen (or tmux) and you disconnnect there will be nohup signal sent to your application whether you start it with nohup or not.  i suggest you try it out by using screen/tmux and just start the program without nohup
you can use this one liner to do what you're asking:  $ cmd="..some command..."; for i in $(seq 5); do $cmd; sleep 1; done   example  $ date fri nov 22 01:37:43 est 2013  $ cmd="echo"; for i in $(seq 5); do $cmd "count: $i"; sleep 1;done count: 1 count: 2 count: 3 count: 4 count: 5  $ date fri nov 22 01:37:51 est 2013   you can adjust the sleep ... to what ever delay you'd like between commands, and change cmd=... to whatever command you want.  brace expansions vs
on “client” machines, the safe way to move /tmp is to reboot
one way:  #!/bin/bash cd ~/b for file in ~/a/* do     file1=$(basename "$file")     [ -f "$file1" ] &amp;&amp; { echo "deleting $file1 "; rm -- "$file1"; } done  
pressing alt+f2 and then enter cinnamon --replace might fix it. 
the menu configuration can be found in  /etc/xdg/menu/   a more detailed description is the gnome desktop menu specification
sometimes it's enough to read man bash:     funcname      an array variable containing the names of all shell                 functions currently in the execution call stack
if you use the command   exim -bp    you will get a list of all messages currently in the queue
#locate my.cnf   this command will help you to find the path of the file. 
preventative measures  if you want to run a command without saving it in history, prepend it with an extra space  prompt$ echo saved prompt$  echo not saved \ &gt; #     ^ extra space   for this to work you need either ignorespace or ignoreboth in histcontrol
grep -i 'a' is equivalent to grep '[aa]' in an ascii-only locale
you can use --ssh_args where you can accommodate your path to your key (-i ~/.ssh/co-user.  running csshx--ssh_args "-i ~/.ssh/co-user" --login co_user co_user@10.32.189.44 should do the job. 
i assume you want to add a border of, say 30px, on all four sides
add it to your /etc/fstab:  tmpfs   /mnt/tmpfs  tmpfs   defaults,size=1g,mode=1777  0 0   you may also need to rebuild your initramfs, e.g.:  sudo update-initramfs -u -k $(uname -r)   or, to rebuild the initramfs for all kernels:  sudo update-initramfs -u -k all   btw, tmpfs doesn't reserve any memory - a tmpfs filesystem only uses as much memory as required by the files it contains (and any file/directory overhead). 
you can pipe the output in to wc
the strings inside single quotes are used verbatim by the shell (and hence cannot contain other single quote, since that would be treated as the closing one of a pair)
cd $home more &gt;&gt; .bashrc &lt;&lt; 'eot' ps1='\n$user:$pwd&gt;' ; export ps1 eot   this will do it permanently for all your future terminal and console sessions.  to refresh your current sessions with this setting :  
all modern cpus have the capacity to interrupt the currently-executing machine instruction
pulseaudio is not gnome-specific, but if i interpret your question correctly, you're looking for kde tools to configure pulseaudio
rsync -avz --delete "/home/user/a" "/home/user/b"   explanation by sonicarg  -a do the sync preserving all filesystem attributes  -v run verbosely  -z compress the data during the sync (transport the data in compressed mode)  --delete delete the files in target folder that do not exist in the source, /home/user/a: source folder, /home/user/b: target folder 
your ps3 is probably putting out an hdcp-protected video signal
regarding your second option, of creating a vmware image..
" a syntax for placeholders " pressing control-j jumps to the next match. inoremap &lt;c-j&gt; &lt;esc&gt;/&lt;++&gt;&lt;cr&gt;&lt;esc&gt;cf&gt; " completions using placeholders inoremap ) )&lt;++&gt;&lt;esc&gt;f)i inoremap ] ]&lt;++&gt;&lt;esc&gt;f]i inoremap } }&lt;++&gt;&lt;esc&gt;f}i   add those it your .vimrc it should work 
in the case of your particular script, neither myscript nor command d will ever be executed
you can generate the public key using ssh-keygen -y
i found a simple solution:  add this normal user to the lpadmin group:  sudo usermod -a -g lpadmin joe   (fwiw&lt; i had previously used visudo to give joe sudo rights to /usr/bin/kde-print-queue and i did not revoke that privilege.)  
have you tried acpipowerbutton from this command set?  vboxmanage controlvm        &lt;uuid&gt;|&lt;name&gt;                             pause|resume|reset|poweroff|savestate|                             acpipowerbutton|acpisleepbutton|   edit after reading the comments:  you can use acpid or other acpi utilities to make it graceful
you need to use an ssh agent
this link provides the details on how to do this, titled: [change file associations in mac os x]]1.  excerpt of details from that link     note this will impact all of a certain file format type, meaning changing this for one pdf will impact all pdf’s, and so on.         find the file type(s) that you want to change the application to open with   get info about a file that is of that file type, say a .mov   click the ‘open with’ arrow to expand an application list   choose the application you want all files of this type to open with (in this example we’ll use vlc to open all .mov files)   click “change all” and then “continue” when the confirmation dialog appears         &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;      note: now all of the files of that type will open in the application you specified
that doesn't seem to be possible using smbclient (from samba 3.x), but it should work using smbclient4 (from samba 4.x). 
sure this should work.  but you make sure by check with 'stat' command.  sh-4.3$ stat test.csv                                                               file: 'test.csv'                                                                  size: 871             blocks: 8          io block: 4096   regular file            device: 20fd4bh/2161995d        inode: 8389896     links: 1                         access: (0644/-rw-r--r--)  uid: ( 1000/      cg)   gid: ( 1000/      cg)            access: 2016-01-06 05:29:32.220197637 +0000                                         modify: 2016-01-06 05:29:32.220197637 +0000                                         change: 2016-01-06 05:29:32.220197637 +0000                                         birth: -                                                                           sh-4.3$                                                                              
/run/user/$uid is created by pam_systemd and used for storing files used by running processes for that user
you can shred everything while it's mounted
all the apps you've mentioned are gtk+ apps so it's quite easy to answer why..
you can change the action associated with a key using xmodmap
there's a known issue with tcpdump where if it fails to write to the output file (e.g
use exec to replace bash with java:  [program:programname] command=bash -c "source /path/to/env/file &amp;&amp; exec java -jar /path/to/jar.jar"   in such a case you will have only one process to be killed. 
this is just a workaround to the problem
use yes:  yes | sudo gem uninstall --all  
awk -f / '{ print $4; }'   will give you the second entry in the path
unfortunately, your first request is not possible
if [ "$target" = m ] || [ "$target" = m ]; then    cut -c12-26,31-43 emplist &gt; names fi if grep -qfe "$name" names; then   echo "$name" else   echo &gt;&amp;2 "no such player"; fi  
it seems we cannot switch a linux partition online while there is opened file. 
you can use:  xmodmap -e 'pointer = 1 2 25 4 5 6 7 8 9'   in order to disable the right button of your mouse (setting the third number to value higher then 10 bind the right button to no action). put this line in the .bash_profile of the user you want to block the right click use 
you can define a variable, and use a $ to recall its value:  apachelog=/var/log/apache2/error_log tail -50 $apachelog   you're not going to do better in bash
if you add the share to fstab you should be ok, but remember you need to have a network connection before you actually mount the drive
you can use cron if your version has the @reboot feature
you could achieve required result by using a systemd unit as below:  [unit] description=service to run on shutdown before any other services after=default.target  [service] type=oneshot execstart=/bin/true execstop=/opt/demo.sh remainafterexit=yes timeoutstopsec=0  [install] wantedby=default.target   systemd stop's services based on their dependency in reverse order
the simplistic approach would be to just use sed and replace the string with the correct one
after learning that tesseract can now also produce searchable pdfs, i found the script sandwich: http://www.tobias-elze.de/pdfsandwich/  after installing ocaml  sudo dnf install ocaml   i followed the script's guide for compiling from source     compile from sources      pdfsandwich is open source software (license: gpl)
apt-get update is the way i'd do it
this seems like an appropriate use of /etc/rc.local to me
use badram kernel patch.. it allocate memory on certain address so it could not be used.  http://rick.vanrein.org/linuxa/badram/  http://blog.eracc.com/2011/02/02/linux-with-badram-saves-the-day/  or badmem  http://badmem.sourceforge.net/docu/badmem-howto.html  or turn of address after certain point  http://gquigs.blogspot.com/2009/01/bad-memory-howto.html 
according to the developer1, this isn't currently possible in tmux.  [1] http://sourceforge.net/mailarchive/message.php?msg_id=27427973 
first that you need to do is convert pdf file into series of images - one image for one page
openbsd packages are not 'signed' at all by default.  if you are using openbsd in commercial environment, let your employer to buy release cd
grep -f &lt;(sed 's/.*/\^&amp;\\&gt;/' town-list.txt) ma-towns.txt   explanation:  grep -f file reads file for a list of patterns to match against
on command line, vim/tmux is probably the closest you'll come
the learning bash book is wrong
for gnu utilities, the full documentation is in the info page, where you can read:     -f    ignored; for compatibility with bsd versions of `touch'.   see historic bsd man pages for touch, where -f was to force the touch.  if you look at the source of those old bsds, there was no utimes() system call, so touch would open the file in read+write mode, read one byte, seek back and write it again so as to update the last access and last modification time.  obviously, you needed both read and write permissions (touch would avoid trying to do that if access(w_ok|r_ok) returned false)
awk can do effectively the same as perl here a little simpler, although implementations other than gnu may waste a little cpu time unnecessarily splitting the (large?) text file:  awk 'nr==fnr{a["\\["$1"\\]"]="["$2"]";next} {for(k in a) gsub(k,a[k]);print}' key.txt essay.txt   since you asked for explanation:   awk operates by taking a 'script' consisting of pattern-action pairs, then reads one or more files (or standard input) one 'record' at a time where by default each record is a line, and for each record splits it into fields by default at whitespace (which includes tab) and applies the script by in turn (unless directed otherwise) testing each pattern (which often looks at the current record and/or its fields) and if it matches executing the action (which often does something to or with said record and/or fields)
you can't use the return code of read (it's zero if it gets valid, nonempty input), and you can't use its output (read doesn't print anything)
[ is not a "special builtin", and according to posix a utility syntax error (option or operand error) of a non-special builtin shall not exit a non-interactive shell ("script").  so much as for why the shell does not exit
the answer is (or at least starts) in fs/proc/base.c (unchanged from kernel 3.12 to 4.2 at least)  742 static int proc_pid_permission(struct inode *inode, int mask) 743 { 744         struct pid_namespace *pid = inode-&gt;i_sb-&gt;s_fs_info; 745         struct task_struct *task; 746         bool has_perms; 747  748         task = get_proc_task(inode); 749         if (!task) 750                 return -esrch; 751         has_perms = has_pid_permissions(pid, task, 1); 752         put_task_struct(task); 753  754         if (!has_perms) { 755                 if (pid-&gt;hide_pid == 2) { 756                         /* 757                          * let's make getdents(), stat(), and open() 758                          * consistent with each other
sed '/p1/,/p2/!d;/p2/q'   ...would do the job portably by deleting all lines which do !not fall within the range, then quitting the first time it encounters the end of the range
if the partition is larger than the filesystem, you can use resize2fs to expand it:     if size parameter is not specified, it will default to the size of the partition.   so it'd just be  [#]&gt; resize2fs /dev/sdb1  
with gnu tools:  grep -rlz --include='*.py' -e 'import project.path.util' \                            -e 'from project.path.util import.*\bfoo\b' 
one reason why some firmwares aren't packaged/included is that sometimes there is no license that allows that, or there is a license that doesn't allow that.  it seems like in this case, the author of the driver has permission to distribute those files, but there is no info about redistribution (so somebody should ask mustek for a license that clearly states that is allowed). 
there's no standard command to enumerate all existing user accounts
&gt; redirects output to a file, overwriting the file
by default sshd uses ipv4 and ipv6
there may be many ways of doing this, but in awk we can do something like  awk 'gsub(/^[0-9.]+ \[ /,$1 " ") { a=2; while (a&lt;=nr &amp;&amp; $a != "]") { if ($a !~ /=/) {print $1 " " $a } ; a++ } }'   let's break this down into something more readable:  gsub(/^[0-9.]+ \[ /,$1 " ") { ...
you can do this with find, but to do it robustly you will need to embed a shell one-liner as well
cryptsetup luksdump /dev/fedora/01 shows the lvm logical volume to be a luks encrypted volume
try this (gawk is needed).  awk '{a=gensub(/.*#([0-9]+)(\").*/,"\\1","g",$0);if(a~/[0-9]+/) {gsub(/[0-9]+\"/,a+11"\"",$0);}print $0}' yourfile   test with your example:  kent$  echo '(bookmarks ("chapter 1 introduction 1" "#1" ("1.1 problem statement and basic definitions 2" "#2") ("exercises 30" "#30") ("notes and references 34" "#34")) ) '|awk '{a=gensub(/.*#([0-9]+)(\").*/,"\\1","g",$0);if(a~/[0-9]+/) {gsub(/[0-9]+\"/,a+11"\"",$0);}print $0}'    (bookmarks ("chapter 1 introduction 12" "#12" ("1.1 problem statement and basic definitions 13" "#13") ("exercises 41" "#41") ("notes and references 45" "#45")) )   note that this command won't work if the two numbers (e.g
you can use ssh's -w option to achieve this
i have just tried looking at the link in the thread you pointed to (btw next time please include such links so that it's easier for others to look at your problem) and everything is working fine
the main loop of gnu cat, in the simplest case is (function simple_cat from cat.c):  while (true)     {         /* read a block of input
you can change the language by generating a file ".i18n" in your home directory
in a strict sense a binary file is one which is not character encoded as human readable text
the tar file is extracted until it finds the marker indicating the end of tar file: physically, an archive consists of a series of file entries terminated by an end-of-archive entry, which consists of two 512 blocks of zero bytes from the tar file format description here.  so your archive file probably has material after the marker that does not get extracted. 
make a copy of your mbox to maildir format, for example using this perl script or the terminal mail client mutt(1)
use unset as last line in your .bashrc:  unset -f do_stuff   will delete/unset the function do_stuff.  to delete/unset the variables invoke it as follows:  unset variablename  
once you've mounted the disk on your desktop use the mount command to get hold the partition and disk the ntfs filesystem is
if there is no matching filename, then a wildcard expression in bash expands to itself
to see the device description for the controller (assuming an internal (pci) controller), which usually contains sata for sata controllers:  lspci -d $(cat /sys/block/sda/device/../../../vendor):$(cat /sys/block/sda/device/../../../device)   if you want to type less, just browsing the output of lspci is likely to give you the answer in a laptop (many desktop have both kinds of interfaces so you'd have to look up the drive you're interested in).  if that doesn't give you the answer, to see what driver is providing sda (you can then look up whether that driver is for a pata or sata controller):  readlink -f /sys/block/sda/device/../../../driver  
if you run emacs foo.spec that will create a spec file with the basic layout
yes
automatically load cards using udev  the pulseaudio module responsible for automatically loading a sound card recognized by alsa is module-udev-detect on sytems supporting udev
echo "type one of the following words:" echo "even, odd, zero, negative" while :; do   read varword   varword="${varword,,}" #downcase it   case "$varword" in     even|odd|zero|negative)       echo "the approved word you have selected is $varword, great work! "; break;;     *)       echo "the unapproved word you have selected is $varword, please try again.";;   esac done  
unzip &lt;target-zip-file&gt; '&lt;folder-to-extract/*&gt;' -d &lt;destination-path&gt;    works fine on el 6 
you can unpack .deb files using the ar command (since .deb files are ar archives).  ar x file.deb  will start the process
you could use sed like this:      sed 'h;s/,[^|]*//g;x     /,/{s/|[^,|]*,*/|-/g;h;}     x;s/-\([^|]\)/\1/g;p;d'   it wound up being relatively simple after all
the 32-bit version works on all pcs, the 64-bit version only works on pcs with a suitable processor
this sounds like a job for find.   use -maxdepth to only return the current directory, not recursivly search inside subfolders use -type f to only return files and not directories or device nodes or whatever else use a combination if -not and -name to avoid the files with names you don't want   it might come together like this:  find /path/to/uploads -maxdepth 1 -type f -not -name 't_*'  
the fedora packaging guidelines have a draft document explaining how to handle selinux in packages, and they use semanage
bc is truncating, try this instead:  printf "%.3f\n" $(echo "$equ" | bc -l)  
you can shrink your existing filesystem and partition to make room for other partitions, then copy your files
a perl solution:  $ perl -lne '$k{"$_:"}++ for split(/\b/); push @l,$_; }{    map{s/\s+:/$k{$&amp;}&lt;2 ? " " x length($&amp;) : $&amp;/e; print}@l;' file      0f a2                   cpuid        a9 01 00 00 00          test   eax,0x1      74 01                   je     a &lt;myfunc+0xa&gt;      c3                      ret     a:   0f 0b                   ud2a   this is equivalent to:  #!/usr/bin/perl use strict; my %wordshash; my @lines; ## read the input file line by line, saving each ## line as $_
no, it can't fully automatically infer dependencies.  if it had been packaged, apt-get build-dep oprofile would have helped
if you had syntax errors in that script, you'd see them on stderr
there are two mechanisms for fonts in x land: server-side and client-side.  the traditional way to render fonts is for the client to tell the server “render foo at position (x,y) in font f” (where a font specification includes a face, size, encoding and other attributes)
i am not entirely sure why, but you need some extra escapes
(this is not a real answer, more a bunch of suggestions - but it's too long to fit into a comment.)  the command xdpyinfo provides a list of x server features, including the list of all registered extensions and visuals; you could start by comparing that.  however, your hint that re-enabling backingstore fixes the problem makes me suspicious that this is a client problem: that the client makes some wrong assumption on the x11 workings, or somehow violates the icccm (java is notorious for this) and thus is broken by a newer version of x11 that changed some defaults...  two tentative workarounds:   run x11vnc on the node where the application resides, and then connect to that over vnc from the newer hosts; you can size the x11vnc screen appropriately so to reduce bandwidth consumption. run xnest on the newer nodes and let the troublesome application connect to the xnest display; you should be able to compile a version of xnest old enough to be compatible with the application.  
gnu unifont has the widest unicode support
to make sure the cron daemon is running and honouring the crontab, you could make a small test
you said bash, so let's do it all with shell builtins:  $ inp="cop1010 add atra522,allison track,ct,canada" $ ifs=, fields=($inp) $ echo ${fields[0]} cop1010 add atra522 $ echo ${fields[1]} allison track $ echo ${fields[2]} ct $ echo ${fields[3]} canada $ ifs=\  cmd=(${fields[0]}) $ echo ${cmd[0]} cop1010 $ echo ${cmd[1]} add $ echo ${cmd[2]} atra522 $    you can set them all as variables (instead of echoing them), and never need to spawn a subshell to run awk, cut, or any other tool. 
you missed @ character before unix timestamps, try:  date +%s -s @1371729865  
rather use a variable to define the base directory.  code_base="/home/me/code/" alias c1="cd $code_base/php" alias c2="cd $code_base/jquery" alias c3="cd $code_base/ruby" alias c4="cd $code_base/c"  
you can grep for an eol along with your real query (if you already have an alias for grep to use --color, as is default in many distributions, you can omit it in the following examples):  grep --color=auto 'word\|$' file   since the eol is not a real character, it won't highlight anything, but it will match all lines.  if you would prefer not to have to escape the pipe character, you can use extended regular expressions:  grep -e --color=auto 'word|$' file  
in the early 90's there was indeed the danger of breaking crt displays when setting too high frequency, but i don't think this is still a big problem
short answer is yes, you'll damage your grub installation.  it doesn't matter where grub is located, on mbr (likely in your case) or on linux partition, it needs /boot/grub directory to work which is (almost) always on your linux partition
ranges only work reliably and portably in the c locale
in my experience, ffmpeg is a tool well suited for that task
thanks to ramesh, slm and stéphane for pointing me in the right direction (i was missing the -r switch for lsattr)
it is because htop is counting buffers and cached memory as free memory, because it can actually can be seen this way.  there is no "cost" in having some cached data in memory, so the kernel keep stuff there just in case it needs afterwards.  for instance, suppose you have watched a video of about 500mb, after you close the video, the kernel may decide to keep it in memory instead of cleaning that part, just in case you need that video again so it doesn't need to load it again from your slow hdd
from the tail(1) man page:      with  --follow  (-f),  tail  defaults to following the file descriptor,    which means that even if a tail’ed file is renamed, tail will  continue    to  track  its  end
freebsd doesn't have an equivalent
the ratio (rkb/s + wkb/s)/%util of the iostat -x output should give you some insight:  device:  rrqm/s wrqm/s   r/s   w/s  rkb/s  wkb/s avgrq-sz avgqu-sz await r_await w_await  svctm  %util sda        0.04   3.65  7.16  6.37 150.82 212.38    53.71     0.03  1.99    0.82    3.31   0.76   1.03   i'm not sure how exactly this ratio corresponds to the disk seek
you might be happy enough just collating the "words", then pass them through the ``which` command
you missed the important line above:  gpg: signature made fri sep 11 17:13:36 2015 cest using rsa key id 6294be9b gpg: can't check signature: no public key   this tells you that this file is signed with key 6294be9b
if you want to have the message displayed every time you open up a new terminal (under an x session), then motd is not the right place
simple answer: you really can't
you need to set up nat on the linux box
to grep the first line of each file and print if they match you can use xargs and awk  find 
you want to put your bindings in fish_user_key_bindings
duplicity creates snapshots, but in the form of compressed archives, not in a form that can be read directly.  there are several ways to create snapshots
apt-get -qy update &gt; /dev/null apt-get -qy dist-upgrade &gt;&gt; /var/log/apt/scripted-upgrades.log   you can send them both to /dev/null if you want-- but once its gone you can never look at what went wrong after issuing the command.  also if your /etc/apt/sources.list is in bad shape, running a plain interactive  apt-get update   should clue you in.  the other guy has it right for scheduling updates for the system
if you can use iptables, you can route all requests to siri via the siriproxy
the problem is that the rule isn't in the input chain
1 - use a programming language that implements chmod  ruby:  ruby -e 'require "fileutils"; fileutils.chmod 0755, “chmod"'   python:  python -c "import os;os.chmod('/bin/chmod', 0755)”   perl:  perl -e 'chmod 0755, “chmod”'   node.js:  require("fs").chmod("/bin/chmod", 0755);   c:  $ cat - &gt; restore_chmod.c  #include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt;  int main () {     chmod( "/bin/chmod", 0000755 ); } ^d  $ cc restore_chmod.c  $ ./a.out   2 - create another executable with chmod  by creating an executable:  $ cat - &gt; chmod.c  int main () { } ^d  $ cc chmod.c  $ cat /bin/chmod &gt; a.out   by copying an executable:  $ cp cat new_chmod  $ cat chmod &gt; new_chmod   3 - launch busybox (it has chmod inside)  4 - using gnu tar  create an archive with specific permissions and use it to restore chmod:  $ tar --mode 0755 -cf chmod.tar /bin/chmod  $ tar xvf chmod.tar   do the same thing but on the fly, not even bothering to create the file:  tar --mode 755 -cvf - chmod | tar xvf -   open a socket to another machine, create an archive and restore it locally:  $ tar --preserve-permissions -cf chmod.tar chmod  $ tar xvf chmod.tar   another possibility would be to create the archive regularly and then editing it to alter the permissions.  5 - cpio  cpio allows you to manipulate archives; when you run cpio file, after the first 21 bytes there are three bytes that indicate the file permissions; if you edit those, you're good to go:  echo chmod |   cpio -o |   perl -pe 's/^(.{21}).../${1}755/' |   cpio -i -u   6 - dynamic loaders  /bin/ld.so chmod +x chmod   (actual paths may vary)  7 - /proc wizardry (untested)  step by step:   do something that forces the inode into cache (attrib, ls -@, etc.) check kcore for the vfs structures use sed or something similar to alter the execution bit without the kernel realising it run chmod +x chmod once   8 - time travel (git; yet untested)  first, let's make sure we don't get everything else in the way as well:  $ mkdir sandbox $ mv chmod sandbox/ $ cd sandbox   now let's create a repository and tag it to something we can go back to:  $ git init $ git add chmod $ git commit -m '1985'   and now for the time travel:  $ rm chmod $ git-update-index --chmod=+x chmod $ git checkout '1985'   there should be a bunch of git-based solutions, but i should warn you that you may hit a git script that actually tries to use the system's chmod  9 - fighting fire with fire  it would be great if we could fight an operating system with another operating system
a simple way to do this, which assumes you save your mail in mbox format, is just save the message to a different folder with no other messages
firefox can go through wlan0 only in this cases:  1) if it would like to use address 169.254.x.x/16, which is automatically added link-local address - you can disable it by uninstall avahi* stuff.  2) if you would like to go to some address in the 192.168.25.0/24 network.  if you would like to use for address in the 192.168.25.0/24 and for ssh protocol wifi0 interface and for other protocols you would like to use eth0, you have to use policy routing:  echo 100 ssh &gt;&gt; /etc/iproute2/rt_tables ip rule add fwmark 100 table ssh ip route add 192.168.25.0/24 dev wifi0 table ssh ip ro add default via 192.168.100.254 dev eth0 table ssh ip ro del 192.168.25.0/24 dev wifi0 table main iptables -a prerouting -t mangle -p tcp --dport 22 -j mark --set-mark 100   main idea is, that "normal" routing table doesn't know nothing about network 192.168.25.0/24, but ssh protocol does.  you can check advanced rounting howto page. 
this is possible if and only if the terminal sends different escape sequences for ctrl+left vs left
your function has an exit status but no output
because that's the way we do things in *nix land
there are a family of unix commands that will probably serve you better if you're aware of them for this type of work.   pgrep pkill killall   you can use these tools to make your "attacks" more targeted, especially in situations where you know the misbehaving process by name(s).  killall  i have a recurring issue with chrome where it eventually needs to be dealt with by killing it
use tar to create tarball of directory and run sum on it then.  tar cf - &lt;directory name&gt; | sum - 
ugly solution before perl/sed expert   ip a s| awk 'begin { s=0 ; } /^[^\t ]/ {if (s&gt;0) printf "\n" ; s++ ; } {printf " %s",$0;} end { printf "\n" ;}'   basically   begin { s=0 ; }   counter for line   /^[^\t ]/ {if (s&gt;0) printf "\n" ; s++ ; }   if line begin with non blank, and not forst, issue a newline   {printf " %s",$0;}   copy line with out newline    end { printf "\n" ;}   at the end, use a new line. 
d'oh!  i figured it out
i think you are looking for lvconvert --merge
my little secret for when i need to capture both stdout and stderr is to use nohup
when you fire off something with sudo a couple of environment variables get set, specifically i think you are looking for sudo_uid
networkmanager use a dynamic configuration, save settings with gconf for each user, whereas network-scripts are system global configure files, you're never getting them synchronized, and you don't need to.  when to use them?  in most cases, if you always use, e.g dhcp on your workstation, you don't need networkmanager, just set it up in network-scripts, (and turn off nm)  but for a laptop, that may use wireless, pppoe as needed, (e.g you move around between office and home) you will need networkmanager to be more adaptive. 
you can get the last command in your history with the bash builtin !! and use echo -n to print that command without a newline character at the end:  echo -n !!   the !! argument will expand to the actual command string and -n makes sure the output contains no newline character. 
you need to specify the full filename using record:  set record = "~/.mutt/sent"   you could also use + to place your sent mail in a mailbox alongside your other mailboxes (thanks to grochmal for the suggestion):  set record = "+sent"   the mailbox location is set using the folder variable, and is ~/mail by default. 
if, as your answer says, the payload is on a single line by itself, this will do it, while creating backups of the files altered:   find -name header.php -exec sed -i.bak '/someplacedodgy\.kr\/js\/jquery.min.php/d' {} \; -ls   just be sure that the "someplacedodgy" string is unique to the payload lines
  the bash manual states:     case word in [ [(] pattern [ | pattern ] ..
you're fine using java 7 to compile java 6 sources, it's backward compatible
you don't even need a livecd; you can correct it within grub
(   while true   do     your-command-here     sleep 5   done ) &amp; disown  
you need to add certificate to fix this issue. as described in mercurial wiki you can add it in your configuration file /etc/mercurial/hgrc:  [web] cacerts = /etc/ssl/certs/ca-certificates.crt   also you can check the way with fingerprints. 
a two-pass solution - in the first pass store all values from field 1 into an array a, in the second pass print each line, with the second field being set to 0 if it is not in the array a  awk 'first{a[$1]; next}; {print $1, !($2 in a)? 0: $2}' first=1 file first=0 file  
david lang on the rsyslog mailing list was able to set me straight on this one
i found the solution! i modified my udev rule to check devpath with some regex as:  kernel=="[a-z][a-z][a-z][1-9]", subsystem=="block", action=="add", devpath=="*[/]usb[1-9][/]*", program+="/opt/microworld/bin/foo.sh $kernel $parent"  
if you're on linux or otherwise have access to gnu tools, you can do this:  last=-1; find 
you can find all messages in /var/log/syslog and in other /var/log/ files
one option is stat + findmnt combo:  findmnt -n -o uuid $(stat -c '%m' "$path")   here -n disables header, and -o uuid prints only uuid value
the shortcut is shown in the view menu : ctrl+m 
off the cuff:  grep -l fieldofinterest /etc/filemod*/* | while read filename; do   sed 's/fieldofinterest.*/fieldofinterest = myvalue/' "$filename" &gt; tmp &amp;&amp; mv tmp "$filename" done   that gathers grep -l the filenames that contain fieldofinterest and passes them to the while loop for sed replacement via a temporary file
the short version is that x11 and vnc serve different purposes, so you'd use them in different circumstances.  it is possible to open a full x11 desktop remotely, using xdmcp; this is how old x11 terminals work (a central system provides the desktops and hosts all the applications, the terminals only display them)
you can do it this way using virsh along with some scripting:  $ for i in `virsh list | awk '{print $2}' | egrep -v "^$|name"`; do      printf "%-14s:%s\n" $i $(virsh ttyconsole $i | grep -v "^$");   done  cobbler       :/dev/pts/1 xwiki         :/dev/pts/3 fan           :/dev/pts/4 mercury       :/dev/pts/5 mungr         :/dev/pts/0 win2008r2-01  :/dev/pts/7   incidentally those same vms through an lsof command:  $ lsof|grep qemu|grep ptmx qemu-kvm   3796      root   14u      chr                5,2         0t0        993 /dev/ptmx qemu-kvm   3895      root   14u      chr                5,2         0t0        993 /dev/ptmx qemu-kvm   3972      root   14u      chr                5,2         0t0        993 /dev/ptmx qemu-kvm   4294      root   15u      chr                5,2         0t0        993 /dev/ptmx qemu-kvm  11897      root   14u      chr                5,2         0t0        993 /dev/ptmx qemu-kvm  16250      root   15u      chr                5,2         0t0        993 /dev/ptmx   it doesn't look like lsof shows which pty they're using, just that they're using the ptmx
install an ntp service on the virtual machine:  sudo apt-get install ntp   that way the virtual machine (assuming it has internet access) will set its time from a remote ntp server.  if this is already installed, check that the service is running:  sudo service ntp status   if it is not, start it:  sudo service ntp start   finally, you can force it to get the time from the server with  sudo ntpdate 1.debian.pool.ntp.org  
you need to run the filter command before the follow command, otherwise the filter command is never applied (pressing ctrl+c to get out of follow mode cancels any pending input, including fake input injected via the command line).  so in the + argument, you need to pass the &amp;foo|bar command first, then the f command
search on this opensuse page for kdesudo and you will get a list of personal repos with it. 
okey, the first thing you should try is to install ubuntu and bootup with monitor plugged in integrated graphics card slot ( i3 sandy bridge comes with integrated graphics, they should probably work)
it appears that package-cleanup can perform a similar task with the following command:  $ package-cleanup --leaves   or, to include more than just libraries  $ package-cleanup --leaves --all   package-cleanup is in yum-utils package, which is available for installation via the fedora repositories. 
considering the primary two modes, command and insert, demonstrates the purpose of a modal interface.  in insert mode you can type normally, inserting text into the document
because bind ~/.inputrc is a command to bind the key sequence /home/aliteralmind/inputrc where /home/aliteralmind is your home directory
i'd try to use bash variable substitution:     test)         shift         docker exec -it $(docker-compose ps -q web) python manage.py test "${@-apps}"         ;;   other way is to check $* instead of $1:  case $* in      bash)          ...     test)          docker exec -it $(docker-compose ps -q web) python manage.py test apps          ;;     test\ *)          docker exec -it $(docker-compose ps -q web) python manage.py test "${@:2}"          ;;  
you can create a debian package from the oracle tarball using the make-jpkg command from the java-package package
check that your module is not listed in file /etc/modules
find 
fdisk -l shows that your new partition already occupies all 20gb of space, so all you need to do is resize the filesystem itself
i copied all of this from ubuntu to fedora, and it works now:  unix password sync = yes passwd program = passwd %u passwd program = /usr/bin/passwd %u workgroup = workgroup server string = %h server (samba, fedora) dns proxy = no syslog = 0 server role = standalone server obey pam restrictions = yes passwd chat = *enter\snew\s*\spassword:* %n\n     *retype\snew\s*\spassword:* %n\n *password\supdated\ssuccessfully* . map to guest = bad user usershare allow guests = yes  
pipe the output to fold to wrap the output at a specified width (defaultly 80):  watch -d "ps -efww | grep '[j]ava' | fold -s"    use the -w flag of ps for wide output, and twice for unlimited output. fold -s breaks at spaces. also notice the grep command
 apt-get install sudo -y - used to install sudo package in debian based systems and y is used to specify yes during installation
wayland is an experimental new display server
you must start by enabling networkmanager by following the instructions here
the steps below work on arch linux (not sure about ubuntu).   edit file /etc/locale.gen, add line cs_cz iso-8859-2, run sudo locale-gen to generate locale files.   after that std::locale("cs_cz.iso8859-2") should work fine. 
the only way to do everything you ask is to rip a disk image of the dvd and then play the image
i think you are looking for a caching web proxy like polipo or squid
depends on which application has the 'focus'
$(history -p \!\!) is a way of getting the last command executed without adding it again to the history
there are two options:   cp --reflink=always cp --reflink=auto   the second is almost always preferable to the first
find uses readdir() to get the content from directories.  as readdir() is a library function that implements caching and as find even without caching cannot know that the called program removes a just discovered directory, a standard find call will always cause such errors.  there is a clean solution for your problem:  find 
tl;dr  on centos 7, you have to enable the persistent storage of log messages:  # mkdir /var/log/journal # systemd-tmpfiles --create --prefix /var/log/journal # systemctl restart systemd-journald   otherwise, the journal log messages are not retained between boots.  details  whether journald retains log messages from previous boots is configured via /etc/systemd/journald.conf
according to its documentation, damn small linux strips /var/lib/dpkg, and the files therein are necessary for dpkg-query to work (and for dpkg to be able to remove packages)
if you have a watchdog on your system and a driver that uses /dev/watchdog, all you have to do is kill the process that is feeding it; if there is no such process, then you can touch /dev/watchdog once to turn it on, and if you don't touch it again, it will reset.  you also might be interested in resetting the device using the "magic sysrq" way
i don't really understand why you have such unusual constraints
another thing to check is if your system is setting the environment variable tmout
you have (inadvertently) incremented the windows in master, the default keybind for which is modi, so that all of your clients in that selected tag are in master.  you can decrement the number of clients in master with modd
you can set the option disabled=1 in the corresponding network entry in wpa_supplicant.conf
elilo  managing efi boot loaders for linux: using elilo  it's really difficult for me to decide which part of that to copy+paste because it's all really good, so i'll just ask you please to read it
because you haven't specified a final action, find is treating this as if you'd done  find / \( -name .
you need to set up key authentication on both machines, both the rebound machine (server) and the target machine (pc).  create a key pair on your client machine (ssh-keygen) if you haven't already done so
patool handles different kinds of archives and creates a subdirectory in case the archive contains multiple files to prevent cluttering the working directory with the extracted files.  extract archive  patool extract archive.tar   to obtain a list of the supported formats, use patool formats. 
dialog --backtitle "package configuration" \        --title "configuration sun-java-jre" \        --yesno "\nbla bla bla...\n\ndo you accept?" 10 30     the user response is stored in the exit code, so can be printed as usual: echo $? (note that 0 means "yes", and 1 is "no" in the shell world).    concerning other question from the comments:   to put output of some command as a text just use command substitution mechanism $(). to give user multiple choices you can use --menu option instead of --yesno to store the output of the user choice into variable one need to use --stdout option or change output descriptor - either via --output-fd or manually, e.g.:  output=$(dialog --backtitle "package configuration" \                 --title "configuration sun-java-jre" \                 --menu "$(parted -l)" 15 40 4 1 "sda1" 2 "sda2" 3 "sda3" \          3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3 3&gt;&amp;-) echo "$output"   this trick is needed because dialog by default outputs to stderr, not stdout.   and as always, man dialog is your friend. 
modern unixes use utf-8, this is the same as 7bit-ascii, but has extension bytes for other unicode characters
you can use the -t option of gnu cp:     -t, --target-directory=directory           copy all source arguments into directory   you should also use find's -print0 and xargs -0 otherwise, this will fail on file names with spaces or other weird characters:  find 
to enable logging on the current window of a screen session, press ctrl+ah (uppercase h, shift+h if you prefer).  that actually toggles the logging state (so if the windows was being logged beforehand, it is now no longer logged).  that's the log command in screen, so you can also do ctrl+a: and enter log (or log on to turn it on instead of toggling the state), or run screen -x log on within the shell running in the current window.  to enable logging on all windows, use the at command to apply that to all windows:  screen -x at '#' log on   or press, ctrl+a: and enter at \# log on.  for more details, see:  info -f screen --index-search=at info -f screen --index-search=log  
the simple stuff  path=$path:~/opt/bin path=~/opt/bin:$path   depending on whether you want to add ~/opt/bin at the end (to be searched after all other directories, in case there is a program by the same name in multiple directories) or at the beginning (to be searched before all other directories).  you can add multiple entries at the same time
according to postfix readme:     by default, postfix sets the "smtputf8 requested" flag only on address   verification probes and on postfix sendmail submissions that contain   utf-8 in the sender address, utf-8 in a recipient address, or utf-8 in   a message header value.   if you submit mail through sendmail command or use address verification you may have to tweak smtputf8_autodetect_classes option.  to successfully flush the queue, after correcting smtputf8_autodetect_classes option, all mails have to be requeued with postsuper -r all command
i hope this is your environment.  host 1 - 1 bridged nic network   host 2 - 1 bridged nic network   host 3 - local nic network  host 4 - local nic network   if you add 1 more nic to host 1 and host 2 respectively and then assign local ip to them as in host 3 and host 4
text utilities work on lines (text lines being (not too long) sequences of non-nul characters terminated by a newline character)
you can use the environment variable $ld_library_path to override the dynamic loader's search path when looking for libraries to load.  to do it temporarily for a single application, you can invoke it like so:  $ ld_library_path=/usr/local/lib &lt;your executable here&gt;   you can make the change more permanent for your shell instance by exporting that variable:  $ export ld_library_path=/usr/local/lib   adjust the paths above as needed for where ever your 32-bit .so is being stored. 
in order to install dotnet-cli, you could use yaourt that helps to build and install aur packages.  you can proceed like this :   add to /etc/pacman.conf  [archlinuxfr]   siglevel = never   server = http://repo.archlinux.fr/$arch  update pacman and install yaourt:  sudo pacman -sy yaourt  next install dotnet-cli using:  yaourt dotnet-cli    and follow the instruction of yaourt. 
you can use the -delete flag of find (first test with -ls)  find -not -name "*.c" -delete   if you do not want to use find, but only files in the current directory, you could do  rm !(*.c)   make sure in bash that with shopt -s extglob the correct globbing is set
as long as you have vg/lv on sda you can only mount those separately, not sda as a whole
only the dvd-1 file is required for installation
the string in xresources usually looks like this:   name.class.resource: value   looks like you use * in place of name and class:  *color0: black   which means you apply color to everything.  if you want apply colors to urxvt only:  urxvt*color0: black  
chroot into it, and run dpkg would be the easiest thing
well, you seem to have a pretty good understanding of it.  to clarify some of what you have,   sh -c /path/to/program is fairly similar to  $ sh % /path/to/program % ctrl+d                             (or you could type “exit”) $   where you start a new shell process, provide the application command path to the new shell, and then let the new shell terminate.  i have shown the new shell giving a different prompt for illustration purposes; this probably wouldn’t happen in real life.  the sh -c "command" construct is mostly useful for doing tricky stuff, like wrapping multiple commands into a bundle, so they look like a single command (sort of a single-use unnamed script), or building complicated commands, possibly from shell variables.  you would hardly ever use it just for running a single program with simple argument(s). 2&gt;&amp;1 means redirect the standard error to the standard output. this doesn’t really have much to do with &amp;; rather, you use it when a command sends error messages to the screen even if you say command > file and you want to capture the error messages in the file. redirecting output to nohup.out is a trivial side-effect of nohup.  the primary purpose of nohup command &amp; is to run command asynchronously (commonly known as “in the background”, or as a “shell independent process”, to use your words) and configure it so it has a better chance of being able to continue to run if you terminate the shell (e.g., logout) while the command is still running.   bash(1) and the bash reference manual are good sources of information. 
netpbm (brew install netpbm) can process xwd files, so you should be able to do the standard unix x11 process:  $ xwd -root -silent -out screen.xwd $ xwdtopnm &lt; screen.xwd | pnmtojpeg &gt; screen.jpg xwdtopnm: writing ppm file  
that's for compatibility with the bourne shell
using /proc/$ppid/fd/0 is unreliable: the parent of the selector process may not have the terminal as its input.  there is a standard path that always refers to the current process's terminal: /dev/tty.  nl "$input" &gt;/dev/tty read -p"select options: " &lt;/dev/tty   or  exec &lt;/dev/tty &gt;/dev/tty nl "$input" read -p"select options: "  
at least in the gnu world:  touch --date=@1403970787 file   like with date. 
if you have xdotool installed, you could just simply use  xdotool keyup iso_level3_shift   which sends a key release (for iso_level3_shift, of course) event to the x server.  but you wanted a program to release all modifier keys. one could use xdotool to achieve that easily, if not for that i have no idea what modifier keysyms are defined
it should be possible to go to the terminal by typing ctrl-alt-f1, logging in and searching for offender with top, then remembering it's name or pid and killing it:   by pid: kill -kill pid by name: pkill -kill -f name   sigkill will make it go away if it's not hanged "inside kernel", i.e
@sch has lead me to this solution:  sed -bne '/\r$/ {p;q}' &lt; /path/to/file | grep -q .   this exits with true if the file has any lines ending with cr
sounds pretty easy:  cp vendor/plugin/*/tasks/*.rake lib/tasks   or if the first * should match a whole subtree, use something like:  find vendor/plugin -path "*/tasks/*.rake" -exec cp "{}" lib/tasks +  
i looked at the string escapes section of the screen man page and found what you may be after
if you have one file per line, one way to do it is:  tr '\n' '\0' &lt; list_of_files_to_be_deleted.txt | xargs -0 -r rm --   the file list is given as input to the tr command which changes the file separator from linefeed to the null byte and the xargs command reads files separated by null bytes on input and launches the rm command with the files appended as arguments. 
your way is adding line breaks to every thing that it write in space of whatever separator ($ifs) is using to split up the read
i looks like there was a typo in my /etc/security/audit_control:  # # $freebsd: releng/10.3/contrib/openbsm/etc/audit_control 293161 2016-01-04 16:32:21z brueffer $ # dir:/var/audit dist:off flags:all minfree:5 naflags:all policy:cnt,argv,arge,seq, filesz:2m expire-after:10m   this configuration produces insane amount of audit trails.  in linux audit they are present in a0, a1, a2 and a3 fields explicitly while in the openbsm format they are stored in the argument tokens (see audit.log(5))
to understand what every file is responsible for you should understand how mpu starts up. as i understood from your qestion you use nxp (freescale) i.mx microprocessor family
you can append to a register instead of erasing it by using the upper-case letter instead of the lower-case one.  for example:  :1y a      # copy line 1 into register a (erases it beforehand) :3y a      # copy line 3 into register a (after its current content) 8g  # go to line 8 "ap        # print register a  
your system seems a lightweight version/variation of debian, based in busybox
on newer upstart systems, a session init process is started when you login using the gui
update  it looks like terdon added and updated some commands over the thanksgiving holiday
utserver is a command line program
man 7 unix:     the af_unix (also known as af_local) socket family is used to communicate between processes on the same machine efficiently
it appears that gnome is the actual culprit here
sleepshell http://www.mariovaldez.net/software/sleepshell/ or rbash http://en.wikipedia.org/wiki/restricted_shell could be you need. 
turns out the man page describes what i was looking for
i think rsync's filter rules can't match the toplevel directory, so it's always synchronized
the simplest way is with a shell for loop
this was implemented to the linux kernel 3.4 as a flag of the system call prctl().  from the prctl(2) manpage:     [...] a subreaper fulfills the role of init(1) for its descendant   processes
the short options or unix style options are usually separated from its argument using a space, but space is not strictly required in some cases  for instance   echo `date -dtomorrow +%y%m%d`   and  echo `date -d tomorrow +%y%m%d`   would work just fine  however in case of,  echo date -d=tomorrow +%y%m%d  =tomorrow is considered the argument to d but it doesn't make a valid date string 
you don't.  see the "initialization file" section of the readline manual (man readline):     readline is customized by putting commands in an initialization file          (the inputrc file)
if a filesystem fills up, that can cause all sort of grief
this is because in the second case, you're rsyncing the contents of /e/, and the filter pattern is rooted there, not up one level
vim /etc/dhcp/dhclient-eth0.conf  
it's well-known fact, that vi has only two modes: it beeps and spoils text (:  so, if you're newbie and know nothing about vi and emacs, the best choice for you will be something simple like nano
the value !root alone doesn't match anything.  the value !root,* matches everything except root.  the man page is not clear about that but it may be that the order matters i.e
explicitly release the lease prior to acquiring a new one:  dhclient -r dhclient -d wlan0  
linux has a mechanism that allows plug-ins to be registered so that the kernel calls an interpreter program when instructed to execute a file: binfmt_misc
it looks like you should be able to access sudo without a password when no password is set
:%s/\${array1\[@\]}/$1/   worked for me
answer  if you are not concerned about speed (this is a one time task), then maybe you could try this:  cat map.txt | while read line; do neww=${line##* }; oldw=${line%% *}; find /some/folder -type f -exec sed -i "s/$oldw/$neww/g" {} \; done   not optimal, i know..
thanks for the responses everyone
(that was easy)  updating the version number properly and then uploading the zip file here worked. 
you could upgrade the kernel via elrepo.  rpm -uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm (external link) yum install --enablerepo=elrepo-kernel kernel-ml   you can also install the updated firmware and headers  yum install --enablerepo=elrepo-kernel kernel-ml-{firmware,headers,devel}   you'll probably need to remove the kernel-firmware first:  yum remove kernel-{firmware,headers,devel}  
reading readme.logcheck-database:  another safety-net is provided by the fact that the process that collates all the applicable rules uses "run-parts", the standard debian utility also used for iterating through "/etc/cron.d", "/etc/ppp/ip-up.d" etcetera
thanks to the comment by @mikeserv i've found out how to revive it.  i have only tested this on linux 4.0.7, so for much earlier or much later versions it may not work.   mount /dev/pts -o remount,gid=5,mode=620   mounting a devpts filesystem in a chroot without using the newinstance option caused it to mount the same "instance" of /dev/pts, containing the same ptys
it's the command-line window (keyboard shortcut q:, quit with ctrl+c,ctrl+c)  it shows a history of your previous commands, which you can navigate to and edit with normal (command) mode
this is simple, these are the two most common ways:  rm ./-yourfile  or  rm -- -yourfile 
according to the manual, the mybook supports both the cifs/smb and the nfs protocols.  cifs/smb is the protocol natively used by windows for accessing network drives
debian has a release maturity model, where unstable, sid, is where all the new stuff goes in
as of december 2015, debian stretch/sid has git version 2.6.4
add ~i (short for ?installed) to match the installed packages whose name contains bash:  aptitude search '~i bash'   to match whose description contains bash.  aptitude search '~i ~d bash'   to limit to the ones that are not installed:  aptitude search '!~i bash'  
you can use sshfs to make the remote files appear in a directory on the local machine.  you don't say what distro you're using on your client, but this is cribbed from the ubuntu sshfs documentation:   install the sshfs package (aptitude install sshfs) add your user to the fuse group (sudo gpasswd -a username fuse) mount the filesystem using the sshfs command   to use sshfs, make yourself a directory (we'll call this /mountpoint), and do  sshfs -o idmap=user remote_user@remote_server:/remote/directory /mountpoint   the remote files will now appear in /mountpoint, but are in fact still on the remote server
with ed instead of sed  ed -s &lt;&lt; eof file.txt 0,/match/-1 r text.txt ,p q eof   or as a one-liner  printf '0,/match/-1 r text.txt\n,p\nq' | ed -s file.txt ----- add this text file before first match match ----- match ----- match -----   (replace ,p by w for in-place editing). 
take a look at the man page for wget.  -o file    --output-document=file        the documents will not be written to the appropriate files, but all        will be concatenated together and written to file
with awk this would be awk 'nr &gt;= 1200 &amp;&amp; nr &lt;= 1300'  with sed: sed -n '1200,1300 p' file  with head and tail: head -n 1300 file | tail -n 100  so many options, so many answers on stackexchange :)  
during the call to a fuse operation you can call fuse_get_context() to get the current calling user id, group id, process id, and umask in a fuse_context struct.  struct fuse_context {         struct fuse *fuse;         uid_t uid;         gid_t gid;         pid_t pid;         void *private_data;         mode_t umask; };   here's a doc and bsd man page mentioning this function. 
i found this askubuntu q&amp;a titled: bind a mouse button to show the gnome shell activities overview
for closure, this is the start of the script i am going to use
grep -e should do what you need
/...foobar.../asu/asu set rsastring_password1 passwordhere   but if it doesn't work try to update libusb, since it communicates via usb.. 
as pointed out in this question, an excellent utility for this task is mediainfo
what growisofs is doing here is looking for the sudo_command environment variable, and aborting if the variable is found
thats the solution:  rsstail -i 3 -u example.com/rss.xml -n 0 | while read x ; do play fail.ogg ; done   so each time a new topic is released in the feed, the sound will be played. play is packaged in sox 
rm -rf is not unsafe per se, so go ahead and run it
why use hardlinks vs
after a small usenet discussion i use the following as a workaround for flock -n lockfile -c command:  #! /bin/bash  if [ $# != 4 -o "$1" = '-h' ] ; then    echo "usage: flock -n lockfile -c command" &gt;&amp;2    exit 1 fi  lockfile=$2 command=$4  set -o noclobber if 2&gt;/dev/null : &gt; "$lockfile" ; then    trap 'rm -f "$lockfile"' exit    $bash -c "$command" else    exit 1 fi  
to answer my own question:  ignacio's answer takes care of the large icon on the system menu, and the taskbar launcher if you add one
if you want to reliably test whether a directory is a subdirectory of another, you'll need more than just a string prefix check
for a single session, i use something like that:  cat &gt; screenrc-test &lt;&lt;eof screen -t test1 sh -c "./myprogram &lt; input_part1.txt &gt; output_part1.txt" screen -t test2 sh -c "./myprogram &lt; input_part2.txt &gt; output_part2.txt" screen -t test3 sh -c "./myprogram &lt; input_part3.txt &gt; output_part3.txt" screen -t test4 sh -c "./myprogram &lt; input_part4.txt &gt; output_part4.txt" eof  screen -s test-all -c screenrc-test   i don't know why you want several sessions, but the syntax is, in a similar way:  screen -mds test1 sh -c "./myprogram &lt; input_part1.txt &gt; output_part1.txt"   for each session
use --color=always.  grep detects if output is to a pipe (or file)
make(1) itself does not know how to run shell commands
you have several options:   either wait until the version you need is present in the repository you use. compile your own version and create a deb. find a repository that provides the version you need for your version of your distribution(e.g
the cursor is drawn by the terminal or terminal emulator, not the applications running within them
locale settings are user preferences that relate to your culture.  locale names  on all current unix variants that i know of (but not on a few antiques), locale names follow the same pattern:    an iso 639-1 lowercase two-letter language code, or an iso 639-2 three-letter language code if the language has no two-letter code
the easy way to compile a package from source is with dpkg-buildpackage
convert the ivs file to hccap:   aircrack-ng out.ivs -j out.hccap   and then:   hashcat --words-skip=0 --hash-type=2500 --outfile=cracked.txt --threads=4 out.hccap wordlist.txt   i tried the latest aircrack-ng and hashcat on a t450 with an ubuntu 15 livecd
i don't think that you need this unless you're planning on teaming multiple network cards together as one.  excerpt - http://fedoraproject.org/wiki/features/teamdriver     the purpose of the team driver is to provide a mechanism to team   multiple nics (ports) into one logical one (teamdev) at l2 layer
a few things pop out at me to try:  1)  on your client, the default private key that it will use when negotiating a connection is ~/.ssh/id_rsa  in order to specify a different key, you can specify like this:  ssh -i ~/.ssh/my_key root@yyy.yyy.yyy.yyy -p xxxx  the -i specifies the key to use  2)  on the server, you need to verify that the permissions on authorized_keys and the .ssh folder are accurate
you can manually create the /dev entry using      mknod /dev/ttyusbn c 188 n    parameters:  mknod is widely known tool to create /dev entries /dev/ttyusbn: device name c : char device 188 : major device number n : minor device number,ttyusb0, ttyusb1, etc.    but the device should be created automatically according to the udev rules 
be sure that you run  sudo update-grub   immediately after you make any changes to the partition table
to do what op need, we need a check at transport level, which turn out to be simple.   add following line to /etc/postfix/main.cf  sender_dependent_default_transport_maps = hash:/etc/postfix/sender_transport_maps  create /etc/postfix/sender_transport_maps as follow  user@local.domain   discard  create postfix map file and restart postfix  cd /etc/postfix postmap sender_transport_maps service postfix restart    this method works because postfix only use transport map for out-bound mail
like find / -type f &gt; /tmp/list_of_all_the_files.txt ? 
there are multiple ways to get this information
to use the postfix relay function, modify your /etc/postfix/main.cf file to include the following configuration:  queue_directory = /var/spool/postfix command_directory = /usr/sbin daemon_directory = /usr/libexec/postfix data_directory = /var/lib/postfix mail_owner = postfix mydomain = domain.com myorigin = $myhostname inet_interfaces = localhost inet_protocols = all mydestination = $myhostname, localhost.$mydomain, localhost unknown_local_recipient_reject_code = 550 relayhost = exchange2010.domain.com alias_maps = hash:/etc/aliases alias_database = hash:/etc/aliases debug_peer_level = 2 debugger_command =          path=/bin:/usr/bin:/usr/local/bin:/usr/x11r6/bin          ddd $daemon_directory/$process_name $process_id &amp; sleep 5 sendmail_path = /usr/sbin/sendmail.postfix newaliases_path = /usr/bin/newaliases.postfix mailq_path = /usr/bin/mailq.postfix setgid_group = postdrop html_directory = no manpage_directory = /usr/share/man sample_directory = /usr/share/doc/postfix-2.6.6/samples readme_directory = /usr/share/doc/postfix-2.6.6/readme_files   where the key entires that will need modifying to suit your local settings are:  mydomain = domain.com   set this to your local domain
well, given that your filesystem is 102% full (this is because of minfree reservation, 8% by default, see "man newfs"; basically filesystem would be totally full at 108%, but non-root users cannot fill it above 100%) you just don't have enough disk space there. 
the most commonly used commands in the default bash emacs mode, for most commonly used keyboards:  movement   ctrl-p, or up: previous command ctrl-n, or down: next command ctrl-b, or left: previous character ctrl-f, or right: next character alt-b: previous word alt-f: next word ctrl-a, or home: begin of command ctrl-e, or end: end of command   editing   bkspc: delete previous character ctrl-d, or del: delete current character alt-bkspc: delete word to left alt-d: delete word to right ctrl-u: delete to start of command ctrl-k: delete to end of command ctrl-y: paste last cut   miscellanea   cltr-/: undo cltr-r: incremental backward history search  
this will return only the files that start with "test":  ls | grep '^test'   more examples:  that will return only lines which contain the word "test"
the correct way according to usermod(8) is:  usermod --lock --expiredate 1970-01-01 &lt;username&gt;   (actually, the argument to --expiredate can be any date before the current date in the format yyyy-mm-dd.)    explanation:   --lock locks the user's password
it's a quoting problem
are you using a 64-bit version of linux with a lot of memory? in that case the problem could be that linux  can lock for minutes on big writes on slow devices like for example sd cards or usb sticks
the extent to which the en_* locales actually take up space on your system really depends on the packages you have installed
edit: apologies, i never noticed you mentioning in your initial post that you'd like to stick to bittorrent
it's talking about killing a child process of the process nominated to be sent a kill signal. 
really, the best solution for the oom killer is not to have one
the periodic script sends the output from certain of the security checks to tempfiles in /tmp
the ffmpeg version packaged in centos is too old to understand some of the options provided.  i'd suggest you to download a more recent version. the easy way is to download the latest static build for your platform, you can find it here: http://johnvansickle.com/ffmpeg/ (choose 32 or 64 bit depending on your arch).  for instance:  $ cd /opt/ $ wget http://johnvansickle.com/ffmpeg/releases/ffmpeg-release-64bit-static.tar.xz $ tar xvf ffmpeg-release-64bit-static.tar.xz $ ln -s /opt/ffmpeg-2.6.3-64bit-static /opt/ffmpeg   and use /opt/ffmpeg/ffmpeg rather than /usr/bin/ffmpeg. 
in short: no.  you'll need to restore from a backup
from man install:  -d, --directory    treat all arguments as directory names; create all components of the specified directories  -d         create all leading components of dest except the last, then copy source to dest   demonstration :   install -d flag :  $ install -d foo bar $ ls -l drwxr-xr-x 2 root   root  6 sep  8 15:55 foo drwxr-xr-x 2 root   root  6 sep  8 15:55 bar    see it created two directories named foo &amp; bar   install -d flag :  $ touch test{1..3} $ ls -l -rw-r--r-- 1 root   root   0 sep  8 16:11 test1 -rw-r--r-- 1 root   root   0 sep  8 16:11 test2 -rw-r--r-- 1 root   root   0 sep  8 16:11 test3 $ install -d test1 test2 test3 bar $ ls -l bar/ -rw-r--r-- 1 root   root   0 sep  8 16:11 test1 -rw-r--r-- 1 root   root   0 sep  8 16:11 test2 -rw-r--r-- 1 root   root   0 sep  8 16:11 test3    it copied files test1..3 to directory bar  conclusion  i don't think install supports copying entire directory trees; it's normally used on files
here-document is a kind of shell redirection, so the shell will perform it as normal redirection, from beginning to the end (or from left to right, or order of appearance)
create a bash script in your /usr/bin folder, it should look something like this  #!/bin/bash whatever combination of commands you want to run when you type this thing.   its really that easy.  just name the bash script what you want to type in to the terminal, and make it excecutable: chmod +x filename and you're good to go! 
in normal mode you start edit at end of line with shift+a.  in insert mode you should be able to move to eol.  in manual:  man readline /vi mode bindings&lt;enter&gt;     as to real/other question, i have to fill in a bit:  $ le eds de x       ^     ^^       |     ||       a     bc   in insert mode do you mean you are not able to move to c, only b from a?  even with →, or end?  so that if you start typing  the letters will enter before x? 
if i understand you correctly, you need a command that will take an os as input and return the correct installation command by reading the table you show
zcache is buried inside the ram and not easily visible with current tools
you got everything described in the linked your post.  1) list all available modules:  :~# ls /lib/modules/`uname -r`/kernel/net/netfilter/   2) list all loaded modules:  :~# cat /proc/net/ip_tables_matches comment addrtype mark conntrack conntrack conntrack recent recent addrtype udplite udp tcp multiport icmp  
socat might work here.  on the 2nd pc you could let socat listen for data on /dev/ttyusb0 and serve it to a tcp port, e.g:  socat /dev/ttyusb0,raw,echo=0 tcp-listen:8888,reuseaddr   then on 1st pc you can connect to 2nd pc with socat and provide the data on a pseudo terminal /dev/ttyvusb0 for your application:  socat pty,raw,echo=0,link=/dev/ttyvusb0 tcp:&lt;ip_of_pc2&gt;:8888   this isn't tested and socat supports many options, so tweaking may be needed. 
you can use brace expansions:  convert -trim -density 400 this_is_a_very_long_filename_of_my_pdf_file.{pdf,png}  
that behavior depends on the 'selection' option
you only need the shell for this job.  posixly:  for f in *.png; do     printf '%s\n' "${f%.png}" done   with zsh:  print -rl -- *.png(:r)  
there are three main ways of running your script without needing to specify the full path.   add the directory containing your script to your $path
you want either:  insert-completions  alt* for 'insert all completions'  with this, a dir containing files name 'aa ab ac ad' ls a* followed by alt + * would complete to ls aa ab ac ad  man page entry on binding:     insert-completions (m-*)        insert all completions of the text before point that would have been generated by possible-completions.   glob-expand-word  on some systems the above will not work with wildchars, the following does work on such systems for me:  ctrlx, * (a two stroke combo)  example: i populated a dir with:    touch {a,b,c,d,e,f}{1,2,3,4,5,6,7,8,9,0}00{a,b,c,d,f,e}   i then ls *100* followed by ctrl + x, *, which turns my readline into:    ls a100a a100b a100c a100d a100e a100f b100a b100b b100c b100d b100e b100f c100a c100b c100c c100d c100e c100f d100a d100b d100c d100d d100e d100f e100a e100b e100c e100d e100e e100f f100a f100b f100c f100d f100e f100f   man page entry for binding:     glob-expand-word (c-x *)        the word before point is treated as a pattern for pathname expansion, and the list of matching file names is inserted, replacing the word
instead of using which, which doesn't work when you need it most, use type to determine what will run when you type a command:  $ which set ./set $ type set set is a shell builtin   the shell always looks for builtins before searching the $path, so setting $path doesn't help here.  it would be best to rename your executable to something else, but if your assignment requires the program to be named set, you can use a shell function:  $ function set { ./set; } $ type set set is a function set () {     ./set }   (that works in bash, but other shells like ksh may not allow it
 running matlab is, or should be, entirely separate from managing swap space
would be strange of that was possible in os x but not with linux
it's the bcm4312 at 07:00.0
i'll finish this as an answer
i found out, how to configure pxelinux for my needs
i finally decided to choose a hardware solution.  i cut two wires from the fan and now the fan always spin (at the max level though).  i found this solution in this blog post. 
file in /etc/ directory called firewall.user must be modified to allow port 22 to connect the router. 
basically, you want a daemon that monitors the free memory, and if it falls below a given threshold, it chooses some process and kills them to free up some memory.  while (true) {     size_t free_memory = get_free_memory();     if (free_memory &lt; free_memory_threshold) {         pid_t pid = choose_a_process_to_kill();         kill(pid, sigterm);     } }   an obvious question is: how do you choose processes to kill? an easy answer would be the one with the biggest memory usage, since it's likely that that is the misbehaving "memory hog", and killing that one process will free up enough memory for many other processes.  however, a more fundamental question is: is it really okay to kill such a process to free up memory for others? how do you know that the one big process is less important than others? there's no general answer
no, there is not
i've done the follow routines and upgraded to mysql-server 5.5 successfully on centos 6.5.   yum remove mysql mysql-* rpm -uvh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm  rpm -uvh http://rpms.famillecollet.com/enterprise/remi-release-6.rpm (choose your relevant remi repo) yum --enablerepo=remi,remi-test install mysql mysql-server service mysqld start mysql_upgrade -u root -p   hope it may help you out. 
usrmodx() { sudo usermod "$1" -l "$2" -md "$2"; } usrmodx durrantm_test durrantm_test2   but shouldn't it be,  sudo usermod -l new_name -md new_dir old_name   so  sudo usermod -l durrantm_test2 -md durrantm_test2 durrantm_test   and as a function,  moveuser() { sudo usermod -l "$2" -md "$2" "$1"; } moveuser durrantm_test durrantm_test2   or am i missing something?  this assumes you're using a shell which supports functions (e.g
not really a transaction error from what i can see, it's a file conflict
 as gilles suggested, why dont you try the details in the powerpc_kvm link. they have described the whole procedure there.    added a document on  kvm on powerpc .  thanks, sen 
either rewrite your script in: perl, php or python, as they all offer api's for ftp, else have a look at using expect
turns out each output device needs its own dmix:  [!default] → multi → dmix → hw [normal]                    ↳ dmix → hw [loopback]   i was missing a second dmix between the multi and loopback-hw, so although my usual card would have been fine, the loopback card had no mixing.  many thanks to cl. for patience and expertise.    for the technical details, here's my ~/.asoundrc now:  pcm.snd_card { # my usual sound card     type hw     card 2 }  ctl.!default { # default control; alsamixer and such will use this     type hw     card 2 }  # software mixer for sound card pcm.dmixer {     type dmix     ipc_key 1024     ipc_perm 0666 # allow other users     slave.pcm "snd_card"     slave {         period_time 0         period_size 1024         buffer_size 4096         channels 2 # must match bindings     }     bindings {         0 0         1 1     } }  # software mixer for loopback device pcm.dmixerloop {     type dmix     ipc_key 2048     ipc_perm 0666 # allow other users     slave.pcm "hw:loopback,0,0"     slave {         period_time 0         period_size 1024         buffer_size 4096         channels 2 # must match bindings     }     bindings {         0 0         1 1     } }  # allows multiple programs to capture simultaneously pcm.dsnooper {     type dsnoop     ipc_key 2048     ipc_perm 0666      slave.pcm "snd_card"     slave      {         period_time 0         period_size 1024         buffer_size 4096         channels 2      }     bindings {         0 0         1 1     } }  pcm.!default {     type asym     playback.pcm "out"     capture.pcm "dsnooper" }  # multi, splitting onto usual card and loopback pcm.out {     type plug     slave.pcm {         type multi         slaves {             a { channels 2 pcm "dmixer" }             b { channels 2 pcm "dmixerloop" }         }         bindings {             0 { slave a channel 0 }             1 { slave a channel 1 }             2 { slave b channel 0 }             3 { slave b channel 1 }         }     }     ttable [         [ 1 0 1 0 ]   # left  -&gt; a.left,  b.left         [ 0 1 0 1 ]   # right -&gt; a.right, b.right     ] }  
this appears to be a known bug with tohtml in vim, supposedly fixed in 7.3, but i can't be sure
just install normally
there's a perl version of scriptreplay that's in the public domain, provided by joey hess: scriptreplay.  you can adapt that to add start/end features (the author placed that implementation in the public domain).  here's a quick and dirty modification of that code that takes two additional parameters - the start time (in seconds from start, default 0), and the end time (optional, runs till the end if not specified)
just reset display to the original value
for your first question  to make that command work, a change delimiter helps
while this solution may look longer, it is actually much less code, and easily testable
with gnu sed:  echo "your string with commas" | sed ':a;s/,,/,n.a.,/g;ta'        :a: label with name a      s/,,/,n.a.,/g: search and replace all (g) ,, by ,n.a.,      ta: if s/// has done a successful substitution, then branch to label a  
the apt-cache utility has the ability to search for packages
it seems that prezto is loading the module from /usr/lib/prezto/modules/completion
in older kernels there was brightness control file somewhere in /proc, but i think that it was the same functionality as /sys in your code snippet
this gives you a solid yellow block (nonblinking) as a cursor:  echo -n -e '\e[?17;14;224c'   for more info check these references: linuxgazette and emacswiki as well as the file /usr/src/linux/documentation/vga-softcursor.txt (if present on your system) 
you need to make sure cronie is started
use find which is better suited for your intended purpose:  find 
you just need ls (or find).  when you create a directory, its link count starts at 2:   one for the directory itself one for the . link inside itself   the other thing that increases the directory's link count is its subdirectories: they all have a .. entry linking back to their parent, adding one to its link count.  you can't hardlink directories in linux, so these are the only things that count towards the link count - two plus number of subdirectories. 
the operating system will not use more memory than it can handle in its allocation table
no, there is no way to undo a command(at least not universal)
if vlock doesn't work for you, try physlock
variables in munin are declared using env.myvariable, not env.var myvariable; try this:  env.mysqlopts -umyuser -pmyp4ssw0rd -h 10.13.13.13  
perl to the rescue:  #!/usr/bin/perl use warnings; use strict;  my $close_to = 6.1937;  my ($close, $lowest);  $/ = q(); while (&lt;&gt;) {     my @arr = split;     if ((! defined $close || abs($arr[1] - $close_to) &lt; abs($close - $close_to))         &amp;&amp; $arr[2] &gt; $arr[3]         ) {         $close = $arr[1];     }     if ((! defined $lowest || $arr[1] &lt; $lowest)         &amp;&amp; $arr[2] &lt; $arr[3]         ) {         $lowest = $arr[1];     }     if (eof) {         print "$close $lowest\n";         undef $close;         undef $lowest;     } }   save as script.pl, call as script.pl file1 file2 file3... 
firestarter hasn't been in the fedora repository since fedora 11
a perl way
to kill the nth ssh session, type &lt;enter&gt;, then 2^(n-1) ~, then .
you are trying to change the prompt displayed by the remote shell
what you've provided seems to be correct; you can verify that java is being invoked correctly by inserting echo into the command:  find $dir -type f -name '*.html' -exec echo java -jar $basedir/upload/htmlcompressor-1.5.3.jar --remove-intertag-spaces {} \;   (assuming a properly posix compliant system which has non-builtin versions of shell builtins on the standard path).  beyond that, you might want to run one of the resulting commands manually to verify that it is working correctly. 
i discovered the dev_install command, it sets up emerge, the gentoo package manager. 
cp -ppr   if yours have them
this is a really, really lame (non-)feature of kde
@stéphane chazelas's comment led me to the answer.  the fault was indeed with the precmd alias:  precmd  echo '\033]30;&lt;my-host-name&gt;\007\c'   unaliasing it obviously made the offending line go away, and from there diving deeper was a breeze.  from man csh:     automatic, periodic and timed events (+)      the beepcmd, cwdcmd, periodic, precmd, postcmd, and jobcmd special aliases can be set, respectively, to execute commands when the shell wants to ring the bell, when the working directory changes, every tperiod minutes, before each prompt, before each command gets executed, after each command gets executed, and when a job is started or is brought into the foreground.   thanks. 
update: a newer version of tmux now allows this: http://stackoverflow.com/a/33553372/1204312    there is currently no way to do this.  see this accepted answer on stackoverflow which suggests changing pane-borders instead.  you can set values for pane-active-border-style and pane-border-style in your ~/.tmux.conf.  see this answer for more details configuring these values (and some inconsistencies between tmux versions). 
you cannot hide your public ip address (assigned to the wan interface of your router)
i feel a bit stupid saying it, but did you try installing perl-doc?  # apt-get install perl-doc  
try:  for i in `find 
df -h | awk '$nf == "/" { if($1 ~ /^[0-9]/) print $3; else print $4 }'   or  df -h | awk '$nf == "/" { if($5 == "/") print $3; else print $4 }'  
it's a convention used both to keep filenames unique, and to control the order in which scripts get executed
if you want to pass the arguments to your script to mplayer, in an xterm, this should work:  #!/bin/sh xterm -e mplayer "$@"   this works because of how "$@" expands: one parameter per item
bc can not output zero before decimal point, you can use printf:  $ printf '%.3f\n' "$(echo "scale=3;1/8" | bc)" 0.125  
you can do it by adding its path to the perl5lib environment variable :  export perl5lib=/opt/dwimperl-linux-5.20.1-10-x86_64/perl/lib/site_perl/5.20.1  
depending on what your ultimate aim is, you could use printf:  $ a=(1 2 3) $ printf "foo %s bar\n" "${a[@]}" foo 1 bar foo 2 bar foo 3 bar   printf re-uses the format string until all the arguments are used up, so it provides an easy way to apply some formatting to a set of strings. 
means folk can leverage this to get a root shell, thereby bypassing your security, eg :!/bin/sh from within vim.  or :r /etc/shadow and :w /etc/shadow
you can compare the backup with the current contents of the system using restore:  restore -c -f backup   where backup is the file containing your backup.  you can also list the contents of a backup:  restore -t -f backup  
the utility you're looking for is diff
basically, everything except for /boot &amp; update initramfs is the same
edit (or create) /etc/dhcp/dhclient-&lt;device&gt;.conf and add the line  append domain-search "example.com";  
bash isn't that bad for this problem
to check whether a library is installed correctly, you'd usually try building a program using it.  make check runs tests in the build tree, not on the installed files
assuming you use gnome, check out system / preferences / keyboard shortcuts.  also, you can create a launcher to any application in any panel: either drag and drop an entry from the menu, or right click on an panel and click on add to panel. 
i'm also fairly new to regex, but since noone else has answered i'll give it a shot. the pipe-operator "|" is used for an or operator.  the following regex should get you going somewhere.  .+((jpg)$|(jpeg)$)   (match anything one or more times followed by either "jpg" or "jpeg" at the end)  extended answer (editted after learning a bit about (e)grep): assuming you have a folder with following files in them:  test.jpeg, test.jpeg, test.jpeg, test.jpg, test.jpg, test.notimagefile, test.gif   (not that creative with names...)  first we start by defining what we know about our pattern:    we know that we are looking for the end of the name
yes, there is a way
here's a small python script using the pypdf library that does the job
it is now extremely easy to install stackapplet on debian thanks to a fallback module for appindicators that i wrote, which ships with stackapplet
pending your response to my comment on the question, here's my answer:   first of all, [^}.to] doesn't do what you seem to think
   how does the whonix workstation ensure nothing is logged, or stored, on the os    it doesn't
in rhel/centos/fedora you can use below tools   ncurses based tool for enabling/disabling : ntsysv gui for starting/stoping  : system-config-services  
your script works for me
this file can lunch writer, with option --writer: /usr/lib/libreoffice/program/soffice.  however, you might want to config mime type for .doc files, called application/msword, follow the instruction discussed here
the problem is the missing blank.  the following code will work:  if [ "$dayofweek" == 4 ];  then    echo yes; else    echo no; fi   but keep in mind (see help test):   == is not officially mentioned, you should use = for string compare -eq is intended for arithmetic tests   i would prefer:    if [ "${dayofweek}" -eq 4 ];  then    echo yes; else    echo no; fi   generally you should prefer the day number approach, because it has less dependency to the current locale
in zsh, you can use setopt to show options enabled and unsetopt to show which are not enabled:  $ setopt autocd histignorealldups interactive monitor sharehistory shinstdin zle  $ unsetopt noaliases allexport noalwayslastprompt alwaystoend noappendhistory autocd autocontinue noautolist noautomenu autonamedirs .....   in bash, you can use shopt -p. 
i find very useful the following readline commands   history-search-backward, history-search-forward   (be aware they are different from the usual reverse-search-history, forward-search-history, tied to ctrl-r, ctrl-s).  i have these commands associated to ctrl-up and ctrl-down putting the following lines into ~/.inputrc:  "\e[1;5a": history-search-backward "\e[1;5b": history-search-forward   how they work: write few chars of the beginning of the command, press ctrl-up and the next older command starting with that prefix will be shown, press again to see the next, and so on
you have to create your key first
those aren't separate processes, they're threads
you could use something like this:  grep "failed password for" /var/log/auth.log | grep -po "[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+" \ | sort | uniq -c   it greps for the string failed password for and extracts (-o) the ip address
it seems likely that your script is writing most or all of it's output to stderr. this is easy to test  myscript.sh &gt; std.out myscript.sh 2&gt; err.out   then look at the contents of each file and be educated.       i doubt it - the only output from the script comes from calls to wget   instead of doubting, again this is easy to test  $ wget http://serverfault.com &gt;std.out --2013-09-09 07:06:25--  http://serverfault.com/ resolving serverfault.com..
what the rfc says is actually immaterial here
am i right in assuming that you put the x11forwarding yes in the sshd config file on the server? this option just permits forwarding of x11, see man sshd_config (see full man page):  x11forwarding        specifies whether x11 forwarding is permitted
nope, there isn't a way to cd to a directory that only allows root without being root
you might want to use these tools to increase the efficiency of perl scripts.  you would want to do this if you had a larger perl program and you wanted to integrate the functionality of an awk script without calling a subprocess
add the lpd service to the printing role on windows server.  on linux, open your system configuration tool then add a network printer, choose the lpd/lpr host or printer and then type the name or ip address of your windows printing server and the printer share name like this : lpd://192.168.100.12/it_support.  the share name can be found in the properties of the printer.    i don't know why but it doesn't work with names containing spaces so you better replace them with underscores. 
someone just pointed me to glances and while it still doesn't replace systat, it still pretty awesome
putty settings can only be saved if assigned to a saved session.  the process is usually to configure putty as you like, go back to the first category ("session"), enter a name, and click "save" to save your settings.  if you don't want to have to load the session each time,you have to save the session as "default settings" in the saved sessions list. 
you can pipe the password and send it in the command inside the script
the gnu sort documentation for the -t option says     by default, fields are separated by the empty string between a non-blank character and a blank character
found the solution myself (in this related question)
op (i, that is) didn't take this openvpn faq seriously enough:  one of the most common problems in setting up openvpn is that the two openvpn daemons on either side of the connection are unable to establish a tcp or udp connection with each other.  this is almost [always] a result of: ... a software firewall running on the openvpn server machine itself is filtering incoming connections on port 1194 [here 5000-5007]
it is possible to do so, and i use it to change the default of some programs (usually in form of my default parameters).  for scripts i write i prefer to put the configuration in a separate file ~/.my_program_x.conf and do a 
you can try following awk:  awk 'begin { fs = ofs = "|" } { $2 = "xyz"; $6 = argv[1]; $7 = "success";} 1' mdd.txt   or:  awk 'begin { fs = ofs = "|" } { $2 = "xyz"; print $0 ofs argv[1] ofs "success"; }' mdd.txt  
you can achieve reasonably fine-grained resource allocation with cgroups - the advantage is, that it allows you to have guaranteed reserved resources, which are available for all processes when not used by the applications in the cgroup to which they are allocated. 
you will have to copy them to the destination and then delete the source, using the commands cp -r * .. followed by rm -rf *.  i don't think you can "merge" directories using mv. 
i get the same problem with i686 arch
you can use find:   find 
getent passwd will list all known users, not only those present on the local /etc/passwd file. 
the canonical way is to do  find 
the tool screen is the tool that could help you
the following should work:  sudo useradd -m -k /home/user1/ user2   where -m says create the home dir, and -k provides the skeleton directory to use. 
something like cron?  note the @reboot entry  this is the most flexible approach, and the one most like windows' "scheduled tasks" (better actually). 
in shells that support them (ksh, zsh, bash4), you can start program as a co-process.   ksh: program &gt; output |&amp; zsh, bash: coproc program &gt; output   that starts program in background with its input redirected from a pipe
&amp; is the shell's backgrounding operator; it places the command preceding it in the background and continues.  so  mkdir gates &amp; cd gates   starts mkdir gates in the background and immediately runs cd gates, which attempts to change the directory before it's created (and fails).  ls &amp; mkdir gates   works because mkdir gates doesn't depend on anything ls does; all that happens is that ls is started in the background, outputting the directory listing, while mkdir creates the gates directory.  you're probably looking for  mkdir gates &amp;&amp; cd gates   which will change directory only if mkdir succeeds; you may prefer  mkdir -p gates &amp;&amp; cd gates   which won't fail if the directory already exists. 
the kill() system call and the kill shell command can be used to kill either processes or process groups
i think the easiest way would be to wrap the prompting code into a function, and then drop it into an until loop.  since all you need really is to call the function until it succeeds, you can put the noop command ":" in the until loop.  something like this:  #!/bin/bash  getgender() {   read -p "what is the gender of the user? (male/female): " gender   case "$gender" in     m|m)       grouptoaddto="boys"       return 0       ;;     f|f)       grouptoaddto="girls"       return 0       ;;     *)       printf %s\\n "please enter 'm' or 'f'"       return 1       ;;   esac }  until getgender; do : ; done sudo usermod -a -g "$grouptoaddto" "$username"     the point here is the function called with until, so it is repeatedly called until it succeeds
ok, now the questino changed almost completely ^^ you now need to calculate, given numbers, how many % they represent relative to the number 600.  here is a revised version.  i let my old answer below for historical reason ^^  new answer:  awk ' { printf "%s %.2f%\n",$1,($1/600)*100; }'  numbers.txt   ie, assuming the file "numbers.txt" only contain 1 column with a number between 0 and 600, it just print the number, and in the next column the % it represents with regard to 600
you want to remove all spaces and dashes immediately before (?  then you need to use a character class or "bracket expression" including space and dash: [- ]  sed -e 's/[- ]*(/(/g'   see man 7 regex and search for bracket expression for more details.  with the input you mentioned (081 379 62 49 (hems) or 081-379-62-49 (hems)), you can do it with awk:  awk -f'(' 'begin {ofs=" ("} ; {gsub(/[- ]/,"",$1) ; print}'   this tells awk to use ( as field separator, and then uses the gsub() function to remove spaces and dashes from the first field (the phone number)
sudo cp -rp /home/my_home /media/backup/my_home   from cp manpage:   -p     same as --preserve=mode,ownership,timestamps   --preserve[=attr_list]           preserve the specified attributes (default: mode,ownership,timestamps),           if possible additional attributes: context, links, xattr, all  
replace:  done   with:  done || exit 1   this will cause the code to exit if the for loop exits with a non-zero exit code.  as a point of trivia, the 1 in exit 1 is not needed
you can use the bedup utility to de-duplicate the identical files
you install uglify-js with npm which comes from node.js  install the npm package (which depends on nodejs)  apt-get install npm   install uglifyjs  npm install --global uglifyjs   now you have uglify-js  $ uglifyjs --version uglify-js 2.4.13   alternatively you can download the node.js linux binaries from the download page
i don't think there's a command that lists built-in modules parameters and their values
just include an actual newline inside the quotes (this works with either single or double quotes)
it's talking about the kernel development headers which are needed for compiling certain applications
in one of your comments, you mentioned using zsh with a preexec function that calls print -p $2.  in zsh, print -p accepts these format characters:   %f means set the foreground color %s means set the standout attribute   see zsh prompt expansion for the full list.  so it's probably best to remove the -p flag from your call to print in preexec.  one way to get the same effect:  settitle() {     printf "%b%s%b" "\033]0;" "$1" "\007" }  tildedir() {     print -pn "%~"  }  preexec() {     settitle "$(tildedir):$2" }  
you can create a shell function:  gedit() { command gedit "$@" &amp; }   or  function gedit() { command gedit "$@" &amp; }   the function keyword is, in theory at least, optional
you generally can't
you can filter out messages to stderr
to rename a file, write permissions to the file don't matter, renaming a file is a change to the directory, not the file
the value can only be extended up to a theoretical maximum of 32768 for 32 bit systems or 4194304 for 64 bit.  from man 5 proc:   /proc/sys/kernel/pid_max     this file (new in linux 2.5) specifies the value at which pids wrap around   (i.e., the value in this file is one greater than the maximum pid)
as @jeff answers, the code didn't previously support this
the argument of ?depends, like any other directive, is a search pattern
the watch linux command executes a program periodically
first, if you're going to keep running 32-bit binaries, you're not actually changing the processor architecture: you'll still be running an x86 processor, even if it's also capable of doing other things
basename from the gnu coreutils can help you doing this job:  $ basename /root/video.mp4 video.mp4   if you already know the extension of the file, you can invoke basename using the syntax basename name [suffix] in order to remove it:  $ basename /root/video.mp4 .mp4 video   or another option would be cutting everything after the last dot using sed:  $ basename /root/video.old.mp4 | sed 's/\.[^.]*$//' video.old  
as per this solution, you have to link coredump.conf to /dev/null then apply with sysctl :   # ln -s /dev/null /etc/sysctl.d/coredump.conf # /lib/systemd/systemd-sysctl    since systemd, things are managed differently
you can boot using any livecd linux like ubuntu, systemrescuecd ..etc then locate your partition containing /etc :  # using root user of the livecd session. fdisk -l   this will show you all partitions
this looks to be an active bug in the rt2800usb driver
you may try to use alt-^ in emacs mode (it's similar to ctrl-alt-e, but it should do only history expansion).  if it doesn't work for you (for example, there's no default binding for history expansion in vi mode), you can add the binding manually by placing  bind '"\e^": history-expand-line'   somewhere in your .bashrc, or   "\e^": history-expand-line   in your .inputrc  update. pair remarks:   if everything is ok, you should be able to press alt-^ to substitute any !! sequence with your previous command, for example echo "!!" would become echo "previous_command with args" if it doesn't work as desired, you can check the binding with bind -p | grep history-expand (it should return something like history-expand-line can be found on "\e^")  
the known_hosts file in your home directory is where ssh automatically stores the identity of every new server you visit
when you read a whole line with plain read (or read -r or other options that don't affect this behavior), the kernel-provided line editor recognizes the backspace key to erase one character, as well as a very few other commands (including return to finish the input line and send it)
the terms "kept alive" and their "handles are stored in this pool" is in reference to something different than caching.  caching  caching is a mechanism where data that's expensive to acquire is kept in a fast accessing location for reuse later on
you need to run chown as root.  root means root: the user with user id 0
under linux, you can get mount point information directly from the kernel in /proc/mounts
as miguel de icaza said in an earlier post: "this functionality is desktop and window manager specific."  in kde desktop environment you can integrate sounds with desktop events, by going to   configure desktop->application and system notifications. 
short: tmux can't display all 256 items in a font  long:  refer to the source code, which is a little awkward since (see kbd – linux keyboard tools webpage) prefers tarballs, but you can use the git-cloning advice to be able to browse the source
yes, pwd has -p (--physical) option to avoid all symlinks.  so do:  pwd -p   or you can use the canonical way, readlink:  readlink -f /path   check man pwd and man readlink. 
if you have a ext2/3/4 filesystem you can use debugfs for a low-level look at an inode
perl to the rescue!  perl -pe 'print "\n" if /^\s*+&lt;/; chomp;' input &gt; output   i.e
if you have seq available, you could do:  for attempt in $(seq 1 3) do   gksu command &amp;&amp; break done   if seq is not available, but you have (and want to use) bash:  for((attempt=1;attempt&lt;=3;attempt++)) do    gksu command &amp;&amp; break done   or even simpler (hat tip to drewbenn):  for attempt in {1..3}  do   gksu command &amp;&amp; break done  
when configuring subversion, try  ./configure --with-apr=/usr/local/apr/   that might not be exactly the right path
the probem because cron run task with sh
xxd can also convert the other way  xxd -r  
sudo yum install foo will look for foo in the package repositories and install it if it exists
you missed just one symbol =)  ssh user@socket command &lt; /path/to/file/on/local/machine  
in zsh, = in form of =word is a special expansion operator, and will be expanded to the full path of the command named word if the command existed and the equals option is set.  that expansion is not performed inside double quotes, so using ${:-=cat} inside double quotes won't work:  $ tmp="${:-=cat}" $ print -rl -- $tmp =cat     now, you have several options to achieve the same thing you want.  don't use double quotes around it:  $ foo="blah blah blah "${:-=cat}" blah blah blah" $ print -rl -- $foo blah blah blah /bin/cat blah blah blah   the zsh/parameter module provides the commands associative array, giving you access to the command hash table
ctrld is usually configured to generate the eof signal which for most shells by default signifies the end of input to the shell and the shell terminates
how about downloading the cd1 iso, then put it on a usb and boot? (my favourite)  how about using an automated tool such as unetbootin?  here is another tool from pendrivelinux. 
use curly braces  export login_va="login" export pwd_va="pwd" export server_var="@server"  echo whenever sqlerror exit | sqlplus "${login_va}${pwd_va}${server_va}" @"table1.sql"  echo 'return code : ' $?   see a little explanation about curly braces in here. 
edit ~/.recoll/mimemap, add the following line:  .md = text/plain   this will tell recoll to index markdown as normal text, which it is, mostly, so i think that things should "just work" 
sure, you can do:  xz -t backup.xz   a blank result is no errors
substitute is not needed, you can simply delete lines starting by a digit :  sed '/^[0-9]/d'   and if you really must use substitution :  sed 's/^[0-9].*//'  
i wonder whether the small sponge general-purpose utility ("soak up standard input and write to a file") from moreutils will be helpful in this case and whether it will follow the symlink.  the author describes sponge like this:     it addresses the problem of editing   files in-place with unix tools, namely   that if you just redirect output to   the file you're trying to edit then   the redirection takes effect   (clobbering the contents of the file)   before the first command in the   pipeline gets round to reading from   the file
ftp clients aren't particularly good at downloading whole directories.  try using wftp with its useful "-r" option
on the internet, including local networks, machines call each other by ip addresses
i'm no elisp expert, but this works
take a look at the bindfs package
the short answer:  yes, you're going to have to use expect.  as for why it's failing:  based on its behavior, bash -i turns on readline (even with --noediting), which plays rather badly with pipes
check out the opkg package manager documentation section on the install argument (under the heading "package manipulation")  opkg can install package files from both remote and local locations, as in:  opkg install http://downloads.openwrt.org/snapshots/trunk/ar71xx/packages/hiawatha_7.7-2_ar71xx.ipk opkg install /tmp/hiawatha_7.7-2_ar71xx.ipk   the latter is (i believe) what you want
to increase the size of a filesystem you must first grow the logical volume container and then increase the size of the filesystem within
in  echo "a bug\\'s life"   because those are double quotes, and \ is special inside double quotes, the first \ is understood by the shell as escaping/quoting the second \
purge nagios3
you could issue the command:  :intro  
here is the code i am running now, based on airfishey's answer with some corrections.  #!/bin/bash  t_lastdue=$(date --date='5seconds ago' +%s)  while true do     t_now=$(date +%s)     t_elapsed=$((t_now - t_lastdue))     if [ $t_elapsed -ge 5 ]     then         echo 'something different'         t_lastdue=$((t_lastdue + 5))         i=0     else         # process of random duration; not important         r=$(( 1 + random % 3 ))         sleep "${r}s"         i=$((i + r))         echo "$i"     fi done  
the following script shows:     current item (iteration) number   sliding window average rate (eg
   i don't know what "-lcap" is   the -l flag to the gcc c compiler tells it to link in a library, in this case called cap, which is an abbreviated version of the library name.  the full name is libcap.so.2.22 on centos 7, with the alias libcap.so.2
unclean :    the unclean match takes no options and requires no more than explicitly loading it when you want to use it
package might not be installed  when people give you information like this you need to make sure you qualify what it actually is
if you want to permanently destroy the bcache volume, you need to wipe the bcache superblock from the underlying device
use cp -p (capital p) to never traverse any symbolic link and copy the symbolic link instead.  this can be combined with other options such as -r to copy a directory hierarchy — cp -rl traverses all symbolic links to directories, cp -rp copies all symbolic links as such
note: the following is based on the gnu implementation of grep, however i think it should apply in your case as well  as noted in the gnu grep manual (emphasis mine)  grep searches the named input files for lines containing a match to the given pattern
i'm guessing that you probably have a file or directory called debug in your current working directory:   $ ls -l total 8 -rw-r--r--   1 jay   wheel   58 feb  1 05:01 t  $ grep [d]ebug t     1 debug  $ grep [dd]ebug t     1 debug     2 debug   $ touch debug  $ ls -l total 8 -rw-r--r--  1 jay  wheel  58 feb  1 05:01 t -rw-r--r--  1 jay  wheel   0 feb  1 05:05 debug   $ grep [d]ebug t     2 debug  $ grep [dd]ebug t     2 debug   i commend you on this excellent illustration why you must always escape shell metacharacters.  update to clarify what's going on: i'm assuming you, like i, are using an os with a case-insensitive filesystem (e.g
as hinted at by this macports.org ticket, the problem lies in having used two different major versions of ocaml (3.12 vs 4.0) in compilation on the two machines
this isn't pacman's default behaviour: if the package has been successfully downloaded (ie., is not considered corrupt either due to incomplete downloading or a failed hash sum), then pacman shouldn't download the same package again
another interesting name derivation from here.     among unix shell (user interface) users, a shebang is a term for the   "#!" characters that must begin the first line of a script
use of passwd -d is plain wrong , at least on fedora, on any linux distro based on shadow-utils
typically, $sty will be set.  so:  if [ -n "$sty" ]; then   echo "i'm most likely running under screen" fi   $sty is typically what you need to talk to your screen
unfortunately, the impression i get (from the dd-wrt forums) is that you can only block domains under access restrictions in the dd-wrt setup.  i've decided instead to set up a dedicated proxy server with dansguardian installed on it, which will allow me a fine level of control, and block any requests that don't go through the proxy on the router using iptables in openwrt. 
start it in a screen session.  screen   now start the process:  myprocess   then, detach the screen session with ctrl+a d.  you can reattach to the screen session again by typing:   screen -r   if you have more sessions running you can list them with:  screen -ls  
zfs set mountpoint=/myspecialfolder mypool  
echo "ginger bread.k +log ../output1 -format +m=3 0 +sleep 10 +suspend 10" | ...   replace ... by :   grep :  grep -op '\+m=\k\d+'   sed :  sed -e 's/.*\+m=([0-9]+).*/\1/'   awk :   awk -f'+m=| ' '{print $7}'   perl :  perl -lne 'print $&amp; if /\+m=\k\d+/'   bash :  x="ginger bread.k +log ../output1 -format +m=3 0 +sleep 10 +suspend 10" [[ $x =~ \+m=([0-9]+) ]] &amp;&amp; echo ${bash_rematch[1]}   output  3  
not really (at least, to my knowledge)
there's a tool called diffstat that sounds like what you're looking for.  $ diff &lt;file1&gt; &lt;file2&gt; | diffstat   example  $ diff afpuri.c afpuri1.c | diffstat  unknown |   53 ++++++++++++++++++++---------------------------------  1 file changed, 20 insertions(+), 33 deletions(-)   this can be used for diff output which includes multiple files in a tree as well.  references   how to get diff to report summary of new, changed and deleted lines  
yes
gui programs don't read from their standard input, they get their input from the x server
(i dislike intruding users' home, i think they should be allowed to do whatever they want to do with they homes… but anyway…)  this should work on linux (at least)
this is probably one of my most irksome things that people mess up all the time
do you know pkgsrc? it's a framework (using makefiles and some pkg_* tools) for compiling packages that also facilitates non-root building of packages (and their dependencies) very much.  so, referring to your choices, it's the "homebrew" thing but already built and proven, with lots of packages
this link to the lists.samba archive has a user with the same file locking issue
some possibilities:   as alan suggested, bad memory is a common cause of problems. bad power-supplies can also cause random freezes and crashes. low-quality motherboard
using mdadm 3.3  since mdadm 3.3 (released 2013, sep 3), if you have a 3.2+ kernel, you can proceed as follows:   # mdadm /dev/md0 --add /dev/sdc1 # mdadm /dev/md0 --replace /dev/sdd1 --with /dev/sdc1   sdd1 is the device you want to replace, sdc1 is the preferred device to do so and must be declared as a spare on your array
first things first, debug the module?  just see if you can load it up in gdb it might point you straight at a line that uses the relevant variable(or close to it)
you cannot have two default routes
in bourne-derived shells (sh, ash, bash, dash, zsh...) the exit code of the last-run program is in the $? variable:  $ ls /no-such-file ls: /no-such-file: no such file or directory $ echo $? 2   so in this case, the exit code of ls is 2. 
you can use bash to do this.  $ cat check-permissions.sh #!/bin/bash file=$1 # handle non-absolute paths if ! [[ "$file" == /* ]] ; then     path=. fi dirname "$file" | tr '/' $'\n' | while read part ; do     path="$path/$part"     # check for execute permissions     if ! [[ -x "$path" ]] ; then         echo "'$path' is blocking access."     fi done if ! [[ -r "$file" ]] ; then     echo "'$file' is not readable." fi $ ./check-permissions.sh /long/path/to/file.txt   to check this for a specific user, you can use sudo.  sudo -u joe ./check-permissions.sh /long/path/to/file.txt  
logrotate was a good idea
/usr/local is usually for applications built from source
you may not be able to do this, at least not yet, or at least not in the general case
assuming your ssd is faster for writes (and not just for reads), then there's an easy way to set this up with linux's raid subsystem
sources looking for dependencies via auto-tools have a configure.ac file (and/or makefile.am, i'm not sure on this one) in which those dependencies are defined
you should be able to set the environment variable prior to the cron job running:  shell=/bin/bash 5 0 * * *       $home/bin/daily.job &gt;&gt; $home/tmp/out 2&gt;&amp;1  
clonezilla isn't available for arm processors (at least not as a bootable image from the main download site), and isn't packaged for debian 6.  in debian 6 on arm you can clone your filesystem using partimage, dd_rescue or ddrescue
there is no "recipe" to get the meanings of an exit status of a given terminal command.  my first attempt would be the manpage:  user@host:~# man ls     exit status:        0      if ok,         1      if minor problems (e.g., cannot access subdirectory),         2      if serious trouble (e.g., cannot access command-line argument).   second: google
it depends on which boot-loader was installed
if you're using gnu grep, you can use -r.  grep -r zenity directory   otherwise, if your grep implementation does not have any options for recursion, you can use find and grep:  find directory -exec grep -h zenity {} +  
if using bash, the following should do the trick:  tolastline=$(tput cup "$lines") ps1="\[$tolastline\]$ps1"   or (less efficient as it runs one tput command before each prompt, but works after the terminal window has been resized):  ps1='\[$(tput cup "$lines")\]'$ps1   to prevent tput from changing the exit code, you can explicitly save and reset it:  ps1='\[$(retval=$?;tput cup "$lines";exit $retval)\]'$ps1   note that the variable retval is local; it doesn't affect any retval variable you might have defined otherwise in the shell.  since most terminals cup capability is the same \e[y;xh, you could also hardcode it:  ps1='\[\e[$lines;1h\]'$ps1   if you want it to be safe against later resetting of ps1, you can also utilize the prompt_command variable
~/.profile is only read by login shells
because strace isn't a shell, strace uses exec.  hope it helps. 
i'm not sure by what method you're passing those filenames to cut, but it seems that you're passing them as filenames rather than data to manipulate.  cut ..
i've never seen anything like one time sudo, but you could still get one time sudo by setting up one time passwords
typically you can set the bios to handle usb support, which will work with whatever boot-loader from there
 unmount the partition:  # umount /part  rename the directory after making sure it's not mounted:  # mountpoint /part &amp;&gt;/dev/null || mv /part /best_name_ever  edit /etc/fstab to replace /part with /best_name_ever remount the partition:  mount /best_name_ever    the # is of course meant to represent your root prompt, not actual input to be typed in.  to test the safety of this solution or any other one on dummy data  the following instructions are (in part) stolen from virtual filesystem: building a linux filesystem from an ordinary file.   create an ordinary file with a size of 20 mb (for example):  $ dd if=/dev/zero of=dummy_fs bs=1k count=20480 # 20480 = 20 * 1024  create an ext4 filesystem on your file:  $ /sbin/mkfs -t ext4 dummy_fs        mke2fs 1.42.5 (29-jul-2012) dummy_fs is not a block special device. proceed anyway? (y,n) y ..
i am not entirely sure what you want to achieve, but with /usr/sbin/airport you can obtain various information from wireless networks/your connection:  e.g.  airport -s gives information about all the networks in range (such as rssi strength).  airport -i gives information about your connection. 
pass the -t option to ssh-agent or to ssh-add
in the kde world, the default file browser is dolphin (instead of nautilus), and the scripts (like in nautilus) it has called service menu.  see here for the official list of them. 
it looks like your command is maybe setting environment variables based on arguments given it on the command-line
you can do this with netcat (ssh works too; but i'm assuming both the old machine and the new machine are on the same "secure" lan).  briefly:   build your vm with your disk space and whatnot
in debian, amd64 is x86_64 so squeeze lts is a viable option for you
check your quotes
1  date=$(date '+%y%m%d') 2 3  for file in maa.trd*.csv 4  do 5      code=$(echo $file | cut -d
that's not really possible because aliases only "exist" when the user is logged in
either use export to turn it into an environment variable, or pass it directly to the command.  var="test" sh -c 'echo "hello $var"'  var="test" export var sh -c 'echo "hello $var"'   or simply use double quotes to allow interpolation without having to export anything nor pass the var to the command:  var='test'; sh -c " echo 'hello $var' "  
in /etc/modules-load.d, add a file {filename}.conf
/etc/passwd is sometimes called the user database
your keyboard is not connected to xterm
you can use the raspi-config command and select "expand_root fs". 
the easier way is to check with your package manager
you can use piped i/o from a command in awk (at least gawk, i haven't tested this on solaris):  find 
it switching because something is detecting the change and setting up the mouse again
it is one less keypress to send a command to your nested session if you choose a different key
edit: it appears the grep is capturing a newline or carriage return which is fine when you submit it as a one off command but not fine in the loop
use the -o option:  wget "http://www.finance.yahoo.com/q/op?s=goog" -o goog.txt   
your question is long and rambling and i don't know what you expect for an answer
that should be configured in your desktop environment (de) settings
ironically, the answer in the question that people are proposing as a duplicate &hellip; bindkey '\e[a' history-beginning-search-backward bindkey '\e[b' history-beginning-search-forward &hellip; is exactly the wrong answer
just using bash:  string="h08w2345678"  echo "${string:3}" w2345678  echo "${string:0:-4}" h08w234  see the wooledge wiki for more on string manipulation. 
you can use the following steps to compile tmux 1.7 on centos 5.8:  install developer tools  yum groupinstall "development libraries" yum groupinstall "development tools" yum install rpm-build gcc   setup .rpmmacros file  $ cat &gt; /home/&lt;myusername&gt;/.rpmmacros &lt;&lt; eof %packager your name %vendor your orgnazation %_topdir /home/&lt;myusername&gt;/rpmbuild %_signature gpg %_gpg_name your packaging dept %_gpg_path /home/mockbuild/.gnupg %dist build_id %buildroot  eof   note: make sure you substitute your $home path into &lt;myusername&gt;.  setup rpmbuild area  mkdir -p $home/rpmbuild/{build,rpms/i386,sources,specs,srpms}   build libevent 2.x rpm  # d/l package wget http://sourceforge.net/projects/levent/files/libevent/libevent-2.0/libevent-2.0.10-stable.tar.gz/download mv libevent-2.0.10-stable.tar.gz rpmbuild/sources/  # download .spec file wget http://geekery.altervista.org/specs/libevent2010.spec mv libevent2010.spec rpmbuild/specs  # build rpm rpmbuild -bb rpmbuild/specs/libevent2010.spec   install libevent packages  cd $home/rpmbuild/rpms/x86_64 rpm -ivh libevent-devel-2.0.10-1build_id.x86_64.rpm libevent-2.0.10-1build_id.x86_64.rpm   download tmux srpm  for this we're going to download the srpm for fedora, but extract the contents of it out and reuse it's .spec file to build tmux for centos 5.x.  cd $home/rpmbuild wget ftp://ftp.muug.mb.ca/mirror/fedora/linux/development/19/source/srpms/t/tmux-1.7-2.fc19.src.rpm mkdir -p temp &amp;&amp; cd temp rpm2cpio ../tmux-1.7-2.fc19.src.rpm | cpio -idmv mv tmux.spec ../specs/ &amp;&amp; mv tmux-1.7.tar.gz ../sources/ cd ../specs/ &amp;&amp; rmdir ../temp/   edit tmux.spec  vim tmux.spec   i ran into several issues with this tmux.spec file
in insert mode, the cursor is between characters, or before the first or after the last character
all you have to do is specify the directory as an argument:  rmdir /path/to/directory  
you can configure this in either ~/.xresources:  xscreensaver.mode: blank   or ~/.xscreensaver:  mode: blank   to verify:  xrdb -load ~/.xresources killall xscreensaver xscreensaver -no-splash &amp;   then press ctrl-alt-l, and stare into the unblinking eye of infinity. 
you can use &lt;m-.&gt; (or &lt;esc&gt;. if your meta key is being used for something else), that is, meta-dot (or &lt;esc> dot), where meta is usually the alt key, to recall the last argument of the previous command
the right answer is not to use tabs
@costas - good answer!  and since they're sh scripts,  sh /home/german/prueba.txt  will work, as well.  and, btw, this was supposed to be a comment (isn't that what add comment is supposed to do?) 
the problem is that * in regular expressions means 0 or more of the preceeding character, it does not mean a literal *
tl;dr: it's doable but you will have to work just a little bit
tl;dr exit codes are application specific.  there are some loose conventions
not 100% the same output as you asked, but hopefully close enough:  function percent(value, total) {     return sprintf("%.2f", 100 * value / total); } {     label[nr] = $1     for (i = 2; i &lt;= nf; ++i) {         sum[i] += col[i][nr] = $i     } } end {     title = label[1]     for (i = 2; i &lt;= length(col) + 1; ++i) {         title = title "\t" col[i][1];     }     print title     for (j = 2; j &lt;= nr; ++j) {         line = label[j]         for (i = 2; i &lt;= length(col) + 1; ++i) {             line = line "\t" percent(col[i][j], sum[i]);         }         print line     } }   produces output:   id    sample1 sample2 sample3 one   62.50   0.00    25.00 two   18.75   60.00   40.00 three 18.75   40.00   35.00    run it with gawk -f script.awk file.txt  of course, you could flatten the script to a single line, but i think it's better to keep it in a script file like this so it's easier to read and maintain.  a simpler and better version that works with bsd awk too, not only gnu awk:  function percent(value, total) {     return sprintf("%.2f", 100 * value / total) } begin { ofs = "\t" } nr == 1 { gsub(/ +/, ofs); print; next } {     label[nr] = $1     for (i = 2; i &lt;= nf; ++i) {         sum[i] += col[i, nr] = $i     } } end {     for (j = 2; j &lt;= nr; ++j) {         $1 = label[j]         for (i = 2; i &lt;= nf; ++i) {             $i = percent(col[i, j], sum[i])         }         print     } }  
it's best to add a user with restricted privileges, see this post for more details
i found a solution:  sudo touch /forcefsck  
using rpm  try the following:  $ rpm -uvh --oldpackage pkg1.rpm pkg2.rpm   excerpt from rpm man page     rpm {-u|--upgrade} [install-options] package_file ...     this upgrades or installs the package currently installed to a newer     version
the difference between [[ … ]] and [ … ] is mostly covered in using single or double bracket - bash. crucially, [[ … ]] is special syntax, whereas [ is a funny-looking name for a command
you can pipe to xargs and use grep -il "" to filter out binary files:  git diff --diff-filter=am --ignore-submodules --name-only head^ | \   xargs grep -il ""   example git openfiles command  #!/bin/bash git show --stat head files=($(git diff --diff-filter=am --ignore-submodules --name-only head^ | xargs grep -il "")) read -p "open ${#files[@]} files in vim tabs? (y/n)" -n 1 -r if [[ -z $reply || $reply =~ [yy] ]]; then   exec vim -p ${files[@]} else   exit 1 fi  
this sed statement will add a 0 to the first two numbers if they are single digits:  sed -e 's!^[0-9]/!0&amp;!' -e 's!/\([0-9]/\)!/0\1!'           e.g.  $ cat x 1/1/1970 10/1/2000 10/10/2100  $ sed -e 's!^[0-9]/!0&amp;!' -e 's!/\([0-9]/\)!/0\1!' x 01/01/1970 10/01/2000 10/10/2100  
how to test if a daemon is running? it depends
don't declare 192.168.3.1 as a gateway
you are running up against a theoretical problem
there is no way to turn if off using config files
without trying to find out more about the internals of curl, i would suggest just piping into it:  printf @hello | curl http://localhost/ --data @-   as @ulrich-schwarz suggested in a comment, you could also use --data @&lt;(echo @hello) if it's more convenient (not all shells support this syntax).  looking at the source code for curl-7.41.0, i don't see any way to escape a @ sign to prevent interpretation as a file name:  if('@' == is_file) {   /* a '@' letter, it means that a file name or - (stdin) follows */    if(curlx_strequal("-", p)) {     file = stdin;     set_binmode(stdin);   }   else {     file = fopen(p, "rb");     if(!file)       warnf(config,             "couldn't read data from file \"%s\", this makes "             "an empty post.\n", nextarg);   }    /* ..
one approach would be to find the first non-whitespace character, and place the bullet before it  sed 's/[^[:blank:]]/* &amp;/' list.txt * job titles     * site reliability engineer     * automation         * automation engineer         * automation architect         * integration specialists  
i finally find my way (xfce solution):   first enable shortcut accelerator as describe here: http://docs.xfce.org/xfce/xfce4-settings/appearance#menu_and_buttons then you can add, change or remove shortcut by pointing the mouse pointer on action in menu, you wish to modify and tape the shortcut or backspace to delete it.  
i don't see this documented in the manual of gnu coreutils
i don't know if any sql dialects offer other ways, but as you haven't said what sql server you use, but this should work:  select datum,count(*) from fdr_data where datum like (select sysdate-1 from dual) group by datum;  when the where clause means there is only one row in the result it can feel strange having to add a group by clause, but the parser will not know so we add it to please that. 
hostname -i reads the /etc/hosts file, and gets you the ip address hostname is set as.  for example, if your hostname is foobar, and /etc/hosts has:  10.42.16.40 foobar   then, hostname -i will give:  10.42.16.40     also look at hostname -i to enumerate all ip addresses of all configured network interfaces (except loopback, and ipv6 link local) of the host. 
the qtcurve config file is ~/.config/qtcurve/stylerc.  you can copy the contents of your downloaded xxxx.qtcurve file into that file.  you can customise many aspetcs of your theme
you can use hdparm to retrieve information about your hard drives, eg.,  hdparm -i /dev/sda  where i, according to the man page:  -i     request  identification  info  directly  from the  drive, which is displayed in a new expanded format with considerably  more detail than with the older -i option.  for scsi drives, use sdparm. 
dovecot 2.2.10 is now in the updates repo and can be installed via yum install dovecot
 compile and install into ~/bin (and edit your .bashrc to set the path to include it)
mount --bind takes two arguments: the path to replicate and the location where it is to be replicated
i think you should change valid users = ashley joe %s to only valid users = %s
the [ command introduces a conditional; it is synonymous with test except for requiring a closing bracket at the end
since libraries are "autoprovided" by rpmbuild:  yum whatprovides libpng12.so.0   if that results in nothing then no package in fedora provides it and you'll need to talk to whoever built the software. 
this happens because shell variables are not expanded in single quotes
you must double quote your variable:  time_stamp="$(date)" touch "$time_stamp"   in this case, double quote in "$(date)" is not mandatory, but it's a good practice to do that
under thunar file manager, you can add to the shortcut pane by dragging items there as shown in the thunar documentation. 
the tutorial is wrong.  posix says:     a single-quote cannot occur within single-quotes.   here's some alternatives:  echo $'it\'s shell programming'  # ksh, bash, and zsh only, does not expand variables echo "it's shell programming"   # all shells, expands variables echo 'it'\''s shell programming' # all shells, single quote is outside the quotes echo 'it'"'"'s shell programming' # all shells, single quote is inside double quotes   further reading: quotes - greg's wiki 
in bash, this will delete everything in the current working directory which has the prefix ._:  rm ._*   if what you actually wanted to do was change their names to a form without the prefix, you can run:  ls ._* | while read line do   mv -- "$line" "${line:2}" done  
as soon as i finished writing it all out it came to me, simply changing the mutate to replace with a comma, or other similar character should solve the issue  edit  i ended up choosing ":" instead of commas, this cannot be used in a file name and works fine with the new grok:  filter {     mutate {       gsub =&gt; ["message","\|",":"]     }     grok {       match =&gt; { "message" =&gt; "%{month:syslog_month} %{monthday:syslog_day} %{time:syslog_time} localhost smbd\[%{int:pid}\]: %{user:user_service}:%{user:user_session}:%{ip:client_ip}:%{hostname:client_netbios}:%{greedydata:name_of_service}:%{year:samba_year}/%{monthnum:samba_month}/%{monthday:samba_day} %{time:samba_time}:%{host:domain}:%{word:action}:%{word:sucess}:%{sambafiles}" }       } }   using the following pattern:  sambafiles (?:%{greedydata:file_start}:%{greedydata:file_end}|%{greedydata:file_position})   this works fine under testing so far 
yes
(the following assumes apache httpd.) if you have the handler configured, you can see status information at http://your.host/server-status, which includes the last request each thread/process handled
i don't think there's a notion of “useful mounts” that makes sense in all scenarios
as i said in my comment, it's generally not a good idea to parse html with regular expressions, but you can sometimes get away with it if the html you're parsing is well-behaved.  in order to only get urls that are in the href attribute of &lt;a&gt; elements, i find it easiest to do it in multiple stages
running systemctl show service_name.service -p timeoutstopusec i could at least see the timeout set by systemd to my service.  i changed the script to a regular unit file one in order for it work properly. 
you suppose to enter the password of user that you are trying to sudo from and make sure user has proper sudo access in visudo (/etc/sudoers) 
if your goal is to really "zero" the drive, then i bet the fastest you can get is to issue a low-level secure erase command using hdparm (see here for step-by-step instructions)
use export grails_home=/usr/grails-2.0.0 in /etc/profile
that's the behavior exhibited by grep -c.  probably you have a file whose name starts with - and contains a c character and you're using gnu grep without setting the posixly_correct environment variable.  use:  grep -- delete *   or better:  grep delete ./*   -- marks the end of options so that that filename will not be considered as an option (with a posix grep, it wouldn't since the non-option delete argument would have marked the end of options), but it wouldn't address the problem of a file called -
can't you just ctrl+alt and then hit f-x keys until you get back to gnome? that's what i do.  on my ubuntu machine ctrl+alt+f7 gets me back to my gnome session. 
any posix compliant version of grep has the switch -q for quiet:  -q      quiet
you can run  ssh-copy-id user@server   so you will never have to enter the passwort again.  before that, you will have to create a local key, which you can do by running  ssh-keygen  
assuming linenumbers.txt has one number per line  awk 'nr == fnr{a[$0]; next};fnr in a' linenumbers.txt sourcefile.csv &gt; extractedrecords.tsv   might do the job.  or, with bash  join  -t':' -o2.1,2.2  &lt;(sort linenumbers.txt) &lt;(awk '{print nr":"$0}' \ sourcefile.csv | sort -k1,1 -t':')  | sort -k1,1n -t':' | cut -f2- -d':'   all the extra jumping through hoops is needed because join does not support numerically sorted input files 
fedora 12 is a bit old but i think you can still do the following:  look in /var/log/secure which has lines for each use of sudo
  awk 'begin {first_row = 0; col_val=""}{ if (first_row == 0) {first_row = $2; col_val=$1} else {print col_val " " first_row - $2; col_val=$1}}'   this is the output from the command line:   $ echo "10 -0.314690785295  20 -0.251967909317  30 -0.215271387106  40 -0.189228416217" | awk 'begin {first_row = 0; col_val=""}{ if (first_row == 0) {first_row = $2; col_val=$1} else {print col_val " " first_row - $2; col_val=$1}}'  10 -0.0627229  20 -0.0994194  30 -0.125462   ok now for why this works:  the begin clause defines a section of code executed as initialization before starting
a usb hub is a device that has one cord that plugs into one usb port, but provides multiple usb ports for you to plug devices into
unless you back the storage with a common file system, email will be delivered to one host or the other
if you wan't to use only a proxy server for specific sites you should look into pac files
no, paint.net will not run on mono.  there was some (currently abandoned) effort to port it to non-windows systems.  also, it has inspired pinta, a project which is supposed to be drop-in replacement for paint.net on non-windows systems. 
sudo touch /bin/rm &amp;&amp; sudo chmod +x /bin/rm apt-get download coreutils sudo dpkg --unpack coreutils*   and never again.       why didn't you use sudo with apt-get?   because the download command doesn't require it:     download              download will download the given binary package into the current              directory.   so, unless you are in some directory you can't write, you don't need to use sudo, and it could get problematic later on since you will need root permissions to remove/move the package. 
this should loop over all .avi files and convert them (untested):  printf '%s\0' *.avi | xargs -0 -i {} -p 1 avconv -i "{}" -c copy "{}".mp4   you can change -p 1 to e.g
updated answer based on some researching  remove duplicated welcome messages   since you login with ssh, the first welcome message should be coming from /etc/issue.net
in the script you present: $1 contains the name of an option, and an $array contains the value of the options
firstly nofail does not permit the boot sequence to continue if the drive fails to mount.  this is what fstab(5) says about nobootwait     the  mountall(8) program that mounts filesystem during boot also recog‐    nises additional options that the  ordinary  mount(8)  tool  does  not.    these  are:  bootwait  which  can  be applied to remote filesystems    mounted outside of /usr or /var, without which  mountall(8)  would  not    hold up the boot for these; nobootwait which can be applied to     non-remote filesystems to explicitly instruct mountall(8) not  to  hold  up    the boot for them; optional which causes the entry to be ignored if    the filesystem type is not known  at  boot  time;  and  showthrough    which  permits  a mountpoint to be mounted before its parent mountpoint    (this latter should be used carefully, as it can cause boot hangs).   fstab(5) has this to say about nofail     nofail do not report errors for  this  device  if  it  does  not                        exist.  
variable catenation is simplest:  echo -s ,$asd   this adds an extra comma to the beginning
you can make a list of the packages whose include-files are missing by using the "verify" feature of rpm.  something like this:  #!/bin/sh rpm -qa|while read name do     include=$(rpm -ql "$name" |grep -e '^/usr/include/' |wc -l)     [ $include = 0 ] &amp;&amp; continue     missing=$(rpm -v "$name" |grep -e '^missing[[:space:]]+/usr/include/' |wc -l)     [ $missing = 0 ] &amp;&amp; continue     printf '# missing %d of %d %s\n' $include $missing $name     printf "sudo dnf -y reinstall %s\n" $name done   it prints a script with comments indicating the number of missing files, as well as commands for reinstalling the broken packages
to have more space for your linux installation you need to expand sda6
most commands that accept --foo as an option also accept -- by itself as an "end of options, start of arguments" marker - so you could do:  printf -- "--no-color\n--format-doc\n--no-profile\n" &gt;&gt; ~/.rspec-test   but the more specific answer to your exact example is that the first argument to printf is a format specifier, and you're making things more difficult than necessary by not using printf for its formatting abilities
you can use the loadkeys command to remap keys on the linux console
i believe you need to use the unicode-based character classes instead
i don't see it in the manpage, but the source code checks if the program is invoked as tcsh or not
no dual boot is a misnomer, it actually means multiple
it will work if you use your shell script rather than the binary.  $ ~/tmp/term_test$ cat ./test_wrapper.sh  #!/bin/bash  ./test &lt;&lt; eof 5  eof read dummy $ gnome-terminal -x  ./test_wrapper.sh  $    the "read dummy" line i added will stop the terminal from immediately closing when the script completes.  are you sure that you need to open a new terminal session? 
ldapadduser set the user primary group which is unique.  you should use ldapaddusertogroup for secondary ones. 
short answer - no.  long answer: you are actually calling a python interpreter
with -www or -http, s_server acts as a static content https server using files in the current directory
you can use the owner match extension for iptables (ipt_owner.ko), together with an exception for the loopback interface, to block external network communication for a specific user
this is actually your terminal doing something weird, not vim
use the -e switch to the ssh-keygen:  ssh-keygen -l -f -e md5   this is available in recent openssh versions and prints the "old" md5 fingerprint, same as putty. 
you probably want:  source &lt;(eb printenv | tail -n +2 | sed 's/ //g; s/^/export /') your_next_command_that_uses_those_env_vars     a test:    define a function that prints out your sample variable definitions  function eb { echo " node_env=staging rdspassword=changme rdshost=sa1c7quehy7pes5.lolol.us-east-1.rds.amazonaws.com rdsusername=derp" }  call it to see what the pipeline produces  $ eb printenv | tail -n +2 | sed 's/ //g; s/^/export /' export node_env=staging export rdspassword=changme export rdshost=sa1c7quehy7pes5.lolol.us-east-1.rds.amazonaws.com export rdsusername=derp  source that output, test the current shell and a new shell to see if it's exported  $ source &lt;(eb printenv | tail -n +2 | sed 's/ //g; s/^/export /') $ echo $node_env staging $ sh -c 'echo $node_env' staging   
here's what i use:  .mailcap:  application/*; mkdir -p /tmp/mutt \; cp %s /tmp/mutt \; xdg-open /tmp/mutt/$(basename %s) &amp;   .mutt/muttrc:  folder-hook 
i found the solution to my problem here.  the workaround: i increased the memory used to 1024m with these instructions. i set the "maximum files opened for read/write" to a 101. i ran the application from the command line with this command:  sudo bash -c 'ulimit -n 8192'; sudo -u username ./azureus  
on debian and derivatives, scripts under /etc/network/if*.d are executed when an interface goes up or down
the -n flag of sed means quiet
on fedora 13 to find and install a new package, on the gnome panel click on  system → administration → add/remove software, or run the gpk-application command at the shell prompt
as far as i know, it's just lost
here are the criteria i use in my ~/.profile:   if one of the variables ssh_client or ssh_tty is defined, it's an ssh session. if the login shell's parent process name is sshd, it's an ssh session.     if [ -n "$ssh_client" ] || [ -n "$ssh_tty" ]; then   session_type=remote/ssh # many other tests omitted else   case $(ps -o comm= -p $ppid) in     sshd|*/sshd) session_type=remote/ssh;;   esac fi   (why would you want to test this in your shell configuration rather than your session startup?) 
simply just change keepcache=0 to keepcache=1 in /etc/yum.conf file.  note: ‍‍‍keepcache=0 exists by default and you only need to change it to 1; if it's not there just add keepcache=1 to the file. 
ssl works by matching public and private keys
i don't have tomcat, but it should be the same as for apache, which i tried as follows (you probably only need to replace httpd by tomcat everywhere)
doing several copies in parallel is rarely useful: whether the limiting factor is network bandwidth or disk bandwidth, you'll end up with n parallel streams, each going at 1/n times the speed.  on the other hand, when you're copying from or to multiple sources (here b and c), then there is an advantage to doing the copies in parallel if the bottleneck is in on the side of b and c (rather than on the common side)
assuming your immediate issue is running genymotion, this should be enough to fix the first error you reported:  sudo apt-get install libgstreamer-plugins-base0.10-0  
finally, i was able to reproduce the output of testdisk on the second drive
you can use  cd -   or you could use   cd $oldpwd  
i can't find anything about "something useful" you can do during that time (though some random undocumented feature would not surprise me)
short answer, no
as sankalp mentioned, pdflush thread is not involved with writes on a file with o_sync flag set
you might get what you need by using unbuffer.  unbufferis a tcl / expect script
[    3.572993] rtlwifi: firmware rtlwifi/rtl8192cfw.bin not available  do this(use lan wired)  apt-get -y update;apt-get -y install apt-file apt-file -y update   then  apt-file search rtl8192cfw.bin   and the package returned you will install with apt-get -y install  apt-get -y install "nameofpackagereturned by apt-file"   then reboot,or if you know the module used by wifi unload and reload with modprobe,after reboot/reload recheck with iwconfig 
store the files in the skeleton directory
a .a file is a static library, while a .so file is a shared object (dynamic) library similar to a dll on windows
this doesn't explain everything, but at least part of the problem is that you have carriage returns at the end of their values
you could try with:  cmake 
on the 11
in muttrc, use  set crypt_opportunistic_encrypt = yes   from $ man 5 muttrc  crypt_opportunistic_encrypt       type: boolean       default: no        setting this variable will cause mutt to automatically enable       and disable encryption, based on whether all message recipient       keys can be located by mutt.        when this option is enabled, mutt will determine the encryption       setting each time the to, cc, and bcc lists are edited
you could process the list of all layouts and for each item in the list check every corresponding variant for level3 symbols:  list=($(sed '/! layout/,/^$/!d;//d s/[[:blank:]]*\([^[:blank:]]*\)[[:blank:]].*/\1/' \ &lt; /usr/share/x11/xkb/rules/evdev.lst))  layouts=("${list[@]##*/}")  for i in "${layouts[@]}"; do sed -n '\|//.*level3|d;h;/xkb_symbols/{s/.*"\(.*\)".*/'"${i}:"'\1/;h} /^};/{x;/level3/d;s/\n.*//p}' &lt; /usr/share/x11/xkb/symbols/${i} done   the first sed lists all layouts in /usr/share/x11/xkb/rules/evdev.lst and saves the result in the array list
if you modify the awk code, can be solved by a single awk process and no shell loop:  awk 'fnr==1{if(o)close(o);o=filename;sub(/\.tex/,"_sorted.tex",o)}{ors=fnr%3?" ":"\n";print&gt;o}' *.tex   not a beauty, just insignificantly faster.  explanations as requested in comment.  fnr (file number or record) is similar to nr (number or record), but while nr is a continuous sequence number of all input records, fnr is reset to 1 when processing of a new input file is started.  a gawk 4.0 only alternative for the fnr==1 is the beginfile special pattern.  awk ' fnr==1{   # first record of an input file?   if(o)close(o);   # was previous output file? close it   o=filename;sub(/\.tex/,"_sorted.tex",o)   # new output file name } {   ors=fnr%3?" ":"\n";   # set ors based on fnr (not nr as in the original code)   print&gt;o   # print to the current output file } ' *.tex  
you can hold the shift key to use the normal mouse selection while xterm mouse-tracking is enabled
verold=$(vim --version |sed -n 's/^included patches:\s1-*//p')  
while the other answers using xmodmap are correct, there is a far easier way
after having another look at the dmesg output, this line caught my attention:  pci 0000:00:14.0: can't find irq for pci int a; please try using pci=biosirq   (together with a lot of others irq errors)  by googling it, i found this thread  apparently, it turns out that booting with the grub multiboot on an efi system is not well supported  i opened this issue for the ubuntu package, and i'll now resort to test xen on another (virtual?) machine. 
in other words, you're using wubi, right? as far as i know, it is currently not possible to resize a wubi installation of ubuntu 10.04 or 10.10.  what you can do is add another virtual disk and mount it on /home or /srv, wherever you need room
subpixel smoothing can improve rendering slightly, but not 100% windows-like
i'm afraid you're going to have to ask your sysadmin to supply you with a new password
this is pretty easy, now that trim can pass through lvm to the underlying device(s).   when you install, make sure your filesystems are all set to ext4
as you surmise, you need to tell wine where to display its applications
quick answer: no, that's not really possible
 pactl unload-module module-remap-sink  
you can modify gamma settings (colors and effectively contrast too) using xrandr tool
find has %s format specifier which is even named "sparseness"            %s     file's  sparseness
as for fedora, both methods will work, there is no guarantee to chose which one is preferable.  for redhat/centos, you should use /etc/sysconfig/modules, since when it's documented in redhat documentation - persistent module loading.  another way you can use /etc/modules.conf in redhat/centos base distro
with posix paste:  paste -d'\0' file1 file2 &gt; new_file   with paste from gnu coreutils, you can use -d ''. 
this worked for me:   download the alerts from your email in a thunderbird directory; install the importexporttools plugin and export the whole directory as html; go to the export directory and run: find * -print0 | xargs -0 -i § bash -c 'name="§"; date="{{#time:j f y| ${name:0:8} }}"; grep --text -eo "ru=([^&amp;]+)&amp;amp;" "§" | sed "s,ru=,;$date:,g" | sed "s,&amp;amp;,,g" ; ' | sort -ru   i used ;$date: as prefix for each url because that's meaningful wikitext and parser functions allow to easily translate the "aaaammdd" format used by the export files
you can use the process substitution operator &lt;() of bash (or zsh):  4s-import &lt;(zcat huge.gz)   this operator will create a temporary fifo /dev/fd/nn and replace &lt;(.) with the string /dev/fd/nn
use -r switch instead.  e.g node -r ./config.js  it will preload that module, and keep the shell for you. 
there're some issues with your command:   /some/path/* can cause argument list too long error if there're too many directories under /some/path it does not filter directory or file it's very in-efficient because it used inline-script sh -c but with -exec ..
here is a bash script to recursively extract a tar archive, remove the original nested archives and create a new archive
you may find q: useful
you may have a problem with line-buffering here
for each entry (stable, testing, unstable) you have pin-priority 500
if you want a quick and dirty solution, simply edit  /usr/share/gnome-shell/theme/gnome-shell.css   of course this will likely get overwritten the next time you update your gnome-shell package.  the cleaner (but a bit more complex) way is to create you own (mini-)theme:  http://rlog.rgtti.com/2012/01/29/how-to-modify-a-gnome-shell-theme/ 
it's not always "tunnel"
floating point arithmetic support in bash is very poor
the [ is a test construct:  $ help [ [: [ arg..
for speed and simplicity, i would pipe the command output into wc -l as munir suggests
   maybe my "users architecture" is all wrong in the first place?   yep
if you're using the mail command (aka mailx) you should be able to add this to the ~/.mailrc file for each user:  set from="user1@gmail.com"   mutt follows the same syntax except ~/.muttrc is the file you edit. 
use cd -p  according to the posix spec,     -p   handle the operand dot-dot physically; symbolic link components shall be    resolved before dot-dot components are processed (see step 7
in the case of csh and tcsh, it records the value of the $home variable at the time the shell was started (in its $home variable as noted by @jdebp).  if you unset it before starting csh, you'll see something like:  $ (unset home; csh -c cd) cd: no home directory.   for bash (and most other bourne-like shells), i see a different behaviour than yours.  bash-4.4$ unset home; cd bash: cd: home not set   the content of the $home variable is initialised by the login process based on information stored in the user database against your user name.  the information about the user name itself is not always available
the btrfs manpage fails to document the property subcommand, which i found by grep'ing the source
echo $histcontrol ignoreboth   man bash:     histcontrol      a  colon-separated  list  of values controlling how commands are saved on the history list
/usr/local/bin is for programs that a normal user may run.   the /usr/local hierarchy is for use by the system administrator when installing software locally
no.  for one, i believe that /var/cache/bind/ is the default directory where bind9 expects its zone files to be stored (at least on debian; i don't know offhand if other distros follow suit)  for another, according to this documentation, pacman (the package manager used by arch linux) stores its package cache under /var/cache/pacman/pkg/ and it most likely expects nothing but itself to modify the contents.  i recommend you read through the documentation more closely and decide whether this is a good time to clear the package cache. 
that's not really possible; lvm doesn't know anything about files.  lvm creates logical volumes, which are block devices
you are mistaken that it doesn't, you just have to tell grub-install to write it there.  once you have done that you can chain-boot-load from that boot sector.  the main reason not to write in the partition by default on a new setup is that your bios will not find it there, you would still need some bootloader in the bootsector of the disc that gets booted
try to fully turn off your intel rapid start and secure boot, and try it from bios, if you have a pre-installed 64-bit windows 8 with uefi, since it is pre-installed, and you also need 64-bit ubuntu, try this  http://askubuntu.com/questions/221835/installing-ubuntu-on-a-pre-installed-windows-8-64-bit-system-uefi-supported 
it is one more than the number of colons.  in awk:  echo `awk -f: '{print nf}' &lt;&lt;&lt;"$path"`   with tr (translate) and wc (word count):  echo $((`tr -dc : &lt;&lt;&lt;"$path" | wc -c`+1))  
the used space reported by df is reserved space
it sounds like you are using grub 2
you can use lsof (available for just about any unix variant, but often not part of the default installation) to list all the files a process is using
a solution is:   awk '{ gsub(",","\n"); print $0 }' $emailsfile  
one possible way, with perl:  perl -alne 'print join " ", grep { length &gt; 1 } @f' file  
...per your comment on the question...  pax -rws'/\.jpg$/.cap&amp;/' /root/of/copied/tree /dest/path   if .jpg and .jpg are your only issues, that should just work.  you can also add a print primitive to the filename substitution to get a list of all of those filenames which were changed:  pax -rws'/\.jpg$/.cap&amp;/p' /root/of/copied/tree /dest/path   as near as i can tell, pax should already be installed on an osx system, and so this should amount to a pretty stress-free solution overall.  if the problems turn out to be more profound after all, though, it may also be of interest to you that pax supports...     -i           interactively rename files or archive members
the original question would be solved by  cat test.xml | tr "&lt;" "\n" | sed -n '/taga>./p' | sed 's/taga>//' the second, current question would be solved with cat test.xml | sed 's/[0-9][0-9][0-9][0-9]=/\n/g'  it looks for an occurence of four numbers followed by an = sign, so if you might have those kinds of characters in other places in the real string it wont work, but it doesn't look like that right now 
as geekosaur and tshepang are saying: assuming that both distributions are using the same kernel, remaining differences should boil down to default configuration settings
if you still have a root shell, you may have a chance to repair your system
to apply a patch of this form:  diff --git a/include/linux/pm_qos.h b/include/linux/pm_qos.h index 0f65d36..ff59753 100644 --- a/include/linux/pm_qos.h   with patch -p1, several conditions have to be met.   you have to be in the top-level directory of a kernel source tree
same as you would with any other block device
use the split command:  split -l 100 file   by default split makes output files xaa, xab, and so on, but you can specify the prefix at the end, and get purely numeric suffixes if you want:  split -d -l 100 file prefix    this command will make files prefix01, prefix02, and so on
to get true atomicity, you would need to use filesystem-level features like btrfs snapshots. 
i am showing you a very basic way to do it
the initial ramdisk (initrd) is typically a stripped-down version of the root filesystem containing only that which is needed to mount the actual root filesystem and hand off booting to it
left=$(tput cub1) right=$(tput cuf1) printf %5s1; printf '%s\n' "$left${left}2${right}3"   details  from the bash prompt howto:  tput cub1 move left one space  tput cuf1 non-destructive space (move right one space)  
you can use perl-file-mimeinfo in the extra repository to manage mimetypes.  example to open all .pdf files in apvlv:  /usr/bin/vendor_perl/mimeopen -d $file.pdf  and then, at the prompt, enter the application: apvlv. 
to accomplish request 1 you will need to use a more sophisticated program than yes to send y n number of times and then pass keyboard input through beyond that
how about this? fewer quotes, parethesis, and brackets, and other syntax!:  l='e.cfg e_randr.cfg exehist.cfg etc'  for i in $l do   echo wget -c "$jef/$i" #$jef is defined in my ~/.bashrc script done   this is oldest and most common way to do it
with unix and linux, any device can be mounted at just about any directory path in the filesystem
if the delimiter is anything other than one fixed character, then cut is the wrong tool.  use awk instead.  consider this test file which has three fields:  $ cat file one///two/2//two///three   to print the second field and only the second field:  $ awk -f/// '{print $2}' file two/2//two  
this page says that is should be present in the transcode-utils package for your version of ubuntu
give the host a fqdn, e.g
ls .[^.]* will show you all entries that start with a dot and are followed by a non-dot character, thus skipping both current (since it has only the leading dot, nothing following that) and parent directories
you should be able to reinstall the package with a simple:    # pacman -s perl-libwww   this will only remove perl-libwww:    # pacman -rdd perl-libwww   please notice the double -d in the command, if you use --nodeps you have to specify that twice too or combine it with a -d like:  # pacman -r --nodeps --nodeps perl-libwww # pacman -rd --nodeps perl-libwww   this removes all the packages which depend on perl-libwww:    # pacman -rc perl-libwww   from pacman's man page:        -d, --nodeps        skips dependency version checks
looking at the manual, the command respawn-pane struck me, but it turned out that this didn't work
you're looking for signals sigtstp and sigcont
you also have to make sure that you add the listen :&lt;port&gt; to your cups configuration file /etc/cups/cups.conf.  /etc/cups/cups.conf  # our private connection we listen to  listen *:12345 # the port number her just an example # substitute it with one you wish to use.  # allow machines on local network to use printers &lt;location /printers&gt;   order allow,deny   allow 192.168.0.*   allow 192.168.1.* &lt;/location&gt;   if this is what your configuration already looks like then awesome
@meuh answered this on stackoverflow, and this was pretty much the answer i was looking for.  you can get an "old-fashioned" core dump in the usual current directory of the process, if the ulimit -c value allows it, by setting  makecompatcore = yes   in config file /etc/abrt/plugins/ccpp.conf. 
note that you're using the perl script called rename distributed by debian and derivatives (ubuntu, mint, …)
look at the time man page on your system, some implementations have format options to include i/o, cpu and memory stats (-f)
vmware will translate your wireless cards on the host to wired cards that are available to the guests
you almost certainly do not want to do this.  if your root user was pointed at your normal users dot files then the permissions on those dot files may change, thus complicating things for your normal user.  what you could do instead is copy the files over to your root users home directory on every login
as a child process of the shell, ls inherits the open file descriptors of the shell
if you take a look at the man page, credentials you'll see why child processes cannot have changes made via adduser immediately reflected in a real-time way:  excerpt     a child process created by fork(2) inherits copies of its parent's   user and groups ids
the file command makes "best-guesses" about the encoding
ucond indicates that the process has a thread that is waiting for a userland condition variable. 
this option was added to address xterm flickering (on some setups) when resizing/scrolling back/long outputs. the initial patch was posted by a user on archlinux forums
i can do it like:  sed 's|\(,[^,]*,\)\{0,1\}\([^,]\{1,2\}\)|\1/\2|g ' &lt;&lt;\in                                      hello_hello,123-world567-helloworld123456,world1234-hello09876 in   ...which prints...  /he/ll/o_/he/ll/o,123-world567-helloworld123456,/wo/rl/d1/23/4-/he/ll/o0/98/76   so most of the changes made are done to the second s///ubstitution - but that's because i removed all of the first.  so the biggest part of your problem was that you were simply telling sed to substitute in a / after every two characters - the . dots mean any char and the g means global - or all.  the second biggest part was that the first substitution was not helping you - and was completely unnecessary.  more than that though, you were also inserting an extra comma in the first substitution - so after i'd get the first bit straightened out, i was still running into extra fields
the mplayer package no longer exists in sid, that's why it is not working. you can see this from your own output of apt-cache policy mplayer
as https://backports.debian.org/instructions/ says:     all backports are deactivated by default (i.e
you can use zle's history-search functionality:  bindkey "^[[a" history-beginning-search-backward bindkey "^[[b" history-beginning-search-forward  this binds up and down (adjust for your own escape sequences) to a history search, backwards and forwards, based upon what has already been entered at the prompt.  so, if you were to enter "vim" and hit up, zsh will traverse backwards through your history for only those commands commencing with "vim".  you can additionally have the cursor placed at the end of the line once you have selected your desired command from zsh's history by using the history-search-end function (typically located in /usr/share/zsh/functions/zle/) and appending -end to the end of each line, like so:  autoload -u history-search-end zle -n history-beginning-search-backward-end history-search-end bindkey "^[[a" history-beginning-search-backward-end 
one way would be to use a while loop that runs  zlogin &lt;zone&gt; svcs -xv   or  zlogin &lt;zone&gt; svcs svc:/milestone/multi-user | grep online   and uses the output from one of those commands to determine whether the zone is ready, or whether to sleep a little longer.  the second command might be better if you regularly have failed services that need manual intervention to fix, as your script might hang otherwise
security is a tradeoff
have a look at how do i connect to a pc through another pc using ssh  you create a new ~/.ssh/config entry with the name tunnelb:  host tunnelb hostname hostb user user proxycommand ssh user@hosta nc %h %p   if you have a recent version of ssh you can use proxycommand ssh user@hosta -w %h:%p instead
use rsync:  rsync -a --ignore-existing cosmo_sim_9 /dest/disk/cosmo_sim_9   --ignore-existing will cause it to skip existing files on the destination, -a will make it recursive, preserving if possible permission/ownership/group/timestamp/links/special devices.  you can do it for all directories by using a bash for loop:  for dir in cosmo_sim_* ; do rsync -a --ignore-existing "$dir" "/dest/disk/$dir" done  
i may have misunderstood
don't use eval, use declare  $ declare "$var_name=$var_value" $ echo "fruit: &gt;$fruit&lt;" fruit: &gt;blue orange&lt;  
you are running a dhcpcd service that is giving you ip addresses no matter what the configuration you have
i would do it like this:  if type pkg-config &gt;/dev/null 2&gt;/dev/null; then …   but as i commented on your previous question, the pkg-config may not be available even on systems that use pkg-config
dd dates from back when it was needed to translate old ibm mainframe tapes, and the block size had to match the one used to write the tape or data blocks would be skipped or truncated
ensure which user has to use sudo - local or remote (or both) users? i.e
using "awk"  this will print lines with n0 &lt; limit:  # -v sets variables which can be used inside the awk script  awk -v limit=10 '      # we initialize two variables which hold the two previous lines     # for readability purposes; not strictly necessary in this example     begin {         line2 = line1 = ""     }      # execute the following block if the current line contains     # two fields (nf = number of fields) and the first field ($1)     # is smaller than limit      ($1 &lt; limit) &amp;&amp; (nf == 2) {         # print the previous lines saved in line2 and line1,         # the current line ($0) and an empty line.         # rs, awk's "record separator", is a newline by default          print line2 rs line1 rs $0 rs     }       # for all other lines, just keep track of previous line (line1),     # and line before that (line2)
try kill command with with -9 signal if sudo kill 'pid' does not work:  sudo kill -9 2092 
these ^@ are null characters, which have an ascii code of 0.  you can delete them using:  tr -d '\000' &lt; myfile &gt; myfile.out   or:  sed 's/\x0//g' &lt; myfile &gt; myfile.out   it's possible that this is a file hole
unfortunately, the ntfs permissions model and the unix one don't look alike at all
that is two very separate questions
the most obvious difference is that aptitude provides a terminal menu interface (much like synaptic in a terminal), whereas apt-get does not.  considering only the command-line interfaces of each, they are quite similar, and for the most part, it really doesn't matter which one you use
use resize2fs to extend the filesystem to the size of logical volume
i don't run centos or red hat to check, but some documentation point to /etc/sysconfig/static-routes-ipv6
you can use fcc-hook to change the folder depending on all sorts of parameters.  fcc-hook '~f foo@example.com' '=foo-folder' fcc-hook '~f bar@example.com' '=bar-folder'   i also use it to depend on the subject (all messages whose subject contains "isdn" go to my =isdn folder, for example),  use '~s' for that. 
i dont know if it is beautiful but it is working for every format of version that i know
indeed mplayer keeps its own pointer into the file, so it does not notice when echo writes to it
as hinted at in this question, the answer is setting up a trap on the err signal - basically set -e corresponds to trap 'exit' err
in this case  var=value ./configure   the behavior depends on your current shell, while in this  ./configure var=value   the behavior depends on the configure-script
the internal structure of filesystems is totally different among each other, so different programs are needed for different filesystems
i think xdotool getactivewindow is what you want - did you try it?  it prints the window id (from the window stack) if there are no further xdotool subcommands on the command line.  in xdotool getactivewindow getwindowpid for example,  getactivewindow puts the id on the window stack, and getwindowpid uses this id to query the pid
a perl approach (assuming your file is small enough to load into memory):  perl -0pe 's/.+?\n.*?linearrec\(1, f{58}\).*?\n.*?\n//' file   the -0 makes perl slurp the entire file, and the -p tells it to print each input line after applying the script given by -e
while we wait for sato katsura to answer the question, this (his) method works fine:  ps ax -o command | sort | uniq -d  
after some research around, i found that it's ok to use quote in execstart definition of a systemd service file
one way of achieving to have the same desktop on the android that was configured on the pc is to log out with android, log in with pc, do the necessary configurations and then log off and   service xrdp restart  this will make the other devices with different resolutions to load in the icons, etc., the session as the last session exited.  for a centos 6.4 with i386 architecture i couldn't find an rpm for xrdp with version >0.6
if you have a filename in a variable: file=photo.jpg  you can get the extension like this: ext=${file##*.}  that removes, from the beginning of the string, all character up to and including the last dot:   $ echo $ext jpg   see http://www.gnu.org/software/bash/manual/bashref.html#shell-parameter-expansion 
mount the olddrive e.g under /mnt/old and then do:   dpkg --root-dir /mnt/old --get-selections | grep -f ' install' ' | cut -f 1   dpkg has facilities built-in to install/list/deinstall on a filesystem not based directly under /. 
mupdf is a viewer application
as mavillan already suggested, just use terminator
i don’t know what shell you are using, but this is in the default path:  $ echo $path /home/[user]/bin:/bin:/sbin:/usr/bin:/usr/sbin:/usr/x11r6/bin:/usr/local/bin:/usr/local/sbin:/usr/games:. $ which pkg_add /usr/sbin/pkg_add  
the process is called caja.  i didn't find out until after i sudo apt-get install gnome-system-monitor and saw the little file cabinet icon next to a process called caja
first possibility  it seems like you are referring to @badroot using the wrong path.  if i am reading your shell prompt correctly, your current directory is ~, your home directory — which is probably /home/mlissner or similar
find does a blind walk of the entire filesystem looking for matches
the extra space on your file system is reserved for root
your subject says "servers", but your question is about clients. i'll answer the question in the body
after reading thomas dickey's answer, i researched what codepage 437 actually is, and it turns out that it's the font that's heavily associated with the dos era.  i came across a site called the ultimate oldschool pc font pack, which has a collection of ttfs that are (near) perfect replications of the old fonts that everyone loves.  i made a package for it called ttf-ibm-vga8 in the arch user repository
in bash*, you have to use braces like this:  echo ${a1[$each]}   to make [$each] a subscript into the a1 array.  per man bash(1):     any element of an array may be referenced using ${name[subscript]}
this doesn't seem like a yast thing (yast will only do very basic things for apache)...you might find something in the advanced setting where you can add the module.  however, you're probably going to still have to make a file in /etc/apache2/conf.d to tell apache what to do when it comes across such a file.  here is a link for some more information.  in case the link goes down\further detail for opensuse only:  edit /etc/sysconfig/apache2  look for the section called apache_modules and inside of the quotes add rivet
yes:  $ export test=`script.py` $ echo $test 5   you need to tell the shell to set test to the result of running script.py, which is what the backticks do for you
you have an option to the kernel where a cpu wont be used by the os, it is called isolcpus.     isolcpus — isolate cpus from the kernel scheduler
the only issue was that after the product id the '*' is still required, so in the end the rule looked like:  keyboard:usb:v11aap11aa*  [remapping rules]   simple syntax error. 
see edit-command-line in zshcontrib.  bindkey -m vicmd v edit-command-line  
this message is about some driver being denied access to devices controlled by the acpi
this might not be accurate
this is a minimal version of the commands to give to resize to width 600 height 400 (if greater than that), setting the jpeg quality to 70 (it is a percentage: a smaller number makes for less bytes but less quality).  cd /home/shirish/input_directory/ mogrify -path /home/shirish/output_directory/ -monitor   -quality 70  -trim  -resize '&gt;'600x400 *.jpg   if there are too many files you may need to use find|xargs 
the shred command can zero out a file
memavailable is included in /proc/meminfo since version 3.14 of the kernel; it was added by commit 34e431b0a
one options is to use:  if system("uname") == "linux"   set filetype off   match extrawhitespace /\s\+$/ endif  
method that i used in the end:   run xfig in its own desktop under tigervnc server. connect to the vnc server with a vnc client that allows scaling.   to simplify the process, i created a tool to run arbitrary applications scaled up, vncdesk
grep has extra options to define how many lines before and after the result:   -a (after)   -b (before)    -c (context [before + after])    so in your case you need -a:  your_command |grep -a number yourdomain   the above command prints number of lines after yourdomain in file. 
the syntax you've used creates two pty masters and connects them together bidirectionally
the file /boot/grub2/grub.cfg is generated automatically by the grub2-mkconfig command, which will be run automatically when a new kernel is installed
awk '{split(filename,u,"/"); print u[2], $1}' users/*/info.txt  
in centos 7, to start a daemon on boot, one must run the command:  sudo systemctl enable daemon.service   in your case, you must run:  sudo systemctl enable sshd.service   for fully qualified domain name, you should add the following line to /etc/hosts in your host (not virtual machine) according to the ip address of the virtual machine:  192.168.*.* osboxes osboxes.local.com   after that, you can login just with:  ssh user@osboxes   also, if one ever wishes to stop a daemon starting on the boot:  sudo systemctl disable daemon.service   is the command to run
it is important to know that there are two kinds of limits:   a hard limit is configurable by root only
i opened a shell and typed "man ps" and then foudn the see also section
while it's certainly possible for users to customize their prompt (and make that update the terminal's title), most use the default shell behavior.  it sounds as if your local machine is setting the title string as a side effect of your prompt, and that the remote machines are not changing the title.  given that, you can update the title without interference by the remote machines, e.g., using a wrapper script for ssh such as this:  #!/bin/bash # trim parameters, leaving just the last (user@hostname or just hostname) title=$(echo "$*" | sed -e 's/^.* //') printf '\033]0;%s\007' "$title" /usr/bin/ssh "$@"   and putting that in your executable path ahead of /usr/bin, you could call that "ssh" and have it set your title string as you visit each remote machine
you can use find and xargs, e.g.:  find /var/spool/postfix/maildrop -user web2 -print0 -type f | xargs -0 -i{} mv {} /var/spool/postfix/temp-spam   you can test it by inserting echo:  find /var/spool/postfix/maildrop -user web2 -print0 -type f | xargs -0 -i{} echo mv {} /var/spool/postfix/temp-spam  
it seems you are asking two or three questions.  to use ssh to tunnel, i advise you start a non-interactive session  ssh -c2qtnn -d 8080 user@ip   that will put the ssh tunnel in the background.  use the proxy: you then configure your browser or system settings to use the proxy on localhost port 8080.  stop using the proxy: you then re-configure your system to not use the proxy (undo the above step).  to end the ssh session,   killall ssh   or kill the process by process id  i usually run a separate ssh session if you wish to enter commands on the server.  see also https://calomel.org/firefox_ssh_proxy.html 
there really isn't a centralized resource that you can just "query" to get at this information
i use the method described here, and it works well
shell expansion is one of the main benefits of 'here documents'
most shells have a cdpath variable that cd can lookup for directories to  change to in the same way that executables are searched in $path.  so if you add your symlinks in a ~/projects directory and do cdpath=~/projects, you'll be able to do cd foo to go in ~/projects/foo  with zsh, if $var contains a path you can do cd ~var to cd to that path
set the ifs (internal field separator) to a newline:  $ cat 1.sh  #!/bin/sh old_ifs=$ifs ifs=" " ./2.sh `cat lines.txt` ifs=$old_ifs  $ ./1.sh p1=a/b p2='c/d e/f' p3=  
reinstalling the font packages was futile
when you press ctrl+c, the process (technically, the process group) that is running in your terminal is killed
at the beginning i had set my default shell to  chsh -s /usr/local/bin/zsh    this shell is installed by brew
what's going on is that bash is getting confused about the number of printing characters in your prompt
they went to whatever was your current directory when you ran tar; if you haven't closed the terminal or changed directories since,  pwd   will tell you where they are. 
pravin offers some good general points, but doesn't really elaborate on any of them and doesn't address your likely actual problems.  first, you need to find out how postfix is receiving those messages and why it's choosing to relay them (the two questions are very likely related).  the best way to do it is by looking at the message id of any one of the messages and then grepping the mail.log file for all log entries regarding it
you can use proxychains for this.  first install proxychains, using the command:  $ apt-get install proxychains   then configure your proxy settings in /etc/proxychains.conf file.  add at last, these lines for http and https proxy.  http    proxy-ip   proxy-port    username        password https   proxy-ip   proxy-port    username        password   now you can do telnet by using the following command:  $ proxychains telnet www.google.com 80  
there are only two commands to add emails to the notmuch index: notmuch new and notmuch insert
a rundown of my discovery process is here at the centos forums.  helpful debugging tips  being relatively new to centos, (and by extension gnu/linux), here are some commands i found helpful in troubleshooting hardware issues:   lsusb lists stuff that's connected via usb. lspci lists stuff that's connected via pci. lsmod lists modules that are loaded. yum has an awesome script that spits out your configuration to help others help you
most webcams, being optimized for capturing video data in a tiny size and budget, don't have shutters at all and thus shutter speed is an irrelevant setting
i don't know why that option would be useful
autofs can do this for you
try authenticating with an ssh key
you're nearly there
run this first to make sure it gets the desired dir's  find ${dir_log} -type d -mtime +90 -name "20[0-1][0-9][0-9][0-9][0-9][0-9]"   then run this to actually delete them.  find ${dir_log} -type d -mtime +90 -name "20[0-1][0-9][0-9][0-9][0-9][0-9]" -exec rm -rf {} \;  
since the rename command didn't work for me for unknown reasons and i do not get any other answers for my question, i myself tried to make an effort to make the rename possible
you can simply use grep:  name        grep, egrep, fgrep, rgrep - print lines matching a pattern  synopsis        grep [options] pattern [file...]        grep [options] [-e pattern | -f file] [file...]  description        grep  searches  the  named  input  files (or standard input if no files are named, or if a single        hyphen-minus (-) is given as file name) for lines containing a match to the  given  pattern
maybe you can try with git ls-files --others --exclude-standard this should list all files wich are not defined in .gitignore 
the --inodes option to df will tell you how many inodes are reserved for use
you have to use backticks (`) instead of fancy quotes (‘).  wget --output-document=camera_3`date +%y-%m-%d_%h:%m:%s`.jpg [ip]/image.jpg   or better yet use the sub command notation, $(...).  wget --output-document=camera_3$(date +%y-%m-%d_%h:%m:%s).jpg [ip]/image.jpg   additionally you can simply the formatting to date like so:  wget --output-document=camera_3$(date +%f_%t).jpg [ip]/image.jpg   the date macros %f and %t are shorthand for the %y-%m-%d and %h:%m:%s formats. 
the quickest way is to set up a nis server and install and configure ypbind to use it
i solved it by installing libpam-unix2 from debian backports and inserting the following lines into /etc/pam.d/login:  session required pam_unix2.so auth required pam_unix2.so nullok account required pam_unix2.so  
check /proc/interrupts to find if one of or more interrupts occur excessively
first, you need to protect the pattern from expansion by the shell
debian and ubuntu are moving to a new multiarch implementation (spec)
assuming your input is small, and the file names don't contain spaces or other weird characters, you can just use ls.  ls -dt $(cat files)   $(cat files) puts the contents of files on the command line, and splits them on whitespace to get a list of arguments
with gnu grep linked to a recent version of the pcre library (perl compatible regular expressions), you could try:  $ grep -op '&lt;essid\b[^&lt;&gt;]*&gt;\k[^&lt;&gt;]*(?=&lt;/essid&gt;)' file wlan-123651234   this would extract the contents of essid tag.  explanation:   &lt;essid matches exactly the string &lt;essid \b called word boundary which matches between a word character and a non-word character, vice-versa. [^&lt;&gt;]* negated character class which matches any character but not of &lt; or &gt;, zero or more times. \k discards the all the previously matched characters from printing at the final. [^&lt;&gt;]* negated character class which matches any character but not of &lt; or &gt;, zero or more times. (?=&lt;/essid&gt;) positive lookahead assertion which asserts that the match must be followed by the string &lt;/essid&gt;.  
quite simple..
if your terminal is still open, type env: it will display all your environment variables
you have to write all the ip (or hostnames)
to search from all available packages to find a particular file, you can use the option wp or se --provides --match-exact as an example:  zypper se --provides --match-exact hg   you will see output similiar to the following:  loading repository data... reading installed packages...  s | name      | summary                  | type    --+-----------+--------------------------+--------   | mercurial | scalable distributed scm | package   from that point you can install the package through a standard zypper install  zypper in mercurial   it should be noted that zypper wp is obsolete and may no longer be available. 
move cursor under a, press v, use arrow key to select until o, press y
i found a script at http://www.linuxforums.org/forum/programming-scripting/190279-daemon-etc-init-d-functions-does-not-return-launching-process.html#post897522 which i was able to modify to suit my needs
write a second script that does the actual calculation and saves the result to a file:  # calculate $curval echo $curval &gt; /var/foo/value.txt   schedule it with cron to run every 2-3 hours.  in the "every 10 minutes" script, simply read the current value from the file:  curval=`cat /var/foo/value.txt`   a nice refinement is to call the calculation script from the "every 10 minutes" script if the value.txt file doesn't exist yet
on ubuntu, some people have had luck doing this using compiz config setting manager
vsz (or virt, depending on the version of top) is the amount of memory mapped into the address space of the process
yes
ubuntu 14.04 has less 458, and fedora 7 has less 394
you can use atop to debug stuff like this
"$(cat mydata)" evaluates to a string which contains the content of the file mydata minus any trailing newline
if clear is clearing history and the terminal there must be a function, alias or script that is doing that
perhaps grass gis pre-defines a variable named "day"?  the code doesn't work in straight bash by the way
it really comes down to what makes up a process in unix
this script works for me:   #!/bin/bash # while ifs= read -r line; do   find "$line" -printf '%t@ %p\n' done | sort -k 1nr | sed 's/^[^ ]* //' | head -n 10   you can pipe your find through it:   (0)asus-romano:~/tmp% find 
the right way in these cases is either to contact your support representative or you can search vendor's web site
the file has probably been locked using file attributes.  as root, do  lsattr zzzzx.php   attributes a (append mode) or i (immutable) present would prevent your rm
i personally prefer view for static content or tail -f for dynamic content.  this does not answer your question, though
the prompt format is in the ps1 environment variable; see the bash manpage, prompting section for format specifiers
first try to umount and mount is again as read write.  if that don't work create a new filesystem and/or partitiontable,  and for that you can use fdisk and mkfs.ext4 or mkfs.vfat. 
rpm -qa --qf '%{name}-%{version}-%{release} %{sigpgp:pgpsig} %{siggpg:pgpsig}\n'  
powertop is not a permanent tool, as you know, so you will have to setup your system to run the commands through sysctl, udev, systemd units, scripts, whatever..
yes, it's man 7 signal which, among other things, includes the following table:     signal     value     action   comment    ──────────────────────────────────────────────────────────────────────    sighup        1       term    hangup detected on controlling terminal                                  or death of controlling process    sigint        2       term    interrupt from keyboard    sigquit       3       core    quit from keyboard    sigill        4       core    illegal instruction    sigabrt       6       core    abort signal from abort(3)    sigfpe        8       core    floating point exception    sigkill       9       term    kill signal    sigsegv      11       core    invalid memory reference    sigpipe      13       term    broken pipe: write to pipe with no                                  readers    sigalrm      14       term    timer signal from alarm(2)    sigterm      15       term    termination signal    sigusr1   30,10,16    term    user-defined signal 1    sigusr2   31,12,17    term    user-defined signal 2    sigchld   20,17,18    ign     child stopped or terminated    sigcont   19,18,25    cont    continue if stopped    sigstop   17,19,23    stop    stop process    sigtstp   18,20,24    stop    stop typed at terminal    sigttin   21,21,26    stop    terminal input for background process    sigttou   22,22,27    stop    terminal output for background process  
users' home directories can be found in in /users/. 
as long as the file is not a symlink or hardlink, you can use sed, tail, or awk
this is a known problem, if you ssh as root somewhere and then su to become a normal user:  $ ssh root@server # su -l anthon $ screen  cannot open your terminal '/dev/pts/3' - please check.   it is e.g
see xserver(1):     -extension extensionname        disables named extension
it sounds like you have the partitions mountable to each other; one way to prevent cross-os access would be to prevent this cross-mounting
it's the meta key
directory permissions:   the write bit allows the affected user to create, rename, or delete files within the directory, and modify the directory's attributes the read bit allows the affected user to list the files within the directory the execute bit allows the affected user to enter the directory, and access files and directories inside the sticky bit states that files and directories within that directory may only be deleted or renamed by their owner (or root)    you can save the files under the ownership of root user and thus this will require them to use password before accessing those files. as said in directory permissions, you can take away  'write bit' and 'execute bit' thus not allowing them to enter directory
imagemagick is your friend here
an easier method is to instead of adding the script to the cron.monthly directory, you add it to an old-fashioned crontab, where you can specify on the crontab line that you want output to go to /dev/null
if you're checking from the server that people are connecting to, then no dice
i have found that this works:  for i in `find 
one general way to find something like this is to capture process listings before and during the program's execution.   ps -a | sort &gt; before.txt run program here; keep it running ps -a | sort &gt; during.txt diff before.txt during.txt   once you have the pathname of the process, use dpkg -s /path/to/file to determine which package owns the file
the brace expansion you're asking about will only expand for files/directories that match on disk to the pattern you use
these device definitions are correct.  the buffer_size is rather small; consider increasing it to be more safe against underruns (but also with larger latency).  to make a device show up in the device list, it needs a name hint:  pcm.hw_plus {     type ...     slave ...     ...     hint.description "my little device, with more cowbell" }  
you're asking the wrong question: you've got an overheating system which should be solved by cooling the system
sorry for the late reply.  i used other command and not xxd since it cannot support a password.  i used openssl command in which i can put a password everytime i encrypt a password:  openssl enc -aes-128-cbc -a -salt -pass pass:test123  now, if i need to decrypt it
you use the -display option as normal
ls itself won't show this information.  you can pipe the output of the find to file -f -, as follows:  $ find /usr/local/bin | file -f - /usr/local/bin:              directory  /usr/local/bin/apt:                  python script, ascii text executable /usr/local/bin/mint-md5sum:                          ascii text /usr/local/bin/search:                     bourne-again shell script, ascii text executable /usr/local/bin/gnome-help:                         python script, ascii text executable /usr/local/bin/office-vb.sh:                           ascii text /usr/local/bin/pastebin:                       python script, ascii text executable /usr/local/bin/highlight:                        posix shell script, ascii text executable /usr/local/bin/yelp:                   python script, ascii text executable   note that find is used instead of ls as it will print the full path, whereas ls will only print the file name
you mentioned /etc/network/interfaces, so it's a debian system...  create a named routing table
here:   check moving from windows to linux: easy steps and resources
this depends on how similar to dyndns.org this service should be.  for your seemmingly small use case i would propably set up a combined dhcp/bind-server (with linux - what else).  the dhcp server is able to update your dns-server that acts as primary server for a subdomain of "your" provider-domain
actually, is dpkg which thinks (rightly so) that your package isn't correctly installed, because the configuration was never done in first place (which is why it says "half-configured")
afaik, xmllint is rather limited
iotop shows statistics from several different origins; take care when adding up stuff.  this previous discussion covers the difference between per-process read/write amounts and the system total read/write amounts: they cover different stuff since the per-process amounts include all i/o (whether to disk, to cache, to network, etc.) whereas the system total is between ram and disk (including swap, delayed cache writes, etc.).  you can't add up numbers from the io&gt; column
this is not a statement about the security of public key pairs or gpg encryption, but wrt entropy and passwords, given a password taken from the range of ascii alphanumeric characters (a-z, a-z, 0-9), the possible number of combinations in 16 characters is:  n = 62^16 = 47672401706823533450263330816   if i have your key and try to "brute force" the password by peeling through all those possibilities, 1 million times per second, then:  n / 1000000 / 3600 / 8760 = 1511681941489838   3600 being the number of seconds in an hour and 8760 being the number of hours in a year, it could, as a worst case scenario, take more than 1.5e13 centuries (1.5 million aeons).  which is why it is very naive to believe that anyone tries to break a password that way.  passwords are important and strong passwords are better than weak passwords, but having "a very (read: very) strong passphrase" is not going to protect you any better from attempts to steal the password, spoof exchanges, or other methods which are not simply about brute forcing the passphrase
your problem may be solved using systemd solely, by simply specifying that your service requires or, even better, bindsto the given device.  quoting:  "if one of the other [required/bound to] units gets deactivated or its activation fails, this unit [service] will be deactivated"  you just need to edit your service file like the following.  [unit] &lt;...&gt; bindsto=&lt;device unit here&gt;.device &lt;...&gt; after=&lt;device unit here&gt;.device   note: to get a list of all available device unit files use systemctl list-units --all --full | grep ".device"  
after considering the options, i decided to modify the command (removed the &amp;&amp; exit) and left it as is for simplicity. 
i know this is an old question, but i recently had the same problem, so i'll provide a solution hoping it'll help someone out there.  it's really easy - use the --force flag.  duplicity --force file:///home/user/backup /   this will probably not only restore missing files to the directories you've backed up, but also replace newer versions of backed up files if they exist, but it's better than nothing. 
you need your ssh public key and you will need your ssh private key
it will always display the "!done" message.  if you want, you could change "!done" to null in command.c (row 272 and 274) to get rid of this behavior.  to get it to execute next-file after the touch command for instance, you could add the following binding:  ^b shell touch ~/testfile\n:n\n   (:n is the default binding for next-file) 
open a terminal and run:  dconf reset /org/gnome/shell/command-history   or  gsettings reset org.gnome.shell command-history   for gnome2:  gconftool-2 -s -t string /apps/gnome-settings/gnome-panel/history-gnome-run []  
any iptables tutorial should do the trick.  positive security is best
there're plenty of documents out there, given a set of rpm packages, you could do something like this,  first install the createrepo script, by  rpm -ivh /path/to/mounted/cdrom/createrepo*.rpm (depends where you mounted your redhat dvd)  now create a folder to hold all rpms that you want to be in the repository, e.g rpms, and put the needed "*.rpm" files inside,  then do createrepo /path/to/rpms to generate metadata.  when finished, add the repository to your yum config, e.g put the following to /etc/yum.repos.d/local.repo  [local] name=local repository demo baseurl=file:///absolute/path/to/rpms enabled=1 gpgcheck=0 protect=1  
you can set it in an existing session with ctrl-b :set display-panes-time 2000 for 2 seconds for example
the point of raid with redundancy is that it will keep going as long as it can, but obviously it will detect errors that put it into a degraded mode, such as a failing disk
assuming the perl rename command:  you're quite close with the last command
i'll assume that extra field from the n lines of file2 should be appended to the last n lines of file1:  awk -f, -v ofs=, 'fnr==nr {a[fnr]=$3; next} {print $0, a[fnr]}' &lt;(tac file2) &lt;(tac file1) | tac     paste -d, &lt;(tac file1) &lt;(cut -d, -f3- &lt;(tac file2)) | tac   these solution add a trailing comma to the first line
the easiest option is to specify its mountpoint:  $ df -h /home filesystem                         size  used avail use% mounted on /dev/mapper/fedora_skrht450s-home  180g  144g   27g  85% /home   the df(1) manpage explains the behaviour you're seeing:     df displays the          amount of disk space available on the file system containing each          file name argument
the unit separator (us) character, also known as is1, is in the cntrl character class and is not in the print character class
the data server driver package for db2 9.5 does not include the install script - that was introduced in 9.7
an option for you is counting number of lease declaration in dhcpd.leases:  dhcpd.leases(5) - linux man page  name  dhcpd.leases - dhcp client lease database  ....  the lease declaration  lease ip-address { statements..
ok, i discovered a solution
i’ve written a function that returns 1 if the argument is the root device, 0 if it is not, and a negative value for error:   #include &lt;stdio.h> #include &lt;stdlib.h> #include &lt;sys/stat.h>  static int root_check(const char *disk_dev) {         static const char  root_dir[] = "/";         struct stat        root_statb;         struct stat        dev_statb;          if (stat(root_dir, &root_statb) != 0)         {                 perror(root_dir);                 return -1;         }         if (!s_isdir(root_statb.st_mode))         {                 fprintf(stderr, "error: %s is not a directory!\n", root_dir);                 return -2;         }         if (root_statb.st_ino &lt;= 0)         {                 fprintf(stderr, "warning: %s inode number is %d; "                                 "unlikely to be valid.\n",                                         root_dir, root_statb.st_ino);         }         else if (root_statb.st_ino > 2)         {                 fprintf(stderr, "warning: %s inode number is %d; "                                 "probably not a root inode.\n",                                         root_dir, root_statb.st_ino);         }         if (stat(disk_dev, &dev_statb) != 0)         {                 perror(disk_dev);                 return -1;         }         if (s_isblk(dev_statb.st_mode))                 /* that's good
make the  mime-info file  $ vi ~/.local/share/mime/packages/x-r-noweb.xml  $ cat ~/.local/share/mime/packages/x-r-noweb.xml &lt;?xml version="1.0" encoding="utf-8"?&gt; &lt;mime-info xmlns="http://www.freedesktop.org/standards/shared-mime-info"&gt;     &lt;mime-type type="text/x-r-noweb"&gt;         &lt;comment&gt;r noweb&lt;/comment&gt;         &lt;glob pattern="*.rnw"/&gt;     &lt;/mime-type&gt; &lt;/mime-info&gt;   update mime database  $ update-mime-database ~/.local/share/mime/  $ xdg-mime query filetype rnoweb0.rnw  text/x-r-noweb $ mimetype -d rnoweb0.rnw rnoweb0.rnw: r noweb $ mimetype rnoweb0.rnw rnoweb0.rnw: text/x-r-noweb   now, you can set the default application  $ xdg-mime default nice-app.desktop text/x-r-noweb # (or edit ~/.local/share/applications/mimeapps.list)  $ xdg-mime query default text/x-r-noweb nice-app.desktop  
folder name example: joe--2014-01-31  folder_name="${user}--$(date +%y-%m-%d)" mkdir "$folder_name"  
the reason for this behavior is that the machine identifier in /etc/machine-id changes at every reboot
i was able to rotate my screens by installing the proprietary amd catalyst drivers for my graphics card and editing xorg.conf.  after installing the drivers i added the line virtual 4096 4096 to my xorg.conf under all of the screenx sections
you need to specify the output width top should use, with the -w parameter (up to a maximum of 512 columns):  nohup top -b -c -d15 -w512 &amp;   if your version of top doesn't support -w, the same effect can be achieved using the columns environment variable:  columns=512 nohup top -b -c -d15 &amp;   as explained by schily, since top isn't outputting to a terminal in this case, it can't determine the terminal width to use and falls back to a safe default. 
if you want to crawl on dirs and subdirs:  find /home/place/to/crawl -type f -exec file --mime-type {}  \; | awk '{if ($nf == "image/jpeg") print $0 }'   what it does?   search all inodes with the type file execute the command file, to get a jpeg header of the file like: image/jpeg awk   edit: added @franklin tip, to use file with -i to use the mime string standard while outputing filetypes
quick and dirty:  in your start up script instead of just executing the python script, use cd first.  #!/bin/sh  cd /home/username/projectname &amp;&amp; python ./scriptname.py  
there is not just one awk and several releases of it
ffmpeg is an os agnostic tool that is capable of determining if a video file has been completely downloaded
you can use the ts command for that:  ts [-r] [-i | -s] [format]  something like the following:  ts_format="%d-%m-%y-%h-%m-%s, " logfile="/home/user/place/backups/backuplog.txt" ls -1tr | head -n -10 | xargs -d '\n' rm -f -v | ts "${ts_format}" &gt;&gt; $logfile   ts is included in the moreutils package.  update: without installing more dependecies  you can use xargs again:  timestamp=$(date +%d-%m-%y-%h-%m-%s) logfile="/home/user/place/backups/backuplog.txt" ls -1tr | head -n -10 | xargs -d '\n' rm -f -v | xargs -l 1 -d '\n' echo "${timestamp}, " &gt;&gt; $logfile   another possibility is to use sed:  timestamp=$(date +%d-%m-%y-%h-%m-%s) logfile="/home/user/place/backups/backuplog.txt" ls -1tr | head -n -10 | xargs -d '\n' rm -f -v | sed "s/^/${timestamp}/" &gt;&gt; $logfile   using awk:  logfile="/home/user/place/backups/backuplog.txt" ls -1tr | head -n -10 | xargs -d '\n' rm -f -v | awk '{ print strftime("%d-%m-%y-%h-%m-%s"), $0}' &gt;&gt; $logfile   and so on. 
assuming a tree like the following  main |--maindata.txt |--sub    |--subdata1.txt    |--subdata2.txt   and you being in directory main as cdw, this can be done with a bash script (even as a one-liner if wish be).  #!/bin/bash for file in sub/* ; do     awk '{actions}' maindata.txt "$file" &gt;&gt; "$file"_differences done   this will simply iterate over all files in your subdirectory and create a file containing the differences for each file in sub. 
here are a couple of ways to monitor accesses to particular files
a process inherits the environment variables from the parent, this means the first time you call screen (create a new one) it has a copy of all the environment variables of the parent process
on a preemptive kernel, a process running in kernel mode can be replaced by another process while in the middle of a kernel function.  this only applies to processes running in kernel mode, a cpu executing processes in user mode is considered "idle"
syntax highlighting tends to be language specific
no, there is no way to do this
this is the default behaviour when using rsync
from man bash:     { list; }           list  is  simply executed in the current shell environment
grep -xv '.\{8,63\}' &lt;input &gt;output   grep's -x switch denotes a whole line match - which is to say that any pattern matched must define a line from head to tail
you can use a tool called linux live usb creator (this is to create the usb from windows)
i like to use the paste command.  paste -d
fold -bw80 /dev/vcs1  substitute 80 for your actual width
sure, this is straightforward
this is an attempt to summarize from the chat troubleshooting session.  the setup turns out to be physical disk -> mdraid raid1 -> lvm
just remove the ipv4 and ipv6 addresses with ip addr flush dev eth1 and ip -6 addr flush dev eth1. 
this kind of site tries to make it difficult not to use a graphical web browser, because if you use wget you'll be missing all these ads that pay for the bandwidth.  some sites don't make advanced checks and can be tricked easily: tell wget to pretend that it's really mozilla and that it's coming from the download site.  wget --user-agent='mozilla/5.0 (windows nt 6.0) gecko/20100101 firefox/14.0.1' \      --referer=http://downloadsite.example.com/download-page-url      http://downloadsite.example.com/download-page-url/filename.ext`   most sites that check let you get away with --user-agent=mozilla and --referer set to the url of the file you're downloading.  with some sites, you might need to export the web browser cookies and pass --load-cookies to wget; at this point using wget starts to be more work than a manual download
you can use zenity (gtk+ dialog display):  zenity --warning --text="warning text" --title="warning title"   change --warning to --error or --info for different window versions
yes you can check /sys/kernel/security what's available
as others have said, this is because the stdin of sh has been redirected to read from the pipe, it is not connected to the terminal as it would normally be
there is a freenas7 repository in the freenas github repository which has some of the documentation that you're looking for
look at the keepcache parameter
distributed works at physical extent level
yes, it's the length in bytes, including the environment.  very roughly:  $ { seq 1 314290; env; } | wc -c 2091391   linux sysconf     the maximum length of the arguments to the exec(3) family of functions.                 must not be less than _posix_arg_max (4096).   posix 2004 limits.h     maximum length of argument to the exec functions including environment data.       minimum acceptable value: {_posix_arg_max}  
you need to sort by the last field (considering / as a field separator)
http://ubuntuforums.org/showthread.php?t=2316240  aswer is here
nproc was the problem:  [root@localhost ~]# ps -elf | grep pascal | wc -l 4068 [root@localhost ~]# cat /etc/security/limits.d/20-nproc.conf # default limit for number of user's processes to prevent # accidental fork bombs. # see rhbz #432903 for reasoning.  *          soft    nproc     4096 root       soft    nproc     unlimited [root@localhost ~]#   man limits.conf states:     also, please note that all limit settings are set per login
this is an example taken from http://www.andybev.com/index.php/using_iptables_and_php_to_create_a_captive_portal 
you can use the equivs tool to create dummy debian packages to satisfy dependencies
i don't know where the "everywhere" is from where you got the instructions that you followed, but the yowsup page is pretty explicit on linux installation:  install using setup.py to pull all python dependencies  linux  you need to have installed python headers (from probably python-dev package) and ncurses-dev, then run  sudo python setup.py install   you should not have to download master.zip as root (sudo), nor extract master.zip as root, but you should follow the instructions to run setup.py, otherwise yowsup will not be installed in your dist/site-packages and python cannot import the package
.war files are packed
you could do this,   x | grep --color=never hello   to quickly test it, you can do,  ls -l /etc/ --color=always | grep --color=never .  
actually, that's an intentional delay to prevent someone from being able to brute force a bunch of passwords in a short time. 
this message is generated by a kernel module called worm:  [myhost ~]% lsmod | grep worm worm                   39172  0  [myhost ~]% grep "worm initializing..." /usr/diags/kernmods/worm/worm.c     printk(kern_alert "worm initializing...");   from the comments in the module source code:  worm.c -- x86 linux wormhole driver for diagnostics for 2.2.x kernels   this kernel module is provided by the field_diags_xe_x86 package, which provides diagnostic tools for sgi hardware:  [myhost ~]% rpm -qf /usr/diags/kernmods/worm/worm.c field_diags_xe_x86-3.24-4a.x86_64 [myhost ~]% rpm -qi field_diags_xe_x86-3.24-4a.x86_64 name        : field_diags_xe_x86           relocations: (not relocatable) version     : 3.24                              vendor: sgi inc. release     : 4a                            build date: wed 05 nov 2008 07:42:58 am mst install date: thu 04 dec 2008 11:29:46 am mst      build host: hook.americas.sgi.com group       : applications/system           source rpm: field_diags_xe_x86-3.24-4a.src.rpm size        : 103026006                        license: sgi signature   : (none) packager    : developer dsd on machine hook url         : http://wwwcf.americas.sgi.com/public/diags/menus/sn2mhome.html summary     : sgi altix xe x86 online diagnostics description : the sgi altix xe x86 online diagnostics software package.   so this message in dmesg is not malicious, though the kernel module may be poorly named. 
use this:  user@host:~$ echo "my string to encrypt" | openssl aes-256-cbc -e -a -k 00000000000000000000000000000000 -iv 00000000000000000000000000000000 a7svr6j/uaz4ky9jvwbjaur/d5qdh5ua/vztln7u/fe= user@host:~$ echo "a7svr6j/uaz4ky9jvwbjaur/d5qdh5ua/vztln7u/fe=" | openssl aes-256-cbc -d -a -k 00000000000000000000000000000000 -iv 00000000000000000000000000000000 my string to encrypt   or you could use command substitution:  user@host:~$ openssl aes-256-cbc -a -k 00000000000000000000000000000000 -iv \ 00000000000000000000000000000000 -in &lt;(echo "my string to encrypt") -out encrypted.txt  
to clear up a fundamental misconception, dmesg does not read from /var/log/dmesg
there is no stand-alone read command: instead, it is a shell built-in, and as such is documented in the man page for bash:  read [-ers] [-a aname] [-d delim] [-i text] [-n nchars] [-n nchars] [-p prompt] [-t timeout] [-u fd] [name ...] [...]        -r     backslash does not act as an escape character
nothing wrong with splitting it up with backlashes as you showed
if i've planned ahead, i use brace expansion
that is the way it works
you don't need to process things like ~, the shell does it for you
to make this an alias, which is possible, you need to use double quotes around the entire value for the alias
man page of time says     the statistics of time command consist of       (i) the elapsed real time between invocation and termination,      (ii) the user cpu time (the sum of the tms_utime and tms_cutime values   in a struct tms as returned by times(2))      (iii) the system cpu time (the sum of the tms_stime and tms_cstime   values in a struct tms as returned by times(2)).   you can see this where the time command is implemented in c program.  the total cpu time is the combination of the amount of time the cpu(s) spend performing some action for a program and the amount of time the cpu(s) spend performing system calls for the kernel on the program's behalf
more digging revealed another solution using plain bash and a normal user account
as mentioned by dopeghoti, you can do this using symlinks:  cd mv .vimrc workspace/dotfiles/ ln -s workspace/dotfiles/.vimrc .   this generally works quite well.  there is a more sophisticated tool designed just for this though: vcsh
the cron job is defined in /etc/cron.daily/mlocate.  to run it immediately:  sudo updatedb   or better  sudo ionice -c3 updatedb   this is better because updatedb is set in the idle i/o scheduling class, so that it do not disturb (from the i/o point of view) other applications
the tsocks application can socksify every other applications  tsocks app args  
yes, the argument -i will print the inode number of each file or directory the ls command is listing. as you want to print the inode number of a directory, i would suggest using the argument -d to only list directories. for printing the inode number the directory /path/to/dir, use the following command line:  ls -id /path/to/dir   from man ls:     -d, --directory           list  directory entries instead of contents, and do not derefer‐           ence symbolic links    -i, --inode           print the index number of each file  
gemalto drivers are now open source i believe
you can check the status code of mount, and most well written executables, with the shell special parameter ?.  from man bash:  ?  expands to the exit status of the most recently executed foreground pipeline.  after you run the mount command, immediately executing echo $? will print the status code from the previous command.  # mount /dev/dvd1 /mnt   mount: no medium found on /dev/sr0 # echo $?   32   not all executables have well defined status codes
usually linux does not log which processes access a file (because of the cost in performance and storage)
${#1} is the length (in number of characters) of $1 which is the first argument to the function.  so (( ${#1} == 0 )) is a convoluted way to test whether the first argument is empty (or unset, unset parameters appear as empty when expanded) or not
that's almost certainly a multi-byte utf-8 character getting interpreted as 2 single-byte characters in some other encoding.  the ability to show utf-8 is more a problem on the client side than the server side
there's a tool called cpuid that one can use to query for much more detailed information than is typically present in lshw or /proc/cpuinfo
now that i'm at work, i'll write up a step by step answer
as jasonwryan pointed out, you can do this more easily by using the aur package
it is not just gnu sort that has it
if it's a postscript printer, surely the raw printer output is already postscript...?  basic postscript is human-readable
if you specify the user_config_dir in vsftpd.conf, you can set any config option on a per-user basis.  from man vsftpd.conf:    this powerful option allows the override of any config option specified in the manual page, on a per-user basis
i found a simple way to do it over the browser.  just went to http://localhost:631 and then to administration
this seems to have worked for the op.  gdbserver :2345 ls &gt; /dev/null 2&gt;&amp;1 &amp;   i think the reason for this is because when a program is daemonized it closes all the stdio 0,1 &amp; 2
apple's package management system is often subject to criticism
'root' is traditionally the name given to the user account with superuser level rights
(converted from question edit)  this is solved by upgrading rsync
   what is the error i get with login?   when searching trough the source code of login, we see this passage:  amroot = (getuid () == 0); [...] utent = get_current_utmp (); /*  * be picky if run by normal users (possible if installed setuid  * root), but not if run by root
quick answer: yes
without / it might also be a file.  in some situations it can be deadly
you need to reinstall grub, you can do this from a chroot
bash version 4 introduced built-in case-modification operators ^ and , operators, making it possible to avoid external programs like awk for such simple string manipulations if you have a recent version of the bash shell
you'll want to use the iptables owner module and perhaps some clever packet mangling.     owner this module attempts to match   various characteristics of the packet   creator, for locally-generated   packets
the problem isn't related to the -and operator, but to the unintuitive syntax of the argument of -size
if you simply want to treat a string as a literal in sed there's already an answer for that:  escaped_testx="$(sed -e 's/[\/&amp;]/\\&amp;/g' &lt;&lt;&lt; "$test"; echo x)" escaped_test="${escaped_testx%x}"   the extra x is to be able to handle trailing newlines, which would otherwise be removed by the command substitution. 
thanks to @derobert for recommending the dragbox application to me.  dragbox does exactly what i need
if fbat insists on getting its input from the terminal and you want to automate, the solution is to use expect (or pexpect)
did you try the man pages? both cgconfig.conf(5) and cgrules.conf(5) have nice examples, it shouldn't be difficult modifying those to match your needs
this should work
the needrestart package will implement what you are describing once installed. 
you could add globdots to $_comp_options in your .zshrc e.g.  ..... compinit _comp_options+=(globdots) .....  
you need both h and b if you want to match headers and body
the input format requires character-backspace-underscore or character-backspace-letter to underline a character
as requested by the asker: according to your ping output there is a network connection
find doesn't have sophisticated options like ls
the easy way to try is to initiate process (ssh -ms ssh.sock &lt;my-server&gt;), remove socket and try how will it behave
since this is the fglrx driver, you can use the aticonfig command to generate an xorg.conf file
this is not a term that i've heard with regard to filesystems
yes:   install homebrew brew install coreutils ln -s /usr/local/bin/gtac /usr/local/bin/tac   or use macports to install coreutils in a similar way. 
you can configure the key bindings and set many settings for less in a file called ~/.lesskey
the best and easiest way is to use tmux or gnu screen
found it on imagemagick.org site:  convert image.png  -bordercolor white -border 0 \       \( -clone 0 -resize 16x16 \) \       \( -clone 0 -resize 32x32 \) \       \( -clone 0 -resize 48x48 \) \       \( -clone 0 -resize 64x64 \) \       -delete 0 -alpha off -colors 256 favicon.ico  
method #1  try a line like this in /etc/fstab:  uuid=xx  /home/user/extradrive ext3   rw,noauto,user,sync          0  2   method #2  examples are also shown using uid/gid too:  uuid=xx  /home/user/extradrive ext3   rw,exec,uid=userx,gid=grpx   0  2   note  you can also override when doing the actual manual mounting like this using mount + options:  $ sudo mount &lt;device&gt; &lt;mount-point&gt; -o uid=foo -o gid=foo   method #3  lastly, you can avoid the whole business by making the top level of the mounted extra drive owned by userx/groupx like so, after manually mounting the hdd:  $ sudo chown -r userx.groupx &lt;directory&gt;   then in /etc/fstab do  &lt;device&gt;    &lt;directory&gt;  ext3   user,defaults 0 2   the userx should now be able to access the drive upon reboots
creating an ha environment has a lot of caveats and is complicated, and often times depends on the actual software (e.g
if you really want to do this with dd, you need to split your reads up:  dd if=/dev/sda bs=512 count=60515006 | gzip -9 &gt; dump1.gz   will dump the first 60515006 sectors of /dev/sda to dump1.gz, compressing with gzip
first, let's be lazy: this can be done using the gui
no, openjdk doesn't do that
optimal blocksizes for dd are around 64k-256k, humans usually prefer 1m.  why are you overwriting your ssd like this in the first place? normally, you try to avoid unnecessary writes on ssds; if it considers all of its space used, it will likely also lose some of its performance until you trim it free again.  you could use this command instead to trim/discard your entire ssd:  blkdiscard /dev/sda   if your ssd has deterministic read zeroes after trim (a property you can check with hdparm -i) it will look like it's full of zeroes, but the ssd actually considers all of its blocks as free which should give you the best possible performance.  the downside of trim is that you lose all chances at data recovery if the deleted file has already been discarded...    a benchmark without real i/o:  $ for bs in 512 4k 16k 64k 128k 256k 512k 1m 4m 16m 64m 128m 256m 512m &gt; do &gt;     echo ---- $bs: ---- &gt;     dd bs=$bs if=/dev/zero of=/dev/null iflag=count_bytes count=10000m &gt; done ---- 512: ---- 20480000+0 records in 20480000+0 records out 10485760000 bytes (10 gb) copied, 4.2422 s, 2.5 gb/s ---- 4k: ---- 2560000+0 records in 2560000+0 records out 10485760000 bytes (10 gb) copied, 0.843686 s, 12.4 gb/s ---- 16k: ---- 640000+0 records in 640000+0 records out 10485760000 bytes (10 gb) copied, 0.533373 s, 19.7 gb/s ---- 64k: ---- 160000+0 records in 160000+0 records out 10485760000 bytes (10 gb) copied, 0.480879 s, 21.8 gb/s ---- 128k: ---- 80000+0 records in 80000+0 records out 10485760000 bytes (10 gb) copied, 0.464556 s, 22.6 gb/s ---- 256k: ---- 40000+0 records in 40000+0 records out 10485760000 bytes (10 gb) copied, 0.48516 s, 21.6 gb/s ---- 512k: ---- 20000+0 records in 20000+0 records out 10485760000 bytes (10 gb) copied, 0.495087 s, 21.2 gb/s ---- 1m: ---- 10000+0 records in 10000+0 records out 10485760000 bytes (10 gb) copied, 0.494201 s, 21.2 gb/s ---- 4m: ---- 2500+0 records in 2500+0 records out 10485760000 bytes (10 gb) copied, 0.496309 s, 21.1 gb/s ---- 16m: ---- 625+0 records in 625+0 records out 10485760000 bytes (10 gb) copied, 0.972703 s, 10.8 gb/s ---- 64m: ---- 156+1 records in 156+1 records out 10485760000 bytes (10 gb) copied, 1.0409 s, 10.1 gb/s ---- 128m: ---- 78+1 records in 78+1 records out 10485760000 bytes (10 gb) copied, 1.04533 s, 10.0 gb/s ---- 256m: ---- 39+1 records in 39+1 records out 10485760000 bytes (10 gb) copied, 1.04685 s, 10.0 gb/s ---- 512m: ---- 19+1 records in 19+1 records out 10485760000 bytes (10 gb) copied, 1.0436 s, 10.0 gb/s    the default 512 bytes is slow like hell (two syscalls per 512 bytes is just too much for the cpu) 4k is considerably better than 512 16k is considerably better than 4k 64k-256k is about as good as it gets 512k-4m slightly slower 16m-512m speed cuts in half, worse than 4k.   my guess is that starting with a certain size, you start losing speed due to lack of concurrency
ubuntu forums suggests the following:  gconftool --type int -s /apps/gnome-power-manager/backlight/idle_dim_time ***time*** gconftool --type int -s /apps/gnome-power-manager/timeout/sleep_display_battery ***time*** gconftool --type int -s /apps/gnome-power-manager/timeout/sleep_computer_battery ***time***  
probably the rule, should be:  pass  in   quick proto tcp  from any  to any port = 22 keep state  pass  out  quick proto tcp  from any  to any port = 22 keep state   in /etc/ipf.conf 
and for the first question: uname, when passed no option, is equivalent to uname -s thus displays linux on your system.  the gcc argument passed is not an option (doesn't start with an hyphen) so is simply ignored by the command. 
the %cpu and c columns are showing almost, but not quite, the same thing
as @jcbermu said, for most programs and in most cases,  the order of command line flags is not important
newer kernels use kms by default, so you should move away from appending vga= to your grub line as it will conflict with the native resolution of kms
the problem lies in your input from yyyy_mm_dd
run du -x / &gt;/tmp/du to generate a breakdown of disk usage per directory on the / filesystem (-x means “don't traverse other filesystems”).  your biggest consumers are:   588m    /home — 0.6gb of user data 1015m   /opt — 1gb of software that you installed manually 6.4g    /usr — 6.4gb of software installed via packages 350m    /var — 0.3gb of data used by system software   none of that is surprising
ok,  i have stumbled upon the solution. here's the link where i got the info from: http://brickybox.com/2009/10/18/os-x-fix-argentina-dst-october-2009  the tzdata source has changed its url
with gnu:  cd ~/path/to/dirs || exit 1 find /path/to/dirs -type d -printf %p\\0 | xargs -0 mkdir -p  find /path/to/dirs -type f -print0 |    xargs -0 cp --symbolic-link --parents --target-directory=.  
make a wrapper script around /usr/bin/gpgv
based on your additional output, it appears that pywwetha is listening on port 80
many wireless card manufacturers support only windows or mac os platforms
it works in both bash and zsh.  $ alias cd1='cd /' $ alias cd01=cd1 $ cd01; pwd / # now, to change cd1 $ alias cd1='cd /etc' $ cd01; pwd /etc  
for the question, where file1.pgm and file2.pgm are files whose contents you want sent to a.out as input:  cat file1.pgm file2.pgm | ./a.out   if file1.pgm and file2.pgm are executables that produce output for a.out:  (file1.pgm; file2.pgm) | ./a.out  
there is a system call named ptrace
single bracket is the traditional form, and is often implemented as an external command
 why would it be set to 0?  i can see a few possible reasons for this.  because you are running on ec2, your hardware (storage and compute instance) is virtualized
of course it is doable:  scp file user@host: ssh user@host path_to_script scp user@host:file_to_copy ./   and that's it...  but there is one problem: you will be asked for password three times
you can't derive a private key from a passphrase
your snippet does not show that anyone got into your system, only that there were attempts
bash operator [ may not be what you are looking for; however, [[ does support =~
i had the same question asking myself some time ago, and i wrote an article how you can do this.  first of all, you can run   make -dbatch install clean   to accept default configuration for all packages (for dependencies too)
historically, there have been many incompatible extensions of the original mail commnad
if [ ! $comment ]   i think you meant to check whether $comment is non-empty, but that's not what this command does
getopt is perfectly fine with having no short options
with gnu xargs:  xargs -d '\n' mkdir -p -- &lt; foo.txt   xargs will run as few mkdir commands as possible.  with standard syntax:  (export lc_all=c  sed 's/[[:blank:]"\'\'']/\\&amp;/g' &lt; foo.txt | xargs mkdir -p --)   where it's not efficient is that mkdir -p a/b/c will attempt some mkdir("a") and possibly stat("a") and chdir("a") and same for "a/b" even if "a/b" existed beforehand.  if your foo.txt has:  a a/b a/b/c   in that order, that is, if for each path, there have been a line for each of the path components before, then you can omit the -p and it will be significantly more efficient
cd only takes one argument
in addition to the existing answer.  if you prefer (like i do) to use the syntax from the iptables-save and iptables-restore command ip6tables-save and ip6tables-restore can be used.  the convenient part is that you can share the same rule file for iptables-restore and ip6tables-restore respectively by prefixing all the version-specific lines with -4 and -6 respectively and leaving it out on lines that apply to both ipv4 and ipv6.  in order to to check for the correct address family ($addrfam) in your script, use:  set -e case "$1" in start)   case $addrfam in   inet)  iptables-restore  &lt; /etc/myfwrules.txt ;;   inet6) ip6tables-restore &lt; /etc/myfwrules.txt ;;   esac   # ...   ;; stop)   # ...   ;; esac exit 0  
gnupg branches  there are different release branches of gnupg, modern, stable and classic.     three different versions of gnupg are actively maintained:         gnupg "modern" (2.1) is the latest development with a lot of new features
the best command-line media type identification tool i'm aware of is mediainfo
command     pid     user   fd   type device size/off     node name webalizer 32342 ctxmortg    5uw  reg   8,17    12288 32890954 /home2/ctxmortg/tmp/webalizer/eyebestdatedotcomauph.ctxmortgagemortgagerefi.com/dns_cache.db   fd - file descriptor  if you are looking for file being written, look for following flag  # - the number in front of flag(s) is the file descriptor number of used by the process to associated with the file u - file open with read and write permission r - file open with read permission w - file open with write permission w - file open with write permission and with write lock on entire file mem - memory mapped file, usually for share library   so 3r means webalizer has a descriptor number 3 associated with ...dns_cache.db, with read permission.  type - file type  in linux, almost everything are files, but with different type.  reg - reggular file, file that show up in directory dir - directory   node  inode number in filesystem  you can find complete details here or here. 
you are pretty close already
my system is a little dated, fedora 14, so i don't have that group, but i do have this group "printing support", but i believe my examples are still relevant to your question.  as you've already mentioned, you can use the command yum groupinfo &lt;group name&gt; to find out what packages are provided by a particular group
android doesn't use rpm as its package format, it uses apks
you can use filtering within top with o (small 'o')
assuming one has an appropriate version of ls, this is possibly the simplest way:  ls -i "*.txt" -i "*.pdf"   if you want to iterate across all the subdirectories:  ls -i "*.txt" -i "*.pdf" -r  
try this (empty line remove is now at first position):    sed -e '/^$/d' -e 's/\r//g' -e '/^{$/d' -e '/^}$/d' -e ':begin;$!n;/^state-text: {[[:space:]]\n/s/\n//;tbegin;p;d' -e "s/'/''/g" &lt;&lt;&lt; $myvar     the part, which is responsible for the not working empty-line-remove is this one:    -e ':begin;$!n;/^state-text: {[[:space:]]\n/s/\n//;tbegin;p;d'   going deeper...     d deletes the contents of the patterns space, up to the first newline (or to the end if there is no newline), and starts a new cycle
use hpvmconsole -p &lt;vm id&gt; to connect the hpux virtual machine from the host.  to get vm id type the command hpvmstatus in the host and you will get the details of virtual machine present in the host
(you might have to install the package ip on openwrt (v12 / attitude adjustment)  ifconfig/netstat etc
if the kernel killed a process (because the system ran out of memory), there will be a kernel log message
i found the answer burried in another thread:   a uuid identifies a filesystems, whereas a partuuid identifies a partition (i.e
bash will interpret a number with a leading zero as octal
see the bash man page, which shows that the syntax when using braces ({, }) is:  { list; }   this means that you are missing a couple of semicolons:  { [ $# -ne 2 ] &amp;&amp; [ $# -ne 3 ]; } &amp;&amp; { echo "uso: $0 [opciones] [nlineasresultado] [archivos a analizar]" &amp;&amp; echo "need 2 or 3 parameters" &amp;&amp; exit 1; }   note that you can also use newlines to achieve the same thing
i'd use the "curl" command line tool to do this
something like this ?   sed -i "s/^%.*$/$(tput setaf 1)\\0$(tput sgr0)/" a.log    and use cat -v file for displaying content without parsing colors. 
redirect the error stream to a file that you can read later
i think you might be misunderstanding what is meant by:  if this option is used several times, the last one will be used.   curl doesn't remember this value between invocations or anything like that
for someone this may be easier to remember:  ls -l | grep 
there is a 'goldendict' package that is part of epel
you still use grep..
if you want this to happen by default when you run screen, then you'll need to edit your .screenrc file
you can use dialog utility
a symbolic link is where a file has one main name, but there is one extra entry in the file name table that refers any accesses back to main name
for salt, the idea is simple:  3des for example has 11 characters of hashed password plus 2 characters of salt
if you want to catch them all, there is no other choice but to do full filesystem traversals
characters of code 0 to 31 in ascii are control characters
you seem to want to change all occurrences of  tranf_field.some_enum_value.toint()  to  tranf_field.that_enum_value  while leaving other enumerations (e.g., trang_field.trang_value.toint()) and other methods (e.g., tranf_field.tranf_value.length()) alone.  this seems simple:  sed 's/\(tranf_field\.[a-za-z0-9_]*\)\.toint()/\1/'   where   [a-za-z0-9_]* is any number of alphanumeric characters (including underscores).  this is intended to match any valid enumeration value.  actually, [a-za-z_][a-za-z0-9_]* would be better, because [a-za-z0-9_]* could match an empty string, or one beginning with a digit. \(…\) groups the enumeration name (tranf_field), the literal period (\.), and the enumeration value (from the first bullet). \1 means “replace the complete string that you found with the first group”, i.e., discard the .toint() part. to handle multiple occurrences per line, add g (global) after the last slash. this will not handle embedded whitespace, e.g., tranf_field 
so what is wrong with a simple chown/chmod?:  cd /tmp mkdir question sudo chown root:root question [sudo] password for user:  chmod 777 ./question touch sth rm sth cd .. rm question -rf rm: cannot remove `question': operation not permitted   ok, let me tell you what is wrong with this: every user has all access to every file in the question directory due to the 777 permissions
the file is created in place where you executed the script
a quick test with info here tells me that pressing enter one time works
you assume that the attacker has made a virtual machine that perfectly emulates your hardware
by default, you can always list other users processes in linux.  to change that, you need to mount proc in /etc/fstab with hidepid=2:   proc            /proc           proc    defaults,hidepid=2   this functionality is supported from kernel v3.2 onwards
for full details, see specifying file variables    there are two ways to specify file local variable values: in the first line, or with a local variables list
the problem is probably with grub seeing usb disks at boot time differently than once run from a running system
you can probably tweak your unix tools to handle the encoding correctly
if you see that the package is available in the testing distribution, then you can assume that it is planned to be released in the next release, as testing is what will become the next stable release.  another clue is to check who the maintainer is
you can do the thing you said:  this_variable=$(echo foo| foobarize; printf .) this_variable=${this_variable%.}   that won't strip any trailing newlines
manually changing the .config file without kconfig is discouraged as it might lead to unexpected behavior
there's no need to escape it if you just want an exclamation mark in the prompt
centos init scripts use /etc/init.d/functions, which declares a "daemon" function that most other init scripts use
as i understand it, you want to see the files, if any, hidden by the mount /dev/sda1 /tmp/somefolder command
the pam_limits.so module can help you there
{ i=0 while ifs= read -r line; do   case "$line" in     ssh*|'##'*)       ;;     server*)       ((++i))       ;;     *)       if ((i&gt;0)); then echo $i;i=0; fi       echo "$line"       ;;   esac done if ((i&gt;0)); then echo $i;i=0; fi } &lt;inputfile &gt;outputfile   the same in perl one-liner  perl -nle '   begin{$i=0}   next if/^(ssh|##)/;   if(/^server/){++$i;next}   print$i if$i&gt;0;   $i=0;   print;   end{print$i if$i&gt;0}' inputfile &gt;outputfile   and golfed  perl -nle's/^(ssh|##|(server))/$2&amp;&amp;$i++/e&amp;&amp;next;$i&amp;&amp;print$i;$i=!print}{$i&amp;&amp;print$i' inputfile &gt;outputfile  
it seems like the main problem is the bt home hub version 4 which came with the internet subscription
the syntax str^^ which you are trying is available from bash 4.0 and above
first, create a new file in the /etc/sysconfig/network-scripts directory called ifcfg-team0 that looks like this:  device=team0 devicetype=team onboot=yes bootproto=none ipaddr=1.2.3.4 netmask=255.255.255.0 team_config='{"runner": {"name": "lacp"}, "link_watch": {"name": "ethtool"}}'   obviously you need to change the ip address and netmask appropriately.  then in the same directory, change all of the ifcfg-eno[1-4] files to look like this:  device=eno1 hwaddr=00:11:22:33:44:55 devicetype=teamport onboot=yes team_master=team0 team_port_config='{"prio": 100}'   as above, your local files will differ a bit, because you will need to preserve the existing hwaddr setting.  this is straight out of the manual.  the ifcfg-team0 file refers to the lacp.conf file you have already created
to switch to console mode press ‘ctrl + alt + f1' (f2 -- f6) to switch between consoles in console mode press ‘alt + f1' (f2 -- f6) to switch to gui mode press ‘alt + f7'  
assuming listoffiles is the file with the list of names, and they all start with / so you want to prefix with "http:/", and use curl, say, to get the file, you can do something simple like:  while read file do    if curl "http:/$file" | grep 'my pattern'   then svn ..."$file"...   fi done &lt;listoffiles  
echo 'áé{d`as' | lc_all=c tr -cd '[:alnum:]|'   (note that it will also remove the newline character appended by echo).  lc_all fixes the locale which determines what characters are and which of them are considered letters or numbers
you should be able to do it using xfce's keyboard settings
if a file can be read, it can be copied
after some more searching it turned out what i already suspected: apt itself provides a set of hooks to invoke commands at certain events, which is used by a lot of tools but seems to be barely documented.  calling a tool like checkrestart after a package upgrade is fairly simple
usually, you can use sighup to "friendly" close an application (with or without graphical interface).  kill -hup &lt;application_pid&gt;   edited: added some other info  the way sighup is handled is application dependent so, as dave noted, it can happen that this signal is masked or handled
from the glossary in /usr/share/doc/man-db/man-db-manual.txt (source is manual/glossary.me):  cat page      a formatted manual page suitable for viewing on a vt100-type terminal.  stray cat page      a cat page that does not have a relative manual page on the system,  i.e.      only  the  cat page was supplied or the manual page was removed after the      cat page had been created. 
first   as i know apache/http authentication don't gives you control. after first authentication, your server cannot instruct the browser to logout or timeout, because http authentication doesn't work with session/cookies and the browser will continuously send authentication credentials
i assume you want to do this from the command line?   if so, use ls  ls *.jpg   * is a wildcard     which will get all files that end with .jpg 
once upon a time i told my debian fairy that i want compose instead of caps lock and typing compose space space now gives me the super solid unbreakable space:  compose space space ! compose space space ! compose space space ! compose space space ! compose space space ! compose space space ! compose space space ! compose space space !   for debianish systems have a look into /etc/default/keyboard, i have the following assigment there: xkboptions="compose:caps".  alternatively, if you're using kde, the "advanced" tab, of the kcmshell4 kcm_keyboard command lets you configure what key to map to compose.  this setting affects the text terminals too..
systemd-cgtop -n1   will do 1 iteration  to find if you are attached to a tty put a line in your script:  tty  #!/bin/sh #  how to check what tty you are on. echo -ne "connected tty: "`tty`  line=$(systemd-cgtop -n1|grep ezdose) echo $line  
the unix time is given as seconds since the epoch: the number of seconds (not counting leap seconds) that have passed since 00:00:00 coordinated universal time (utc), or thursday, january 1st, 1970,   the gnu date command has some very nice features that allow you to translate between different time formats
yes stacks grow dynamically
most touchpads can be manipulated with the command line tools synclient and xinput
i usually use the column program for this, it's in a package called bsdmainutils on debian:  column -t foo   output:  case           elems  meshing   nlsys uniform        2350   0.076662  2.78 non-conformal  348    0.013332  0.55 scale          318    0.013333  0.44 smarter        504    0.016666  0.64 submodel       360    .009999   0.40 unstruct-quad  640    0.019999  0.80 unstruct-tri   1484   0.01      0.88   excerpt from column(1) on my system:  ...  -t      determine the number of columns the input contains and create a         table
i just ran into this problem myself, and it took quite a bit of searching to find the answer! so here it is, and it works for me.  to use multiple versions of unison, install unison-all
as @meuh pointed out in the comment, i need to run the test on my ext4 partition, while i tried it on my /tmp solved!  ps: following the test result, i can confirm that the drive on my xps 9343 (samsung pm851 m.2 2280 256gb, firmware revision:  ext25d0q) supports trim command, even if dmesg reports ncq send/recv log not supported 
you could try like this:  example 1: your answer.  #!/bin/bash read -e -p "enter a directory: " directory new_directory="$(echo $directory | sed 's/ /\\ /g')" echo $new_directory   example 2: if you are going to cd script output wrap it with double quote.  #!/bin/bash read -e -p "enter a directory: " directory new_directory=\"$directory\" echo $new_directory  
for a fresh install of fedora 19:  step 1: from a computer having access to internet, download the following packages from  pkgs.org  cpp-4.8.1-1.fc19.x86_64.rpm gcc-4.8.1-1.fc19.x86_64.rpm gcc-c++-4.8.1-1.fc19.x86_64.rpm glibc-2.17-14.fc19.x86_64.rpm glibc-common-2.17-14.fc19.x86_64.rpm glibc-devel-2.17-14.fc19.x86_64.rpm glibc-headers-2.17-14.fc19.x86_64.rpm kernel-devel-3.9.5-301.fc19.x86_64.rpm kernel-headers-3.9.5-301.fc19.x86_64.rpm libmpc-1.0.1-1.fc19.x86_64.rpm libstdc++-devel-4.8.1-1.fc19.x86_64.rpm perl-5.16.3-264.fc19.x86_64.rpm perl-carp-1.26-243.fc19.noarch.rpm perl-encode-2.51-1.fc19.x86_64.rpm perl-filter-1.49-1.fc19.x86_64.rpm perl-libs-5.16.3-264.fc19.x86_64.rpm perl-macros-5.16.3-264.fc19.x86_64.rpm perl-pathtools-3.40-1.fc19.x86_64.rpm perl-pod-escapes-1.04-264.fc19.noarch.rpm perl-pod-simple-3.20-264.fc19.noarch.rpm perl-scalar-list-utils-1.27-246.fc19.x86_64.rpm perl-socket-2.009-2.fc19.x86_64.rpm perl-threads-1.87-1.fc19.x86_64.rpm perl-threads-shared-1.43-2.fc19.x86_64.rpm   step 2: copy them to the machine and run the command:  # yum install *.rpm   step 3: download compat-drivers-2013-03-04-u.tar.bz2 then run the commands:  # tar -xf compat-drivers-2013-03-04-u.tar.bz2 # cd compat-drivers-2013-03-04-u # ./scripts/driver-select alx &amp;&amp; make &amp;&amp; make install # reboot   taken from: http://commandlinewani.blogspot.in/2013/11/how-to-install-atheros-wired-lan.html 
your script changes directories as it runs, which means it won't work with a series of relative pathnames
you want select-pane:  bind c-l select-pane -l bind c-h select-pane -r bind c-k select-pane -u bind c-j select-pane -d 
i prefere fetchmail
the reason that installing command-not-found did not start providing suggestions for non-installed packages was that i had missed a small notification from dpkg as part of the install
search  x is for extract.  after you are inside man, type /-xenter to search info about the -x parameter, press n to jump to the next -x match, and n for the previous  search with regex  for large man pages, or a common terms, a little regex can be used to narrow the search.  if you just want the main entry, you can use /^ *-x to remove most extraneous matches. this works as most man pages are formatted with the entry indented with spaces
your question isn't clear as q by default prints the numbers of the panes, it doesn't switch between them...  nevertheless, you can achieve what you are after with some simple binds: first, resetting the prefix key to q and then setting f1 to move to the left pane and f2 to the right
if you install the alsa driver for pulseaudio then it will redirect alsa audio through pulseaudio instead of hogging the alsa device directly. 
if you have lshw installed:  $ sudo lshw -c memory   example  $ sudo lshw -c memory ...   *-cache:0        description: l1 cache        physical id: a        slot: internal l1 cache        size: 32kib        capacity: 32kib        capabilities: asynchronous internal write-through data   *-cache:1        description: l2 cache        physical id: b        slot: internal l2 cache        size: 256kib        capacity: 256kib        capabilities: burst internal write-through unified   *-cache:2        description: l3 cache        physical id: c        slot: internal l3 cache        size: 3mib        capacity: 8mib        capabilities: burst internal write-back   *-memory        description: system memory        physical id: 2a        slot: system board or motherboard        size: 8gib      *-bank:0           description: sodimm ddr3 synchronous 1334 mhz (0.7 ns)           product: m471b5273ch0-ch9           vendor: samsung           physical id: 0           serial: 67010644           slot: dimm 1           size: 4gib           width: 64 bits           clock: 1334mhz (0.7ns)      *-bank:1           description: sodimm ddr3 synchronous 1334 mhz (0.7 ns)           product: 16jtf51264hz-1g4h1           vendor: micron technology           physical id: 1           serial: 3749c127           slot: dimm 2           size: 4gib           width: 64 bits           clock: 1334mhz (0.7ns)  
really ugly and probably works only with gnu date:  date -d "$( date -d "$( date +'%y-01-01' ) +40 weeks") -$( date -d "$( date +'%y-01-01' ) +40 weeks" +'%w' ) days+1 day" +'%y-%m-%d'   tested only for your 3 october example, may fail for some other cases.    update: if you have a non eng locale you need to specify the output from the inner date to get to to work
vinagre appears to work well enough.  &nbsp;&nbsp;&nbsp;  you invoke it from the command line like so:  $ vinagre   there is also a applet that should be available when you install it so that you can just pick machines that you've bookmarked with it form a pulldown when you add the applet to your toolbar. 
i've found the solution: the index of x font files was not created.  i discover this looking at the /var/log/xorg.0.log log file.  $ grep /fonts /var/log/xorg.0.log.old  [    13.492] (ww) the directory "/usr/share/fonts/type1/" does not exist. [    13.493] (ww) `fonts.dir' not found (or not valid) in "/usr/share/fonts/100dpi/". [    13.493]    (run 'mkfontdir' on "/usr/share/fonts/100dpi/"). [    13.493] (ww) `fonts.dir' not found (or not valid) in "/usr/share/fonts/75dpi/". [    13.494]    (run 'mkfontdir' on "/usr/share/fonts/75dpi/").     /usr/share/fonts/misc/,     /usr/share/fonts/ttf/,     /usr/share/fonts/otf/   i then run mkfontdir on /usr/share/fonts/75dpi and /usr/share/fonts/100dpi and that was solved. 
i asked the graphviz developers about this and looks like the answer is that there is no way to do that:     we looked at this problem years ago
use grep or any other search tool to look for the definition:  grep -r '^struct task_struct ' include   or search online at lxr: http://lxr.linux.no/linux+v2.6.30.5/+search?search=task_struct  the structure is still defined in include/linux/sched.h
as you have the machine c on the internet, make a special account there named sesame, and  on a you make an account with a public/private key from which you have copied the public key to the sesame account on c.  you can now login from a to c, but instead of doing that you do:  ssh -n -r 19930:localhost:22 sesame@yourserverc   ( you might want to combine this with a sleep statement or e.g
debian expects you to install ntp yourself if you want your clock synchronized
performing ssh tunneling can get a bit confusing with all the terminology, but there is a complementary feature to -l, which provides you the ability to "dynamically" assign ports by allocating a socket locally, instead of a single port.  from the man page:   -d [bind_address:]port     specifies a local ``dynamic'' application-level port forwarding
assuming you're on linux.  try:  sudo /lib/udev/scsi_id --page=0x80 --whitelisted --device=/dev/sdc   or:  cat /sys/block/sdc/device/{vendor,model}   you can also get information (including labels) from the filesystems on the different partitions with  sudo blkid /dev/sdc1   the pathid will help to determine the type of device:  readlink -f /sys/class/block/sdc/device   see also:  find /dev/disk -ls | grep /sdc   which with a properly working udev would give you all the information from the other commands above.  the content of /proc/partitions will give you information on size (though not in as a friendly format as lsblk already mentionned by @max).  sudo blockdev --getsize64 /dev/sdc   will give you the size in bytes of the corresponding block device.  sudo smartctl -i /dev/sdc   (cross-platform), will also give you a lot of information including make, model, size, serial numbers, firmware revisions... 
sed '/^.\{2048\}./d' input.txt &gt; output.txt  
normal minix file system partitions can be further divided into up to four subpartitions
there's no magic bullet here
you can use pkill:  pkill httpd   you may also want to use process substitution(although this isn't as clear):  kill $(pgrep command)   and you may want to use xargs:  pgrep command | xargs kill  
virtual interfaces do not artificially limit throughput to a particular data rate, like a physical interface would
it is likely to be buffering in awk, not cat
ulimit is made for this. you can setup defaults for ulimit on a per user or a per group basis in   /etc/security/limits.conf   ulimit -v kbytes sets max virtual memory size
there is a big difference
you can install just the telnet package and have telnet client functionality
this almost made me wince.   you might want to stop pointing that shotgun at your foot
   if the whole disk is encrypted, and some pre-boot tool asks the user for a key to decrypt it, doesn't that mean this tool has to run beneath the os that's going to boot?   yes, pretty much
you can use the command   chage -d 0 [username]   to change the users expiration date, forcing them to change their password on first log in.  you can read more about it in the man pages for chage and usermod. 
if alpine indeed works with step files, then, according to man open, you could try:  open -w -n -e    the -w option ensures open waits until the app is closed to return. the -n option is used to run a new instance of your app, even if it’s already running (this way, if you’re already running textedit, you don’t have to close the currently running instance).   if you’d like to use another editor, let’s say “awesome text editor.app”, you can replace the -e by  -a.  open -w -n -a "awesome text editor"   notice that you’ll need to close the application, not only the document.  some editors also offer their own command-line utilities
   i have tried the following options    echo "hello world" | xclip -i selection primary | xclip -i selection clipboard      you were really close there... if you use -f with the first xclip command it will print the text back to stdout and you can pipe it to the second xclip command:  echo "hello world" | xclip -i -sel p -f | xclip -i -sel c   from man xclip:  -f, -filter             when xclip is invoked in the in mode with output level set to             silent (the defaults), the filter option will cause xclip to print             the text piped to standard in back to standard out unmodified  
as it looks for gentoo's wiki, they seem to be worried about its security:  http://en.gentoo-wiki.com/wiki/samba#non-privileged_mounting  they show you how to do it manually but also warn you about security risks.  above that section, at first lines of page they also note the following:     note: net-fs/mount-cifs, the old mount helper, is no longer needed, as   the current stable version of net-fs/samba includes all of its   functionality.   so you seem to have both choices but they recommend using samba, it has an use flag 'client' so you don't have to install everything
to clarify what the commenters noted in code:  begin {     fs="\t"     hpd=0     hpdname=""     lpd=0     lpdname=""     hpw=0     hpwname=""     lpw=0     lpwname="" } # stuff in here needs to be printed during the process. {   print $1   pd=$2/$4   print pd   pw=($3/($3+$4))*100   print pw  # these if statements see if there is a new highest or lowest value for the     categories.   if (pd&gt;hpd)   {     hpd=pd     hpdname=$1   }   if (pd&lt;lpd)   {     lpd=pd     lpdname=$1   }   if (pw&gt;hpw)   {     hpw=pw     hpwname=$1   }   if (pw&lt;lpw)   {     lpw=pw     lpwname=$1   } }  # prints off all of the ending information that we have been keeping track      of. end {     print "the highest population density: "hpdname" "hpd     print "the lowest population density: "lpdname" "lpd     print "the highest percentage of water: "hpwname" "hpw     print "the lowest percentage of water: "lpwname" "lpw }   you're mixing up bash like variable syntax and awk.  bash:  variable='something' echo $something   awk:  variable="something" print variable   awk uses $ for the field variables, like $1, $2, $0, $nf, but not for variables you have created
after adding the alias declaration in ~/.bash_profile you need to either source that file with 
sadly, no
although you restrict the commandline arguments there is nothing that prevents the user from using vim to open, edit and overwrite any random file once it is running as root
fvwm2 uses "layers"
there is a gnu standard naming scheme for compilers and other parts of the toolchain:  &lt;target triplet&gt;-&lt;tool name&gt;   the target triplet is of the form  &lt;machine&gt;-&lt;vendor&gt;-&lt;operatingsystem&gt;   and the tool name is gcc for the compiler, or another tool name like ld or strip or ar, etc...  the default compiler, the one that compiles native binaries (is not a cross compiler) is just called as gcc without the triplet.  the triplet of the compiler that is inside the file you mentioned in your question is arm-none-linux-gnueabi (looks like a quadruplet, i know, but that's what it is)
as @hauke laging says, it will not become ext4, but you could mount it to /mnt/winshare or some other place, using samba
to display within a gnome session, add display=&lt;display id&gt;
   (uptime-(idle_time/num_core))   may give an idea of how long the system has been busy, in seconds
   since i use centos, which is a rhel variant, the rpm command will need to be executed in terminal to accomplish this (i believe so)   while rpm is used to work with the actual packages, rhel and friends now use yum to make it less tedious.  yum lets you install software through repositories, local or remote collections of rpm packages and index files, and handles dependency resolution and the actual fetching &amp; install of the files for you.  you can find the list of repositories configured on your machine by peeking in the /etc/yum.repos.d/ directory.     however, to use the wget command to download the package, i will need a url that points to the package
i heard it (sorry, i forget where) as typing the sync command three times (as in: s y n c return, wait for the prompt, repeat, repeat)
in order to enable access to these devices you'll need to add your username to the group vboxusers.  $ sudo usermod -a -g vboxusers &lt;username&gt;   example  $ sudo usermod -a -g vboxusers saml   you can confirm the change afterwards:  $ groups saml saml : saml wheel vboxusers wireshark   after doing the above you'll want to logout and log back in in order for the newly added group to get picked up by your user account
the command you are running (nc a.k.a
by just reading the title of this question, i thought it was about "how to connect from a drupal site to some external database in postgress format"
you can install using a specific name-version as described in the man page:  dnf install tito-0.5.6-1.fc22      install package with specific version
you can use the svcadm commands:  disable the cde-login service:  svcadm disable svc:/application/graphical-login/cde-login:default   enable it back:  svcadm enable svc:/application/graphical-login/cde-login:default   or, if you want to do it old school:  disable:  /usr/dt/bin/dtconfig -d   enable:  /usr/dt/bin/dtconfig -e  
 perform ifconfig on server and try to ping &lt;server_ip&gt; from client you can login via ssh using the following command from client_vm   ssh client_01@192.168.5.132   if you would connect using a "name", you could edit the /etc/hosts file on client_vm, adding a line like this  192.168.5.132   server-vm   backup the file before edit it, just in case
you can use apt-get --reinstall install … to reinstall all the files in a bunch of packages
if your package manager is in a working state, you can force reinstallation of the packages containing the binaries you overwrote
yum will do that by default in live mode; anything you install whilst running off a live optical disc is installed to ram because you are running off of ram as it is
just use the command line parameters instead of stdin, and use chpasswd for the password.  for example:  sudo adduser myuser --gecos "first last,roomnumber,workphone,homephone" --disabled-password echo "myuser:password" | sudo chpasswd  
to resize your virtual hd, i recommended installing gparted to a usb stick and booting the usb to your virtual machine
a snapshot contains the differences between the original and the "mirrored" device
fopen is a library function, and it returns a file data structure
if you look at what mpd play is supposed to do:  play &lt;position&gt;   starts playing the song-number specified
i was able to do the above with a tool named passe-partout
the usual way is to create a script which calls the binary as part of the script
the kernel-devel package in fedora and other red hat derivatives does not contain the full kernel source, just headers for public interfaces and makefiles needed for driver development
you don't need to give sudo access to echo
i found the way to do it (was rather easy after all):   prerequisite: preware is installed (done this already) install ipkg-opt (called the "optware advanced linux command line installer" in preware) connect to your device command line as root (via novaterm/usb cable or ssh, if already installed) call ipkg-opt update call ipkg-opt list | grep sudo to make sure the package is available call ipkg-opt install sudo   at which point my device did:  palm-webos-device ipkg # ipkg-opt install sudo installing sudo (1.7.4.4-1) to root... downloading http://ipkg.nslu2-linux.org/feeds/optware/cs08q1armel/cross/unstable/sudo_1.7.4.4-1_arm.ipk configuring sudo successfully terminated.   i assume an unpriviledged user has already been added to the system
if you don't already have it, install glxinfo; in apt it's part of mesa-utils:  apt-get install mesa-utils   run glxinfo and look for a line about direct rendering (another term for hardware acceleration):  &gt; glxinfo | grep "direct rendering" direct rendering: yes   if it says "yes", hardware acceleration is enabled 
export in zsh is shorthand for typeset -gx, where the attribute g means “global” (as opposed to local to a function) and the attribute x means “exported” (i.e
even though sed is commonly used for these types of tasks, it isn't actually designed for them—its very name is stream editor.  the tool that is designed for non-interactive file editing is ex
here's an idea using perl to execute the script for you
if you are on linux and can handle having ss installed:  ss -o state established '( dport = :5222 )'|awk -f"[\t :]+" 'nr!=1{ ip[$5]+=1 } end{ for (i in ip){n++};print n }'   if you would like the awk explained just let me know. 
you're probably looking for trouble-maker. 
i found myself in this position today and the answer seems to be – simply: you don't want to
what finally worked for me in installing the non-free firmware was to first download firmware-linux-nonfree_0.36+wheezy.1_all.deb to a directory in my home directory
you want to get from command_with_arguments to command "escaped_command_with_arguments". you get escaped_command_with_arguments by scanning command_with arguments from left to right and replacing each \ by \\ and each " by \".  alternatively you put command_with_arguments in an editor and   replace all \ by \\ replace each " by \"   in this order
add a sudo rule to allow that user to run your script
month names are not tied to a timezone, but to locale.  $ lc_all=cs_cz.utf8 date +%b leden $ lc_all=es_es.utf8 date +%b enero  
i am not really sure what you are trying to do here, but you can grep "all strings that begin with $ and end with a non-alphanumeric character" with this:  grep -op '\$.+?\w'      in response to your comment, how about something like this:  for f in `find 
scp has the -r argument
simply throw away all characters that are not digits and not space:  echo '&lt;summary failed="10" notexecuted="0" timeout="0" pass="18065" /&gt;'|\ sed -e 's/[^0-9 ]//g'   gives  10 0 0 18065   .  the sum can be done with dc (with the timeout field filtered as requested)  echo '&lt;summary failed="10" notexecuted="0" timeout="0" pass="18065" /&gt;'|\ sed -e 's/timeout="[0-9]*" //' \     -e 's/[^0-9 ]//g' \     -e 's/^ *//' \     -e 's/ *$//' \     -e 's/ /+/g' \     -e 's/^/0 /' \     -e 's/$/pq/'|dc   .  description  as a sed script this would look like this  s/timeout="[0-9]*" //    #remove the timeout s/[^0-9 ]//g             #drop anything but numbers and spaces s/^ *//                  #drop spaces at the beginning of the line s/ *$//                  #drop spaces at the end of the line s/ /+/g                  #replace remaining spaces with + s/^/0 /                  #add a 0 to initialize the sum for dc s/$/pq/                  #add print and quit command for dc   the script can be simply used with  input|sed -f script.sed   
there are currently no mailfromd rpms for el6
handling it with different user accounts may well be the only possible way since processes do not own any files and can therefore not have a disk quota.  to make it even clearer, at the very best you could manage a quota for the files currently used, should you develop such a kernel patch, but it would still lose its sense to track the files that were written previously and got closed as they are not under its responsibility at all.  doing such a flawed patch would also result in considerable performance degradation and wouldn't make sense in situations where more than one program opens the same file.  for those and many other reasons, it theoretically simply can not be done properly. 
update: if you're following the bleeding-edge development versions, there's recently been added a much easier way to get a full-width message area for copying purposes, called the "bare display" mode!  it's bound to meta-! by default—do /key missing to set this keybinding if it's not already in your configuration—and it toggles off all of the weechat chrome, leaving just a log-style display of the current buffer's content.  if you don't have the development versions, the following solution using a bunch of settings still works, but i strongly recommend using bare display mode if you have it.    well, you can fairly easily move the nicklist out of the way or hide it entirely
you should add it to your shell’s configuration file
the managed save option of virt-manager pauses the guest and dumps its memory (and cpu state) to a save file
the applicable package i found via yum is pygtk2, not "-2.0".  note: questions of this nature may be better served on serverfault. 
pidof won't find scripts, since it only looks at the first part of the process name (argv[0]).  you could use pidof -m, but that will find any long_running_script.sh, not just the one started by this script.  a better way is to use the $! variable, which holds the pid of the most recent background job.  #!/bin/bash  long_running_script.sh &amp;   pid=$!  while ps -p $pid &gt;/dev/null do     echo "."     sleep 1 done  
two things could be the cause of this:  one possible cause is the way you've built the private network (using the bridge on the host)
you can use sed with binary files (at least gnu sed; some implementations may have trouble with files containing null characters or not ending with a newline character)
there is no single standard or tool to query hardware devices on linux systems in general
i wrote this bash script to do it. it basically forms an array containing the names of the files to go into each tar, then starts tar in parallel on all of them. it might not be the most efficient way, but it will get the job done as you want. i can expect it to consume large amounts of memory though.  you will need to adjust the options in the start of the script. you might also want to change the tar options cvjf in the last line (like removing the verbose output v for performance or changing compression j to z, etc ...).  script  #!/bin/bash  # user configuratoin #=================== files=(*.log)           # set the file pattern to be used, e.g
your command also has another problem, what if the filename has spaces?  #!/bin/bash cat "$1"   always quote unless you have a compelling reason not to
you can do this with gnu cpio:  $ find 
   is is as simple as comparing /proc/filesystems with lsmod?   no:  $ comm -31 &lt;(lsmod | awk 'nr!=1 {print $1}' |sort) \            &lt;(&lt;/proc/filesystems awk '{print $nf}' |sort) | fmt anon_inodefs autofs bdev cgroup cpuset debugfs devpts devtmpfs ext2 ext3 fuseblk fusectl hugetlbfs mqueue nfs4 pipefs proc pstore ramfs rootfs rpc_pipefs securityfs sockfs sysfs tmpfs   many of these are not built into the kernel on that system
your linux mint comes pre-installed with a gcc package
tl;dr: take a look at your system logs, or use something like bootlogd, this should show you where the slow down is occurring
you need to export lang to date
use:  rpm -vf /etc/pam.d/system-auth   although in this example, rpm will complain that the file isn't owned by any package as it's a symlink
from the man page,  # -a, --analyze # analyze a flac encoded file (same as -d except an analysis file is written)  flac -a myfile.flac   edit  it might be easier to use soxi from the sound exchange project
the client-server capabilities of vim depend on x11, citing from its help:     the communication between client and server goes through the x server.  the   display of the vim server must be specified
it should work fine; markdown files are plaintext files, so git diff is perfect.  this could be one of a few possible things:   there is no difference in the file (empty output). the changes to the files have not been added (git add -p *.md)   what does git status say? if it doesn't contain a few lines that say something like "modified: something.md" or "new file: something.md" then you're not going to get a diff.  edit: also, probably a stupid question, but these files are actually in a git repo right? if not, just use unix's normal diff utility (man diff for more info). 
dnsmasq is simpler and because of that has less features
from a casual review of the source, it appears the author(s) were overzealous in their use of set_nonblock in sslh-select.c.  if you flag every socket (as it does) as non-blocking, the the loop  while(1) {     select(… a bunch of non-blocking sockets …); }   at around line 230 in the linked file becomes a busy-wait
with prename:   setup:  $ mkdir test &amp;&amp; cd test $ &gt; "foo bar xxx doo par.jpg"; &gt; "foo bar yy yy doo par.jpg"   action:  $ rename -n 's/^foo bar //; s/ doo par(\.[^.]*)$/$1/'  *   foo bar xxx doo par.jpg renamed as xxx.jpg   foo bar yy yy doo par.jpg renamed as yy yy.jpg   (remove the -n to have those moves actually performed) 
they represent the values of the shell's flags; this is defined by posix:     -      (hyphen.) expands to the current option flags (the single-letter option names concatenated into a string) as specified on invocation, by the set special built-in command, or implicitly by the shell.   the zsh manual mentions it briefly:     - &lt;s> flags supplied to the shell on invocation or by the set or setopt commands.   as does the bash manual in the description of set:     the current set of options may be found in $-.   to understand the output of echo $- you need to look up the options in your shell's manual
create new align partition  disk=/dev/sdd  (assumed new disk is point to sdd)    dd if=/dev/zero of=$disk count=1 bs=1m   parted -s -- $disk mklabel msdos   parted -s -- $disk mkpart primary ext3 64s 401624s   parted -s -- $disk mkpart primary 401628s 6144866s   parted -s -- $disk mkpart primary 6144868s 100%   parted $disk unit s print    (echo t; echo 1; echo 83;echo t; echo 2; echo 82;echo t; echo 3; echo 8e; echo w)  | fdisk $disk   (echo a; echo 1; echo w)  | fdisk $disk   install grub:    mkfs –t ext3 –l /boot dev/sdd1   mount $dsik1 /mnt   cd /mnt    dump -0 -b 1024 -f - /boot/ | restore -r -f - -b 1024   cd /   umount /mnt   grub:  grub&gt; device (hd1) /dev/sdd device (hd1) /dev/sdd  grub&gt;root (hd1,0)      root (hd1,0)      filesystem type is ext2fs, partition type 0x83  grub&gt; setup (hd1)     setup (hd1)     checking if "/boot/grub/stage1" exists..
kali linux 2.0 is based on jessie and is, from now on, a rolling release, where they pull packages from debian testing.  this makes it a complicated situation
there is no difference
gnu find has an optimization which can be applied to find . but not to find 
xwininfo -root -children | grep -q '"firefox")' echo "$(($? == 0))"   would output 1 if there's a window of class firefox connected to your x server (by any user from any machine).  to limit to firefox processes local to the machine where you're running that command:  xwininfo -root -children |   awk '/"firefox"\)/{print $1}' |   xargs -i% xprop -id % wm_client_machine |   cut -d\" -f2 |   grep -qfx "$(uname -n)"   searching by process name gives you no guarantee that the processes are actually displaying their window on your x server.  the method described above is consistent with how firefox checks for a currently running firefox when not passed the --no-remote option. 
from sudoers manual below is the only message you are allowed to configure with the sudo conf.  badpass_message="sorry, try again."   however to answer your question you are more than welcome to compile your own copy of sudo
indeed, the page describes setting up a partition, but it's similar for a swapfile:  dd if=/dev/urandom of=swapfile.crypt bs=1m count=64 loop=$(losetup -f) losetup ${loop} swapfile.crypt cryptsetup open --type plain --key-file /dev/urandom ${loop} swapfile mkswap /dev/mapper/swapfile swapon /dev/mapper/swapfile   the result:  # swapon -s filename                                type            size    used    priority /dev/mapper/swap0                       partition       4000176 0       -1 /dev/mapper/swap1                       partition       2000084 0       -2 /dev/mapper/swapfile                    partition       65528   0       -3   swap0 and swap1 are real partitions. 
why root over ssh is bad  there are a lot of bots out there which try to log in to your computer over ssh. these bots work the following way.  they execute something like ssh root@$ip and then they try standard passwords like "root" or "password123". they do this as long as they can, until they find the right password. on a world wide accessible server you can see a lot of log entries in your log files
to see what your terminal is sending when you press a key, switch to insert mode, press ctrl+v, then the key
   why not only use what's on the disk ?   you can
the command who prints the entire hostname.   ~ $ who --version who (gnu coreutils) 8.4 ...  ~ $ who root     tty1         2013-08-06 10:01 amp      pts/0        2013-10-21 11:30 (entire.hostname) rafael   pts/4        2013-10-21 11:59 (entire.hostname)  
i figured it out after asking.  i started out by going to:  then i downloaded it to the desktop (i used 1.10 version, but that doesn't really matter)  then i used then commands in this order     cd desktop      java -jar jarfilename.jar   and now it's moded
for beeps generated in your shell (which seem to be the most annoying ones), add this to "~/.inputrc":  set bell-style none   note that this is not terminal- but host-specific
the default device, based on the kernel name (sr0 in this case) is always created automatically as a real device file, so no rule is needed for that.  additional synonyms are then created by writing rules which specify symlinks to be added which point at the real file. 
the relevant files for ppa's are unter /etc/apt/sources.list.d.  apt-add-repository -r ppa:ehoover/compholio and avoid ubunu-ppa's unter debian
you can use the command readlink to track down errant links to files, so that you can find out the true executable behind the link.  example  link  $ ls -l /sbin/reboot lrwxrwxrwx
summary answer after exchange of comments : allow vm to obtain ip address + subnet mask + default router via dhcp. 
where i worked we had a very similar situation and this might sound heavy handed but we literally filled the usb ports with epoxy
the best way that i have found until now is to use the pkgfile command. you could install it by:  # sudo pacman -s pkgfile   according to the official arch wiki,     pkgfile is a tool for searching files from packages in the official repositories.    (files being the binaries you mentioned as bash commands)
there are two ways that you can do this.  1: using sudo  one is to allow everyone to use sudo to mount the disk
it's to simplify the interface
you need to edit the file /etc/udev/rules.d/70-persistent-cd.rules simply look for the line that contains the entry symlink+="cdrom3" and rename it to your liking.  to make the changes take effect, i think a simple restart of udev would work (service udev restart) although you might need a reboot. 
an environment variable is one that is exported to subprocesses. this script, yet to adapt to your need, could be of help
autokey is a desktop automation utility for linux and x11
if your libraries are not on standard path then either you need to add them to the path or add non-standard path to ld_library_path  export ld_library_path=$ld_library_path:&lt;your_non-standard_path&gt;   once you done any one of above things then you need to update the dynamic linker run-time binding by executing below command:  sudo ldconfig   update:  you can make the changes permanent by either writing the above export line into one of your startup files (e.g
going from 32-bit to 64-bit isn't necessarily complicated, but given that you're two full release cycles behind it's probably best if you create a fresh vm, install wheezy, and then see about copying over the data.  how viable this is will depend largely on what kinds of services you're running and how much custom configuration work you've done to them -- i recently ran into some trouble with a truly ancient legacy mysql server setup (originally predating lenny) and a bunch of config options that were suboptimal at best and outright incompatible with more modern versions of mysql at worst
the first distro that you should as a entry-level system admin is ubuntu
as you have found, there is no roundcube package for debian 8.x (jessie), which is currently the latest release.  as i see it, your options are:   install a backport of roundcube
 the uuid fb..
you can manipulate some of the pci bus registers of the device fairly easily with setpci
unless you have a specific need to use the shell for this, terdon's answer provides better alternatives.  since you're using bash (as indicated in the script's shebang), you can use the -n option to echo:  echo -n "${line} " &gt;&gt; output.txt echo "$line" | cut -d'_' -f 1 &gt;&gt; output.txt   or you can use shell features to process the line without using cut:  echo "${line} ${line%%_*}" &gt;&gt; output.txt   (replacing both echo lines).  alternatively, printf would do the trick too, works in any posix shell, and is generally better (see why is printf better than echo? for details):  printf "%s " "${line}" &gt;&gt; output.txt echo "$line" | cut -d'_' -f 1 &gt;&gt; output.txt   or  printf "%s %s\n" "${line}" "${line%%_*}" &gt;&gt; output.txt   (strictly speaking, in plain /bin/sh, echo -n isn't portable
this is kind of a weird question, seeing as zsh is the only shell with this feature
to determine what editor to run, sudo checks three environment variables (in order): sudo_editor, visual, and editor, and uses the first editor it finds
basically, without going too much into detail:  the user interface (ui) is a generic term for the space where interactions between user and computer occur
you are basically asking two separate questions.   how to set permissions on your local system to mirror the production one?  you need to know the server configuration - in this case it includes configuration of the http daemon (httpd aka apache in this case) - usually found in /etc/httpd or /etc/apache)
this answer over on askubuntu.com covers many different ways to solve the problem
[this does not directly address the issue of systemd-tmpfiles but i think you have already recognized that in this particular case you are better off just using echo.]  first up, "multi-user.target" may or may not be what you want to use
you can use xclip to paste the contents to a temporary file and then open that file with firefox
route del default route add default 1.2.3.4   where 1.2.3.4 is the new gateway
that command opened the connection on file descriptor 3
you need to have shntool and cuetools installed.  also install the tta encoder and decoder from  http://www.etree.org/shnutils/shntool/.  it needs to be compiled it with g++ and yasm
you can't.  you can use chmod to set the sticky bit on a directory (chmod g+s directory/) and that will cause all files created in the directory to be in the same group as the directory itself
an operating system usually "takes a processor away" from a thread of control whenever the running thread makes a system call, or there's a clock interrupt, or some other interrupt occurs.  that is, the running thread invokes the kernel via a read() or write() or gettimeofday() system call
i wonder whether you’re leaving something out of the question, because you seem to be doing more work than you need to for what you say you want to do.  if i’m understanding you correctly.  if all you want to do is output (echo) the first three fields (values) from the line in the file that contains h1 (assuming that there is only one such line), all you need to do is  awk '/h1/ { print $1, $2, $3 }' input_file  or, if you want the values on three separate lines,  awk '/h1/ { print $1; print $2; print $3 }' input_file  to achieve the same result for multiple files, just list their names, for example, using brace expansion:  awk '/h1/ { print $1; print $2; print $3 }' /folder{1,2,3}/file  or use a wildcard, as the other answers suggested:  awk '/h1/ { print $1; print $2; print $3 }' /folder?/file  if you require that the values be assigned to variables, so you can manipulate them in your script, you need to explain your requirements more clearly. 
file="00 foo 99.jpg" expr "x$file" : '.*[^0-9]\([0-9]\{1,\}\)'   don't use echo for arbitrary data, you can't use sed as sed works on lines and filenames can be made of several lines.  match is not a standard operator of expr, : is the standard equivalent, so you might as well use it instead to avoid portability issues.  prefixing $file with x makes sure $file is not taken as an expr operator
assuming you have gnu date, we need to add a space between the date and time and pass it with -d  $ date -d "20160713 1001" wed jul 13 10:01:00 edt 2016   we can do that split pretty easily with parameter expansions
do the opposite
i had found a solution...  i asked on mozilla forum and they returned a answer to me
you can do this by combining both patterns in a single command-line argument:  aptitude search '~n !-dbgsym$'   this causes the search to look for packages with are both new and whose name doesn't match the -dbgsym$ regex
tried sqliteman? look for sqliteman in your package manager
this will do:  /^[^']*\%('[^']*\)\{4}$   it searches for a quote followed by any non-quotes ('[^']) four times (\{4}; here, you can also specify ranges like \{2,5})
you can't run make config just anywhere - you have to be in a directory which contains a make file
process substitution results in a special file (like /dev/fd/63 in your example) that behaves like the read end of a named pipe
execute the command modinfo &lt;kernel_module_name&gt; and look for vermagic     shw@shw:/tmp # modinfo btrfs   filename:       /lib/modules/3.13.0-36-generic/kernel/fs/btrfs/btrfs.ko   license:        gpl   alias:          devname:btrfs-control   alias:          char-major-10-234   alias:          fs-btrfs    srcversion:     ea2c07f0b841ae2a6d8f91f   depends:        libcrc32c,raid6_pq,xor   intree:         y   vermagic:       3.13.0-36-generic smp mod_unload modversions 686   &lt;==   signer:         magrathea: glacier signing key   sig_key:        ff:9a:da:11:b8:55:51:6a:72:98:65:9d:4e:3f:bb:76:c5:4a:d3:30   sig_hashalgo:   sha512    
with zsh, you could try something like:  x=3 b_words=($(&lt;b)) a_words=($(&lt;a)) a="$a_words"  setopt extendedglob for ((i = 1; i&lt;=$#b_words - x + 1; i++)) {   phrase=$b_words[i,i+x-1]   [[ " $a " = (#a2)*" $phrase "* ]] &amp;&amp; printf '%s\n' $phrase }   which should give you the sequences of 3 words of file b that are also found in file a (allowing 2 errors with (#a2)).  for instance, if a is your question and b is the sentence above, i get:  of 3 words 3 words of in file a   or if you want to see what was matched in file a:  for ((i = 1; i&lt;=$#b_words - x + 1; i++)) {   phrase=$b_words[i,i+x-1]   [[ " $a " = (#a2)(#b)*" "($phrase)" "* ]] &amp;&amp;     printf '%s\n' "$phrase ($match[1])" }   which gives:  of 3 words (of words) 3 words of (words of) in file a (in file b,)   words here are defined as sequences of non-ifs characters which with the default value of $ifs is any character other than space, tab, newline and nul. 
as you fill the memory with apps various block/filesystem caches are getting pushed out of the same memory
by adding the md5sum to the file, the md5sum of the file content changes
when you delete all the files from a directory, for most file systems, the directory remains the same size
unfortunately aix su doesn't have the --shell parameter available on other platforms
first of all, check that you really have already space on your vg
tail +1f file   i tested it on ubuntu with the libreoffice source tarball while wget was downloading it:  tail +1f libreoffice-4.2.5.2.tar.xz | tar -tvjf -   it also works on solaris 10, rhel3, aix 5 and busybox 1.22.1 in my android phone (use tail +1 -f file with busybox). 
i was not comfortable with having bug in kernel or a module, so i digged further and found out..
tmux sets the tmux environment variable in tmux sessions, and sets term to screen
the reason this does not work is because it sees -i /bin/sh as a single argument to env
in general dd displays the time it took for the entire transfer and the speed is "amount of data divided by time it took"
it's doing a no-op brace expansion first (expanding to what you started with), then parameter expansion, then brace expansion within "eval":  # no-op brace expansion example: echo foo.{not..understood} # see: foo.{not..understood}  ext0=10 extn=20  # parameter expansion echo foo.{$ext0..$extn} # see: foo.{10..20}  # final brace expansion eval echo foo.{$ext0..$extn} # see: foo.10 foo.11 foo.12 foo.13 foo.14 foo.15 foo.16 foo.17 foo.18 foo.19 foo.20  # now if you want to have fun with it (each eval unwraps one level of escapes) eval eval eval eval echo foo.{\\\\\\\$ext0..\\\\\\\$extn} # see: foo.10 foo.11 foo.12 foo.13 foo.14 foo.15 foo.16 foo.17 foo.18 foo.19 foo.20  
the procedure is made pretty simple with the help of package iproute2.  first configure the can interface (as root):  # ip link set can0 up type can bitrate 250000   ..
a list of non-zero cpu % processes:  ps -eo pid,tid,class,rtprio,ni,pri,psr,pcpu,stat,wchan:14,comm --sort=+pcpu | awk '$8!=0.0 {print}' | awk 'nr&gt;1'   to count them  ps -eo pid,tid,class,rtprio,ni,pri,psr,pcpu,stat,wchan:14,comm --sort=+pcpu | awk '$8!=0.0 {print}' | awk 'nr&gt;1' | wc -l   to see this continuously updated, but them in a file called processes.sh:  #!/bin/bash ps -eo pid,tid,class,rtprio,ni,pri,psr,pcpu,stat,wchan:14,comm --sort=+pcpu | awk '$8!=0.0 {print}' | awk 'nr&gt;1'   and make it executable with chmod +x processes.sh
there are 2 main reasons for installing windows first:  1 - the boot loader  configuring the windows boot loader to load linux is a royal pain in the butt
watch cat /proc/mdstat | grep -oe 'finish=[[:digit:]]+\.[[:digit:]]' | grep -oe '[[:digit:]]+\.[[:digit:]]'   if you really like the perl-style "\d" format and your grep supports perl-style regexes, then:  cat mdstat | grep -op 'finish=\d+\.\d' | grep -op '\d+\.\d'   where the "-p" option specifies perl-style regular expressions.  the "-o" option tells grep to display only the part of the line that matches the regular expression
oh-my-zsh config file should have a line starting with plugins=, like this:  plugins=(git gitignore autojump jira command-not-found zsh-syntax-highlighting)  whatever you put there is considered by zsh to be an active plugin.  in case of autojump, oh-my-zsh plugin wiki states that:     enables autojump if installed with homebrew, macports or debian/ubuntu package.   this does not add any commands on its own.   config file you are looking for: .zshrc   edit:   note that some folks claim fasd is better, if autojump won't work for you, you may try fasd instead. thanks @adaephon, added link to source of the quote and marked it's oh-my-zshell rather than pure zsh.  
you can use winscp client just login with username/password you're allowed to login with .  https://winscp.net/eng/index.php 
you can use rsync for it
1
the file $home/.profile is used by a number of shells, including bash, sh, dash, and possibly others.  from the bash man page:     when bash is invoked as an interactive login shell, ..
reality is you're asking 2 different questions.   --sport is short for --source-port --dport is short for --destination-port   also the internet is not simply the http protocol which is what typically runs on port 80
~ is your home directory, / is the root directory
this is a known issue and the fix is here:  http://forums.seagate.com/t5/barracuda-xt-barracuda-barracuda/announcement-new-firmware-update-for-barracuda-1tb-platter/td-p/162362 
assume that you have # at beginning of comment lines, so you can do:  yum -y install $(awk '!/^#/' list)   !/^#/ cause awk to ignore any lines that start with #, print the rest. 
you don't have to give an absolute path to scp — the easiest way to deal with this is to go where you want to put things and use scp rrtigga@pc35.cs.ucdavis.edu:cputimer.h . (. refers to the current directory), or give a relative path like desktop
setting up a custom log for sshd  i realize that there is the default option already setup on openbsd for logging so this is an alternative if there is something either broken or mis-configured with that setup!  if you're having an issue with the regular logging facilities included with openbsd 5.3 you can override where the logs get sent using the following modification to your sshd_config file:  syslogfacility local7   then configure syslogd to pick up these messages and log them to a separate file:  local7.*     /var/log/local7.log   be sure to restart the sshd and syslogd services after making the above changes.  pam_exec  if you want something more customizable you might want to give pam_exec a look
write yourself a tiny shell script to use as a "sendmail" value
the correct way then would be  find -iname \*foobar\*   where -iname is for case insensitive search, and the \ to escape the * wildcard.  the function seems a bit unnecessary for this case, but it is easy to write  function lazyfind () {     find -iname \*$1\* }  
most web statistics tools summarise the log over a period of 24 hours or a month
remember that each of the nfs client systems will determine the username by looking up the numerical uid locally using the local system's /etc/passwd, or in your centralized user database
the mate-desktop wiki reports an update on availability of mate for fedora:     news since 2012/01/20: wolfgang ulbrich built experimental mate x86_64 rpms for fedora 16
we can take advantage of the fact that the unicode code point of persian numerals are consecutive and ordered from 0 to 9:  $ printf '%b' '\u06f'{0..9} ۰۱۲۳۴۵۶۷۸۹   that means that the last hex digit is the decimal value:  $ echo $(( $(printf '%d' "'۲") &amp; 0xf )) 2   that makes this simple loop a conversion tool:  #!/bin/bash (   ### use a locale that use utf-8 to make the script more reliable.     ### maybe something like lc_all=fa_ir.utf-8 for you?.     lc_all=en_us.utf-8     a="$1"     while (( ${#a} &gt; 0 )); do         # extract the last hex digit from the unicode code point         # of the first character in the string "$a":         printf '%d' $(( $(printf '%d' "'$a") &amp; 15 ))         a=${a#?}    ## remove one character from $a     done ) echo   using it as:  $ sefr.sh ۰۱۲۳۴۵۶۷۸۹ 0123456789  $ sefr.sh ۲۰۱ 201  $ sefr.sh ۲۱ 21   note that this code could also convert arabic and latin numerals (even if mixed):  $ sefr.sh ۴4٤۵5٥۶6٦۷7٧۸8٨۹9٩ 444555666777888999  $ sefr.sh ٤٧0٠٦7١٣3٥۶٦۷ 4700671335667  
you can set up an x server inside an x server using xephyr
use tee and redirect it to stderr  my_command | tee /dev/stderr | grep -q '^error'   it will save grep exit status and duplicate all the output to stderr which is visible in console
you can achieve the required result in wget (or curl) by specifying an output document.   with wget:  wget https://raw.git...etc.../readme.md -o ./temp/readme.md    with curl:  curl https://raw.git...etc.../master/readme.md &gt; ./temp/readme.md  
you can use dpkg-deb command to manipulate debian package archive (.deb).  from manpage:-  -i, --info archive [control-file-name...]               provides information about a binary package archive.                if  no  control-file-names are specified then it will print a summary of the contents of the package as               well as its control file.                if any control-file-names are specified then dpkg-deb will print them in the order they were specified;               if  any  of  the components weren't present it will print an error message to stderr about each one and               exit with status 2.   example usage:-  $ dpkg-deb -i intltool_0.50.2-2_all.deb   new debian package, version 2.0.  size 52040 bytes: control archive=1242 bytes.      831 bytes,    19 lines      control                   1189 bytes,    18 lines      md5sums                package: intltool  version: 0.50.2-2  architecture: all  maintainer: ubuntu developers &lt;ubuntu-devel-discuss@lists.ubuntu.com&gt;  original-maintainer: debian gnome maintainers &lt;pkg-gnome-maintainers@lists.alioth.debian.org&gt;  installed-size: 239  depends: gettext (&gt;= 0.10.36-1), patch, automake | automaken, perl (&gt;= 5.8.1), libxml-parser-perl, file  provides: xml-i18n-tools  section: devel  priority: optional  multi-arch: foreign  homepage: https://launchpad.net/intltool  description: utility scripts for internationalizing xml   automatically extracts translatable strings from oaf, glade, bonobo   ui, nautilus theme and other xml files into the po files.   .   automatically merges translations from po files back into .oaf files   (encoding to be 7-bit clean)
the superuser or any process with the cap_sys_admin or cap_sys_resource capabilities are not affected by that limitation, that's not something that can be changed
zachary has explained the source of the problem.  while you can work around it with  tty=$(tty) tty_without_dev=${tty#/dev/} who | grep -v "$tty_without_dev"   that would be wrong as for instance if that tty is pts/1, you would end up excluding all the lines containing pts/10
you need the gcc toolchain for both.  the toolchain is part of the android source tree
this is usually fixed by running the scripts detect the installed operating systems and generate the boot loader's (grub2 in this case) configuration file
release a window's pc's ip  (rephrased question)  you might be able to use the tool winexe to do this.  $ winexe -u dom/user_name  //remotepc "ipconfig /release"   release my ip  (original question)  the command is ifconfig &lt;interface&gt; on linux
as pointed out by ulrich schwarz, .ssh/authorized_keys must be a regular file
it's readable by remote_user and root
from your list, only the fourth possibility (writing a small setuid script in a safe directory e.g
reconfigure your config by running  # dpkg-reconfigure exim4-config    general type of mail configuration: internet site other destinations for which mail is accepted: example.com ip-addresses to listen on for incoming smtp connections: fill in your ip address   those should be the most important items to change
you should take a look at the wikipedia page on benchmarking, it gives quite a few benchmark tools including the cpu ones that will work on linux
does suse useradd have the -p option?  that takes the password (albeit in encrypted form, but you should be able to generate that i think).  so useradd -p &lt;crypt'ed password&gt; &lt;new username&gt; should do it i think 
initial investigation  i checked to see what rpms this application was a part of.  $ type -a abrt-action-generate-core-backtrace abrt-action-generate-core-backtrace is /usr/bin/abrt-action-generate-core-backtrace abrt-action-generate-core-backtrace is /bin/abrt-action-generate-core-backtrace  $ rpm -qf /usr/bin/abrt-action-generate-core-backtrace /bin/abrt-action-generate-core-backtrace abrt-addon-ccpp-2.1.10-1.fc19.x86_64 abrt-addon-ccpp-2.1.10-1.fc19.x86_64   that package's description is as follows:     this package contains hook for c/c++ crashed programs and abrt's c/c++   the rpm also mentions this url: https://fedorahosted.org/abrt/
you can use the alias command.  $ alias ll ll='ls --color=auto -flh'  
it seems your linux formatted /dev/ada4 mbr disk is not recognized properly by freebsd geom driver
it's hard to figure out what exactly is going on from this post
the circumflex (^) was equated to the up-arrow character on teleprinters
you can select particular word from last typed command with !!: and a word designator
if your servers are expected to be up and connected most of the time, then i'd say leave the mount in place
you can for example use this:  $ awk '/h/{sub("h", "h"++v)}1' file 1562 first part 1563 h1     col3 h col4 1564 h2     col3 h col4  3241 h3     col3 h col4 3242 third part ...   this looks for those lines containing h and replaces that h with h together with a variable we keep incrementing
yeah it's definitely a bug but don't worry, lvm is smart enough to handle this stuff, i once had the power go out in the middle of a pvmove and all i had to do was basically get the server turned on again "cancel" the old pvmove and start it over it again.  first off, it's important to know that the tools you use are just a user-space interface to kernel processes
. is the bourne and posix shell command while source is the c-shell command.  some bourne-shell derivatives like bash, zsh and most implementations of ksh also have a source command which is generally an alias for . though for ksh with differences.  for bash and zsh, . and source behave the same, but their behavior is affected by whether they run in posix mode or not¹.  posix requires that the . command exits the shell if it can't open the file for reading and requires that the file be found through a search of the directories in $path if the provided path doesn't contain a /.  zsh and bash . and source behave as posix requires when in posix mode, and as pdksh's source when not, that is they don't exit the script if they fail to open the file for reading (same as command .) and lookup the file in $path and the current directory if the provided path doesn't contain a /.  at&amp;t ksh's source doesn't exit the shell either but doesn't look for the file in the current directory.  all in all, in bourne-like shells (though not the bourne shell that doesn't have a command builtin), if you want a consistent behavior, you could do  command 
i don't know what you are trying to achieve, but if you want to account when did you run a certain command you could checkout your shell history and prepend the time it was executed
that's caused by the latest gnome-settings-daemon updates... there is no such option in power settings because it was removed by the gnome devs (the shutdown/power off action is considered "too destructive"). bottom line: you can no longer power off your laptop by pressing the power off button
the easiest way to restore the old way kernel/modules/udev rename your ethernet interfaces is supplying these kernel parameters to fedora 19:   net.ifnames=0 biosdevname=0   to do so follow this steps:   edit /etc/default/grub at the end of grub_cmdline_linux line append "net.ifnames=0 biosdevname=0" save the file type "grub2-mkconfig -o /boot/grub2/grub.cfg" type "reboot"   if you didn't supply these parameters during the installation, you will probably need to adjust and/or rename interface files at /etc/sysconfig/network-scripts/ifcfg-*.  up to fedora 18, just biosdevname=0 was enough.  as an example, in a certain machine, in a exhaustive research, i got:  -no parameters: nic identified as "enp5s2". -parameter biosdevname=0: nic identified as "enp5s2". -parameter net.ifnames=0: nic identified as "em1". -parameter net.ifnames=0 and biosdevname=0: nic identified as "eth0". 
this works for me:  sed 's/.*time=\([0-9]*\) .*/\1/' times | sort -n &gt; outfile   where times is this file:  cat times  64 bytes from onofri.org (67.222.36.105): icmp_req=1 ttl=47 time=202 ms 64 bytes from onofri.org (67.222.36.105): icmp_req=2 ttl=47 time=206 ms 64 bytes from onofri.org (67.222.36.105): icmp_req=3 ttl=47 time=215 ms   and outfile looks like this:  cat outfile  202 206 215  
all shells will support the standard glob *.c
frederik's answer involving magic sysrq and kernel dumps will work if the kernel is still running, and not truly hung
(copied from http://serverfault.com/a/683542/68920)  the route command is deprecated, and should not be used anymore.  the new way is to use the iproute set of commands, which are all invoked with ip followed by an object
e4fsck supports -d flag which seems to do what you want:     try to optimize all directories, either by reindexing them if the filesystem supports directory indexing, or by sorting and compressing directories for smaller directories, or for filesystems using traditional linear directories.   of course, you'll need to unmount the filesystem to use fsck, meaning downtime for your server.  you'll want to use the -f option to make sure e4fsck processes the file system even if clean.  testing:  # truncate -s1g a; mkfs.ext4 -q ./a; mount ./a /mnt/1 # mkdir /mnt/1/x; touch /mnt/1/x/{1..4000} # ls -ld /mnt/1/x drwxr-xr-x 2 root root 69632 nov 22 12:54 /mnt/1/x/ # rm -f /mnt/1/x/* # ls -ld /mnt/1/x drwxr-xr-x 2 root root 69632 nov 22 12:55 /mnt/1/x/ # umount /mnt/1 # e2fsck -f -d ./a e2fsck 1.43.3 (04-sep-2016) pass 1: checking inodes, blocks, and sizes pass 2: checking directory structure pass 3: checking directory connectivity pass 3a: optimizing directories pass 4: checking reference counts pass 5: checking group summary information  ./a: ***** file system was modified ***** ./a: 12/65536 files (0.0% non-contiguous), 12956/262144 blocks # mount ./a /mnt/1 # ls -ld /mnt/1/x drwxr-xr-x 2 root root 4096 nov 22 12:55 /mnt/1/x/  
one of the reasons for that behaviour will be the setting of the terminal for each user.  for example:   user1 is using term=xterm, in this case when you exit vim it will clear the terminal. user2 is using term=vt100, in this case when you exit vim it will not clear the terminal.   check what terminal user1 is using with echo $term and set the same for user2. for bash:      term=xterm; export term  
c++11 isn't a compiler, but an iso standard implemented by a number of popular compilers
in bash, declare -p can be used to dump the definition of a variable as shell code ready to be interpreted, so you can do updates to the file with:  #! /bin/bash - file=${1?}; shift declare -a row source -- "$file" || exit while [ "$#" -ge 2 ]; do   row[$1]=$2   shift 2 done declare -p row &gt; "$file"   a script to show the contents of the file would be:   #! /bin/bash - file=${1?}; shift declare -a row source -- "$file" for i in "${!row[@]}" do   echo "key  : $i"   echo "value: ${row[$i]}" done  
it seems that manually editing out the parameter containing rd.lvm.lv=fedora_old/swap in the grub configuration file does the trick
during the reboot, the runlevel is set to 6 (0 for a shutdown, 1 for maintenance mode, and 2–5 for normal operation).  if [ "$(runlevel | sed 's/.* //')" = 6 ]; then   echo "a reboot is in progress" fi   this is not very likely to be useful, since there will be only a very small window (often less than one second) during which the machine is still accepting commands after the reboot has been initiated.  if you need a notification after the computer has rebooted, make it send a message (over ssh, email, snmp or whatever is convenient) as part of its startup process, after all the services you need are started. 
there is no issues with the python package module installation using root login or some other user other than root.  anyway you can uninstall the python package using pip and easy_install as below.  #pip uninstall packagename  #easy_install -m packagename  
regexes in man magic are not extensively detailed
i don't think there is an additional security risk from running an arbitrary editor from visudo strictly speaking
you need patched kernel, losetup and mount
ordinarily, you'd put your "export" line into whatever shell startup file is appropriate: .profile, .bash_profile, .zprofile, whatever, in your $home directory.  if you want to make it permanent for every user, the various shells usually have system-wide config files in /etc/: /etc/profile exists on this linux box, but do read the man page to figure out which user-specific and which system-wide file to put it in. 
swapon have -p switch which sets the priority
you can start emacs with the --no-window-system command line option (-nw for short).  $ emacs --no-window-system   debian also offers a package that has x disabled, emacs-nox
i don't think there is any way to do this robustly purely with environmental variables
there are basically two things to this:  1) permissions on the files and directory that already exist:  alan's answer mostly covers this: create a special group to which you add all users that might need to write the files
sed solution:  sed -e 1b -e '$!d' file   when reading from stdin if would look like this (for example ps -ef):  ps -ef | sed -e 1b -e '$!d' uid        pid  ppid  c stime tty          time cmd root      1931  1837  0 20:05 pts/0    00:00:00 sed -e 1b -e $!d   head &amp; tail solution:  (head -n1 &amp;&amp; tail -n1) &lt;file   when data is coming from a command (ps -ef):  ps -ef 2&gt;&amp;1 | (head -n1 &amp;&amp; tail -n1) uid        pid  ppid  c stime tty          time cmd root      2068  1837  0 20:13 pts/0    00:00:00 -bash   awk solution:  awk 'nr==1; end{print}' file   and also the piped example with ps -ef:  ps -ef | awk 'nr==1; end{print}' uid        pid  ppid  c stime tty          time cmd root      1935  1837  0 20:07 pts/0    00:00:00 awk nr==1; end{print}  
if you're new, gparted is probably your friend as it's quite user-friendly for both the above options
because red hat enterprise linux is foremost about stability, and is a long-lived distribution (some 10 years guaranteed)
if you want a way to reboot, without saving open documents, but without hitting the reset button, then there are ways that are less likely to cause data loss
if you dd'd it to your actual drive's partition, then what you're seeing on the bootloader is simply an entry for an os that doesn't exist anymore
note: instead of the php code below, if you wanted to track all git commits (and not only those committed using php), it should be possible to set up a post-commit hook with similar output.    just after writing the question i came across this really simple guide
mknod /dev/null c 1 3 chmod 666 /dev/null   use these command to create /dev/null or use null(4) manpage for further help. 
the --noflush option for iptables-restore doesn't work for user-defined chains, such as testchain, only builtin chains
i don't think any shell does anything beyond whitespace munging when storing commands into the history
it's quite a minimal config for a basic virtual host
a linux distribution such as arch isn't really a single piece of software; instead, it's a collection of many different programs by many different authors
variable assignment is just a simple command, so you can use the if condition to check whether function success of fail:  if ! function_output=$(test hi); then   echo function return non-zero status   exit 1 fi  # this line never printed printf '%s\n' "$function_output"   if the function success, you will have the variable function_output with the result of function:  if ! function_output=$(test hii); then   echo function return non-zero status   exit 1 fi  # output content of function_output printf '%s\n' "$function_output"  
according to the freedesktop specification, which both gnome and kde support, the recommended filesystem locations for placing .desktop files are:    /usr/share/applications for system-wide menu items; ~/.local/share/applications for user-private menu items.   the command-line utility xdg-desktop-menu is provided to install .desktop files in a specific submenu (identified by a .directory file). 
this isn't elegant but it would get the job done.  ps ax | grep 'sshd: &lt;insert username here&gt;' | grep -v 'grep' | awk '{print $1}' | xargs kill  
i believe this is specific to cut from the gnu coreutils:  $ cut --complement -f 3 -d, inputfile 1111,2222,4444 aaaa,bbbb,dddd   normally you specify the fields you want via -f, but by adding --complement you reverse the meaning, naturally
protections  sudo has builtin protections that you're noticing when you run several of these commands
the problem is that ssh reads from standard input, therefore it eats all your remaining lines
you can use grep to grab all files within foo that end with .a.  foo | grep "\.a$" | xargs -d'\n' -r bar 
as the name goes, you only have the binaries, which means you don't have the source code of the program, you have the compiled program.  in windows world, that is usually the way everything works, in linux since most of the programs are open source you have the code and you can check it for yourself if you want to learn or modify it, or if you are paranoic about someone inserting spyware/backdoor/whatever in that program
(bash 4 or later)  if you set prompt_dirtrim to a non-zero number, it will replace directories after ~ with ..., retaining the given number of trailing directories
answering your question, there is no feature in either netcat or tee to achieve this.  maybe you could write a cron job, which runs every minute and checks the size of the label.txt, and when it reaches 20mb, clears the first 10mb. 
something like this would be useful:   dmesg | grep -ic 3 "what you are looking for"    for example, if looking for your video card, you could try:  dmesg | grep -ic 3 "video"   or:  dmesg | grep -ic 3 "graphics"    the c 3 flag will print 3 lines before and after the matched string, just to give you some context on what the results are
if you request gzip'ed content (using the accept-encoding: gzip header, which is correct), then it's my understanding that wget can't then read the content
this list gets created by analyzing .desktop files located at:  /usr/share/applications ~/.local/share/applications   there might be more than one usecase per application, take for example the media player banshee which has three .desktop files by default:  $ ls -1 /usr/share/applications/banshee* /usr/share/applications/banshee-1-audiocd.desktop /usr/share/applications/banshee-1.desktop /usr/share/applications/banshee-1-media-player.desktop   the only difference between those files is the starting parameter and the mimetype list.   banshee-1.desktop: general media files banshee-1-audiocd.desktop: audio cd's banshee-1-media-player.desktop audio player (also used by rhythmbox, vlc, and others)   so we have three 'banshee media player' in the 'open with' list (and maybe also in the 'main menu').  the other way of filling this space is by creating personal .desktop files in ~/.local/share/applications
from my experience in ubuntu, when you "eject" a usb stick from within nautilus, the device actually disappears from the system
i assume your conflict is that you are trying to add two default routes
but the name of the programs/packages each on its own line in a file, say packages.txt, and use rpm -qa |grep -iff packages.txt  now ..
i appended nomodeset to the end of the linux kernel line:  linux /vmlinuz-3.0.0-12-generic-pae root=uuid=&lt;another long hex value&gt; ro nomodeset  that fixed it! 
i'm afraid you're out of luck, unless you want to patch the sources (and possibly also offer the patch upstream)
if you don't want to change your ${path}, alternatively you can just link to the grep you like from an early entry of the ${path} value.  for example /bin is the second entry of your ${path} and its probably in all users's ${path} values.  so you could do this as root:  cd /bin ln -s /usr/local/bin/grep  
try alt + backspace.  from bash documentation:     backward-kill-word (m-del)      kill the word behind point
use cfdisk as root to create a partition in the free space
sounds like autossh (automatically restart ssh sessions and tunnels) could be something for you: http://www.harding.motd.ca/autossh/  to keep tunnels alive, and to administrate them in general.  should be on most distros base repos, so just use one of the following:  apt-get install autossh # deb pacman -s autossh # arch yum install autossh # rhel  
posixly, using grep with -e option:  find /var/www/http -type f -exec grep -ie 'string1|string2' /dev/null {} +   or -e:  find /var/www/http -type f -exec grep -i -e 'string' -e 'string2' /dev/null {} +   with some implementations, at least on gnu systems, osx and freebsd, you can escape |:  find /var/www/http -type f -exec grep -i 'string1\|string2' /dev/null {} +  
here's a pure bash approach that will delete the first newline of every pair:  command |    while ifs="\n" read i; do      let c++; [ "$(expr $c % 2)" -eq "0" ] &amp;&amp; echo "$i" || printf "%s " "$i";    done   if you don't need to keep the whitespace unchanged, you can leave out the ifs:  command |    while read i; do      let c++; [ "$(expr $c % 2)" -eq "0" ] &amp;&amp; echo "$i" || printf "%s " "$i";    done   the same idea using perl:  command | perl -ne 'chomp;$
i am not aware bind does allow changing globally the minimum ttl for answers for which is not authoritative besides making patches to the source code
in general, libraries have three different types of memory that is loaded from the file
it's not awk, it's in how the shell expands things.  let's take an example:  $ a="1 &gt; 2 &gt; 3 &gt; 4"   so we've created a variable over 4 lines
this is how i did it:  vi /usr/share/applications/newitem.desktop     [desktop entry] version=1.0 name=my program exec=/home/danny/some/path/myprog/prog terminal=false type=application startupnotify=true categories=network;webbrowser; x-desktop-file-install-version=0.15   an icon can be added by including icon=/some/path. 
$ sudo lpoptions -d hp_deskjet_f4200_series   this command solved it. 
i'm the one that suggested changing the completion-display-width readline variable at /r/bash, but then you didn't specify you only wanted it to work on this one completion function.  anyway, in a completion function, you can detect whether it's triggered by tab (comp_type == 9) or by tabtab (comp_type == 63), and if the latter is the case, you could pad the results with spaces so they fill the entire width of the terminal
nothing exits, but the handler for sigint (sigint_sighandler()) sets the exit status to 130 (128 + 2, as dopeghoti's answer explains) anyway:  if (interrupt_immediately)   {     interrupt_immediately = 0;     last_command_exit_value = 128 + sig;     throw_to_top_level ();   }   and in throw_to_top_level():  if (interrupt_state)   {     if (last_command_exit_value &lt; 128)     last_command_exit_value = 128 + sigint;     print_newline = 1;     delinterrupt;   }  
the jiffy does not depend on the cpu speed directly
in the simplest calling of sed, it has one line of text in the pattern space, ie
edited after having found the update script.  the oui list is compiled into the netdiscover binary, so you'll have to recompile it to update the list
there are three normal ways to set a user's umask.   set umask in /etc/login.defs add pam_umask.so to your pam configuration in /etc/pam.d set it in the shell startup files, e.g
this is set by the dir::etc::sourcelist configuration directive
after the problem in my question i found yum failed every time with   another app is currently holding the yum lock; waiting for it to exit...   i've been trying to get over this for four days,asking questions all over the place, finally i tried this:  [root@localhost owner]# ps &lt; /var/run/yum.pid   pid tty          time cmd  4126 pts/0    00:00:00 su  4138 pts/0    00:00:00 bash  4181 pts/0    00:00:00 yum  4262 pts/0    00:00:00 ps [root@localhost owner]# kill 4181 [root@localhost owner]# ps &lt; /var/run/yum.pid   pid tty          time cmd  4126 pts/0    00:00:00 su  4138 pts/0    00:00:00 bash  4181 pts/0    00:00:00 yum  4276 pts/0    00:00:00 ps [root@localhost owner]# cat /var/run/yum.pid 4181[root@localhost owner]# kill -9 4181 [1]+  killed                  yum install dconf-editor [root@localhost owner]# cat /var/run/yum.pid 4181[root@localhost owner]# ps &lt; /var/run/yum.pid   pid tty          time cmd  4126 pts/0    00:00:00 su  4138 pts/0    00:00:00 bash  4373 pts/0    00:00:00 ps [root@localhost owner]# yum install xemacs 
i assume that users a and b are using the same linux machine(s) where you are the administrator
"pausing the booting" does not exactly apply with systemd; systemd runs multiple services in parallel.  however, by adding "dependencies" to services, you can essentially specify at which point the "booting should pause" and wait for your service.  for the use case above, add to /etc/systemd/system/&lt;service&gt;:  [unit] description=commands to run before gui loads before=display-manager.service   this will force display-manager.service to wait for &lt;service&gt;. 
well, since nobody wants to answer :)  this wiki article, while not completely related, provided useful pointers:     you can easily check if you have 3d rendering ...   by installing mesa and running the following command:  glxinfo | grep renderer       if you have no 3d acceleration you'll get some output like this:  [joe@arch64]$ opengl renderer string: software rasterizer       if 3d acceleration is enabled you'll get a message like this:  [joe@arch64]$ opengl renderer string: mesa dri r600 (rv730 9490) 20090101 x86/mmx+/3dnow!+/sse2 tcl dri2    also i had to install xf86-video-intel, libgl, intel-dri, mesa and mesa-demos, and added i915 to the modules line in /etc/mkinitcpio.conf as described here.  everything works perfectly now
first, install the user themes extension
the best ways is to get source code from subversion official site and compile it manually.  in my own experience, if you compile it without berkeley db, there would be no problem with other dependencies
you can just pass through sort:  $ md5deep -rl * | sort -k2 d41d8cd98f00b204e9800998ecf8427e 2014-12-01/img_1969.png bd12c358db0c97230b9d48f67b2c0c98 2014-12-01/img_1970.png c3a9d8cb047192a03b857023948a7ba6 2014-12-01/img_1971.png   if your file name can contain newlines or other strangeness, use this instead (assumes gnu sort):  $ md5deep -0rl * | sort -zk2 | tr '\0' '\n' d41d8cd98f00b204e9800998ecf8427e 2014-12-01/img_1969.png bd12c358db0c97230b9d48f67b2c0c98 2014-12-01/img_1970.png c3a9d8cb047192a03b857023948a7ba6 2014-12-01/img_1971.png  
thanks for the answers, i created a sed command for it:   [root@notebook ~] test `whoami`=root &amp;&amp; k=`cryptsetup luksdump -q --dump-master-key $(blkid | awk '/crypto_luks/ {print $1}' | cut -d: -f1 | head -1)` &amp;&amp; echo "$k" | sed 's/^mk dump:/fgkmtusjs\nmk dump:/g' | sed '1,/^fgkmtusjs/d' | sed 's/.*\t//g' | sha512sum | sed "s/\-/`hostname`/g" enter luks passphrase:  d78abb0542736865f94704521609c230dac03a2f369d043ac212d6933b91410e06399e37f9c5cc88436a31737330c1c8eccb2c2f9f374d62f716432a32d50fac  notebook.localdomain [root@notebook ~]   tested on: scientific linux 6.4; ubuntu 12.04 
if hdparm can talk to the drive, and the drive supports ata-9, you'll see a line in the output of hdparm -i with the appropriate info:          nominal media rotation rate: 7200   (for a 7200 rpm rotating drive)          nominal media rotation rate: solid state device   (for a solid state device). 
-exec indeed can be used as a predicate
an http proxy server and memcached are different technologies that solve different problems and apply at different layers of your software stack
try sudo -i -u $user  gerald@book:~$ env |grep home home=/home/gerald gerald@book:~$ sudo -u ubuntu env |grep home home=/home/gerald gerald@book:~$ sudo -i -u ubuntu env |grep home home=/home/ubuntu  
simply add n to the end of the command for it to match the nth match, like this:  uname -r | sed 's/\./ /2'   what do you need it for though?    from the info page on sed:     the `s' command can be followed by zero or more of the following   flags:      g  apply the replacement to _all_ matches to the regexp, not just the first.       number  only replace the numberth match of the regexp.   
you could manually mount the camera: http://manpages.ubuntu.com/manpages/natty/man8/mount.8.html 
with bash, zsh, gnu echo or some implementations of ksh on some systems, this can be decoded simply by echo -e after replacing all % with \x.  url_encoded_string="%d1%80%d0%b5%d1%81%d1%83%d1%80%d1%81%d1%8b" temp_string=${url_encoded_string//%/\\x}  printf '%s\n' "$temp_string" # output: \xd1\x80\xd0\xb5\xd1\x81\xd1\x83\xd1\x80\xd1\x81\xd1\x8b  echo -e "$temp_string" # output: ресурсы   (it assumes the string itself doesn't contain backslash characters and is not one of the options supported by your echo command)  as @joshlee also points out, the "echo caveat" can be avoided by directly using:  printf ${url_encoded_string//%/\\x}   instead directly behind the first command. 
to plagiarize myself, you can set up a profile with your desired settings (instructions adapted from here):   run terminator, and set up the layout you want
maybe something like:  sed 'h;/#$/!d;s/^/\ /;x;/\n%/!d;s/.//;x;s/.*//;x'   since you want both the prompt before the error and after the error, that one includes both except for prompts that would otherwise appear both as the prompt after one error and the one before the next error to match your sample output.  it's a lot simpler if we include both prompts regardless of whether errors follow each other or not:  sed 'h;/#$/!d;x;/\n%/!d'   if you wanted only the prompt before the error, that would also be a lot simpler:  sed '/#$/!{h;d;}      x;/\n%/!d'     probably the best way to explain those is translate to a more verbose language like perl
use a negative argument to kill to kill the entire process group.  #!/bin/sh ps -eo pid,args | awk '/[r]epo/{print $1}' | xargs -i {} kill "$@" -{}   note also the ancient faq about how to avoid the useless grep | grep -v grep | awk.  invoke this like  55 7 * * * /path/to/killsync 0 8 * * * /path/to/killsync -9   we hope the second one will never actually be needed; that's hopefully useless too.  see http://stackoverflow.com/questions/11000538/linux-kill-with-negative-pid 
you can use the older [ syntax  if [ -n "$env" -a "$env" = 'production' ]   (note i used -n rather than ! -z because it reads easier, but it's the same thing).  or we can simplify to an even older syntax by forcing the string to have a value:  if [ "x$env" = 'xproduction' ]   finally, the -n test may not really be needed and you can possibly just do  if [ "$env" = 'production' ]  
it depends whether you have overwritten the beginning of the encrypted partition
first split one of the windows in two  ctrl+x 3,  then switch one of the two horizontal windows to the previous one (i.e
you can do this with gettimeofday()
it sounds like a perfect use for yum-downloadonly.   run yum install yum-downloadonly yum update --downloadonly --downloaddir=/path/to/dir   nixcraft has an excellent write-up on this tool. 
 because they didn't exist originally, and the default behavior is backwards compatible
there are many ways to handle suspend and hibernate capabilities, many of the old methods are deprecated
use | which is "or" operator for regex in the grep command
each processor has a run-queue, and might want to access other run-queues of other processors
i think it works. but probably it doesn't do what you expect.   $ exit &amp;   will create a sub-shell process, and make it run as a background job which will just finish right away. 
there are a number of things you can do to reduce the size and number of files in /boot/kernel.  possibly the best space saving is to be had by setting without_kernel_symbols in /etc/src.conf (if this file doesn't already exist, just create it), and the next time you installkernel, the debug symbol files won't be installed
theo de raadt (founder of the openbsd project) answer via mail:      because that is how it is.      if you want an operating system without network services, go find an   old copy of ms-dos.  
edit your "/etc/ssh/ssh_config" and comment out these lines:  gssapiauthentication yes gssapidelegatecredentials no  
you can set options in your .htaccess file
try booting the system with the kernel-option clocksource=jiffies or nohpet.  i have an open case about sles11 sp2 (using kernel 3.0) where i observe time-mismatches on vms.  the clocksource=jiffies made it worse in my case - but in yours it might help.  currently the support is focussing on the high-precision-event-timer (but i doubt that your embedded system has such a device). 
the best test to see if a server is accepting connections is to actually try connecting
you need to define and start the networks in libvirt before.   start by creating a xml file describing your network. enter in libvirt console, define the network using the xml file and then activate it
i have found an answer, namely running:  sudo setxkbmap -layout ara   changes my keyboard to an arabic one
either you can enable an compose key, or you can press ctrlshiftu followed by the unicode hexadecimal number of the character (leading zeroes can be skipped)
i switched back to the proprietary fglrx driver
awk doesn't remember the field positions or the delimiter strings
try  echo alt+1alt+6ctrl+v0  that's 6 key strokes (assuming a us/uk qwerty keyboard at least) to insert those 16 zeros (you can hold alt for both 1 and 6).  you could also use the standard vi mode (set -o vi) and type:  echo 0escx16p  (also 6 key strokes).  the emacs mode equivalent and that could be used to repeat more than a single character (echo 0ctrl+walt+1alt+6ctrl+y) works in zsh, but not in bash.  all those will also work with zsh (and tcsh where that comes from)
dhag's comment is correct
resolved  using iptables ruleset:  -a prerouting -p tcp -m tcp --dport 80 -j dnat --to-destination 2.2.2.2:3128 -a postrouting -s 172.17.0.0/16 -j snat --to-source 1.1.1.1   looks like this was because of the interface being set incorrectly (should have been docker0) -- have removed the interface flag from the iptables rules and works fine now 
i'm guessing you really want something like this:  function check_update {         echo "checking update" }  function reinstall_theme {         echo "reinstalling theme" }  all_done=0 while (( !all_done )); do         options=("check for update" "reinstall theme")          echo "choose an option:"         select opt in "${options[@]}"; do                 case $reply in                         1) check_update; break ;;                         2) reinstall_theme; break ;;                         *) echo "what's that?" ;;                 esac         done          echo "doing other things..."          echo "are we done?"         select opt in "yes" "no"; do                 case $reply in                         1) all_done=1; break ;;                         2) break ;;                         *) echo "look, it's a simple question..." ;;                 esac         done done   i've separated out the tasks into separate function to keep the first case statement smaller
escape the dollar sign, or remove the useless echo $( ..
one solution would be to assign a keyboard shortcut for that kwin action
arecord will record from your sound card, which is a dummy, so its not surprising it contains rubbish
you can extract the contents of the rpm to the disk (and not into / but some other directory)
to answer your question literally:  sed 's/   */:/g' | cut -d : -f 5   or  awk -f '  +' '{print $5}'   but that won't do if the number in brackets reaches 10, etc
in:  dirs="   $home/documents   $home/music "   you're assigning a string (containing spaces and newline characters and whatever characters $home may contain) to a scalar variable ($dirs).  then, you want to pass a list of directories to ls, that is several arguments
to find out what sound drivers are loaded, look for drivers containing snd and their dependencies (assuming your sound driver is part of the alsa framework; most are):  /sbin/lsmod | grep snd   for example, my pc has an intel sound chip, and amongst the dependencies of the snd module is the snd_hda_intel module, which is my chip's driver.  you can also ask the alsa tools
it's not on key combinations but on characters
rm --one-file-system should do the trick.     --one-file-system           when removing a hierarchy recursively, skip any directory that           is on a file system different from that of the corresponding           command line argument   source: http://man7.org/linux/man-pages/man1/rm.1.html 
reset or tput reset only does things to the terminal
to get the output of time into a var use the following:  usr@srv $ mytime="$(time ( ls ) 2&gt;&amp;1 1&gt;/dev/null )" usr@srv $ echo "$mytime"  real    0m0.006s user    0m0.001s sys     0m0.005s   you can also just ask for a single time type, e.g
gmail setup  in gmail, go click the gear icon, go to settings, go to the tab forwarding pop/imap, and click the configuration instructions link in imap access row.  then click i want to enable imap
your probably installed windows 10 after arch linux and windows wiped out the systemd-boot uefi entry
if those settings are not applied, than your desktop is broken.  is xfsettingsd running and reacting? is xfwm4 running and reacting?  join me in irc for live help 
checking the file /etc/urpmi/urpmi.cfg works as @slafat01 mentioned.  there is also the command:  [user@localhost ~]# urpmq --list-media ...&lt;list of media&gt;...   from man urpmq  --list-media [type]     list available media
the home dirs were never created for the other users
when dealing with aspell if you're not sure where things are stored it's best to consult its configuration to find out.  $ aspell --lang=en dump config | less   the 2 items that will tell you where the added words are ending up are as follows:  # home-dir (string) #   location for personal files # default: &lt;$home|./&gt; = /home/saml  # personal (string) #   personal dictionary file name # default: .aspell.&lt;lang&gt;.pws = .aspell.en.pws   so with this information in hand you can consult the file $home/.aspell.en.pws
probably an easier and safer way is to take the sources for 3.3.3 and compile your own backport
any time you have a question about a command on a red hat distro such as fedora, centos, or rhel it's best to utilize the package manager tools rpm or yum.  if the package isn't installed then use yum to see what it's about.  $ yum info &lt;package name&gt;   if it's already installed then you can also use rpm.  $ rpm -qi &lt;package name&gt;   example  $ yum info fedmsg loaded plugins: auto-update-debuginfo, changelog, langpacks, refresh-packagekit available packages name        : fedmsg arch        : noarch version     : 0.7.7 release     : 1.fc19 size        : 465 k repo        : updates/19/x86_64 summary     : tools for fedora infrastructure real-time messaging url         : http://github.com/ralphbean/fedmsg license     : lgplv2+ description : python api used around fedora infrastructure to send and receive messages with             : zeromq
swapping allows physical pages to be moved around, in the sense that a page used for one purpose could have its content swapped out then used for another purpose.  under a garden variety virtual memory management system, there is no such thing as fragmentation of physical memory as far as applications are concerned
tmpfs filesystems are independent
perhaps with tput, check available colors count,  ncolors=$(tput colors)  if [[ $ncolors -ge 8 ]];then    # colors available fi  
chroot doesn't change processes' personality by default, so within the chroot you still see the host's (kernel) architecture, x86_64.  on the other hand you've set up your trusty_i386 schroot with a linux32 personality, so schroot runs that when setting the chroot up — and linux32 (which links to setarch) changes the current personality to report a 32-bit kernel architecture, i686. 
what you want is a head request, but wget does not support it; curl does.  your distribution most probably has curl in repositories.  curl -s -i $url -l | awk '/location: (.*)/ {print $2}' | tail -n 1  $ url=http://unix.stackexchange.com/questions/89282/ $ curl -s -i $url | awk '/location: (.*)/ {print $2}' | tail -n 1 /questions/89282/how-to-figure-out-where-a-link-gets-redirected $ _   here:    -s prevents curl from showing a progress bar; -i makes curl issue a head request; -l makes curl follow redirects (thanks @brianstone), you may want or not want to include this, depending on which redirect headers you want to track; the awk script prints the matched expression in parens, just the local part of the uri.  
there is actually no need for tom 's custom my-disable-here-document function rebinding the keys
you can send as many files as you want to chmod; you don't have to individually chmod each file if they all are being set to the same permission set.  you have many options here:  chmod 0755 *.ksh  # if you want to set these permissions on all *.ksh files chmod 0755 script?.ksh  # if you want to set these permissions on all files named script[any single character].ksh chmod 0755 scripta.ksh scriptb.ksh scriptc.ksh  # the plainest form - simply list the files chmod 0755 script{a..c}.ksh  # use brace expansion   in short, this is a cat with many skins to filet
this should work:  who | cut -d ' ' -f 1 | sort | uniq |    while read user; do ps -u $user -o %u%c%a; done  
1
an interesting question, indeed
just figured out the problem.  when you giving privileges from other then the root user, then you need to specify user at the sudo command.  see below example:  this command run by cat and it works.  sudo -u dog vim /home/dog/test.txt  
you can try a naive approach to match non-comments like this:   $ egrep -v "^(//|/\*| \*)" sourcecode   this will only inverse match against prefixed comments - that is lines starting with either //, /*, * or */ - and hence it'll not leave out blocks that are commented out with the /* and */ pair. 
the wait command can be given multiple arguments, and it will wait for all those processes to exit
i recently came across this tool called lstopo that's bundled in the package hwloc (at least on fedora 19, that's where it was located)
give this tested version a try:  netstat -tn 2&gt;/dev/null | awk '/:80 / {print $5}' | sed 's/.*::ffff://' | sed 's/:.*//' | sor t | uniq -c | sort -nr |\ while read index ipaddress ; do \   printf "%s " "${index}" ;\   getent hosts "${ipaddress}" ;\   if [ $? -eq 2 ]; then \     printf "%s\n" "${ipaddress}" ;\   fi ;\ done   it is using the standard getent to query the hosts database in order to retrieve the hostname given its ip address.  the test:  5 81.133.113.200  host81-133-113-200.in-addr.btopenworld.com 4 80.229.142.126  garnerhome.plus.com 2 94.136.36.29    mail.e-trackit.co.uk 2 92.19.231.69    host-92-19-231-69.static.as13285.net 2 85.159.56.230 2 83.70.246.152   83-70-246-152-dynamic.b-ras1.prp.dublin.eircom.net 2 81.131.118.236  host81-131-118-236.range81-131.btcentralplus.com 2 185.106.92.42 1 92.19.232.88    host-92-19-232-88.static.as13285.net ...  
run the application under xtrace
one approach could be to use pid namespaces:  boot your system with a init=/some/cmd as kernel parameter, where /some/cmd forks a process in a new namespace (clone_newpid) and runs /sbin/init in it (it will have pid 1  in that new namespace and pid 2 in the root namespace), then in the parent, execute your "program".  you'll probably want a way to control your program in one way or another (tcp or abstract unix socket for instance).  you'll probably want to mlock your program in memory and close most references to the filesystem so that it doesn't rely on anything.  that process won't be seen from the rest of the system
you can do  :100,200w filename   of course 100,200 is the range of lines you want to write. 
the arch wiki has a locale page.  essentially, you first have to enable a specific locale by uncommenting the name of the locale in the file /etc/locale.gen   then update the list with # locale-gen  to define the system-wide locale used on the system, add the specified locale to the /etc/rc.conf file  
all services need to be loaded and parsed before starting them, and your service isn't available early on in the boot process when systemd parses all services since it's on a different partition.  to solve it either keep the local services in /etc/systemd/system/ or make a package for your distribution and place them in /usr/lib/systemd/system/ 
if you want to ensure fragmentation but not prevent it (so you only have partial control over what happens), and you don't care about the specifics of the fragmentation, here's a quick &amp; dirty way of doing things.  to create a file of n blocks in at least two fragments:   open the file with synchronous writes, write m &lt; n blocks. open another file
as far as i know there is no way to directly do that as cron has a special purpose - running schedules commands at a specific time
from the ln man page:     when creating hard links, each target must exist.   no mention of symlinks there; in fact, this statement seems to imply that this is not the case for symlinks.  as i said in my comment on your question, when creating a symlink to a non-existent source, a broken link is created:  $ ln -sfv blah blabla 'blabla' -&gt; 'blah' $ file blabla blabla: broken symbolic link to 'blah'   as far as ln is concerned, there's no reason to cry error: you asked for a symlink and it obliged
turns out to be some crazy interrupt on macbook pros
brandbot: tool to write branding to /etc/os-release when you start it1, it looks for /var/lib/rhsm/branded_name and adds in /etc/os-release:  pretty_name=first_line_from_branded_name   1path-based activation — system services that support path-based activation can be started on-demand when a particular file or directory changes its state
from man ping:     -w deadline           specify a timeout, in seconds, before ping exits regardless of how many packets have been sent or received
the drwx------ on your home directory is preventing other users from traversing it, i.e
i don't think using yum is feasible for such an early release of fedora
symlinks themselves have 777 because in unix, file security is judged on a file/inode basis
i came across this method discussed on so in this q&amp;a titled: how can i log my logins/logouts and screen locks/unlocks in gnome
sed '/^start-date:/ {n; /\n$/d}'   sed's a stream editor, slurp up/identify line gaggles and have your way with them
to get the key name, run the command xev and press the key you intend to use
the difference between [ and [[ is quite fundamental.   [ is a command
you should use &lt;location&gt; instead of &lt;directory&gt;.  &lt;location /my_folder/&gt; order deny,allow deny from all allow from 1.1.1.1 &lt;/location&gt;   see document on sections for apache 2.2, apache 2.4. 
you cannot
if your host is windows, you can use samba to share files from the client with the host
the complete bit in my /etc/services is:  # /etc/services: # $id: services,v 1.53 2011/06/13 15:00:06 ovasik exp $ # # network services, internet style # iana services version: last updated 2011-06-10  [...]  # port 1236 is registered as `bvcontrol', but is also used by the # gracilis packeten remote config server
one way to do this is via the /sys/power interface
gzip stores some of the original file's metadata in record header, including the file modification time and filename, if available
switch to vim, and use :set hlsearch  you can then use :highlight search ctermfg=yellow to customize; where:   cterm is for formating ctermfg is for foreground color ctermbg is for background color   see :help highlight link  you can then use :noh to temporarily hide the last search highlight. 
not quite the answer you were looking for, but it might be a better one.  mandb is an implementation of man that will format man pages in html
most of the distros can be used as a base and then customizations can be applied to this base, and written to an iso.  fedora  fedora offers what's called a a "spin" or "respin"
you can track (and submit) kernel bugs in the kernel bug tracker . 
your bash functions should work, but the "usual" way of doing that is to write a wrapper script for each executable, and set anything that needs to be set in there
i think there might be a version mis-match or something, but jasonwryan was on the right track for my purposes
to get the familiar regexps working you need to enable "extended regular expressions" with the flag '-e'
if i understand the source correctly, under linux, the maximum number of characters that can be read in one go on a terminal is determined by n_tty_buf_size in the kernel source
the package is either nautilus-share or gnome-user-share. 
on most unices:  head -c 1g &lt;/dev/urandom &gt;myfile   if your head doesn't understand the m suffix:  head -c 1073741824 &lt;/dev/urandom &gt;myfile   if your head doesn't understand the -c option (it's common but not posix; you probably have openbsd):  dd bs=1024 count=1048576 &lt;/dev/urandom &gt;myfile   do not use /dev/random on linux, use /dev/urandom. 
as others have said in the comments, listing only non-directories doesn't exactly mesh with the purpose of the tree command.  however, listing only the files in the current directory is not unusual if you're like me and prefer to use a customized tree over ls (and maybe you've even aliased ls to tree with your preferred flags and arguments).  leveraging a combination of tree and grep will get you what you want:  $ tree -f . ├── file1.txt ├── file5.txt ├── parent_dir1/ │   ├── child_dir/ │   ├── file2.txt │   └── file3.txt └── parent_dir2/     └── child_dir2/         └── file4.txt  4 directories, 4 files $ tree -fl 1 | grep -v /$ . ├── file1.txt ├── file5.txt  2 directories, 1 file   the 'f' flag causes tree to append a '/' to directories, and the 'v' flag to grep inverts the given pattern, which matches all lines ending in '/'.  you'll notice that even the summary at the end is still applicable, despite the fact that the directories aren't actually being displayed.  once you go more than one level down, the tree structure dominates and things get  a bit weird.  $ tree -fl 3 | grep -v /$ . ├── file1.txt ├── file5.txt │   ├── file2.txt │   └── file3.txt         └── file4.txt  4 directories, 4 files   edit  also, if the sort of broken tree output bothers you (i.e
according to the man page the parameter -nh should do what you are looking for:     directory options    -nd    --no-directories        do not create a hierarchy of directories when retrieving recursively
in a debian-derived system like mint, deb packages are not meant to be installed in a user's home directory
you can use lspci -v to list pci device information, along with their irqs
ssh allows you to execute multiple commands
disclaimer: this is entirely without testing right now:  gawk '1{ print $9, $7;}' httpd.log \ | sort \ | uniq -c   will take the fields 9 (status code) and 7 (path) from the log file, sort them (first by status code, then by path), then combine consecutive lines to one, prefixing with the number of occurences
@sukminder has already given the simple answer; i have a couple tidbits of style points and helpful syntax about your example code (like a code review)
the default behavior is to add a interface that will only accept packets where the 802.1q field is the same as the vlan id to this given interface
i don't have chrome installed, only chromium, but i hope they aren't too different for this to work
from the screen manpage:  screen -d -r attach here and now
you aren't really supposed to use the shell on the main freenas host, and so the pkg repositories are disabled
it's an xorg bug
given the issue of module dependencies that make blacklisting a module like that difficult, i would suggest the route of recompiling your kernel with that subsystem explicitly not built
in order to get a core dump file generated you need to setup your environment so that the following bash configuration is set:  $ ulimit -c unlimited   you can add this to your $home/.bashrc or $home/.bash_profile. 
at least the version of dooble you uses has no history saving at all implemented
this is a open questions (please edit):   break free from front-monotomy (linux libertine) those that can, do
these .jar files are not really being installed into the /etc directory
when writing about this topic, i recommend reading through this paper:  http://www.giac.org/paper/gcih/571/x11-forwarding-ssh-considered-harmful/104780  it describes the consequences of letting forwardx11 option turned on by default in really nice and prosaic way.  but to sum this up, yes, you should turn this off by default and let it on only for trusted servers where you actually need it in your local ~/.ssh/config file.  untrusted machine is basically each machine, where somebody else has a root access, because that root can access your whole local x11 session, which is basically a thing you don't want from server in remote data-center or for internet facing machine that could be compromised. 
if you have column(1), an old bsd tool, try column -t, for pretty-printing tables
if you want to capture both standard output and standard error streams then redirect standard error into standard output:  mountres="$(mount &lt;host&gt;:/exported_dir /mount_dir 2&gt;&amp;1)"  mount &lt;host&gt;:/exported_dir /mount_dir &gt;mountmsg 2&gt;&amp;1  
there isn't anything you actually need to do, things will work for the user that did run the rm -rf
linux mint is ubuntu-based, you can install packages from the ubuntu repositories
it's referring to this page from the readme, which tells you how to specify your hostname
something along the lines (depending on your shell) of  for file in rb-script/*.rb; do ruby "$file"; done   should do the trick; alternatively (and shell-independently, i think)  find rb-script -type f -exec ruby "{}" \;   using find; where you can, depending on your situation, be more specific, à la  find rb-script -maxdepth 1 -type f -name '*.rb' -exec ruby "{}" \;   in general, command &lt;glob-pattern&gt; would also work if command accepts several files (and there are less files than the commandline argument maximum of your shell), but i doubt ruby does that
when building the kernel and module using make oldconfig, make and make install, the resulting modules will have debug information available in the files.  use the install_mod_strip option for removing debugging symbols:  make install_mod_strip=1 modules_install   similarly, for building the deb packages:  make install_mod_strip=1 deb-pkg  
“sleep” is not really the right metaphor for this process state if you aren't a kernel designer
this cannot be done with suspend because of the ram issue, but it can be done with hibernate.  you will need to carefully setup your boot loader and make sure you aren't using any shared partitions (swap and wherever each kernel looks for the hibernate files).  you can even take this farther than just linux distros
what is happening is that you are recursively calling your ls function
short answer: you can't, at least not exactly the way you want.  more useful answer: you can achieve what you want by piping the output to something like more or less , for example :  locate linux | less   this will pause the output scroll at the end of each page, where the page length is defined as the terminal height. 
i found the answer in documentation for the open system call:     the term open file description is the one used by posix to refer to the entries in the system-wide table of open files
answering my own question... in fact it is possible to remove directory from the remote server completely (including directory itself)
inode 0  is used as a null value, to indicate that there is no inode.  indoe 1 is used to keep track of any bad blocks on the disk; it is essentially a hidden file containing the bad blocks
the simplest thing of course would be to try and connect, if it asks you for a password, then you know it needs one.  another approach, presumably closer to what you had in mind is  /sbin/iwlist wlan0 scan   the command above will use the wireless interface wlan0 (change it to the name of the interface on your machine) to scan the available wireless networks
you could use /var/tmp, but:  if you have a quota, the admin will probably not appreciate you creating large files outside of your $home directory
there's no built-in way to concatenate a file and remove it, you'll have to break it into two steps.  in zsh, or in bash ≥4 after running shopt -s globstar, or in ksh after running set -o globstar:  cd test3 for x in **/*.fastq; do   cat "$x" &gt;&gt;"/auto/dr-lc_sa1/data/test2/$x" &amp;&amp; rm "$x" done   without ** to recurse into subdirectories, use find.  cd test3 find 
./test.sh runs test.sh as a separate program
you need to tell vim using command! -bar that a command can be followed by another command with the pipe symbol |:  command! -bar fixwhitespace %s/\s\+$//e command! fixcommas %s/,\s\@=/, /ge   now this is ok:  command! fix fixwhitespace|fixcommas   but this isn't:  command! fix fixcommas|fixwhitespace   see :h command-bar for more details.  the error message e488: trailing characters: fixwhitespace|fixcommas is vim's way of telling you that it didn't expect anything following the fixwhitespace command
finally success:  i found that the torobot usb board could be communicated with an arduino serial driver
$ sed 's/^.*\(%[0-9]\+\).*$/\1/' input   assuming that a line contains at most one of those %123 tokens and that every line contains such a token.  the \( \) meta character mark a match-group - which is then referenced in the substitution via the \1 back-reference
sed '/big.20021208.00001/!d;s/.*\*//' &lt;&lt;\data     st*810*0001     big*20021208*00001**a999     n1*st*xyz test corporation*9*122334455     n3*987 freeway dr.     n4*new york*ny*98765     n1*bt*abc test company*9*122334455     n3*123 highway street     n4*los angeles*ca*12345     itd*01*3*2**30**30*****60     fob*pp     it1**1*ea*200**ua*ean     pid*f****lamp     it1**4*ea*50**ua*ean     pid*f****chair     tds*2000     cad*****routing     iss*30*ca     ctt*50     se*19*0001     st*810*0002     big*20021208*00001**a1000     n1*st*xyz test corporation*9*122334455     n3*987 freeway dr.     n4*new york*ny*98765     n1*bt*abc test company*9*122334455     n3*123 highway street     n4*los angeles*ca*12345     itd*01*3*2**30**30*****60     fob*pp     it1**1*ea*200**ua*ean     pid*f****lamp     it1**4*ea*50**ua*ean     pid*f****chair     tds*2000     cad*****routing     iss*30*ca     ctt*50     se*19*0001     st*810*0002     big*20021208*00001**a1000     n1*st*xyz test corporation*9*122334455     n3*987 freeway dr.     n4*new york*ny*98765     n1*bt*abc test company*9*122334455     n3*123 highway street     n4*los angeles*ca*12345     itd*01*3*2**30**30*****60     fob*pp     it1**1*ea*200**ua*ean     pid*f****lamp     it1**4*ea*50**ua*ean     pid*f****chair     tds*2000     cad*****routing     iss*30*ca     ctt*50     se*19*0002     st*810*0003     big*20021208*00001**1001     n1*st*xyz test corporation*9*122334455     n3*987 freeway dr.     n4*new york*ny*98765     n1*bt*abc test company*9*122334455     n3*123 highway street     n4*los angeles*ca*12345     itd*01*3*2**30**30*****60     fob*pp     it1**1*ea*200**ua*ean     pid*f****lamp     it1**4*ea*50**ua*ean     pid*f****chair     tds*2000     cad*****routing     iss*30*ca     ctt*50     se*19*0003 data   that yields only these results:  a999 a1000 1001  
all the implementations of cron that i know of re-read /etc/crontab every minute, i.e
there are lots of different ways to do this.  command line  you don't necessarily need to ‘format’ (i.e
there are 2 sorts of hostname entries managed by xauth, local names such as myhost/unix:0 and remote names such as remote:0
there is no difference in them
appears to be related to this question http://gaming.stackexchange.com/questions/21848/how-can-i-play-minecraft-through-a-proxy-server  you can either port forward or create a socks proxy
the steps i took to fix it:   updated bios in the bios, diabled the sata ide combined mode with this help reading the kernel documentation about kernel parameters, since every solution online was about adding parameters to that
try something on these lines:  sudo apt-get install v4l2loopback-utils gstreamer1.0-tools sudo modprobe v4l2loopback # might not be needed gst-launch-1.0 -v rtspsrc location=rtsp://your_stream_url ! v4l2sink device=/dev/video1   then you should be able to use zbarcam against /dev/video1 as usual. 
you will have to write some c code, as described in the kernel doc.  #include &lt;linux/serial.h&gt; struct serial_rs485 rs485conf = {0};  int fd = open ("/dev/ttyacm0", o_rdwr); if (fd &lt; 0)... rs485conf.flags |= ser_rs485_enabled; if (ioctl (fd, tiocsrs485, &amp;rs485conf) &lt; 0)...  
you need to run depmod.  depmod (by default) reads the modules under /lib/modules/$(uname -r), finds which symbols they export and also what they need themselves, then using these info creates the symbol (module) dependencies between modules, and saves it in the file /lib/modules/$(uname -r)/modules.dep and also creates a binary hash /lib/modules/$(uname -r)/modules.dep.bin.  it also creates two other files:   /lib/modules/$(uname -r)/modules.symbols (and it's binary hash /lib/modules/$(uname -r)/modules.dep.bin): contains the symbols each module exports /lib/modules/$(uname -r)/modules.devname: contains the /dev entry that needs to be created for necessary modules, contains the module name, name of the /dev entry and the major, minor numbers   just to note, you can also run depmod for a specific kernel version or on a specific module, check man depmod. 
x refers usually to the x window system, a networking protocol and a software which supports drawing application windows on your screen
so recently i wanted to do this with tar
if you are running vm tools, the tool has an option to periodically sync the time with the host.  if in your path: vmware-toolbox-cmd timesync status to view and vmware-toolbox-cmd timesync disable to stop it.  of course any non-vm method of time sync could be there as well
i have fixed the problem
this is an illustration of the difference between authentication and authorization.  sudo is primarily a tool for authorization
use the newer linux driver version 15.00.00.00 from lsi
if you have root access to the remote box, install the package ncurses-term. this will provide the rxvt-256color terminfo entry.  as a non-root user, you can also copy over the rxvt terminfo entries to $home/.terminfo/r/ on the remote machine, and export terminfo=$home/.terminfo.  ssh &lt;host&gt; 'mkdir -p .terminfo/r' scp /usr/share/terminfo/r/rxvt-unicode-256color &lt;host&gt;:~/.terminfo/r/  
leverage an alias or better a function.  for example:  ssh () { command ssh "$@"; echo foobar; }   now, you can run:  ssh mysite   after you exit from the ssh session, echo foobar will be run.  change echo foobar with the actual command you need to run, and of course you can tack multiple commands if you want.  to make the function definition permanent, put it in your ~/.bashrc.    also note that, it might not always be desired to have the function named as ssh when you want to explicitly use the external ssh
if you're on gnu/anything and the number of lines is multiple of 9, you could run  split -l9 --filter='pr -3 -s" " -t' infile   this splits the input into pieces of nine lines and each piece is piped to pr -3 -s" " -t' which columnates it..
use the n;p;d cycle and attempt to substitute each time:  sed '$!n;s/\(foo\n\)#\(bar\)/\1\2/;p;d' infile   this removes the leading # from #bar only if it follows a line ending in foo otherwise it just prints the pattern space unmodified.    apparently, you want to uncomment us mirrors in /etc/pacman.d/mirrorlist which is a whole different thing (please edit your question to reflect that):  sed '/united states/,/^$/{//!s/^#//}' /etc/pacman.d/mirrorlist   this will uncomment all mirrors in the united states section  in /etc/pacman.d/mirrorlist 
the first line of the script probably should start with #!, followed by the name of the python interpreter
does this do what you want?  sed '/{\.to/b;/\.to\(_not\|\)\s/s/^\s*/\0expect(/' file   alt:  sed '/{\.to/b;/\.to\(_not\|\)[[:space:]]/s/^[[:space:]]*/\0expect(/' file   sample:  $ diff -ytw 48 infile &lt;(./sed_script) .to do                 |  expect(.to do   .to space and        |    expect(.to space and         .to tab        |          expect(.to tab some s                    some s day x                     day x .to r                  |  expect(.to r .tofry                    .tofry not t                     not t .to     tab            |  expect(.to      tab {.to not me               {.to not me {.to nor me               {.to nor me when e                    when e         {.to nope                 {.to nope .to_not but yes!       |  expect(.to_not but yes   {.to oh nono              {.to oh nono .to_notx                  .to_notx .do s                     .do s {.to not do me            {.to not do me so d                      so d  |--- original file ----|--- modified file ----|  
since you only want to get the domains accessed via http you could setup up a transparent http-proxy with polipo or privoxy and evaluate the log file.   set up the proxy install and configure the proxy, that he listen for example on the address 127.0.0.1:8080 and enable logging. set up the firewall rule write a firewall rule, which redirect all outgoing traffic to the port 80 to the address of proxy 127.0.0.1:8080, which then forwards the traffic to requested domain. parse the log file set up a parser to extract all the accessed domains from the log file.   this solution has it's up and downs:   up's:  your users don't have to change something on their system, browser, ... you gain some capabilities, like caching, filtering, ..
a theme change fixed the problem
use lshw!     lshw      lshw -class disk  
so you want to run something like sudo passwd root? 
as explained here, the syntax $'string' specifies a c-style string which includes magic escaped characters, such as \n for a newline
when you type function_under_test, the shell think it's a command, not a variable
maybe better than earlier answer;  firewall-cmd --permanent --zone=trusted --change-interface=docker0 firewall-cmd --permanent --zone=trusted --add-port=4243/tcp firewall-cmd --reload  
penguintutor.com/linux/useradmin-reference  excerpt:     su (switch user)      one of the features of linux is the ability to change userid when   logged into a system
source packages which use autotools -- ./configure; make; make install -- usually have a make uninstall target as well
$ sleep 5 &amp; [1] 1234 $ disown  
dm-crypt is a  transparent disk encryption subsystem
with awk  awk '{sub(/\..*/,"",$2);$0=$1 "  "$2}1' foo.txt   with sed  sed 's/^\(\([^.]*\.\)\{4\}\).*$/\1/;s/\.$//' foo.txt  
createrepo creates some informational files that can be used by yum tool while fetching data from a reposiotry. the files are filelists.xml,repomd.xml etc. the below tutorial explains the complete yum working. how does yum work? 
..
there is a feature request in gnome's bugzilla asking for a way to do this, so it seems it is not possible at the moment
ps has -u and -u options for that.  from man ps:   -u userlist       select by real user id (ruid) or name
basing on responses from: http://www.rdoxenham.com/?p=288 and http://superuser.com/questions/259216/disabling-mouse-acceleration-in-x-org-linux you can use xinput command.  find your device   xinput    virtual core pointer                          id=2    [master pointer  (3)]    ↳ virtual core xtest pointer                id=4    [slave  pointer  (2)]    ↳ synps/2 synaptics touchpad                id=14   [slave  pointer  (2)]    ↳ a4tech usb device                         id=12   [slave  pointer  (2)]    ↳ a4tech usb device                         id=17   [slave  pointer  (2)]  ....   you need to find a device that is named like your pointing device (in my case a4tech usb device)
with these awk scripts i always find it best to break them down so i can see what's going on.  printf  this one is easy
as suggested in my question, it was a server-side change that needed making
if you are using a bashshell, you can try:  if [ $2 == "+" ] ;then  res=$(($1 + $3))  echo $res  fi   edit  change the next line (note the substitution of ' by "):  else res=`operación no válida` ;   to:  else res="operación no válida" ;   edit 2  instead of using so many if else statements, you can use a case statement:  case $2 in +)   res=`expr $1 + $3`   ;; -)   res=`expr $1 - $3`   ;; /)   res=`expr $1 \/ $3`   ;; x)   res=`expr $1 \* $3`   ;; *)   res="operación inválida"   ;; esac  echo "$res"  
as mentioned, use other separator or escape the slashes
@jordanm's comment nailed it
quote the eof terminator passed to the &lt;&lt; operator (in any way):  cat &lt;&lt; 'eot' &gt; file $var eot   or  cat &lt;&lt; \eot cat &lt;&lt; eo\t cat &lt;&lt; "e"'o't cat &lt;&lt; ""eot   that's the documented and standard way to prevent any type of expansion inside the here-document. 
add zsh to /etc/shells:  command -v zsh | sudo tee -a /etc/shells   you can now use chsh to set zsh as shell:  sudo chsh -s "$(command -v zsh)" "${user}"   see this documentation: changing your login shell 
ethernet cards might have (supposedly) unique mac addresses, but what about virtual interfaces like aliases (e.g
it matters very much that the file is on an ntfs partition.  the : sign is not a special character on most unix systems, and in particular not on linux (only / is special)
this depends on your distribution: some versions of cron support this, others don't
you could do a lot of the work w/ shell math so you don't have to fork every few seconds, but you probably would want to work in some sort of synchronizer every once in a while to ensure the time is keeping well.  the below loop just sets some initial values for $h, $m, and $s then decrements once every 15 seconds and prints a countdown line at the top-left hand of the terminal screen (row 1, column 1, \033[home)
in fact it seems that the system was more affected that the log was saying! maybe because of the dev folder, maybe symlinks..
supporting gnu or solaris 11 sleep arguments (one or more &lt;double&gt;[smhd] durations, so would also work with traditional implementations that support only one decimal integer number (like on freebsd), but not with those accepting more complex arguments like iso-8601 durations)
using awk:  history | awk '{$1="";print}' 
bbkeys was overriding my key-bindings
i know there is already a selected answer, but you can get the requested behavior with just ls:  ls -ld -- */   (note that the '--' marks the end of parameters, preventing folder names beginning with a hyphen from being interpreted as further command options.)  this will list all the directories in the current working directory where it is run
if you don't need to use sed for this, here are a few other options:  $ echo 1 2 3 4 | tr ' ' '\n' | while read f; do let f+=1; echo $f; done 2 3 4 5 $ echo 1 2 3 4 | tr ' ' '\n' | awk '{print $1+1}' 2 3 4 5 $ echo 1 2 3 4 | tr ' ' '\n' | perl -lne '$i=$_+1; print $i' 2 3 4 5   sed is a stream editor, it is not supposed to do mathematical expressions
there is a bug where thunderbolt connections aren't recognized in linux kernel 4.1, 4.2 and 4.3 but are in 4.0
there are several factors to consider before choosing a directory path
are you using bash? in that case, try something like that:  maxcount=10 count=1  while [ "$count" -le $maxcount ]; do  number[$count]=$random  let "count += 1" done  echo "${number[*]}"   you can also replace the last line with:  echo "${number[@]}"   some documentation here: http://www.tutorialspoint.com/unix/unix-using-arrays.htm 
you're close:  rm /some/path/{file1,file2}   or even  rm /some/path/file{1,2}   related, and supported by other shells, is a pattern like  rm /some/path/file[12]   the first two are expanded to two explicit file name arguments; the third is a pattern against which all files in /some/path are matched. 
chrome is not opensource..
use single quotes:  $ sudo chroot mychroot /bin/bash -c 'my_var=5; echo ${my_var}'  
you'll probably find the "choosing the right installation medium" part of the install guide helpful.  install-x86-minimal-timestamp.iso is the livecd image
this script iterates across the set of mp4 files that you have
working code solution for anyone who just came here for a copy-paste based on wurtel's:  #!/bin/bash for i in {01..84}; do     #declare array to store files with same prefix     declare -a files=()     echo "processing $i"     for j in `ls $i*.csv`; do         #add files with same prefix to array         files=("${files[@]}" "$j")     done     #cat first file including header with the rest of the files without the headers     if [ ${#files[@]} -gt 1 ]; then         cat &lt;(cat ${files[@]:0:1}) &lt;(tail -q -n+2 ${files[@]:1}) &gt; "$i".csv     else         cat &lt;(cat ${files[@]:0:1}) &gt; "$i".csv     fi done   stéphane chazelas' way using awk
tl;dr (aka executive summary)   yes, you should be worried. yes, this is severe (giving total strangers potential complete control over your files and resources).   you should definitely upgrade your desktop as well as any servers.  (https://security.stackexchange.com/questions/68156/is-connecting-to-an-open-wifi-router-with-dhcp-in-linux-susceptible-to-shellshoc)  your dhcp client uses dhclient-script which uses shell variables passed from the server
to uninstall:  sudo rm -f -r /usr/local/nginx &amp;&amp; rm -f /usr/local/sbin/nginx   source:  http://articles.slicehost.com/2007/12/3/ubuntu-gutsy-installing-nginx-from-source 
this shell script should handle the starting and stopping of any program:  #!/bin/bash  basecmd=${1%%\ *} pid=$(pgrep "$basecmd") if [ "$?" -eq "0" ]; then     echo "at least one instance of "$basecmd" found, killing all instances"     kill $pid else     echo "no running instances of "$basecmd" found, starting one"     $1  fi   let's say you saved it under ~/mystarter, you can run any command with it using ~/mystarter &lt;name&gt;, eg in your case, bind meta+r to:  ~/mystarter gnome-run   and make sure the script is executable: chmod u+x ~/mystarter
edit: the next google result after your question was this one with same solution : zsh: make alt+backspace stop at non-alphanumeric characters  this answer was provided by /nick foh from #zsh on freenode.  backward-kill-dir () {     local wordchars=${wordchars/\/}     zle backward-kill-word } zle -n backward-kill-dir bindkey '^[^?' backward-kill-dir   this way you can use ctrl+w for deleting a word (in vim lingo) and alt+bkspc to delete a word 
the closest equivalent would probably be to install the below packages:  su -     yum install make automake gcc gcc-c++ kernel-devel   however, if you don't care about exact equivalence and are ok with pulling in a lot of packages you can install all the development tools and libraries with the below command.  su - yum groupinstall "development tools" "development libraries"  
if you want to output a regexp match and all the indented lines that are just after the match:  command | perl -ne '/^( *)/; $i = length $1; $j &amp;&amp; $i &gt;= $j and print, next; $j = 0; /regexp/ and $j = $i + 1, print'   replacing regexp by your regular expression.  for instance,  $ perl -ne '/^( *)/; $i = length $1; $j &amp;&amp; $i &gt;= $j and print, next; $j = 0; /a/ and $j = $i + 1, print' &lt;&lt;eof a b   c   a     b     a     c       b     d   e     b   a     c e eof   outputs:  a   a     b     a     c       b     d   a     c  
that thread and its accepted answer in particular are about using python for shell scripting, not as an interactive shell.  to write scripts in a different language, put e.g
ok, here it is answered by pierre schmitz, thx nymous for the link:  openssl, phar and posix modules are now built in php7 core
you can do this using process substitution.  
 add space after [ (it is a command) use -n to test if length of string is nonzero, or -z to test if it is zero put double quotes around variables   so:  read finding  if [ -z "$finding" ]; then     echo "you didn't enter anything" else     grep "$finding" information.txt     if [ ! "$?" -eq 0 ]; then         echo "no such information in database."     fi fi  
i looked and did not find any offering that provided just a web app interface to an existing slocate database file
using awk  to remove blanks from lines 2, 4, and 5:  $ awk 'nr==2 || nr==4 || nr==5 {gsub(/ /,"");} 1' file  f h t s q e g h c h t fhtrfhvfdgn q a z x s w e d c v f fhbchthbvhf plkoijuhygt t f r d c v b h n j u   in awk, nr is the line number
if i understand what you are asking correctly then what you want is inside the smb.conf located here:     /etc/samba/smb.conf   add these options to the [global] section:     force user = rolf    force group = coders  
this is doable - even with alias, though the only way i know would involve eval which can be dangerous depending on what the arguments might contain - but not with regex
try this: open terminal, then type su and type your root user password
you can't rename a file to . or .. because all directories already contain entries for those two names
by convention, /opt is used for manually installed programs with self contained directories
you can specify a directory or file on command line and the file system that contains that file/directory.  $ df / filesystem     1k-blocks     used available use% mounted on /dev/sda1       63579860 22097564  38297452  37% /   you can read more on the manpage, df(1). 
gnu sed accepts an optional extension after -i
you have to use grep -r config_snd_soc_mxs_sgtl5000.  each of these config options just represents a #define macro
poking at posix:  initialization in ex and vi    see  initialization  in  ex  and  vi  for  a  description  of ex and vi    initialization for the vi utility.   and the manpage for ex says:     ieee std 1003.1-2001  does  not  mention system-wide ex and vi start-up    files
using awk '{print $nf}'  will do the trick
that's close:  rpm -q --whatprovides "foo = 2"   but it does not accept a version
the method is called overstriking or overtyping, and goes back to the days of typewriters.  byte 0x08 (aka \x08 or ^h) is the ascii "backspace" character
ok so this is what i found out:  the latest ubuntu versions make use of upstart (as @polemon correctly pointed out), which uses specific config files in the /etc/init directory to configure the run level at which a script should run. upstart puts upstart job files in the /etc/init folder and normal init scripts in /etc/init.d and in the various /etc/rc*.d folders and is actually able to run both of them.  systems not using upstart only use /etc/init.d and /etc/rc*.d
the command mesg n opts out of all messages
no
you're doing this:  ssh -av -e deploy@domain.com:/var/www/domain.com /users/user/workspace/domain   you're not executing rsync at all and ssh is telling you that deploy@domain.com:/var/www/domain.com is not a valid escape character.  read ssh(1):     -e escape_char               sets the escape character for sessions with a pty (default: `~')
when executing shell scripts that have the setuid bit (e.g., perms of rwsr-xr-x), the scripts run as the user that executes them, not as the user that owns them
you can call exec again to restore the original descriptors
use parameter expansion:  #! /bin/bash  strings=('job with id 0 ended with status completed, return code 16, in 1 minute 12 seconds'          'job with id 0 completed with return code 255'         )  for string in "${strings[@]}" ; do     code=${string#*return code }     code=${code%%[!0-9]*}     echo $code done   # removes pattern from the left, % from the right. 
set up your user ftp_user so that they can ftp successfully into their home directory
it's not that difficult to decipher in fact.  this piece of code just defines a function named : which calls two instances of itself in a pipeline: :|:&amp;
you do not need to run a program
it's a proprietary microsoft format
to move files with the word in its name:  find /path/to/dir1 /path/to/dir2 /and/so/on -type f -iname "*heavengames*" \ -exec mv -t /path/to/heavengames-threads {} \+   to move files with word in its body:  find /path/to/dir1 /path/to/dir2 /and/so/on -type f -exec grep -q heavengames {} \; \ -exec mv -t /path/to/heavengames-threads {} \+   ps
you can use format specifiers in stat to get the specific information:  stat -c "%s %y" yourfile   to assign it individually for later comparison:  size=$( stat -c "%s" yourfile ) modt=$( stat -c "%y" yourfile )   to compare an attribute of two files you may use, e.g.:  size1=$( stat -c "%s" yourfile1 ) size2=$( stat -c "%s" yourfile2 )  if [[ $size1 == $size2 ]] then echo equal size else echo different size fi   this can also be done inline; using the arithmetic command it's:  if (( $( stat -c "%s" yourfile1 ) == $( stat -c "%s" yourfile2 ) )) then echo equal size else echo different size fi   to compare against a string containing an iso date in field 4 you need stat -c "%y", e.g.:  refdate=$( awk '{print $4}' &lt;&lt;&lt; "${output1}" ) modt=$( stat -c "%y" yourfile2 | awk '{print $1}' )  if [[ "$modt" == "$refdate" ]] then echo equal date else echo different date fi  
you just want to increase the swap size on your system using the space from sda2
the err trap is not to run code when the shell itself exits with a non-zero error code, but when any command run by that shell that is not part of a condition (like in if cmd..., or cmd || ......) exits with a non-zero exit status (the same conditions as what causes set -e to exit the shell).  if you want to run code upon exit of the shell with non-zero exit status, you should add a trap on exit instead and check $? there:  trap '[ "$?" -eq 0 ] || echo hi' exit   note however that upon a trapped signal, both the signal trap and the exit trap would be run, so you may want to do it like:  unset killed_by trap 'killed_by=int;exit' int trap 'killed_by=term;exit' term trap '   ret=$?   if [ -n "$killed_by" ]; then     echo &gt;&amp;2 "ouch! killed by $killed_by"     exit 1   elif [ "$ret" -ne 0 ]; then     echo &gt;&amp;2 "died with error code $ret"   fi' exit   or to use exit status like $((signum + 128)) upon signals:  for sig in int term hup; do   trap "exit $((128 + $(kill -l "$sig")))" "$sig" done trap '   ret=$?   [ "$ret" -eq 0 ] || echo &gt;&amp;2 "bye: $ret"' exit   note however that exiting normally upon sigint or sigquit has potential annoying side effects when your parent process is a shell like bash that implements the wait and cooperative exit handling of terminal interrupt
the usage of -f is more clearly described in the man page from 4bsd, which was where the -f and -i options were added:     if file2 already exists, it is removed before file1 is moved
compare the two here documents in the following example:  (yeti@darkstar:6)~/wrk/tmp$ cat ./xyzzy  #!/bin/bash cat &lt;&lt; eof version 1 - today is $(date) eof cat &lt;&lt; 'eof' version 2 - today is $(date) eof (yeti@darkstar:6)~/wrk/tmp$ ./xyzzy  version 1 - today is sa 21
you are trying to map linux ps options and field name to freebsd ps options and keywords : this is one of the main obvious differences between a linux-like system and a bsd-style one.  first the -e option on freebsd ps means "display the environment as well". what you want is in fact displaying all processes, that is -ax for freebsd; -x is to display also processes without a controlling terminal (kernel processes and daemons) and the default behavior is not to display them.  regarding linux ps about per field selection (from man ps):   euser      euser    effective user name
see the relevant section in the installation manual.  to answer your questions in more detail:   you'll find the files on http://cdimage.debian.org/cdimage/unofficial/non-free/firmware/; if you're installing debian 8, look in http://cdimage.debian.org/cdimage/unofficial/non-free/firmware/jessie/current/ and download whichever archive is the easiest for you to handle (presumably firmware.tar.gz or firmware.zip). extract the firmware archive in the root of a flash drive; plug the drive into the computer you're installing, and the installer should find the firmware automatically. the typical fat32 filesystem is just fine
(note: this answer was written before the question was updated with the join command and the error messages)  the command is called join.  from the man page:     join - join lines of two files on a common field   since your input files are not sorted you need to sort them first  join &lt;(sort file1) &lt;(sort file2)   the &lt;(...) things are called process substitution and is supported by bash and some other shells
this really depends on what you mean by "unix"
from zac thompson's link to gnu gettext utilities section 2.3 setting the locale through environment variables the sub-section the language variable:     in the language environment variable, but not in the other environment variables, ‘ll_cc’ combinations can be abbreviated as ‘ll’ to denote the language's main dialect
the forward slash / is the delimiting character which separates directories in paths in unix-like operating systems
the following modification to @stephane's solution appears to provide what @berniereiter was looking for:  $ perl -pi.back -le 's/"(?:[^"]|"(?=[^,]))*"|[^",]*/($r=$&amp;)=~   s@(^"|"$|\\.)|"@$1||"'\''"@ge;$r/ge' test.csv   the key thing to notice in the original perl solution is this sub component:  s@(^"|"$|\\.)|"@$1||"\\\""@ge   specifically this piece of code:  "\\\""   that's a double quote block around \\\"
the ssh protocol is not based on http, and, as such, cannot be proxied through the regular proxy_pass of ngx_http_proxy_module  however, recently, starting with nginx 1.9.0 (released as stable with 1.10.0 on 2016-04-26), nginx did gain support for doing tcp stream proxying, which means that if you have a recent-enough version of nginx, you can, in fact, proxy ssh connections with it (however, note that you wouldn't be able to add anything like the x-real-ip to the proxied connection, as this is not based on http).  for more information and examples, take a look at:   http://nginx.org/en/docs/stream/ngx_stream_proxy_module.html http://stackoverflow.com/questions/34741571/nginx-tcp-forwarding-based-on-hostname/34958192#34958192  
everything has probably actually worked as you expected, but you have been misled by two different phenomena:   ls and some other utilities display ? for non-printable characters by default ? is a glob that matches a single character   that results in the following behaviour:  $ echo foo &gt; $'\007' $ ls ? $ cat ? foo   so it seems like we have a file that is literally named ?, right? actually, that's just a happy coincidence of the two above phenomena -- the file is still called ^g:  $ printf '&lt;%q&gt;\n' * &lt;$'\a'&gt; $ ls -lb total 0 -rw-r--r-- 1 chris chris 0 aug  1 14:20 \a   probably everything worked as you expected, despite what immediately appeared to indicate that the file was literally called ?. 
use command  export libdir=/usr/lib/x86_64-linux-gnu:$libdir   and try again. if it works, put this line in your ~/.bashrc 
if you are on a red hat based system, as you mentioned, you can do the following:   create a script and place in /etc/init.d (e.g /etc/init.d/myscript)
 in your case, you can simply disable zero padding by append - after % in the format string of date: %-h     by default, date pads numeric fields with zeroes
i don't think this is possible at the level of macros, it's going to depend on the commands inside the macro
ok i guessing this is a udev issue (most linux distros use this by default), this is what creates the symlinks
no, but: rxvt-unicode has tab support.  add this to your .xdefaults/.xresources:  urxvt.perl-ext-common: default,tabbed   i also like to disable the 'selection' perl extension so that it is possible to triple-click-and-drag to select multiple complete lines (as in xterm)
you can use the literal newline in ps1:  ps1="$_timedhms &gt; [username]machine:${pwd#$home/} $ "   or using $'\n' with ksh93:  ps1="$_timedhms$'\n' [username]machine:${pwd#$home/} $ "  
you could use fedora lxde spin, where fedora is the base of red hat, and centos is just a rebranding/copy of red hat.  the only difference: fedora has very recent software which sometimes is like beta
one of many ways to change settings in a desktop environment is to use tools that are provided with that environment
shell scripts are very similar to the commands you'd type interactively in the shell
they both use the same back end dependency solver and pull from the same repositories, but due to different projects moving a different speeds, they don't pull from a unified local cache (including the metadata cache — the information about what updates are available and so on)
when typing in a shell over an ssh connection, every character you press needs to be sent to the remote side, interpreted, and sent back to be displayed if appropriate
if you are asking "what is the way to connect to an smtp server using ssh instead of telnet?" the answer is there is none.  ssh only communicates over ports using the ssh protocol
if the file is named baboon.txt: sed '/baboon/ s/$/ baboon/' baboon.txt  to write the changes to file use the -i option.  sed -i '/baboon/ s/$/ baboon/' baboon.txt 
it's not so easy if you want to take into account wlan and other alternative interfaces
considering /home is generally used for end users' home directories, it is not a good practice to mount general use filesystems in /home, as it may lead to a confusion later on with other sysadmins, whom, one day, will take over this system from you upon your departure for greener pastures.  i am not familiar with seafile-server, but assuming it is a 3rd party application and its related directory tree, then it is fine to mount it under /opt.  having said all of this, mounting a directory on either /home or /opt, technically has no difference
if both terminals belong to the same user, you can send your output to the virtual device that is used as the particular terminal's tty.  so you can use the output from w, which includes the tty information, and write directly to that device.  ls &gt; /dev/pts/7   (if the device mentioned by w was pts/7)  another option is to use the number of a process that is connected to that device
with gnu xargs:  ack -l --print0 foo | xargs -r0 rm --   ack's --print0 and xargs' -0 cause ack and xargs to write and read using nul as the delimiter, which guarantees proper filename handling
the -ssq flag queries the sync database
you can use the command type to see if the executable is present on your box:  if [ -n "$(type -p tmux)" ]; then      ...tmux is installed...  else      ...tmux isn't installed...  fi   i've often used this code snippet to do it:  $ [ -n $(type -p tmux) ] &amp;&amp; echo "installed" || echo "not installed" installed   i can fake it out using the alternative to -n (not empty string), -z (empty string).  $ [ -z $(type -p tmux) ] &amp;&amp; echo "installed" || echo "not installed" not installed  
traditional mailx does not support imap or pop, but the one that comes with linux does.  for your particular problem, i recommend using fetchmail instead
ctrlw is the standard "kill word" (aka werase). ctrlu kills the whole line (kill).  you can change them with stty.  -bash-4.2$ stty -a speed 38400 baud; 24 rows; 80 columns; lflags: icanon isig iexten echo echoe -echok echoke -echonl echoctl         -echoprt -altwerase -noflsh -tostop -flusho pendin -nokerninfo         -extproc -xcase iflags: -istrip icrnl -inlcr -igncr -iuclc ixon -ixoff ixany imaxbel         -ignbrk brkint -inpck -ignpar -parmrk oflags: opost onlcr -ocrnl -onocr -onlret -olcuc oxtabs -onoeot cflags: cread cs8 -parenb -parodd hupcl -clocal -cstopb -crtscts -mdmbuf cchars: discard = ^o; dsusp = ^y; eof = ^d; eol = &lt;undef&gt;;         eol2 = &lt;undef&gt;; erase = ^?; intr = ^c; kill = ^u; lnext = ^v;         min = 1; quit = ^\; reprint = ^r; start = ^q; status = &lt;undef&gt;;         stop = ^s; susp = ^z; time = 0; werase = ^w; -bash-4.2$ stty werase ^p -bash-4.2$ stty kill ^a -bash-4.2$   note that one does not have to put the actual control character on the line, stty understands putting ^ and then the character you would hit with control.  after doing this, if i hit ctrlp it will erase a word from the line
you can use pvmove to move those extents to the beginning of the device or another device:  sudo pvmove --alloc anywhere /dev/device:60000-76182   then pvmove chooses where to move the extents to, or you can specify where to move them.  see pvs -v --segments /dev/device to see what extents are currently allocated. 
the installation of grub has 2 parts: the resource files, and the boot loader
you can change the timezone with smitty, the reason it wants a reboot is because services like cron are running with the old settings.  in order to avoid the reboot you would need to,   change the timezone with smitty log off, log on again, and switch to a new root session that session will have the right timezone now you need to stop every single service that cares about the timezone and restart them all again. then you realise you can't stop/start init, and you end up rebooting anyway.   if you don't care that services are running with the wrong timezone, then you don't need to reboot the server.  as a minimum, to avoid rebooting you should kill cron and let init restart it
the shell command and any arguments to that command appear as numbered shell variables: $0 has the string value of the command itself, something like script, ./script, /home/user/bin/script or whatever
the bios reads the first sector (512 bytes) of the disk and branches into it
you can back up your partition table, if it is a msdos label disk with sfdisk  sfdisk -d /dev/sda &gt; sda.partition   replace /dev/sda with your actual disk name when you boot into a livecd.  if it is a gpt table, you can use   parted /dev/sda print &gt; sda.gpt.partion   there are other ways.  depending on whether you are using mbr or uefi, the boot sector/partition is different
once you've graduated from the advanced bash-scripting guide, i'd suggest the much more useful greg's wiki (especially the pitfalls article)
you can use xrandr.  i have tested this breathy on a single monitor.  first look at current resolution and subtract 228 from x
you can do it like this:  mount -t msdosfs -m 644 -m  755 /dev/da0 /media/usb   see man mount_msdosfs for more details. 
if you have bash 2.04 or above with the /dev/tcp pseudo-device enabled, you can download a file from bash itself.  paste the following code directly into a bash shell (you don't need to save the code into a file for executing):  function __wget() {     : ${debug:=0}     local url=$1     local tag="connection: close"     local mark=0      if [ -z "${url}" ]; then         printf "usage: %s \"url\" [e.g.: %s http://www.google.com/]" \                "${funcname[0]}" "${funcname[0]}"         return 1;     fi     read proto server path &lt;&lt;&lt;$(echo ${url//// })     doc=/${path// //}     host=${server//:*}     port=${server//*:}     [[ x"${host}" == x"${port}" ]] &amp;&amp; port=80     [[ $debug -eq 1 ]] &amp;&amp; echo "host=$host"     [[ $debug -eq 1 ]] &amp;&amp; echo "port=$port"     [[ $debug -eq 1 ]] &amp;&amp; echo "doc =$doc"      exec 3&lt;&gt;/dev/tcp/${host}/$port     echo -en "get ${doc} http/1.1\r\nhost: ${host}\r\n${tag}\r\n\r\n" &gt;&amp;3     while read line; do         [[ $mark -eq 1 ]] &amp;&amp; echo $line         if [[ "${line}" =~ "${tag}" ]]; then             mark=1         fi     done &lt;&amp;3     exec 3&gt;&amp;- }   then you can execute it as from the shell as follows:  __wget http://example.iana.org/   source: moreaki's answer upgrading and installing packages through the cygwin command line? 
you can use less +f to start less in its "forward forever" mode
the right thing to do is something like mdadm --add /dev/md0 /dev/sdb1
there are quite a few tools around to generate makefiles
you can try getting info with xset:  xset q | grep caps   result:  00: caps lock:   off    01: num lock:    on     02: scroll lock: off   but if no x you can try kbdinfo:  kbdinfo gkbled   result:  scrolllock:off numlock:on capslock:off   edit: if you want to change states with xset you may check following answer
terminology is complicated because there are several unix-like os kernels and some flavours of non-kernel (user-space) os software.   “unix-like” or “*nix” – anything derived from original unix and vaguely resembling it. “linux”, “gnu/linux”, a “linux distribution” – systems based on the linux kernel. “gnu” – a collection of open-source unix-like software, excluding the kernel, otherwise sufficient to build an os
this is what i have in /etc/grub.d/40_custom
as far as i know, the command key modifier syntax (&lt;d-...&gt;) is only effective in gui-mode instances of vim on mac os x.  the vim instance must be gui-based because most terminal emulators (terminal, iterm, etc.) do not generate control sequences for command key combinations, so a tty-only instance of vim has no way to know that a command key combination was ever pressed (the terminal emulator never sends anything across the tty interface)
you shouldn't even need to test if emacs is already running or not
boot from a livecd, then mount the / harddrive partition
 hold both "[windows] key + [alt]"  "right-click" the bar click "properties".   in the "general tab", simply resize the bar. 
perhaps you could do something like the following script (untested):  #!/bin/sh  for fn in "$@"; do     source-highlight --out-format=esc -o stdout -i $fn 2&gt;/dev/null || /bin/cat $fn done   this does a few things:   iterates through each command line argument tries to run source-highlight, redirecting error output to /dev/null if source-highlight fails, then run regular /bin/cat   you put this script in a file named cdc for example, then alias cat=cdc.  as a function  you can adapt the above script into a bash function call which can then be incorporated into your dot files like so:  cdc() {    for fn in "$@"; do      source-highlight --out-format=esc -o stdout -i $fn 2&gt;/dev/null || /bin/cat $fn;   done  }   edit (michael) for some reason trying to use ccat for the function name didn't work but cdc did! 
all of the commits and the files that they reference would be stored as objects  in the objects directory
no problem
in "terminal" (not a graphic emulator like gterm), shift+pageup and shift+pagedown work. 
here is a simple solution for the problem described:  for gtk-3 apps like gnome-terminal and nautilus just craete (or edit if you have one) the file ~/.config/gtk-3.0/gtk.css with following content:  $ cat ~/.config/gtk-3.0/gtk.css @binding-set nokeyboardnavigation { unbind "f10" }  * { gtk-key-bindings: nokeyboardnavigation }   more on the problem see at http://youdev.co/fedora-17-f10-key-frustrating-behaviour-solved/ 
remove the line default vesamenu.c32 (or comment it out) and replace it with default live-.  from the syslinux docs (emphasis mine):     selects a specific user interface module (typically menu.c32 or vesamenu.c32)
a symbolic link does not circumvent permissions of the original directory/file
if you assign bits of awk code to shell variables that you then combine to create a single program fed to a single invocation of awk then you can access arrays created in one from the other
this fork bomb always reminds me of the something an ai programming teacher said on one of the first lessons i attended "to understand recursion, first you must understand recursion"
this field is often formatted as a gecos field, which typically has 4 comma-separated fields for extra information in addition to the user's name, such as phone number, building number, etc.  in all cases i have seen, if the field has a comma, the name is what is before the comma
sudo sudo -v  you can use the command sudo sudo -v to get all it's options.  example  $ sudo sudo -v sudo version 1.8.6p7   configuration options that it was built with     configure options: --build=x86_64-redhat-linux-gnu --host=x86_64-redhat-linux-gnu --program-prefix= --disable-dependency-tracking --prefix=/usr --exec-prefix=/usr --bindir=/usr/bin --sbindir=/usr/sbin --sysconfdir=/etc --datadir=/usr/share --includedir=/usr/include --libdir=/usr/lib64 --libexecdir=/usr/libexec --localstatedir=/var --sharedstatedir=/var/lib --mandir=/usr/share/man --infodir=/usr/share/info --prefix=/usr --sbindir=/usr/sbin --libdir=/usr/lib64 --docdir=/usr/share/doc/sudo-1.8.6p7 --with-logging=syslog --with-logfac=authpriv --with-pam --with-pam-login --with-editor=/bin/vi --with-env-editor --with-ignore-dot --with-tty-tickets --with-ldap --with-selinux --with-passprompt=[sudo] password for %p:  --with-linux-audit --with-sssd   sudoers policy plugin version 1.8.6p7   sudoers file grammar version 42   config files  sudoers path: /etc/sudoers nsswitch path: /etc/nsswitch.conf ldap.conf path: /etc/ldap.conf ldap.secret path: /etc/ldap.secret   options  authentication methods: 'pam' syslog facility if syslog is being used for logging: authpriv syslog priority to use when user authenticates successfully: notice syslog priority to use when user authenticates unsuccessfully: alert ignore '.' in $path send mail if the user is not in sudoers use a separate timestamp for each user/tty combo lecture user the first time they run sudo require users to authenticate by default root may run sudo allow some information gathering to give useful error messages only allow the user to run sudo if they have a tty visudo will honor the editor environment variable set the logname and user environment variables length at which to wrap log file lines (0 for no wrap): 80 authentication timestamp timeout: 5.0 minutes password prompt timeout: 5.0 minutes number of tries to enter a password: 3 umask to use or 0777 to use user's: 022 path to mail program: /usr/sbin/sendmail flags for mail program: -t address to send mail to: root subject line for mail messages: *** security information for %h *** incorrect password message: sorry, try again. path to authentication timestamp dir: /var/db/sudo default password prompt: [sudo] password for %p:  default user to run commands as: root value to override user's $path with: /sbin:/bin:/usr/sbin:/usr/bin path to the editor for use by visudo: /bin/vi when to require a password for 'list' pseudocommand: any when to require a password for 'verify' pseudocommand: all file descriptors &gt;= 3 will be closed before executing a command reset the environment to a default set of variables   environment variables  environment variables to check for sanity:     term     linguas     lc_*     language     lang     colorterm environment variables to remove:     tmpprefix     zdotdir     readnullcmd     nullcmd     fpath     java_tool_options     shellopts     globignore     ps4     bash_env     env     termcap     termpath     terminfo_dirs     terminfo     _rld*     ld_*     path_locale     nlspath     hostaliases     res_options     localdomain     cdpath     ifs environment variables to preserve:     xauthority     _xkb_charset     linguas     language     lc_all     lc_time     lc_telephone     lc_paper     lc_numeric     lc_name     lc_monetary     lc_messages     lc_measurement     lc_identification     lc_collate     lc_ctype     lc_address     lang     username     qtdir     ps2     ps1     mail     ls_colors     kdedir     inputrc     histsize     hostname     display     colors   misc  locale to use while parsing sudoers: c compress i/o logs using zlib directory in which to store input/output logs: /var/log/sudo-io file in which to store the input/output log: %{seq} add an entry to the utmp/utmpx file when allocating a pty  local ip address and netmask pairs:     192.168.1.20/255.255.255.0     192.168.122.1/255.255.255.0     fe80::226:c7ff:fe85:a720/ffff:ffff:ffff:ffff::  sudoers i/o plugin version 1.8.6p7   sudo -l  another method for finding out sudo's configuration is to use sudo -l.  example  $ sudo -l matching defaults entries for saml on this host:     requiretty, env_reset, env_keep="colors display hostname histsize inputrc kdedir ls_colors", env_keep+="mail ps1 ps2 qtdir username lang     lc_address lc_ctype", env_keep+="lc_collate lc_identification lc_measurement lc_messages", env_keep+="lc_monetary lc_name lc_numeric lc_paper     lc_telephone", env_keep+="lc_time lc_all language linguas _xkb_charset xauthority", secure_path=/sbin\:/bin\:/usr/sbin\:/usr/bin  user saml may run the following commands on this host:     (all) all  
the syntax you tried is actually ambigous
assuming you're looking for the amd64 kernel, the package is linux-image-4.4.0-1-amd64. 
 make sure you've got bash installed. learn the location of bash:  which bash   or  whereis bash   below, i'll assume the location is /bin/bash.  a) if you have administrative rights, just run as root:  usermod -s /bin/bash your_username   (replacing your_username with your user name).  b) if you don't have adm
it's mint's alternative to usb creator
it is easier to use grep:  grep -po 'data-addon="\k[^"]*' file   or to store output in the variable:  var=$(grep -po 'data-addon="\k[^"]*' file)  
the typical solution with awk:  awk '   nr==fnr { k[$1] = $2; next }   { print $1, (k[$1] == $2) ? "updated" : "out-of-date" } ' local.txt server.txt  
$# is number of arguments you passed to bash script, not counting $0, which is program name.  example:  #!/bin/bash  echo "number of arguments is: $#"   then run:  % cuonglm at ~ % ./test.sh a b c d number of arguments is: 4  
in basic regular expression you have to escape the + quantifier:  sed 's/;\+$//' file   or use extended regular expression (if your sed supports them; gnu sed does):  sed -r 's/;+$//' file  
well, according to some of your edits you've got ctrl+j bound to a bindkey macro command
from the ps man page:     -e              select all processes
the general way to change or add to the autoexec, is in the .dosbox/dosbox-x.xx.conf. at the end of the file is the section ...   [autoexec]   place your commands after that decleration, they will execute when dosbox starts.  if you need to create something like a "shortcut", which is not specific to your users's dosbox config
as root you can change any users password by using the "passwd" command followed by the username;  passwd username  this will then prompt you to enter the new password twice.  to clarify there is no way to see an existing users password. 
to symlink all css-files in a given directory into another simply do:  $ cd /path/to/symlinkdir $ ln -s /path/to/orgdir/*.css .   if a file is already symlinked (or otherwise existing), you will get a warning like ln: failed to create symbolic link '/path/to/orgdir/style_1374065326.css': file exists which you can safely ignore.  if you want this to be fully automated, you might want to check inotify to monitor the source directory and run the symlink command whenever a .css is created therein. 
you can set the ip in /etc/network/interfaces
you should look at bchunk, which is specifically meant for this type of conversion
figured it out
first hurdle: the syntax of an argument to _arguments is n:message:action where message is not allowed to be empty
as michas has explained, those are terminal escape sequences
a process's resident set size is the amount of memory that belongs to it and is currently present (resident) in ram (real ram, not swapped or otherwise not-resident).  for instance, if a process allocates a chunk of memory (say 100mb) and uses it actively (reads/writes to it), its resident set size will be about 100mb (plus overhead, the code segment, etc.). if after the process then stops using (but doesn't release) that memory for a while, the os could opt to swap chunks of that memory to swap, to make room for other processes (or cache)
in kde 4.11 (but should work for previous versions too) go to:   settings ->   configure ->   appearance ->  layout ->   check "show message preview panel next to the message list" 
the hard part is editing your linux filesystem from windows
append any command that plays a sound; this could be as simple as  $ time mycommand; printf '\7'   or as complex as  $ time mycommand &amp;&amp; paplay itworked.ogg || paplay bombed.ogg   (commands assume pulseaudio is installed; substitute your sound player, which will depend on your desktop environment.) 
you could first escape the &amp; when found in an entity, and then substitute the remaining ones
there is not a dedicated gnome latex editor, for what i know, apart from gedit + gedit-latex-plugin.  a gtk alternative could be geany + geany-plugin-latex. 
it seems the current work around for this is to upgrade to libgtk-3.0 from debian unstable
to change the version of python that is executed when you type python on the command line, and only then, define an alias in your shell initialization file (the one for interactive shells)
save output to local file, then rsync --partial --append on that file to keep pushing it up to the server? 
as mentioned in why does a software package run just fine even when it is being upgraded?, the lock is placed on inode not on filename
at several points in rc.sysinit, rcs-emergency will be run when there's a problem requiring administrator intervention, such as:  echo $"*** an error occurred during the file system check." echo $"*** dropping you to a shell; the system will reboot" echo $"*** when you leave the shell." str=$"(repair filesystem)" ps1="$str \# # "; export ps1 [ "$selinux_state" = "1" ] &amp;&amp; disable_selinux start rcs-emergency   here is the rcs-emergency script:  
i don't believe that's how sockets work
these are:   copy: cp file_name &lt;directory|file_name&gt; move: mv file_name &lt;directory|file_name&gt; delete: rm file_name   visit their man pages for more information. 
nothing
the following command will give you the character count of every regular file (remove the -type f for all types of files including directories) underneath the directory you execute it in, and sort them so the longest ones are output last:  find 
reset all uids and gids:  for i in $(rpm -qa); do rpm --setugids $i; done   reset all permissions:  for i in $(rpm -qa); do rpm --setperms $i; done   try to restart:   service sshd restart   does that help? 
a couple of ways:   if you can get smart data from an sd cart with smartctl, it may have a bytes written counter (no idea if this is possible)
most probably this is ext2, ext3 or ext4 file system which reserve a few percent of disk space (by default 5%) to be used only by specified users (usually root).  if you create file system with mke2fs then -m option is what you are looking for:      -m reserved-blocks-percentage           specify the percentage of the filesystem blocks reserved for the  super-user.           this avoids fragmentation, and allows root-owned daemons, such as syslogd(8),           to continue to function correctly after  non-privileged  processes  are  pre‐           vented from writing to the filesystem
thanks to @msw, i figured out the package names for ubuntu
you can create a recursive script
you can't directly install packages from one distribution onto another distribution.  usually driver issues don't depend on the distribution, they depend on the kernel and driver versions
i'm not really sure what your question is, but i have two remarks which are too long for a comment:   your current script will stop once you log to host (at line 4) and will wait for you to do something interactively - only when you exit will the script proceed (which probably isn't what you want).  hence put anything that is to be executed on the remote server into a standalone shell script, scp it there with the rest of the data and run it with ssh username@host /path/to/my/script.  thus:   #!/bin/bash # your local script scp ./inputs* ./do_stuff.sh username@host:/home/tmp ssh username@host /home/tmp/do_stuff.sh scp username@host:/home/tmp/outputs* .  #!/bin/bash # script for remote execution do_stuff.sh cd /home/tmp module purge module load gcc/4.6.0 icc/11.1.075  ifort/11.1.075 compilers-extra mpi-openmpi/1.4.3-icc-11.1 vasp mpirun -np 20 vasp &gt; out.vasp 2&gt;&amp;1   replace inputs*/outputs* with whatever you need to copy to/from the cluster - you probably don't want to copy back the inputs
looks like, i managed to get data from your image. i did the following:   open with gimp colors -> threshold position the slider around center (i don't remember exact value i chose) and click ok image -> canvas size choose percents canvas size: width: 160 % canvas size: height: 120 % offset: click on "center" click resize tools -> transform tools -> rotate tool angle: -0.50 and click rotate (it's useful to add a vertical guide before doing so) file -> export as choose file name and click export and then export (with all defaults)   here is the image i got after all of these steps:   running dmtxread gives an instant result (less than a second): dmtxread --shrink=2 c8wcn1b.jpg &gt; quant.paperkey size is 1428 bytes, two first octets looks like binary paperkey format. to verify the resulting file, you can download it here. 
just use /sys.  example
the basename tool can strip the path before the filename.  find /home/user/logfileserror/ -maxdepth 1 -type f -name "gandalf_*"\ -daystart -mtime -1 -exec grep -rl "error" "{}" + | xargs -n 1 basename   will give you the desired output.  -n 1 tells xargs to use exactly one argument for basename
you do not need any external tools, just read man fluxbox-apps, edit .fluxbox/apps and put there something like  [app] (name=xyz)    [workspace] (n) [end]  
you could use eix tool (from app-portage/eix):  eix --in-overlay overlay_name   from man eix:     --in-overlay overlay                only match packages with at least one version in an overlay matching overlay.      --only-in-overlay overlay                 only match packages which have only versions in an overlay matching overlay.   if you're not familiar with eix: before use you must must build packages database using eix-update
from help command:  $ help command command: command [-pvv] command [arg ...]     execute a simple command or display information about commands.      runs command with args suppressing  shell function lookup, or display     information about the specified commands
to avoid race conditions, still assuming gnu date:  eval "$(date +'today=%f now=%s')" midnight=$(date -d "$today 0" +%s) echo "$((now - midnight))"   with zsh, you can do it internally:  zmodload zsh/datetime now=$epochseconds strftime -s today %f $now strftime -rs midnight %f $today echo $((now - midnight))   portably, in timezones where there's no daylight saving switch, you could do:  ifs=: set -- $(date +%t) echo "$(($1 * 3600 + $2 * 60 + $3))"  
you need to get the list of url's then parse out the links to feed to the download
the problem is that  the graphics driver xserver-xorg-video-vmware was compiled without 3d acceleration support
in one sense, using env could be considered "portable" in that the path to bash is not relevant (/bin/bash, /usr/bin/bash, /usr/local/bin/bash, ~/bin/bash, or whatever path) because it is specified in the environment
assuming the httpd is apache:  rewriteengine on rewritecond %{http_host} ^demo\.* [nc] rewriterule .* http://domain.com/ [l]  
it can be done by comparing device numbers.  in a shell script on linux it can be done with stat:  stat -c "%d" /path  # returns the decimal device number    in python:  os.lstat('/path...').st_dev   or  os.stat('/path...').st_dev  
alias clear='source ~/.bashrc; \clear'  the \ tells bash that you want to invoke the external command, not the alias. 
the syntax for scp is:  if you are on the computer from which you want to send file to a remote computer:  scp /file/to/send username@remote:/where/to/put   here the remote can be a fqdn or an ip address.  on the other hand if you are on the computer wanting to receive file from a remote computer:  scp username@remote:/file/to/send /where/to/put   scp can also send files between two remote hosts:  scp username@remote_1:/file/to/send username@remote_2:/where/to/put   so the basic syntax is:  scp username@source:/location/to/file username@destination:/where/to/put   you can read man scp to get more ideas on this. 
i put this as an answer, because cannot format it in the comment properly  foo() {    echo foo    echo bar }  &gt; foo foo bar   imho, you have more freedom with a function than with alias
as i mentioned in the comments, here is a thread that talks bare metal programming.     general answer to the question: it can be done
i think i have an answer: when nc tries an ip address that has a server listening on port 22 (which is typically ssh server), it reads the rest of the input and passes it to the server on port 22
maybe ssh-keygen -lf authorized_keys is enough
typical awk job:  awk '$1 == "start" {d[++n] = $2; next}      $1 == "end" {n--; next}      {        printf "%s ", $1        for(i=1;i&lt;=n;i++) printf "%s/",d[i]        print $2      }'   (on solaris, you might need /usr/xpg4/bin/awk or nawk).  though it could also be done with sed:  sed '/^start /{s///;x;g;s/\n//;s:$:|:;h;d;}      /^end/{g;s:[^|]*|$::;h;d;}      g;s/ \(.*\)\n\(.*\)/ \2\1/;y:|:/:'   (here assuming the paths don't contain | characters). 
from man xrandr (this is not listed in the -h options, but it works for me):     --brightness brightness      multiply the gamma values on the crtc currently attached to the output   to specified floating value
as daniel arndt said, you can also use htop instead of top
you could pipe your command into a shell so it gets executed:  echo "mv ..." | bash   or you could pass it as an argument to a shell:  bash -c "$(echo "mv ...")"   or you could use the bash built-in eval:  eval "$(echo "mv ...")"   note, however, that all of those code-generating commands look a bit brittle to me (there are ways they will fail as soon as some of the paths contain spaces, etc.). 
this occurs becaues you have another screen already active, in this case dp2
in any bourne-like shell, it's:  for arg do printf 'something with "%s"\n' "$arg" done   that is, for does loop on the positional parameters ($1, $2...) by default (if you don't give a in ... part).  note that that's more portable than:  for arg; do   printf 'something with "%s"\n' "$arg" done   which is not posix nor bourne (though works in most other bourne-like shells including bash even in posix mode)  or than:  for arg in "$@"; do   printf 'something with "%s"\n' "$arg" done   which doesn't work properly in the bourne shell when $ifs doesn't contain the space character, or with some versions of the bourne shell when there's no argument, or with some shells (including some versions of bash) when there's no argument and the -u option is enabled.  or than  for arg do   printf 'something with "%s"\n' "$arg" done   which is posix and bourne but doesn't work in very old ash-based shells
i eventually found an answer.  the ca_default section of the ca's openssl.cnf file should contain  copy_entensions = copy  then extensions in the request are copied to the certificate.  it doesn't appear possible to limit this to only subjectaltname entries. 
don't export prompt_command to the environment
you have to download your files to a temp file, because (quoting the unzip man page):     archives  read  from  standard input   are not yet supported, except with   funzip  (and  then only  the  first    member  of  the  archive  can  be   extracted).   just bring the commands together:  wget http://www.vim.org/scripts/download_script.php?src_id=11834 -o temp.zip; unzip temp.zip; rm temp.zip  but in order to make it more flexible you should probably put it into a script so you save some typing and in order to make sure you don't accidentally overwrite something you could use the mktemp command to create a safe filename for your temp file:  #!/bin/bash tmpfile=`mktemp` pwd=`pwd` wget "$1" -o $tmpfile unzip -d $pwd $tmpfile rm $tmpfile  
the exact rules followed by the gcc compiler for finding include files are explained at: http://gcc.gnu.org/onlinedocs/cpp/search-path.html  a quick command-line trick to find out where an include file comes from is the following:1  echo '#include &lt;unistd.h&gt;' | gcc -e -x c - &gt; unistd.preprocessed   then, if you look at the unistd.preprocessed file, you will notice lines like:  # 1 "/usr/include/unistd.h" &lt;some numbers&gt;   these tell you that the following block of lines (until the next # number ... line) come from file /usr/include/unistd.h.  so, if you want to know the full list of files included, you can grep for the # number lines:  echo '#include &lt;unistd.h&gt;' | gcc -e -x c - | egrep '# [0-9]+ ' | awk '{print $3;}' | sort -u*emphasized text*   on my ubuntu 10.04 / gcc 4.4.3 system, this produces:  $ echo '#include &lt;unistd.h&gt;' | gcc -e -x c - | egrep '# [0-9]+ ' | awk '{print $3;}' | sort -u "&lt;built-in&gt;" "&lt;command-line&gt;" "&lt;stdin&gt;" "/usr/include/bits/confname.h" "/usr/include/bits/posix_opt.h" "/usr/include/bits/predefs.h" "/usr/include/bits/types.h" "/usr/include/bits/typesizes.h" "/usr/include/bits/wordsize.h" "/usr/include/features.h" "/usr/include/getopt.h" "/usr/include/gnu/stubs-64.h" "/usr/include/gnu/stubs.h" "/usr/include/sys/cdefs.h" "/usr/include/unistd.h" "/usr/lib/gcc/x86_64-linux-gnu/4.4.3/include/stddef.h"     1 note: the search path for include files is modified by the -i command-line option; so, you should add any -i path arguments to the gcc invocation
the ! character triggers history expansion, as you discovered
conky has excellent documentation:  maximum_width   maximum width of window minimum_size    minimum size of window 
from the bash script, you start a subprocess (running a python program), and create a pipe from it to the bash script.  after the bash script exit, there is no longer any process that has the pipe open for reading
what about dd? you can use it to do a 1:1 copy of your sd card to a new one:  dd if=/dev/&lt;your_old_sd_card&gt; of=/dev/&lt;your_new_sd_card&gt;   or to copy it to a file:  dd if=/dev/&lt;your_sd_card&gt; of=/a_file.img  
see:  $ xscreensaver-command -time xscreensaver 5.15: screen locked since wed sep 26 16:26:15 2012  
this works for me
there isn't anywhere special the source code needs to be
you need to use indirect parameter expansion with !:  tmp=h_$i echo "${!tmp}   you have to make the extra tmp variable here - you can't just use a string, unfortunately
first of you need to realize that if you get message like this the application you trying to run is not meant to this platform/distribution
as of coreutils 8.6 (2010-10-15), gnu sort already sorts in parallel to make use of several processors where available
#!/usr/bin/awk -f  begin { fs = "\t"; ofs = "," } {     for(i = 1; i &lt;= nf; i++) {         if ($i + 0 == $i) { $i = "=" $i }         else gsub(/"/, "\"\"", $i);         $i = "\"" $i "\""     }     print }   assuming you name this convert.awk, you can either call with either   ec2-describe-snapshots -h --hide-tags | awk -f convert.awk &gt; snapshots.csv   or (after adding execute permissions, chmod a+x convert.awk)  ec2-describe-snapshots -h --hide-tags | ./convert.awk &gt; snapshots.csv   this will make a new column for each  tab, which will keep the comment column together (unless it contains tabs), but add empty columns (though that is how your sample output looks, so maybe you actually do want that). if you want to split on all whitespace (this will collapse extra tabs within the table but put each word in the description as a new column), take out the fs="\t"; statement.  for future generations, if you don't need the "s or =s or embedded whitespace, you can make it a one-liner:  awk -v ofs=, '{$1=$1;print}'  
this is from my emergency response notes
i happen to be using nemo, and took a quick glance at nemo's settings and nemo's settings in dconf editor.  there doesn't appear to be anything about changing the type of scrolling for compact view, so perhaps it was designed that way without an option to change it.  i would say if you've already spent at least 30 minutes searching, it would probably be better to just keep to list view and save yourself the headache of searching any longer
add the -nc option to your debuild command line
assuming you're running linux:  you can use the audit subsystem to monitor access to a particular file.  you can use the inotify subsystem to watch for activities on files
i think the solution is to write udev rules like this.  kernel=="sd*", env{id_fs_uuid}=="your-sdb1-uuid", env{id_fs_label}="partition_1", env{id_fs_label_enc}="partition_1" kernel=="sd*", env{id_fs_uuid}=="your-sdb2-uuid", env{id_fs_label}="partition_2", env{id_fs_label_enc}="partition_2"  
you probably want:  for i in n5 n25  do    if [ ${#i} -eq 2 ]; then         python two.py n5    elif [ ${#i} -eq 3 ]; then        python three.py n25    fi done   note that:   for goes with do ..
that's a job for a function
in bash  while read -r word do     grep -q "$word" file.before     if [ $? -ne "0" ]     then         echo "$word not in file"      fi done &lt; &lt;(cut -f1 -d" " file.after)   the -q to grep tells it to be quiet, you can then interrogate $? to see if there was a match 0 or not 1. 
first of all, what makes you think skype is not supported? while there are many good reasons not to use it, you can install it on linux and the desktop environment you use is irrelevant
at least openssh sets different tos bits (0x16 for interactive sessions, 0x08 for bulk transfers), as discussed on quora.  this can be easily exploited using rules that match those bits
shell scripts aren't quite the same as typing at a terminal. what's going to happen here is that iptables-save is going to wait for sudo su to complete, and then run
the easy answer is because ksh is written that way (and bash is compatible)
the answer from sf is accurate as far as it goes, though if all the lines you wish to comment are in one block there is a way "around" this problem
i think you might be able to accomplish what you want using network block devices (nbd)
you must check the routing table
here is a pure ksh (ksh93) way:  function cap {     typeset -u f     f=${1:0:1}     printf "%s%s\n" "$f" "${1:1}" }  $ cap korn korn  
in version 6.25, nmap switched the language of the nmap scripting engine (nse) from lua 5.1 to lua 5.2
from the manual:     -o ctl_cmd    control an active connection multiplexing master process
nohup is ineffective against watch because watch installs a signal handler for sighup which overrides the one installed by nohup.  nohup works by setting the signal handler for sighup to sig_ign which causes the signal to be ignored, and then it runs the program it was asked to run
if you convert your psudo code to sh, here is a test for your if  netstat -anp|grep est|sed 's/^..p6\? \+[^ ]\+ \+[^ ]\+ \+[^ ]\+ \+\([^ ]\+\) \+.*$/\1/'|grep -q 8.8.8.8 &amp;&amp; echo connected   so you need a while loop and a sleep 10m and a pmset 0 but as my osx box is in storage it would be a good idea to check my re. 
~user is just a shorthand notation for the home directory of user user
sendmail: sending email with custom headers  you can generate any header when you send using sendmail. [ sendmail fills missing important headers ]  file=/home/myon/executionresults.txt hostname=`hostname` cat - $file &lt;&lt;emailcontent | /usr/sbin/sendmail -i -- myon@hakugyokuro.gk subject: results for $hostname to: myon@hakugyokuro.gk  results of execution of command $command on $hostanme: ------------------------------------------------------ emailcontent   p.s. in such "no strict checks" script with generated dynamic headers do not use -t command line option 
the feature request michael mrozek mentioned has been closed with the feature being available in the next release (1.7)
use the bash [[ conditional construct and prefer the $(&lt;command&gt;) command substitution convention
on linux, the ps command works by reading files in the proc filesystem
the magic(5) manual page says only (referring to this as a datatype):    beid3   a 32-bit id3 length in big-endian byte order.    leid3   a 32-bit id3 length in little-endian byte order.   and libmagic's associating the id3 tags with mp3 has been noticed, e.g., discussion: libmagic for mp3 can go horribly wrong, since the feature was added in 2008:  2008-11-06 18:18  christos zoulas &lt;christos@zoulas.com&gt;      * handle id3 format files.   the id3 format stores the tag length as a special 32-bit integer (which is the length you are asking about):  the id3v2 tag size is stored as a 32 bit synchsafe integer (section    6.2), making a total of 28 effective bits (representing up to 256mb).  further reading:   why are there synchsafe integer?  
if you want to use your way, try maybe:  ls -altr | grep "23 dec" | awk '{print $9}' | xargs -i grep -l "some_string" {}   or with find i would do:  find 
the shutdown binary will only work for the root user
you can use the directive stopwhenunneeded=yes in the dependency target unit file (i
vlc media player has been using qt interface for quite long time
with gnu awk you can define how arrays should be sorted with procinfo special array
use some thing like:  httpurl[0]="http://www.nnin.com" query[0]="curl -s -x post -d 'uid=user1&amp;pwd=1111'" name[0]="firstcust" ip[0]="105.105.0.1"  httpurl[1]="http://www.mmim.com" query[1]="curl -s -x post -d 'uid=user2&amp;pwd=2222'" name[1]="secondcust" ip[1]="106.106.0.1"  httpurl[1]="http://www.ooio.com" query[1]="curl -s -x post -d 'uid=user3&amp;pwd=3333'" name[1]="thirdcust" ip[1]="107.107.0.1"  for i in 0 1 2   do      ${query[$i]) ${httpurl[$i]}      status=$?      if [ $? -eq 0 ]; then         echo "${name[$i]} : ${ip[$i]} (success)"         #exit $status     else         echo "${name[$i]} : ${ip[$i]} (failed)"         #exit $status     fi   done   reference: bash reference manual - arrays 
 man bash is the canonical bash reference. help help gives you help on the help bash builtin, and how it gives you short help messages about other bash built-ins, such as help for. greg's wiki is the best place to find to-the-point, terse, and sometimes even entertaining reference material for pretty much every aspect of bash. if you want a quick way to look up syntax, you could version control .bash_history
i glanced over the xdg-open source and saw that it uses xdg-mime to figure out the type
there is no general solution for this problem
using sed  by selecting the lines starting with .lruno := 72 and continuing to the next clear, this produces the output you request:  $ sed -n '/.lruno := 72/,/clear/p' file .lruno := 72 .infno := 1 .tid.noel := 101 .tid.info := 64 .tid.setnr := 1225 .typeidm := 1 .sourcetable := 2 writedb clear .lruno := 72 .infno := 205 .tid.noel := 101 .tid.info := 76 .tid.setnr := 1225 .typeidm := 1 .sourcetable := 2 writedb clear   how it works: -n tells sed not to print unless we ask it to
  if you want to check whether $path is a symbolic link whose target is /some/where, you can use the readlink utility
for a nat to work properly both the packets from client to server and the packets from server to client must pass through the nat
pluggable authentication modules are probably the way to go
from the 4bsd manual for csh:     a ^z takes effect immediately and is like an interrupt in that pending output and unread input are discarded when it is typed
there's a good little tutorial at this location: http://atlas.evilpiepirate.org/git/linux-bcache.git/tree/documentation/bcache.txt?h=bcache-dev (liked to from bcache's main website)
reverse the input before and after cut with rev:  &lt;infile rev | cut -d, -f2 | rev   output:  d i n  
as @northben and @andreas-wiese mentioned, i did get an answer from a ticket that i opened with tmux.  here is the response to the question, "why does this happen?":     historic reasons
so, first of all, as is discussed briefly here the common form...  for arg in {brace..expanded..set}; do ...   ..
hacky but could you use tcpdump and push stdout straight into your speakers?  sudo tcpdump -vvvv | padsp tee | aplay   tcpdump - linux for snoop padsp - pulseaudio oss wrapper aplay - command-line sound recorder and player for alsa soundcard driver  
the error codes aren't from make: make is reporting the return status of the command that failed
there are two problems with your example.  the primary one is that you're assuming that regular expressions work the same as glob patterns in that * is a wildcard meaning "any sequence of characters." in regular expressions, * means "any number of the previous atom" instead, so fil* means f followed by i followed by zero or more l characters
i suspect that your sshd is configured to allow access via public key authentication and to disallow access via password.  there are a couple of thiongs that you can do
maybe you want:    set ../mo/*e.log for file2 in ../excited/*-d.log; do   file1=$1; shift   awk 'nr == fnr{a[$1]=$2; b[$1]=$3; next}        /:/ || !nf{print; next}        {print $1, $2*a[$1], $2*b[$1]}' "$file1" "$file2" &gt; "${file1%e.log}f.log" done   or with zsh:  file1s=(../mo/*e.log) file2s=(../excited/*-d.log) for file1 file2 (${file1s:^file2s}) {   awk 'nr == fnr{a[$1]=$2; b[$1]=$3; next}        /:/ || !nf{print; next}        {print $1, $2*a[$1], $2*b[$1]}' "$file1" "$file2" &gt; "${file1%e.log}f.log" }   above, we've got 2 sorted lists of file names and we go through both lists in parallel
you can write a macro and bind it to a key, or key sequence
aptitude search '!~i'   see the search term reference in the aptitude user's manual for details. 
the name of the session is stored in the tmux variable #s, to access it in a terminal, you can do  tmux display-message -p "#s"   if you want to use it in .tmux.conf, it's simply #s
from http://www.manpagez.com/man/1/ksh/:     &lt;&gt;word        open file word for reading and writing as  standard  out-                  put.     &lt;&amp;digit       the standard input is  duplicated  from  file  descriptor                  digit  (see  dup(2))
is there a specific reason for which you used this particular algorithm?   i'd rather construct the binary in shell variables than in a file
of the list, ubuntu 12.04 is likely to be closest to debian wheezy
sudo modprobe snd_aloop   adds a loopback device to alsa, which appears in the pulseaudio volume control
you can prevent hackers from using php code to change modification time (mtime) of files that are writeable by your web server by disabling those php functions (such as touch) using [disable_functions][1] option in php.ini configuration file.  however, tracking modification time is not the right approach because the modification time of files do not change when they are uploaded to your server (i.e
at the moment on rhel7.1--i'm not sure if this has always been there and i missed it--i can execute the following to get a list of all the filecontexts and just pipe the output to grep:  # semanage fcontext -l |grep ifconfig_exec_t /bin/ip                                            regular file       system_u:object_r:ifconfig_exec_t:s0  /sbin/ethtool                                      regular file       system_u:object_r:ifconfig_exec_t:s0  /sbin/ifconfig                                     regular file       system_u:object_r:ifconfig_exec_t:s0  /sbin/ip                                           regular file       system_u:object_r:ifconfig_exec_t:s0  /sbin/ipx_configure                                regular file       system_u:object_r:ifconfig_exec_t:s0  /sbin/ipx_interface                                regular file       system_u:object_r:ifconfig_exec_t:s0  /sbin/ipx_internal_net                             regular file       system_u:object_r:ifconfig_exec_t:s0  /sbin/iw                                           regular file       system_u:object_r:ifconfig_exec_t:s0  /sbin/iwconfig                                     regular file       system_u:object_r:ifconfig_exec_t:s0  /sbin/mii-tool                                     regular file       system_u:object_r:ifconfig_exec_t:s0  /sbin/tc                                           regular file       system_u:object_r:ifconfig_exec_t:s0  /usr/bin/ip                                        regular file       system_u:object_r:ifconfig_exec_t:s0  /usr/sbin/ethtool                                  regular file       system_u:object_r:ifconfig_exec_t:s0  /usr/sbin/ifconfig                                 regular file       system_u:object_r:ifconfig_exec_t:s0  /usr/sbin/ip                                       regular file       system_u:object_r:ifconfig_exec_t:s0  /usr/sbin/ipx_configure                            regular file       system_u:object_r:ifconfig_exec_t:s0  /usr/sbin/ipx_interface                            regular file       system_u:object_r:ifconfig_exec_t:s0  /usr/sbin/ipx_internal_net                         regular file       system_u:object_r:ifconfig_exec_t:s0  /usr/sbin/iw                                       regular file       system_u:object_r:ifconfig_exec_t:s0  /usr/sbin/iwconfig                                 regular file       system_u:object_r:ifconfig_exec_t:s0  /usr/sbin/mii-tool                                 regular file       system_u:object_r:ifconfig_exec_t:s0  /usr/sbin/tc                                       regular file       system_u:object_r:ifconfig_exec_t:s0  
i don't know specifically about aix, but on most unices, you cannot do this, by design
!#$&lt;tab&gt; works for me
#!/usr/bin/perl  use list::moreutils qw(pairwise); use list::util qw(sum); use strict;  sub read_file {     my ($filename) = @_;     open f, '&lt;', $filename or die "could not open $filename: $!";     my %data;     while (&lt;f&gt;) {         my ($id, @data) = split;         $data{$id} = \@data;     }     close f;     return %data; }  sub output_file {     my ($filename, %data) = @_;     open f, '&gt;', $filename or die "could not open $filename: $!";     for (sort keys %data) {         print f "$_\t$data{$_}\n";     }     close f; }  my %votes = read_file 'votes.tsv'; my %weights = read_file 'weights.tsv';  my %unweighted; while (my ($id, $data) = each(%votes)) {     my $sum = list::util::sum(@$data);     $unweighted{$id} = $sum &lt; 0 ? -1 :                        $sum &gt; 0 ? +1 : 0; } output_file('unweighted.tsv', %unweighted);  my %weighted; while (my ($id, $data) = each(%weights)) {     my $dot_prod = sum(pairwise { $a * $b } @{$votes{$id}}, @$data);     $weighted{$id} = $dot_prod &lt; 0 ? -1 :                      $dot_prod &gt; 0 ? +1 : 0; } output_file('weighted.tsv', %weighted);  
probably the easiest thing to do here is just to grep for the commented line first:  grep -q '^# deb.*multiverse' /etc/apt/sources.list &amp;&amp;   sed -i '/^# deb.*multiverse/ s/^# //' /etc/apt/sources.list &amp;&amp;   apt-get update  
skype poll fix addresses this specific issue.  prevents skype from frantically polling so often. 
i was able to fix this issue by adding the following two lines to the eclipse.ini (simply put it under one of the other --launcher options):  --launcher.gtk_version 2   this will tell eclipse to use gtk2 which is not affected by the bug
hi if you want check connection between server with socat try below command and refer link ..  cwsocat [options] &lt;address&gt; &lt;address&gt; cwsocat -v cwsocat -h[h[h]] | -?[?[?]] cwfilan cwprocan   try this link for better understanding.. there are other method to check the connectivity.. 
bash or ksh together with mv could solve it:    for f in *.png; do mv -n "$f" "${f/-0}"; done   in case the file name may have “0” after the first dash too and the “-0” is always in front of the dot, you may want to include that dot too in the expression:  for f in *.png; do mv -n "$f" "${f/-0./.}"; done   but as that renaming rule is simple, if you have rename from the util-linux package, that will do it too:  rename '-0.' '.' *.png  
you are using the single quotes for for the -d commandline options both for specifying strings separated by $variable as well as for quoting the argument for the second sed command.  for $aallowusers someuser this might be what you want, but for /permitrootlogin/s/^.*$/permitrootlogin no/ this is probably not what you want /bin/sh to expand
1
you can add the applications you want to automatically start when booting the system by adding them to startup applications in the tweak-tool - open the tweak tool from activities launcher :        alternatively copy a .desktop file from /usr/share/applications/ to ~/.config/autostart/. 
use   echo "${string:index:length}"    for your example   x="asdfqwer" echo "${x:2:3}"  
you can override normal-mode commands (like [n]g) with :nnoremap, but there's no hook for ex commands (like the peculiar :[n])
you need to add that script to your initramfs
ls -d "$pwd"/* &gt; listoffiles.list  
taking nano as an example,   to list package contents, use  pkg_info -l nano-2.2.6  to query owner of a file,  pkg_info -w /usr/local/bin/nano  the last one is easy, just run  pkg_info 
sed will only replace the matching substring of a string.  $ echo '01xx1234' | sed 's/xx/af/' 01af1234   if you intent to always replace the third and forth character but keep the first and second intact you can use:  $ echo '01xx1234' | sed 's/\(.\{2\}\).\{2\}/\1af/' 01af1234    \{2\} means two occurrences of the character standing before (in this case .: any character) \(...\) parentheses are used to create a matching group; you can refer to the matched substring later in the pattern or in the replacement string \1 refers to the first matched substring (in this case i.e
use netstat -anp | grep ':6016' that will give you the pid of the process connected to the port
i think you're misunderstanding the usage of port 80
to untabify the whole buffer upon opening a file that uses web-mode, you could add something like this to your init file:  (add-hook 'web-mode-hook   (lambda () (untabify (point-min) (point-max))))   this assumes that web-mode is the name of the mode you want this setting to apply to; adjust to taste. 
when you give a locale by the name language_country, you actually specify one of the locales defined as language_country.codeset: the default one for this language and country
i don't use it, but a few google searches and it looks like gnome power manager isn't that configurable (i.e., there are reports that it doesn't allow any customization).  that being the case i'd recomend switching to something else (e.g, acpid, hal, devicekit-power, etc.) that is scriptable.  find (or create) the script that runs on the low battery event and use zenity to give yourself a warning, schedule a shutdown.  zenity --warning --title "battery" --text "low battery
i'm using a script for this, at least this does do log playback in private chats:  http://scripts.irssi.org/scripts/queryresume.pl  by changing return unless (ref $witem &amp;&amp; $witem-&gt;{type} eq 'query');  to #return unless (ref $witem &amp;&amp; $witem-&gt;{type} eq 'query'); this can also be used for playback of chatlogs regarding irc-channels as well. 
gentoo linux has a very nice home router guide in it's gentoo linux documentation: http://www.gentoo.org/doc/en/home-router-howto.xml  many of the steps can be adapted to use with ubuntu. 
the question lies in the sata3 controller
to clone a debian installation, use the apt-clone utility
all union filesystems with read-only and read-write branches use some form of "whiteout" marker on a read-write branch to suppress a file that exists on a read-only branch
sed:  sed '2,$s/^\("[^"]*","\)/\1'"'"/ test.in   using eres to get rid of some of the escaping:  sed -e '2,$s/^("[^"]*",")/\1'"'"/ test.in   awk:  awk -f, 'nr&gt;1{sub(/^"/,"\"'"'"'",$2)}1' test.in   if you don't want to worry about the quoting, use the escape code:  awk -f, '{sub(/^"/,"\"\x27",$2)}1' test.in  
keeping your extension pack up-to-date from cli.  i am assuming you always have the latest vbox version installed (oracle provides repositories for ubuntu, debian, opnensuse, sles, fedora and oracle linux).  save the version number of the latest version:  vboxversion=$(wget -qo - http://download.virtualbox.org/virtualbox/latest.txt)   wget -qo - keeps wget quiet and retrieves the content of that file to stdout, where it can be saved into the variable
dave_thompson_085 is correct with his comment
exec here could be a system call or a bash built-in or something else from this 
to run a jar file, pass the -jar option to java
you can use command e.g.:  command -v vim   it is a shell built-in command
gnome-terminal (more properly vte) imitates some version of xterm's escape sequences
i've found that using perl's pod is much easier than writing man pages directly, and you can create a man page from the pod file with the pod2man utility (part of the base perl package)
beware that $0 can be a relative path, so calling cd twice might not work
threads are an integral part of the process and cannot be killed outside it
you can use gnu grep (if built with pcre support) for this:  $ grep -po '(?&lt;=a href=")[^"]*' file a.htm b.htm c.htm   it is a look-behind (what's after a href="?) and gets everything up to next double quote. 
if you switch your term variable to a terminal that does not support ansi colors, you will not see any blue background anymore
(in response to the upvotes on my comment)  there isn't a concrete way of determining if an application reads from stdin or something else
terminator doesn't support this
since they're debian machines, use make deb-pkg (instead of make, make install, etc.), which is part of the upstream kernel sources
try:  find 
functions are perfectly suitable for this purpose
in debian packaging, the control file contains the details about the binary packages that the source package will produce
the dependencies are expressed not as package names, but as pkg-config dependencies
temp="~/dropbox"   the above defines a variable that contains a literal tilde followed by a slash
you can do this with find alone using the -exec action:  find /location -size 1033c -exec cat {} +   {} will be expanded to the files found and + will enable us to read as many arguments as possible per invocation of cat, as cat can take multiple arguments.  if your find does not have the + extension or you want to read the files one by one:  find /location -size 1033c -exec cat {} \;     if you want to use any options of cat, do:  find /location -size 1033c -exec cat -n {} + find /location -size 1033c -exec cat -n {} \;   here i am using the -n option to get the line numbers. 
try this one.  #!/bin/bash  # run it in the folder containing dir a and dir b.  a=a #first dir, replace with the propper name b=b #second dir, replace with the propper name in_file=f #replace with propper name out_file=data.dat  b_subs=( $(ls b | sort -n) )  i=0 cd "$a" for d in $( ls | sort -n) ; do     a="$d"/"$in_file"     b=../"$b"/"${b_subs[$i]}"/"$in_file"     ((i++))     mkdir ../"$i"     # the one below is not correct, but gives your results     # join "$a" "$b" | awk '{print $1, $3-$2}' &gt; ../"$i"/"$out_file"     # the one below is correct     join "$a" "$b" | awk '{print $1, $2-$3}' &gt; ../"$i"/"$out_file" done  
if you install it on your own (see here and, for example, here), no distribution's scripts will mess with it.  on the other hand, i found it convenient to let debian manage my grub.cfg and add other oses (if they're not found by os-prober) to /etc/grub.d/'s custom file. 
the ip network layer doesn't know if a tcpwrapper is blocking the connection
the freebsd handbook is the canonical reference to learn how to install and administer a freebsd system
to prevent grep from interpreting a string specially (a regular expression), use -f (or --fixed-string):  $ cat test one &lt; two hello world x&lt;h a &lt;h a i said: &lt;hello&gt; $ grep -f '&lt;h' test x&lt;h a &lt;h a i said: &lt;hello&gt;   remember to quote the search pattern properly, otherwise it may be interpreted badly by your shell
have you tried using logger with process substitution?  $ forever -a &gt;(logger -t forever) -o &gt;(logger -t app.js) -e &gt;(logger -t app.js) app.js   you can play around with the logger -p switch for specifying log levels, warn, info, err, etc
how about /etc/rc.local?  this will be executed last in the startup sequence. 
it may help to disable the bluetooth coexistance parameter of the iwlwifi module to see if conditions improve
have you tried synaptiks? it's a simple gui program that always solved any problems with my touchpad configuration.  to install:  sudo apt-get install kde-config-touchpad   then you should be able to run it with  synaptiks &amp;&amp; synaptiks   (the first synaptiks only puts the icon in the system tray and doesn't launch the gui for some reason) 
using grep and sed to a) get the integer (!) number following icount (with any number of digits) and b) removing the icount specifier:  grep -o 'icount = "[0-9]\{1,\}' | sed 's/.*"//'  
basically, https://www.rocketleaguereplays.com uses outdated encryption (ssl3), you can force curl to connect to insecure sites like this using the -k (--insecure) switch.  try this: curl -kvh "accept: application/json" https://www.rocketleaguereplays.com/api/replays/-1/  you could also try using the -3 aka --sslv3 switch, however, if curl was built without ssl3 support, then you need to compile your own version of curl, enabling ssl3.  edit: the op has found the problem.  i got confused by the error message.  this is a bug in gentoo:  https://bugs.gentoo.org/show_bug.cgi?id=531540  basically, when you build openssl with the bindist flag, the elyptic curve crypto is disabled
one way you could do this is booting from the dvd of the slackware iso.  then, when at the root prompt, you should mount the root partition of the hard drive, like this (used sdb1 in the example)  mkdir /mnt/sdb1 mount /dev/sdb1 /mnt/sdb1 mount --bind /dev /mnt/sdb1/dev mount --bind /sys /mnt/sdb1/sys mount --bind /proc /mnt/sdb1/proc chroot /mnt/sdb1   now, edit /etc/fstab and change mount points according, knowing that probably your disk was labeled sda before and now it will be named sdb.  if you're using the default boot loader, lilo, edit /etc/lilo.conf and in the boot section change both the line  boot = /dev/sda to boot = /dev/sdb and the root line in  image = /boot/vmlinuz root = /dev/sdb1       &lt;-- change here to sdb1 label = slackware64 vga = 773 initrd = /boot/initrd.gz read-only   now run /sbin/lilo so that it can install lilo again with the new definition.  one last thing you should check is whether you're using initrd or not
you cannot do that using octal notation
in linux, you can use    cat /proc/meminfo to see total swap, and free swap  (all linux) cat /proc/swaps to see which swap devices are being used  (all linux) swapon -s to see swap devices and sizes (where swapon is installed) vmstat for current virtual memory statistics   in mac os x, you can use   vm_stat to see information about virtual memory (swap) ls -lh /private/var/vm/swapfile* to see how many swap files are being used.   in solaris, you can use   swap -l to see swap devices/files, and their sizes swap -s to see total swap size, used &amp; free vmstat to see virtual memory statistics   on some systems, "virtual memory" refers only to disk-backed memory devices, and on other systems, like solaris, virtual memory can refer to any user process address space, including tmpfs filesystems (like /tmp) and shared memory space. 
your examples and description are inconsistent
where to export  after having read https://bitbucket.org/padavan/rt-n56u/wiki/en/usingcron a good way to export configuration variables for both crontab and shell usage, is to insert the /opt related variables into /opt/etc/profile.  where and how to source  to use ("source") the variables in cron it is suggested to:   create a shell-wrapper script source /etc/profile in that wrapper scriptnote: /etc/profile will also source /opt/etc/profile call that wrapper script by prepending the crontab configuration content with the line: shell=/etc/storage/cron/shell-wrapper.sh  
this sounds fragile — you could get into the habit into typing foo instead of git foo, and then one day a new foo command appears and foo no longer invokes git foo — but it can be done
you can use tar as a buffer process  cd .rubies tar cf - ruby-2.1.3 | ( cd /opt &amp;&amp; sudo tar xvfp - )   the first tar runs as you and so can read your home directory; the second tar runs under sudo and so can write to /opt. 
minicom is a terminal program
the question was solved, after reading this blog post. i will write the solution in short form:   boot from a live cd with use gdisk (if you use gpt) otherwise you could go with good old fdisk note your partition settings, in my case gdisk -l /dev/sdb delete your partition with create a new partition with the exact same alignment as the previous one (in my example starting at block 2048) write your new partition table run $ partprobe -s to refresh the partition table without a reboot resize your physical volume with pvresize /dev/sdb1 or whereever your pv is (use pvs to determine if you dont know) now resize yout logical volume with lvextend -l +100%free /dev/file/of/your/lv, in my case sudo lvextend -l +100%free /dev/linuxvg/home resize the filesystem sudo resize2fs /dev/linuxvg/home first check the consistency sudo e2fsck -f /dev/linuxvg/home enjoy :)  
from the ksh faq:     q1
it depends on how you are installing grub
adding to the answers already given, other places to set the variable would be:    a file under /etc/env.d (shell-independent), /etc/bash/bashrc for bash users, /etc/zshenv or /etc/zprofile or /etc/zshrc or /etc/zlogin for zsh (as per man zsh), other shell-specific config files, described in each shell's manpage under files section.  
you are correct in that it is referring to syncing the disks
so, i did this thing in testing and, yeah, it consumes a lot of memory
if a file is symlinked to itself then there's no data present and any attempt to access it will result in a loop, and ultimately an error  eg  $ ls -l myfile  lrwxrwxrwx 1 sweh sweh 19 sep  9 22:38 myfile -&gt; /path/to/here/myfile  $ cat myfile  cat: myfile: too many levels of symbolic links   since there's no data, deleting these symlinks won't lose any data, because there is no data to preserve.  if you don't get the too many levels of symbolic links error when you try to cat the file then your file is not a link to itself. 
search for a plain &amp; (unescaped) and you will match this character
i figured it out myself! i discovered mhddfs and it seems to do exactly what i want.  i'm about to test with a virtualbox, but i believe i will be using snapraid with mhddfs (probably all running on lubuntu) and it solves my problem. 
first, make sure you understand the difference between primary, extended and logical partitions
change your command to this:  nc -zv 192.168.1.1 1-100 2&gt;&amp;1 | grep succeeded   2&gt;&amp;1 causes stderr of a program to be written to the same file descriptor as stdout
while it may appear you have more than enough ram, linux buffers file data in memory
you could start with the release notes:  https://wiki.centos.org/manuals/releasenotes/centos7  which (in 12
the directory containing lspci is likely not in your path.  you can find its location using sudo -i which lspci and add the directory to your path.  the likely locations are /sbin or /usr/sbin  to add them you your current path, you can run (in a bourne-based shell) export path="$path:/usr/sbin:/sbin"  to make the change permanent, add the export command to your .bashrc or .bash_profile (assuming you are using bash as a shell) 
usually, when the shell returns a status code above 128, it means that the process was killed by a signal
the user fyi on the openwrt forum suggested that using wep is a bad idea for bridges and that using wds instead could fix this
sed 's/\\\\/&amp; /g;s/\\n/\ /g;  s/\\\\ /\\\\/g' &lt;in &gt;out   ...should handle the \newline replacements without misinterpreting backslash escapes - so you can still have a literal \\n in input
use parted instead, possibly coupled with your filesystem's resizing command
from man bash     -c        if the -c option is present, then commands are read from the              first  non-option  argument  command_string
there might be more direct ways, but one thing you can do is:  1) prepare an installation in a virtual machine under ubuntu 12.04
the best way to keep track of such unwanted behavior is to collect logs of your machine activity from time to time.  running a script every 15 minutes with cron that will look at open network connexions might be the best way to go.  i would advise you to use the lsof command and collect information about the network connexion made by your machine
i realize this is going to sound both simplistic and absurd, but if you have control over the apps in question (maybe in a test environment) you could  mount only that directory on a partition of its own, then iostat, etc
process arguments are visible to all users, but the environment is only visible to the same user (at least on linux, and i think on every modern unix variant)
top is mostly used interactively (try reading man page or pressing "h"  while top is running) and ps is designed for non-interactive use (scripts, extracting some information with shell pipelines etc.) 
thomas orgis, a mpg123 developer and maintainer, just implemented this functionality in mpg123 (as a script called 'conplay') at my request
many applications support a command line option -geometry or --geometry with a geometry specification as argument
if i correctly understood your question you are looking for  sed 's/\(pattern {[^}]*}\)/\1;/g'   where \1 replaces everything what matched inside \(...\).  the output:  hello {sdsdsdsds} pattern {askjdasjkdjasd}; hello {siadsd} pattern {iuewer};  
ssh has a "batchmode" option which will make it simply fail rather than asking for a password
trying to pass magic options through the various layers of shell scripting is entirely the wrong way to go about this on a systemd linux operating system.  systemd already logs the standard outputs/errors of services that are auto-generated by the "sysv" service generator, as this one is
same size should be fine, however, i believe dd copies sector for sector, so when the source disk is only by one sector larger i think you will run into problems
kiss and use the +nottlid option? man dig.  -----[ 16:44:51 ] (!4302) [ :-) ] janmoesen@janbookpro ~  $ dig -t any bix.hu | egrep -v "^;;|^;|^$" | sort bix.hu
some sites disable support for ssl 3.0 (possible because of many exploits/vulnerabilities), so it's possible to force specific ssl version by either -2/--sslv2 or -3/--sslv3. also -l is worth a try if requested page has moved to a different location.  in my case it was a curl bug (found in openssl), so curl needed to be upgraded to the latest version (>7.40) and it worked fine.  see also:   3 common causes of unknown ssl protocol errors with curl error when installing meteor at so [bug 861137] re: openssl tls errors while connecting to sslv3 sites  
if i correctly understand your question you want to rearrange your data, i.e
i use this script (from this thread on the arch boards):  #!/bin/bash read cpu a b c previdle rest &lt; /proc/stat prevtotal=$((a+b+c+previdle)) sleep 0.5 read cpu a b c idle rest &lt; /proc/stat total=$((a+b+c+idle)) cpu=$((100*( (total-prevtotal) - (idle-previdle) ) / (total-prevtotal) )) 
you need to use matching operator ~, not subtraction operator -:  $ awk '$2 ~ /^2$/' file   or use equality operator == like @glenn jackman's answer.  but let take a look at your previous solution, to explain that why you got all the lines.  awk '$2 - /^2$/ {print}' numbers.txt   here, with each line input, if expression $2 - /^2$/ is true, you will print this line, else do nothing
logs from the audit subsystem are based on paths
i found this answer on au in a q&amp;a titled: how can i set up dual monitor display with ati driver?.  excerpt        open a terminal and type:    $ gksudo gedit /etc/x11/xorg.conf    in the sub-section "display" add this code or modify if already exist:    virtual 2880 1024    where 2880 and 1024 are the value returned by the error: required   virtual size does not fit available size: requested=(2880, 1024),   minimum=(320, 200), maximum=(1600, 1600).   restart the computer.   then you will be able to extend your desktop without issue.      in the op's configuration he opted to use this:  virtual 3360 1050  
the lines you are seeing indicate the system time has been automatically updated
most of the time, a source line will be in the file /etc/apt/sources.list, so you should edit that
as hinted by https://packages.qa.debian.org/m/mod-mono/news/20140104t163913z.html, the problem was https://bugs.debian.org/731374, which is fixed in unstable, in version 3.8-1 as you can see as the end of the bug thread
as manuals (and even wikipedia) point out:     /proc/uptime        shows how long the system has been on since it was last restarted.      the first number is the total number of seconds the system has been up
you can edit the /etc/inittab file and comment out the unneeded ttys. take a look at the inittab manpage here.  if inittab doesn't exist, take a look at the /etc/ttys file
i bet your camera is on usb
do you really need to do both of the things? would not be easier to curl on the remote server and pull the result without port forwarding, such as  ssh user@10.10.10.10 curl http://remoteserver/my/endpoint/ -o - &gt; result  
from openssh readpassphrase.c, line 75:      /*      * read and write to /dev/tty if available
cat script.sql - | mysql -p database  
i got the answer
i believe these are the defaults:   username: lubuntu password: blank (no password)   that's literally nothing, for the password.  linux format magazine  if you're using the compilation cd/dvd that comes with this magazine the username should be "ubuntu" with again a blank password.   ubuntu 14.04 compilation disc   references   what is the default user/password? how to disable autologin in lubuntu?  
it seems that the answer was that i had set up my wife's account with no password, so the login stage and screen were by-passed
see this related stack overflow answer - http://stackoverflow.com/questions/2927672/how-can-i-get-git-status-to-always-use-short-format  it looks like the best option would be making an alias, so you could type git s to get the short listing instead of git status --short and then just use git status for the --verbose listing.  git config --global alias.s 'status --short'  
i don't think cdpn exists for nfs, but you can achieve something roughly equivalent with basic tools
first, the grep: you can tell it not to search through binary files - use the -i switch - as manpage says:   -i     process a binary  file  as  if  it  did  not  contain  matching data;        this  is  equivalent  to  the --binary-files=without-match option.      second, the find: to avoid using xargs and lots of piping, make use of the -exec test of find program
to run your script by double clicking on its icon, you will need to create a .desktop file for it:  [desktop entry] name=my script comment=test hello world script exec=/home/user/yourscript.sh icon=/home/user/youricon.png terminal=false type=application   save the above as a file on your desktop with a .desktop extension
for passing file paths as arguments to a command, find does this on its own with its -exec option without any xargs trickery:  find /home/user -name '*.csv' -exec yourcommand '{}' +   that will find every file called *.csv in /home/user and then execute yourcommand /home/user/a\ b.csv /home/user/my\ dir/c\ d\$2.csv ... with all of the found files as arguments
you can always do:  tac &lt; filename | sed  '/endpattern/,$!d;/startpattern/q' | tac   if your system doesn't have gnu tac, you may be able to use tail -r instead.  you can also do it like:  awk '   inside {     text = text $0 rs     if (/endpattern/) inside=0     next   }   /startpattern/ {     inside = 1     text = $0 rs   }   end {printf "%s", text}' &lt; filename   but that means reading the whole file.  note that it may give different results if there's another startpattern in between a startpattern and the next endpattern or if the last startpattern does not have an ending endpattern or if there are lines matching both startpattern and endpattern.  awk '   /startpattern/ {     inside = 1     text = ""   }   inside {text = text $0 rs}   /endpattern/ {inside = 0}    end {printf "%s", text}' &lt; filename   would make it behave more like the tac+sed+tac approach (except for the unclosed trailing startpattern case).  that last one seems to be the closest to your edited requirements
recursively, using expand (which was made for this purpose): find 
i noticed that the devpath attribute is constant for my usb ports
redirections are set up by the current shell, so sudo has no effect on your ability to write in /etc/udev/rules.d.  the usual trick for this is to use tee:  sudo tee /etc/udev/rules.d/69-libmtp.rules &lt; /tmp/1   as pointed out by infixed though, in this particular case you don't need a redirection:  sudo cp /tmp/1 /etc/udev/rules.d/69-libmtp.rules  
an alternative is to rename the files:  for file in days/* do       day=`cut --delimiter '_' --fields 1 ${file}`       month=`cut --delimiter '_' --fields 2 ${file} | cut --delimiter '.' --fields 1       newfile=${month}_${day}.tex       cp ${file} ${newfile} done   or you could use the touch command so that ls -1t would work. 
you can try starting from the command line with info info
you can trap the exit event
the specific issue with sqlite is a transient problem with a bad update that made it to the repositories
you can say:  history | awk '{$1=""; sub("^ ", "", $0)}1' | sort -u   to get a list of unique entries in the history.  however, you can also set histcontrol to avoid duplicates in the history:  histcontrol=ignoredups:erasedups   quoting from the manual:     histcontrol      a colon-separated list of values controlling how commands are saved on the history list
issue has been fixed in recent releases, you can get latest builds of master branch here.  in case of failures, you can check current list of issues and create your own on their github page. 
thanks to ruslan's comment (upvote!) and some testing i probably found a solution for the next real case:   try alt+f4, or clicking somewhere on the "fail whale" message (to get the focus) and then alt+f4 if 1 doesnt work: go to a tty and type display=:0 gnome-shell --replace and then go back to gnome and try alt+f4 again
here's a perl one-liner to pipe your generate_output into:  perl -e '$/ = "\r"; $| = 1; while(&lt;stdin&gt;){s/ foo//;print;}'   $/ sets the input line delimiter, and $| makes output unbuffered. 
i would write:  perl -mfile::path=make_path -00 -ne '     ($block) = /block number : (\d+)/;      @sizes = /size : (\d+) (\d+)/;      $dir = sprintf "data/%d-size1/%d-size2", @sizes;     make_path $dir;     if (open $fh, "&gt;", "$dir/$block-block.txt") {         print $fh $_;         close $fh;     } ' bigfile.txt   
the usb connection resets indicate that there is something physically wrong with your usb device (or maybe the electrical connection)
password failures have an intentional delay introduced in a attempt to make password cracking a slow process
visually highlight the text in brackets:     ctr+v2jl   increment each number by five:     :norm 5ctr+v ctr+a   explanation:   :norm executes the whole command in normal mode. the ctr+v is necessary, otherwise the cursor would jump back to the beginning of the line
a straightforward way would be to select just the first line, drop non-witespace characters from it, and count how many characters are left:  head -n 1 | tr -cd ' \t' | wc -c  
the ; has to be its own separate argument to find:  find /home/shredtest/ -depth -exec /home/test.sh "{}" \;   (note space between {} and \;)
here's the best option i've been able to find:  complete job 'p/1/`listjobs`/' \              'p/2/`set cmd = ( $command_line ); listtasks $cmd[$#cmd]`/'   it's relying on a variable called $command_line, which is available on my ubuntu system, but i'm not sure if it's standard.     command  invoked from ... version has additional environment variable set, the variable name is command_line and contains (as its name indicates) contents of the current (already typed                  in) command line
you can use the match() function in awk:   $ cat file somedata45 somedata47 somedata67  somedata53 somedata23 somedata12     awk ' begin { rs = ""; ofs = "\n"; ors = "\n\n" } match($2, /[0-9]+/) { value = (substr($2, rstart, rlength) + 5) * 100 } match($3, /[0-9]+/) { $3 = substr($2, 1, rstart - 1) value }1' file somedata45 somedata47 somedata5200  somedata53 somedata23 somedata2800   we set the record separator to nothing effectively enabling the paragraph mode (separated by blank line)
i think you would be better off just removing libnotify and notify-send from the equation, given your stated requirements they do not provide any additional flexibility of functionality.  if you are looking for a minimal status bar, conky has a comprehensive amount of functionality, all of which can be updated in real time (depending upon how resource intensive you are prepared to accept it being).  if you wanted to tailor something specific to your setup, you could also use simple scripting and dzen.  you could also combine the two and pipe conky to dzen for your status bar; which also means that you can display icons in the bar, if that is what you are after.  there is a long conky thread on the arch boards that has a myriad of different configurations and approaches to provide some inspiration.  for simple notifications, you could combine dzen and inotifywait (from the inotify-tools package) to achieve this
method #1  you can use this sed command to do it:  $ sed 's/\([a-za-z]\)\1\+/\1/g' file.txt   example  using your above sample input i created a file, sample.txt.  $ sed 's/\([a-za-z]\)\1\+/\1/g' sample.txt  name        nice - run a program with modified scheduling priority         synopsis               nice     [-n    adjustment]    [-adjustment] [--adjustment=adjustment] [comand [a$   method #2  there is also this method which will remove all the duplicate characters:  $ sed 's/\(.\)\1/\1/g' file.txt    example  $ sed 's/\(.\)\1/\1/g' sample.txt  name     nice - run a program with modified scheduling priority      synopsis        nice   [-n  adjustment]  [-adjustment] [-adjustment=adjustment] [comand [a$   method #3 (just the upper case)  the op asked if you could modify it so that only the upper case characters would be removed, here's how using a modified method #1.  example  $ sed 's/\([a-z]\)\1\+/\1/g' sample.txt  name        nice - run a program with modified scheduling priority         synopsis               nice     [-n    adjustment]    [-adjustment] [--adjustment=adjustment] [command [a$   details of the above methods  all the examples make use of a technique where when a character is first encountered that's in the set of characters a-z or a-z that it's value is saved
when uploading packages, the section and priority are read from the .changes file, in the files: stanzas (see https://www.debian.org/doc/debian-policy/ch-controlfields.html#s-f-files).  to retrieve the section and priority from a .dsc (and the associated files), you can use dscextract from the devscripts package with a little scripting.  dscextract &lt;yourdsc&gt; debian/control   will extract debian/control (or fail if it can't); then you can read the section and priority from source section of the control file (stop at the first empty line). 
readline's vi-mode is a subset of vi (essentially features that affect a single line, with some allowances for usability)
from man page of getfacl:  -p, --absolute-names        do not strip leading slash characters (`/')
expansions that occur within double quotes (") do not undergo field splitting.    in echo $var, since the expansion of $var does not occur within double-quotes, so it does undergo splitting
the issue is the backticks in your do ..
you can accomplish this using the advanced searching features of aptitude
with bash:  shopt -s nullglob files=(/mydir/*.gz) ((${#files[@]} == 0)) || gzip -d -- "${files[@]}"   with zsh:  files=(/mydir/*.gz(n)) (($#files == 0)) || gzip -d -- $files   note that in zsh, without (n), like in pre-bourne shells, csh or tcsh, if the glob doesn't match, the command is not run, you'd only do the above to avoid the resulting error message (of no match found as opposed to gzip failing on the expanded glob in the case of bash or other bourne-like shells)
to answer your specific question, root must own the user home directory for the chroot provided by sshd to work correctly
the gnu project chose its recursive acronym for "gnu's not unix!" because gnu's design is unix-like, but differs from it by being free software (while the original unix was closed-source) and containing no original unix code (i.e
with default mounts options, access times are handled in a special way on linux:     relatime – a filesystem mount with this option causes the access time to be updated if they are (before the update has occurred) earlier than the modification time
rui's comment is nearly enough; this should copy everything, including hidden files:  cd /foo; tar cpf - 
the stderr output of an executable can be redirected to a file with the following syntax:  mycommand 2&gt; error.txt   if you want to redirect stdout (i.e
building a static binary should be as simple as running gcc with -static, or if ld is being called directly use -bstatic
the program on the left side of a pipe does not receive an eof (which is not a signal) when the right side of the pipeline ends
here's what i would do
i was having the opposite problem on a debian 8 image which somebody had put together for a wandboard
use single quotes:  echo -e '#!/usr/bin/python\nimport string as s,random;print "".join(random.sample(s.letters+s.digits+s.punctuation,9))'&gt;pg;chmod +x pg;./pg   the rules for ! were sort of grafted onto the other quoting rules afterwards (from csh)
what you really want is "or", not "and"
here another short solution with sed and ed.  it modify the xml file inplace
on android, like on many linux-based systems, the kernel first mounts an initramfs on /
if by fragmented you mean that the jpeg images (as that is the most commonly encoutered image format) are "pixelated" or have strange artefacts like stripes it means that the files haven't been recovered fully.  now if the card itself is working, try cloning it with dd into a file:  dd if=/dev/mmcblk0p1 of=/path/to/image bs=1m   and work on the resulting image - it will be faster and you won't have to worry about accidentally damaging the only copy of your data
getent passwd | cut -d: -f1 | while read user ; do   echo $user #use this to show some kind of progress otherwise delete this string   find / -user $user &gt; ${user}.txt 2&gt;/dev/null done   ps
from what i can tell, there is no configuration file for uw-imapd
braiam suggested in the comments that if wpa_supplicant@wlan0 doesn't exist, i may need to create it myself, and also pointed me to a page in the arch linux wiki describing how to do so
it turned out that my dir-850l was to blame, i have replaced it with a asus rt-ac66r and everything is working correctly as expected now
just search for it yourself.  export ifs=":" [ -z "${1}" ] &amp;&amp; exit 1 for dir in $path do    if [ -x "${dir}/${1}" ];then       echo "${dir}/${1}"       exit 0    fi done echo ${1} not found exit 1   tested in bash, dash, ksh, mksh, zsh  update  the above is nice for a stand alone script however if you're planning on embedding this into a larger script you may want to use something more like the following.  function find_path() {    ifs_save="${ifs}"    export ifs=":"    [ -z "${1}" ] &amp;&amp; exit 1    for dir in $path    do       if [ -x "${dir}/${1}" ];then          echo "${dir}/${1}"          export ifs="${ifs_save}"          return 0       fi    done    export ifs="${ifs_save}"    echo ${1} not found    return 1 }   this is so that ifs is restored after finding the match, also swapped exit's with return's  
try using screen -rr
use ed
 change the setuid bit of mysqld executable and the ownership of the executable file to mysql  account, besides adding the required user in the group mysql for making him have access to the files on the filesystem. use visudo -f /etc/sudoers and grant him permission to execute the /etc/rc.d/init.d/mysql start and /etc/rc.d/init.d/mysql stop as two seperate commands in the command list and in the execution part, grant the user to execute both the commands as user (mysql). for more information on sudoers, refer to the sudoers man page
going back from machine code to the source language is called decompilation
through trial and error, i learned that by right clicking on the dvd icon on my desktop > selecting "copy disc" > select the option to iso.  once i have created the iso i can then go to yast > software management > configuration > repositories > add the iso to the repository list to search the catalog of program files to be installed. 
an excellent answer to this question can be found here: design patterns or best practices for shell scripts 
the first matching rule applies, so include .htaccess before excluding .*.  rsync -avp --include=".htaccess" --exclude=".*" 
filereadable() or isdirectory() would be better choices than findfile() -- the latter one searches in a set of directories
just use array syntax on the assignment and quote your variable:  array=("${array[@]:1}") #removed the 1st element   edit according to question in comment
ok, it seems that i've found the problem
you are confusing a few things
the argument to -regex has to match the whole path that is found
1) edubuntu,it is a part of ubuntu project.  2) qimo, it is also based on ubuntu.  3) ubermix, it's almost same as ubuntu but it has applications which are for kids.  for kid-safety applications, there is 'parental control' which is help you control your web-browser.  there are a lot of time time organizer applications for to get control how much time pc going to open. 
okay, i worked around it on my own
you didn't specify the shell you're using, but e.g
because you're using a single sed expression, everything that follows after the w (including the }) is interpreted as the wfile name:      the argument wfile shall terminate the editing command.   you can see that if you add a second command } e.g
a cumbersome workaround is to write your reply, then instead of sending the mail, postpone it (using p instead of y)
on the one hand, the first method calls tail twice, so it has to do more work than the second method which only does this once
you need to install kernel headers to compile a module
you can always try using ps to determine what processes are running out of everything, e.g.:  ps -ely | grep -i $processname   guessing at what the widget names will be:  ps -ely | grep -i gnome   is very likely to list them all. 
you could see if the window is hiding somewhere by using the wmctrl command to list the windows known to your instance of x11.  example  $ wmctrl -l 0x02600007 -1 greeneggs.bubba.net desktop 0x01a0005d  0 greeneggs.bubba.net linux - how to pop up "hidden" x application - unix &amp; linux stack exchange - google chrome 0x02a00006 -1 greeneggs.bubba.net saml@greeneggs:~   if you see your window in this list then you might be able to summon it to the front using the command line tool xdotool.  example  $ xdotool windowactivate '0x01a0005d'   the above is the window id from the wmctrl command i previously showed. 
luit -c &lt;infile &gt;outfile   the -c switch makes luit act like as a simple interpreter from stdin to stdout without its wrapping a child (your shell by default) in a pty and handling its i/o instead.  if you also do:  luit -olog /dev/tty -c &lt;infile &gt;outfile   luit will write to both your terminal and the outfile.  basically the -olog switch will log to a named file a copy of all that luit writes to its output as it writes it - and so it represents luit's processed input, but -ilog would do the same for all of luit's preprocessed input. 
the command runlevel | cut -d ' ' -f2 should give you the output of current runlevel
just check if you are not running linux
turns out this is 2 individual systemd issues, specifically how systemd-cryptsetup-generator works
it sounds like you want the -n option to ssh.   -n      do not execute a remote command
service units:   a unit configuration file whose name ends in .service encodes information about a process controlled and supervised by systemd.    — systemd.service(5)  systemd service units are the units that actually executes and keeps track of programs and daemon, and dependencies are used to make sure that services are started in the right order
in theory, yes: you can create a custom write-intent bitmap, or tell mdadm to assemble an array from only the beginnings of the disks, or probably some tricks i haven't thought of.  in practice, trying to do so carries a high risk of data loss: you're bypassing the system's safeguards, so it can't protect you from getting your disks mixed up, or incorrectly specifying where the array begins, or other user errors
you have enabled midgard2.so twice
put  shell -zsh   in your .screenrc, which will tell screen to start zsh as a login shell, which will in turn cause zsh to source ~/.zprofile . 
that's not a regex
use process substitution on bash:  diff -ywb --suppress-common-lines &lt;(git branch --merged prod-server) &lt;(git branch --merged test-server)  
just use:  cd -p ..   from the bash manpage:     the -p option says to use the physical directory structure instead of   following symbolic links.  
specify "myvps" as the hostname.  rsync /var/bar myvps:/home/foo ...  
stress is not available (yet) in epel-repository for rhel 7
if i understand correctly, and given that you want to include your new src directory in the patch, you could call diff -naur with a non-existent (or empty) directory as the first parameter:  diff -naur nonexistent src &gt; src.patch   however, when using this patch file, for example with patch -p0 &lt; src.patch, the files will be extracted in a directory named "nonexistent".  to make it easier for the receiver, perhaps you could temporarily rename your src dir to something else, for example:  mv src src-real diff -naur src src-real &gt; src.patch mv src-real src   i don't know if there is a better way... 
i ended up with something that's seemingly gross, if there's a better way please post it:  #!/bin/sh  done=false until $done; do     for i in $(seq 1 $2); do          read line || done=true;         [ -z "$line" ] &amp;&amp; continue;         lines+=$line$'\n';     done     sql=${lines::${#lines}-10}     (cat "header.sql"; echo "$sql";) | sqlcmd     #echo "--- processed ---";     lines=; done &lt; $1   run with ./insert.sh "file.sql" 100 where the 100 is the number of lines to process at a time. 
you might like to try dtdgen, a program i wrote many years ago to generate a dtd for a document
from advanced bash-scripting guide:      $$ is the process id (pid) of the script itself
if you're running the daemon from your own account, start it at boot time with cron
i think what you want to do is a bad idea, because in the case of a system crash you'll lose your work
$lc isn't being incremented in the loop 
avahi requires that the interface have the multicast flag set
first find out the appropriate section by lsblk
you want to un-comment "strict-order" in /etc/dnsmasq.con, as near as i can tell.  # by  default,  dnsmasq  will  send queries to any of the upstream # servers it knows about and tries to favour servers to are  known # to  be  up
it is difficult to do nontrivial things in a signal handler, since the rest of the program is in an unknown state
the gnu and bsd grep utilities has the a -a option for lines after a match and a -b option for lines before a match
if you want to receive email for frank.com then your mx record for frank.com  will need to point at your virtual machine
it is not possible
i would do something like:  ls -1 | grep "\.png$" | xargs -l 50 rm -f    this will match (and remove) only files ending with .png. 
tl;dr  don't use -t
#!/bin/bash  touch /script_logs/test.log maxfilesize=2048 while true do      sh test.sh &gt;&gt; /script_logs/test.log #get size in bytes**      file_size=`du -b /script_logs/test.log | tr -s '\t' ' ' | cut -d' ' -f1`     if [ $file_size -gt $maxfilesize ];then            timestamp=`date +%s`         mv /script_logs/test.log /script_logs/test.log.$timestamp         touch /script_logs/test.log     fi  done   i have removed the "&amp;" as it may cause an issue. 
the semicolon ; is the sequencing operator
there is a standard method, if the programs cooperate
here is a working function that's similar to your test function.   function testvarz       switch (count $argv)           case 0               echo 'zero'           case 1               echo "one $argv[1]"           case 2               echo "two $argv[1] $argv[2]"           case '*'               echo 'else'       end   end   you can use a similar structure for your connect function.  by the way, you should similarly use $# in your bash function instead of trying to rely on $2 being null
sounds like you're looking for wmctrl - see here for more examples.  edit: your window manager/desktop environment has to be standards compliant (ewmh)
problem #1 was caused by selinux
$ cat t.sh #!/bin/bash  for func in guard rspec rake; do         eval "         ${func}() {                 local foo=(command ${func})                 [ -e 'gemfile' ] &amp;&amp; foo=(bundle exec ${func})                 \"\${foo[@]}\" \"\$@\"         }         " done  type guard rspec rake   .  $ ./t.sh guard is a function guard () {     local foo=(command guard);     [ -e 'gemfile' ] &amp;&amp; foo=(bundle exec guard);     "${foo[@]}" "$@" } rspec is a function rspec () {     local foo=(command rspec);     [ -e 'gemfile' ] &amp;&amp; foo=(bundle exec rspec);     "${foo[@]}" "$@" } rake is a function rake () {     local foo=(command rake);     [ -e 'gemfile' ] &amp;&amp; foo=(bundle exec rake);     "${foo[@]}" "$@" }   the usual cautions about eval apply. 
you need to use iotop to find which program with high io usage first
yes, you can use xargs for this.  for example a simple:  $ locate commands.cfg | xargs grep check_dns   (when grep sees multiple files it searches in each one and enables filename printing along matches.)  or you can explicitly enable filename printing via:  $ locate commands.cfg | xargs grep -h check_dns   (just in case one grep is called only with 1 argument by xargs)  for programs that only accept one filename argument (unlike grep) you can restrict the number of supplied arguments like this:  $ locate commands.cfg | xargs -n1 grep check_dns   that does not print the names of files where matched lines are from.  the result is equivalent to:  $ locate commands.cfg | xargs grep -h check_dns   with a modern locate/xargs you can also protect against whitespace issues:  $ locate -0 commands.cfg | xargs -0 grep -h check_dns   (by default whitespace separates input of xargs - which is of course a problem when your filenames contain whitespace ...) 
to simplify your setup, you can set up an ssh config file which is located at ~/.ssh/config
unless it is explicitly set, there is no default shell history
you should already know the basics:   install the font and use fc-list to see that it shows the font, and use the family name shown in the output of fc-list in your x resources.   the question is about stylistic sets, i.e., a feature of the fonts:  os2vendor: 'pfed' lookup: 1 0 0 "'ss01' stylistic set 1 - no loop k" { "'ss01' stylistic set 1 - no loop k-1" ("noloop") } ['ss01' ('dflt' &lt;'dflt' &gt; 'cyrl' &lt;'dflt' &gt; 'grek' &lt;'dflt' &gt; 'latn' &lt;'dflt' &gt; ) ] lookup: 1 0 0 "'ss02' stylistic set 2 - flat base i" { } ['ss02' ('dflt' &lt;'dflt' &gt; 'cyrl' &lt;'dflt' &gt; 'grek' &lt;'dflt' &gt; 'latn' &lt;'dflt' &gt; ) ] lookup: 1 0 0 "'ss03' stylistic set 3 - no base serif i" { } ['ss03' ('dflt' &lt;'dflt' &gt; 'cyrl' &lt;'dflt' &gt; 'grek' &lt;'dflt' &gt; 'latn' &lt;'dflt' &gt; ) ] markattachclasses: 1   the stylistic-set feature is discussed in using opentype features on the web, e.g., making variations of fonts using the stylistic sets
don't parse ls output: http://mywiki.wooledge.org/parsingls.  also, in this example you don't need a loop, just let ln loop over args
you could run this before adding the device to store the inital list in a file:  ls /dev &gt;~/a   and then this after adding the device:  ls /dev | diff -u ~/a -   this should show you in what way the two lists of files differ
i run a minecraft server from a debian terminal, and this is probably the wrong way to do it, but it works
this looks like a general installation issue, nothing plugin-specific (for which you should open an issue against the plugin)
i think you need to retrieve the existing items and append yours.  zstyle -s ':completion:*:hosts' hosts _ssh_config [[ -r ~/.ssh/config ]] &amp;&amp; _ssh_config+=($(cat ~/.ssh/config | sed -ne 's/host[=\t ]//p')) zstyle ':completion:*:hosts' hosts $_ssh_config  
i too struggled for installing rabbitvcs+nautilus but i ended with rabbitvcs+thunar
lsblk should do the trick
first, consider that the windows install might be broken (rather than the hard drive) or just configured for a different set of hardware, thus windows is rebooting (or bsod'ing but set to automatically reboot) since it is not recognizing your machine's hardware
you'll have to extract the id substring from the file names
assuming that .z file is a compress-compressed file (as the .z extension implies as opposed to pkzip archives that zip file would suggest):  file='oms_profile_20150922.list.z' export file zcat &lt; "$file" | awk -f'|' -v ofs='|' '   {print $1,$6,$7,$8, environ["file"]}'  
i think the tool you may be looking for is vimdiff  vimdiff file.copy file.original  
   that it is because of lack of memory
try just time instead of timethis.  although be aware that there's often a shell builtin version of time and a binary version, which will give results in different formats:  $ time wget -q -o /dev/null http://unix.stackexchange.com/  real    0m0.178s user    0m0.003s sys     0m0.005s   vs  $ \time wget -q -o /dev/null http://unix.stackexchange.com/ 0.00user 0.00system 0:00.17elapsed 4%cpu (0avgtext+0avgdata 0maxresident)k 0inputs+0outputs (0major+613minor)pagefaults 0swaps   unlike your "timethis" program, you get three values back
you're observing a combination of the peculiar behavior of dd with the peculiar behavior of linux's /dev/random
rmmod 8139too doesn't work because either:   8139 support is built into the kernel, and the driver can't be unloaded because it's not a module
i thought i had seen everything in unix
find / -mount -name '*mysql-connector-java*' -print   the -mount predicate is so that find skips searching virtual filesystems like /proc and /sys (useless to search) and other things that might be mounted like network-mounted filesystems (which could make it really slow!), but you can omit it if you want to search absolutely everything. 
the reason is that tz=utc-8 is interpreted as a posix time zone
at that point, i would think about using a power monitor to measure the load on the computer at any time
they are under /sys/bus/usb.  for example,  ls /sys/bus/usb/devices/1-0\:1.0/ep_81/  bendpointaddress  blength       direction  power  uevent binterval         bmattributes  interval   type   wmaxpacketsize  
you can tell an x program which display to use with the display environment variable, as long as you know which display alpha is currently showing
this is because all the kernel modules are not stripped
if you have access to the repository, you can find all files in the attic with find
i launch my x server with this: "xwin.exe -multiwindow" 
that is a feature of “ido”, which you seem to be using.  just go to “customize emacs”, and in the group “convenience / ido”, change the settings “ido default buffer method” and “ido default file method”, which surely are now set to “raise frame if already shown”. 
the cd command modifies the "current working directory", right?  "current working directory" is a property that is unique to each process.  so, if cd was a program it would work like this:   cd foo the cd process starts the cd process changes the directory for the cd process the cd process exits your shell still has the same state, including current working directory, that it did before you started.  
the only reliable way to write scripts that support different operating systems is to only use features that are defined by posix.  for things like your personal shell configurations, you can use hacks that fit your specific use case
your home directory is probably mounted with the nosuid flag
what shell are you using?   if korn?   'r' will run the previous   bash?   ctrl-p or up-arrow or '!!'   to edit the command try using fc - it will used the $editor env variable and open up the editor
ok, it's been a long time, but i'll still answer my question with the best option i found as of now
so i'll just give the answer for the question
i found these methods on ubuntu forums in a thread titled: thread: how do i lock the screen in xfce?.  excerpted from 2 of the answers in that thread  method #1 - keyboard shortcut     open the settings manager > keyboard > shortcuts and you can see that the default shortcut to lock the screen is ctrl-alt-del
the basic question is slightly hard to answer, as files could have been touched at various points.  one file that doesn't get touched very often, and is created when the machine is first booted up, is the ssh private key file for the server
this looks like a problem with the loader
see https://irssi.org/documentation/startup/ in particular (oftc network, identify with nickserv and wait for 2 seconds before joining channels)  /network add -autosendcmd "/^msg nickserv ident pass;wait 2000" oftc   likely, in your case you will simply add ;wait 2000 to your auth command
base on this answer from serverfault,     ufw supports per rule logging
generally, in linux, and unix, traceroute and ping would both use a call to gethostbyname() to lookup the name of a system
here is sample output from free:  % free              total       used       free     shared    buffers     cached mem:      24683904   20746840    3937064     254920    1072508   13894892 -/+ buffers/cache:    5779440   18904464 swap:      4194236        136    4194100   the first line of numbers (mem:) lists   total memory used memory free memory usage of shared usage of buffers usage filesystem caches (cached)   in this line used includes the buffers and cache and this impacts free. this is not your "true" free memory because the system will dump cache if needed to satisfy allocation requests.  the next line (-/+ buffers/cache:) gives us the actual used and free memory as if there were no buffers or cache
yes, either  su -c 'udisksctl mount -b /dev/sdd --no-user-interaction' - thb   or  su - thb udisksctl mount -b /dev/sdd --no-user-interaction exit   will mount /dev/sdd on e.g
grep is the way to go, it returns 0 if a match is found
if your admin's use sudo, instead of just su'ing to root, they'll retain their own command history.  alternatively, you can use ksh's histfile variable to set the filename for the history
the extra pair of quotes would be consumed only by an extra evaluation step
are you wanting all of the raspberry pi devices to be accessible from the internet, for example to run a web server cluster? or are you just trying to be able to have the raspberry pi devices access the internet from behind a firewall?  if you are just trying to give them access from behind a firewall then, just use a router instead of a switch
a [probably not perfect] solution to this has been to hook onto the "systemd-remount-fs.service" systemd service, which is the remounting of the filesystem to read-write.  this means the module will be loaded as early as possible, whilst still being loaded after the filesystem becomes readwrite.  my sample systemd config file is as follows:  [unit] description=starts kernel modules for usb otg after=systemd-remount-fs.service defaultdependencies=false  [service] type=simple execstart=/home/pi/programs/startmod.sh workingdirectory=/home/pi/programs/  [install] wantedby=local-fs.target   this works, if a little hackily. 
you have to boot linux with efi mode to get access to efi variables and the ability to use efibootmgr so you can switch to grub
from the fedora documentation for rpm, spec files, and rpmbuild:  the --target option sets the target architecture at build time
don't do this...  if two operating systems try to access the same raw block device at the same time then you should expect to see data corruption
if by useless whitespace you mean trailing whitespace at the end of the line, this will work on gnu systems:  find -name '*.c' -print0 | xargs -r0 sed -e 's/[[:blank:]]\+$//' -i   (replace *.c with whatever your source files match) 
if you want the entire hard drive encrypted, even the linux mint system partitions, swap, your home, the whole works, then i suspect the easiest would be to:   backup your data (the mint backup tool you linked an image to should work, but double-check for files you want backed up that aren't in your home) reinstall with encryption using the installer (i'm pretty sure it supports system encryption) then restore your data (home, reinstall programs)   or  just encrypt your home folder now with ecryptfs-migrate-home but be sure &amp; read it's man page &amp; should heed it's warnings:     warning:  make  a  complete  backup  copy  of the non-encrypted data to another system or          external media
nawk -v count=0 '!nf {count++; next}; 1; end {print count}'   for all lines without any fields (!nf) (empty lines, in this case), increment the count and move on
here is what i had to do in my .bashrc  export ps1="\\n[\\!
no, 'usage' is not a command
as per man page of mount   we can define only three option in errors i.e continue|remount-ro|panic     errors={continue|remount-ro|panic}      define the behaviour when an error is encountered
edit: as @fpmurphy1 mentioned in a comment, there's no need for all the runlevel grepping below. a simple last reboot -n 10 will do
try using fgrep (or the -f option to grep that does the same), and write your query without escaping the "&lt;" and "&gt;"
ddclient  the easiest way is to use ddclient
as most others have observed, "-n" is interpreted literally if placed anywhere but immediately after the echo command.  historically, unix utilities were all like this -- they looked for options only immediately after the command name
find /path -type f -print0 | xargs -0 dos2unix -- 
what you're looking for is typically called kiosk mode
nothing to see with what you have provided of information
you could do this:  find -type f -printf '%ty-%tm-%td %.8tt %p\n' | sort -r | sed -r 's/(^[^ ]+ [^ ]+) (.+)/\2 \1/' | head -20   putting .8 between % and tt modifies that field to limit it to 8 characters (hh:mm:ss)
this would be consistent with unsuccessful authentication attempt?  # this option controls how unsuccessful authentication attempts are mapped # to anonymous connections    map to guest = bad user   please post logfile showing your authentication succeeding or otherwise 
the opposite of &lt;c-o&gt; is &lt;c-i&gt; a.k.a
to fix your taglist issue, add the following somewhere in your .vimrc:  let tlist_inc_winwidth=0   from the vim documentation:  window resizing with xterm only works if the allowwindowops resource is enabled
cat /sys/class/net/eth0/carrier is by far the easiest method. 
in this answer, let it be clear that all your data will be destroyed on the array, so back it up first!  log in as root:    su   check what number (mdx) the array has:    cat /proc/mdstat   suppose it is md0 and it is mounted on /mnt/raid1, first we have to unmount and stop the array:  umount /mnt/raid1 mdadm --stop /dev/md0   now, we need to erase the super-block on both hdds, suppose sdb and sdc:  mdadm --zero-superblock /dev/sdb1 mdadm --zero-superblock /dev/sdc1   then, we re-initialize both hdds with mbr, you can do this e.g
you could use awk:  awk '{print &gt; nr".txt"}' file   nr is the current line number in awk, so the command above will print each line into a file whose name is the current line number plus .txt
you have to wait after the for loop, so all currently active child processes are waited for:  for time in "${array[@]}" do     test "$time" &amp; done  wait  
gilles, no wonder you were puzzled (i wasn't, i just didn't understand the syntax ;-) ), it was a bug:  https://bugzilla.novell.com/show_bug.cgi?id=676041  luckily fixed already. 
if that list was in a file, one per line, i'd do something like:  sort -nu file |   awk 'nr == fnr {rank[$0] = nr; next}       {print rank[$0]}' - file   if it was in a zsh $array:  sorted=(${(nou)array}) for i ($array) echo $sorted[(i)$i]   that's the same principle as for the awk version above, the rank is the index nr/(i) in the numerically (-n/(n)) ordered (sort/(o)), uniqued (-u/(u)) list of elements.  for your average rank:  sort -n file |   awk 'nr == fnr {rank[$0] += nr; n[$0]++; next}   {print rank[$0] / n[$0]}' - file   which gives:  5 7 1 6 2.5 2.5 4   (use sort -rn to reverse the order like in your google spreadsheet version). 
you can use grep with pcre (-p) to extract the desired portion and use it as input for date:  date --date="$(sudo debugfs ...
your question suggests that debian uses temp files for all writes, which isn't the case
you can retrieve the value of an option by using its name with a &amp; prepended
you can do it with awk
as you're extracting a tar.gz file from stdin, you don't need to specify the f option, tar defaults to reading from stdin.  assuming you want to extract the contents to $destdir, you also need to use gnu tar's -c (change directory) option.  i've also put " quotes around the variables, in case $src_uri or $destdir contain any spaces or shell meta-characters - &amp;, *, ? and the like.  finally, the {} curly braces around the variables aren't strictly necessary here, but i've left them in anyway - they certainly don't cause any harm.  putting that all together, you get:  wget -q -o- "${src_uri}" | tar -xz -c "${destdir}"  
take a look at cron
from man page:   by  default,  the on and off options affect only runlevels 2, 3, 4, and    5, while reset and resetpriorities affects all of the  runlevels
it's not just you.  see here: http://www.dd-wrt.com/wiki/index.php/wireless_bridge#limitations  basically, the spec for wifi says that any wireless adapter can only have one mac address, which makes bridging wifi an impracticality.  there are several bugs in several forms describing slightly different symptoms filed against virtualbox (735, 2975, 5503, etc.) but the underlying cause in each case is bridging a wireless interface.  i have ended up adding host-only interfaces for this kind of activity instead. 
it means the child process of the parent process id
you definitely can do this, but it can get annoying. i'd put libxml 2.8 in a separate prefix (./configure --prefix=/path/to/prefix/) alongside php 5.1.0 (e.g
i have already answered this using a parser - what i consider the 'right way'
with the help from iptables-save, i found out what the proper format is, when saving it to:  /etc/iptables/rules.v4   sample of the rules on the link in the question follows:  *raw :prerouting accept [0:0] :output accept [0:0] -a prerouting -p icmp -m u32 ! --u32 "0x4&amp;0x3fff=0x0" -j drop -a prerouting -p icmp -m length --length 1492:65535 -j drop -a prerouting -p tcp -m tcp --tcp-flags fin,syn fin,syn -j drop -a prerouting -p tcp -m tcp --tcp-flags syn,rst syn,rst -j drop -a prerouting -p tcp -m tcp --tcp-flags fin,syn,rst,psh,ack,urg fin,psh,urg -j drop -a prerouting -p tcp -m tcp --tcp-flags fin,syn,rst,psh,ack,urg fin -j drop -a prerouting -p tcp -m tcp --tcp-flags fin,syn,rst,psh,ack,urg none -j drop -a prerouting -p tcp -m tcp --tcp-flags fin,syn,rst,psh,ack,urg fin,syn,rst,psh,ack,urg -j drop commit  
if it is a software which obeys the filesystem hierarchy standard than you should place it in /usr/local and the appropriate subdirectories (like bin, lib, share, ...).  other software should be placed in their own directory under /opt
you are forgetting that the default action of sed is to print each pattern space (line) - so suppress the default behaviour you need to add the -n switch  sed -n '1,4p' list  
assuming you just want the name of each directory:  find /path/ -type d -print  
unless it is a vendor provided package that integrates with the os package manager you shouldn't extract it in that location
i would confirm the steps that you used to compile the driver yourself
udev adds some environment variables to the partition node (leaf node) including partition entry flags for mbr table
you can do this with a fairly small modification of either answer from the last question:  rename s/ras\.// sw.ras.*   or  for file in sw.ras.*; do     mv "$file" "${file/ras./}" done   explanation:   rename is a perl script that takes a perl regular expression and a list of files, applies the regex to each file's name in turn, and renames each file to the result of applying the regex
i wrote one-liner based on tobi hahn answer.  for example, you want to know what device stands for ata3:  ata=3; ls -l /sys/block/sd* | grep $(grep $ata /sys/class/scsi_host/host*/unique_id | awk -f'/' '{print $5}')   it will produce something like this  lrwxrwxrwx 1 root root 0 jan 15 15:30 /sys/block/sde -&gt; ../devices/pci0000:00/0000:00:1f.5/host2/target2:0:0/2:0:0:0/block/sde  
yes, it's cunningly called security.debian.org
just run it in the package source folder:  check-all-the-things   you'll probably want to tee that to a log file, the output is very verbose
you can use the wildcard * for the name that you don't know
not exactly swallowing, but you can remove them with parameter expansion:  str='hello \e[31mc\e[32mo\e[33ml\e[34mo\e[35mr\e[m world'  # colorful output echo -e "$str"  # colorless output     echo -e "${str//\\e\[+([0-9;])m}"   the above in bash requires the extglob shell option to be turned on
in your example you can go with:      pgrep -fc 'sleep 500'   it matches both /bin/sleep 500 and sleep 500.  or if you want to be more precise:  pgrep -fc 'sleep 500$'  
+x means to set the execute bit:     if the file is a directory or if the current (unmodified) file mode bits have at least one of the execute bits (s_ixusr, s_ixgrp, or s_ixoth) set
it's not bash, it's find; though you'll find that most utilities will follow the same principle:   if operating on file contents, a symlink to a regular file is equivalent to the actual file. if operating on directory entries, symlinks are a category of their own.   when you run find $symlink, find sees an object that isn't a directory, so it doesn't traverse it
all the locale variables use the same locale name so that you can specify your favorite locale in a single swoop, e.g
i'd guess lack of features - no command history, no fancy redirection, no command line editing
unless something changed recently gparted is de facto standard tool
in the meantime i was able to compile and install on debian squeeze, ubuntu and also centos 6.0 and it works
download and extract the source code from here
ls already performs that lookup
sed has a function for that, and can do the modification inline:  sed -i -e '/pointer/r file1' file2   but this puts your pointer line above the file1
typically, stopping sshd will prevent it from accepting any new connections, but won't kill off existing connections
with awk:  awk 'nf{nf-=1};1' &lt;in &gt;out   or:  awk 'nf{nf--};1' &lt;in &gt;out   or:  awk 'nf{--nf};1' &lt;in &gt;out   although this looks like voodoo, it works
up until a few hours ago testing was effectively jessie, so you should be able to cross-grade without trouble
this can be do the same thing with purge:  sync &amp;&amp; echo 3 &gt; /proc/sys/vm/drop_caches   from man proc:  /proc/sys/vm/drop_caches (since linux 2.6.16)               writing to this file causes the kernel  to  drop  clean  caches,               dentries  and  inodes from memory, causing that memory to become               free.                to free pagecache, use echo  1  &gt;  /proc/sys/vm/drop_caches;  to               free dentries and inodes, use echo 2 &gt; /proc/sys/vm/drop_caches;               to  free  pagecache,  dentries  and  inodes,  use   echo   3   &gt;               /proc/sys/vm/drop_caches.                because this is a nondestructive operation and dirty objects are               not freeable, the user should run sync(8) first.   and from man sync:  name        sync - flush file system buffers  description        force changed blocks to disk, update the super block.  
clarification : this .exe file you downloaded is an installation file for windows operating systems
you can do this using udev
a unix system consists of several parts, or layers as i'd like to call them.  to start a system, a program called the boot loader lives at the first sector of a hard disk partition
the stty utility sets or reports on terminal i/o characteristics for the device that is its standard input
you can save your mbr to a file using dd  dd if=/dev/sdx of=~/mbr.backup bs=512 count=1  where x is the device you want the backup from
one way to remove all comments is to use grep with -o option:  grep -o '^[^#]*' file   where   -o: prints only matched part of the line first ^: beginning of the line [^#]*: any character except # repeated zero or more times   note that empty lines will be removed too, but lines with only spaces will stay. 
you are thinking that the !, * or x has a special meaning here, and are therefore worrying that there might be some distinction among them.  the fact is that these characters are chosen simply because they stand out, at least to western eyes
on your version of sunos nawk(or for that matter awk) should be able to do the trick   nawk -f';' 'begin{ofs=";"}{print($1,$2,$3,$(nf-1),$(nf))}' file.txt   
the recommendation in the filesystem hierarchy standard is that /media contains subdirectories for mount points of removable media
for ksh:  printf "%s\n" "alias shh='sqlplus hfdora/hfdora@hfd1" &gt;&gt; ~/.kshrc source ~/.kshrc   for bash:  printf "%s\n" "alias shh='sqlplus hfdora/hfdora@hfd1" &gt;&gt; ~/.bashrc source ~/.bashrc   for zsh:  printf "%s\n" "alias shh='sqlplus hfdora/hfdora@hfd1" &gt;&gt; ~/.zshrc source ~/.zshrc     use source for the instant effect     and as @glennjackman said:     a note to readers: ~/.kshrc is for ksh93
apt-get does not install the last php version because it is not available in the official debian package repository
the following one-liner will show look for the word linux in all upgradable packages, highlight it and specifically notify you (requires the ack-grep package):    apt update &amp;&amp;    apt list --upgradable | ack --color --passthru linux &amp;&amp;    echo 'there is something of interest!'   (you might replace the last echo with e.g
the command you are looking for is args:  for example:  :args /path_to_dir/*.py   or   :args /path_to_dir/**/*.py   ** to match files recursively
hard drives usually don't have labels, it's filesystems that do
at will typically use your installed mail transport agent (mta) to deliver the mail
 cygwin x faq states that they use getdtablesize :      cygwin/x queries getdtablesize() for the maximum number of client   connections allowed; by default cygwin returns 32 from   getdtablesize()
unix systems have a single directory tree
from man man:  -k, --global-apropos       search for text in all manual  pages
three more options:  ls  | grep ^data-...........tsv     or:  ls  | grep ^data-"[[:digit:]]\{4\}-[[:digit:]]\{2\}-[[:digit:]]\{2\}.tsv"   or:  ls  | grep ^data-[1-2][0-1][0-9][0-9]-[0-1][0-9]-[0-1][0-9].tsv  
it seems like if it's a tab
if you run an os that supports dtrace, this script will help you identifying what processes are launching short lived processes:  #!/usr/sbin/dtrace -qs  proc:::exec {   self-&gt;parent=stringof((unsigned char*)curpsinfo-&gt;pr_psargs); }  proc:::exec-success /self-&gt;parent != null/ {   printf("%s -&gt; %s\n",self-&gt;parent,curpsinfo-&gt;pr_psargs);   self-&gt;parent=null; }   if you are on an os without dtrace support, have a look to alternatives, e.g
try using this site/service to generate the colors that you want.   bash $ps1 generator   note: i think you're looking for the color cyan to get light blue: (cyan - 0;36).  excerpt      references   how to customize your command prompt  
create your own "select":  #!/bin/bash  options=("show all elements" "add elements" "load file" "write to file" "generate lines" "clear file" "clear elements" "choose file" "exit") width=25 cols=3  for ((i=0;i&lt;${#options[@]};i++)); do    string="$(($i+1))) ${options[$i]}"   printf "%s" "$string"   printf "%$(($width-${#string}))s" " "   [[ $(((i+1)%$cols)) -eq 0 ]] &amp;&amp; echo done  while true; do   echo   read -p '#? ' opt   case $opt in     1)       echo "${options[$opt-1]}"       ;;      2)       echo "${options[$opt-1]}"       ;;      9)       echo "bye bye!"       break       ;;   esac done   output:   1) show all elements     2) add elements          3) load file              4) write to file         5) generate lines        6) clear file             7) clear elements        8) choose file           9) exit                   #?   
well, i kinda-sorta found out what's wrong
use atop
you can usually use alsamixer from a command line over ssh to control alsa sound levels
i think you're looking for apt-offline.  on your linux machine with no internet connection, let's say you want to install emacs
you need to include -dwithout_x11 as make argument
try using /reconnect
as a computer expert, whether you are one or aspire to be one, you should have a good basic knowledge of linux, mac, and windows
the /sys directory is generally where the sysfs filestystem is mounted, which contains information about devices and other kernel information.  the files in /sys/block contain information about block devices on your system
apparently, many tools (among them udev) will soon require a /run/ directory that is mounted early (as tmpfs)
a text editor is not a word processor
ok, i found a way to solve this issue
i have the same remote and i have it sending correct keycodes to my 2.6.38-gentoo-r3 kernel
remount the root filesystem read-write temporarily and make a symbolic link for .ssh that points somewhere where ssh can write
grep -ve '"&gt;[^&lt;&gt;]{101,}&lt;/a&gt;&lt;br&gt;'   to remove lines that contain more than 100 non-&lt;> characters between a "&gt; and a &lt;/a&gt;&lt;br&gt;. 
fstrim should run on "mountpoint", so you need to have devices mounted
this is covered in variable expansion:  ${parameter:?word}  if parameter is null or unset, the expansion of word (or a message to that effect if word is not present) is written to the standard error and the shell, if it is not interactive, exits
wget does not offer such an option
debian provides cd/dvd images that you can use as package installation sources after the os installation: http://cdimage.debian.org/debian-cd/7.8.0/amd64/iso-dvd/  mind you that the link is for the (still) current stable release, wheezy
it would help if you were a lot more specific about what you are trying to do.  here is an extremely simplistic example:  while true do     clear     date     sleep 1 done  
the default record returned by nslookup is the a record, in this case 198.252.206.16
two points: find "ignores fractional parts"
if you just type export path=$path:&lt;/path/to/file&gt; at the command line it will only last for the length of the session.  if you want to change it permanently add export path=$path:&lt;/path/to/file&gt; to your ~/.bashrc file (just at the end is fine). 
vt100 terminals (which all modern terminal emulators emulate to some extent) supported a number of problematic commands, but modern emulators or distributions disable the more problematic and less useful ones
you could try running (as root) dmidecode -t memory
httr imports the openssl package which needs as system requirement libssl-dev (sudo apt install libssl-dev)  ------------------------- anticonf error --------------------------- configuration failed because openssl was not found
just put your repository above [extra] in pacman.conf
to recompile glibc with custom dtv_surplus and override the existing version:   copy /var/abs/core/glibc to another directory so you can write to it without being root, then cd to that directory. use makepkg -o to download and extract the source code without building it(because we will edit the source code before building). edit dtv_surplus located in src/glibc-&lt;version&gt;/sysdeps/generic/ldsodefs.h
on aix you can have 3 compilers:   gcc newer xl c/c++ enterprise edition older visualage c++ professional   for gcc since late 2.x, syntax for creating shared libraries is:  gcc -shared -wl,-soname,your_soname -o library_name file_list library_list   example:  gcc -fpic -g -c -wall a.c gcc -fpic -g -c -wall b.c gcc -shared -wl,-soname,libmystuff.so.1 -o libmystuff.so.1.0.1 a.o b.o -lc   for the above aix native compilers, see this page for detailed instructions:  http://www.ibm.com/developerworks/aix/library/au-gnu.html  (see section shared libraries on aix versus system v systems) 
press enter on the .. when you're in the root of sshfs. 
this is the most near that you can get of what you want, otherwise look for another file manager:  look for 'preferences', in the 'views' tab, select "view new folders using: list view", then select the 'display' tab, there will be a checkbox that tells you 'navigate folders in a tree', close nautilus
/private is a container for parts of the standard unix filesystem hierarchy that may vary between individual computers (e.g
the dd does not bypass the kernel disk caches when it writes to a device, so  some part of data may be not written yet to the usb stick upon dd completion
it's not the program output, it's some useful shell information.  anyway, those can be hided by using subshell and output redirection  ( sleep 3 &amp; ) &gt; /dev/null 2&gt;&amp;1  
acls are the answer
getopts removes the "-" sign from the options.  so you need:  while getopts ha:b: opt; do     case $opt in         h)             help             exit             ;;         a)   ....   and remember to clear your variables before calling getopts (unset opta optb) as they  may be in the environment received by your script
dnat may suffice:  # iptables -t nat -a prerouting -i eth0 -p tcp -d 192.168.1.2 --dport 8080 -j dnat --to-destination 192.168.3.2:80   the ufw before.rules file from some altagoobingleduckgoing looks like it uses the iptables-save format, so thus may contain something along the lines of:  *nat :prerouting accept [0:0] -a prerouting -i eth0 -p tcp -d 192.168.1.2 --dport 8080 -j dnat --to-destination 192.168.3.2:80 commit  
no they're written to disk
actually, if you just have problem with running the gui there's no need to install another distribution, simply modify the startup sequence to prevent the graphical interface from coming up and work from the command line as you desire.  i don't have access to a system right now, but i believe the script you'll need will be found in the /etc/init.d  or /boot/grub directory
the apparent answer is to run these two commands  lvcreate --name opt --size 23gi group mkfs -t ext4 -l opt /dev/group/opt   however, via the comments thread it became apparent that lvcreate threw an error message,  /dev/group/opt: not found: device not cleared aborting: failed to wipe start of new lv   a search on google finds that this is a known error, and the suggested workaround is to avoid zeroing the first part of the lv by using lvcreate --zero n ....  i've done some more investigation and it appears that lvcreate will work fine once udev is restarted (either via a system reboot or with udevadm reload)
the following is a direct fix of your approach:  find 
you can't configure linux not to require sudo
no, you cannot add your structure in a meaningful way to /proc because it is generated (not a "real" filesystem)
&gt; touch .#test &gt; find 
use the --prefix option with the configure command.  i won't try to give a complete configure command here, since gcc is one of those programs most often given complex configuration options, but adding something like --prefix=$home/my-gcc-4.7 will work
i don't think you can disable it, but you could use a mapping and append &lt;cr&gt;:  map &lt;f4&gt; :!mv file1 file2&lt;cr&gt;&lt;cr&gt;  
it turns out that posixovl (https://sourceforge.net/projects/posixovl/) does exactly what i was looking for
if you export ps1, then the value shouldn't be reset
why are you using -n if you don't want to suppress the default output?  just use:  sed -e -e 's/:[0-9]+$//'  
indeed, graphics.x11.extratypes.xf86 does not appear to provide an xf86xk_audiomicmute keysym
you can use the following function, which use the same way sudo auto-completion generate the completion list:  comp() {     local comp_line="$*"     local comp_words=("$@")     local comp_cword=${#comp_words[@]}     ((comp_cword--))     local comp_point=${#comp_line}     local comp_wordbreaks='"'"'&gt;&lt;=;|&amp;(:"     # don't really thing any real autocompletion script will rely on     # the following 2 vars, but on principle they could ~~~  lol.     local comp_type=9     local comp_key=9     _command_offset 0     echo ${compreply[@]} } comp git config ''   where _command_offset is defined in bash-completion (package).  note: the function need to be run in a interactive shell (i.e
installation of boost via apt installs several boost packages which are not uninstalled on the remove that you are using
you could do something with a bash function  site() {     cd /foo/bar/site${1}/usera }   put that in your .bashrc and then call it like  site 2   it will take you to /foo/bar/site2/usera 
uptime is part of the 'procps' package, the upstream source is at http://procps.sourceforge.net/  (not a fedora user, so not sure where to find their .src.rpm).  to answer the question you didn't ask, however; take a look in /proc/uptime the first number is seconds since boot
you are already re-logged in with the new ssh session that you set up
the packages graph and rbgl are in the bioconductor package repository, the following works for me:  r&gt; source("http://bioconductor.org/bioclite.r"); bioclite(c("graph", "rbgl")) r&gt; install.packages("reshape") r&gt; install.packages("vennerable", repos="http://r-forge.r-project.org")  
link mint is an ubuntu-based distribution intended for desktop systems
too easy :  tar xvjf myarchive.tar.xz --to-command=sha1sum   the result is like this :  z/ z/documentation 3c4d9df9bcbd1fb756b1aaba8dd6a2db788a8659 *- z/getnameenv.sh 1b7f1ef4bbb229e4dc5d280c3c9835d9d061726a *-   or create "tarsha1.sh" with :  #!/bin/bash  sha1=`sha1sum` echo -n $sha1 | sed 's/ .*$//' echo " $tar_filename"   then use it this way :  tar xjf myarchive.tar.xz --to-command=./tarsha1.sh   the result is like this :  3c4d9df9bcbd1fb756b1aaba8dd6a2db788a8659 z/documentation 1b7f1ef4bbb229e4dc5d280c3c9835d9d061726a z/getnameenv.sh  
fb_query must be quoted:  curl -f access_token=$fb_token -f query="$fb_query" https://api.facebook.com/method/fql.query  
contrary to what their most common use would lead you to think, su and sudo are not just meant for logging in (or performing actions) as root
alias dl='fc -s'   see http://www.gnu.org/software/bash/manual/bashref.html#bash-history-builtins 
i had that problem too some months ago, and i remember i had to delete some .desktop files that were inside the $home/.local/share/applications folder. i think you should delete any file that has notepad as part of its name, and also you should try to delete (or move somewhere else) the files wine-extension-*. 
don't use kill -9! this command is meant to be used in some specific extreme cases only
the problem is, you didn't quote your -name parameter
why are loki and host_a connected by a router when they are on the same subnet?  is it really a router, or is it just a switch?  (from your later comments, although the device is a router, it is just acting as a switch between loki and host_a).  what is the routing table on host_a and router?  if it were to try to reach 192.168.200.1, why should it use loki as a destination?  unless the routing table on these devices know to use loki for the 192 subnet, they will just forward to the default gateway.  as an alternative, you might want to investigate installing nat on loki
this might interest you.  basically, you need to determine whether or not stdin in a terminal, or some sort of pipe/redirection
x11r6.7 refers to the version number of the x.org window system
that result you're getting is because . matches any single character   from manpage >regular expressions:     &emsp;&emsp;&emsp;the fundamental building blocks are the regular expressions that match a single character
that's just using the backtick as an opening quote; it's the equivalent of     ‘stakbot’ is preserved by this routine   and     the command ‘bye’ is identical to ‘exit’   using only ascii characters. 
for "simple" columns like this, comma separated values will open nicely in excel.  awk 'begin{ ofs=","; print "hosts,output,status"}; nr &gt; 1{print $1, $2, $3, $4, $5, $6, $7, $8, $9;}' input.txt &gt; output.csv  
posting an answer as requested:  use the --spider option:  wget -r -nv --spider http://example.com   then you can parse the structure of the site from the output
the option you are looking for is --noconfirm 
if some-boring-process is running in your current bash session:   halt it with ctrl-z to give you the bash prompt put it in the background with bg note the job number, or use the jobs command detach the process from this bash session with disown -h %1 (substitute the actual job number there).   that doesn't do anything to redirect the output -- you have to think of that when you launch your boring process
the folders in /mnt/config/.data and /mnt/config/.work contain your changes
you can echo the result and pipe it to xargs -n1:  echo /path/to/file{1,2,3} | xargs -n1 command  
these are part of the console-setup package in debian, and reading the sources for those would show you that the answer is in chapter 2 - bdf2psf of the hackers guide for console-setup:     uni1 (512 glyphs)      supports most of the latin languages, the slavic cyrillic languages, hebrew and barely arabic.      uni2 (512 glyphs)      supports most of the latin languages, the slavic cyrillic languages and greek.      uni3 (512 glyphs)      supports most of the latin and cyrillic languages.   the 512 is a limitation of the linux console.  there also appears to be some mapping (multiple characters to single glyphs), because the number of unicode values in each source-file does not match the 512-glyph limit:  $ wc -l uni1.512 uni2.512 uni3.512      502 uni1.512     1870 uni2.512     1854 uni3.512     4226 total  
the appres utility lists the resources used by an application, both user and default.  appres xterm xterm   the first argument is the class name (xterm -class xxx)
here's what you could do in plain bash, assuming the data is exactly as you posted
great classic question about managing jobs and signals with good examples!  i've developed a stripped down test script to focus on the mechanics of the signal handling.  to accomplish this, after starting the children (loop.sh) in the background, call wait, and upon receipt of the int signal, kill the process group whose pgid equals your pid.   for the script in question, play.sh, this can be accomplished by the following: in the stop() function replace exit 1 with  kill -term -$$  # note the dash, negative pid, kills the process group  start loop.sh as a background process (multiple background processes can be started here and managed by play.sh)  loop.sh &amp;  add wait at the end of the script to wait for all children.  wait    when your script starts a process, that child becomes a member of a process group with pgid equal to the pid of the parent process which is $$ in the parent shell.  for example, the script trap.sh started three sleep processes in the background and is now waiting on them, notice the process group id column (pgid) is the same as the pid of the parent process:    pid  pgid stat command 17121 17121 t    sh trap.sh 17122 17121 t    sleep 600 17123 17121 t    sleep 600 17124 17121 t    sleep 600   in unix and linux you can send a signal to every process in that process group by calling kill with the negative value of the pgid
your question doesn't say where the previous known-good values come from
use xvncviewer   useage: xvncviewer ip_address:display_no, where the display_no can be seen from the ps output:  11233 ? s 0:03 xvnc :11 -geometry 1440x900 -depth 16 -rfbauth /home/vagrant/.vnc/sesman_vagrant_passwd -bs -ac -nolisten tcp  it then prompts for the password with which the session was created.  in ubuntu you can install it by using sudo apt-get install xvnc4viewer (on the client end). 
one way to accomplish this is to use the command debsums.  $ debsums &lt;package&gt;   example  $ debsums xz-utils /usr/bin/lzmainfo                                                             ok /usr/bin/xz                                                                   ok /usr/bin/xzdiff                                                               ok /usr/bin/xzgrep                                                               ok /usr/bin/xzless                                                               ok /usr/bin/xzmore                                                               ok /usr/share/doc/xz-utils/news.debian.gz                                        ok /usr/share/doc/xz-utils/readme.debian                                         ok /usr/share/doc/xz-utils/readme.gz                                             ok /usr/share/doc/xz-utils/copyright                                             ok /usr/share/doc/xz-utils/extra/7z2lzma/7z2lzma.bash                            ok /usr/share/doc/xz-utils/extra/scanlzma/scanlzma.c                             ok /usr/share/doc/xz-utils/faq.txt.gz                                            ok /usr/share/doc/xz-utils/history.txt.gz                                        ok /usr/share/man/man1/lzmainfo.1.gz                                             ok /usr/share/man/man1/xz.1.gz                                                   ok /usr/share/man/man1/xzdiff.1.gz                                               ok /usr/share/man/man1/xzgrep.1.gz                                               ok /usr/share/man/man1/xzless.1.gz                                               ok /usr/share/man/man1/xzmore.1.gz                                               ok  
the application to start is called gnome-session-properties (part of gnome-session-bin)
~/.bash_profile and ~/.bashrc are not read by scripts, and functions are not exported by default
according to the removals file, it was removed from future debian at the request of the maintainer
awk 'nr==1{print; print "new line"} nr!=1'  
first we download the latest steam package:  wget --continue http://repo.steampowered.com/steam/archive/precise/steam_latest.deb   then we update apt cache:  sudo apt update   and install the steam package with apt:  sudo apt install ./steam_latest.deb   after you first run steam and agree to eula, it will check for additional packages needed:     steam needs to install these additional packages     you enter your sudo password and agree with the installation and wait for it to install.  open terminal again and delete these two files:  rm $home/.local/share/steam/ubuntu12_32/steam-runtime/i386/lib/i386-linux-gnu/libgcc_s.so.1  rm $home/.local/share/steam/ubuntu12_32/steam-runtime/i386/usr/lib/i386-linux-gnu/libstdc++.so.6   run steam again, this time it will start with:     updating steam...   once successfully updated you will need to remove those two files again.  now you are done, you may launch steam and log into your account.  i'm afraid you will have to repeat those two files deletion once the steam client gets updated again, until they fix it, at least. 
normally on stackexchange sites, answers are supposed to be comprehensive and not merely link to other resources
ctrl-q  to disable this altogether, stick stty -ixon in a startup script
you can also do this using awk, paste, and bc
the correct answer depends on which terminal you are using.  for gnome terminal or recent versions of xterm, put this in ~/.inputrc:  "\e[1;5c": forward-word "\e[1;5d": backward-word   for putty, put this in your ~/.inputrc:  "\eoc": forward-word "\eod": backward-word   for rxvt, put this in your ~/.inputrc:  "\eoc": forward-word "\eod": backward-word   you can probably get away with putting all of those together in ~/.inputrc.  in all cases, you also need to put this in your ~/.bashrc (or ~/.zshrc):  export inputrc=~/.inputrc   if that doesn't work, or you have a different terminal, go to your terminal and type ctrl+v ctrl+->
egrep returns non-zero if no lines were matched. 
by far the best way is to use public/private key pair authentication
for this card, i should think is nouveau driver
i have the same network hardware in my laptop running ubuntu 10.10 maverick.  for the wireless adapter, you need the binary broadcom sta proprietary drivers
from understanding the linux kernel:     in linux, process priority is dynamic
use systemd-analyze built-in tool
it turns out mplayer was removed from the machine. 
there is no need at all for you to use the default shell for a given system
in this case the card is always the same
your first task would be to connect both disks to an existing linux system or connect the new disk to the original system.  you must be very careful since it is very simple to copy the blank disk on top of the good disk!  to end up with the boot sectors and all, you would do something like:  dd if=/dev/hdx of=/dev/hdy   where hdx is your 40g disk and hdy is your 160g disk
at least with ristretto 0.6.3, there's a preference for that
truecrypt, or another encryption method, is probably the way to go with this. 
there are a few things that need to be in place
my answer is only related to the line  sudo jupiter=(all)nopasswd:/bin/&lt;script&gt;     with this line you allow user sudo to run /bin/&lt;script&gt; on host juptier as any user without authentication
this should work with most shells and most oses:  $ ps -o comm -p $$ | tail -n -1 ksh93   edit: after reading the duplicate link, here is a simpler way that avoids the tail command.  $ ps -o comm= -p $$ ksh93   
if the threat model is focused on files and x access, files should be handled by creating a new user/group, and making sure file permissions are restrictive enough this user/group cannot access anything important.  restrictions to x can be handled by starting a virtual x server (e.g
the general answer is: you can not
try out multitail
with sed:  sed -e n\;d &lt;file   with posix awk:  awk 'fnr%2' &lt;file   if you have older awk (like oawk), you need:  oawk 'nr%2 == 1' &lt;file   with ex:  $ ex file &lt;&lt;\ex :g/$/+d :wq! ex   will edit the file in-place.   g mark a global command /$/ match every lines +d delete the next line wq! save all changes   this approach share the same ideal with sed approach, delete every next line of current line start from line 1.  with perl:  perl -ne 'print if $
according to /usr/share/doc/hashdeep/readme.md.gz, it's all one executable that acts differently depending on the name of the called program
from the discussion in the bug linked in daniel bruno's answer .
there is no universal answer here....as the output from a given command is the responsibility of the author of that particular program not anything in the linux operating system or any of the shells
keybinding can be done using one of the following forms:   keyname: command_name "keystroke_sequence": command_name   in first form you can spell out the name for a single key
the escapeshellarg docs say it turns it into: "a single safe argument"  but you want it to be interpreted as multiple arguments.  try doing the expansion using glob first. 
there are several things that you could do here
systemd has native support for mounts (man systemd.mount)
you can use false (/bin/false, /usr/bin/false, or shell builtin):  $ false || echo it failed. it failed. $   you can also use exit 1 from a subshell:  $ (exit 1) || echo gosh, it failed too. gosh, it failed too. $  
pdcp from the pdsh package is one option
if you add up mem% for all the identical looking chrome processes, then you have well over 100%, which is impossible
that's because ldd is actually a script that calls /lib/ld-linux.so.3 with the executable as argument and ld_trace_loaded_objects=1 in its environment, so /lib/ld-linux.so.3 reports itself as the dynamic linker.  instead, you can run  ld_trace_loaded_objects=1 /root/m2/m2/stagingarea/armv7l-linux-ubuntu-12.04/bin/m2.tmp   directly, in which case that will be the dynamic linker that you specified that will dump the libraries and itself. 
in latest ubuntu which ships lightdm, that supports a guest account,   so install lightdm and replace gdm should work for you, which would do the exactly same thing in ubuntu 12.04:  apt-get install lightdm 
proper sas/sata connectors are hot plug safe, so as long as you are using those connectors both for data and power ( not the usual pc molex power connector ) then you won't hurt anything plugging them in. 
your best bet if on a gnu system:  stat --printf="%s" file.any   note: see @chbrown answer below how to use stat in terminal on mac os x  or  #!/bin/bash filename=/home/heiko/dummy/packages.txt filesize=$(stat -c%s "$filename") echo "size of $filename = $filesize bytes."  
with openbsd's implementation of tcpwrappers, i think you need to include each of your addresses in /etc/hosts.allow, which, with 10k entries, will very soon get very unwieldy.  all : ..
the cause of this may be in a way related to lxde but not directly: it is the xfce's session manager that seems to be the real problem, and switching between different de sessions might have triggered this
with awk:  awk ' {print;} nr % 2 == 0 { print ""; }' inputfile   with sed (gnu extension):  sed '0~2 a\\' inputfile   with bash:  #!/bin/bash lines=0 while ifs= read -r line do     printf '%s\n' "${line}"     ((lines++ % 2)) &amp;&amp; echo done &lt; "$1"  
using a script to monitor ntpd is not commonly done
you can use pam_exec to invoke an external command
you could use the iconv character set conversion gnu utility. here's an example:  iconv --from-code=utf-8 --to-code=mac  inputfile &gt; outputfile  where inputfileand outputfile are the names of your original and converted file (which may be the same)
well, from the top (the parent of the arndell, claremont, and monte) directories you could type:  ls */*/{weekly,daily}   which expands to:  ls */*/weekly */*/daily   which would show you the contents of all the weekly and daily directories. 
ok, turns out the answer was staring me in the face.  firstly, whether using our custom driver, or using the generic one that normally takes over the device, it's still all ultimately controlled by hid, and not usb.  previously i tried to unbind it from hid, which is not the way to go
if you do the following:  ls | grep -f -v ' '   you will not see any file with spaces in the names  ( i used to have fgrep instead of grep -f in the example, but as hauke laging pointed out that is deprecated) 
you need to specify additional argument you already know about (as you named your instances by using it):  $ vifm --help | grep -a1 server-name   vifm --server-name &lt;name&gt;     name of target or this instance.   note this part:     name of target ..
there's only winnr(), which is a sequential numbering; i.e
files is a symbolic link to /media/files/tb-prod/files
you should be able to do this in the same shell you're in with the wait command:  $ sleep 30 &amp; [1] 17440  $ wait 17440 &amp;&amp; echo hi  ...30 seconds later... [1]+  done                    sleep 30 hi   excerpt from bash man page  wait [n ...]      wait for each specified process and return its termination status
as you mentioned, btrfs can do this
have a look at the file $home/.local/share/applications/defaults.list  there is a section [default applications] to specify the programs for particular mime types
for the resize2fs bit, it's like this:  e2fsck -f /dev/myvg/lvtest resize2fs /dev/myvg/lvtest 96m #always a bit smaller than the lv  ### then the rest as above lvresize -l 100m /dev/myvg/lvtest vgreduce myvg /dev/sdx  ###then regrow that to fit the volume perfectly  lvresize -l 100% /dev/myvg/lvtest resize2fs /dev/myvg/lvtest    i hope you're on ext2/3/4 
as mariusmatutiae mentioned you have to modify the unit file (or disable it)
you're reaching the limit of the precision of awk numbers.  you could force the comparison to be a string comparison with:  awk -v num1=59558711052462309110012 -v num2=59558711052462309110011 '   begin{ print (num2""==num1) ? "equal" : "not equal" }'   (here the concatenation with the empty string forces them to be considered as strings instead of numbers).  if you want to do numerical comparison, you'll have to use a tool that can work with arbitrary precision numbers like bc or python. 
grep -f &lt;(printf "%x\n" $(seq -f "%.f" $(printf "%d %d" 0x1234ab00 0x1234b0ff))) file    the inner printf prints decimal values of the two hex values. then seq prints all between them, in decimal. the outer printf prints hex values for all those decimal values. and finally grep -f searches for all those patterns in the file.     the output:  blah;pc=1234abcd pc=1234abff  
one problem with your first command is that you redirect stderr to where stdout is (if you changed the $ to a &amp; as suggested in the comment) and then, you redirected stdout to some log file, but that does not pull along the redirected stderr
you can use paste:  $ :|paste -d',' file1 - | paste -d' ' - file2 1, john 2, sam 3, george 4, ken   or:  $ :|paste -d', ' file1 - file2  
in gnome, you would press and hold down ctrl+shift, then type u201c.  of course, that won't work in gnome terminal if ctrl+shift+c is bound to copy, in which case type it in gedit and paste it in, or learn how to enter it in your editor of choice. 
correct answer by meuh: have double quotes and escape them like   sudo sed -i.bak  \     "${pos[1]}i\ include \"level3(ralt_switch)\"" /usr/share/x11/xkb/symbols/us  
parsing the output of ls is always problematic
three things.   you are running centos 5.2
ok, as stephen kitt said there is no ready to use traceroute binaries for cygwin
man du itself mentions:  -x, --one-file-system               skip directories on different file systems   so something on the lines of   du -xm * | sort +0nr | head -30   will do the trick, at least if you are using du from gnu coreutils (mine is version 8.20)
probably because you do not use the userdel command as superuser (root) or other privileged user
thanks for the replies, actually it worked by itself :d  i had to create the hotspot via networkmanager, and then start lampp, or the other way, the order doesn't matter.  the problem was that i tried to access localhost, instead of the my ip :d so after i tried to access my ip, it worked as desired
this is not really a unix answer, but if you don't mind leaving it running in the browser:  window.setinterval(function () {     document.getelementsbyname('generate_daily_trends')[0].click(); }, 1000); // 1000 milliseconds   and if you want a bookmarklet that you can click to get it going (once you're already on the page), add this for the bookmark url:  javascript:(function() {     window.setinterval(function () {         document.getelementsbyname('generate_daily_trends')[0].click();     }, 1000); }());  
take a look at the output of udevadm(8)
from the byobu documentation:   see: status notifications  here's a few samples from the documentation:     cpu_count - the number of cpu's or cores on the  system;  displayed  in the lower bar toward the right in the default text color   on the default background, followed by a trailing 'x'      cpu_freq - the current frequency of the cpu in ghz;  displayed  in  the lower bar toward the right in white text on a light blue   background      disk_io  -  instantaneous read/write througput in kb/s or mb/s over the last 3 seconds; displayed in the lower bar toward the  right    in  white text  on  a  light purple background with a leading '&lt;' sign   indicating 'read speed' and  '>'  sign  indicating  'write  speed';    override  the default   monitored   disk  by  specifying  an    alternate  device  with monitored_disk=/dev/sdb, and override the   default  disk_io_threshold=50 (kb/s) in $byobu_config_dir/statusrc  
first i will try to help with ansible
that device has the same blocks, used and free space as your rootfs filesystem, so they are probably the same
imho, its a bad idea to split the 50tb file system into smaller chunks because it introduces problems at a later time: either the partitions are too small, or you have to use something like lvm to be able to resize your partitions later
the gnu coreutils manual gives some example applications such as collapsing multiple newlines into one (tr -s '\n'), or putting each word on its own line while removing punctuation at the same time (tr -cs '[:alnum:]' '[\n*]'). 
first test bzip2 compression, it should output ok.  bzip2 -tv file.tar.bz2   next uncompress the tarball, to get just the tar.  bunzip2 file.tar.bz2   finally verify the tar file,   tar -tvfw file.tar   truthfully the best indicator of a problem, is a failed extraction
editing a disk image is possible, but very risky
echo "tsa_15_20161014_11-12-50" | awk -f'_' '{print $3$4}' | tr -d -   echo the var in which the string is stored  explanation:  awk -f'_' '{print $3$4}' change the field separator to _ and print the 3rd and 4th column  the output is 2016101411-12-50  tr -d - deletes - from the previous result
you should nslookup the ip
relaying on date might be tricky, however, what about  cd /usr/share/doc  ## less that 365 dyas find 
the vc is the virtual console which is also known as a virtual terminal vt
change:  filter &gt; /app/me/logs/${1}.filtered   to:  filter "$@" &gt; "/app/me/logs/${1}.filtered"   why? each function has its own list of positional parameters
if you want to move it from daily to monthly run, you need to use mv and not cp as otherwise you would simply add a monthly run. sudo mv /etc/cron.daily/0yum-cron /etc/cron.monthly/0yum-cron should do what you're asking for. 
it looks like your output is in some way encoded
you need to quote the eof marker, eg &lt;&lt;\eof or &lt;&lt;'eof' to stop your $filename variable from being evaluated before it is passed to the remote
you already have a great sed approach so here's a perl way:  $ perl -00ne 'print if $.&gt;1' file    the -00 turns on "paragraph mode" where a line is defined by \n\n
on linux you can look through the /proc filesystem specifically for a given pid under /proc/&lt;pid&gt;/fd
ls -l /sys/block/blockdevice  should tell you the complete path to the device, including the pci bus
when ping works you probably have a firewall rule on the vm which blocks port 80.  firewall-cmd --get-active-zones to get the zone argument.  firewall-cmd --zone=zone --add-service=http --permanent to open the port.  firewall-cmd --reload to activate the rule.  you could substitute --add-service=http with --add-port=80/tcp. 
like many unix applications, atlas has a configure script that you run as first part of the build process
i'm done, and the re-partition worked
try adding this to your vimrc:  nmap &lt;buffer&gt; &lt;silent&gt; &lt;expr&gt; &lt;f12&gt; insertcol() imap &lt;buffer&gt; &lt;silent&gt; &lt;expr&gt; &lt;f12&gt; insertcol()  function! insertcol()     let w:first_call = exists('w:first_call') ? 0 : 1     "if w:first_call     "    startinsert     "endif     try         let char = getchar()     catch /^vim:interrupt$/         let char = "\&lt;esc&gt;"     endtry     if char == '^\d\+$' || type(char) == 0         let char = nr2char(char)     endif " it is the ascii code.     if char == "\&lt;esc&gt;"         unlet w:first_call         return char     endif     redraw     if w:first_call         return char."\&lt;esc&gt;gva\&lt;c-r&gt;=redraw()\&lt;cr&gt;\&lt;f12&gt;"     else         return char."\&lt;esc&gt;gvla\&lt;c-r&gt;=redraw()\&lt;cr&gt;\&lt;f12&gt;"     endif endfunction  function! redraw()     redraw     return '' endfunction   then press ctrl-vi as usual, and then press f12
sounds like you're trying to re-implement grep, there. instead of sed just use:  grep -n -- "$var" file   if var contains regex metacharacters that you want to match literally, supply the -f option to grep:  grep -nf -- "$var" file   where var contains your desired pattern.  from the grep(1) man page:     -n, --line-number      prefix  each  line of output with the 1-based line number within      its input file
in bash you can use the syntax  str=$'hello world\n===========\n'   single quotes preceded by a $ is a new syntax that allows to insert escape sequences in strings.  also printf builtin allows to save the resulting output to a variable  printf -v str 'hello world\n===========\n'   both solutions do not require a subshell.  if in the following you need to print the string, you should use double quotes, like in the following example:  echo "$str"   because when you print the string without quotes, newline are converted to spaces. 
the easiest way i can think of, since the line in question is a command, is:  `$easy_install 2&gt;&amp;1 | grep sudo`   the backticks or $(…) take the output of a command pipe and execute it as if you typed it, returning the output.  please note that this command won't work if you're missing sudo and trying to install it
stratum (st): how close the server is to an actual reference time source  offset (ms): the time your system clock is off the time server  delay (ms): how long the response took to get here and back (rtt)  jitter (ms): difference between 2 samples  reach: number of syncs    you should use the europe ntp servers because:   you have a lower delay lower average stratum likely lower jitter (the above output for the ubuntu servers only did one sync, so no jitter)   you should not use the europe ntp servers because:   you wish to run your own time server (at stratum 3) you are syncing with other time servers (all your other servers in europe) from your time server     instead i would head over to www.pool.ntp.org and look at their list of stratum 2 time servers and configure a few of these manually
microkernels require less code to be run in the innermost, most trusted mode than monolithic kernels
you can do this with gawk:  echo "ciência" | gawk '{x = toupper($0); print x;}'   (also perl, someone is certain to point out) 
you can just disable gdm service:  sudo mv /etc/init/gdm.conf /etc/init/gdm.conf.off  
if kmail fails to send e-mail it will save it in local folders "outbox", not the imap outbox
well, i want to share this workarround, i think is not so elegant as i wanted but it works.  first create a file and call it as you want i.e fwsrv  #!/bin/bash # author: francisco tapia # # /etc/init.d/fwsrv # ### begin init info # provides:          fwsrv # required-start:    network # should-start:      $null # required-stop:     $null # should-stop:       $null # default-start:     5 # default-stop:      5 # short-description: executes iptables rules. # description:       this is not a service. ### end init info  
with awk:  $ awk '$0 = $0 " " $nf ($nf ~ /\.$/ ? "" : ".") "com"' &lt;file 127.0.0.1   localhost localhost.com 1.2.3.4 hostname1 hostname1.xyz hostname1.xyz
your kill command is backwards.  like many unix commands, options that start with a minus must come first, before other arguments.  if you write  kill -int 0   it sees the -int as an option, and sends sigint to 0 (0 is a special number meaning all processes in the current process group).  but if you write  kill 0 -int   it sees the 0, decides there's no more options, so uses sigterm by default
$ awk 'nr==fnr{a[$1]=$0} $1 in a &amp;&amp; $2 in a &amp;&amp; $3 in a{print a[$1] ors a[$2] ors a[$3]}' file1 file2 strawberry fruit 22 11 straw thing 2 33 berry fruit 33 33    save lines based on first column of file1 and then print matching lines if all three columns of file2 lines match  
in general, xml processing should be done with an xml parser.  update: in fact, i think it's unfortunate that this answer was picked as the "accepted answer" since @satokatsura's answer is in all ways correct and better
you are trying to boot without an initramfs
using the standard syntax (since the op mentioned solaris):  sed 's/^\([[:blank:]]*\)\.*/\1/;s/\.*\([[:blank:]]*\)$/\1/'   on solaris, as usual, you may need to call /usr/xpg4/bin/sed or command -p sed 
like traditional unix file systems, ext2, ext3 and ext4 have a segment of metadata called a superblock, which contains information about the configuration of the file system
the fact that you can do something in bash doesn't mean that you should
ps is annoying that way
if you use mv --backup=numbered   (or one of the other options for the --backup switch), then mv will complete the merge and preserve the files intended to be overwritten. 
if you know that none if the file names contain new lines, tabs, spaces or glob combinations that may produce a match, this may be easier for a one off case:  mv $(grep -l attachments *) dest_dir  
the boot flag is from ancient times, where you would indicate an mbr partition record as bootable, so you could indicate where the boot loader resided.  on modern os'es this is widely unused, as the mbr consists of a minimal stage loader which bootstraps either into its own partition or jumps to another area on the disk where the boot loader code is kept
i suppose the uri ends with a space: grep -o 'magnet://[^ ]*' filename  update: grep -o "magnet:?xt[^']*" filename  update: cat * | grep -o "magnet:?xt[^']*" or grep -oh "magnet:?xt[^']*" * 
i had to do this on my old laptop, (hp g6 with rt5390).  many of the fields stay blank, including ssid i had once upon a time populated this, but it wasn't needed.  the main thing to do was there were a couple of files that needed editing pre-build.  i booted up my old laptop to check..
in python, start with the input file as an argument:   import sys  res = []  # list of lists for line in open(sys.argv[1]):     try:         x, y = line.split()  # split on space     except valueerror:         line = line.rstrip()         x, y = line.split(',')  # retry with comma     for l in res:         if x in l:             if y not in l:                 l.append(y)             break     else:         res.append([x, y])  for line in res:     print ' '.join(line)   the test if y not in l: skips adding the same value twice, i am not sure if that is wanted, or if the source has such anomalies
the source code for lesskey says:   * copyright (c) 1984-2015  mark nudelman   which gives a hint that performance might have been a factor in deciding to use a compiled configuration file
you can do   curl -l  http://downloads.sourceforge.net/project/romfs/genromfs/0.5.2/genromfs-0.5.2.tar.gz &gt; genromfs.tar.gz   to download the file.  the -l tells curl to follow any redirects, which sourceforge normally does.  if wget is available, that would be far simpler. 
when writing complex one liners in bash, it is handy to use readline's edit-and-execute-command (bound to c-xc-e by default in emacs mode)
you can use macros which alternate font styles:  .br bold .   will produce     bold.   there are other variants, .bi, .ir..
the -prune action makes find not recurse into the directory
you can express those conditions using regular expressions and use grep to filter the results based on those.  the first one is ^?
i found no way with xprop
if you're using man on linux to generate the output (e.g
if your program spawned another process which for some reason doesn't respond, the easiest way is to kill the unresponsive process
not very difficult.  dd if=/dev/dvd of=saved.iso  for i in {1..20}; do     eject /dev/dvd     read -p 'insert disc and press return: '     eject -t /dev/dvd     growisofs -z /dev/dvd=saved.iso done eject /dev/dvd  
if this satisfies you, here is proposition how to do this using pipes.  assumption is that input and output files of "badtool" can be pipes.  mkfifo if mkfifo of  # one therminal tool | tool2 |..
the best way to remove such unmet dependencies that you do not want to satisfy is to use:   apt-get purge  purge ensures that any configuration files in relation to the package are deleted as well
there are several ways
i found out the answer by asking on the mailing-list.  btrfs doesn't do raid per-volume, but rather on a per-chunk basis
you can't force a remote client to attempt to authenticate, because you don't know until the rcpt to: whether the client is attempting to deliver an email to your server (which doesn't require authentication unless you have a very unusual configuration like only accepting mail from known mail servers) or it is trying to relay through your mail server without authorisation.  the rcpt to stage of an smtp session comes well after any auth negotiation (if any). 
it's hardcoded, but you can override the defaults by the kernel parameter init=....  from init/main.c:  if (execute_command) {   run_init_process(execute_command);   printk(kern_warning "failed to execute %s
i always run services with a dedicated user
we can simplify this to a single loop, just by passing all the filenames in a single go:  #!/bin/bash  for file in /users/connor/documents/github/whatthepdf/dat/{forms,data,maps,none}/*.pdf do   echo "${file}"   destfile="${file/.pdf/_source.txt}"   echo "${destfile}"   qpdf --qdf --object-streams=disable "${file}" "${destfile}" done   for readability we might split this out a little  eg cd to the directory and abort if it fails:  #!/bin/bash  cd /users/connor/documents/github/whatthepdf/dat || exit 255  for file in {forms,data,maps,none}/*.pdf do   echo "${file}"   destfile="${file/.pdf/_source.txt}"   echo "${destfile}"   qpdf --qdf --object-streams=disable "${file}" "${destfile}" done  
with gnu sed  $ sed ':a;n;$!{/\n$/!ba}; s/[[:blank:]]*\n[[:blank:]]*/ /g' textfile start of p1 continued p1 end of p1
it's generally bad practice to put sudo in a script
zsh has a preexec hook that executes a function before a command entered on the commandline is executed
you want to use posix acls for this, if you can't create sensible groups
you forgot to post both scripts
your apparent question: testing the existence of a process with a given pid  ps -p $pid is posix and should work on any modern non-embedded unix (not antiques or minix or busybox).  a simple and portable way to test whether there is a process by a given pid is kill -0 $pid
is there something wrong with listing the files you'd like to add to the .tar file?  $ tar cvf some.tar file1 file2 file3   example  $ tar cvf some.tar serveralert.log page.html serveralert.log page.html  
od has the --width=n argument, which you can use to choose how many bytes per line, perhaps that's what you're looking for?  hexdump has a -e formatstring which has promise, but i've never played too much with it. 
executable=mysql  executable_path=$(command -v -- "$executable") &amp;&amp;   dirname -- "$executable_path"   (don't use which).  of course, that won't work if $executable is a shell builtin, function or alias
you can use bash trap err to make your script quit if any command returns status greater than zero and execute your function on exiting.  something like:  myfunc() {   echo 'error raised
line 1: your hashbang line is not correct, use:  #!/bin/bash   line 3: take care with the test utility (it needs a space before the closing ]):  if [ -f keyfile ]   line 5: in the sed command, use -i to activate in-place editing of sed, else the edits are only printed to the stdout:  sed -i 's/[0-9][0-9]nm/okay/g' keyfile  
with gnu tools:  find 
that's an interesting observation; the only concrete evidence i could find, so far, is this scap mailing list thread talking about the change from rhel5's default permissions of 0400 to rhel6's default of 0
you can login as the user or simply su from root to the user and run the command     history    you can also search history quite easily  history | grep "what ever"   finally you can use  ctrl+r {whatever}  
you should be able to download the source code with  wget https://www.kernel.org/pub/linux/kernel/v3.x/linux-3.16.7.tar.xz   then you need to extract it   tar xpvf linux-3.16.7.tar.xz   then cd into the correct directory  cd linux-3.16.7/drivers/bluetooth   when you post the result of lsusb i should be able to finish this answer  gedit btusb   go to the end of line 116 which should be { usb_vendor_and_interface_info(0x0489, 0xff, 0x01, 0x01) },  press enter key twice, then tab once and paste this in  /* lite-on technology - broadcom based */     { usb_vendor_and_interface_info(0x04ca, 0xff, 0x01, 0x01),       .driver_info = btusb_bcm_patchram },  check the spacing and format to see if it matches the other entries, then save and exit gedit.  then we can copy some configuration files into the directory  zcat /proc/config.gz &gt; .config   now we can build the bluetooth modules with  make -c /lib/modules/$(uname -r)/build m=$pwd modules   when they are compiled we can copy the btusb.ko to the kernel directory  sudo cp btusb.ko /lib/modules/$(uname -r)/kernel/drivers/bluetooth/ cd /usr/lib/modules/$(uname -r)/kernel/drivers/bluetooth/ gzip btusb.ko   this bluetooth device needs firmware  cd ~ wget https://www.dropbox.com/s/xbmm9vfg2fby2zn/fw-04ca_2006.hcd sudo cp fw-04ca_2006.hcd /lib/firmware/   then we can unload btusb and load it so that the new version is loaded  sudo modprobe -r btusb sudo modprobe btusb  
does  wsconsctl keyboard.encoding=us   work?  if yes, put that in /etc/wsconsctl.conf to make it persistent.  or are you saying that that would only work for ps/2 keyboards?  maybe enabling usb legacy keyboard mode in the bios would help in that case?  wsconscfg -k   may also be of use.  perhaps you need to change the device from  /dev/uhid0   to something like  /dev/wskbd0   or  /dev/wskbd1  
in fact mkisofs 2.01 points to genisoimage:  $ mkisofs --version mkisofs 2.01 is not what you see here
sideways answer, os x-specific in this case.  one option, and the one that i used in the end in this case, was as follows:  use something to launch screen locally, which will work, and then re-attach to the session.  i wrote a python program that generates and runs an apple script program which opens a new terminal.app window and runs the command you asked for, even when you're over ssh (obviously, the account must be logged in in a gui on the machine itself for this to work).  it is called "osxhijack" and it's on github here
curl file:///dev/fd/0   is the correct way to make curl read from file descriptor 0 (stdin).  take any readable textfile, do  &lt;thetextfile.txt curl file:///dev/fd/0   and it should work just like cat.  your problem is "how do i make curl read from a pipe?" and i'm afraid the answer is: patch curl's source code.    if you analyze the strace of curl on the example up top, you'll see it mmaps the file
this kind of thing should not be done in (pre|post)|(inst|rm) scripts
from the output, the links are all to ~/third-party-source/openssl/crypto
that depends on the filesystem
thanks to the ideas from comments and other sources i was finally able to write this code and answer my own question:     inputstream | awk -f'\t' -v ofs="\t" '{             if ( col1 == ""){                 for (i=1;i&lt;=nf;i++){                     if ($i == "blueid"){                         col1=i;                     }                     else if ($i == "whiteid"){                         col2=i;                     }                 }             print "-1" "\t" "-1" "\t" $0             }             else {                 print $col1 "\t" $col2 "\t" $0             }         }' | sort -k1,1n -k2,2n | cut -f3- | outputstream   it works like this: it takes stream data, finds desired columns' numbers and prints in front of every row both values needed to sort
for a running process you can do this:  pid=5462 command ps -p "$pid" -o etime command ps -p "$pid" --no-headers -o etime   as a general feature you can modify your shell prompt
this is documented in section 28.9, "seconds since the epoch" of the gnu coreutils info page:  info coreutils 'seconds since the epoch'   i am including the first paragraph here: the section reads:     if you precede a number with `@', it represents an internal time stamp   as a count of seconds
systemd-nspawn --network-interface=ppp0   ppp0 will disappear from the host namespace
the answer was that the demo version is mounted to a ram disk.  so yes - you must build the image
mount itself has an autodetection option, -t auto, you can always try that.  to check the type of some file, i usually find file to be a pretty good tool, perhaps file -k if you want to be sure it does not stop at the first match
scripts in the /etc/rc?.d directories that start with s are used to start services
a desktop-environment-agnostic open utility is xdg-open, which could fill your need
a gnu (bash, wc and find) solution which works with any path, even those containing spaces, newlines or starting with a dash:  shopt -s nullglob for dir in ./*/ do     printf '%s\n' "$dir"     find "$dir" -mindepth 1 -printf x | wc --chars done   explanation:   the nullglob option prevents errors if ./ contains no directories. the ./ in the directory glob ensures that file names starting with a dash ("-") won't mess up echo or find. the slash at the end of the glob ensures that only directories are processed. -mindepth 1 avoids counting the directory itself. if you want to include directories which start with a dot on the top level, you should run shopt -s dotglob before the for loop.  
hex:  printf '\x4a'   dec:  printf "\\$(printf %o 74)"   alternative for hex :-)  xxd -r &lt;&lt;&lt;'0 4a'  
awk can replace the entire script pretty easily:  #!/usr/bin/awk -f  /sync/ {synccount++} /paused/ {pausecount++} /copying/ {copyingcount++}  end {     if(synccount == 11)         print "all 11 mirrors are in sync."     else         print (+pausecount) " mirrors are paused and " (+copyingcount) " mirrors are syncing." }   the (+var) is to force awk to treat the variable as a number (so it will output 0 if the variable was unset)
   question #1: when the documentation says "log it to the system log once, then immediately reject it and forget about it" what do they mean by forget about it?   means that the message will show up in the logs, but only once, so your log won't get polluted with a continuous stream of messages every time the rule is triggered.     question #2: forget about it forever?   no not forever
this works (code edited to get the value for only the default user):  awk -f'= ' '/default:/,/umask =/{ if(/umask =/){ print $2 } }' /etc/security/user   -f sets the input field separator
a shell script is a program
the difference may be seen via strace:  $ strace -ff -o bq watch sh -c 'ls\ /tmp/|wc -l' ^c $ strace -ff -o nobq watch sh -c 'ls /tmp/|wc -l' ^c $ grep exec bq* | grep sh bq.29218:execve("/usr/bin/watch", ["watch", "sh", "-c", "ls\\ /tmp/|wc -l"], [/* 54 vars */]) = 0 bq.29219:execve("/bin/sh", ["sh", "-c", "sh -c ls\\ /tmp/|wc -l"], [/* 56 vars */]) = 0 bq.29220:execve("/bin/sh", ["sh", "-c", "ls /tmp/"], [/* 56 vars */]) = 0 $ grep exec nobq* | grep sh nobq.29227:execve("/usr/bin/watch", ["watch", "sh", "-c", "ls /tmp/|wc -l"], [/* 54 vars */]) = 0 nobq.29228:execve("/bin/sh", ["sh", "-c", "sh -c ls /tmp/|wc -l"], [/* 56 vars */]) = 0 nobq.29229:execve("/bin/sh", ["sh", "-c", "ls", "/tmp/"], [/* 56 vars */]) = 0   in the backquote case, ls /tmp is passed as a single argument to the -c to sh, which runs as expected
with gnu awk (this also retains original order)  printf '%s\n' "1 2 3 2 1" | awk -v rs='[[:space:]]+' '!a[$0]++{printf "%s%s", $0, rt}' 1 2 3    to read into a bash array  read -ra arr&lt;&lt;&lt;$(printf '%s\n' "1 2 3 2 1" |  awk -v rs='[[:space:]]+' '!a[$0]++{printf "%s%s", $0, rt}') printf "%s\n"  "${arr[@]}" 1 2 3  
there is a unix command called last that will list the last times and sources of all the logins to the system
here's a quick python program that should output your desired schema, using recursion
ebuilds are the right way to package an application in gentoo
since i nolonger have this problem i'd like to share my solution:  i've daemonized the python script. this enabled me to open the serial connection on start-up of the script and then read the serial-port data every ten seconds.  no more overruns since.  code of the script is here on github 
screen or tmux  sure you can start processes and have then run continuously by making use of a terminal multiplexer such as screen or tmux
you can try something along the lines of this:   $ cat script.sh  while sleep 1  do      eval "$@"  done  $ ls  $ sh script.sh !!   the script will run the command passed to it over and over again
the cleanup script can look something like   sed -i '/^# do not edit.*\|^# (.*/d' /tmp/crontab.user   because your version of cron at least puts # do not edit and # ( in at the header part and you never use things that start like that in any of your managed code (and if anyone else does, they'll be sorry) 
using aptitude --sort parameter  theoretically you should be able to use aptitude's search and sort facilities directly – sadly there seems to be a bug that causes aptitude to output packages with state c (deleted packages with configuration files still on the system) last and in a rather unsorted order:  aptitude -f '%p %i' search '!~v' --sort "installsize"   where -f is used to tell aptitude how to format the output: %p is the package name, %i the estimated install size
it's so much easier with zsh globs here:  for f (**/*.xml(.)) (mv -v -- $f **/$f:r:t(/[1]))   or if you want to include hidden xml files and look inside hidden directories like find would:  for f (**/*.xml(.d)) (mv -v -- $f **/$f:r:t(d/[1]))   but beware that files called .xml, ..xml or ...xml would become a problem, so you may want to exclude them:  setopt extendedglob for f (**/(^(|.|..)).xml(.d)) (mv -v -- $f **/$f:r:t(d/[1]))   with gnu tools, another approach to avoid having to scan the whole directory tree for each file would be to scan it once and look for all directories and xml files, record where they are and do the moving in the end:  (export lc_all=c find 
execute:  grep flags /proc/cpuinfo  find 'lm' flag
the command you're getting when you ran which is a a function, called prompt
you can use xcape under x11 to configure shift to emit e.g
no, it doesn't
see how do keyboard input and text output work? for an overview of the topic.  in more detail, under linux, the kernel receives scan codes from the hardware and converts them into keycodes
here's a perl script that folds stdin on words (i.e
thunar internally uses tumbler for the thumbnail generation
use the regex end-anchor ($), e.g.:  echo "$file" | grep '\.xml$'   to find all files ending with "xml", i would suggest using the find command, e.g.:  find 
pretty much any distro (kali included) can be used as a decent desktop
regular languages (i.e
when you need to manipulate data in fields, awk tends to fit the bill quite nicely:  awk '$2 == "active" { print $1 }' test   this reads each line of test, splits it into fields, then checks if the second one ($2) is active; if so, it prints the first field. 
as improbable as it might seem, putty does this in response to a combination of characters.  putty recognizes many (by no means all) of the escape sequences used for xterm, linux console and some less familiar terminals
this can be achieved with the command  find -samefile filename -exec sed -i ';;' {} \;   or if you now the inode number of the file  find -inum inode -exec sed -i ';;' {} \;   note both these commands only find the files with matching inodes in subdirectories of the current working directory
you can use sleep with while loop as follows:  while true; do echo "1" &gt; /sys/kernel/mm/ksm/run; sleep 120; echo "0" &gt; /sys/kernel/mm/ksm/run; sleep 7200; done;   here, while loop starts with condition while true; that means no condition for stopping loop (it runs forever until script is killed) then commands will be run (with sleeping as you wish) at done; loop will be redirected to condition that is while true; thus, it will again start executing commands.  note: with gnu sleep you can also use sleep 2m, sleep 2h etc. 
i assumed that cron was the only way to achieve my goal, but i was wrong because cron is for starting background jobs
hm, it was easier than i thought:   in the build memcached-1.4.27/script directory there is the file memcached.service copy this into the /usr/lib/systemd/system directory which contains all service files. create in the /etc/sysconfig directory the environment file memcached - as referenced in memcached.service with the following content in order yast and the system can start memcached:   example of the memcached file:  port=11211 user=root cachesize=1000 maxconn=1024   that's it
on linux systems using gnu libc, lines starting with # are ignored in /etc/shadow
lvm itself doesn't care what the underlying storage is: sata, scsi; hdd, ssd; local, networked; physical, virtual; etc.  different types of disks have different performance characteristics, so you may want to put the different types of disks in different groups anyway
no
the answer to this question depends on what version of grub you are using
in general, you should use the distribution's package manager (apt) to install software, and proper configuration management tools (eg, ansible/chef/puppet as mentioned in a comment, or debian's local debconf) to propagate site-specific information and files
top will not do this by itself, but you could write a simple shell script which runs top in batch mode (the -b option), filtering that using grep, and in a loop
what i recommend doing has been mostly described in this ask ubuntu question.  for this particular case i would install suphp which in short allows you to execute php scripts as your user under apache.  by doing the following:  sudo chown -r youruser:youruser /var/www find /var/www/ -type d -exec chmod 0755 {} \; find /var/www/ -type f -exec chmod 0644 {} \;   install suphp-common and libapache2-mod-suphp from this ppa (what are ppas and how do i use them?)  disable mod_php5 and enable mod_suphp  sudo a2enmod suphp sudo a2dismod php5   update your virtual hosts to include this line at the bottom of them:  suphp_usergroup youruser youruser   replacing youruser with the user you use to edit files on the server
if you're only interest is in downloading a package + its dependencies for offline installation you can use the tool yumdownloader
search for a line that starts with projdir, and replace the whole line with a new one:  sed -i 's/^projdir .*$/projdir pacman/' .ignore   ^ and $ are beginning/end-of-line markers, so the pattern will match the whole line; .* matches anything
the current gstreamer0.10-ffmpeg 0.10.12-1 provides both an en- and decoder for g722:  $ gst-inspect-0.10 | grep 722 ffmpeg:  ffenc_g722: ffmpeg g.722 adpcm encoder ffmpeg:  ffdec_g722: ffmpeg g.722 adpcm decoder rtp:  rtpg722depay: rtp audio depayloader rtp:  rtpg722pay: rtp audio payloader  
you should be able to permanently add an exclude rule by adding it to your /etc/yum.conf file
the shell starts both, to establish the ends of the pipe, so ps sees itself as well as the process at the other end of the pipe. 
the process that writes to the page gets a new copy
off-the-cuff answer, assuming the files are sorted:  awk '{$2= -$2; $3= -$3} 1' file2 |   join -a1 -a2 file1 - |   awk 'nf &gt; 3 {$2+=$4; $3+=$5; nf=3} 1'   output on provided input:  game1 10 -5 game3 40 5 game4 -40 -2   (if the files aren't sorted, just sort them and keep them sorted
this is filed as debian bug #525141 (against upstart) and bug #561627 (against sysvinit).  arno schuring notes that as a workaround, you can use aptitude full-upgrade instead of apt-get dist-upgrade (the two commands are synonyms, but aptitude tends to be a bit better at dependency management). 
i just did the following for all of my servers so that when i connect via ssh i am automatically put into a screen session.  add the following to the ~/.bashrc for your user accounts:  # auto-screen invocation
short answer is you don't
jar is part of the jdk
are you looking for csplit file /::/ '{*}'? 
it is possible to circumvent the fact that the atempo filter is not available for avconv(yet the setpts video filter is)
i had a similar issue with my sd card recently
do you know flossmanuals.net?  they've got a great manual on how to bypass internet censorship (also as epub and pdf for offline use -- and note the translations, among others in farsi).  among many tools and methods, they cover socks proxies
this was caused by the presence of a 'drop-in' file /etc/systemd/system/user@.service.d/dbus.conf that overrode the 'standard' definition of the user@.service from /usr/lib/systemd/system and in particular changed the dbus_session_bus_address  how that drop-in file got there is still a mystery
a simple and proper way can be to define a foobar function,   foobar () { ./foo "$@" | ./bar ; }   (either in the command line, as needed, or in some startup scripts, such as ".bashrc" for example).  then whenever you do :   foobar "this"  that   "and this also"   it will do  ./foo  this   that   "and this also" | ./bar  
use the shell's suffix removal feature  str=/opt/oracle/app/oracle/product/12.1.0/bin/tnslsnr path=${str%/*} echo "$path"   in general, ${parameter%word} removes word from the end of parameter
you might know the normal read, write and execute permissions for files in unix
see source at https://github.com/tobiasquinn/gnome-shell-mousewheel-zoom  install for ubuntu:  sudo add-apt-repository ppa:tobias-quinn/gsmz sudo apt-get update sudo apt-get install gnome-shell-mousewheel-zoom mousewheelzoom &amp;   done
you would need to be at the directory from which the tar file was created, for instance $home
with gnu sed:  sed -e '/\[ssh\]/,+2{s/false/true/}' file   with posix sed:  sed -e '/\[ssh\]/n;n;s/false/true/' file  
short answer  use -1 instead of --portrait.  slightly longer answer  by default a2ps tries to put 2 pages on each sheet, this works best side-by-side and landscape, even if you rotate the page a2ps still tries to insert 2 pages
most routers/firewalls allow to redirect traffic based on a certain port, e.g
usb devices are far more complex than simply pipes you read and write
   i find it surprising how fast does locate work or the autocompletion (that i know) work in linux
you can download a src.rpm with zypper's source-install command.  zypper si -d --download-only hello would download the .src.rpm ignoring any dependencies needed to build the package.  you can find the .src.rpm at /var/cache/zypp/packages/repo/src/hello-version.src.rpm.  you can then go through the normal process of extracting the package.  % rpm2cpio /var/cache/zypp/packages/virtualization/src/qemu-2.1.0-260.12.src.rpm | cpio -idmv 0001-xxx-dont-dump-core-on-sigabort.patch 0002-xxx-work-around-sa_restart-race-wit.patch 0003-qemu-0.9.0.cvs-binfmt.patch 0004-qemu-cvs-alsa_bitfield.patch &lt;...&gt;  
in vi do  :1,$d   to delete all lines
i don't know if there are ubuntu packages available, but if not, you could build from source and install to /usr/local
perl has a module called scalar::util (included with perl since v5.8) which has a useful function called looks_like_number(), which can be used to detect whether a field is a number or not.  looks_like_number is not perfect, but is pretty good.  the bare outline of a simple perl program to do what you want might look something like this:    #! /usr/bin/perl  use scalar::util qw(looks_like_number);  while(&lt;&gt;) {   chomp;   my @fields=split("\t");   foreach my $f (0..scalar @fields-1) {     if (looks_like_number($fields[$f])) {       $fields[$f] += 42;       $fields[$f] *= 7;       $fields[$f] = sprintf("%.2f",$fields[$f]);     }   }   print join("\t",@fields),"\n"; }   if given your sample data above as input, it prints this:  file name   size    owner     file1.txt   380.41  root file2.txt   295.21  user1 file3.txt   2016.00 user2 file4.txt   86709.00    root file5.txt   441.00  user3 file6.txt   2016.00 user1 file name   owner   last modified   last accessed text4.txt   root    383.11  388.71 text5.txt   user3   401.33  532.00 file1.txt   root    455.00  511.02   here's another version of the script that uses math::bigfloat for all calculations, rounding decimals to 2 digits.  #! /usr/bin/perl  use scalar::util qw(looks_like_number); use math::bigfloat;  while(&lt;&gt;) {   chomp;   my @fields=split("\t");   foreach my $f (0..scalar @fields-1) {     if (looks_like_number($fields[$f])) {       my $bf = math::bigfloat-&gt;new($fields[$f]);       $bf-&gt;badd(42);       $bf-&gt;bmul(7);       $bf-&gt;ffround(-2);        $fields[$f] = $bf-&gt;bstr();     }   }   print join("\t",@fields),"\n"; }   example input:  file name   owner   last modified   last accessed text4.txt   root    12.73   13.53 text5.txt   user3   15.3333 34 file6.txt   root    903709792518875002.42857142857142857142 903709792518875002 file7.txt   root    6659166111488656281486807152009765625   539422123247359763587428687890625   output:  file name   owner   last modified   last accessed text4.txt   root    383.11  388.71 text5.txt   user3   401.33  532.00 file6.txt   root    6325968547632125311.00  6325968547632125308.00 file7.txt   root    46614162780420593970407650064068359669.00   3775954862731518345112000815234669.00  
there is documentation here, quite a lot of it too
to add to @timo's answer there sounds like there are 3 ways to setup vnc access
if i understand correctly, you want to change _x to x as long as it occurs inside '...' strings.  then, with gnu sed, you could do:  sed -e ":1;s/^(([^']|'[^']*')*'[^']*)_([^'])/\1\u\3/;t1"   that is replace a _x following '... itself following a sequence of either non-quotes or matched quotes.  which on an input like:  foo_bar 'ab_cd_ef gh_ij' zz_zz 'aa_bb'' delta_limits=limits(general_settings['signal_lower_limit']   gives:  foo_bar 'abcdef ghij' zz_zz 'aabb' delta_limits=limits(general_settings['signallowerlimit']   that assumes you don't have strings embedding single quotes (as in 'foo\'bar')
as several others have mentioned, the tz environment variable is what affects the output of date
that's the last resort comparison
with [ expression ] (posix standard) syntax you can use the following:  if [ "$name" != "$blank" ] &amp;&amp; [ "$age" = "$blank" ]; then    echo true fi   but in [[ expression ]] syntax you can use both conditions:  if [[ $name != "$blank" &amp;&amp; $age == "$blank" ]]; then    echo true! fi   two advantages of [[ over [:   no word splitting or glob expansion will be done for [[, and therefore many arguments need not be quoted (with the exception of the right-hand side of == and !=, which is interpreted as a pattern if it isn't quoted). [[ easier to use and less error-prone.   downside of [[: it is only supported in ksh, bash and zsh, not in plain bourne/posix sh.  my reference and good page to comparing [[ and [: bash faq  security implications of forgetting to quote a variable in bash/posix shells 
end the line by pressing ctrl+c
it depends a bit on what distribution you use
first, download the patch
opensuse provides all the expected options in the installation wizard to remove the partitions you wish (your elementary os partitions) and to leave the windows partitions in place and to create the necessary partions for opensuse in the space made available by deleting the elementry os partitions
you can possibly use policykit rules to "unlock" libvirt for uids which are members of a specific gid-group
a shell alias is used as an interactive part of the shell
my answer is only a half solution of the problem
obviously, use another symbol instead of %.  use for example -i @
this is actually done by your shell, not by ls.  in bash, you'd use:  shopt -s nocaseglob   and then run your command.  or in zsh:  unsetopt case_glob   or in yash:  set +o case-glob   and then your command.  you might want to put that into .bashrc, .zshrc or .yashrc, respectively.  alternatively, with zsh:  setopt extendedglob ls -d -- (#i)*abc*   (that is turn case insensitive globbing on a per-wildcard basis)  with ksh93:  ls -d -- ~(i:*abc*)   you want globbing to work different, not ls, as those are all files passed to ls by the shell. 
you can use sed, match the before and after parts of the line and put a . in the middle
the traditional way is to copy all files elsewhere and see which one triggers a read error
sed takes its input from stdin, not from the command line, so your script won't work either theoretically or practically
set the values of session.screen0.slit.placement and/or session.screen0.toolbar.placement to topcenter in your ~/.fluxbox/init file and reload the configuration:  session.screen0.toolbar.placement: topcenter   the available placements are bottomcenter, bottomleft, bottomright, leftcenter, rightcenter, topcenter, topleft, and topright.  see also man fluxbox ("resources") for all of the available configuration options. 
i did have a similar problem trying to build a newer version of ruby
no, you did not overlook a configuration setting
with gawk, you can use the split() function to determine fields and their separators:  $ echo "the quick brown fox   jumps over the lazy dog" | awk '{ split($0, a, "\\s+", s); for (i = 3; i &lt;= 7 &amp;&amp; i &lt;= length(a); i++) printf "%s%s", a[i], (i &lt; 7 ? s[i] : "\n") }' brown fox   jumps over the  
ssh user@111.111.111.111 'cd ~/user/path &amp;&amp; ./my_script.sh' 
i assume that your gateway device to the internet does nat (network address translation), i.e
this is in the works upstream, as of today, 2016/02/09
executing ls -l you will get something like:  -rwsr--r--   1 user user    8111573 sep 26  2012 net-snmp.tar   where the s (can be also s) indicate this file have suid set  s is set when you do not have execution flag set  s is set when you have execution flag set 
as you had already said, it is under "processor types and features".  you are compiling gentoo's hardened kernel source, so the code would have undergone many patches.  a quick search in google returned this : gentoo kernel vdso
nice idea
this might be part of the same family of issues that cause one not to be able to mount usb drives and other kinds of external media in debian (and other distros) without administration privileges when policykit is involved.  though i don't have the complete information at hand, i seem to remember the culprit is the default permissions for udisks (which xfce uses to handle automounting)
 start tmux as follows:  (cd /aaa/bbb; tmux)   now, any new windows (or panes) you create will start in directory /aaa/bbb, regardless of the current directory of the current pane. if you want to change the default directory once tmux is up and running,  use attach-session with -c.  quoting from the tmux man page for attach-session:  -c will set the session working directory (used for new windows) to working-directory.   for example:   ctrl+b : attach -c /ddd/eee   new windows (or panes) will now start in directory /ddd/eee, regardless of the directory of the current pane.  
the basic idea is to use the file utility to determine the type of each file, and filter on video files.  find /some/directory -type f -exec file -n -i -- {} + | sed -n 's!: video/[^:]*$!!p'   this prints the names of all files in /some/directory and its subdirectories recursively whose mime type is a video type.  the file command needs to open every file, which can be slow
you can do this with find:  cd top_level_dir find 
give this howto a look
depending on what "fully use all my programs" means, the options are:   use standard unix file permissions to protect your files
backtrack linux is not configured by default to load a display manager, so there is more work to be done than just installing gdm
i do not have a way of installing a new linux on a new partition without touching the boot menu customization made with grub customizer on a previously installed linux system, but i have a simple solution for restoring that very customization by using boot repair.  installing a new linux on a separate partition will replace the boot menu edited with grub customizer in a previous linux system
this sed command runs a regex that should be helpful for your task:   sed 's#\(/[^/]\+/[^/]\+/\).*\(/[^/]\+/[^/]\+\)/\?#\1...\2#g'   test:  ps1pwd_regex='s#\(/[^/]\+/[^/]\+/\).*\(/[^/]\+/[^/]\+\)/\?#\1...\2#g' $ echo "~/apps/webs/2014/" | sed $ps1pwd_regex  ~/apps/webs/2014/ $ echo "~/apps/webs/chip/mips/2014/" | sed $ps1pwd_regex  ~/apps/webs/.../mips/2014 $ echo "~/apps/webs/chip/mips/2014" | sed $ps1pwd_regex  ~/apps/webs/.../mips/2014 $ echo "/apps/webs/chip/mips/clips/2014" | sed $ps1pwd_regex  /apps/webs/.../clips/2014 $ echo "/" | sed $ps1pwd_regex  / $ echo "~" | sed $ps1pwd_regex ~   you might then setup your profile in the lines:  export ps1='[\u@\h `pwd | sed "s#\(/[^/]\+/[^/]\+/\).*\(/[^/]\+/[^/]\+\)/\?#\1...\2#g"`]\$ '   i myself prefer a multiline prompt which gives plenty of space for long paths on the first line. 
in case you want to consider alternatives to rename, with zsh, i'd write:  autoload -u zmv zmv -n '(*).&lt;-&gt;-&lt;-&gt;(.[^.]##.rpm)' '$1$2'   (and remove -n when happy). 
using sed with a string  you have correctly identified the problem: $reg is a string, not a file
pdfunite $(sed 's/$/_*.pdf/' filenames.txt) output.pdf  so if filenames.txt contains  csai_isotig00407:342-556 csai_isotig00408:342-556   that command will effectively do  pdfunite csai_isotig00407:342-556_*.pdf csai_isotig00408:342-556_*.pdf output.pdf  
you can change top's intervall (defaultly 3 seconds) within top: press d and type 0.1enter
someone may have a script (or write one)
!! is expanded by bash when you type it
i suggest you extract the info that you need from ps, nothing else, and let awk (not bash) do the rest: grepping, comparisons, formatting
create another vm (adding --libvirt qemu:///system this time), but don't boot it -- virsh edit it and replace the path to your virtual disk with your existing vm's disk path. 
the issue was essentially the result of my misunderstanding of how to properly install virtualbox guest modules
why is your system read-only? try to search in dmesg | less
i would suggest filing the bug report with the distribution's bug tracking system, if you are using their build.  they can then escalate the bug report to the upstream maintainer, should it turn out that it exists in a vanilla build as well.  the rationale behind this is simply that since many distributions apply patches of their own, unless you are certain that the bug exists in a vanilla build, the packager is likely in a better position to be able to test both possible configurations (vanilla and patched) than an upstream developer who might even be running their system on a completely different architecture that your distribution of choice doesn't even support.  depending on the complexity of the program and what kind of unexplainable behavior you are seeing, it might even make sense to file a bug against the distribution's bug tracker even if you are using a vanilla build of the program in question but patched versions of any dependencies.  you can certainly escalate the bug to the upstream maintainer if you get no response from the distribution's package maintainer for a reasonable amount of time
change the used loglevel in your networkmanager.conf file     [logging]          this section controls networkmanager's logging
for a moment, i thought that this might be inherited from the gdm configuration (since the gdm login screen does the same thing), but apparently it's not.  after checking a few other places without any luck, i decided to find out for myself and took a look at the source code(v2.30)
first, sudo is a good way to run a script as a limited user
a "temporary" label change is done via the chcon command:  bash-4.2# touch freetds.conf.new bash-4.2# ls -lz freetds.conf.new -rw-r--r--
as requested, i'm creating a list of variables prefixed with q followed by a sequential number (c) which is then assigned your array variable.  #!/bin/bash declare -a matrix num_rows=1 num_columns=50  c=1  for ((n=0;n&lt;=(($num_columns-1));n++)) do     for ((i=1;i&lt;=num_rows;i++)) do         matrix[$i,$j]=net$(($n+1))         declare "q$c=${matrix[$i,$j]}"         ((c++))     done done   to output them, you can use something like:  for ((i=1;i&lt;(($num_columns-1));i++)) do     var=q$i     echo "${!var}" done  
use tar: tar -cf my_big_folder.tar /my/big/folder  restore the archive with tar -xf my_big_folder.tar -c /  -c will change to the root directory to restore your archive since the archive created above contains absolute paths.  edit: due to the relatively big size of the archive, it'd be best to send it [directly] to its final location, using ssh or a mount point of the cloud resource/folder
last and who are what you want.  who  this prints information about the users that are currently logged in
you need to provide either the x magic cookies credentials (see display and authority) or allow connections from localhost via xhost +local:
it sounds like you want to externally invoke tmux from your shell rather than doing this from within tmux, so .tmux.conf is the wrong place
the purpose of watch is to show the results of a command full-screen and update continuously; if you're redirecting the output into a file and backgrounding it there's really no reason to use watch in the first place.  if you want to just run a command over and over again with a delay (watch waits two seconds by default), you can use something like this:  while true; do     cmd &gt;&gt; output.txt     sleep 2 done  
i don't think rob's answer is right
try feature(preserve_local_plus_detail) in your .mc file, and rebuild your .cf. this modifies ruleset 5 (localaddr)
if you can login as root, or otherwise get a root shell (e.g
using gnu parallel it looks like this:  parallel script1.sh {}';' script2.sh {} ::: a b c ::: d e f   it will spawn one job per cpu.  gnu parallel is a general parallelizer and makes is easy to run jobs in parallel on the same machine or on multiple machines you have ssh access to
the program gpgv / gpgv2 is used for simple checking of signatures
that happens because each package in apt has a list of dependencies, which you can see with:  apt-cache depends libgtkspell0 pidgin-data atom   in order to retain the packages apt is suggesting you remove, atom, which has a dependency that conflicts with one of the dependencies atom has
assuming removing the dots from the version number is a typo.  sed can easily do the job:  echo 'version …………2.465.76.8.332' | sed 's/^[^0-9]*//'   to extract only the version number from a file the number on is the first line beginning with 'version' and nothing follows the version number, you could do:  sed -n '0,/^version/ s/^version[^0-9]*//p' file  
if vendorscript.sh does not use an absolute path to launch the screen program, you could try manipulating the $path prior to execution
you can use --rcfile to specify an alternative to .bashrc at start up
i assume you mean utf-8 encoded unicode characters.  that depends what you mean by invalid.  invalid_byte_sequence=$'\x80\x81'   that's a sequence of bytes that, by itself, isn't valid in utf-8 encoding (the first byte in a utf-8 encoded character always has the two highest bits set)
you should always read /usr/ports/updating before carrying out a port upgrade
use the -f option instead:  tail -f /var/log/kern.log   the -f option tells tail to track changes to the file by filename, instead of using the inode number which changes during rotation
for fast search (but not definitive):  locate -br '^settings.xml$'   from man locate:     locate  reads  one or more databases prepared by updatedb(8) and writes    file names matching at least one of the patterns  to  standard  output,    one per line.     -b, --basename           match  only  the base name against the specified patterns
chromium uses the default application.  how to find the default application for a given mime type  # general case xdg-mime query default &lt;mime-type&gt;  # your case xdg-mime query default application/x-bittorrent xdg-mime query default x-scheme-handler/magnet   changing the default application  # general case xdg-mime default &lt;application.desktop&gt; &lt;mime-type&gt;  # your case xdg-mime default transmission-gtk.desktop application/x-bittorrent xdg-mime default transmission-gtk.desktop x-scheme-handler/magnet   those commands alter the file $home/.local/share/applications/mimeapps.list and/or $home/.local/share/applications/defaults.list, which means you can also do the change manually. 
first of all, a partition can be mounted to multiple locations.  and for your own purpose, i doubt mount itself supports so
you could do:  :|tee -- *.dat   or the zsh (with multios) equivalent:  :&gt;*.dat   though because that opens all the files concurrently, you may reach the limit on the maximum number of open file descriptors if there's a large number of files. 
like others have said, you'll need to set up a local mail server (sendmail, postfix, or whatever is your preference)
you need to use openssl for analyzing the certificate:  openssl s_client -showcerts -connect www.domain.com:443 openssl x509 -text -noout -in some.crt  
are you looking for this?   $ mv  file dir/ mv: cannot stat ‘file’: no such file or directory $ mv  file dir/ 2&gt;/dev/null # &lt;---- silent -----&gt;  
there are several different options here, each with different effects and tradeoffs.  firstly, you probably don't want to do anything with dd
looking at the drive with gdisk renders:  root@ubuntu-mate:~# gdisk /dev/sda gpt fdisk (gdisk) version 1.0.1  partition table scan:   mbr: protective   bsd: not present   apm: not present   gpt: present  found valid gpt with protective mbr; using gpt.  command (? for help): v  warning: the 0xee protective partition in the mbr is marked as active
tcp communication is done through sockets, which you create with the socket() system call
firefox use a lot of xorg resources (much more than other browsers)
if you want just the text between your patterns on each line, do the following:  sed 's/.*raw\(.*\)transformed.*/\1/'   \(.*\) remembers the text that is output using \1
ctrl+k will kill the text from the cursor to the end of line
rsync is usually used via ssh like this:  $ rsync -avz -e ssh hosting:&lt;path&gt; .   -e ssh can be omitted because ssh is the default:  $ rsync -avz hosting:&lt;path&gt; .   where hosting is ssh alias for your vps server
the versions are as follows:   nvidia-331: the current release nvidia-173: an old legacy binary driver, supporting (much) older cards nvidia-304: a more recent legacy binary driver, supporting older cards nvidia-331-updates: the update channel for the current release (but it's the same as the version in nvidia-331 now) nvidia-304-updates: the update channel for nvidia-304 nouveau: the nouveau free driver   update channels contain new versions available for testing; once a version has been tested it is made available in the normal channel.  if nouveau isn't working for you, then nvidia-331 is the appropriate version, since it supports your card
i don't believe either configure or make is hard to learn
at least three different utilities imaginatively named rename(1) are floating around in the linux waters: (1) the one that came with util-linux, (2) an older perl script by larry wall further munged by tom christiansen, and (3) a newer perl script evolved from the former and included with unicode::tussle
if you put    set -xv     in your script, you might be able to detect why there is an error.  in your script, it will output this line:  +for divider in '{2..$a}'   notice the expansion did not occur
maybe you have it backwards
it's because you're missing a second -v:  awk -v sourceip="$sourceip" -v reversedns="$reversedns" '{    gsub(/^_tmpsourceip_/, sourceip);    gsub(/^_tmpreversedns_/, reversedns);    print }' /home/foo/footemplate   -v needs to be present for each variable you assert
with winetricks you can sandbox the wine prefix to remove all links to $home
it works: https://www.centos.org/modules/newbb/viewtopic.php?topic_id=15725  wget http://packages.sw.be/rpmforge-release/rpmforge-release-0.5.2-2.el5.rf.x86_64.rpm rpm --import http://apt.sw.be/rpm-gpg-key.dag.txt rpm -k rpmforge-release-0.5.2-2.el5.rf.*.rpm rpm -i rpmforge-release-0.5.2-2.el5.rf.*.rpm yum -y install vlc  
smooth scrolling is a feature of the qt widget set, not of kde
the su command does not change the home environment variable under solaris
here is the problem in your understanding:     my understanding is that the bootloader grub2, is mounted to /boot.   grub is not "mounted" on boot
the problem is not in software, it's in hardware. keyboard keys are not independent: there're about 100 keys, but only about 26 wires going into keyboard's internal controller:    (image from dreamstime.com)  this means that not all keys can be detected when simultaneously pressed
you should be able to achieve this with apparmor, which allows one to block access based on pathname
first off, sudo all by itself, doesn't send any emails or create warning messages, other than logging your unsuccessful attempt to the log
grepping for non-ascii characters is easy: set a locale where only ascii characters are valid, search for invalid characters.  lc_ctype=c grep '[^[:print:]]' myfile   if you want to search for japanese characters, it's a bit more complicated
if you want to preserve the essence of your awk command, then you can simply sub away the unwanted trailing portion of $1  awk '{sub(/\.png.*$/,"",$1); print $1","$2}' file   or (perhaps more awkishly)  awk '{sub(/\.png.*$/,"",$1)}1' ofs=, file  
no, it's  echo test &gt; "$tmppipe" # btw, you've got the quotes in the wrong places   that hangs
to answer your initial question, the most basic way to keep a command running after logging out is to run it with the nohup command.  for example, if i wanted to run a script, and drop it into the background while keeping it running after logging out i would type:  nohup ./myscript &amp;   more information can be found here: https://en.wikipedia.org/wiki/nohup  otherwise, as you stated, screen is a good option. 
this is similar to the existing question  upstart on debian?  regardless of version, it must be disclaimed that running upstart as the init system in debian seems to be "at your own risk"
so, as @muru points out in the comments, there doesn't seem to be a simple way to interface the pty created for you with just the shell
look closely at an excerpt from an ls -al /dev command on my system:  brw-rw----  1 root floppy    8,   0 jun  7 19:55 sda brw-rw----  1 root floppy    8,   1 jun  7 19:55 sda1 brw-rw----  1 root floppy    8,   2 jun  7 19:55 sda2 brw-rw----  1 root floppy    8,   3 jun  7 19:55 sda3 brw-rw----  1 root floppy    8,   5 jun  7 19:56 sda5 brw-rw----  1 root floppy    8,   6 jun  7 19:56 sda6 brw-rw----  1 root floppy    8,   7 jun  7 19:56 sda7 brw-rw----  1 root floppy    8,   8 jun  7 19:57 sda8 brw-rw----  1 root floppy    8,  16 jun  7 19:55 sdb brw-rw----  1 root floppy    8,  32 jun  7 19:55 sdc brw-rw----  1 root floppy    8,  33 jun  7 19:55 sdc1 brw-rw----  1 root floppy    8,  34 jun 11 10:39 sdc2 brw-rw----  1 root floppy    8,  35 jun  7 19:56 sdc3   the two numbers after the group id but before the date are the device file's major and minor numbers
install a package  the path for usb is in /media, so you will have to search there what's the path
i was able to do it with a backslash:  25 % grep \&lt; xmospos.c #include        &lt;stdio.h&gt; #include        &lt;stdlib.h&gt; #include        &lt;getopt.h&gt; #include        &lt;x11/xlib.h&gt;   a quoted less-than, and a quoted, backslashed less than both gave goofy answers. 
print -rl /usr/local/include/**/*(^/)  
you're looking for fallocate's falloc_fl_punch_hole
you can download webkitgtk-2.2.4-1.el7.x86_64.rpm for rhel7 for example from http://rpm.pbone.net/index.php3/stat/4/idpl/27127038/dir/redhat_el_7/com/webkitgtk-2.2.4-1.el7.x86_64.rpm.html and then install by rpm -ihv webkitgtk-2.2.4-1.el7.x86_64.rpm  it need libsecret,libwebp, gstreamer1-plugins-base packages - yuu can install it from rhel7/centos7  alternativly, but "right way" - yuu can add whole epel repository:  yum install epel-release   and then install webkitgtk package by  yum install webkitgtk  
answer: https://askubuntu.com/questions/39217/unlock-keyring-with-fingerprint-reader-on-login/238055#238055 in short, no the keyring cannot be unlocked with fingerprint authentication
$ hash /usr/local/bin php $ php file.php   help :  $ lang=c help hash hash: hash [-lr] [-p pathname] [-dt] [name ...]     remember or display program locations.      determine and remember the full pathname of each command name
after some more research i have found out that those indicators are called overshoot and undershoot.  related ticket:     in gtk 3.16 (for example from ppa:ubuntu-desktop/ww),   gtkscrolledwindows indicate whether there is content that can be   scrolled to (adwaita shows a dashed line for this) and if the user   scrolls when there is no more content (adwaita shows a gradient   thing)
you can do that
so i've been chasing my tail on this exact same issue, and i stumbled across a bug report filed against firewalld for enabling igmp during application install
your best bet is probably iotop:     iotop  watches  i/o  usage  information  output  by  the  linux  kernel    (requires 2.6.20 or later) and displays a table of current i/o usage by    processes   or   threads   on   the   system
i found this perl script, parse-audit-log.pl, that shows a function that can parse that string as follows:  sub parse_saddr {     my $sockfd = $_[0];     my $saddr = $_[1];     # 0 - sys_bind(), 1 - sys_connect(), 2 - sys_accept()     my $action = $_[2];      ($f1, $f2, $p1, $p2, @addr) = unpack("a2a2a2a2a2a2a2a2", $saddr);     $family = hex2dec($f1) + 256 * hex2dec($f2);     $port = 256 * hex2dec($p1) + hex2dec($p2);     $ip1 = hex2dec($addr[0]);     $ip2 = hex2dec($addr[1]);     $ip3 = hex2dec($addr[2]);     $ip4 = hex2dec($addr[3]);     #print "$saddr\n";     if ($family eq 2) { #&amp;&amp; $ip1 ne 0) {         my $dst_addr = "$ip1.$ip2.$ip3.$ip4:$port"; #       print "family=$family $dst_addr\n\n";         # todo: avoid code duplication         if ($action eq 0) {             $sockfd_hash{ $sockfd } = $dst_addr;         } elsif ($action eq 1) {             my $src_addr;             if (exists $sockfd_hash{ $sockfd }) {                 $src_addr = $sockfd_hash{ $sockfd };             } else {                 $src_addr = "x.x.x.x:x";             }             print "$src_addr -&gt; $dst_addr\n";         } elsif ($action eq 2) {             my $src_addr;             if (exists $sockfd_hash{ $sockfd }) {                 $src_addr = $sockfd_hash{ $sockfd };             } else {                 $src_addr = "x.x.x.x:x";             }             print "$dst_addr &lt;- $src_addr\n";         } else {             print "unknown action\n";         }     } elsif ($family eq 1) {         $tmp1 = 0;         ($tmp1, $tmp2) = unpack("a4a*", $saddr);         my $file = pack("h*", $tmp2); #       print "family=$family file=$file\n";     } else { #       print "$saddr\n";     } }   this script was part of this twiki page on the cern website, under linuxsupport
the find command has a switch for that
if it wasn't a bash script but a regular application, you would give ownership of it to root and set the setuid bit on the application
you should try restarting nis server since it was unreachable during the disconnection the yp has not binded yet again
i'm unsure which version of wget or os and any proxy's exist between you and sourceforge but wget downloaded the file when i removed the "/download" and left it at the file extension.  i don't want to flood the post or pastebin my entire session but i got the 302 then 200 status codes before the transfer began
another approach with gnu sed:  | sed '/ram/,/^$/d;/^$/d'   output:   disk /dev/sda: 931.5 gib, 1000204886016 bytes, 1953525168 sectors units: sectors of 1 * 512 = 512 bytes sector size (logical/physical): 512 bytes / 4096 bytes i/o size (minimum/optimal): 4096 bytes / 4096 bytes  
try this way:  gs -depscrop -c "&lt;&lt;/orientation 1&gt;&gt; setpagedevice" -f input.eps -c quit   p.s this code snippet come from this post in the rhinocerus forum. 
yes, we see a number of things like:  while read line; do   echo $line | cut -c3 done   or worse:  for line in `cat file`; do   foo=`echo $line | awk '{print $2}'`   echo whatever $foo done   (don't laugh, i've seen many of those).  generally from shell scripting beginners
apparently you just created the array
   why does file 'two' also get them?   cause ln(1) make hard links by default, and 'two' is a hard link of 'one', according to the man page:     a hard link to a file is indistinguishable from the original directory entry; any changes to a file are effectively independent of the name used to reference the file.        if i do ls -l, i see that files one and two have 28 bytes, whereas file three has only 3 bytes (maybe for six)
afaik the only way to be completely sure of security would be to write a compiler in assembly language (or modifying the disk directly yourself)
lets go from top to bottom, this guide is not distro specific (most of these commands will be available on most distros either out of the box, or through the package repositories) first you probably want to get the rough lay of your hardware specs
to change the default editor at the system level:  sudo update-alternatives --config editor   and then follow the onscreen prompts. 
in the pattern clauses of a case statement, | means precisely or.  from the bash manual on case:     the syntax of the case command is:   case word in [ [(] pattern [| pattern]…) command-list ;;]… esac       the ‘|’ is used to separate multiple patterns, and the ‘)’ operator terminates a pattern list.  
new answer  sorry i wasn't cautious enought. on powerpc there's no official support for flash your only alternative is a free plugin "gnash" sudo apt-get install gnash browser-plugin-gnash        old answer  to add non free app to your installation source modify the file /etc/apt/sources.list:  sudo 'the_editor_of_your_choice' /etc/apt/source.list   edit the line deb http://ftp.us.debian.org/debian/ wheezy-updates main to deb http://ftp.us.debian.org/debian/ wheezy-updates main contrib non-free   edit 2: deb http://ftp.us.debian.org/debian/ wheezy main or deb http://ftp.us.debian.org/debian/ wheezy main contrib non-free   then run those line  #this is for updating ths list of app available in repository after the update made to your `source.list` file   sudo apt-get update  # you might want to run this command to upgrade your packages: sudo apt-get upgrade   #this is the command to install flash on debian once you activate the nonfree and contrib repositories sudo apt-get install flashplugin-nonfree  #this seems to be the command to update according to the [debian wiki][2] sudo update-flashplugin-nonfree --install   and that should do the trick. 
i think you will see errors in journalctl, or possibly ~/.xsession-errors.  something like what you describe might cause a permissions error
all right, so for the first question it turns out the debugfs stats command tells what the starting blocks for every section of a group are
the gpg-agent man page explains under the option --enable-ssh-support that the ssh agent protocol is not able to provide the name of the tty to the agent, so it defaults to using the original terminal it was started in
here's a perl script that opens files (given as command line arguments) in utf-16 (endianness detected via bom), and counts the lines.  #! /usr/bin/env perl use strict; use warnings;  while (my $file = shift @argv) {     my $fh;     if (!open($fh, '&lt;:encoding(utf-16)', $file)) {         print stderr "failed to open [$file]: $!\n";         next;     }     my $count = 0;     $count++ while (&lt;$fh&gt;);     print "$file: $count\n";     close $fh; }   (dies if the bom is not understood.) 
if your system doesn't have /dev/stderr, you can use perl that way:  {   your-code   .. } | perl -pe 'print stderr'   perl processes the input one line at a time, so you won't see partial lines there
as you've noticed, the file is created before ls is run
you have two options: modify the python script, or write a shell script wrapper.  to modify the python script:   you should loop around what it is you want to be doing. install a signal handler to catch the int signal (sent by ctrl-c) and term signal (sent by plain kill)
you need to use - foo format:  $ ls -l file -rw-r--r-- 1 terdon terdon 0 nov 29 11:05 file $ touch -d '-1 week' file  $ ls -l file -rw-r--r-- 1 terdon terdon 0 nov 22 11:06 file  
you can use systemtap for this sort of thing.   first, set up your system
you're already using printf in the true branch of your if statement, which supports formatted output
the "source port" means the port the remote machine sent the packet to your server from
as far as i know, uname will display the generic name of the operating system.  my roommate has the latest (i think) version of osx, and it displays darwin when it runs.  if you'd like more of an output, uname -a will give you the kernel version, os version, and a bunch of other information, in addition to the generic name.  that said, this doesn't always properly fingerprint an os
you don't need a tempfile to do this, and sed (or awk) are far more flexible in comment processing than a shell case statement.  for example:  configfile='/opt/myconfigfile.txt' [ $# -gt 0 ] &amp;&amp; [ -r "$1" ] &amp;&amp; configfile="$1"  sed -e 's/[[:space:]]*#.*// ; /^[[:space:]]*$/d' "$configfile" |     while read var1 var2 var3 var4; do       # stuff with var1, etc.     done   this strips comments (with or without leading whitespace) and deletes empty lines from the input before piping it into the while loop
yes, you can use hiera data with masterless setup
as tim said, type fg to bring the last process back to foreground.  if you have more than one process running in the background, do this:  $ jobs [1]   stopped                 vim [2]-  stopped                 bash [3]+  stopped                 vim 23   fg %3 to send the vim 23 process back to foreground.  to suspend the process running in the background, use:   kill -19 %job_id.   the -19 signal is sigstop (the signal sent by ctrl+z) .  example: kill -19 %3
simply remove the ; character, so in final :   for i in *; do something.py $i &amp; done   and for running n instance of your script at the same time, see man 1 parallel  see http://www.gnu.org/software/parallel/   
q1: “it” is wake_up
   is there a way to delete the newline ..
knowing that the desktop wallpaper could be a child window created by xfdesktop, a lead to follow could be exploring the content of the x windows list with the command:  xwininfo -tree -root   excerpt of the output ("scrivania" simply meaning "desktop" in english):      0x800744 (has no name): ()  4x538+736+30  +755+50     0x800743 (has no name): ()  4x541+0+30  +19+50  0x8005f9 (has no name): ()  1920x1080+0+0  +0+0     16 children:     0x1400003 "scrivania": ("xfdesktop" "xfdesktop")  1920x1080+0+0 +0+0        1 child:        0x1400004 (has no name): ()  1x1+-1+-1  +-1+-1     0x800608 (has no name): ()  1x1+0+0  +0+0     0x800607 (has no name): ()  1x1+0+0  +0+0   following this hypothesis it is relatively simple in your script to check if the window belonging to xfdesktop exists and/or has children 
since at defaults to reading from standard input, you can just do this:  echo /path/to/script argument | at 17:45  
the redhat (and thus centos and friends) at and also debian-derived vintages (as rpm -qi at on redhat indicates a debian url, and also derobert in comments, above) should support a -m option:      -m      never send mail to the user.   lacking this, another option would be to suppress output from the job:  #!/bin/bash exec &gt;/dev/null 2&gt;&amp;1 ..
   mv -i "${file}" "${file/-id-/-submit_go_id-}"   that string replacement tells it to replace -id-, which doesn't occur in your source file names
   q#1: can you set up a raid system using usb sticks as the storage media   you should be able to use any block storage devices in a raid
here are 2 ways to do it:  mount  using mount's -v switch:  $ mount -v | grep /home/sam mulder:/export/raid1/home/sam on /home/sam type nfs (rw,intr,tcp,nfsvers=3,rsize=16384,wsize=16384,addr=192.168.1.1)   nfsstat  using nfsstat -m:  $ nfsstat -m | grep -a 1 /home/sam /home/sam from mulder:/export/raid1/home/sam  flags: rw,vers=3,rsize=16384,wsize=16384,hard,intr,proto=tcp,timeo=600,retrans=2,sec=sys,addr=mulder  
i don't have an exact solution for your problem, hopefully a better answer than mine will come up
this has turned out to be a royal pita
with gnu find, you can use the -fstype predicate:  find / -fstype nfs -prune -o \( -nouser -o -nogroup \) -print   having said that, hymie's approach probably makes more sense: white-list what fs you want to search rather than black-listing those that you don't want to search.  if you want to only include jfs2 file systems (assuming / is on jfs2), then, you need to write it:  find / ! -fstype jfs2 -prune -o \( -nouser -o -nogroup \) -print   don't write it:  find / -fstype jfs2 \( -nouser -o -nogroup \) -print   as that while that would stop find from printing files in non-jfs2 filesystem, that would not stop it from crawling those non-jfs2 filesystems (which you need -prune for).  note that -a (and which is implicit if omitted) has precedence over -o (or), so you need to watch whether parenthesis are needed or not.  the above correct command is short for:  find / \( \( ! -fstype jfs2 \) -a -prune \) -o \   \( \( -nouser -o -nogroup \) -a -print \)  
if your variable is exported (bash: by the export command or by default because of set -a) then a called shell gets it in its environment like any other process would. 
in a terminal input:  echo $desktop_session   
$ ddate today is prickle-prickle, the 41st day of discord in the yold 3179  
if you want to append  to a file you have to use &gt;&gt;.  so your examples would be  $ md5sum file &gt;&gt; checksums.txt   and  $ sha512sum file &gt;&gt; checksums.txt  
it turns out that sftp crashes if any text is output to the console
sourcing your script only sets shell variables, while printenv shows environment variables
change your name variable definition so that it returns the person's name, and we can test on that
yes, just type in a shell terminal  xz -l *.xz  
copy and paste this code on ttyecho.c  compile it using gcc -o3 -o ttyecho ttyecho.c  use it ./ttyecho -n /dev/pts/1 ls 
use find to count all directories in a tree starting from current directory:  find 
put a line like this in a file in /etc/udev/rules.d:  kernel=="sd*", attrs{vendor}=="yoyodyne", attrs{model}=="xyz42", attrs{serial}=="123465789", run+="/pathto/script"   add a clause like name="subdir/mydisk%n" if you want to use a custom entry path under /dev.  run udevadm info -a -n sdb to see what attributes you can match against (attribute=="value"). 
check that your default jdk is the oracle jdk and not openjdk
with those syntax-highlighting rules files, nano assumes that filenames ending in .1 - .9 are man pages.  it's been quite a while since i edited a man page, but i'm pretty sure that in groff -man, .i is for italic and .bis for bold. 
basically you have to make sure that you use a recent john version that has openmp support enabled.  if you compile it yourself you have to explicitly enable openmp support in the makefile (and verify that needed dependencies are available - e.g
try removing ntfs-3g-2:2011.4.12-5.el6.x86_64 package by:      yum remove ntfs-3g   see which packages depends on this package
it indicates that chromium may be passed a list of urls on its command line
according to archlinux-wiki , to use wicd you need to disable other network daemons (netctl, netcfg, dhcpcd, networkmanager)     warning: running multiple network managers will cause problems, so it is important to disable all other network management daemons.      first, stop all previously running network daemons (like netctl, netcfg, dhcpcd, networkmanager).   disable any existing network management services, including netctl, netcfg, dhcpcd, and networkmanager   you can find a list of the currently running services with systemctl --type=service and then stop them. 
i think you want to do:  export prompt='[%n]%t '  setenv doesn't seem to work with zsh version 5.0.8, which is what i tried it with.  try man zshmisc and look for the section "simple prompt escapes" to see all of the escape-sequences available
btrfs supports duplicated data blocks if you enable mixed block groups:  mkfs.btrfs --mixed --metadata dup --data dup /dev/&lt;device&gt;   edit: notice that there is a patch so that we can do this without using mixed mode
try  for file in *"$foobar"* do    dest="$(echo $file| sed -e 's/\(.*\)\.[^\.]*$/\1.csv/' )"    if test -f "$file"     then         /home/user/scriptmodelise.pl  "$file" &gt;&gt; /home/user/documents/collectcsv/$dest    else      echo "no $foobar file"    fi done   where   \(.*\)\.[^\.]*$ capture a pattern with any char, (end of pattern) followed by a dot, non dot till end of line \1.csv insert pattern found, add .csv *"$foobar"* will expand to litteral *foobar* (with proper value) if no matching file are found
dirname /home/user/desktop/script.sh 
namespace:   2.2.14 is the version number from the upstream package (from apache.org) -5 is the debian package version on top of which ubuntu does some modification, each iteration increasing the version number
there is no good or reliable way for a host to tell whether another machine is already using its ip address, or if the ip is in the wrong subnet for your local network.  you could usetcpdump or arpwatch or similar to listen to the network interface to try to find out if some other mac address is using your ip (but even this is not reliable because the other host may be switched off or have no reason to send any packets on the network at the moment
you can use find
this is commonly done with sbcs (raspberrypi, odroid, etc) what they do is add a line to /etc/rc.local, something like;  if [ -f init.sh ] ; then init.sh; fi   and init.sh resizes the partition ext4 (with or without lvm) then deletes itself.  pvresize /dev/sda2 lvresize -l +100%free /dev/v_a/l_a resize2fs /dev/v_a/l_a rm init.sh   to copy an image use dd;  dd if=my.img of=/dev/sdb bs=10m; sync  
you need to add --import to the command line to import the private key
there are many ways to achieve this, i'd just loop over the different values you'd like to split, i.e.  for i in {0..9} a b; do     ls -1 gsc"${i}"* &gt; filelist"${i}".txt done   this will effectively run  ls -1 gsc0* &gt; filelist0.txt ls -1 gsc1* &gt; filelist1.txt ls -1 gsc2* &gt; filelist2.txt ...   note that if no file exist, the error message will be printed on stderr, i.e
may be it's not very original, but i think list of topics from lfs101x.2 introduction to linux course could help:   chapter 01: the linux foundation (not very useful) chapter 02: linux philosophy and concepts       section 1: linux history      section 2: linux philosophy      section 3: linux community      section 4: linux terminology      section 5: linux distributions    chapter 03: linux structure and installation       section 1: linux filesystem basics      section 2: the boot process      section 3: linux distribution installation    chapter 04: graphical interface       section 1: session management      section 2: basic operations      section 3: graphical desktop    chapter 05: system configuration from the graphical interface       section 1: system, display, date and time settings      section 2: network manager      section 3: installing and updating software    chapter 06: finding linux documentation       section 1: documentation sources      section 2: the man pages      section 3: gnu info      section 4: help command      section 5: other documentation sources    chapter 07: command line operations      section 2: basic operations      section 3: searching for files      section 4: working with files      section 5: installing software    chapter 08: file operations       section 1: filesystems      section 2: filesystem architecture      section 3: comparing files and file types      section 4: backing up and compressing data    chapter 09: user environment       section 1: accounts      section 2: environment variables      section 3: recalling previous commands      section 4: command aliases      section 5: file permissions    chapter 10: text editors       section 1: basic editors: nano and gedit      section 2: more advanced editors: vi and emacs    chapter 11: local security principles       section 1: understanding linux security      section 2: understanding the usage of the root account      section 3: using sudo, the importance of process isolation, limiting   hardware access and keeping systems current      section 4: working with passwords      section 5: securing the boot process and hardware resources    chapter 12: network operations       section 1: introduction to networking      section 2: browsers      section 3: transferring files    chapter 13: manipulating text       section 1: cat and echo      section 2: sed and awk      section 3: file manipulation utilities      section 4: grep      section 5: miscellaneous text utilities      section 6: dealing with large files and text-related utilities    chapter 14: printing       section 1: configuration      section 2: printing operations      section 3: manipulating postscript and pdf files    chapter 15: bash shell scripting      section 1: features and capabilities      section 2: syntax      section 3: constructs    chapter 16: advanced bash scripting      section 1: string manipulation      section 2: boolean expressions      section 3: the case statement      section 4: looping constructs      section 5: script debugging      section 6: some additional useful techniques    chapter 17: processes      section 1: introduction to processes and process attributes      section 2: listing processes      section 3: process metrics and process control      section 4: starting processes in the future    chapter 18: common applications       section 1: internet applications      section 2: productivity and development applications      section 3: multimedia applications      section 4: graphics editors and utilities  
on debian and derivatives (including ubuntu), you could use rename, which applies a perl expression to each file name.  rename 's/%20/ /g' l*         |  |  | |   |         |  |  | |   +--- files to match         |  |  | +------- globally         |  |  +--------- with space         |  +------------ %20         +--------------- substitute   i would consider using underscore instead of space – as it generally makes life easier in the cli world.  to generalise to all uri encoding:  rename 'use uri::escape; $_ = uri_unescape $_' *%*  
you can pass the ssh client a command to execute in place of starting a shell by appending it to the ssh command.  ssh username@domain.com 'rm /some/where/some_file.war'   you don't have to cd to a location to remove something as long as you specify the full path, so thats another step you can skip.  the next question is authentication
you need to add a command to the relevant pane
you might try the file utility
i fixed it myself by using yum command to install rpm package.  yum install http://yum.spacewalkproject.org/2.5/rhel/6/x86_64/spacewalk-repo-2.5-3.el6.noarch.rpm  
you can use tcpflow to do this
thanks to the hints in warl0ck's answer i wrote this script fakepkg:  #!/bin/bash set -e  olddir=$pwd  newdir=$(mktemp -dt fakepack.xxx) cd $newdir  yaourt -g $1 cd $1  #todo this can probably be retrieved from the pacman desc file while true; do   read -p "edit pkgbuild? [yn]" -n1 yn   case $yn in     [yy]* ) $editor pkgbuild; break;;     [nn]* ) echo; break;;     * ) echo ;;   esac done  
that's not a bad idea
the current governor can be obtained as follows:  cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor   this solution might be system dependent, though
from wikipedia :      on posix platforms, locale identifiers are defined similarly to the   bcp 47 definition of language tags, but the locale variant modifier is   defined differently, and the character encoding is included as a part   of the identifier.      it is defined in this format:   [language[_territory][.codeset][@modifier]]
ctrl+d, when typed at the start of a line on a terminal, signifies the end of the input
this appears to have been a cache issue, though it's unclear what went wrong
in xrdp.ini do you have the autorun directive set under [globals]?  it may be the case that it's set to autostart a session and this is why it's failing to provide the logon screen
there's no posix equivalent
as long as the jobs were all started from your current shell: use 'jobs' to get a list of backgrounded jobs
assuming the seven columns are a:g and the first row is 1:  in h1 enter =countif(a1:g1;"=a")  and copy down.  credits to john v at www.oooforum.org. 
you can use  :help usr_01.txt   to access a specific file
to check which package a file belongs to, use dpkg -s:  $ dpkg -s /etc/init.d/mountnfs.sh initscripts: /etc/init.d/mountnfs.sh   mountnfs.sh belongs to an essential package called initscripts.  unless you wrote them, you should never remove scripts from /etc/init.d/
take a look at the centos wiki, titled: how to become root
you can use the pattern matching flag in sed as follows:  echo "hello world xxx this is a file yyy" | sed 's/.*xxx \(.*\)yyy/\1/'   so .*xxx will match from the beginning up to xxx
from the cli, as requested:  gsettings set org.gnome.nautilus.preferences enable-delete true   explanation requested from op:  nautilus is a part of gnome, so it stores preferences under org.gnome.nautilus.preferences
sh does not support array, and your code does not create an array
yes:  xinput set-button-map id &lt;button map&gt;   where you find the id via xinput list and the &lt;button map&gt; is what you would have passed to xmodmap
you should be able to adjust the gamma using the xgamma command. 
you need to add p flag to make the following flag recognize escape sequences:  $ foo=$'x\034y\034z' $ print -rl -- ${(ps:\034:)foo} x y z   if you don't want to hard-code the delimiter (require version >= 5.0.8):  $ delim=$'\034' print -rl -- ${(ps:$delim:)foo}  
in centos you have the file /etc/sysconfig/iptables if you don't have it there, you can create it simply by using iptables-save to dump the current rule set into a file.  iptables-save &gt; /etc/sysconfig/iptables   to load the file you don't need to restart the machine, you can use iptables-restore  iptables-restore &lt; /etc/sysconfig/iptables  
those messages are sent to stderr, and pretty much only those messages are generally seen on that output stream
in your second reference, where it says     the memory allocator gets a big chunk of memory (say, 4 pages, or 4 * 4 kib) and divides this into much smaller chunks   "the memory allocator" is not the kernel but the libc routines like malloc.  the kernel allocates memory to the process in page-sized chunks
a function that is reachable through fpath does not “exist” in the sense that it can be invoked
comparing distros  i'd start first with the comparison of linux distributions on the wikipedia page titled: comparison of linux distributions
best way to do it would be to check if it exists and is executable:  if { ! ([file exists /usr/bin/scp] &amp;&amp; [file executable /usr/bin/scp])} {     puts stderr "/usr/bin/scp does not exist or is not executable"     exit 7 }  spawn /usr/bin/scp ...  
combine the two:  awk -f: '/^n\*:/ {print $2}' 
pulseaudio is started via xdg autostart, which can be found under ~/.config/autostart/ 
centos/rhel/fedora is using openssh compiled with libedit, which has its problems, but does its job for basic use cases
note: the 9.x branch of reader has been eol'd as of june 26, 2013
awk '$5-$4 &gt;= 2000' file  if $5 always larger than $4 
it seems that this problem was caused by another connected device competing for the same ip address
adding binding="strong" to your first edit line like so:  &lt;edit name="family" mode="assign" binding="strong"&gt;&lt;string&gt;essential pragmatapro&lt;/string&gt;&lt;/edit&gt;   should do the trick
try this,  iptables -a output -o ethx -m owner --uid-owner {username} -j drop   where,  --uid-owner { username } : matches if the packet was created by a process with the given effective username. -a : append rule to given table/chain -i : insert rule to head of table/chain  for example, my oracle user id is 1000 so i will append following rule:  /sbin/iptables -a output -o eth0 -m owner --uid-owner 1000 -j drop  service iptables save  
one more time awk saves the day!  here's a straightforward way to do it, with a relatively simple syntax:  ls -l | awk '{if ($3 == "rahmu") print $0;}'   or even simpler: (thanks to peter.o in the comments)  ls -l | awk '$3 == "rahmu"'   
apparently this issue has nothing to do with android
set stricthostkeychecking no in your /etc/ssh/ssh_config file, where it will be a global option used by every user on the server
plug in your usb drive  turn on your pc  enter uefi through pressing esc or f2  from the boot tab  disable fastboot  ( enable launch csm if you need to boot the legacy mode)  press f10 to save &amp; exit  press esc or f2 again  in boot tab your usb drive should be listed.  change the order  press f10 to save &amp; exit  your should now boot from the usb drive  edit  you need to go to security tab, secure boot menu and choose disabled 
you should try to avoid "-c" if it is possible
there are usually 2 things you would need to do to get this effect:   reparent the process to a new shell.  there is basically no way to do this as far as i know
the headers you are mentioning as well as /lib64/libc.so and /lib64/libm.so belong to glibc (as the placement in /lib64 already suggests these are core system files (otherwise they would be in /usr/lib64)
you have to define highlight colors
running uname -a should give you some general information about the system
in rhel 7, you'll have to use nmcli command for permanent change
code executes at the same speed whether it's in the kernel or in user land, but there are things that the kernel code can do directly while user land code has to jump through hoops
first of all, the network persists even when you arch-chroot
the blue glow is not an effect, it's part of the desktop theme
you can look at gnu's aspell dictionary list  or simply install the sources for the packages, which will give you what these have been made from. 
following andrew sun's suggestion in this stackoverflow answer, i installed adbd insecure from google play
edit file /etc/hosts and add line:  192.168.20.254 this.is.my.host   of course instead of this.is.my.host enter proper hostname
put your variable inside double quote to prevent field splitting, which ate your spaces:  $ mycustomtab='     ' $ echo "${mycustomtab}blah blah"      blah blah  
an ubuntu-base distro for beowulf clusters developed by the university of the basque country in spain: http://www.ehu.eus/ac/abc.htm     abc gnu / linux distribution is based on ubuntu and specializes in the   automatic construction of high-performance beowulf clusters with only   boot in "live " mode in frontend or being installed on your hard   drive
using the dmidecode | grep -a3 '^system information' command
in zsh, at the prompt, type print, and then alt-h.  if it gives you the man page for the print system command instead of the print builtin, you may want to follow the instructions given under accessing on-line help at:  info zsh utilities   for zsh documentation, i prefer to use info in general
to save a lot of clipboard text to file quickly, you can run cat &gt; file.txt, paste the contents, then press ctrl-d.  if you have xsel installed, you can do :r !xsel to insert the "primary" (aka
save a backup of your all your grub configuration files.  there are two methods i have used in the past:  1) install ntfs-3g (which should allow your installation to see the windows partition automatically) using your package manager
the simple answer is that you can't
if you have customized the package/software at all, either by editing the config files directly, or via a gui, you may want to keep your customizations
basically, i686 is for pentium pro/ii and later, while i386 covers 386 and 486 cpus as well
you can use find with xargs for this  find /thisdir -type f -name "*.ogg" -print0 | xargs -0 -imysongs mv -i mysongs /somedir      the -i in the above command tells   xargs what replacement string you want   to use (otherwise it adds the   arguments to the end of the command).   or in your command just try to move '{}' after mv command.  find /thisdir -type f -name '*.ogg' -exec mv -i {} /somedir  \; 
the ram in a computer is useful for two things: to store the memory of programs, and as a cache of recently-used disk content
the best answer that came up so far is  test_for_redundancy=false eix -t   source  it shows a little bit more then i asked for, but it's a good starting point. 
you can modify the export histtimeformat="%h %d %t " and add the information of the filename of the terminal through the tty command, like   export terminal=`tty | cut -d\/ -f4` export histtimeformat="$terminal %h %d %t "  
from python subprocess doc :     popen.returncode  the child return code, set by poll() and wait() (and indirectly by communicate())
one of the following 2 should work:  $ nohup redshift &amp;   or  $ redshift &amp; $ disown   see the following for a bit more information on how this works:    man nohup help disown difference between nohup, disown and & (be sure to read the comments too)  
on linux, you can find the position of the file descriptor number n of process pid in /proc/$pid/fdinfo/$n
you seem pretty close with your pam conf line:  session [success=1 default=ignore] pam_succeed_if.so service in sudo quiet uid = 0   looking at the manual page for pam_succeed_if, i think you want to test that the requesting user (ruser) is zabbix.  so i suggest:  session [success=1 default=ignore] pam_succeed_if.so quiet uid = 0 ruser = zabbix   that will suppress the next test when user zabbix becomes root (but no other transitions)
if bash can't find a match, it passes the literal string to the application with *s unexpanded
as ulrich said, you can do this by enabling the userdir module.  on debian, this can be done by using the a2enmod utility, which enables or disables apache modules
assuming you already know how to use space to do normal selection in screen's copy mode, the only new keys you need are c to set the left margin, and c to set the right margin.  this is described in the screen manual. 
partial answer, since i'm not familiar with unbound.  ds belongs on the server(s) delegating to your zone's servers, not on your zone's server(s)
this sounds like a job for jq: http://stedolan.github.io/jq/. 
depending on what fits your situation you could look into customizing the filetype plugins (if you want tabstop settings by filetype) or enable modelines and accept the accompanying security risks if the settings are specific to individual files.  for the filetype approach, as an example i have the following in ~/.vim/after/ftplugin/python.vim:  setlocal expandtab softtabstop=4 shiftwidth=4  
on debian and ubuntu, the place to configure networking without network manager is /etc/network/interfaces
the lack of packages for 9.1 is due to a security incident on the freebsd network late 2012
the command to set the hostname is definitely, hostnamectl.  root ~ # hostnamectl set-hostname --static "your-hostname-here"   here's an additional source that describes this functionality a bit more, titled: correctly setting the hostname - fedora 20 on amazon ec2.  additionally the man page for hostnamectl:  hostnamectl(1)                    hostnamectl                   hostnamectl(1)  name        hostnamectl - control the system hostname  synopsis        hostnamectl [options...] {command}  description        hostnamectl may be used to query and change the system hostname and        related settings.         this tool distinguishes three different hostnames: the high-level        "pretty" hostname which might include all kinds of special characters        (e.g
1) there was a syntax error, this is the good one:   lvconvert -v -m 1 --mirrorlog mirrored /dev/archivvg6/orau011archlv /dev/mpath/orau11db6_32gcc1 /dev/mpath/orau11db6_32gcc2 /dev/mpath/orau11db6_8gcc1 /dev/mpath/orau11db6_8gcc2   cc1 cc2 cc1 cc2  but the man page doesn't really speaks about this.
you need a separate program to clear and write the new file since nc doesn't offer that option.  nc -l 7007 | while true; do     while read line; do       echo "$line" &gt; /tmp/test     done done   you can save everything after the pipe in a separate script that accepts a file path.  save-last-line.sh  while true; do     while read line; do         echo "$line" &gt; $1     done done   then it's simply:  nc -l 7007 | save-last-line.sh /var/tmp/test.log   you'll want to add checks to make sure $1 is writable and show usage when $1 isn't specified. 
find mydir -name '*.html' -print0 | xargs -0 -j % cp % ~/otherdir 
on debian squeeze/wheezy:  force unmount the local mount  umount -f /mnt/dir   then restart nfs  /etc/init.d/nfs-common restart  
pure bash solution, no external tools used to process the strings, just parameter expansion:  #! /bin/bash str='battery.charge: 90 battery.charge.low: 30 battery.runtime: 3690 battery.voltage: 230.0 device.mfr: mge ups systems device.model: pulsar evolution 500'  ifs=: read -a fields &lt;&lt;&lt; "$str"  for (( i=0 ; i &lt; ${#fields[@]} ; i++ )) ; do     f=${fields[i]}      notfirst=$(( i&gt;0 ))     last=$(( i+1 == ${#fields[@]} ))      (( notfirst )) &amp;&amp; echo -n ${f% *}      start=('' $'\n' ' ')     colon=('' ': ')     echo -n "${start[notfirst + last]}${f##* }${colon[!last]}" done echo   explanation: $notfirst and $last are booleans
you create a mode hook, which replaces lambda with the greek character
rather than type your password multiple times you can make use of pssh and its -a switch to prompt for it once, and then feed the password to all the servers in a list
 you are right in assuming that lsof uses the inode from the kernel's name cache
probably your python install is messed up: /usr/bin/lib/python2.7/... makes no sense since python installs its stuff under /usr/lib/python2.7   try removing the python package and then reinstalling it again. 
yes you can do that
you can try enabling yum's rollback feature as follows:   vi /etc/yum.conf add this line to file: tsflags=repackage vi /etc/rpm/macros (create if non-existent) add this line to file: %_repackage_all_erasures 1   now you can use rpm to rollback to different restore points:  $ rpm -uvh –rollback ’21:00′ $ rpm -uvh –rollback ’3 hours ago’ $ rpm -uvh –rollback ‘august 13′ $ rpm -uvh –rollback ‘yesterday’   all repackaged software is available here: /var/spool/repackage
you should be able to get this to run by putting in house.sh:  export display=:0.0   and running xhost + on your interface
i was running a freebsd based firewall without problems over many years with this particular issue
there's not much point in doing this
short answer:  aptitude install lxde xorg   will do.  longer answer:  the aptitude show command will show you a description of a package and its dependencies from the command line, so you can use that to decide  whether to install the package or not
apparently, leave(1) is a freebsd program, not a shell command. here is a ubuntu package for it: http://packages.ubuntu.com/search?keywords=leave&amp;searchon=names&amp;suite=trusty&amp;section=all  i guess it's not installed by default
there's no foolproof way to tell
yes, if you use notify-send -t 0 the notification will stay on the screen until you click it.  it's unfortunate that the man page doesn't mention this. 
my c is rough but it looks like the dirty bit is set when the superblock is read here
i like cyrus's answer, but this syntax also works:  #!/usr/bin/env bash  fail_color=$'\033[31;1m' color_end=$'\033[0m' function="foo" line_number="42"  printf "%serror - function: %s, line: %d%s\n" "$fail_color" "$function" "$line_number" "$color_end"   and shellcheck says "it all looks good!"
linux mint is an ubuntu derivative, you should have no problem following these instructions  vbox installation 
you really should just define a partition to contain the space
this is a limitation of bash
the issue you're experiencing is that wc -l counts new lines
the fastest solution is generally the one that introduce the less overhead compared to a non virtualized environment
you might want to checkout shorewall, is a tool for configuring iptables
i am developer of libburn and work since a year with about the same system as mentioned here
sounds like you want the opposite of printing them literally, you want those escape characters converted to a printable descriptive form like \e or \033, ^[...  if it's just the esc (0x1b) character you want to convert to \e, then with ksh93, zsh or bash (typically, the same ones that also support that non-standard %q), you can do:  printf '%s\n' "${red//$'\e'/\\e}"   or pipe to sed $'s/\e/\\\\e/g'  for a more generic approach at converting non-graphical characters, you can use:  $ printf %s "$red" | od -a n -vt c # posix  033   [   3   1   m $ printf %s "$red" | sed -n l # posix \033[31m$ $ printf '%s\n' "${(qqqq)red}" # zsh $'\033[31m' $ printf '%s\n' "$red" | cat -vt # some cat implementations ^[[31m $ printf %s "$red" | uconv -x ':: [:cc:]; ::hex;' # icu tools \u001b[31m $ printf %s "$red" | uconv -x ':: [:cc:]; ::name;' # icu tools \n{&lt;control-001b&gt;}[31m  
you can put the man pages in this directory:  $home/.local/share/man   accessing directly  and then you can access them directly using man:  man $home/.local/share/man/manx/manpage.1.gz   $manpath  you can check what the $manpath is with the command manpath, or echo out the environment variable $manpath.  examples  $ manpath manpath: warning: $manpath set, ignoring /etc/man_db.conf /home/saml/apps/perl5/perlbrew/perls/perl-5.14.0/man:/home/saml/.rvm/rubies/ruby-1.9.2-p180/share/man:/home/saml/.rvm/man:/usr/local/share/man:/usr/share/man:/usr/brlcad/share/man:/usr/man:/usr/brlcad/share/man:/usr/brlcad/share/man  $ echo $manpath /home/saml/apps/perl5/perlbrew/perls/perl-5.14.0/man:/home/saml/.rvm/rubies/ruby-1.9.2-p180/share/man:/home/saml/.rvm/man:/usr/local/share/man:/usr/share/man:/usr/brlcad/share/man:/usr/man:/usr/brlcad/share/man:/usr/brlcad/share/man   you can add things to the manpath temporarily:  manpath=$home/.local/share/man:$manpath   if you want to make this permanent then add a file in your /etc/profile.d/ directory called myman.bash with the above manpath= line in it
you can close stderr as in:  ls /blah 2&gt;&amp;-   while that will work in most cases, it may cause problems as poorly written applications may end up opening a new file which would automatically get 2 as the file descriptor and could end up writing error messages where you wouldn't want them to.  that also means that any write to stderr done by the application would return with an error (ebadf) which may affect their  behavior.  as pipes are allowed, you could provide with a command that discards all its input
i had a similar problem, installing opensuse 13.2 x86_64 from scratch, using a boot partition and an encrypted lvm containing root and swap
i found a python library, fonttools (pypi) that can be used to do it with a bit of python scripting.  here is a simple script that lists all fonts that have specified glyph:  #!/usr/bin/python  from fonttools.ttlib import ttfont import sys  char = long(sys.argv[1], base=0)  print u"looking for u+%x (%c)" % (char, unichr(char))  for arg in sys.argv[2:]:     try:         font = ttfont(arg)          for cmap in font['cmap'].tables:             if cmap.isunicode():                 if char in cmap.cmap:                     print "found in", arg                     break     except exception, e:         print "failed to read", arg         print e   first argument is codepoint (decimal or hexa with 0x) and the rest is font files to look in.  i didn't bother trying to make it work for .ttc files (it requires some extra parameter somewhere).  note: i first tried the otfinfo tool, but i only got basic multilingual plane characters (&lt;= u+ffff)
a virtual machine (vm) is quite a generic term for many virtualisation technologies.  there are a many variations on virtualisation technologies, but the main ones are:   hardware level virtualisation operating system level virtualisation     qemu-kvm and vmware are examples of the first
you can use chmod command for changing the rights or permissions for the folder &amp; chown command for changing the ownership.  for changing the ownership you need to use sudo from root to yourself.  here is the syntax  to change the ownership for the folder alone.  sudo chown &lt;username&gt;:&lt;groupname&gt; &lt;foldername&gt;   to change the ownership to the folder recursively for all the files and folders inside the folder.  sudo chown -r &lt;username&gt;:&lt;groupname&gt; &lt;foldername&gt;  
squeeze3 is the third patch release for squeeze, squeeze5 is the fifth
there is timestamp_timeout option in your /etc/sudoers
as someone who has successfully removed the /windows subdirectory from a running windows system, and deleted the contents of /bin on a running linux boxen (it didn't die!)..
it's not really clear what you're asking.  apt-get is package manager - it is used to get packages(programs) from repository, which is remote server, to your computer - and install them
i figured this one out by examining ps awwwwx|grep gnome after logging in normally
this is technically what cat ("concatenate") is supposed to do, even though most people just use it for outputting files to stdout
from what i can tell, it looks like your best bet is to start with the format variable client_prefix when you define your status line.  for your reference, there's a solid answer to a similar question on so by chris johnsen that you might reference:   http://stackoverflow.com/questions/12003726/give-a-hint-when-press-prefix-key-in-tmux  this is a good question, and would prove to be a very useful addition to my workflow
in this example, we create a 8gb swap file in /root/ directory
agrep can do it with this syntax:  agrep 'pattern1;pattern2'   with gnu grep, when built with pcre support, you can do:  grep -p '^(?=.*pattern1)(?=.*pattern2)'   with ast grep:  grep -x '.*pattern1.*&amp;.*pattern2.*'   (adding .*s as &lt;x&gt;&amp;&lt;y&gt; matches strings that match both &lt;x&gt; and &lt;y&gt; exactly, a&amp;b would never match as there's no such string that can be both a and b at the same time).  if the patterns don't overlap, you may also be able to do:  grep -e 'pattern1.*pattern2' -e 'pattern2.*pattern1'   the best portable way is probably with awk as already mentioned:  awk '/pattern1/ &amp;&amp; /pattern2/'   with sed:  sed -e '/pattern1/!d' -e '/pattern2/!d'   please beware that all those will have different regular expression syntax. 
no, you can't shorten the left hand side of the comparison
this could be used to encrpyt a file mypic.png, given you already have a private/public keypair in ccbild-key.pem/ccbild-crt.pem
to extract a specific directory (and its contents, recursively), just pass it as an extra argument on the command line
you do the 2&gt;&amp;1 on the remote machine
it is possible
it appears that this was my problem:  bug #201786 “ssh agent admitted failure to sign using the key on...” : bugs : “gnome-keyring” package : ubuntu https://bugs.launchpad.net/ubuntu/+source/gnome-keyring/+bug/201786  to resolve my problem all i did was run ssh-add on the virtualbox instance running on my laptop:  ssh-add ~/.ssh/my_other_key   which is the solution mentioned in this comment: https://bugs.launchpad.net/ubuntu/+source/gnome-keyring/+bug/201786/comments/58  i do not understand why the problems shows up only when running virtualbox, but since some feel it is related to endian-ness, maybe that explains it in a very nebulous way
you want command substitution, not redirection:  cd "$(locate descargas | grep -f 'descargas$')"   the bits between the $( and the ) are run as a command and the output (stripped of any final newline) is substituted into the overall command.  this can also be done with ‘back ticks’ (“`”):  cd "`locate descargas | grep -f 'descargas$'`"   the dollar-paren syntax is generally preferred because it is easier to deal with in nested situations:  # contrived cd "$(grep '^dir: ' "$(locate interesting-places | head -1)" | sed 's/^[^ ]*//')"  
the solution i found was to run the following:  sudo sed -i \     's/allowed_users=console/allowed_users=anybody/' /etc/x11/xwrapper.config   note, that in your situation, the console may be root or another, based on your particular initial configuration* 
/dev/mapper is used by lvm
if i had to make an educated guess about what's going on here, i'd say that firefox first looks for an open firefox window before launching, and if that exists sends it a message using x to just start a new browser window
the idea how to get plain version of man pages one can find in man man:  man foo | col -b   based on that you can can get only one section for example with pcregrep:  man man | col -b | pcregrep -mo '^see also(.|\n)*?^[^ ]'   you can adjust it a little bit and put into function to grep in any section of any manual easily:  gsman () { man $1 | col -b | pcregrep -imo "^$2(.|\n)*?(?=\n[a-z])" ; }   and usage would be  gsman grep options | grep invert  
you can specify the architecture for apt to use by modifying the source entry (adding [arch=architecture] or during installation (apt-get install package:architecture)
tail lets you add -n to specify the number of lines to display from the end, which can be used in conjunction with -f
the short answer is no, i'm pretty sure no such program exists.  you could in principle build one; it would have to look at the readline configuration and at the terminal emulator (the kernel and hardware are not involved).  bind -p | grep 'can be found' in bash lists the key bindings.  abort can be found on "\c-g", "\c-x\c-g", "\e\c-g". accept-line can be found on "\c-j", "\c-m".   to have a more descriptive name for the command you'd need to parse the bash or readline documentation.  the correspondance between key sequences and keys is determined by the terminal (usually, the terminal emulator)
update for pcmanfm v
number  start   end     size    file system     ......................................         468gb   520gb   52.4gb  free space   well, as you can see start is 468gb and end is 520gb
i figured this out
from the top manpage:   -n : number of iterations limit as:  -n number         specifies the maximum number of iterations,         or frames, top should produce before ending.    so just run:  top -n 1  
first and foremost, and i realize that it was not one of the terms from your question, you must understand metadata
insted of .bashrc put the setting line to /etc/profile
an executable refers to any file with the executable bit set that could be executed (even if there are errors in the actual running of the program).  a shell script is a specific type of executable that is intended to be interpreted by a shell using the #! directive to specify an interpreter. 
what i usually do in my dual-boot installations is to keep separate paritions for windows and linux, keeping also the /home folder inside the linux partition as well
you can list all currently active keybinds in tcsh with the bindkey command:  % bindkey standard key bindings "^@"           -&gt;  set-mark-command "^a"           -&gt;  beginning-of-line "^b"           -&gt;  backward-char "^c"           -&gt;  tty-sigintr ..
you should disable them using either systemctl (if you're using systemd) or update-rc.d:  systemctl disable apache2 mysql   or  update-rc.d apache2 disable update-rc.d mysql disable  
many programs that generate colored output detect if they're writing to a tty, and switch off colors if they aren't
use wait:  # start the job: ksh -x myscript.sh 20150102 &amp;  # save its process id job_pid=$!  # do some other stuff in the meantime asdf ghjk zxcv qwer  # later, when you want to know what its exit status was: wait $job_pid if [ $? -ne 0 ]; then     echo "something may have gone wrong" &gt;&amp;2 else     echo "the world is perfect." &gt;&amp;2 fi   in this context, i'm considering "return code" and "exit code" synonymous
it looks like fgconsole (part of the kbd package on fedora) does what you want. 
i think the programmers of zypper intended it more for installation of source packages than for download
from this answer to "install gcc 4.7 on centos [6.x]", the easiest way to get g++ 4.7, and the required tools and libraries, for centos 5.x is via the devtools package:  cd /etc/yum.repos.d wget http://people.centos.org/tru/devtools/devtools.repo  yum --enablerepo=testing-devtools-6 install devtoolset-1.0   since you're running g++ manually (as opposed to through make), you'll need to update your $path variable so your shell will use the new gcc, g++, etc
this is my understanding of the situation, but i'm not an expert so it is less technical than the other answers
you can't change some language setting and your script's echo commands will magically be another language.  you can do one of the following:   source a language file. create a bash script that converts the original bash script. create a function in the bash script that translates the output.   as you're not keen on the dict solution as it's too google translatey..
check the output of make listnewconfig. 
editing the lsb init.d info header in an init.d script will not directly modify the start order and such
from what i found, noip2 includes the script /etc/init.d/noip2, (also here, for those not running debian right now) which should already be all you need
those are batch scripts – as in ms windows batch
that is the contents
the [[:alnum:]] character class represents alphabetic and numeric characters, you can use   [^[:alnum:]]  for non alpha numeric so for your goal:     my target is to work with all kind of characters non alpha numeric and alpha numeric    you can use this expression [[:alnum:]] | [^[:alnum:]]  so the awk command will be something like this:  awk 'gsub(/("[ ]+|[ ]+")/,"\""){$0=gensub(/"(([[:alnum:]]|[^[:alnum:]])+)"/,"\\1","g")}1' file.csv  
this is just bash shortcuts
if you are on a systemd based distribution with a util-linux version less than 2.27, you will see this unintuitive behaviour
you cannot refer variable updates made in the child process (pipe connected while block).  instead, feed data using input redirection like this:  #!/bin/bash  data_file="$1" down=() counter=0  while read line; do     iseven=$(( $counter % 2 ))     if [ $iseven -eq 0 ]; then         down+=("$line")     fi     (( counter ++ )) done &lt; $data_file  echo ${down[@]}    exit  
open the terminal with a program that sits there doing nothing
you can achieve this in any terminal emulator by the simple expedient of arranging for the program not to exit without user confirmation
there is no way to do this from inside the terminal
open a text editor
you can use the ts program from moreutils to add a timestamp to each line.  { echo foo; sleep 1; echo bar; } | ts dec 13 01:07:23 foo dec 13 01:07:24 bar   to read from the serial port and output to a file:  ts &lt;/dev/ttys0 &gt;arduino.log   (replace /dev/ttys0 by the right path for the serial port device, .) 
use ssh-agent and ssh-add all the keys you need to it.  example:  # start the agent and capture its environment in the current shell eval `ssh-agent`  # add keys needed to connect to the different accounts ssh-add /path/to/first/ssh/key ssh-add /path/to/second/ssh/key  # do the copying scp first@host1.example.com:file1 second@host2.example.com:file2  
a simple but not elegant solution will be add the file name in the first line of each file:  for x in $(ls regional_vol*.txt | sort -n); do    echo ${x} &gt; tmp-${x}    cat ${x} &gt;&gt; tmp-${x} done  paste tmp-regional_vol*.txt &gt; final_table.csv rm tmp-regional_vol*.txt  
are these errors really fatal, i.e
if your solution depends on correctly creating a sym link to /my_path/node, then the problem might be with your command to make a sym link, your original post says:  lns /my_path/node   doesn't it give you an error?  the correct syntax for creating a sym link or soft link, is ln -s target, so applied to your example:  ln -s /my_path/node   also remember if the directory you are trying to create a sym link in requires root priviledges, you may need to use sudo ln -s /my_path/node  
maybe this example is just extremely oversimplified, but i'm having trouble seeing why you wouldn't just run:  cp /etc/httpd/conf/httpd.conf /a.txt   that is, there's already a command that simply reads from one file and creates another with its contents, and it's called cp
   so is it possible to check how many sessions are running and will it be possible to check for http also?   a web application needs to be configured or programmed to enumerate active sessions, but for a list of users and idle times for ssh sessions...  w | tr -s " " | cut -d " " -f 1,5 | tail -n +3   see the notes section in the man page for w
when you want to modify a file, you have two options, each with its benefits and drawbacks.   you can overwrite the file in place
no, this is not currently possible.  the only thing you can do about this without restarting the server is to override the name manually when creating a new session by issuing tmux new -s 5, for example:  $ tmux new -d -p 10: $ tmux ls 10: 1 windows (created wed jan  7 15:50:29 2015) [107x89] $ tmux new -s 5 -d -p 5: $ tmux ls 10: 1 windows (created wed jan  7 15:50:29 2015) [107x89] 5: 1 windows (created wed jan  7 15:50:40 2015) [107x89] $ tmux new -s 5 -d -p duplicate session: 5     the automatic session number is governed by the global variable u_int next_session_id in session.c which cannot be accessed from the command line, as grepping the source code reveals.  tmux new-session calls session_create() in session.c (line 88) and next_session_id is incremented whenever you create a new session
yes
here's what you're looking for:  http://www.linuxfromscratch.org/ 
you could use nohup combined with &amp;:  nohup cf logs broker-analytics &gt; /var/www/cfbrokerlogs/message.log &amp;   the nohup command causes the program to ignore hangup signals (i.e
you should verify the .iso image : steps to verify an iso image  the available linux image come wiht the .iso extension and not .iso.part  before unplugging your usb it is recommanded to run sync   there is an example:  dd if=linuxmint-18-xfce-64bit.iso of=/dev/sdb bs=4m &amp;&amp; sync   edit      the syncis to make sure that all the writes are flushed out before the command returns.      if is input file (or device), of is output file (or device)      bs=4m tells dd to read/write in 4 megabyte chunks for better performance; the default is 512 bytes, which will be much slower  
the bash internal command source, first looks for the filename in path, unless there is a slash (/) in the filename
you can use rpm -qf /bin/ls to figure out what package your installed version belongs to:  [09:46:58] ~ $ rpm -qf /bin/ls coreutils-8.5-7.fc14.i686 [09:47:01] ~ $    update: per your comment, the following should work if you want only the name of the package (i just got a chance to test):  [01:52:49] ~ $ rpm -qf /bin/ls --queryformat '%{name}\n' coreutils [01:52:52] ~ $    you can also use yum provides /bin/ls to get a list of all available repository packages that will provide the file:  [09:47:01] ~ $ yum provides /bin/ls loaded plugins: fastestmirror, langpacks, presto, refresh-packagekit adding en_us to language list loading mirror speeds from cached hostfile  * fedora: archive.linux.duke.edu  * rpmfusion-free: mirrors.tummy.com  * rpmfusion-free-updates: mirrors.tummy.com  * rpmfusion-nonfree: mirrors.tummy.com  * rpmfusion-nonfree-updates: mirrors.tummy.com  * updates: mirror.vcu.edu coreutils-8.5-6.fc14.i686 : a set of basic gnu tools commonly used in shell                           : scripts repo        : fedora matched from: filename    : /bin/ls    coreutils-8.5-7.fc14.i686 : a set of basic gnu tools commonly used in shell                           : scripts repo        : updates matched from: filename    : /bin/ls    coreutils-8.5-7.fc14.i686 : a set of basic gnu tools commonly used in shell                           : scripts repo        : installed matched from: other       : provides-match: /bin/ls  [09:47:01] ~ $  
my current solution is  rm -f "$(readlink -f "a")"; rm -rf "a"   but maybe there's something easier? 
install samba
using the example in the question, put the following inside the "~.jhbuildrc" file (reference):  module_autogenargs = {"mutter": "--disable-werror"}  
googling easily leads to a message on a debian mailing list which is in fact debian bug #578704, a proposed addition to the release notes (snipped):     since the rewrite has absolutely zero compatibility with previous   versions, it will not be upgraded in place
you can run sshfs with the "reconnect" option
i only use the special signs when i write code so i managed to fix this is sublime text.  in preferences -> key bindings - user  insert the following:  [ { "keys": ["ctrl+alt+2"], "command": "insert", "args": {"characters": "@"} }, { "keys": ["ctrl+alt+3"], "command": "insert", "args": {"characters": "£"} }, { "keys": ["ctrl+alt+4"], "command": "insert", "args": {"characters": "$"} }, { "keys": ["ctrl+alt+5"], "command": "insert", "args": {"characters": "€"} }, { "keys": ["ctrl+alt+7"], "command": "insert", "args": {"characters": "{"} }, { "keys": ["ctrl+alt+8"], "command": "insert", "args": {"characters": "["} }, { "keys": ["ctrl+alt+9"], "command": "insert", "args": {"characters": "]"} }, { "keys": ["ctrl+alt+0"], "command": "insert", "args": {"characters": "}"} }, { "keys": ["ctrl+alt++"], "command": "insert", "args": {"characters": "\\"} }, { "keys": ["ctrl+alt+&lt;"], "command": "insert", "args": {"characters": "|"} }   ] 
evince is updating the pdf automatically
yes, you are terminating it.  to disconnect from the screen session press ctrl+a followed by d.  to reconnect to screen session - you need to first get screen session id.  screen -list   followed by  screen -r sessionid  
if i understand the question correctly you should be able to cycle through alternatives by repeatedly hitting ctrl+r.  e.g.:  ctrl+r grep ctrl+r ctrl+r ... 
ps aux is the berkley standard of ps.  ps [ a ] [ c ] [ e ] [ ew ] [ eww ] [ ewww ] [ g ] [ n ] [ w ] [ x ] [ l | s | u | v ] [ t tty ] [ x ] [ processnumber ]  a = displays information about all processes with terminals (ordinarily only the own processes of the user are displayed). u = displays user-oriented output
you can set the "immutable" attribute with most filesystems in linux.  chattr +i foo/bar   to remove the immutable attribute, you use - instead of +:  chattr -i foo/bar   to see the current attributes for a file, you can use lsattr:  lsattr foo/bar   the chattr(1) manpage provides a description of all the available attributes
this is not supposed to be possible; either you are running a vulnerable version of some software or you have misconfigured something.  under normal configurations, connecting to an x server requires a sort of password called “x cookie”
use -r option for extended regexp syntax:  sed -r -e 's/foo|bar/narf/g'   otherwise escape the disjunction as \|:  sed -e 's/foo\|bar/narf/g'  
the information that df produces comes from the statvfs() system call
the nul character is not included when the md5 is calculated
where would the error be sent when running file_2?  when you type ./file_2 (with said file executable), the system actually runs /bin/sh ./file_2 -- i.e
you could scan your localhost for open ports using a tool like nmap.  nmap -v -st localhost   nmap can be built from source or installed from the repo of most (if not all) major distros. 
the "system settings" and "font" dialog will (as a rule) affect only desktop applications which have been integrated with it
try using cut, like: cut -d/ -f6 file 
you wrote (redundant parentheses added for clarity):  find zunorganized/ \( -not -iname "*.mp3" -and -not -iname "*.flac" -and -not -iname "*.mp3" -and -not -iname "*.wav" \) \                -or \( -not -iname "*.m4a" -and -not -iname "*.jpg" \)   either use -and -not throughout, or use or throughout and finish with -print (meaning: do nothing for this, otherwise do nothing for that, etc, otherwise print)
when you have the file open, you can run:  :set filetype=messages   to automate this for all files called messages, put the following into ~/.vim/ftdetect/messages.vim:  autocmd bufnewfile,bufreadpost *messages* :set filetype=messages  
i don't have ack-grep utility on my mac so will this awk solution work for you?   awk -v fs=[?\"] '/param/{print filename; print $3 }' input_file   execution:  [jaypal:~/temp] cat file0 &lt;a href="http://example.com/fnord.layername.html?parameter=foo-_-bar-_-fnord" class="poit"&gt;     &lt;img ..
compression algorithms are declared in lib/decompress.c
this small shell script will loop through every file in the current directory and compare it's last-modified timestamp to the range that is built by the start and end timestamps (here, october 10th)
in /var/log, you can delete everything that ends with .1 or .2.gz (or 3, or 4, or whatever)
   when i add that path to path in /etc/environment, the user can call the script without providing the full path but the daemon can not; it just says "not found".   according to this source, which is ibm aix documentation (i could not find anything else) but is presumably true in general:1      the first file that the operating system uses at login time is the   /etc/environment file
vim is a modal editor
usually, sysstat, which provides a sar command, keeps logs in /var/log/sysstat/ or /var/log/sa/ with filenames such as /var/log/sysstat/sadd where dd is a numeric value for the day of the month (starting at 01)
unfortunately, there is no way to use a variable in that expansion (afaik), since variable expansion happens after brace expansion.  fortunately, there's a tool that does the same job.  for i in $(seq 1 $numlines); do     # stuff done   seq is from gnu coreutils; no idea how to do it in posix. 
 the cgroup document suggests flushing all file system buffers and free pagecache, dentries and inodes using the following commands:  ~]# sync  ~]# echo 3 > /proc/sys/vm/drop_caches it's possible you have not reached the peak of iops
-exec is a predicate that runs a command (not a shell) and evaluates to true or false based on the outcome of the command (zero or non-zero exit status).  so:  find 
there's not really such a thing as a "library call"
a linux distribution consists of many pieces
by default, gpg stores everything under the .gnupg directory in your home directory
microsoft windows and gnu/linux, along with other unix-like systems, are based on very different approaches to user interaction
fwiw,   prob=$(echo "0.0139" | bc)   is unnecessary - you can just do   prob=0.0139   eg,  $ prob=0.0139; echo "scale=5;1/$prob" | bc 71.94244     there's another problem with your code, apart from the underflow issue
this one can work, but only if you allow access to port 3306 from the outside: (but this doesn't work)  iptables -t nat -a prerouting -p tcp --dport 34306 --syn -j dnat --to :3306   what you ultimately want to do though, is: (but this doesn't work either)  iptables -t nat -a prerouting -p tcp --dport 34306 --syn -j dnat --to 127.0.0.1:3306   that is, you want packets to port 34306 on an external interface to be redirected to 127.0.0.1, port 3306
you are not specifying an archive in your statements. it should look something like:  tar -cvf tar2/tar1.tar tar1/   this places the tarball tar1.tar inside the directory tar2/.  before:  tree tar* tar1 ├── a.txt └── b.txt tar2 ├── a.txt └── b.txt  0 directories, 4 files   after:  tar -cvf tar2/tar1.tar tar1/ tar1/ tar1/a.txt tar1/b.txt  tree tar* tar1 ├── a.txt └── b.txt tar2 ├── a.txt ├── b.txt └── tar1.tar  0 directories, 5 files     environment:  distributor id: debian description:    debian gnu/linux 8.6 (jessie) release:    8.6 codename:   jessie  
this should work, i have tested it on the output you posted
firstly,   $cur_date=20150405 $cur_time=12:35:12   should be  cur_date=20150405 cur_time=12:35:12   also, don't use backticks, they're deprecated
i've written the following expect script for this, and it works (on my vms). sample run:  ./scp.exp &lt;first host user&gt; &lt;first host user pass&gt; &lt;first host name&gt; &lt;second host name&gt; &lt;second host user&gt; &lt;second host user pass&gt; &lt;directory path i.e
(this answer assumes you installed in a separate partition on the same drive with your windows partition.)  you should look into using a program like gparted to resize your partions and the file-systems inside them
and here's a nice, simple, gawk one-liner :  $ gawk '/^\[/{match($0, /^\[ (.+?) \]/, k)} {print &gt;k[1]".txt" }' entry.txt   this will work for any file size, irrespective of the number of lines in each entry, as long as each entry header looks like [ blahblah blah blah ]
there are some occasions when bash creates a new process, but the old value of $$ is kept
here's a quickie script which will do what you need:  #!/bin/bash logdir=/var/log/somedir oldlogs=/var/log/keep-old-logs-here path=/bin:$path today=$(date +'%y%m%d')  [ -d $oldlogs ] || mkdir -p $oldlogs  cd $logdir  for log in $(ls | egrep '^[[:digit:]]{8}$'); do     [ $log -lt $today ] &amp;&amp; gzip $log &amp;&amp; mv $log.gz  done   make the script executable:  $ chmod +x /where/you/put/this/script   the crontab entry will look like:  30 0 * * * /where/you/put/this/script   just adjust logdir and oldlogdir
yes, both option will work because then linux will not try to probe the driver hence no accesses will be made. 
record my desktop supports jack
use reboot -p instead
assuming your remote server has a posix-compliant shell, the following should work:  ssh ...options..
edit smb.conf and find a line like this,   smb ports = 445 139  change this default port to   smb ports = 2222 2000  then restart samba server
zsh is one of the few shells (the other ones being tcsh (which originated as a csh script for csh users, which also had its limitation, tcsh made it a builtin as an improvement)) where which does something sensible since it's a shell builtin, but somehow you or your os (via some rc file) broke it by replacing it with a call to the system which command which can't do anything sensible reliably since it doesn't have access to the interns of the shell so can't know how that shell interprets a command name.  in zsh, all of which, type, whence and where are builtin commands that are all used to find out about what commands are, but with different outputs
such a thing already exists for ubuntu:     https://apps.ubuntu.com/   you can browse by category and search for packages using the web interface
assuming gnu date, you have almost the right command in your question:  $ date --date="05/02/2012 +2 days" fri may  4 00:00:00 eest 2012   to get the exact string 4 may, use this:  $ date --date="05/02/2012 +2 days" +"%e %b" 4 may  
after spending time with vagrant i got the solution for custom box. first of all install any linux os in libvirt/qvm and login to it for customization and create vagrant user with password vagrant  adduser vagrant   vagrant user should be able to run sudo commands without a password prompt   sudo visudo -f /etc/sudoers.d/vagrant   and paste   vagrant all=(all) nopasswd:all   do whatever you want to customize your vagrant box and install openssh-server if not installed previously    sudo apt-get install -y openssh-server   put ssh key from vagrant user  mkdir -p /home/vagrant/.ssh chmod 0700 /home/vagrant/.ssh wget --no-check-certificate \ https://raw.github.com/mitchellh/vagrant/master/keys/vagrant.pub \ -o /home/vagrant/.ssh/authorized_keys chmod 0600 /home/vagrant/.ssh/authorized_keys chown -r vagrant /home/vagrant/.ssh   open sudo vi /etc/ssh/sshd_config and change   pubkeyauthentication yes authorizedkeysfile %h/.ssh/authorized_keys permitemptypasswords no passwordauthentication no   restart ssh service using   sudo service ssh restart   install additional development packages for the tools to properly compile and install   sudo apt-get install -y gcc build-essential linux-headers-server   do any change that you want and shutdown the vm 
printf applies its format string to each argument that follows it on output
since you are doing this on a mac, this sed will do it: sed 's/{$/\'$'\n{/'  example:  echo "public class test {  }" | sed 's/{$/\'$'\n{/' public class test  {  }   if you want to edit the file "in place" execute this command:  sed -i "" 's/{$/\'$'\n{/' java   result:  cat java  public class test  {  }   here is a reference on inserting newlines in sed on mac.    tested in os x 10.11.6 
if the floppy drive is not in use anyway, the better solution may well be to simply disable the floppy module
so, it sounds like you have not installed a boot loader (e.g
you would want to use the utility ecryptfs-find  
there is no correlation between the number of processes and the “clarity” of an operating system
restore it with dd and then resize the partition(s) with gparted running from bootable media
the universal way to solve every computer problem¹ is to add a level of indirection.  instead of calling edit-command-line, call a wrapper function.  nano-command-line () {   local visual='nano -y sh'   edit-command-line } zle -n nano-command-line bindkey '^x^e' nano-command-line   ¹  hyperbole
yes, you can run x without anything else -- sort of, because what will happen is it ends right away, which i think is what is happening here.  to test this, make sure you have xterm installed by trying it from the console
you can use blktrace (available in debian) to trace all the activity to a given device; for example  sudo blktrace -d /dev/sda -o - | blkparse -i -   or just  sudo btrace /dev/sda   will show all the activity on /dev/sda
first you need to make sure that your particular version of ffmpeg was built with and supports that switch
if you leave out one of the sides of the range, it means the end
if you're logging into a graphical session, arrange to start ssh-agent during your session startup
it sounds like you're asking for a solution to the bin-packing problem
you can list a host (ip address) under as many domains (names) as you wish
the easiest way to install software is to let someone else build it for you
there are 3 main implementations of ksh   the original one from david korn (at&amp;t ksh), with two main branches: ksh88 and ksh93 (and for ksh93, many version with new features added for each). pdksh, the public domain version (a free reimplementation of ksh88 with which it is mostly compatible) which is the base upon which is built the sh on some bsds like miros or openbsd (hence mksh and oksh). the zsh implementation
i got an answer from mtwebster here (see the comments), which i feel is the "right" answer :  check out this file: https://github.com/linuxmint/mdm/blob/master/config/init.in  this runs before the greeter in mdm (if you look at the recent commit there, we added syndaemon to run, to disable the touchpad while typing.  you should be able to add a shell script to /etc/mdm/init to run your program – if not, at the very least you can add it to the /etc/mdm/init/default script. 
upgrading the standard library is risky, as some programs and libraries may depend on the current version.  my recommendation if you need to run newer programs is to install a full chrooted distribution
you may remove the ampersand (&amp;): spawn always operates that way
according to this page you can convert your dsa keys to a format that putty will accept with a putty tool, putty key generator.  there is more detail on this page which describes importing your rsa or dsa key into  putty format
 i use an external drive, where i backup some of my folders and dotfiles with rsync -avz once the first snapshot is taken, it only needs very little data to move onto the external drive for backups. pretty much all of that information is stored in a dotfile or in some dotdirectory
when they are not quoted, $* and $@ are the same
those options work by passing options to the compiler, so the most straightforward way is to recompile the kernel
you can do this by creating or editing a file called user-dirs.dirs in ~/.config
this is impossible because it's the linux kernel that creates and manages the ram disk.  responding to a later amendment to your question, asking how to reserve a chunk of memory that the os cannot access. the os manages all your access to the hardware
in normal mode, j (as distinct from j, which moves the cursor down one line) is used to join a line with the one directly beneath it
if i understand the requirement properly you should be using -path ..
you can list files under /proc with ls, and you can read their content with cat (with a few exceptions — /proc/pid/mem is peculiar).  file under /proc reflect the current state of the system, so they might exist at one moment and no longer exist the next moment
just repeat the substitution until output doesn't change:  $ echo 'a|b|c|d|||e' | sed ':x;s/||/|""|/g;tx' a|b|c|d|""|""|e   where   :x sets the label x t x go to label x if s/// was successful  
the -rescue option is meant to "continue reading past block read errors." as per this manual.  this means that it doesn't stop when it reaches a sector error
rts and dtr are output pins - which you can set.  dcd and cts are input pins and can only be read.  the device is probably set for hardware handshaking by default
you could do it in one line without the tunnel using something like:  $ ssh user@remote "mysqldump -u user --password=password database_name" |    mysql -u local database_name  
the core(5) manpage describes the parameters affecting core dumps in detail, including their naming etc.  to answer your stated question, there is no generalisable way to find a core dump
quote the command:  echo "`ps aux --sort -rss`"   otherwise bash just parses the tokens, ignoring whitespace including newlines like it does when you type it by hand. 
thanks to mark plotnick, there was an entry in cron coinciding with the time of crash (4:30am - run dmesg -t to display absolute times)
after a bit of googling, i found an answer with the discovery an app called screen
the kernel line in grub should looks like:  kernel /vmlinuz-3.1.4-1.fc16.x86_64 ro root=/dev/volgroup00/logvol00 rhgb lang=en_us.utf-8 crashkernel=128m   there's a note in the instructions:     (...) an example command line might look like this (for grub2, "kernel" is replaced by "linux"):   so, the one you are looking for is how to replace the kernel boot parameters
i have figured out my problem at:   https://github.com/passingthru67/workspaces-to-dock/issues/75   this is the patch i'm applying to /usr/share/themes/arc-dark/gnome-shell/gnome-shell.css for now (besides adopting the nice workspaces-to-dock):  @@ -1440,17 +1440,10 @@  .workspace-thumbnails-left:rtl {    visible-width: 40px;    spacing: 11px; -  padding: 12px; } - -.workspace-thumbnails, -.workspace-thumbnails-left:rtl { -  padding-right: 7px; -  border-image: url("common-assets/dash/dash-right.svg") 9 9 9 9; } - -.workspace-thumbnails:rtl, -.workspace-thumbnails-left { -  padding-left: 7px; -  border-image: url("common-assets/dash/dash-left.svg") 9 9 9 9; } +  padding: 12px; +  background-color: transparent; +  border: 1px solid transparent rgba(82, 148, 226, 0.8); +  border-radius: 1px; }   .workspace-thumbnail-indicator {    border: 4px solid rgba(82, 148, 226, 0.8);      
it displays the notification icon that indicates that you currently have superuser privileges in some situations
this kind of question cannot possibly be answered objectively
follow these steps:   start up windows just like you normally would, and download the latest (non-test) version of plop boot manager here. extract the zip and open the folder "windows" in it
the terms 'stable' and 'unstable' are relative
you only choose audio card once when starting jackd
this is not possible with a stock gedit; there's an open ubuntu brainstorm idea for adding the ability
you have to worry about more than just $java_home; you also need to set $path if you are going to call the commands without an absolute path
m-c-b works for me
tl;dr: recursive queries are part of the way the internet and dns work, but not all dns servers should be receiving recursive queries, and when the ones that shouldn't respond do respond you can get problems.  longer version:     recursion, n: see under recursion.   a recursive dns query happens when the dns server you asked for the address of, say, unix.stackexchange.com doesn't know the answer itself, so it has to check with another server.  normally this is actually how dns works -- the dns server of your isp does not have the entire internet's domain records permanently memorized for obvious reasons, so the following exchange happens under the hood:   you: hey, browser, show me http://unix.stackexchange.com browser: sure thing! ..
you could use find with a type argument
you can pipe the entire set of commands directly to dc.  printf "1 2 3 - - p" | dc   if you'd like to subtract an arbitrary stack you can use a macro.  printf "%s [-z1&lt;r]srz1&lt;rp" "&lt;insert numbers here&gt;" | dc   so for example  printf "%s [-z1&lt;r]srz1&lt;rp" "100 5 2 1" | dc 96   the macro does the following:   [ start macro - subtract top two numbers and push back to stack z1&lt;r push stack size to stack and 1, then compare lessthan, if true run r macro ]sr end of macro, store in register r z1&lt;r check if stack contains elements by testing 1 &lt; stack size p print result. `  
the dns srv record is a way publish a defined service endpoint
for the system using rpm (yum) package manager, for instance (here) centos, use yum provides or yum whatprovides:  provides or whatprovides               is used to find out which package provides some feature or               file
to get an idea of why your process dies, make its parent process print the exit status
when you create a virtual machine and provision virtual network interfaces inside it, each virtual network interface gets a corresponding network interface in the host
turns out alsa will automatically mute my main speakers when something plugs in the headphone jack
similar sounding bug?  not sure if this issue is related or not but if you look at the details of this issue in the bluefish bugzilla issue tracker
you are having problems with idempotency because you are using keysym instead of keycode
i'm not sure you will like this answer, but, in my experience too, using ptp has always caused a high wtf/min
banner; on my system it's called printerbanner
you actually want to disable the desktop directory and prevent the de to automatically recreate it
newer versions of midnight commander use alt-o (also esc followed by o) to do this.  older versions used alt-o for doing a change directory to the currently highlighted directory, so it will depend on which build you are using. 
right from the man page you reference:  elf - format of executable and linking format (elf) files   elf defines the binary format of executable files used by linux
there are two  answers for this question.  on centos 7 systemd is how you can run a service or script on start you put a .service file under /etc/systemd/system, which can look like this:  ; /etc/systemd/system/swift.service [unit] description=swift  [service] type=notify execstart=myscript  [install] ; runlevel here:  wantedby=multi-user.target   but actually systemd can be used for mounting devices directly, if this is the intention of your script.  for a (non-rpm-packaged) service you would put the a ".mount" file under /etc/systemd/system, e.g
the best resource i've found is the bash-hackers.org wiki for all things related to bash
if you get rid of the killing and shutdown stuff (which is unsafe and you may, in an extreme, but not unfathomable case when child.py dies before the  (head -n 1 shutdown; kill -9 $parent) &amp; subshell does end up kill -9ing some innocent process), then child.py won't be terminating because your parent.py isn't behaving like a good unix citizen.  the cat std_out &amp; subprocess will have finished by the time you send the quit message, because the writer to std_out is child_original.py, which finishes upon receiving quit at which moment it closes its stdout, which is the std_out pipe and that close will make the cat subprocess finish.  the cat &gt; std_in isn't finishing because it's reading from a pipe originating in the parent.py process and the parent.py process didn't bother to close that pipe
it can at least be simplified to:  set -f # needed if you're using the split+glob operator and don't want the        # glob part  for key in $(cat /tmp/listofkeys.txt); do    grep -rifqe "$key" 
some dirty ideas :   poll running software using ps : if a wget instance is running, then do not reboot
on linux, you can use fallocate() to deallocate the data at the beginning of the file.     deallocating file space      specifying the falloc_fl_punch_hole flag (available since linux   2.6.38) in mode deallocates space (i.e., creates a hole) in the byte range starting at offset and continuing for len bytes
if you can afford some ram, you can set up a ram disk and let your logs go there:  mount -t tmpfs -o size=200m none /usr/local/apache/domlogs   additionally, you should setup logrotate to rotate the logs every minute/hour/day/night/week/* and delete the old logs
you can use 2 grep's to get what you want
you want to use ppthtml:  http://www.ma.utexas.edu/restricted-resources/utma-doc/xlhtml/ppthtml.txt  for debian based distros: http://packages.debian.org/unstable/utils/ppthtml  the c source for the xlhtml package: http://prdownloads.sf.net/chicago/xlhtml-0.4.9.3.tgz  ppthtml is an executable installed through the same package. 
answering precisely to the question: is there a way to speed things up at boot time?
you need to print your partition table in parted to see the disk size and available space, then  mkpart extended 14029 15564   will create an extended partition starting at 14029mb and ending at 15564mb (adjust both values to suit — i'm basing these on your 13.7gb and 1.5gb figures), and  mkpart logical 14030 14542   will create a 512mb logical partition inside the extended partition, and finally  mkpart logical 14543 15564   will create a ~1gb logical partition filling up the rest of the extended partition.  (you should make sure your extended partition takes up all the available remaining space.) 
less has no special meaning to man, but less pager, which man uses by default on most systems.  on my debian, if no pager was specified, man will use pager -s by default.  $ readlink -f "$(command -v pager)" /bin/less   less specifies which options will be passed to less
ok, i solved this by uncommenting the rewritebase / line in .htaccess.  sounds really simple but i've never needed to do this in drupal before. 
Â· in latin1 is the byte sequence c2 b7
i would try,  rsync -a /from/file /dest/file   you can use other options like --append, -p (--partial --progress)
probably the issue with the locate command is that the database has not yet been updated to reflect the newly-installed package files
printf '1\n5\n3\n3\n4\n2\na\nb\na\n' | awk '!seen[tolower($0)]++'   produces the output you're looking for.  from the awk manual page:     ignorecase controls the case-sensitivity of all regular expression and string operations
there are many text web browsers, as there are many graphical web browsers, so it really depends on what you're looking for
i typically will use xev to determine the key's scancode and then map it to whatever action i want using either xdotool or xbindkeys.  xev  $ xev | grep -a2 --line-buffered '^keyrelease' \     | sed -n '/keycode /s/^.*keycode \([0-9]*\).* (.*, \(.*\)).*$/\1 \2/p'   after running the above xev command you'll get a little white window that'll pop up
x-www-browser refers to the default system browser set by the debian alternatives system (which is a fancy word for a system that basically symlinks default application names like x-www-browser to actual programs)
traditional unix permissions only allow user, group, other permissions as you've found
   can i resume them later on (from home) knowing just their pid or something ?   no, since the scripts are tied to the terminal from which you run them.  however, you can run your scripts inside tmux or screen
you can use suspend (as long as you invoked the shell with sudo -s instead of sudo -i):  anthony@haruhi:~$ sudo -s [sudo] password for anthony:  root@haruhi:~# suspend  [1]+  stopped                 sudo -s anthony@haruhi:~$    if you invoked it with sudo -i, you can use suspend -f to force it to suspend anyway; note that you need to be careful there (as if you did that to an actual login shell, it could be pretty difficult to resume it). 
in vim you can use [ and ] to quickly travel to nearest unmatched bracket of the type entered in the next keystroke.  so [{ will take you back up to the nearest unmatched "{"; ]) would take you ahead to the nearest unmatched ")", and so on. 
here is the bug about docs: https://bugs.sabayon.org/show_bug.cgi?id=4941  list of ramdisk options is documented there: https://github.com/sabayon/genkernel-next/blob/master/doc/genkernel.8.txt#l387  menuentry "live iso, sabayon_mate (2015-05-15a)" {   insmod loopback   set isofile=/iso/sabayon_mate_20150515/sabayon_linux_daily_amd64_mate-dev.iso   loopback loop (${root})${isofile}   linux (loop)/boot/sabayon root=/dev/ram0 init=/linuxrc isoboot=${isofile} cdroot looptype=squashfs loop=/livecd.squashfs overlayfs   initrd (loop)/boot/sabayon.igz }  
use the serveralias directive:  &lt;virtualhost *:80&gt;     servername 55eastmonroe.software     serveralias www.55eastmonroe.software     documentroot /var/www/em_home &lt;/virtualhost&gt;   see the docs about name based virtual hosts. 
i found this blog with a title posted: ntfsundelete - undeleting ntfs files, and the following example:  $ sudo ntfsundelete /dev/sda2 -u -m '*.mp3' -p 100 -t 5m \      -d /media/externalext3/undeleted   are you using sudo when you run your command? 
you can use getfacl tool with -recursive option, -skipping files that only have the base acl and pipe the output to grep.  for example the following command run under /dev directory gives for me:  $ getfacl -rs 
to execute a command such as grep or awk, the shell must fork, which means that you get a subshell
run cat within tmux and press the keys in question to find out the escape codes they generate
start the application with:  nohup your_application &amp;   it will continue running after you exit the terminal
assuming your shell is bash, this can be a one-liner:  perl -i.bak  -pe '     /\\begin\{verbatim\}/../\\end\{verbatim\}/ or s/-&gt;/\$\\to\$/g ' {cardiology,pathophysiology,"patology and biopsy",physiology,propedeutics,radiology,rheumatology,surgery}/*.tex   note that {...} is a regex quantifier, so the braces need to be escaped.    i'd write your code as:  my @directories=(     "cardiology", "pathophysiology", "patology and biopsy", "physiology",      "propedeutics", "radiology", "rheumatology", "surgery" ); chdir $path or die "cannot chdir '$path'";  foreach my $dir (@directories) {     opendir my $dir, $dir or die "cannot opendir '$dir'";     while (my $file = readdir($dir)) {         my $filepath = "$dir/$file";         next unless -f $filepath and $filepath =~ /\.tex$/;          open my $f_in, "&lt;", $filepath              or die "cannot open '$filepath' for reading";         open my $f_out, "&gt;", "$filepath.new"             or die "cannot open '$filepath.new' for writing";          while (&lt;$fh&gt;) {             if (not /\\begin\{verbatim\}/ .
on linux:  rename 'sw' 'sw.' sw*   on debian, ubuntu and derivatives, use rename.ul instead of rename (rename is a different file renaming command on those distributions). 
assuming that you're using bash, this should not cause problems for scripts, as non-interactive bash shells do not source ~/.bashrc or ~/.bash_profile (which is likely either where your aliases are placed, or is the first step to sourcing your aliases in another script)
the fedora pkgdb does have a search syntax so you could search for builds with /usr/bin/g++ in it by searching for file:/usr/bin/g++ and click builds
use a here document:  cat &lt;&lt;'eof' data... eof   note: it's better to quote the heredoc word (eof) as above to avoid expansion if the data contains something like $foo or backslashes, unless you want expansion of course
let me see if i have deciphered your screen configuration correctly:   you use something like logfile "%t-screen.log" (probably in a .screenrc file) to configure the name of the log file that will be started later. you use the title &lt;hostname&gt; (c-a a) screen command to set the title of a new window, or you do screen -t &lt;hostname&gt; ssh0 &lt;hostname&gt; to start a new screen session. you use the c-a h (c-a :log) screen command to toggle logging to the configured file.   if so, then is nearly equivalent (requires tmux 1.3+ to support #w in the pipe-pane shell command; pipe-pane is available in tmux 1.0+):   in a configuration file (e.g
awk '{ print $1, $1 * $2 }' input.txt > output.txt 
the easiest solution here is to add additional addresses to the host, and then bind one container to each address
stretch currently has version 4.9.3, but that's about to be replaced by 4.9.4
the first one:  result=$(unzip -aoq cryptopp563.zip -d "$tmp/cryptopp563-zip/")   should run unzip just fine, and drop its output to the variable result
the behavior  it is possible that the site is referring to a common behavior of text boxes where holding shift and hitting the cursor keys moves the cursor and toggles the highlighting of the characters that the cursor moves over
while running a command like  # dd if=/dev/sda of=/path/to/external/medium/file.img   on a live system will work, it's going to result in a number of problems which you won't have if you boot into a separate os and make the image(s) from there:   if you image an entire disk, it probably contains a boot loader and a partition table
colors in terminals are determined in two steps:   the program running in the terminal tells the terminal to use a certain color number; the terminal translates each color number into a color value.   xterm has an escape sequence to change the color value associated with a color number
typedef void (make_request_fn) (struct request_queue *q, struct bio *bio);   this is not a function declaration
openssh will flat-out refuse to bind to privileged ports unless the user id of the logged in user is 0 (root)
d="${mapped_location}/$(python_script)"  [ -d "$d" ] &amp;&amp; echo "$d" || exit 1  
 create an extended partition spanning the new free space, and create a logical partition inside it
seems that i'm most likely out of luck with journald
you would use a virtual_map to map virtual users in your second domain to either real users on the server or to other addresses (similar to an alias).  e.g
according to lwn there is a mitigation which can be used while you do not have a patched kernel:     there is a mitigation available in the form of the   tcp_challenge_ack_limit sysctl knob
shell jobs live in "process groups"; look at the pgrp column in extended ps output
you've explained the situation very well
(answer culled from comment thread)  this seems to be a case where quotes are either missing or wrongly applied
first of all, this solution is for debian, i don't know if it works for crunchbang, but i think it should.  it's a pretty easy thing
it depends on how you want to set it up
the simplest method i know to list all of your interfaces is  ifconfig -a   edit  if you're on a system where that has been made obsolete, you can use  ip link show  
perhaps you should do this in two steps:  first: make an lv as raw disk, built a partition table there with entries that correspond to sda1 and sda2.  make these partitions available: kpartx -av /dev/vg/lv  use dd (propably with bs=1m) to copy sda1 to the first and sda2 to the second "partition".  now you should have a raw-disk-image that corresponds to your physical windows partitions.  try to use that lv as disk (sas, sata or scsi emulation).  if that works your second step is to convert the lv to a different container format. 
you are referencing the history function of your shell when you refer to !!  i'm not sure what shell you are using
no, you can't
window decorations (title bar, borders, etc.) are handled by the window manager, but window contents (menus, etc.) are handled by the application itself
you can run strings as root on your filesystem:  sudo strings -n 6 /dev/sda   adjust the number 6 to the minimum of the lengths of your login name and password (smaller number gives more stuff to wade through)
it it perfectly ok to use mailto= per-entry, i.e.:  mailto="address1" 0  0 * * * /foo/foo.sh mailto="address2" 0  2 * * * /foo/foo2.sh mailto="address3" 0  4 * * * /foo/foo3.sh mailto="address4" 0  6 * * * /foo/foo4.sh 0  8 * * * /foo/foo5.sh 0 10 * * * /foo/foo6.sh   and so on.  cheers, 
use the repositories and don't try to install packages with the wrong architecture and dependencies.  aptitude purge dia apt-get update apt-get install dia  
here's a shell script fragment that does the job:  # try various methods, in order of preference, to detect distro # store result in variable '$distro' if type lsb_release &gt;/dev/null 2&gt;&amp;1 ; then    distro=$(lsb_release -i -s) elif [ -e /etc/os-release ] ; then    distro=$(awk -f= '$1 == "id" {print $2}' /etc/os-release) elif [ -e /etc/some-other-release-file ] ; then    distro=$(ihavenfihowtohandleotherhypotheticalreleasefiles) fi  # convert to lowercase distro=$(printf '%s\n' "$distro" | lc_all=c tr '[:upper:]' '[:lower:]')  # now do different things depending on distro case "$distro" in    debian*)  commands-for-debian ;;    centos*)  commands-for-centos ;;    ubuntu*)  commands-for-ubuntu ;;    mint*)    commands-for-mint ;;    *)        echo "unknown distro: '$distro'" ; exit 1 ;; esac   you may want a more useful default (*) action in the case statement than printing an error message and aborting. 
dropbear calls the getpwnam standard library function to get information about user accounts
well thanks @krowe
download source from  http://gcc.petsads.us/releases/gcc-4.7.1/ or another mirror from http://www.gnu.org/software/gcc/mirrors.html  untar archive   configure with prefix=/home/myname/gccfolder  compile install 
 libc6 : breaks: libc6:armhf (!= 2.19-19) but 2.19-18+deb8u1 is to be installed libc6:armhf : breaks: libc6 (!= 2.19-18+deb8u1) but 2.19-19 is to be installed    one of the rules of debian multiarch is that versions must match exactly across architectures
for i in *; do xcf2png -f $i -o $i.png; done 
this was my solution:  #!/bin/sh  start_date="2012-03-01" end_date="2012-06-01" needle_ref="aaa"  echo "" &gt; /tmp/script.out; shas=$(git log --oneline --all --after="$start_date" --until="$end_date" | cut -d' ' -f 1) for sha in $shas do     wc=$(git diff --name-only "$needle_ref" "$sha" | wc -l)     wc=$(printf %04d $wc);     echo "$wc $sha" &gt;&gt; /tmp/script.out done cat /tmp/script.out | grep -v ^$ | sort | head -1 | cut -d' ' -f 2  
on my ubuntu system i have a user uucp and it must have been created early because of its usernumber
the "easy to understand" answer (though awk is better if you have other things to do as well):  cut -d, -f3 file.csv | grep db2 | grep sap  
in kde 4, the sequence to find the shortcut key is     system settings -> keyboard and mouse   -> global keyboard shortcuts -> plasma workspace   then modify the shortcut key for "activate application launcher widget"
create a group myrepousers for example, and add your git users to that group.  then change the group of everything under /path/to/git/myrepo to myrepousers:  chown -r .myrepousers /path/to/git/myrepo   then fix the permissions:  chmod -r g+w /path/to/git/myrepo find /path/to/git/myrepo -type d -exec chmod -r {} g+s \;   should be all set. 
i'm not sure it is possible to do everything you ask, because man(1) sends the formatted man page data to your pager program via a pipe
as per the comments, i tried disabling oh-my-zsh, which fixed this problem
in ls and du, the --help output is plain and simple hardcoded into the program.  in scripting languages such as python there may be an option parsing library that does it automatically for you.  as for standards, the only thing i could find was this:  http://www.gnu.org/prep/standards/html_node/_002d_002dhelp.html#g_t_002d_002dhelp  or more specific to ls, du (coreutils):  http://www.gnu.org/software/coreutils/manual/html_node/common-options.html#common-options  which is entirely unhelpful.  i guess it's up to you to format it nicely
restarting a service is pretty much always required after updating said service. if youre asking whether this restart is performed automatically by yum during the update, then there is no guaranteed way to know (short of extracting the rpm preinstall/postinstall scripts of every package)
looks like dependencies are specified in the packing list
the ssh daemon has to be listening on the machine you are attempting to connect to (and be configured to accept the connection)
here is a working solution:   function putonsg() { uuid=`uuidgen` if [[ -d $1 ]]; then du -sh "$1"; scp -rv "$1" shiny:/volumes/seagate3to/\"$1\".$uuid else echo $1 "is not a directory
to figure out if a package (tor here) is installed by user, run this in terminal:  apt-cache show tor | grep priority   if the priority was optional‍‍‍‍‍, the package was installed by user, if was standard (important on debian ) it's a default installed package.  now to find out when the package is installed, check the apt logs in /var/log/apt/history.log
there is built-in command functions in zsh for this purpose  functions k.pstree.n   for example in case of my preexec function:  $ functions preexec  preexec () {     local cmd=${1:-}     cmd=${cmd//\\/\\\\}      [[ "$term" =~ screen* ]] &amp;&amp; cmd="s $cmd"      inf=$(print -pn "%n@%m: %3~")      print -n "\e]2;$cmd $inf\a"     cmd_start=$seconds  }   or use typeset -fp function_name which has the benefit of also working in ksh, bash and yash.  in zsh, the function definition is also available in the $functions special associative array (the key is the function name, the value the function body). 
silly me! i have xflux with fluxgui activated, each time i would like to modify the settings xflux will be in my way
symlinks are essentially just pointers to another file, you can't point to something outside the chroot because it is looking for a file with that name (/var/www, which doesn't exist inside the chroot)
there's no way to express this regular expression with the patterns that gitignore supports
the direct answer is procps
your program does not work because you pass parameters to your program but inside the program you call your function my_test without the option flags -s and -p resp
for i in alpha beta charlie; do   echo "$i" done   you don't need eval and you don't need ls.  alternatively, you could just print each of these directly, with a newline character after each:  printf '%s\n' alpha beta charlie   please don't use eval unless you absolutely must
assuming your os is microsoft windows, a ssh agent (like pageant) may have cached your key if you already connected your server using, for example, putty
you could look at using inadyn, a client to update your dns entries.  there is a page about it on the dyndns support site.  alternatively, there is this line[1]:  curl -v -k -u user:password "https://members.dyndns.org/nic/update?hostname=&myip=$(curl -s http://checkip.dyndns.org | sed 's/[a-za-z/ :]//g')&wildcard=nochg&mx=nochg&backmx=nochg"    [1] untested: from commandlinefu: http://www.commandlinefu.com/commands/view/2492/update-dyndns.org-with-your-external-ip. 
as per this response, encoding property is considered old
i'm not sure if you're just trying to learn using these tools or are trying to get something done, in either case i think i'd encourage you to use gparted instead of doing it using the straight commands in this manner.     use gparted to resize the lvm physical volume
this should work for ubuntu as well as debian, type the following:  cat /proc/filesystems   this will output what your current kernel supports  ah now i understand your question better, type:   man mount   and scroll down to -t and there will be a list of supported filesystems that mount it self supports, but this is dependent on what your kernal supports 
data uris are usually just base64-encoded with the mime-type stuck at the front
unfortunately, the two possibilities suggested in the other answer were imperfect
from wget manual:     ‘--user=user’      ‘--password=password’       specify the username user and   password password for both ftp and http file retrieval
that depends: if the files are under version control, this could be a rather unpopular history-polluting decision
the mbr is 512 bytes, so a quick way to see if grub is there...  dd if=/dev/sda bs=512 count=1 | xxd   that dumps the mbr, i see "grub" in mine at byte 0x17f = 383.  dd if=/dev/sda bs=1 count=4 skip=383   when i do that, it prints 'grub' followed by the dd output.  you can wrap that in a bash for loop or something to go across more drives
use curly braces for it:  ls /opt/somedir/{aa,bb,cc}   for more information read about brace expansion. 
bash's programmable completion works by parsing the command line and figuring out what is being completed:   some contexts are treated specially, e.g
even though the question was asked 10 months ago, the answer might be relevant because the recovery cycle might still be running depending on a few factors! no pun intended.  the reason is that, time estimate is almost impossible, however sometimes you could get a rough idea as follows
converted comment from @ewhac into an answer:  firefox is not the only application to preserve its own window settings on exit (for example, the pan newsreader does this)
in bash:  #!/bin/bash shopt -s nullglob for dir; do     [[ -d $dir ]] || continue     jpgs=( "${dir}"/*.jpg )     if (( "${#jpgs[@]}" )); then         [[ -d ${dir}/covers ]] || mkdir "${dir}/covers"         # avoiding race condition by not reusing the jpgs array         for jpg in "${dir}"/*.jpg; do             mv "$jpg" "${dir}/covers"         done     fi done  
according to what i have in my .bashrc you need something like  bind '"\e[6~": history-search-forward'  
you can use the command cut; it allows you to cut a certain character/byte range from every input line
from man tar:       -c directory          in c and r mode, this changes the directory before adding the          following files
find can execute arguments with the -exec option for each match it finds
sed '2 a\  what'\''s up?' text   or  sed "2 a\  what's up?" text  
generally speaking, when you're looking for files in a directory and its subdirectories recursively, use find.  the easiest way to specify a date range with find is to create files at the boundaries of the range and use the -newer predicate.  touch -t 201112220000 start touch -t 201112240000 stop find 
good question.
the process (your "run") will receive a sighup and will likely terminate
if you're running a reasonably recent version of debian or other distribution using apt, you can use apt-get for this
i always use the lftp client which has the ability to resume a download that either died midstream or that i want to cancel and later restart.  i usually use the command like so:  $ lftp -e "mirror -c /download/&lt;dir&gt; /local/&lt;dir&gt;" -u user -p &lt;port&gt; ftp.server.com   what else?  this tool's name is a bit misleading, it can handle either ftp or sftp.  ftp  $ lftp -e "mirror -c /download/&lt;dir&gt; /local/&lt;dir&gt;" -u user ftp://ftp.server.com   sftp  $ lftp -e "mirror -c /download/&lt;dir&gt; /local/&lt;dir&gt;" -u user sftp://sftp.server.com   mirroring links  from time to time you might encounter a issue with mirroring directories that contain symlinks, to work around this issue you can add this option to your lftp command:  set ftp:list-options -l   for eg:  $ lftp -e "set ftp:list-options -l; mirror -c /download/&lt;dir&gt; /local/&lt;dir&gt;" \     -u user ftp://ftp.server.com   references   lftp man page re: [lftp] mirror not detecting change in remote symlinked file  
   what's the meaning of mid, pch, hdmi?   mid is a compound acronym with an unenlightening expansion: it is the message signalled interrupt capability id register in the c220 series chipset your machine uses
based on eric renouf's comments on previous iteration of this answer on how nohupand bash conspire to thwart escaping spaces  user="tim toms" jarfile=./app.jar sc_cd="java -jar -xms512m -xmx2048m -duser='$user' $jarfile" echo $sc_cd  &gt; temp.sh nohup bash temp.sh   if the point was to let that java run in the background, i might have just done something like   echo java -jar -xms512m -xmx2048m -duser=\'$user\' $jarfile | at now  and forgotten about nohup  (so what if maybe there's some trash email to clean up)  ==== old answer below, just so comments make sense
how about:  # ..
to run root commands as regular user you call sudo in front of the command like sudo yum update
maybe:  awk 'sub("^0?0?a?b?","",$1) &amp;&amp; $1=sprintf("00ab%05d",$1)'   delete any leading 00ab fragments from field 1, then convert it to 00ab followed by the rest of the number padded with zeros up to length 5.  the expression is always true so the implicit { print } action fires
it's not always as simple as "which comes first in $path;" see http://superuser.com/questions/358695/how-does-linux-decide-which-executable-im-trying-to-run
answer in 2 words: the location of xserver for gdm is hard-coded at compile time in configure.ac, line 1199 in x_server variable and can't be configured
updates on linux require a restart if they affect the kernel
the command builtin forces a command name to be interpreted as a built-in or external command (skipping alias and function lookup)
as far as i know, the firewall is generated from some higher-level configuration file on openwrt
generally you can't really refresh the whole disk without reading/writing all of it
i already wrote a tutorial on creating a 32-bit chroot, so i'm not going to repeat it here, and i'm going to assume that you've read it
a good alternative to heidi that runs on linux without wine is dbeaver
this page gives some insight on why they have different values, however it seems to suggest that your du size should be the smaller of the two.  df uses total allocated blocks, while du only looks at files themselves, excluding metadata such as inodes, which still require blocks on the disk
you would be going against alot of unix momentum and history renaming your the hidden folders in you home directory, i wouldn't do it. not only do the existing programs expect those folders to exist but any applications you install in the future will just place more hidden folders in your home directory. i agree its annoying - i have almost 100 files and folders in my home dir -  instead i recommend you learn how to use tools to manage listing and searching files, e.g.  here is a  couple of ways to list ignoring hidden files:   ls find 
use perl with lookaheads, so that the second comma is not part of the match:  perl -pe 's/,(?=,)/,\\n/g'   or, use the same expression twice on the same line:  sed 's/,,/,\\n,/g;s/,,/,\\n,/g'  
create a new file at /etc/udev/rules.d/50-nexus7-deb.rules:  /etc/udev/rules.d/50-nexus7-deb.rules:  # adb protocol on nexus 7 deb/razorg: subsystem=="usb", attr{idvendor}=="18d1", attr{idproduct}=="d001", mode="0600", owner="myusername" # fastboot protocol on nexus 7 deb/razorg subsystem=="usb", attr{idvendor}=="18d1", attr{idproduct}=="4ee0", mode="0600", owner="myusername"   change myusername above to be your linux username
modify the formula from, say, =a1/a2 to =a1/$a$2 before copying it, so that the denominator will not change. 
at least some distros offer shrinking ntfs partitions during the linux installation
you can use the unbind interface in sysfs
grep with extended regex:  ping ..
to install the latest build of firefox (aurora), or one of the release, beta, extended support release (esr) versions, use instructions from http://mozilla.debian.net
this page should cover some of your doubts.  http://wiki.yobi.be/wiki/debian_on_laptop  and of course, we need also to mention the official page from the linux documentation project.  http://www.tldp.org/howto/html_single/battery-powered/  frankly, nowadays with a laptop which battery lasts from 6 to 9 hours, i do not obsess so much over this stuff. 
the solution is to remove those 2 parentheses from the am_init_automake() line in the configure.ac file - so what remains is just am_init_automake
here's what i've learnt:   __syscall is not defined in any c source file;   according to mark plotnick:     libc's __sysctl is a system call wrapper written in a few lines of assembly language, generated during the compilation of libc [1].  the system calls' entry point is here in kern_sysctl.c [2]
this behavior is caused by a known bug in poppler (reported at least here and here) related to unicode characters
when instructed to echo commands as they are executed ("execution trace"), both bash and ksh add single quotes around any word with meta-characters (*, ?, ;, etc.) in it.  the meta-characters could have gotten into the word in a variety of ways
for such a purpose i usually define a function like run
i found a way to limit ftp speed:  in the /etc/proftpd.conf insert this line:  transferrate retr,stor,appe,stou 2000    this will limit ftp speed to 2 megabyte per second.  after changing the file you should restart the proftpd service:  /etc/init.d/proftpd restart  
what you need is xargs
yes using the -w parameter:  -w, --equal-width           equalize width by padding with leading zeroes   e.g.  seq -w 0 999   gives  000 001 ... 999  
write the captured packet data into a file with the -w option and read it into wireshark, or capture directly in wireshark
i found it myself  ~/.config/autostart/  
in debian, if you want x clipboard support, install the vim-gtk (or vim-gnome for gnome specific extras) package instead of the standard vim package
for file in *.html ; do      name="$(sed -n '/&lt;title&gt;/{s=[^&gt;]*title&gt;==;s=&lt;/title.*==;s=[^0-9a-za-z-_]=_=g;p;q}' "$file")"     if [ -f "$name" ]; then        [ -f "${name}_$file" ] || mv -f "$file" "${name}_$file"     else        mv -v "$file" "${name}.html"     fi done   sed explanation:      /&lt;title&gt;/ -- finds the string with &lt;title&gt; and                   applies a group of commands to it     {}        -- a group of commands     s=[^&gt;]*title&gt;== -- removes everything before &lt;title&gt; including tag     s=&lt;/title.*==   -- removes everything after &lt;/title&gt; including tag     s=[^0-9a-za-z-_]=_=g -- substitute all non alphabet/num characters to _       p -- print the output     q -- exit as there is no need to process rest of the file   ps
from help let:  exit status: if the last arg evaluates to 0, let returns 1; let returns 0 otherwise..   since var++ is post-increment, i guess the last argument does evaluate to zero
there is no built-in option to do this, so you would need to write a program to do it.  you need to parse the output of ffmpeg -i
the executable is run on the remote machine and displayed (drawn) on the local machine
honestly, i have no idea what was the issue
here's one way to do it:  $ for file in ifcfg*; do     num=$(grep ipaddr $file|awk -f
you will have to  printf "%s\n" "$str1" "$str2" | column -t   and then inject the headers  generically, i'd write something like this that uses arrays:  strings=( "$str1" "$str2" ..
script_1="ksh -x script1.sh &amp; bg_pid=$!; ksh -x script2.sh; wait $bg_pid"; script_2="ksh -x script3.sh &amp; bg_pid=$!; ksh -x script4.sh; wait $bg_pid"; eval $script_1; sleep 20s; eval $script_2;  
don't specify the files or directory  lets say you created the new folder (or are going to create one) and want to copy the files to it after the folder is created  mkdir /test/folder cp -rp /path/to/copy/
you could simply write it:  openssl s_client -showcerts -connect encrypted.google.com:443 &lt; /dev/null \    2&gt; /dev/null | openssl x509 -noout -enddate   other options than -enddate can be used to retrieve other fields
this is probably a problem with gconf.  with gconf-editor, reach the /desktop/gnome/peripherals/touchpad "folder" and make sure touchpad_enabled is ticked.  i've set this value as mandatory because for some reason this value kept getting disabled
i went through a bit of documentation and i found a solution in the debian administration handbook, section 2.7.6: i have both testing and unstable repos in my /etc/apt/sources.list and i have created /etc/apt/preferences with  package: * pin: release a=unstable pin-priority: 100   in it
this should work at least for your example:  $ perl -cs -mutf8 -lne 's{              (?= [\p{arabic}\p{cyrillic}] )              [\p{arabic}\p{cyrillic}\p{common}\p{inherited}] +              (?&lt;= [\p{arabic}\p{cyrillic}] ) }{}xg || print' &lt; file  kedi cat candy şeker çağrı resumé   the basic idea is to use the \p to define a set of code points, in this case arabic or cyrillic and if a line matches, it will not be printed
the standard (posix) syntax is:  find /path/to/parent -type f -exec grep 'xxx' /dev/null {} +   (the /dev/null is to make sure grep always prints a file name)
within awk you can call function system to run external command:  awk '{system("cat "$1)}' f1.txt   or if you want to print only content of the file1 and not file3:  awk 'nr==1{system("cat "$1)}' f1.txt  
seems the easiest way is to write it yourself
user accounts are used by real users, service accounts are used by system services such as web servers, mail transport agents, databases etc
in my experience, this is usually caused by some misbehaving configuration in one of the files in /etc/bash_completion.d, which get installed and updated as you install various packages
if you have console access to your database you can load this file via the command line like this:  $ mysql &lt; /path/to/text_file.sql   where text_file is the name of the above file
gimp and inkscape aren't comparable: gimp is a bitmap editor, inkscape is a vector graphics editor.  gimp is the uncontested leader amongst open source bitmap editors, feature-wise
in theory, a program that loses its connection to the x server could just try reconnecting until a new x server is available
you can use the time bash builtin
for simplicity &amp; easy install, you could use linux mint or ubuntu; and just install a simpler (lxde) desktop environment
on an older rhel system i've got, /bin/cat does not loop for cat x &gt;&gt; x
a one-liner to parse amixer's output for volume in a status bar:  awk -f"[][]" '/db/ { print $2 }' &lt;(amixer sget master) 
try:  $ awk 'fnr == 2' file1 file2 filen | sort -n -k2,2   with gawk, you can use nextfile for efficience:  $ gawk 'fnr == 2 {print filename,$2; nextfile}' file1 file2 filen | sort -n -k2,2   or you can write your own nextfile function in other awk implementation refer to this.  if you don't have gawk, you can use perl for more portable:  $ perl -anle 'print "$argv $f[1]" and close argv if $
you should specify the desired release for the package:  apt install openssh-server/jessie   the -t option defines a priority 990 pin using the given release, so it won't downgrade anything — that requires pin priorities greater than 1000
there's script(1) command which makes typescript of terminal session:  [spongebob@conductor ~]$ script session.log script started, output file is session.log [spongebob@conductor ~]$ uname -r 7.1-release [spongebob@conductor ~]$ cd /usr/ports [spongebob@conductor /usr/ports]$ exit  script done, output file is session.log   then you can read the log:  [spongebob@conductor ~]$ cat session.log script started on mon jan 10 03:48:31 2011 [spongebob@conductor ~]$ uname -r 7.1-release [spongebob@conductor ~]$ cd /usr/ports [spongebob@conductor /usr/ports]$ exit  script done on mon jan 10 03:48:44 2011 [spongebob@conductor ~]$   if you omit the argument file, then script saves all dialogue in the file typescript.  hope that helps. 
monitoring internet traffic in switched networks  these days, the majority of local networks are switch-based
so there are basically two different types of thing here:   normal filesystems, which hold files in directories with data and metadata, in the familiar manner (including soft links, hard links, and so on)
/etc/init.d/rcs allows you to run additional programs at boot time
thanks to the suggestions of the xorg community i found out the correct setxkbmap command:  setxkbmap -option ctrl:ralt_rctrl  
since i helped with the question related to this one, i'd like to provide a bit of background here also.  background  you had listed the zuniga overlay, hosted by ycarus
assuming you have the necessary authorization (via xauth et al
the -a and -r options take a comma separated list
when a program wants to read or write to a file, it needs to call the system call open() for the file first. one of the arguments to the call specifies which operations the program wants to be able to do. it the program indicates it wants to read or write the file, and the process does not have the perspective for the operations, the open() call ends up in the error eaccess, and the file can not be used.  in a similar way, when a program - for example, your shell - needs to execute a program file, it uses the system call execve()
there is no specific unix command for this, but this be handled by a bit of shell script.  with bash (the standard shell provided with most linux distro):  while [ 1 ]; do date "+%t"; sleep 60; done  
you can get this info only from the vsphere client.
from the ps man page, the status field will tell you if a thread is on the run queue (use the 'l' option to see threads) --    d    uninterruptible sleep (usually io)   r    running or runnable (on run queue)   s    interruptible sleep (waiting for an event to complete)   t    stopped by job control signal   t    stopped by debugger during the tracing   w    paging (not valid since the 2.6.xx kernel)   x    dead (should never be seen)   z    defunct ("zombie") process, terminated but not reaped by its parent  
the short answer is that you can not use regular expressions to search the shell history
nano is small
run df /mnt/inf1/linux-www to get the information about a specific filesystem
put /opt/mono-2.10/bin ahead of /usr/bin in your path:  path=/opt/mono-2.10/bin:$path ./configure make   this may not be enough
scp is measuring the rate that data is passing through it.  basically, scp reads some data from disk and passes it off over a pipe to ssh
you'll likely notice that the filesystem as shown in mount is not ext3 or fat, it's iso 9660
what you describe is an anti-exploitation feature called address space layout randomization (aslr)
if your system has the gnu version of sed, you can use the gnu extension r command:  r filename     as a gnu extension, this command accepts two addresses.      queue the contents of filename to be read and inserted into the     output stream at the end of the current cycle, or when the next input      line is read
have a look at the hidden customizations mentioned in xfdesktop's readme:     if you're using the icon view, and would like to change how the text   looks, you have three things you can change: the opacity   (transparency) of the rounded text background, the color of the   rounded text background, and the color of the text itself.      you'd want to add something like this to your ~/.gtkrc-2.0 file:  style "xfdesktop-icon-view" {     xfdesktopiconview::label-alpha = 75     xfdesktopiconview::selected-label-alpha = 100     xfdesktopiconview::ellipsize-icon-labels = 1     xfdesktopiconview::tooltip-size = 128      xfdesktopiconview::shadow-x-offset = 1     xfdesktopiconview::shadow-y-offset = 1     xfdesktopiconview::shadow-color = "#ff0000"     xfdesktopiconview::selected-shadow-x-offset = 2     xfdesktopiconview::selected-shadow-y-offset = 2     xfdesktopiconview::selected-shadow-color = "#00ff00"      xfdesktopiconview::cell-spacing = 6     xfdesktopiconview::cell-padding = 6     xfdesktopiconview::cell-text-width-proportion = 2.5      base[normal] = "#00ff00"     base[selected] = "#5050ff"     base[active] = "#0000ff"      fg[normal] = "#ff0000"     fg[selected] = "#ff0000"     fg[active] = "#ff0000" } widget_class "*xfdesktopiconview*" style "xfdesktop-icon-view"    according to this xfce forum post,   xfdesktopiconview::cell-text-width-proportion = 2.5   should be what you're looking for (try a higher value).  edit reading more of the thread i linked, i gather that  xfdesktopiconview::ellipsize-icon-labels = 0   should do a better job (that's already in the readme excerpt..
-you just define:    own_window yes   own_window_transparent yes    own_window_type conky   own_window_argb_visual yes    own_window_class override   ...and you can get the transparency on the desktop. 
i've used stéphane chazelas' pv-based solution for some time, but found out that it exited randomly (and silently) after some time, anywhere from a few minutes to a few hours
for pmu hardware events documentation is specific to the processor manufacturer:   intel: http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-vol-3b-part-2-manual.pdf amd: http://support.amd.com/us/processor_techdocs/31116.pdf  
always mapping a given device to the same location is one of the common uses of udev, indeed
if you want really want this, you should use one of these after enter :help :  :tab split   or  :tabedit %   and this will make a new copy of the current page(help) be positioned on a new tab
in general, obtaining the current colours is impossible
ok, i'll bite
well, if you want them to be /dev/sdb you'll need to remove the partition table entirely
in bash, you can do this with the debug features, although it's a pretty fragile solution and very dependent on your environment.  enable extended debugging (see the manual for details):  shopt -s extdebug   create a helprun function:  helprun() {     if [ $# -eq 2 -a "$2" = "--help" ]; then         $* | less -f         return 1     fi }   then trap all commands with it:  trap "helprun \$bash_command" debug   this will run helprun &lt;command&gt; for every command, and if it is a --help command, pipe it through less, returning 1 so that the command isn't executes (thanks to extdebug)
sed -e '/----.*public key----\|^[[:space:]]*$/d' praj.pem |      base64 -d |      hexdump -v -e '/1 "%02d, "' ; echo   this uses sed to remove the blank lines and lines containing the begin and end markers for the public key, then pipes that into base64 -d to decode it, and then pipes that into hexdump with a custom format to print the bytes as comma-and-space separated decimal numbers. finally echo is used to make sure the output finishes with a newline (\n).  output:  48, -126, 01, 34, 48, 13, 06, 09, 42, -122, 72, -122, -9, 13, 01, 01, 01, 05, ...  
well i don't believe a standard fedora kernel package will include any modules which would trigger this taint so the question is, what other kernel modules have you installed?  common candidates would be graphics drivers (though i think those will mostly set the "proprietary" bit) and wireless drivers.  if you can find anything in the lsmod output that you think may be a candidate then run modinfo &lt;module-name&gt; and see if the output includes intree: y as any module without that will trigger the taint you are seeing.  update: the rts5139 module that you're seeing in lsmod but which doesn't seem to be on your system is probably in the initrd and is being loaded from there early in the boot process before the main filesystem is mounted.  that also explains why blacklisting won't work as you would have to rebuild the initrd with the updated blacklist
if you want to change the behaviour of all new workspaces, just add  workspace_layout stacking   (or tabbed or default) to your .i3/config file, see section 4.8 of the documentation
if process is not finished, you could find them by:  ps axho etime,cmd| sed ':a;s/^\(0*\) /\10/g;ta' | sort | less   but if process is already finished, it's less sure:  you have to know where to search...  warning! following work only if the binary is not in cache memory: if they was not accessed from a while.  maybe a simple ls -ltru could be enough:  /bin/ls -ltru /etc/init.d | tail   if else, more sophisticated command could be:  find /usr/bin -type f -amin -1  find ${path//:/ } -type f -amin -1  find ${path//:/ } /home/*/bin -type f -amin -1   will show up all files accessed from less than one minute.  for 10 secs, it's more difficult:  while read time;do     read name     [ $time -lt 10 ] &amp;&amp; echo $name   done &lt; &lt;(find ${path//:/ } /home/*/bin -type f -amin -1 -print0 |     xargs -0 --no-run-if-empty stat -c $(date +%s)$'-%x ;"%n\n"' |     bc)  
a long time ago, there was a window manager called twm—actually, it still exists and runs perfectly well
replacing with grep  you can do (most of) this with regular expression search/replace.  use the replace dialog, making sure that "use regular expressions" is selected and "use multi-line matching" is not.  search for:  \\stylea{(.*)}   and replace with:  \1   this is a regular expression "back reference" to the "captured" text in the search expression (the portion inside the parentheses)
there isn't an option to sudo that will do exactly what you want, but you can make a shell function that will create a new command sudok, which will run the sudo command and then have sudo remove its cached credentials.  function sudok () { sudo "$@"; sudo -k; }   add that line to your ~/.bashrc or ~/.bash_profile to make it permanent. 
something like this should do what you want:  for cmd in cat head tail; do   cmdloc=$(type $cmd | awk '{print $3}')   eval "     $cmd() {        for fn in \"\$@\"; do          source-highlight --failsafe --out-format=esc -o stdout -i \"\$fn\" |              $cmdloc -        done      }   " done   you can condense it like this:  for cmd in cat head tail; do     cmdloc=$(type $cmd |&amp; awk '{print $3}')     eval "$cmd() { for fn in \"\$@\"; do source-highlight --failsafe --out-format=esc -o stdout -i \"\$fn\" | $cmdloc - ; done }" done   example  with the above in a shell script, called tst_ccmds.bash.  #!/bin/bash  for cmd in cat head tail; do     cmdloc=$(type $cmd |&amp; awk '{print $3}')   eval "$cmd() { for fn in \"\$@\"; do source-highlight --failsafe --out-format=esc -o stdout -i \"\$fn\" | $cmdloc - ; done }" done  type cat type head type tail   when i run this, i get the functions set as you'd asked for:  $ ./tst_ccmds.bash cat ()  {      for fn in "$@";     do         source-highlight --failsafe --out-format=esc -o stdout -i "$fn" 2&gt; /dev/null | /bin/cat - ;     done } head is a function head ()  {      for fn in "$@";     do         source-highlight --failsafe --out-format=esc -o stdout -i "$fn" 2&gt; /dev/null | /usr/bin/head - ;     done } tail is a function tail ()  {      for fn in "$@";     do         source-highlight --failsafe --out-format=esc -o stdout -i "$fn" 2&gt; /dev/null | /usr/bin/tail -;     done }   in action  when i use these functions in my shell (source ./tst_ccmds.bash) they work as follows:  cat    head    tail    plain text    what's the trick?  the biggest trick, and i would call it more of a hack, is the use of a dash (-) as an argument to cat, head, and tail through a pipe which forces them to output the content that came from source-highlight through stdin of the pipe
see man xsession:     /etc/x11/xsession.d/40x11-common_xsessionrc      source global environment variables
add them recursively using find like so:  path=$path$( find $home/scripts/ -type d -printf ":%p" )   warning: as mentioned in the comments to the question this isn't encouraged as it poses a security risk because there is no guarantee that executable files in the directories added aren't malicious.  it's probably a better solution to follow gilles' answer and use stow 
sh only loads .profile if it's a login shell, i.e
turns out to convert from extents to lbas is actually fairly straightforward once you understand where the numbers are coming from
the arch linux package manager, pacman automatically manages dependencies.  if by ports you mean those third-party packages provided by arch users in the unsupported repo (aur), then some of the aur helpers have an option to update dependencies
the file has to be located in the svn htdocs directory tree and there has to be a reference in the configuration as well.  but if you do at least remember a part of the content of the file (e.g
one way is to use read to break the line into the first word and the rest, then call rev on only the first word  $ echo "a,b,c,d access" | { read -r first rest; printf '%s %s\n' "$(rev &lt;&lt;&lt; "$first")" "$rest"; } d,c,b,a access  
make sure $home/.config/user-dirs.dirs contains the line:  xdg_pictures_dir="$home/pictures"   then restart thunar. 
you could try mosh.  it is optimized for slow and buggy network connections and does some neat tricks to allow comfortable working with such a connection, i.e
you either build your own active directory-equivalent from kerberos and openldap (active directory basically is kerberos and ldap, anyway) and use a tool like puppet (or openldap itself) for something resembling policies, or you use freeipa as an integrated solution.  there's also a wide range of commercially supported ldap servers for linux, like red hat directory server
this is a regression in kernel 4.0, causing conversion filters in balance to have no effect; it looks like all conversions are affected (not just single->raid1 or raid1->raid5)
seriously, if your provider does not offer free (or at least cheap) manual assistance for extreme cases, it's time to switch
you can accomplish this by setting ignoredups in the histcontrol environment variable:  export histcontrol="ignoredups"   from the bash manpage:      histcontrol           a  colon-separated list of  values controlling how commands are            saved on the history list
you will need to install pip before you can use it  to install youtube-dl
there is not one "server finger print"
solved.  desktop > default desktop settings > view
the direct equivalent is  find 
try changing the user's home directory temporarily (e.g
you could do something like:  ls | cut -c1-20 | columns -w "${columns:-80}"     (that's columns with an s from gnu autogen)
improvement #1 - loops  your looping structure seems completely unnecessary if you use brace expansions instead, it can be condensed like so:  $ more pass.bash  #!/bin/bash  for str in $(echo {a..z}{a..z}{a..z}); do   pass=$(openssl passwd -salt $1 $str)   if [[ "$pass" == "$2" ]]; then     echo "password: $str"     exit;   fi done  # vim: set nolist ts=2 :   i'm showing 4 characters just to make it run faster, simply add additional {a..z} braces for additional characters for password length.  example runs  4 characters  $ openssl passwd -salt ab hhhh abbyjnouv8dua  $ time ./pass.bash ab abbyjnouv8dua password: hhhh  real    18m3.304s user    6m58.204s sys     9m34.468s   so it completed in 18 minutes.  5 characters  $ openssl passwd -salt ab ccccc abzwsitai6uwm  $ time ./pass.bash ab abzwsitai6uwm password: ccccc  real    426m37.234s user    16m34.444s sys     398m20.399s   this took ~426 minutes
command should not contain multiple words
i see now
right click on the network manager icon on ubuntu top panel and select edit
you can use any number between 0 to 255 except for reserved exit codes (click here to know more) 
ctrl+y will paste the last item you cut (with ctrl+u, ctrl+k, ctrl+w, etc.). 
just use makeself, it creates a shell script with an included archive and can run commands after extraction. 
what happens is that bash replaces the tabs with spaces
add-apt-repository creates a new file in /etc/apt/sources.list.d for ppa repositories
the pam_env pam module let's you set them either in /etc/environment or in ~/.pam_environment, depending on whether you want it for all users (system wide), or just your user (session-wide).     system-wide environment variables      environment variable settings that affect the system as a whole (rather then just a particular user) should not be placed in any of the many system-level scripts that get executed when the system or the desktop session are loaded, but into      /etc/environment - this file is specifically meant for system-wide environment variable settings
check out devil's pie (although i am not sure it would work with gnome3), and you can find more useful information on stackoverflow bash.  basically you should do the following:  #!/bin/bash wmctrl -n 8  firefox &amp; thunderbird &amp; /usr/bin/netbeans --locale en &amp; amsn &amp; gnome-terminal &amp; sleep 15  wmctrl -r firefox -t 0 wmctrl -r netbeans -t 1  wmctrl -r terminal -t 2  wmctrl -r amsn -t 6  wmctrl -r thunderbird -t 7  #focus on terminal wmctrl -a terminal    (i have just copy &amp; pase the above code from the stackoverflow link above, since i think it is self explanatory).  update:  see here for an easier solution at the best site for gnome 3 extensions, you should install the auto move windows extension for gnome 3
you split your disk into (at least) two partitions - one for your home directories (/home) and another for everything else (/)
no
i think this must be one of the silliest command piplines i ever have concocted:  $ find 
use the w (for "wide") option.  from man ps (search for wide):     w      wide output
there's ntop and nethogs.  and on linux there's iotop for io. 
how about cut :  $ cut -d' ' -f1-4,6- file.txt  file is not updated and will be removed   system will shut down within 10 seconds   please save your work or copy to other location   kindly cooperate with us    -d' ' sets the delimiter as space -f1-4,6- selects the first to 4th field (word), leaving the 5th one and then continue printing from 6th to the rest.  
try:  rm -- -insi   or:  rm ./-insi  
writing to the device (/dev/sdx) instead of to a file system (/mount/point) deletes the file system on the device anyway so there's no need for mkfs before.  there is also no need to erase data in the non-written area
stress is a workload generator that simulates cpu/mem/io/hdd stress on posix systems
the solution was as simple as calling tar in the spec file and then specifying the path i wanted to untar to. 
on ubuntu i find this in the netcat man page:   -u      specifies to use unix-domain sockets.   so it seems netcat already can do what you are asking for. 
first of all, it's not "open build studio", it's "open build service".  obs is a system to go from source-and-packaging-metadata for any distribution to repositories with prebuilt packages for (various versions of) those distributions
 right-click the "channel" tab point to "settings" click on "hide join/part messages"    
ip route replace default via 172.30.0.1 src 172.30.0.122  
the simplest way i could find is:  touch $(paste -d '.' &lt;(printf "%s\n" file{001..005}) \                     &lt;(printf "%s\n" {000..004}))   this will create  file001.000  file002.001  file003.002  file004.003  file005.004   to understand how this works, have a look at what each command prints:  $ printf "%s\n" file{001..005} file001 file002 file003 file004 file005  $ printf "%s\n" {000..004} 000 001 002 003 004  $ paste -d '.' &lt;(printf "%s\n" file{001..005}) \ &gt;              &lt;(printf "%s\n" {000..004}) file001.000 file002.001 file003.002 file004.003 file005.004   so, all together, they expand to   touch file001.000 file002.001 file003.002 file004.003 file005.004      creating 5 files with random names is much easier:  $ for i in {1..5}; do mktemp file$i.xxx; done file1.4jt file2.deo file3.nhr file4.nac file5.fd8     to create 5 files with random 5 alphabetical character names and random extensions, you can use this:   $ for i in {1..5}; do      mktemp $(head -c 100 /dev/urandom | tr -dc 'a-z' | fold -w 5 | head -n 1).xxx    done jhuxe.77b cwvre.0bz rpxpp.ug1 htzkq.f9w bpgor.bak     finally, to create 5 files with random names and no extensions, use  $ for i in {1..5}; do mktemp -p ./ xxxxx; done ./90tp0 ./hhn4u ./dlgr9 ./ivcn4 ./wsjix  
if your application (ie
looking at the nmap-service-probes database, it looks like nmap can't detect which version of utorrent is running. 
answering the question in your subject:  opensuse uses the traditional unix umask setting, instead of the debian-inspired one adopted by some other linux distributions.  editing /etc/login.defs should be sufficient to change it; this will not affect users currently logged in, nor is there any way for you to force such a change to programs that are currently running
assuming the vps runs linux as well, i'd setup some ssh tunnels from a to b with b acting as a gateway
this works if the last line is ok:  awk 'begin {ignorecase=1}; nr==1 {lastline=$0; next;}; {if($0&gt;lastline) {print lastline; '\ 'lastline2=lastline; lastline=$0;} else if ($0&gt;lastline2) lastline=$0; }; '\ 'end {print lastline;}' file1.txt   old version (with bugs, for comparison)  awk 'begin {ignorecase=1}; nr==1 {lastline=$0; next;}; '\ '{if($0&gt;lastline) print lastline; lastline=$0;}; end {print lastline;}' file  
 you want to use /dev/sda3 as a new lvm pv. /dev/sda3 was previously used as a swap device.   you have 2 choices:   overwrite/wipe the previous contents of the device and make it an lvm pv. don't overwrite, leave it alone, and abort the operation
if you didn't install the package with yum or rpm, you also can't remove it with yum.  yum is essentially telling that the package is available in the repository but it's not installed.  to remove node.js just delete it from where you downloaded it to. 
sed -e 's!&lt;e&gt; *!&lt;e&gt; !g' -e 's! *&lt;/e&gt;! &lt;/e&gt;!g'   (note: i've used ! rather than # or / as my regular expression delimiter
ntop is probably your best solution for doing this
if you download the files from e.g
to see the pollution of your library, try:  find ./ -type f -iname "*.mp3" -exec /usr/bin/mid3v2 -l '{}' + | egrep -e "aenc|aspi|comm|comr|encr|equ2|etco|geob|grid|link|mcdi|mllt|owne|priv|pcnt|popm|poss|rbuf|rva2|rvrb|seek|sign|sylt|sytc|tbpm|tcom|tcop|tden|tdly|tdor|tdrl|tdtg|tenc|text|tflt|tipl|tit3|tkey|tlan|tlen|tmcl|tmed|tmoo|toal|tofn|toly|tope|town|tpe3|tpe4|tpos|tpro|tpub|trsn|trso|tsoa|tsop|tsot|tsrc|tsse|tsst|txxx|ufid|user|uslt|wcom|wcop|woaf|woar|woas|wors|wpay|wpub|wxxx"   generally you can use mid3v2 to edit id3v2 tags of an mp3 file.  find ./ -type f -iname "*.mp3" -exec /usr/bin/mid3v2 --delete-frames=aenc,aspi,comm,comr,encr,equ2,etco,geob,grid,link,mcdi,mllt,owne,priv,pcnt,popm,poss,rbuf,rva2,rvrb,seek,sign,sylt,sytc,tbpm,tcom,tcop,tden,tdly,tdor,tdrl,tdtg,tenc,text,tflt,tipl,tit3,tkey,tlan,tlen,tmcl,tmed,tmoo,toal,tofn,toly,tope,town,tpe3,tpe4,tpos,tpro,tpub,trsn,trso,tsoa,tsop,tsot,tsrc,tsse,tsst,txxx,ufid,user,uslt,wcom,wcop,woaf,woar,woas,wors,wpay,wpub,wxxx '{}' +   this will, recursively from the current directory, find all *.mp3 files and delete almost all of their id3v2 frames
yes, there can be
you don't need '' (strong quotes), you can use the weaker form "", except you then need to escape the "s.  awk "{sum+=\$5} end { print \"average = \",sum/nr}"  but why? 
found a working way! here is my line in fstab: device_uuid /media/data ntfs-3g defaults,windows_names,locale=en_us.utf8  0 0 doesn't show it in devices but mounts correctly. also the mount folder must exist! 
it looks like the language used in the tutorial refers to unpartitioned space as "free space"
you can use command substitution directly:  if $(dmesg | grep -q "firmware patch 1563"); then   # do something here fi   or a better way, use commands directly like l0b0's answer. 
yes, the contents of the file /sys/block/xxx/queue/cache_type file is how you can tell whether a device needs cache flushes or not
raid controllers present a virtual disk to the system that looks like a single disk to the operating system but is actually the array made up of multiple disks
i occasionally use the following script to add bluetooth keyboards to my systems, it adds it at a system level, rather than a user level, which seems to make things work right from the boot, and my keyboard(s) are usable from the login prompt.  as written, you'll need bash (v4.0+ hopefully) and the bluez package, which supplies the bluez-simple-agent, bluez-test-device, bluez-test-input programs.  most of the code below is to implement a list to allow you to choose which device, it really just boils down to the last 6 (non-comment) lines, if you know your bt mac address, you can replace all the choice stuff with a static assignment.  #!/bin/bash # # l nix &lt;lornix@lornix.com&gt; # setup-bt-kb : allow choosing &amp; pairing a bluetooth keyboard from the console # declare -a addrlist # while [ 1 ]; do     echo -n "scanning for bluetooth devices ..
i'd amend your list of criteria for protecting a script a little
rebuilding the experimental 5.6 mysql sources from experimental on wheezy is easy bordering on trivial
 du -ch *zip | grep total   just add a grep statement in the end
make sure you are running mknod -m 660 /dev/loop10 b 7 10
have a look at your display manager (lightdm, gdm, kdm, xdm, wdm).  newer lightdm versions can have a session-cleanup-script entry in the [seatdefaults] section of /etc/lightdm/lightdm.conf.  for gdm, you can put a script in the postsession directory.  for kdm, xdm and wdm have a look at this answer at superuser. 
you appear to have both a dos and mac partition table on the disk, and parted is recognizing the mac one
one (kinda ugly) solution, using bash arithmetic evaluation and the gnu date command:  echo $(date +%y)q$(( ($(date +%-m)-1)/3+1 )) echo $(date -d "-1 month" +%y)q$(( ($(date -d "-1 month" +%-m)-1)/3+1 ))   note that the %-m prevents date from 0-padding, so this will still work for august and september. 
well, rather confusing but anyway..
(copied from my comment on the question, as requested.)  see why should files end with a newline? - stack overflow
your management is wise in not trying to upgrade a working cluster that is performing an important function based on a proprietary package.  backporting packages is time consuming and risky, that is, not always feasible
yes you should be safe to remove any *-dev packages, since these are typically the header files needed when compiling against a give packaged library
found the solution to my problem
i would recommend a provisioning tool such as fabric or ansible for this
cloning the path is easy if you can run your terminal program from the command line
something like will help you  for file in aprilplate.txt  mayplate.txt  juneplate.txt  julyplate.txt  augustplate.txt; do for z in a b;    do for i in 3 4 5 13 14 15;      do grep $z$i $file |         awk -f "\t" '{print $3 "\t" $5}' |         sed -e 's/a[3-5]/swc/g;s/a[1][0-9]/swd/g;s/b[3-5]/tzc/g;s/b[1][0-9]/tzd/g;' &gt;&gt; stone.txt;    done; done &lt;snip&gt; done  
the orange text isn't the location, that's identifying the entry as swap
try this (as a partial example):  bind -n s-right next-window bind -n s-left previous-window   that should be enough to make it easy to get the other 2 settings working too
echo() {   command echo -n "$@" }   using command here means asking for the echo command (which happens to be builtin here) instead of the function one which otherwise would take precedence.  and since here, echo also happens to be a builtin (is not looked-up in $path btw as builtins have precedence over filesystem commands), you could also do:  echo() {   builtin echo -n "$@" }   that latter approach is preferable in zsh, where command echo would run /bin/echo instead (except in sh emulation).  there are some subtle variations between shells, but the order of precedence is generally:   special builtins functions builtins commands in $path (and the order depends on the order in $path and in the hash table as managed by the hash builtin)   bearing in mind that aliases and keywords in the shell syntax (for, if...), when not quoted are considered before those.  the order of 1 and 2 is reversed in some shells like bash or zsh
spawn your script within a screen session
i don't belive that the thunar automount is configurable to ignore special devices (i'm not for 100% sure...).  anyway in my point of view, mounting filesystems is not the job of an application, it should be the job of the operating system.  you could disable thunars automount feature and use udev and autofs.  with udev rules you can recoginze your devices and define how to handle it. 
you could use something like this, but it's not really recommended:  { rm logfile.log &amp;&amp; tail -n 100000 &gt; logfile.log ;} &lt; logfile.log   this is better:  tail -n 100000 logfile.log &gt; _tmp_ &amp;&amp;   mv -- _tmp_ logfile.log  
from man dir_colors:     the  program  ls(1) uses the environment variable ls_colors to determine the colors in which the filenames are to be displayed
i disabled "firewall" and "selinux default enforcing" and then the problem was solved. i also added device name (or host name, e.g
just edit your /etc/sysconfig/network-scripts/ifcfg-eth0 file
maybe like this:  #!/usr/bin/env bash clear ifs=: read -r -a paths &lt;&lt;&lt;"$path" read -p "type a command:  " cmd read -d ' ' file &lt;&lt;&lt;"$cmd"  #the first component of command for path in "${paths[@]}"; do          [ -x "$path/$file" ] &amp;&amp; eval "$path/$cmd" done   this basically runs the inputted command for every possible path resolution. 
first of all, check out pkill
the theory  the rules are :   inside a ' delimited string, nothing gets interpreted and anything but a ' doesn't have special meaning
according to the doc you link, you should be in the unix subdirectory of tcl8.5.9 to run the configure script, not in the tools subdirectory. 
chat &amp; pppd  chat is a program that the pppd program can use to dial a modem connection
in the old ufs, directory size was limited only by your disk space as directories are just files which - like other files - have effectively unbounded length
this can easily be done with diff
disregarding that your awk is missing a brace, and assuming list contains a single line, why not: name=$( cat list | awk '{print $1".modifications_to_name"') &amp;&amp; checkstatus | grep pertinentinfo | cleanupformatofpertinentinfo | sendalert $name  if you want to iterate through a list with multiple lines and have name evaluate to something different each time:  while read name; do checkstatus | grep pertinentinfo | cleanupformatofpertinentinfo | sendalert $name ; done &lt; &lt;(cat list | awk '{print $1".modifications_to_name"')  this seems like an x y question though. 
let's see
this is apparently an old issue (as in 15 years old)
to suppress error output in bash, append 2&gt;/dev/null to the end of your command
the problem is that with while read you are reading the file line by line
create a hostname file in /etc with the interface's name.  /etc/hostname.iwn0   add to it:  dhcp nwid "name of network" wpakey password   restart the interface.  sudo sh /etc/netstart iwn0   this way connection to the wireless network will be attempted on boot.    if you don't know the name of the wireless interface run,  ifconfig   and look for 802.11 in 'media' or wlan in 'groups'. 
from man bash:     *(pattern-list)                  matches zero or more occurrences of the given patterns   you have a glob expression which matches files beginning with zero or more 1s - which is all files.  one simple way to disable this globbing behaviour is to \ escape the parentheses:  rm *\(1\)*   otherwise you can use shopt -u extglob to disable the behaviour and shopt -s extglob to re-enable it:  shopt -u extglob rm *(1)* shopt -s extglob   note that as stephane says, extglob is enabled by bash-completion so disabling it may cause completion functions not to work properly. 
in terminal, run  gsettings set org.gnome.desktop.interface clock-format 12h   or fire up dconf-editor, go to org/gnome/desktop/interface/clock-format and turn off use default value then set custom value to 12h:   
i think there's no way to do this easily with sshd
generally when you buy a redhat license, you get access for one year to their repository
one way of being sure of not missing any message from the kernel is to debug it in a virtual machine.  for example, the following script uses qemu to start a virtual machine with a custom kernel:  qemu-system-x86_64\     -kernel arch/x86/boot/bzimage\     -drive file=/home/lgeorget/vm/image.qcow2,if=virtio\     -append "root=/dev/vda1"\     -netdev user,id=mynet0 -device e1000,netdev=mynet0\     -enable-kvm\     -s   the important option here is -s which makes qemu start a gdb server and wait for the debugger to be ready before booting.  in another console, go to your linux development tree, where you compiled your custom kernel, and here start gdb with gdb vmlinux to load the kernel symbols
boot from live linux distro (you can use ubuntu install disk) and use gparted  but always something can go wrong, so it is advisable to make a backup.  the other option is to format the unused partition and mount it and use it (depending on the size) as /home or /usr 
patches are usually contained in .diff files, because the patches are created using the diff command.  a patch is a series of insertions and deletions into source code
you cannot tell cat to use multiple standard out that way, the last redirection takes precedence so:  cat file1.txt &gt;&gt; file2.txt &gt;&gt; file1.txt   is equivalent to:  &gt;&gt; file2.txt ; cat file1.txt &gt;&gt; file1.txt   which obviously quickly fills the file system, given the fact the source file being the destination too grows indefinitely provided file1.txt is large enough not to be read at once.  most modern cat implementations should detect the recursivity and abort:  solaris cat:  cat: input/output files 'file1.txt' identical   gnu cat:  cat: file1.txt: input file is output file   they can be fooled anyway with something like:  cat &lt; file1.txt | cat | cat  &gt;&gt; file2.txt &gt;&gt; file1.txt   a nice not so useless use of cats ... 
you're probably thinking of the alternate screen feature, which allows full-screen applications such as htop to display in a different view, and on completion returning to the normal view (without the application showing)
you can configure swappiness per cgroup:  http://www.kernel.org/doc/documentation/cgroup-v1/cgroups.txt  http://www.kernel.org/doc/documentation/cgroup-v1/memory.txt  for an easier introduction to cgroups, with examples, see  https://access.redhat.com/site/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide/ch01.html 
identity file = private key file? from the manual, (man ssh-keygen):     ssh-keygen -p [-p old_passphrase] [-n new_passphrase] [-f keyfile]    the -p switch changes the passphrase of a private key file with a prompt, whereas the -p switch specifies the old password on the command line
i'm going to go out on a limb and recommend that you turn off dhcpd.service
if the statement would be correct without continuation, you need to use \
csv parsing is not easily done with posix tools only, unless you are using a simplified csv variant with no quoting (so that commas can't appear in a field)
edit in place, keeping only lines that match the pattern:  sed -n -r -i "/(pattern1|pattern2|pattern3|pattern4|pattern5)/p" ~/mpp/*.xml   on bsd sed (mac osx), try:  sed -n -e -i '' "/(pattern1|pattern2|pattern3|pattern4|pattern5)/p" ~/mpp/*.xml   basing the file name off of an already existing variable  for fname in ~/mpp/*.xml do     egrep "pattern1|pattern2|pattern3|pattern4|pattern5" "$fname" &gt; "$fname.2" done   the above works because a period is not legal in a variable name
i am afraid that is impossible afterwards
there are lots of ways of storing numbers - ascii (which can have locale specific variants, such as using ',' to seperate fractional part or as a thousands grouping), binary integer (variable number of bits)/float/double (all of which may vary depending on endian architecture and whether software producing the file formalises the representation), bcd (uncompressed, packed, fixed point and other variants), bi-quinary coded decimal....  there is no standard. 
i found a solution
you're using ansible already
the default zsh configuration for debian (and probably ubuntu) just doesn't include support for the command-not-found package per default.  in order to have the same functionality you just have to source /etc/zsh_command_not_found in your ~/.zshrc per default via:  [ -f /etc/zsh_command_not_found ] &amp;&amp; 
the problem is well explained here, as wce wait and cooperative exit and i encourage you to read it
stow has ignore lists which let you put a file called .stow-local-ignore at the top of your source tree
i am not sure i understand what you wish, so i will answer different, separate questions
you can't use crontab like that
(sorry, long explanation)  yes, the ifs variable in while ifs=" " read; do … has no effect on the rest of the code.  let's first precise that in shell's command-lines there are usually two different kinds of variables involved:   shell variables (which only exist within a shell, and are local to the shell) environment variables, which exist for every process
shell variable  you could accomplish this by adding the directories that you want to put in s1 in variables instead like so:  s1=/some/long/directory/that/is/deeply/nested/   you can then access these like this:  $ cp x.x $s1   symbolic link  you could maintain a link in your home directory that merely points to today's long directory.  $ ln /some/long/directory/that/is/deeply/nested/ $home/shortlink $ cp x.x $home/shortlink   directory bookmarking tools  take a look at this q &amp; a  titled: quick directory navigation in the terminal
messaging can be controlled through the banner and match commands in the sshd_config file
there's (out-of-tree) module called tp_smapi, which provides access to (amongst others) access to the battery-related functions of the embedded controller
from your comments, you seem to be confused about exactly what a shell is
the command mail -s "hello kid" mymail@gmail.com is waiting for you to type the mail message and then control-d
you have not said which os you are using so i am going to assume linux and will use debian as an example
you are writing the command in the wrong way
m-xdiff-buffer-with-file  i've just found it by looking through files.el where i felt there is such a command:     view the differences between buffer and its associated file.  
in tcsh (which i suppose is what you're calling "c-shell" if you're not totally masochist) in emacs mode (usually the default), you can use ctrl-w
debian squeeze has reached eol , it doesn't receive any security updates ,but if you need to update your database and install packages , its repositories can be found on debian archive .  you should edit your sources.list as bellow :  deb http://archive.debian.org/debian/ squeeze main non-free contrib   also you need to comment out all other repositories.  to update run:  apt-get install debian-archive-keyring apt-get update  
you can use the route command's -ifscope option to bind a route to a specific interface
different tools and versions thereof support different variants of regular expressions
for browing current directory, you could try to use : xdg-open . . 
there is a worm going around for an exim4 vulnerability in debian: http://blog.bytemark.co.uk//2010/12/12/fresh-worm-food 
yes you can, with capture groups
openwrt versions from kamikaze onwards (which is basically kamikaze and backfire, but not white russian) do not use nvram to store settings or configuration
this doesn't work because the read runs in a child process which cannot affect the parent's environment.  you have a few options:  you can convert your command to:  w1=$(echo "one two three four" | awk '{print $2}') w2=$(echo "one two three four" | awk '{print $4}')   alternatively, change ifs and use set:  oifs="$ifs" ifs=' ' set -- $(echo "one two three four" | awk '{print $2" "$4}') ifs="$oifs" w1=$1 w2=$2   or a here string:  read w1 w2 w3 w4 &lt;&lt;&lt; "one two three four"  
you can override the default setting for options such as requiretty for a specific user or for a specific command (or for a specific run-as-user or host), but not for a specific command when executed as a specific user.  for example, assuming that requiretty is set in the compile-default options, the following sudoers file allows both artbristol and bob to execute /path/to/program as root from a script
nixos community has three manuals, always consult them first, if you're stuck:   nix manual, for the package manager nixos manual, for the operating system nixpkgs manual, for nix package infrastructure   every package on nix is specified by a nix expression
simple answer: you can't, root can do everything.  you can set the "i" attribute with chattr (at least if you are on ext{2,3,4}) which makes a file unchangeable but root can just unset the attribute and delete the file anyways.  more complex (and ugly hackish workaround): put the directory you want unchangeable for root on remote server and mount it via nfs or smb
try:  tr ',' '\n' &lt; infile | sort -u | paste -sd, -  
you may adjust the panel size to large enough and it will split the window list to multiple rows. 
more does this by default:     once more has obtained input, it displays as much as can fit on the current screen and waits for user input to advance, with the exception that a form feed (^l) will also cause more to wait at that line, regardless of the amount of text on the screen.   to disable this behavior, use the -l option. 
you can use the virsh option mentioned above (probably faster, in fact) or you can use the "add hardware" option in virt-manager to either add new space or assign existing space.  simply open the vm, go to "details" (top left), and select "add hardware" (bottom left):    storage is the default type of hardware, so it should already be selected by default.  fwiw, since it's a new disk, if the guest is linux, you probably want to add it as virtio instead of ide
find /path/to/testroot -type f | wc -l 
you can get the locale information with:  $ locale lang=en_us.utf-8 language= lc_ctype="en_us.utf-8" lc_numeric="en_us.utf-8" lc_time="en_us.utf-8" lc_collate="en_us.utf-8" lc_monetary="en_us.utf-8" lc_messages="en_us.utf-8" lc_paper="en_us.utf-8" lc_name="en_us.utf-8" lc_address="en_us.utf-8" lc_telephone="en_us.utf-8" lc_measurement="en_us.utf-8" lc_identification="en_us.utf-8" lc_all=   the relevant variable for your concern would then be $lc_messages:     lc_messages            formats of informative and diagnostic messages and            interactive responses.   in a sctipt you could source that output to have those environment variables available:  $ source &lt;(locale)  
you can use shutdown:  sudo shutdown -h  06:45 &amp;   and to check it:  ps -aux | grep shutdown   if you want to cancel it:  sudo shutdown -c   this assumes of course that the shutdown time has already passed. 
rule of thumb, if escaping one kind of quotes doesn't work, escape the other:  alias analyze="hexdump -e '/1 \"%_ax) \"' -e '/1 \"%02x\" \"\n\"'"   here, i have escaped the inner double quotes, and quoted everything with double quotes.  the complete rule seems to be that you can escape double quotes inside double quotes, but you cannot escape single quotes inside single quotes
difference between threads and processes  important question on linux, because documentation perpetuates doubts (about threads not having their own pid for example).  note: this answer explains linux threads precisely.   in short: the kernel only handles "runnable entities", that is, something which can be run and scheduled
i think the best way to make use of your cores in gpu is to use opencl
sg allows switching the primary group to a different supplementary group (i.e
the information about what hard drives to mount where is stored in /etc/fstab. 
the binary would be inside the application bundle
it sounds like you want your müşteriler to have file transfer access to a folder without actually giving them shells
you can try to go for a key bind instead of command.  in case you want both commands available within a single combination then put to config ~/.config/zathura/zathurarc file something like:  map &lt;c-l&gt; feedkeys ":set recolor-lightcolor \#002b36&lt;return&gt;:set recolor-darkcolor \#839496&lt;return&gt;"   ps
you are looking for exactly the same like what is used for embedded systems.  you can make use of many tools, infrastructure and documentation from this area.  depending on your definition of super tiny, there is a choice of more or less minimal systems. besides specialized linux distributions, there are tools to strip down a common standard distribution to create a minimal system based on it.  as you are using ubuntu, good solution would be to use these tools to create a minimal ubuntu version;   see so: "what is the easiest x86 embedded linux?" and openembedded.org - getting started   you should first take a look at ubuntu core,  it may be just what you need.    the compressed images for 14.04 are about 65mb in size. 
use awk
if there is only one foo3 in line  sed -n '/foo3=/{s/.*foo3=//;s/\s*=.*//;p}' file.txt   suppress printing any line (-n options) exept which pushed by p
you can jump directly to a pane by typing pane's index while it is showed by display-panes command.  from man tmux:  display-panes [-t target-client]                    (alias: displayp)              display a visible indicator of each pane shown by target-client.              see the display-panes-time, display-panes-colour, and              display-panes-active-colour session options
update (new answer):  dtach has a -z option with the description "disable processing of the suspend key"
scribus is an open-source desktop publishing program and the closest analogue to publisher
the main problem with checking the desktop_session is that it is set by the display manager rather than the desktop session and is subject to inconsistencies
termbin.com supports what you need.  $ grep --color=force foo /etc/motd | nc termbin.com 9999 http://termbin.com/xxxx  $ curl http://termbin.com/xxxx   you'll get exactly what you sent.  the service is running on a free and open software called fiche so you can also install your own. 
use sh -c 'commands' as the command, e.g.:  /usr/bin/time --output=outtime -p sh -c 'echo "a"; echo "b"'  
as meuh says, the use of a pseudo-terminal may be forced with the -t option, and then the login will show-up with who
there's a few options.   od should be available on posix systems, so most unix and linux variants will have it
i've just found out that your chip is actually rtl8192eu
in order to create 'open folder as root' context menu command - and in order to create any new such command - a new *.contract file has to be created in /usr/share/contractor.  to create the file in gedit:  sudo gedit /usr/share/contractor/open_as_admin.contract  for 'open folder as root' - that file would have to contain something like  [contractor entry] name=open folder as root icon=gksu-root-terminal description=open folder as root mimetype=inode;application/x-sh;application/x-executable; exec=gksudo pantheon-files -d %u gettext-domain=pantheon-files   (but no icon appears in te context menu anyway)   
the -print0 action gets bound only to the second -name "filter" (test in find parlance), so it will only print out something if the second filter matches
if you want to add another language to your kde environment, you should install the appropriate language pack
the problem here is that by default arch boots up with kernel modesetting for the display (and console), using the open source nouveau driver
if you want to find all regular files beginning with p, you can use:  find /etc -type f -name 'p*'   if you want to no recurse into subdirectories:  find /etc -maxdepth 1 -type f -name 'p*'  
you can use:  awk '...     cpjpegvariable="cp -r '\''" imagedirectory "'\'' assets";     ...'   (note that ' doesn't need escaping for awk, but you need '\'' for the shell)
if you run the script with nohup python thermometer.py &amp; it will write the output to nohup.out file
i've since adopted another approach to this - using ![line-number]:p  this prints the statement and adds it to history but doesn't actually execute it
shell's prompt  inside your virtualenv environment is a file, bin/activate
a lot of commands (head/tail, sort, sh, vim...) treat arguments that start with + specially, so it's not a good idea to use that as the first character of a file name
for newer versions see koterpillar's answer.    iirc ibus uses gconf to store its settings so you should be able to use either gconf-editor or gconftool (cli) to get/set those settings. 
with curl:  curl ftp://example.com/ -x 'dele myfile.zip' --user username:password  
rpm has no concept of "suggested" packages, like deb has
running kill-ring-save doesn't deactivate the mark directly, but merely sets the variable deactivate-mark to t in order for the deactivation to be done afterward
the following program will do that  #!/bin/bash cd ~/target # first the tests: for program in `ls ~/target/*_rspec.rb` do   file=`echo $program | sed "s|$pwd/||"`   echo "testing ruby format for $file" - `ruby -wc $program` done # and then the page objects file: echo "testing ruby format for page_object_methods.rb" - `ruby -wc $pwd/page_object_methods.rb`  
i'm afraid the core of your problem is very much related to the use of vga
xargs expects input in a format that no other command produces, so it's hard to use effectively
the feature you are talking about is called auto-scrolling
actually, there is a wonderful explanation on why ! is used from here
in that specific example you could pipe it through to cut:  ps -ef | grep pmon | cut -d _ -f 3   why you would want to, however, is a bit of a mystery. 
if you are scripting downloads, you should consider using curl instead
use the -j option to zip to remove (junk) the paths:     -j      --junk-paths           store just the name of a saved file (junk the path), and do not store directory names
you can find all gnome projects here https://git.gnome.org/browse/.  and this is the documentation to develop https://developer.gnome.org/guides.  the man behind the design of all that is william jon mccann you can try to talk to him. 
since you seem to be using the linux version of stat(1), i'll assume you also have the gnu coreutils version of date(1):  timestamp=$( date +'%y-%m-%d %h:%m:%s' -r "$jarname".jar )  
this is a little convoluted, but at least it avoids the use of sql
the arch wiki mkinitcpio page explains the difference between the two:  the fallback image utilizes the same configuration file as the default image, except the autodetect hook is skipped during creation, thus including a full range of modules
with the conditions:   i cannot use any xml parser tool as i don't have permission , read only my xmllint version does not support xpath, and i cannot update it , read only i dont have xmlstarlet and cannot install it   i resorted to finding other unconventional solutions
try:  grep -- -r *.gnu   the -- indicates end of options so that -r is seen as an argument instead of an option to grep 
for upload/download testing i found the iperf tool quite useful:   user@hosta: iperf -s   user@hostb: iperf -c hosta   if the kernel is really the problem, you will usually get a kernel oops before the crash
this has nothing to do with the charset
chsh is the program for configuring your login shell
each linux distribution (or family of distributions) has its own package management system
split -l $y main.tsv main_part_ for part in main_part_*; do     program $part &amp; done wait echo "all done"   wait is a bash builtin: check the man page for details 
vms: vnic = 00:11:22:33:44:55 is what you're looking for 
if this is your setup, all you need to do is boot into linux and let it know you have a new os installed
(a) an entity known as the unicode common locale data repository seems to be the place that handles locales
your code says to print a string
i'm not sure what didn't help you in the link you provided, but sed seems like the right tool for this
in essence an ephemeral port is a random high port used to communicate with a known server port
it is called mbox-hook supporting printf-like sequnces in mailbox
the problems you've had with alien are most likely not due to a bug or limitation in alien, but to an intrinsic problem of your approach
from: another question,  the problem is that the program was compiled against 2.14 and you've got an older version
the way names in resolv.conf works is that a hostname is attempted to be resolved by the first name in the list, waits until a timeout, then proceeds to the next one and so on until you exhaust the list of nameservers.  if what you are trying to do is to use multiple hostname resolution souces concurrently, this is not the way things are designed.  as to acceptability of including multiple souces, there is no problem. 
if you have an usb stick bigger than 4 gb and you want to put big files on it, try ntfs
the issue is buffering.  use the --line-buffered option to force grep to flush the buffer after every line:  tailf log | grep --line-buffered "some words" &gt;&gt; file  
this works, as indicated by jasonwryan:  awk 'begin{print "start"}; {print}; end{print "end"}'  
unfortunately you are going to have to repopulate the rpmdb, and you can only do that if you have the rpms itself
the syndaemon should do the job
turns out that for some reason ubuntu had enabled mir on my laptop
yes the rpm spec is not part of packaged rpm. however, you can query the rpm package for information which was present in the spec file.  for example:  1) following command will give you the pre/post scripts which are executed when rpm package is installed or updated.  rpm -q --scripts (installed rpm name, this name will be without the .rpm extension) rpm -qp --scripts (if you have a rpm file)   2) you can look at specific information present in the spec file, using the --queryformat option of rpm command.  rpm -q --queryformat '%{arch} %{name}\n' (rpm name, if it installed) rpm -qp --queryformat '%{arch} %{name}\n' (if you have an rpm file)   above will give the architecture for which the rpm is designed and the actual name of the rpm. these information go in specific sections of the spec file, like name, arch, requires(pre), requires(post), buildrequires etc. for valid query options check this link 
you appear to be referring to the session group index, which is generated, and not used for telling tmux which session you would like to attach to.  it's used in the template for list-sessions:  "#{?session_grouped, (group ,}" \   and generated in session.c (and always starts at zero):  /* find session group index
you could do it with awk instead of grep if that's acceptable:  mycmd | awk '/id:/ {print "   " $0}'   or if you need grep, sed could help:  mycmd | grep "id:" | sed -e 's/^/   /'   the awk version does its own pattern match for lines that contain "id:" and then will print the spaces before the line
bash does not completely re-interpret the command line after expanding variables
the client can specify the hostkey algorithm it prefers with the option hostkeyalgorithms in ssh_config or ~/.ssh/config or on the command line
ok, i worked out that even though i was setting gksu to use sudo for authentication, this was all irrelevant as the shortcuts that i was using in the xfce menu were starting applications using polkit and not gksu.  from the gentoo wiki on polkit, i did:  sudo bash -c "cat &gt; /etc/polkit-1/rules.d/10-admin.rules" &lt;&lt;eol polkit.addadminrule(function(action, subject) {     return ["unix-group:wheel"]; }); eol   ...and this let me start applications which needed root privileges by entering my password in sudo-style fashion. 
if you want to delete all blank lines starting with line 5 and keep lines 1 to 4, you can use  sed -i '5,${;/^$/d;}' temp_spec.rb   the { is the grouping operator, so the first command 5,${ means "from line 5 until the end of input ($) execute the following commands until the matching }"
iptables keep a count (per chain) of packets processed
please don't post pictures of text; copy and paste from the terminal into the question.  there are several ways to filter out blank lines
in some cases, especially with smaller tools/utilities, one might resort to compiling from source.  in this case compiling as described on the wiki worked
diff takes filenames as arguments -- you passed the data from the stdout of the command, instead
the current domain controller container from turnkey uses samba, and includes the web-based interface (webmin)
try (awk can be in one line)   id=...  awk -v id=$id 'nr==1 { x=nf+1 ; $x = "id" ; print ; }                 nr &gt; 1 { x=nf+1 ; $x = id ; print ; } ' file &gt; new_file   where    -v id=$id  paste id from shell to awk, if id has funny char, use -v id="îd" nr == 1 , nr  &gt; 1 select first, other line { x=nf+1 ; $x = id ; print ; } push $id ( id in awk )  
you can do:  htop -p `pstree -p $pid | perl -ne 'push @t, /\((\d+)\)/g; end { print join ",", @t }'`   where $pid is the root process. 
-vnc 127.0.0.1:x: use a vnc terminal emulator to connect to the virtual terminal on port 5900+x at localhost where you can use the given credentials. 
you need quotes around the result of the command substitution, i.e
to answer the question in your title: how to fake a filesystem that cannot be mounted by others? write random data
the solution was not that complicated
i would recommend a full terminal emulator for windows like cygwin, mobaxterm, or bitvise
try this:  #!/bin/bash  while ifs= read -r pp; do   find 
this should work with gdm ≥ 3.12 (tested on archlinux w
gnu bash exports <a href="http://tldp.org/ldp/abs/html/functions.html" rel="nofollow" title="advanced bash-scripting guide: chapter 24
you can think of ldap as a tree (example)
for trim to work, it has to be enabled on all layers
woohoo, i solved it :)  the short answer is you can't mount >4k block size devices on x86 linux machines as far as i can tell without some serious kernel hacking.  however, there is a work around.
you should be able to use the user-mode networking stack
this can be done with process groups (suggested here) and setsid to start new one:  while true; do       handle_input_with_timeout &lt; &lt;( setsid bash -c '           printf -- "-$$" &gt; /tmp/saved_process_group.pid           prog1 | prog2 | prog3           ')     echo "data stopped flowing
your problem is so obvious that you're going to knock yourself on the head once you see it: stop advertising a router -- get rid of your "option routers" line in your dhcpd.conf
one thing i would do is have a look at /var/log/syslog
it is possible to install a gnu/linux distro on a mac
string multiplication trick based on this answer: http://stackoverflow.com/a/5349772/4082052    use substitution to insert programmable number of dashes  paste $(for i in {1..400}; do echo -n '- '; done)   or   paste $(printf -- "- %.s" {1..400})   to know why printf -- was used: dashes in printf 
you first have to add the webupd8 repository to your system:    sudo add-apt-repository ppa:webupd8team/java sudo apt-get update   then install the package oracle-java7-installer.  if you already added the repository to your system, it could be you just never performed a sudo apt-get update, to update the package list.  another option is openjdk. 
although the ultimate decision comes from the software developer, this seems to be more in line with files zsh uses (from the man page):     $zdotdir/.zshenv    $zdotdir/.zprofile    $zdotdir/.zshrc    $zdotdir/.zlogin    $zdotdir/.zlogout    ${tmpprefix}*   (default is /tmp/zsh*)    /etc/zshenv    /etc/zprofile    /etc/zshrc    /etc/zlogin    /etc/zlogout   ignoring a leading dot, none of these use a zsh_ prefix, and only a few a full zsh prefix
when using shell variables, you can preserve space characters (more precisely, prevent values from being split into words based on the field separator characters, which are enumerated in the $ifs shell variable) by surrounding the shell variables with double quotes.  for w in "${words[@]}"  do    echo -n "$f [$w]:"   grep -aci "$w" $f 2&gt;/dev/null done   (it wouldn't hurt to surround $f with quotes, too, in case you encounter filenames with spaces.)     as the second loop(2) ends up outputting every unique occurrences of a word in a log, how can its scope be restricted or how should i discard:      the output consisting of single chars?   add grep .. in the pipeline to include only lines with 2 or more characters.     the output consisting of single occurrences?   add -d to the uniq in the pipeline, so that it will only show duplicate lines.  cat $f 2&gt;/dev/null | tr -c '[:alnum:]' '[\n*]' | tr -d '[:digit:]' | sort -f | grep .
to make that work, you need files to be an array, not a variable
i think the case/esac construct fits well here.  #!/bin/bash  case "`date +%j`" in   40) name=osvaldo ;;   47) name=berenice ;;   54) name=nizaá ;;   *) exit ;; esac  echo "esta semana le toca preparar el café a ${name}" \    | mail -s 'café' mailgroup@somedomain.mx   note: if the same person needs to make coffee several times, you can aggregate tests with |:  case "`date +%j`" in   12|23|40|49) name=osvaldo ;;   10|19|30|47) name=berenice ;; ...  
use single quotes to prevent expansion at the time of assignment:  alias atm='atom $(fzf)'  
sudo su - ###gets you to /root, as the root user.  
you can use grep
this was due to a system which was outdated
heirloom-mailx hardcodes the options to pass to /usr/sbin/sendmail, and unfortunately the ones it passes don't make bcc: headers work right in exim
   what is a kernel?   in the sense of your question, it is a single large program that runs at a special privilege level on the processor
actually it uses whatever is specified in the manpager or the pager environment variable.  depending on your man implementation and version there could be also a command line switch to specify the pager.  with the man-db implementation i use all the below ways work:  manpager=cat man man  pager=cat man man  manopt='-p cat' man man  man -p cat man   to set it permanently, just add it to your ~/.bashrc (or other initialization file used by your shell):  export manpager=cat   that works with some older man implementations too, while manopt is man-db specific:  export manopt='-p cat'   (better do not set pager that way
the portions of an executable file that contain the machine instructions are called the text sections, and taken together they're called the text segment
the debian distribution (and hence ubuntu, which is derived from it) does not define any differences between runlevels 2-5 as a matter of policy
you can automate this with globbing, specifically the e glob qualifier, plus eval, but it isn't pretty and the quoting is tricky:  eval paste *.csv(e\''reply="&lt;(cut -d, -f1 $reply)"'\')    the part between \'…\' is some code to execute for every match of the glob
use find with an absolute path
let's say you lack both gnu screen and tmux (and x11, and virtual consoles) but want to switch between a login shell and another interactive shell.  you would first login on the console, and then start a new shell, temporarily blocking the login shell
you will probably see the most major benefits by using compression using the -c option
you can do this:  awk -f, '$3 == "0"' ./inputfile.csv &gt; ./out/output.csv   ~ is pattern matching, which you don't want here
the line which ends the here document is  \$fff   from the man bash section on here documents:     the format of here-documents is:             &lt;&lt;[-]word                   here-document           delimiter      no  parameter  and  variable  expansion,  command substitution, arithmetic expansion, or pathname expansion is performed on word
for question 1, you can do this:  find 
the nullglob option (which btw is a zsh invention, only added years later to bash (2.0)) would not be ideal in a number of cases
looks to me like that is because of a new version of iptables that came out in october
watch is great, but this is one of the things it can't do
you're gonna need a launcher (.desktop file)
seems to be an effect of this bug: https://bugzilla.gnome.org/show_bug.cgi?id=127731  the bug is triggered when you have a very long line (something over 500k chars)
it's a separator of commands
you wrote everything right but missed something here: swap swap defaults  # lvcreate –name lv_swap2 –size 100m vg # mkswap /dev/vg/lv_swap2 # swapon /dev/vg/lv_swap2 # vi /etc/fstab /dev/vg/lv_swap2 swap swap defaults 0 0   now it should work. 
starting with the situation you have:  cd dpkg-1.18.15 patch -p1 &lt; ../d-m-h-verbose-version-check.patch   will apply the patch
from the journalctl manpage:     the output is paged through less by default, and long lines are    "truncated" to screen width
add this to your ~/.zshrc  alias sudo='nocorrect sudo'  
you can read michael homer's answer to know the reason.  to remove all things in /var/www exclude wp, posixly:  find /var/www -path /var/www/wp -prune -o ! -path /var/www -exec rm -rf {} +  
this can be done using command substitution, like so:  mvn -dvar_name="$(cat /path/to/file)" # posix mvn -dvar_name="$(&lt;/path/to/file)"    # bash   this has a notable caveat, though, namely that all trailing newlines are stripped
it is documented in solaris 9 but not in solaris 8. 
i use fail2ban. you can edit /etc/fail2ban/filter.d/postfix.conf to catch any further attempts
you're running ubuntu 14.04, which uses upstart as its init process
typically, for finding the processes sharing the library, you can use the command lsof shared_library_path
you cannot enable just some key-repeats when all key-repeats of all keys are already disabled
dd if=/dev/zero of=/dev/null&amp;  the trailing &amp; means run the prefix command in background
okay, i eventually found it
   i wonder why only 90kb was removed when i downloaded many mb ?   this 90kb might only be the nginx executable
i found this script which you can modify to attach a signature to an existing pdf file.   http://emmanuel.branlard.free.fr/work/linux/dev/signpdf/signpdf   you can also download it from this pastebin url:   http://pastebin.com/9tl5pvba   there is also this q&amp;a on askubuntu that has many other methods for doing this
thanks for posting this
in all honesty, i'd just set up key-based authentication, disable password authentication, and not worry about people rattling the doorknob
if you want to select @ and up to the first , after that, you need to specify it as @[^,]*,  that is @ followed by any number (*) of non-commas ([^,]) followed by a comma (,). 
shebang wasn't meant to be that flexible
apart from not getting detailed information about your test setup the main problem seems to be, that you use a message size of 64 byte
you just need to update your logic a bit, only count lines actually added inside the loop
it's possible, but probably not desirable
use the tee command as follows:  (cmd | tee stdout.log) 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3 | tee stderr.log   3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3 is how you swap stderr and stdout, because tee can only accept stdout.  take a look at unix tee command for more advanced redirections using tee. 
best way to get an idea is taking look at the slackware build scripts (located in sources/*/* in the distribution trees)
i've got to get this out of the way first:  you really, really need to turn off that system
don't use xml::simple
how about  if synclient -l | egrep "touchpadoff.*= *0" ; then      synclient touchpadoff=1 ;  else      synclient touchpadoff=0 ;  fi   note that there is a third setting, "touchpadoff = 2", where only tapping is disabled.  another possibility, a oneliner, but not a very efficient one:  synclient touchpadoff=`{ synclient -l | egrep "touchpadoff.*= *0" &amp;&amp; echo 1 ; } || echo 0`  
from https://awesomewm.org/wiki/awesome_and_xfce4   go to: settings -&gt; session and startup -&gt; session and change restart style of xfwm4 to never then go to application autostart and add awesome   it should work after restarting xfce 
normal users can not do much harm on linux.  but you should check that memory and number of process limits are in place
the answers to your questions:   if the systemout.log file is owned by the same or more privileged account that runs the script, yes you can write to it, but i suggest not doing this, as you may need to provide that log to vendor for troubleshooting a problem one day and foreign entries in the log may throw them off and at the worst case they might refuse to help you because the file integrity was compromised (far chance but not non-existent) as long as the file/directory ownerships and permissions allow you, you can write this anywhere you want. you can add this log file to the logrotate scope and it will get recycled in the schedule desired
the /boot directory in the root is simply the place where your boot partition gets mounted, which means the files in that partition appear in /boot
thunderbird is written is xul
anything with the ppid of 1 is, for the most part, likely a daemon
try a "softer" search pattern, there are 2 hw controllers for me ethernet and network, each hw device requires a driver.  here's mine.  $ lspci -vvnn |grep -i net 03:00.0 network controller [0280]: atheros communications inc
there are several possibilities.  one method is to compile using   :!gcc file.c   but a nicer strategy would be to have a makefile and compile just using  :make   where the easiest makefile would look like.  program:         gcc file.c   others can explain this a lot better. 
i hope i understand it right.  cat file1 file2 | grep -e '(^restoration\ was\ successfully|^server\ restoration\ is\ complete)'   when the files start with single-quotes :  cat file1 file2 | grep -e '(^\'restoration\ was\ successfully|^\'server\ restoration\ is\ complete)'  
yes, you can.  using grep with pcre(-p):  ip addr | grep -po '^\d+:\s+\k[^:]+'    ^\d+:\s+ matched the portion before interface name at the start, \k discards the match [^:]+ gets the portion upto the next : i.e
there is xman, a graphical utility for displaying manpages.  i don't know anyone who has ever used it though
i don't know if the existing options (e.g
how about pure grep solution?  df -k | grep var | grep -o '[0-9]*%'   you can then join those two greps with a little help of perl regexp:  df -k | grep -po 'var.* \k[0-9]*%'  
you can use xargs:  locate filename123 | xargs vi   by default xargs will execute as few instances of the specified command as possible, passing as many parameters as possible according to the system's arg_max
it should be   if [ "$dir1" = "$dir2" ] &amp;&amp; [ "$length1" -gt 0 ] &amp;&amp; [ "$length2" -gt 0 ]   remember, variable names must be preceded by $s
you can install it normally !          just boot with your usb pluged in and chose it .  if you want to install it while running your current os then install kvm and use the folowing cmds :    cdrom=/path/to/kali.iso   hda=/dev/sd[x] # e.g /dev/sda (a hd not part like /dev/sda1) use lsblk   kvm -cdrom "$cdrom" -hda "$hda" -m 1024 -boot d   you can use this script !       #!/bin/bash ((!euid)) || exec sudo "$0" #note : don't use $home var in your paths , because the script will restart as root # which means if you have var=$home/file.iso , when script re-exec itself  # your var will be "/root/file.iso" not "/home/user/file.iso" xcdimagedirectory=/home/younes/documents/library/application/x-cd-image xrawdiskimagedirectory=/home/younes/documents/library/application/x-raw-disk-image defaultharddrive=$xrawdiskimagedirectory/`basename $0`.img #creat a default raw-img if like testing os's function bootxcdimage() {   kvm -cdrom "$1" -hda "$2" -m 1024 -boot d } function bootxrawdiskimage() {   kvm -hda "$1" -m 1024 }  echo -n "boottype : 1=&gt;isoimage , 2=&gt;rawimage,   ??: " read boottype case $boottype in   1 )     echo "pick an xcdimage!"     ls $xcdimagedirectory/ | nl     read n     ((${#n})) &amp;&amp; {     xcdimage=$(ls $xcdimagedirectory/* | sed -n "$n p")     echo "selected image : $xcdimage"     } || {         echo "nothing done"         exit     }     echo "pick a hard drive to use ! sdx or sdxy or empty for default image.img"     lsblk | grep --color=auto 'sd[a-z]'     read harddrive     [[ -n $harddrive ]] &amp;&amp; {         harddrive=/dev/$harddrive     } || {         [[ -f $defaultharddrive ]] &amp;&amp; {             harddrive=$defaultharddrive         } || {         echo "$defaultharddrive does not exist !"         exit         }     }     echo "selected harddrive: $harddrive"     bootxcdimage "$xcdimage" "$harddrive"     ;;   2 )     echo "pick an xrawdiskimage!"     ls $xrawdiskimagedirectory/ | nl     read n     ((${#n})) &amp;&amp; {         xrawdiskimage=$(ls $xrawdiskimagedirectory/* | sed -n "$n p")         [[ -f $xrawdiskimage ]] || {             echo "$xrawdiskimage does not exist !"             exit         }         bootxrawdiskimage "$xrawdiskimage"         } || {         echo "nothing done"         exit     }     ;;   * )     echo "nothing done!"     ;; esac exit  
you could use the -o switch to specify your output format:  $ ps -eo args   from the man page:     command with all its arguments as a string
because it's saving the filename and timestamp so that it can try to restore both after you decompress it later
many, but i will cite a few on top of my head.   what if ssh/rsh are not available on the remote server or if they are broken in terms of configuration or stricter network rules
just quote your path   basename  "/isf/gcm/vpfig/aas/ar/clco el doma republic/vmn crtro.txt"  
with xterm, you could use the translations resource to assign a string (such as "setxkbmap us") to a function-key
because at does not execute commands in the context of your logged in user session
you can do it by piping to mysql:  while … do     ⋮     echo "insert into ip_mactable (ip_address, mac) values ('$ip','$mac');" done | mysql -u root …   note how i changed your while loop to output the queries it wants to run to stdout
you can throttle the network bandwidth on the interface using the command called tc man page available at http://linux.die.net/man/8/tc  for a simple script, try wondershaper. 
your question is not clear, you talk about a daemon in the title, but in the body only talk about a generic process.  for a daemon there are specific means to stop it, for example in debian you have      service daemon-name stop   or      /etc/init.d/daemon-name stop   similar syntaxes exist for other initscript standards used in other distributions/os.  to kill a non-daemon process, supposing it is in some way out of control, you can safely use killall or pkill, given that they use by default the sigterm (15) signal, and any decently written application should catch and gracefully exit on receiving this signal
you can use sed to print a range selection (from 2 to 3):  ~$ sed -n '2,3p' filea donec.non.nibh=ut tortor nam.mattis.lacus=et rhoncus sodales   or use head to select the first 3 lines, and tail to select the last 2 lines (of the 3 lines):  ~$ head -3 filea | tail -2 donec.non.nibh=ut tortor nam.mattis.lacus=et rhoncus sodales  
what is costly, is doing system calls on the files (for the system calls themselves and for the i/o).  things like -type, -mtime require a lstat(2) system call on the file
you use the -x switch
turned out this was a numbskull error, looks like my copy of badblocks may have just had a bug.  i ran yum update and after that, badblocks no longer segfaults. 
put this in your .profile or .bashrc or .zshrc or whichever shell you use:  function mycommand {     tor &amp;     polipo &amp;     planobar }   and now just run mycommand 
wildcard matches are sorted in lexicographic order, so 10 is between 1 and 2, not after 9.  to sort matches with numbers in numeric order, use zsh and its n glob qualifier  pdfjam *.jpg(on)   or (still zsh-only) set the numeric_glob_sort option:  setopt numeric_glob_sort   # this can go in your ~/.zshrc pdfjam *.jpg   if all your files have a number of the same format, you can enumerate the number of digits:  pdfjam masi?.jpg masi??.jpg   but with fancier file names mixed in like masi3-1.pdf, there's no easy solution in bash. 
use apt-cache:  apt-cache search packagename   this shows packages that apt considers related(many of them don't even include name of packge in both description and name).  if you only want packages that contain packagename in description or name, pipe with grep:  apt-cache search packagename | grep 'packagename'   but! other tools for the rescue:  axi-cache search packagename   you can read more about axi-cache here
check your bios settings, make the boot priority look like this:   cdrom usb internal drive   then if your usb is not connected it will boot from the internal drive
{ grep -m1 match; grep -c ''; } &lt;file   that will work w/ gnu grep and an lseek()able infile
the program calling the linux partition "unallocated" sounds like the windows disk management tool
if you define a function like  loglast() {     fc -ln -1 | sed 's/^[[:space:]]*//' &gt;&gt; "${1:-${logfile:-~/command.log}}" }   then after every command you want to log, you can run loglast to log the previous command.  the log file used is (in order): the optional first argument to loglast, or $logfile if no argument given, or $home/command.log as a last default.  the sed -s '/^[[:space:]]*// removes the leading spaces that fc adds. 
to list active aliases, run:  alias   to see names of all active functions, run:  declare -f   to see the names and definitions of all active functions, run:  declare -f   more  the information on aliases is also available is a script-friendly format with:  declare -p bash_aliases   man bash provides more info on the alias builtin:      alias [-p] [name[=value] ...]           alias with  no  arguments  or  with  the  -p           option  prints  the  list  of aliases in the           form alias name=value  on  standard  output.           when  arguments  are  supplied,  an alias is           defined for each name whose value is  given.           a  trailing  space in  value causes the next           word to be checked  for  alias  substitution           when  the  alias is expanded
there is no default standart way to setup a firewall in debian, except maybe calling a script with a pre rule in the network configuration (/etc/network/interfaces) but there are many packages providing different ways to do it.  for example the packages uruk and iptables-persistent provide very simple scripts to load and backup a very simple firewall. 
 rc  is typically not used by linux distributions but is used in bsd rc.local is used to be able to execute additional commands during the startup without having to add symlinks. rc.sysinit seems to be redhat specific and is executed very early in the process
need to edit the board's file that defines platform devices
ps1 stands for "prompt string one" or "prompt statement one", the first prompt string (that you see at a command line).  yes, there is a ps2 and more! please read this article and the arch wiki and of course the bash reference manual. 
less can determine if it has been given a directory
if available (ie
fedora 15 uses systemd
normally, the project will have a website with instructions for how to build and install it
if you use an absolute path in a filter (include/exclude), it's interpreted starting from the root of the synchronization
you can use fuser, or lsof.  fuser foo.zip   the output looks like so:  $ fuser archlinux-2013.02.01-dual.iso  /home/chris/archlinux-2013.02.01-dual.iso: 22506 $ awk -f'\0' '{ print $1 }' /proc/22506/cmdline  wget  
if you know the line numbers you want to search (as your q suggests), tighten the regex so that you don't match unwanted lines.  for example, change:  sed -n '/11/,/14/p' | grep name | awk -f "= " '{print $2}'   to  sed -n '/^11 /,/^14 /p' | grep name | awk -f "= " '{print $2}'   the ^ will match the beginning of the line and a space after the number guarantees that the specific line number will be matched, and you won't process unwanted blocks. 
if you really had to, you could do something like this:  host xxxx      user my_username      proxycommand nc asd$((1+$((random %% 30)))).asd.asd.asd.com 22   this assumes you're using the bash shell -- otherwise you can put the proxy command as the argument for a bash invocation, e.g.       proxycommand /bin/bash -c "exec nc asd$((1+$((random %% 30)))).asd.asd.asd.com 22"  
there is no need to use eval in this instance  eval $i forces eval to evaluate the contents of i as a command - this is why you see errors such as b: command not found being reported  a better way would be to print parameter values with bash using variable deferencing  for i in a b c; do echo "$i=${!i}"; done a=1 b=2 c=3  
hvc0 is the xen hypervisor console
assuming you have the ports tree installed, it's as easy as  cd /usr/ports/shells/bash make all install clean   if you don't have the ports tree, just do this:  portsnap fetch extract   and then try again
aside from how to cut and re-arrange the fields (covered in the other answers), there is the issue of quirky csv fields
you can use the perl library libtext-lorem-perl
i googled a bit around with 'fedora add repository' and got some outdated and not very helpful links
this is for the mate version :  fonts:     click 'menu', type  'apparence' and click, select tab : polices ,  then update font and/or size as needed.  desktop icons size:     right click the icon, there is a 'resize icon' entry, drag the icon's corner. 
something to get you started (just in case you want to write it yourself):  #!/bin/bash # # usage: bwmon pid  in=0; out=0; time=0  get_traffic() {     t=`awk '/eth0:/ { printf("%s,%d,%d\n",strftime("%s"),$2,$10); }' &lt; /proc/$1/net/dev`     in=${t#*,}; in=${in%,*}     out=${t##*,};     time=${t%%,*}; }  get_traffic $1 while true do     _in=$in; _out=$out; _time=$time     get_traffic $1     echo "$time,$(( $time - $_time )),$in,$(( $in - $_in )),$out,$(( $out - $_out))"     sleep 1 done   comments:   checks only eth0 checks every 1 second works only under linux, but other unixes work similar (procfs or whatever) output could be stored into a sqlite.db with stat --printf="%n\n" /proc/pid/exe | cut -d ' ' -f 3  
it seems the raid metadata got damaged somehow
you'll have to close (or otherwise redirect) the standard input of the individual commands:  #!/bin/bash  apt-get purge -y nginx &lt;&amp;- apt-get install -y nginx &lt;&amp;-  date   otherwise subsequent line are fed to the commands. 
as per struct usb_device:   urbnum      number of urbs submitted for the whole device    where urb stands for usb request block
there are a number of factors that might make a software clock run slow or fast
the behaviour you're looking for is a special case:   cp -r [-h|-l|-p] [-fip] source_file..
in my case i edited /etc/ssh/sshd_config and uncommented the line passwordauthentication no, that did it in my case, now if the client send no key or an unauthorized one the server closes the connection
from http://blog.chewearn.com/2008/12/18/rearrange-pdf-pages-with-pdftk/  pdftk a=src.pdf b=blank.pdf cat a1 b1 a2-end output res.pdf   hope you like this script, just save it as pdfinsertblankpageat.sh, add execute permissions, and run
the master boot record (mbr) at the beginning of a disk contains only 446 bytes of code, so it is tiny and cannot do much
if you have the binary .deb file, you can use midnight commander (mc) from the shell to just navigate inside and retrieve files from it.  for your convenience, this is the file as found in pure-ftpd-mysql_1.0.36-1.1_i386.deb:  #! /bin/sh ### begin init info # provides:          pure-ftpd-mysql # required-start:    $remote_fs $syslog # required-stop:     $remote_fs $syslog # should-start:      slapd mysql postgresql-8.3 postgresql-8.4 # should-stop:       slapd mysql postgresql-8.3 postgresql-8.4 # default-start:     2 3 4 5 # default-stop:      0 1 6 ### end init info # # pure-ftpd     starts and stops the pure-ftpd ftp daemon # # copyright 2002-2011 by stefan hornburg (racke) &lt;racke@linuxia.de&gt;  path=/sbin:/bin:/usr/sbin:/usr/bin name=pure-ftpd desc="ftp server" : ${ssdaemonlogopts:="--quiet"} uploaddaemon=/usr/sbin/pure-uploadscript udname=pure-uploadscript uddesc="ftp upload handler" wrapper=/usr/sbin/pure-ftpd-wrapper  # load lsb init-functions to get status_of_proc helper 
you have several options here:   git commit your .vim folder and have your group members clone it from there
couple of ways to approach this.   merge streams  you could by pass determining the difference all together and simply merge stderr and stdout.  example  quodlibet --status 2&gt;&amp;1 | ...  use grep  you could chop the output down by using the -o &amp; -e switches to grep.  example  $ echo "...blah not-running blah..." | grep -eo "not-running|paused|playing" not-running  $ echo "...blah paused blah..." | grep -eo "not-running|paused|playing" paused  $ echo "...blah playing blah..." | grep -eo "not-running|paused|playing" playing   this will cut everything out except for the strings that match the regex argument to grep. determine the stream's type  you can use the -t switch to determine the type of the file descriptor stream.  excerpt from bash man page     -t fd true if file descriptor fd is open and refers to a terminal.      where fd is one of:      0:     stdin   1:     stdout   2:     stderr   example  this detects if the output is coming from stdout.  $ if [ -t 1 ]; then echo "from stdout"; fi from stdout   returns "from stdout" since the output is coming through while:  $ (if [ -t 1 ]; then echo "from stdout"; fi) | cat   returns nothing, since the output is being directed to cat.  
use set -o:  $ set -o allexport       off braceexpand     on emacs           on errexit         off errtrace        off functrace       off hashall         on histexpand      on history         on ignoreeof       off interactive-comments    on keyword         off monitor         on noclobber       off noexec          off noglob          off nolog           off notify          off nounset         off onecmd          off physical        off pipefail        off posix           off privileged      off verbose         off vi              off xtrace          off   also see set and shopt - why two? 
adding entries to your .bashrc for settings to survive a powercycle (or just logout and login) is good practise, but both your examples have problems:  export http_proxy=http://proxy:8080 export all_proxy=$http_proxy   only sets and exports http_proxy on the first application:  $ export http_proxy=http://proxy:8080 export all_proxy=$http_proxy $ echo $http_proxy http://proxy:8080 $ echo $all_proxy  $ export http_proxy=http://proxy:8080 export all_proxy=$http_proxy $ echo $all_proxy http://proxy:8080   so put those on two separate lines in .bashrc in this order:  export http_proxy=http://proxy:8080 export all_proxy=$http_proxy   appending to .bashrc using the echo command allows copy and paste as a one liner
   it allows switching users without logging out [many user can be logged in on the same hardware at the same time with one user active].   i believe consolekit provided a mechanism for applications to determine which user is active, i.e
there is another way of thinking on this matter: restrict ssh access to specific groups.   edit /etc/ssh/sshd_config add the line allowgroups sshusers or allowgroups your_user_primary_group  in case of allowgroups sshusers create this administrative group: groupadd -r sshusers add ssh allowed users to this group:  usermod -ag sshusers username  reload sshd service
extent must be used after background and gravity, e.g.:   gm convert -resize '1920x1080&gt;' -background black -gravity southeast -extent 1920x1080 infile outfile   or   gm convert infile -resize '1920x1080&gt;' -background black -gravity southeast -extent 1920x1080 outfile  
with zsh, use glob qualifiers:  mv home*(.) dst    moves only regular files.  while   mv home*(^/) dst    moves files of any type except directories.  mv home*(^-/) dst   would also exclude symlinks to directories. 
i'm going to assume you're talking about changing something found in $path, and that the shell you are in is still launching the original program.  if so, what you're looking for is hash -r  $ help hash hash: hash [-lr] [-p pathname] [-dt] [name ...]     remember or display program locations.      determine and remember the full pathname of each command name
the solution i used was to search the sql file for everywhere that this text existed:  -- database: `my_database_01`   and right under it, add the following lines:  create database if not exists `my_database_01`; use `my_database_01`;   i did this for each database in the sql dump file, and then i was able to import and restore all databases using phpmyadmin's import command. 
my mainboard is an asus p8z77-m
ssh has a feature to pass environment variables from the client to the server, but openssh disables it in the default server configuration
you can find out which package ships a given binary under fedora like this:  yum provides "*bin/xfontsel"   however this only works if you know the name and directory of the executable
i haven't used it myself but the gimp has scripting tools available which are cli based, script-fu i think it's called
a simple grep should do this for you:  grep -o "https://sitename.com/.+/ending" somefile.html   (note: i don't have a *nix machine in front of me right now to test this on.)  edit: fired up my linux box and found this to work:  grep -weo "https://sitename\.com/[^/]+/ending" somefile.html   a .+ will be greedy and capture way too much
run the script on its own
okay, i solved it myself
commands within your prompt command function alter pipestatus, bash saves and restores pipestatus (and $?) after your prompt command, see the description of the intended behaviour here
tl;dr  cat /sys/fs/cgroup/memory$(cat /proc/self/cgroup | grep memory | cut -d: -f3)/memory.limit_in_bytes   or  cat $(mount | grep cgroup | grep memory | cut -d' ' -f3)$(cat /proc/self/cgroup | grep memory | cut -d: -f3)/memory.limit_in_bytes   if your default container configuration allows host's cgroup info from within container (based on lxc.mount.auto setting),you could simply parse cgroup info as shown below  check your cgroup info from /proc/self/cgroup  root@my-firefox:/# grep memory /proc/self/cgroup  4:memory:/cv/my-firefox   now based on your cgroup mount point (could locate that from /proc/mounts), verify memory limit file content  root@my-firefox:/# cd /sys/fs/cgroup/memory/cv/my-firefox/ root@my-firefox:/sys/fs/cgroup/memory/cv/my-firefox# cat memory.limit_in_bytes  268435456   in my case above, cgroup root was mounted at /sys/fs/cgroup so with that info and appending path /memory/cv/my-firefox, i could query all memory limits set for the container  this case the limit is 256m  ps: free &amp; ansible_memtotal_mb are host based and they are not container aware
try grep -o with this minimal pattern:  grep -o '..././..' file  
if all the files you're searching in have the same encoding:  lc_ctype=ru_ru.koi8-r luit ack-grep "$(echo 'привет' | iconv -t koi8-r)" *.txt   or in bash or zsh  lc_ctype=ru_ru.koi8-r luit ack-grep "$(iconv -t koi8-r &lt;&lt;&lt;'привет')" *.txt   or start a child shell in the desired encoding:  $ lc_ctype=ru_ru.koi8-r luit $ ack-grep 'привет' *.txt $ exit   luit (shipped with xfree86 and x.org) runs the program specified on its command line in the locale specified by the lc_ctype setting, assuming an utf-8 terminal
make sure your bios is set to restart the system after a power failure.  turn off auto login unless you have a really good reason for it to be enabled
in command mode, run:  :%!column -t   but this does not align the first column
with gnu sed anhd grep, you can try:  sed -n "/$(date +%y%m%d)/,\$p" file | grep -c partitioned   /pattern/,$ matched first pattern to the end of file.  with your input:  $ sed -n "/$(date +%y%m%d)/,\$p" 1.txt | grep -c partitioned 1   without matching date:  $ sed -n "/$(date +%y%m%d)/,\$p" 1.txt | grep -c partitioned 0  
it looks to be in this config file, at least according to this su q&amp;a titled: get mplayer to start with a default volume other than 25%.   ~/.mplayer/config   to override the muted option you can press the numeric keys, 9 &amp;  0
the following should work for your needs:  #!/bin/bash convert -size 1000x706 xc:white img_0.jpg || { printf '%s\n' 'failed to create original image' ; exit 1 ; } for (( _num = 1 ; _num &lt; 1700 ; _num++ )); do    cp img_0.jpg "img_${_num}.jpg" || { printf '%s\n' "failed to copy to image img_${_num}.jpg" ; exit 2 ; } done   imagemagick creates the first image, and then it is copied to make up 1700 files
assuming your powertop is in /usr/sbin, you can use sudo /usr/sbin/powertop with no password
you can use if to check
executes current line and captures the output in the file replacing the line  :
openbsd is binary-centric. you can update the binaries (if any updates/changes are available) by executing pkg_add:  pkg_add -uu   the openbsd team recommends using the packages over building from ports - the openbsd packages and ports system  freebsd can be updated via packages or ports. 
since asking this question, i've adopted a different but much more effective solution: use tmux.  start a new named, detached session:  $ tmux new -d -s top   send a command to its zeroth window.  $ tmux send-keys -t top:0 "top" c-m   c-m is equivalent to hitting return
qemu-kvm was indeed merged into qemu, but that happened in version 1.3
you could do:  ..
it is  apt-cache policy package   between release and architecture. 
ideally, your sysadmin would have set up the network with a dns server, and that dns server would be dynamically updated with host names from dhcp
this is untested (since i don't use guis) but try this:  #!/bin/bash  # from this answer http://unix.stackexchange.com/a/29949/82289 ssh_host=me@mylab.myuniversity.edu ssh -f -n -d 12345 -m -s /tmp/ssh_tunnel_%h.sock -o exitonforwardfailure=yes $ssh_host &amp;&amp; \ echo "ssh tunnel started successfully" || \ echo "ssh tunnel failed to start"  # launch firefox firefox -p uniprofile -no-remote  # we should only get here after firefox closes # close the ssh tunnel socket ssh -s /tmp/ssh_tunnel_%h.sock -o exit $ssh_host # end shell-script   the 2 flags -f and -n are what i think you want (from man ssh).     -f      requests ssh to go to background just before command execution
the only reference i can find to the special parameter $_ in posix is in the rationale section on shell variables
just copy everything from /etc/skel/ to your home and change the owner to yourself.  there should be a .bashrc in it. 
the commands below will work for percentages above 50% (if you want to split only into two files), quick and dirty approach.  1) split 70% based on lines  split -l $[ $(wc -l filename|cut -d" " -f1) * 70 / 100 ] filename    2) split 70% based on bytes  split -b $[ $(wc -c filename|cut -d" " -f1) * 70 / 100 ] filename  
you can use the -w option:     -w, --where, --path, --location           don't actually display the manual pages, but do print the  loca‐           tion(s) of the source nroff files that would be formatted.   that returns almost what you asked for:  $ man -wk hairpin /usr/share/man/man1/nmcli.1.gz /usr/share/man/man8/ip-link.8.gz /usr/share/man/man8/bridge.8.gz /usr/share/man/man5/systemd.network.5.gz /usr/share/man/man5/nm-settings.5.gz /usr/share/man/man5/nm-settings-ifcfg-rh.5.gz /usr/share/man/man7/systemd.directives.7.gz   if that's not enough, you can parse it into shape:  $ man -wk hairpin | perl -pe 's#.*/([^/]+)\.(\d+)\.gz#$1($2)#' nmcli(1) ip-link(8) bridge(8) systemd.network(5) nm-settings(5) nm-settings-ifcfg-rh(5) systemd.directives(7)   finally, you could make that into a function
there are a few ways to output the user id (uid) with ps; a simple one is with -f:  ps -fc x   will give you information for all the x servers that are running (there can be more than one).  this presumes that the executable is called x -- if there's no such process, you will have to target something else
this is because man does not use the pager unless output is sent to a terminal
this requires vim to have x11 clipboard integration
--block-size is a parameter of rsync's delta transfer algorithm, i.e
i think you're looking for otfinfo
it means that it is a directory
an iso file is a complete, formatted filesystem image
just like the partition table on a whole disk records where the partitions end relative to the disk, the filesystem itself knows where it ends relative to the beginning of its partition.  it does not matter if there is garbage on a partition after the filesystem, apart from the wasted space on the medium
if lastdir is the only directory of that name in your directory hierarchy, you might get away with this in bash (although it may take a while to run)  shopt -s globstar cd **/lastdir  
set the environment variable debian_frontend=noninteractive.  for example:  export debian_frontend=noninteractive apt-get install -y libpq-dev   this will make apt-get select the default options. 
follow this how-to: getting iphone internet tethering working in linux (no jailbreaking involved!) 
it's possible but highly difficult to do this so that it's done correctly
for some reason,  the patch file has to be fed into the patch program by redirection, i.e.       patch file   does not work,  but      patch &lt; file   works 
sounds like you've got access to the server using putty (going over ssh)
create backup of first 446b on your disk (this is not all mbr - it has 512b), so when your disk is /dev/sda:  :~# dd if=/dev/sda of=/data/disk.img bs=446 count=1   and next remove (only erase bootloader without disk table):  :~# dd if=/dev/zero of=/dev/sda bs=446 count=1   if you revert:  :~# dd if=/data/disk.img of=/dev/sda bs=446 count=1  
you will need to play with the colours, but something like this should do the trick
you can do however you please, the only thing you must make sure is that the new serial number is greater than the old one.  having said that, i would recommend a timestamp based approach following a scheme like:   yyyymmddxx   where xx starts at 00 and is incremented for all edits on that specific day (when editing on another day, you reset xx to 00)  the main advantage of this scheme is, that you also know the date of the last modification of your zone-file at first glance.  it also makes the serial number incrementing more robust.  the alternative is to start with 1 and just increment whenever you edit the file.  if the serial number is already timestamp based (and 2015040500 looks very much like that), you shold probably stick with that decision (even if not made by you), and use the logical successor 2015042200 
if the name and wo are always consecutive, it's quite straightforward:  sed  '/frank;wo12345;/s/;$/;sometext/' -i file   if they can appear either way around, or not necessarily next to each other, use blocks of commands to combine the two tests:  sed  '/;frank;/{/;wo12345;/s/;$/;sometext/}' -i file  
   where is this information stored?   it's probably under /var/db/sudo or /var/run/sudo and you'll probably find directories of usernames with files under them ordered by tty number.  the actual privileges granted, including how long the sessions lasts before you have to enter your password again depends on how sudoers is setup
are you just looking for something looking busy? don't care about any productive output?   check out hollywood
i use both clonezilla and back in time to do system and data back-ups respectively
you could use sed with an appropriate pattern along the lines of s#([0-9]{2})\.([0-9]{2})\.([0-9]{4})#\3-\2-\1# this could be made more robust by matching the start of line anchor too if required
( isn't a special character in sed regular expressions
you can use eric hameleer's build from http://www.slackware.com/~alien/slackbuilds/wine 
you can use the lower level dmsetup command to direct the kernel device mapper to create a snapshot
yes, it's just an abbreviation for ipv4 link-local
you haven't used any wildcards, but have provided two arguments
try this:  find 
so i'm digging through old questions but hopefully this will still be of some use to you.  so if you want the absolute most up to date releases of those, your best bet is to get them directly from the projects themselves and build from sources.  if you are looking just looking to regularly make sure everything is up to date you might want to set a cron job that runs yum update nightly
if you know there is only 1 audio stream and that it is aac, then you only need this:     ffmpeg -acodec copy -i "movie.mp4" -y "audio.aac"   if you want to script the  first audio stream id and codec-type/file-extension, you can use this:    eval $(ffmpeg -i "movie.mp4" 2&gt;&amp;1 |awk '/stream.*audio/{print "stream=" $2 ";codec=" $4}' |head -n1) stream=${stream:1}; stream=${stream/:/} extn=${codec/,/}; [[ $extn == "aac" ]] ||      { echo "you need to manually set the fiie extension
write to /dev/kmsg (not /proc/kmsg as suggested by @nils)
you just need to put the location of the new binary in your path first
there is no
first, a nitpick: a string like a* in normal shell syntax is a glob, which works differently from regular expressions.  on a high-level overview, the shell interpreter (i.e
use exiftool instead:  exiftool -ext '' '-filename&lt;%f_${imagesize}.${filetype}' .   would rename all the images in the current directory (.). 
i didn't manage to get the synaptics.h header however i found the way to get the position (x y coordinates) of a finger on a touchpad.  the software is called evtest and the source code can be found here for example
the most standard way is to use __git_ps1 directly from git
to edit the list of insults, you will need to edit the source and recompile.  the insults are stored in plugins/sudoers/ins_*.h (4 files)
use ~/.screenrc on the server.  example:  split screen -t top top focus screen -t shell   where:  split — splits current window/region horizontally  focus — switch to next region  screen -t name [command] — set name for current window/region and run command 
there may be different mechanisms to handle these default settings
take a look at /var/lib/dpkg/info/tzdata.postinst, which i think is what is being run when dpkg-reconfigure tzdata is called.  note in particular the following command, which runs after /etc/timezone has been updated.  cp -f /usr/share/zoneinfo/$area/$zone /etc/localtime.dpkg-new &amp;&amp; \             mv -f /etc/localtime.dpkg-new /etc/localtime   so, the file /etc/localtime needs to be updated
turns out you have to edit the key bindings for the emacs-copy table
read this blog post: solving problems with proc  there are a few tips what you can do with the proc filesystem
you can just use keyboard shortcuts, available via main menu's search ..  just add a new item..
~/.lo-rcs/common/* matches all the non-hidden files in that directory, if there are no files in that directory or all of them are hidden, the pattern evaluates to itself resulting to your error message.  there is no good reason to make those files hidden
turns out postfix and sendmail were running at the same time
use magic sysrq key combinations
the one that gets output when you run which without -a is the one which will get executed
i'm sure there's a better way, i think this is all handled by udev now but if you know that those commands will solve it, you could always just make them into a script:  #!/usr/bin/env bash cvt 1600 1200 xrandr --newmode "1600x1200_60.00"  161.00  1600 1712 1880 2160  1200 1203 1207 1245 -hsync +vsync xrandr --addmode vga-1 1600x1200_60.00   make it executable and then add it to your desktop environment's startup applications
how about?  rm -i ?   i think this should work... 
download shelled eclipse plugin (update site didn't work for me) which allows editing bash scripts
try adding the switch --archlist=x86_64 to yumdownloader.  example  32-bit  $ yumdownloader --destdir=`pwd`/i686 --assumeyes \      --resolve parted --archlist=i686   64-bit  $ yumdownloader --destdir=`pwd`/x86_64 --assumeyes \      --resolve parted --archlist=x86_64   results:  $ tree  . |-- i686 |   |-- device-mapper-libs-1.02.63-2.fc14.i686.rpm |   |-- libblkid-2.18-4.8.fc14.i686.rpm |   |-- libsepol-2.0.41-3.fc14.i686.rpm |   `-- parted-2.3-5.fc14.i686.rpm `-- x86_64     |-- device-mapper-libs-1.02.63-2.fc14.i686.rpm     |-- libblkid-2.18-4.8.fc14.i686.rpm     |-- libsepol-2.0.41-3.fc14.i686.rpm     |-- parted-2.3-5.fc14.i686.rpm     `-- parted-2.3-5.fc14.x86_64.rpm  
 if ( $1 $2 in array ) doesn’t work; you have to do if (($1,$2) in array). you can’t use array[$3] and array[$4] like that.  your array looks likearray[chry,59363551]=“chry 59363551 g 8 0 7 0 0 0 1 0 5 0 0 0 0 0 0 0 7 0 0 0” array[chry,59363552]=“chry 59363552 g 7 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0”              ︙and when you say array[$3] and array[$4], you’re referring to array[g] and array[2], etc., which do not exist. the ability to specify &gt; "filename" in awk code is a great feature when you want to write to multiple files.  it’s not so useful when you have only one output file — why don’t you just redirect the output from the awk command? long lines are bad.  break long commands into short lines.  reduce duplication by reusing variables. don’t use an array called array.  that’s like having a variable called variable, a file called file, a person called person, etc.  use descriptive names.   ok, that said,  awk 'fnr==nr {file1data[$1,$2]=$0; next}         {       if (($1,$2) in file1data) {                         # save desired values from file2.                         file2arg03=$3                         file2arg04=$4                         file2arg08=$8                         file2arg10=$10                         file2arg12=$12                         pct_file2=($8+$10+$12)/$4                         # get data from file1.                         $0=file1data[$1,$2]                         pct_file1=($8+$10+$12)/$4                         print $1, $2, $3, $4, $8, $10, $12, pct_file1, \                                 file2arg03, file2arg04, file2arg08, file2arg10, file2arg12, \                                 pct_file2, pct_file1-pct_file2                 } else printf "(%s,%s) in file2 but not file1.%s", $1, $2, ors         }' treated.bam.tsv untreated.bam.tsv &gt; awkoutput.bam.tsv   like your version, this saves the file1 data in an array and then does all the work/output while it’s reading file2.  upon receiving a line from file2, it saves the desired fields from that line into named variables (we could also use another array, five elements long) and then it restores the data from the corresponding line in file1.  by assigning the entire line to $0, it causes $1, $2, $3, $4, etc., to be restored to their original values.  are you really having a problem writing a header line in the output?  try:          {       if (fnr == 1) {                         print "chrom pos ref reads_all mismatches deletions insertions pct_file1 …"                 } else if (($1,$2) in file1data ) {                         file2arg03=$3                               ︙     ok, here’s a version that’s closer in spirit to your attempt, and that handles the header line:  awk 'fnr==nr {file1line[$1,$2]=$0; next}         {       if (fnr == 1) {                         print "chrom pos ref reads_all mismatches deletions insertions pct_file1 ref reads_all mismatches deletions insertions pct_file2 pct_sub …"                 } else if (($1,$2) in file1line ) {                         # get data from file1.                         split(file1line[$1,$2], file1arg)                         pct_file1=(file1arg[8]+file1arg[10]+file1arg[12])/file1arg[4]                         pct_file2=($8+$10+$12)/$4                         print $1, $2, file1arg[3], file1arg[4], file1arg[8], \                                 file1arg[10], file1arg[12], pct_file1, \                                 $3, $4, $8, $10, $12, pct_file2, pct_file1-pct_file2                 } else printf "(%s,%s) in file2 but not file1.%s", $1, $2, ors         }' treated.bam.tsv untreated.bam.tsv &gt; awkoutput.bam.tsv   this retrieves the line from file1 (from file1line) and passes it to split to break it down into its constituent 23 values, which get stored in the array file1arg.  then it is able to use file1arg[3], file1arg[4], …, the way you were using array[$3], array[$4], … 
all key bindings:  for m ($keymaps) bindkey -lm $m   all zle user widgets  zle -ll   all zstyles:  zstyle -l   loaded modules:  zmodload -l   all variables:  typeset -p +h -m '*'   with the zsh/parameters module loaded, that will also include aliases, options, functions... 
this will give you proper answer of your trouble.     du -ch --max-depth=1 -x /var   -x will show only data usage of one file-system so skipping other filesystem's content from /var directory   --max-depth=1 will give data usage of only first level e.g
i usually use vim or gvim, eclipse, or intellij
the term 'normally' used in this context typically means that an executing process exits when having completed all its instructions successfully, without e.g
if you want to avoid clobbering any backup files with gnu cp, you can use numbered backups:  cp --backup=t  source destination   rather than overwrite a backup, this creates additional backups.  example  as an example, let's consider a directory with two files:  $ ls file1  file2   now, let's copy file1 over file2:  $ cp --backup=t file1 file2 $ ls file1  file2  file2.~1~   as we can see, a backup was made.  let's copy it again:  $ cp --backup=t file1 file2 $ ls file1  file2  file2.~1~  file2.~2~   another backup was made.  documentation  from man cp, just before the end of the "description" section, the various possible options for --backup are itemized:     the  backup  suffix  is  '~',  unless  set  with --suffix or   simple_backup_suffix
the bourne shell had a construct for that
you would need to use some command-line json parser, extract the specific value for each file by printing it and sort it by the printed value.  here is the example of the script which you can use:  ls -1 *.json | tr \\n \\0 | xargs -0 -l1 -i% sh -c "cat '%' | jshon -e view_count | awk '{print \$1\" %\"}'" | sort -k 1 -nr   where view_count is your json property name. the script will list the .json files and for each file will print the json view_count property value and numerically sort by the 1st column.  in this example, you need jshon tool which can be easily installed from the package manager
the term for that is "dirty" data (data that has been changed, but not yet flushed to permanent storage).  on linux you can find this from /proc/meminfo under dirty:  $ cat /proc/meminfo | grep dirty dirty:               0 kb  
if you are running lvm, or have the lvm tools installed, it will scan for lvm devices during the init sequence
you don't need to rename, copy..
systemd allows users to run their own systemd instances to manage private daemons.  if you already have systemd installed, all you have to do is launch systemd --user and manage your services by running systemctl --user
according to xmonad/key codes,     you can also search in /usr/include/x11/keysymdef.h and lower-case the first character (xk* becomes xk*)
telnet has two basic modes of operation: line mode and character mode
it is possible to combine two keybinds into one but a better way to express it would be to want to combine two actions under one keybind.  however, in the specific case i described, there is a problem
i would suggest that uzbl is just the right ninja magic for this
. is the relative reference for the current directory. .. is the relative reference for the parent directory.  this is why cd .. makes the parent directory the new working directory. 
according to the developer of retext, "qt supports cursor customization (via qstyle::pm_textcursorwidth), but unfortunately that's not exposed via qstylesheetstyle"
the groups command lists groups that the user is currently a member of, not all the groups available on the system
solution 1: sudo rules  add to your sudoers file (using visudo) the following rule:  &lt;user_name&gt; all=(root) nopasswd:&lt;path/to/your/script&gt;   replacing &lt;user_name&gt; to your non-root user login name and &lt;path/to/your/script&gt; with the absolute path to what you want to execute.  the same operation may be done by placing that rule inside a file under /etc/sudoers.d
apt-get installs and removes all dependencies automatically
i found the source code for dspcat.c: http://www.smart.net/~rlhamil/
sed 's,\([a-z]\)1\.gif$,\1.gif,g'   or, if you want to allow any non-digit before the 1  sed 's,\([^0-9]\)1\.gif$,\1.gif,g'   the backslash-parenthesis construct delimits a capture group, which the freebsd man page calls a “bracket expression” (despite the use of parentheses — square brackets mean something else)
you're executing the command sudo su - user2; whoami; pwd on the remote host
your question is difficult to answer precisely because you haven't said what path you're passing to the daemon and you haven't specified the permissions of ~agent
there is a "send later" add-on for thunderbird:     true "send later" functionality to schedule the time for sending an email.   i'm afraid this functionality isn't possible with evolution.  using the command line, you can use a combination of the at command along with some mta such as ssmtp, mailutils or postfix.  example with mailutils:  echo "test" | mail abc@def.com | at 7:30  
to determine where a file is hosted this is what i do:  cd /path/to/folder df -k .   the host name where the file is sourced from is at the beginning of second line
options are also taken from the less environment variable
$ man 2 read   ...  read(2)                    linux programmer's manual                   read(2)  name        read - read from a file descriptor  synopsis        #include &lt;unistd.h&gt;  ...  
you need first to upgrade bash with up2date bash command on each servers, then execute this script to test if all is ok
in bash, you can use the read function to request input from a user and store it in a variable
bash, ksh93, zsh, and other recent shells support process substitution (the &lt;(command) syntax), but it is a non-standard extension
according to this building vim page, you'll need these dependencies on ubuntu  sudo apt-get install libncurses5-dev libgnome2-dev libgnomeui-dev \    libgtk2.0-dev libatk1.0-dev libbonoboui2-dev \    libcairo2-dev libx11-dev libxpm-dev libxt-dev   run configure again.  ./configure --with-features=huge --enable-gui=gnome2 --enable-cscope   i've tried and all seemed to be enabled. 
if you want to fire off a background job, do some other stuff, then stop and wait for the background job to finish, you can do   nohup do_something & pid=$! ...more stuff... wait $pid   alternatively, you can test for the job having exited like this:   nohup do_something & pid=$! ...more stuff... ps -p $pid > /dev/null [ $? == 1 ] && echo "it's gone, buddy!"  
write the script, using the proper syntax:  #!/usr/bin/perl &lt;your code&gt;   put the file somewhere. make the script executable (chmod a+x yourscript.pl). then run the script using cron (with crontab, or writing a file in /etc/cron.d, /etc/cron.daily, /etc/cron.hourly, etc, depending on your needs). depending on your choice of cron, the call to the script varies. 
there is no way to specify the password to adduser on the command line
ls -l --block-size=m will give you a long format listing (needed to actually see the file size) and round file sizes up to the nearest mib.  if you want mb (10^6 bytes) rather than mib (2^20 bytes) units, use --block-size=mb instead.  if you don't want the m suffix attached to the file size, you can use something like --block-size=1m
the purpose of these files is to provide an easy means for other processes to communicate with them (e.g
i believe that jw013 answered the question in his comment:     i suppose some mutt dev long ago decided on this for the default   behavior
use this:  sed 's/|end|/\n/g' test.txt   what you attempted doesn't work because sed uses basic regular expressions, and your sed implementation has a \| operator meaning “or” (a common extension to bre), so what you wrote replaces (empty string or end or empty string) by a newline. 
apt-file will tell you (install it if you don't have it already):  $ apt-file search fontconfig/fontconfig.h libfontconfig1-dev: /usr/include/fontconfig/fontconfig.h   so  apt-get --reinstall install libfontconfig1-dev   should restore fontconfig/fontconfig.h. 
with a linux kernel, you can refer to /proc/[pid]/stat (defined in /usr/src/linux/fs/proc/array.c). it contains numerous fields, the 23rd is the virtual memory size in bytes (see man proc).  alternatively, you also have /proc/[pid]/statm which contains only values about memory (in pages), or, more human readable, /proc/[pid]/status.  all these informations are detailed in man proc.  use cat command to view these files. 
ln -f "$(readlink &lt;symlink&gt;)" &lt;symlink&gt;  
updated  solution for alias git.home, which operates with ~/.git.home as repo.  partially based on this answer.  add to ~/.bashrc:  alias git.home='git --git-dir=$home/.git.home/'  _completion_loader git eval "$(complete -p git | sed -r 's/(\s)git$/\1git.home/')"  eval "$(type __gitdir |    sed '1d;1,/if/s|if|if [[ "$comp_line" == "git.home "* ]]; then\necho "$home/.git.home"\nelif|')"     explanation of last eval (for other lines see answer):  we are patching the function __gitdir(), which returns a path to the git repo dir
it can be very tedious to chain it back manually
no, it's not possible
the debian installer should either ask you for the name-server's ip address, or auto-discover it via dhcp.  if your dhcp server doesn't provide the name-server ip then:   it's broken and should be fixed you can add it to /etc/resolv.conf yourself:  echo "nameserver 8.8.8.8" &gt; /etc/resolv.conf    you might want to cat /etc/resolv.conf to check its contents first.  if you have a local resolving name-server on your network (highly recommended) then use that rather than google's. 
once you have become root via su, do:  adduser orangepi sudo   if you don't have adduser on your system, try with usermod -a to append to the groups list:  usermod -a -g sudo orangepi   you might also want to investigate which groups your user is a member of by default, and add those back as well (such as the group named after your user, adm, etc.).  alternatively, you can use su -c:  su -c "adduser orangepi sudo"  
making a source package  my recommendation is to make a source package
your video card does not support vdpau but it does support xvmc, which is a precursor to vdpau
using gnu grep:  grep -w -f file2.txt file1.txt    this tells grep to match on only whole "words", and to get the list of patterns to search for from file2.txt  if there's any chance that the contents of file2.txt may appear in the remainder of lines in file1.txt, then you can use sed and bash's process substitution like so:  grep -f &lt;(sed -e 's/^/^/ ; s/$/\\b/' file2.txt) file1.txt   this uses sed to transform each idn line into ^idn\b before using it in grep -f. 
when detaching program, you should redirect both outputs somewhere (to /dev/null or to log file), and use:  &amp;&gt;/dev/null &amp;                         ...when bash --version &gt;= 4   or  &gt;/dev/null 2&gt;&amp;1 &amp;                     ...all shells   instead of just:  &amp;   ..
the easy way  the easy way is to boot from a live installation on a machine where both the old disk and the new disk are connected and copy the data wholesale with cat
qcow2 works in a grow-only manner, yet it is actually rather understandable
you should to try to rebuild the catalog file (b-tree) on the specified file system (which is hfs+) by specifying -r option for fsck, for example:  $ fsck.hfsplus -fryd /dev/sdd2   this option currently will only work if there is enough contiguous space on the specified file system for a new catalog file and if there is no damage to the leaf nodes in the existing catalog file (in other words, fsck is able to traverse each of the nodes in the requested btree successfully).  of course, do the backup (whole image disk dump) before performing any disk operations, if you don't want to risk of corrupting any data further more.  see more by running man fsck.hfsplus.  if this won't help, try using some other tools to repair your disk, e.g.:   testdisk by cgsecurity | mac, windows, linux (apt-get install testdisk) diskwarrior by alsoft (commercial) - bootable disk or mac app  
i3status  using i3status i believe you can change your configuration slightly so that it get's the cpu's core temperature directly from the /sys by providing a path to it's value
there's a simple way of extracting all chunks from a bar to a foo with sed:  sed -n '/bar/,/foo/p'   or with awk:  awk '/bar/, /foo/'   if you want to truncate the chunks, it's a little more complicated (in awk; in sed it's a lot more complicated)
it would vary by distro
it'd appear you're using a compression algorithm that has been patched in to the xbian kernel, but not the ubuntu kernel
you need to introduce a file for done of while such as :  done &lt; myfile.txt  
sed '/\n/p;//!s/_\.[^ ("]*text([^)]*)/\n&amp;\n/;d' files..
yes, there is a big difference
   xdg-open is a desktop-independent tool for configuring the default   applications of a user
you delete files with the rm command, e.g.:  rm /var/lib/pacman/db.lck   i hate to be "that guy", but if you don't know how to delete a file from the linux command line, arch is not the linux distribution for you
try:  find /var/myfolder -type f -delete   this gets all the regular files under /var/myfolder and deletes them leaving only the directories. 
oracle linux, which is the base of oracle vm is based on rhel 5.  another clone is centos 5
you want the range operator
for red hat/fedora:  $ yum install foo   for ubuntu ( run this as root ) :  # apt-get install foo  
okay, after joe pointed me the right direction in comments, this is how i did it:   basicly just install pacman -s linux-lts (optional) check if kernel, ramdisk and fallback are available in ls -lsha /boot remove the standard kernel pacman -r linux update the grub config grub-mkconfig -o /boot/grub/grub.cfg reboot   note, for syslinux you'll need to edit the syslinux config file in /boot/syslinux/syslinux.cfg accordingly, just point everything to the -lts kernel. 
it's not a typo
going by the instructions on the dm-cache github, to create a cache you need the kernel modules dm_mod and dm_cache loaded (assuming you already have a patched kernel) also you will need to access the dmsetup executable and presumably you want /dev to be populated so you can access the device on which you will create the cache.  as cjm already mentioned, to do this you will need to modify your initramfs, which is a file system that is loaded into memory before the hard disk is mounted.  luckily, dmsetup is already installed on the initramfs (this should always be the case, as it is needed for volume management; but to check use "lsinitramfs /initrd.img | grep dmsetup")  this leaves two things things which you will have to add to your initramfs: the two modules and the script to create the cache
i've asked on the mailing list and thomas petazzoni replied that the:  /etc/inittab   should contain:  console::respawn:/bin/sh   instead of:  console::respawn:/sbin/getty -n -l  console 0 vt100 # generic_serial   with qemu_x86_defconfig, the inittab is being used by busybox' init system, due to br2_init_busybox=y.  an easy way to get it working it to just edit package/busybox/inittab and replace the line:  # console::respawn:/sbin/getty -n -l  console 0 vt100 # generic_serial   but thomas said that this is not good practice (todo why) and that you should use br2_rootfs_overlay or a post build script instead. 
you have got to run it as root
try this with gnu sed:  sed -n '/^&lt;tr&gt;/p' file   or  sed '/^&lt;tr&gt;/!d' file  
this can be a way:  awk 'begin{fs=ofs=","}              # set input and output field separator as comma      {for (i=5; i&lt;=nf; i++) {       # loop from 5th field             gsub("\"","", $i);      # remove "             gsub(/^[ \t]+/,"", $i); # remove leading spaces             gsub(/[ \t]+$/,"",$i)}  # remove trailing spaces      }1' file   removing leading and trailing is based on this answer by bmw: remove leading and trailing space in field in awk.  test  $ awk 'begin{fs=ofs=","} {for (i=5; i&lt;=nf; i++) {gsub("\"","", $i); gsub(/^[ \t]+/,"", $i); gsub(/[ \t]+$/,"",$i)}}1' file 24,cosc,linux,"/vp/ame/ar/celts/cof",fbsutamante,fbu2012,kkk,&amp;^#$@j,,,,, 25,cosc,linux,"/vp/ame/ar/celts/cof",fbsutamante,fbu2012,iiii,*****,,,,,     if it also have to clean 1st to 3rd fields, just add if (i!=4) and loop through all the fields:  $ awk 'begin{fs=ofs=","} {for (i=1; i&lt;=nf; i++) {if (i!=4) {gsub("\"","", $i); gsub(/^[ \t]+/,"", $i); gsub(/[ \t]+$/,"",$i)}}}1' a 24,cosc,linux,"/vp/ame/ar/celts/cof",fbsutamante,fbu2012,kkk,&amp;^#$@j,,,,, 25,cosc,linux,"/vp/ame/ar/celts/cof",fbsutamante,fbu2012,iiii,*****,,,,,  
sshd is the daemon
just use pdfgrep directly:  pdfgrep -n therapy *.pdf   the -n option will display the page number of each match. 
ok, with help from this thread i got it working
if you launched sort in this same shell session before installing your symlink, bash has cached the path-search results
okay, i actually feel confident after doing some reading that using dd will do what you want
you can use wget (for windows) (or via cgywin) to download the site recursively,   $ wget -c \      --recursive \      --no-clobber \      --page-requisites \      --html-extension \      --convert-links \      --restrict-file-names=windows \      --domains vault.centos.org \      --no-parent \      http://vault.centos.org/5.4/os/i386/   the options are:  --recursive: download the entire web site. --domains vault.centos.org: don't follow links outside vault.centos.org. --no-parent: don't follow links outside the directory tutorials/html/. --page-requisites: get all the elements that compose the page (images, css and so on). --html-extension: save files with the .html extension. --convert-links: convert links so that they work locally, off-line. --restrict-file-names=windows: modify filenames so that they will work in windows as well. --no-clobber: don't overwrite any existing files (used in case the download is interrupted and resumed).  
both perl and python (and probably ruby as well) have simple kits that you can use to quickly build simple http proxies.  in perl, use http::proxy
(sorry to spam you) using a xml parser in perl   (if ncessary: sudo cpan xml::dt)  #!/usr/bin/perl use xml::dt; my $file = shift;  # $c - contents after child processing  print dt(    $file,    'unique' =&gt; sub{$c =~ s/^(\d{1,9}-\d+|\d+-\d{1,8})$/fixme:$1/; toxml }, )   in this case you get a xml anotated with "fixme"s 
printf '%s\n' {♠,♣,♢,♡}$'\t'{{2..10},j,k,q,a} | shuf -n5 |   gawk 'begin{ split(",twos,threes,fours,fives,sixes,sevens,eights,nines,tens",vt,","); vt["j"]="jacks"; vt["q"]="queens"; vt["k"]="kings"; vt["a"]="aces"; } # values-text         { c[$2]++; printf("%s %s", $1, $2(nr==5?"\n":"\t")) }         end{ for(i in c){                  if( c[i]==2 ){ print "pair:  " vt[i]; cp++ }                    if( c[i]==3 ){ print "three: " vt[i]; ct++ }                  if( c[i]==4 ){ print "four:  " vt[i] } }              if( cp==2  ) { print "two pairs" }              if( cp&amp;&amp;ct ) { print "full house" } }'   example output:     ♡ q    ♣ a    ♢ a    ♢ q    ♡ 2  pair:  aces pair:  queens two pairs   here is the same thing done entirely by awk, except for the method of seeding awk's rand(), by using bash's $random passed to awk via the -v option
find ./path/to/your/drive -type f -name '*.jpg' -exec du -ch {} +   or much faster  find /path/to/your/drive -name "*.jpg" -print0 | du -ch --files0-from=-   or simply,  du -ch /path/to/your/drive/*.jpg | grep total   or with help of awk,  find /path/to/your/drive -iname "*.jpg" -ls | awk '{total += $7} end {print total}'   on my system file size shows on seventh field, if it's different for you then adjust accordingly.  as requested by op in comment, if you want to find all images from a directory and total size you can use this command (suggested by @stéphane chazelas)   find 
netstat doesn't accept an ip address argument
   what can i do on group level to make sure nginx will read those files?   it doesn't sound like there would be any particular issue with putting the nginx user into the developers group:  as root:  usermod -a -g developers nginx   a user can be in multiple groups
that there was no proper read/write ntfs support before ntfs-3g
if you would have taken the time and read the grep manual, you would have found the l option  -l, --files-with-matches        suppress normal output; instead print the name of each input file from which  output would normally        have been printed
#!/bin/sh  file="$1" outfile=${file%.flac}.mp3  eval $(metaflac --export-tags-to - "$file" | sed "s/=\(.*\)/='\1'/")  flac -cd "$file" | lame --preset fast extreme \         --add-id3v2 --tt "$title" --ta "$artist" --tl "$album" \         --ty "$date" --tn "$tracknumber" --tg "$genre" \         - "$outfile"  
it's a feature of the gnu linker ld
you should read the dmesg values "memory akb/bkb available" as:     there is a available for use right now, and the system's highest page frame number multiplied by the page size is b.   this is from arch/x86/mm/init_64.c:  printk(kern_info "memory: %luk/%luk available (%ldk kernel code, "                  "%ldk absent, %ldk reserved, %ldk data, %ldk init)\n",                  nr_free_pages() &lt;&lt; (page_shift-10),                  max_pfn &lt;&lt; (page_shift-10),                  codesize &gt;&gt; 10,                  absent_pages &lt;&lt; (page_shift-10),                  reservedpages &lt;&lt; (page_shift-10),                  datasize &gt;&gt; 10,                  initsize &gt;&gt; 10);   nr_free_pages() returns the amount of physical memory, managed by the kernel, that is not currently in use
one approach that would work is just appending to the end of the bashrc rather than syncing it.  echo "path=\$path:~/bin" &gt;&gt; ~/.bashrc   this will add ~/bin onto the path variable
if you are the only user of it, just slap it in /home
in case you're referring linux virtual consoles as ttys, their number by default is 64 and this is defined in include/uapi/linux/vt.h inside the linux kernel source tree
this happens because your command substitution for ls outputs whitespace, and it ultimately undergoes word splitting before being passed to [
given what dumpe2fs is reporting, it must be the case that blkid is wrong and the others are correct
sigkill pulls the rug out from your running process, terminating it immediately
you can of course add projectrootdirectory to your $path, but this has at least two drawbacks:   it looks like, the way you are describing it, this particular project does not organize its project nicely into bin and lib subdirectories like so:  projectrootdirectory ├ bin │ └ programbinary └ lib   ├ somelibrary   └ somelibrary2   therefore you'd be forced to put projectrootdirectory itself into the $path, and since that contains other things besides binaries intended for execution, it's a bit ugly. if you have many similar projects, the contents of your $path will proliferate out of control.   instead, the simplest thing you can probably do in this particular case is to place a wrapper executable in /usr/local/bin, which is a very simple shell script that just runs the "real" program from the location where it lives.  #!/bin/sh exec projectrootdirectory/programbinary "$@"   since the wrapper script is calling it with its full pathname, it will probably be able to locate its auxiliary files in the manner it normally does. 
you can't move a file, and edit it at the same time, since moving a file doesn't physically move the data (on the same filesystem), it just moves a pointer to the data
find file modified within x minute under /path  find /path -cmin -x  sign before minute:     + more than x minutes / over x minutes     - less than x minutes / within x minutes    (no sign) exact   example: find all files in /var/log (including sub-dir) modified within last 30min  find /var/log -cmin -30   find file with size bigger x under /path  find /path -size +x&lt;unit&gt;  sign before size:     + larger than     - less than    (no sign) exact  &lt;unit&gt; :     b = block (default,512byte)     c = byte     w = word (2-byte)     k = kbyte     m = mbyte     g = gbyte   example: find all files in /var/log (including sub-dir) bigger than 50k  find /var/log -size +50k   combine  example: find all files in /var/log (including sub-dir) bigger than 50k modified within last 30min  find /var/log -cmin -30 -size +50k   if you want to include 50k in your result, change to  find /var/log -cmin -30 -size +49k   ps: avoid doing find / ..... as not only it will take a long time, it also include directories(/dev, /sys, /proc, ...) generally not suitable for search. 
if you can't get ls to sort the way you want, try shell expansion.  you can use file name patterns to run ls with a list of files that the shell already sorted, bypassing the method that ls uses.  ls -lf _* [!_]*   assuming you have the files  _a a _b b _c c   this is like running  ls -lf _a _b _c a b c   explanation:  _* is a shell pattern matching any file name beginning with an underscore, expanded in alphabetic order.  [!_]* matches any file name not beginning with an underscore, expanded in alphabetic order.  -f tells ls to not sort, because the shell already did.  more information: bash filename expansion  if there are directories in the current directory you will want to run the command like this to avoid ls listing files in the directories:  ls -lfd _* [!_]*  
yes, you can
the shell command to change key bindings is bindkey, backspace presumably sends byte 127 (^?; check by typing ctrl+v then backspace), and the edition command to delete a character backwards is backward-delete-char
as mentioned on lwn, the easiest is:  git describe --contains f3a1ef9cee4812e2d08c855eb373f0d83433e34c   if you don't want a local clone, gitweb's "plain" formatted commit contains the same info in the x-git-tag header
a version in perl, using negative lookaheads:  $ perl -0pe 's/\n(?!([0-9]{8}|$))//g' test.txt 20141101 server contain dump 20141101 server contain nothing    {uekdmsam ikdas jwdjamc ksadkek} ssfjddkc * kdlsdlsddsfd jfkdfk 20141101 server contain dump   -0 allows the regex to be matched across the entire file, and \n(?!([0-9]{8}|$)) is a negative lookahead, meaning a newline not followed by 8 digits, or end of the line (which, with -0, will be the end of the file). 
can't think of any kind of simple way to do this
bc natively do not support adding zero.  workaround is:     echo 'scale=4; 1/3' | bc -l | awk '{printf "%.4f\n", $0}'      0.3333   "\n" - add a new line.  "%f" - floating point  "%.4f" - the number of digits to show after the decimal point
you can use getent, which comes with glibc (so you almost certainly have it on linux)
just put your command in /etc/rc.local
youtube and google are served via a cdn, and having the dns names they use map to many different ip addresses is normal and expected.  if you want to make sure that queries are actually going through dnscrypt, temporarily stop it:  # pkill -stop dnscrypt-proxy   and see if you still get responses to new dns queries
oh-my-zsh enable two things, which cause this behavior:   auto_cd: if command can not execute, and command is a directory name, perform cd to that directory cdable_vars: if the argument to a cd command (or an implied cd with the auto_cd option set) is not a directory, and does not begin with a slash, try to expand the expression as if it were preceded by a ~   in your case, when typing home, auto_cd made zsh performed cd home, cdable_vars made zsh performed cd ~home, ~home was expanded to your home directory.  you can call zsh with --xtrace option to see what happened:  $ zsh --xtrace $ home ... +zsh:1&gt; cd /home/cuonglm ~ ....  
typically shebang refers to just the #! (! is typically called "bang", and it looks like "she" is a corruption of either "sharp" or "hash" for #) -- the whole line is called a shebang line  it does intentionally start with a comment character for backwards-compatibility with things that don't know how to handle it; the ! is presumably just to distinguish it from a random comment starting the file, so a file that begins with # this is my script! doesn't try to run the this is my script! interpreter 
systemd-detect-virt can tell you whether your system is running in a vm/container
the most common issue is to forget to properly set permissions:  chmod -r 600 ~/.ssh  
you have forgot to put ; between if and then:  if [ "$uid" -ne 0 ]; then     echo "non-root user." else     echo "root user." fi   also the if conditional construct ends with fi, not fi.  ; is basically a shorthand for newline
correct me if i'm wrong, but you seem to be wanting to run regular shell commands on the remote server where the script is local.  #!/bin/sh trap "rm -f /tmp/sendonssh.$$.*" 0 1 2 3 15 # commands to run on the remote server cat &lt;&lt;'eof' &gt;&gt; /tmp/sendonssh.$$.sh mkdir -p /tmp/foobar.$$ mv $home/xyzzy /tmp/foobar.$$ chmod 640 $home/xyzzy eof # call for each argument for userhost in "$@"; do     errorout=`ssh -atxo batchmode=yes $userhost /bin/sh -s &lt; /tmp/sendonssh.$$.sh 2&gt;&amp;1`     rc=$?     if [ $rc -ne 0 ]; then         echo "error: $userhost: $errorout"         exit $rc     fi done   i do this with some 'remote execution' apps in my test environment using python instead of the shell: ssh $userhost python &lt; $pythonscriptfilename. 
you cannot chroot into different architecture. by chrooting, you are executing the binaries (from the chroot) on your architecture
grub is a piece of software that is installed in the mbr.  delete sda5 and run grub-update or change grub config manually to boot from sda1, maybe this howto can help you.  http://www.techsupportforum.com/357-how-to-configure-grub-bootloader-in-mint-linuxubuntu/  if grub is installed on sda u can change the grub config to boot from sda1. if not try to install grub on sda.  $sudo grub-install /dev/sda $sudo update-grub   if grub-install gives problems, you can install manually from the grub shell with:   grub root (hd0,0) setup (hd0) quit  
 cd $(dirname $(which go))   which go will show the path of the executable
you can use paste for this:  paste -d '\0' aaaa.txt bbbb.txt &gt; cccc.txt   from your question, it appears that the first file contains ; at the end
maybe something like:  if sudo -hu "$user" xdpyinfo -display "$display" &gt; /dev/null 2&gt;&amp;1; then   echo "user $user can connect to display $display" else   echo "user $user cannot connect to display $display" fi  
grepping around in /etc turned up a link that googling did not
so, i've discovered that the wp.com [sourcecode language="xxx"] tags work with markdown/vimrepress with a caveat - dont have any empty lines in the code
bug in the implementation of ext4 feature dir_index which you are using on your destination filesystem.  solution : recreate filesytem without dir_index
if you are unable to find the file with the below command then try updatedb  locate -r foot/bar/   or   # locate  "/*/bar/avi" /foot/bar/avi   find command can also do this   find / -path */foot/bar*    find /  will search the whole system starting from /  
i found the answer here: tty (console): disable monitor.  the command line utility vbetool can be used to turn the monitor on or off: vbetool dpms off 
/lib/modules/$(uname -r)/source should be a symbolic link to the kernel source tree (if it was installed in a reasonable way).  other than that  find / -type d -name "linux-3.14.0"   will look for the distribution directory of the 3.14.0 linux kernel - that is the one you get when you unpack the tarball
you should put two arguments in quote or double quote:  % ./ppa.sh -i 'ppa:chris-lea/node.js nodejs' received -i with ppa:chris-lea/node.js nodejs  
try:  awk '{a[$1] += $2}; end{for(c in a) print c, a[c]}' &lt;file  
you're seeing output to the terminal while it is not in nlcr mode (stty -onlcr).  normally the kernel driver for ttys outputs a carriage return along with a newline whenever a newline is output
you can back up a vps the same way you would any other server.  on the basic i would recommend copying your important files to another server, or an external hdd
you could simply do a 'rsync' from the old disk to the new disk
you can check the source for freebsd out of version control here
which python only tells you the executable that would be run with the command python, i.e
as i said in comments, gksu and gksudo were considered hacks and are now deprecated
the syntax for lookarounds in vim is different from the pcre syntax that you appear to have assumed
you need to modify your ~/.screenrc if you don't have one you can copy it with:  cp /etc/screenrc ~/.screenrc   and then add the following line.  caption always "%{rw} * | %h * $logname | %{bw}%c %d | %{-}%-lw%{rw}%50&gt;%{rw}%n%f* %t %{-}%+lw%&lt;"   you can change the caption to your personal needs. therefor you should read the gnu screen manual especially the string escape chapter.  an alternative to gnu screen is byobu, it is an already configured screen, may be you should take a look at it, if you want gnu screen
drivers are maintained in-kernel so when a kernel change requires a global search-and-replace (or search-and-hand-modify) for all users of a function, it gets done by the person making the change
you use apache environment variable manipulation.  so for example:  setenv db_pass swordfish   this can be done in httpd.conf or in .htaccess
your shell's history is saved in the file indicated by the histfile variable
apt-file  apt-file provides the feature of searching for a package providing a binary (like debian or ubuntu), it is not installed by default but in the repositories.  apt-file search &lt;path-to-file&gt;   you may want to update once before searching...  apt-file update    for example, let's search for the not installed binary mysqldump:  $ apt-file search /usr/bin/mysqldump  mysql-client-5.1: /usr/bin/mysqldump mysql-client-5.1: /usr/bin/mysqldumpslow mysql-cluster-client-5.1: /usr/bin/mysqldump mysql-cluster-client-5.1: /usr/bin/mysqldumpslow   it's also possible to list the contents of a (not-installed) package:  $ apt-file list mysql-client-5.1  mysql-client-5.1: /usr/bin/innochecksum mysql-client-5.1: /usr/bin/innotop mysql-client-5.1: /usr/bin/myisam_ftdump mysql-client-5.1: /usr/bin/mysql_client_test ...   yum  yum accepts the command whatprovides (or provides) to search for installed or not installed binaries:  yum whatprovides &lt;path-to-file&gt;   again, the not installed mysqldump:  $ yum whatprovides /usr/bin/mysqldump  mysql-5.1.51-2.fc14.i686 : mysql client programs and shared libraries repo        : fedora matched from:  filename    : /usr/bin/mysqldump  mysql-5.1.51-1.fc14.i686 : mysql client programs and shared libraries repo        : fedora matched from:  filename    : /usr/bin/mysqldump   zypper  zypper's search command can check file lists when used with the -f option.  zypper se -f /bin/mksh loading repository data... reading installed packages...  s | name | summary           | type    --+------+-------------------+--------   | mksh | mirbsd korn shell | package   webpin provides a webbased solution, there is even a script for the command-line.  pkgfile  available as pkgtools for pacman based systems
the output of the clear command is console escape codes
if you don't want to be challenged every time for your password then i'd recommend setting it to nopasswd in your /etc/sudoers file rather than hardcode your password in your logins
add a default case:  case $price in [0-9] | "." | "$") true             ;; *)     do-something    ;; esac  
emdebian stopped being maintained in november 2014
nope, it's impossible.    manually modify the source code would work for you, but you could submit a bug report for it. (e.g make this configurable through xfce4-settings) 
my guess would rather be that your camera uses a thumbnail which may be embedded in the jpeg file - no scanning through the image and interpreting it, just looking at a very little blob containing the thumbnail
posted the bug to buildroot bugzilla
 iselect provides an up-down list, (as input from a prior pipe), in which the user can tag multiple entries, (as output to the next pipe):  # show some available executables ending in '*sh*' to run through `whatis` find /bin /sbin /usr/bin -maxdepth 1 -type f -executable -name '*sh'   | \ iselect -t "select some executables to run 'whatis' on..." -a -m | \ xargs -d '\n' -r whatis    output (after tagging a few on my system):  dash (1)             - command interpreter (shell) ssh (1)              - openssh ssh client (remote login program) mosh (1)             - mobile shell with roaming and intelligent local echo yash (1)             - a posix-compliant command line shell  vipe allows interactively editing (with one's favorite text editor) what goes through a pipe
i believe mailutils doesn't support the -r option
 system settings > system > system info (or details on some distros)
just:  # echo "&lt;newuser&gt;  all=(all) all" &gt;&gt; /etc/sudoers   cf: https://www.debian.org/doc/manuals/debian-reference/ch01.en.html#_sudo_configuration  and personnaly i would use:  # tee -a "&lt;newuser&gt;  all=(all) all" &gt;&gt; /etc/sudoers   tee -a present the advantage of merge stuff to the existant without removing the old stuff 
from the command line you can run  aptitude why bar   this seems to do whatever it takes to provide an answer, meaning it will never tell you "explicitly installed" and will instead find a recommends or suggests that the package fulfills. 
the filesystem hierarchy standard says, per /usr/local : local hierarchy, that      the /usr/local hierarchy is for use by the system administrator when   installing software locally
i found this thread on lkml that answers your question a little
the simplest way to do this is to use do the following 3 steps:   stop all the containers remove all the containers remove all the images   to achieve this you can make use of the docker ps and docker images commands abilities to just return you a list of ids via there -q or --quiet switch
if you have -- or can install -- the imagemagick package, it has an identify utility that can print out a histogram of the colors in the file; the awk program below will scan the identify -verbose output for the number of colors and the colors listed in the histogram
sounds like puppy linux could do the trick
the favourite in gnome classic view follows the favourites in the gnome 3 shell.  click on activities in the top-left corner or use your keyboard's windows button if it has one, to bring up the activities overview
the following worked for me.  to ~/.bashrc, add the line:  ps1='$([ -n "$tmux" ] &amp;&amp; tmux setenv tmuxpwd_$(tmux display -p "#i") $pwd)\u@\h:\w$ '   and to ~/.tmux.conf, add the lines:  bind-key c run-shell 'tmux neww "cd $(tmux display -p "\$tmuxpwd_#i"); exec bash"' bind-key % run-shell 'tmux splitw -h "cd $(tmux display -p "\$tmuxpwd_#i"); exec bash"' bind-key '"' run-shell 'tmux splitw -v "cd $(tmux display -p "\$tmuxpwd_#i"); exec bash"'   restart tmux.  sources  see the section, "how can i open a new window in the same directory as the current window?" at http://tmux.svn.sourceforge.net/viewvc/tmux/trunk/faq
(replace-string "o" "ô") replaces the next occurrence of o after the cursor¹, except in transient mark mode with an active mark in which case it replaces the first occurrence in the marked region.  this works to replace the character after the cursor, but of course if that isn't an o then it could replace a character further
i don't know how this task is managed in cinnamon, but if you are using synaptics touchpad then you should install xf86-input-synaptics driver and then run syndaemon program
from red hat magazine: introducing networkmanager :     words with the creator      networkmanager creator and developer dan williams took time out of his hectically busy schedule to answer some questions
if your command works, simply put it in $home/.bashrc if you are using a bash shell.  $home will be /root for root, /home/xyz for user xyz, etc. for ls command, you can create an alias like so (again, in bashrc):      alias ls='ls --color=auto'  you can always source the .bashrc file too in your current shell if you, for some reason, do not want to spawn a new one. 
perl -ne 'print unless $seen{$_}++' data.txt   or, if you must have a useless use of cat:  cat data.txt | perl -ne 'print unless $seen{$_}++'   here's an awk translation, for systems that lack perl:  awk '!seen[$0]++' data.txt cat data.txt | awk '!seen[$0]++'  
centos has an answer on their faq page about it, it is for compatibility with 32 bit stuff
short answer: yes, ssh can do this
apparently you are following a guide written for debian based distributions, give a try to a guide for rhel based distros, eg.: http://distributedbytes.timojo.com/2015/05/how-to-install-neo4j-server-on.html  note: i've not tested it 
try: sed -i 's/aprefix.*asuffix/mynewword/g' testfile
very simple:  for i in *; do   echo "&lt;$i&gt;" done   this uses bash's file globbing
yes, you do see the recommendation for -u often, usually paired with -z
i believe what you're trying to accomplish is probably best (and afaik only) possible combining multiple commands as you're currently doing
use cpio, not tar for this
restorecon doesn't handle symbolic links just the way it handles files
first of all, to find what a command's options do, you can use man command
you might use rsync -u which provides the same functionality
several methods for detecting the virtualization technology are listed on http://www.dmo.ca/blog/detecting-virtualization-on-linux/
looking at the source code of gnu patch, this behavior is built in since version 2.7
i have solved it, it was not straight forward but after a analyzing the script that runs that service of pure-ftpd, i figure that the script    /etc/init.d/pure-ftpd   starts another script called    pure-ftpd-wrapper   looking at this script it apprears to read some configuration values from disk, then searching for manpage of pure-ftpd-wrapper took me to page pure-ftpd-wrapper manpage here we can see that configs are palace in directory     /etc/pure-ftpd/conf   here in this directory there is one file for each parameter of the executable so all i had to do was create a file by the name of     passiveportrange   in the conf directory and then put my port numbers seperated by space in there    echo "50000 50100" &gt; /etc/pure-ftpd/conf/passiveportrange   after this change service must be restarted for the changes to take effect    sudo service pure-ftpd restart   done! now you can access your ftp service even if it is behind a nat/firewall assuming you have done port forwarding for port 21 and the above range of ips and use passive mode in the ftp client. 
i advise you to use other method to test for sslv2
this is a bug in older versions of bash, fixed in bash 4.1 alpha
packets can be in various states when using stateful packet inspection.   new: the packet is not part of any known flow or socket and the tcp flags have the syn bit on. established: the packet matches a flow or socket tracked by conntrack and has any tcp flags
context:  assuming from above comments that a bsdish libc is meant.  i think it's been looked into, but libc tends to be tightly tied to a given kernel (glibc has an abstraction layer, which allows it some portability but causes the usual problems that an abstraction layer causes) and making bsd libc work with a linux kernel would require a near complete rewrite
to logout from unix or linux you can either:   type exit and press [enter] on a command line where you haven't typed anything press [ctrl]-d   to log out. 
after downloading it when i run the ./configure command it complained about 2 libraries missing:  checking for xcreatewindow in -lx11..
try to add this to [media] section:  public = no hide unreadable = yes printable = no force create mode = 0664 force group = xbmc write list = xbmc directory mask = 0775   do you authenticate to samba share as user xbmc under macos? 
looks like you have been using both dag and nux repos
everything you need should be covered in the arch linux wiki article titled fan speed control.  excerpt     once sensors is properly configured, run pwmconfig to test and configure speed control
copy the files using the install command
sed processes its input line by line, so a newline character will never spontaneously appear in the input
you can chroot the software into a bind mount setup where these directories are mounted read-only.  mkdir /foo mount --bind / /foo mount --rbind /dev /foo/dev mount --bind /proc /foo/proc mount --bind /run /foo/run mount -t tmpfs tmpfs /foo/tmp mount --bind /sys /foo/sys mount --bind /usr/bin /foo/usr/bin mount -o remount,ro /foo/usr/bin chroot /foo rpm …   note that hostile processes running as root can escape a chroot, so this is not a secure confinement, only a way to ensure that a non-malicious process isn't writing where it isn't supposed to.  an alternative approach would be to set up selinux rules
with gnu awk:  begin { fname = "/dev/null" } /&lt;header&gt;/,/&lt;\/header&gt;/ { hdr = hdr $0 "\n"; next } /^&lt;event / {     events++     if(events % 10000 == 1) {         if(files++) close(fname)         fname = sprintf("file%02d.txt", files)         print hdr &gt;fname     }         }             { print &gt;&gt;fname }   to run it: write it to a file script.awk, then run:  gawk -f script.awk file.txt  
you can use something like getid3 to analyze a media file for various information
after trying a lot of things, i found the solution:  if i want to mount /home/user on a usb drive and keep all the files there after ejecting it, i have to first mount the usb drive like:  mount -o uid=user /dev/sdb1 /hometemp    then, i have to mount the directory /hometemp on home/user like this:  mount --bind /hometemp /home/user   it works for me 
acpi_osi= causes linux to disable the acpi operating system identification function (_osi) when executing acpi code provided by the mainboard.  your laptop probably checks for specific windows versions to switch between different modes of how the brightness hotkeys are reported to the os
i have found the answer:  my problem was that bind can't rndc reload zone with the dynamic zones so bind won’t allow us to reload a dynamic zone
you can observe what the process does with the strace command
when i get stuck like this i'll often use strace to fish for clues.  here's a handy one-liner to do it  ps -ef |grep apache |grep -v grep |awk '{print $2}' | while read pid ; do sudo strace -p$pid -o /tmp/strace.$pid &amp; done   it gets all the apache pids, and attaches a strace to each of them, writing their output each to a different file in /tmp/  once you've done that, reproduce the error, then kill all the strace processes:   sudo killall strace   look for the biggest file(s) generated by strace, they will likely be the strace of the apache process(es) in question:  ls -lsrh /tmp/strace.*   see if there are any clues in there (lines that contain eno or err are especially of interest). 
the newer kernel versions use a new numbering
i resolved this by installing the autocutsel rpm from the software management section of yast, and then running:  $ autocutsel -s primary -fork   this enabled copy/paste between my vnc and my windows clipboard.  thanks to this source. 
you need to keep asking for a response until it isn't one you want:  while true; do     read -r -p "yes or no? " response        if [[ $response =~ ^([yy][ee][ss]|[yy])$ ]]     then         echo "you chose yes"     else         exit 0     fi done  
if i understand you correctly this is what you want to do:  find 
i'm not sure (it has been a while) but it looks to me that is a reference to the old linux routine (1992): ftp://ftp2.de.freebsd.org/pub/linux/tsx-11/sources/usr.bin/doshell.c:  #include &lt;stdio.h&gt; #include &lt;sys/file.h&gt; #include &lt;errno.h&gt;  extern char *sys_errlist[];  main(int argc, char *argv[]) {      if (argc != 3) {     fprintf(stderr, "usage: doshell &lt;ttyname&gt; &lt;shellname&gt; &amp;\n");     exit(1);     }      /* close down fd's */     close(0);     close(1);     close(2);      /* detach from parent process's group */     setsid();      /* open new tty */     if (open(argv[1], o_rdwr, 0) == -1)     exit(2);     dup(0);     dup(0);     execlp(argv[2], "-", 0);     /* should appear on new tty...: */     fprintf(stderr, "can't exec shell: %s\n", sys_errlist[errno]);     exit(3); }   it might also refer to the older minux routine: http://users.sosdg.org/~qiyong/mxr/source/commands/mail/mail.c#l702  void doshell(command) char *command; {   int waitstat, pid;   char *shell;    if (null == (shell = getenv("shell"))) shell = shell;    if ((pid = fork()) &lt; 0) {         perror("mail: couldn't fork");         return;   } else if (pid != 0) {        /* parent */         wait(&amp;waitstat);         return;   }    /* child */   setgid(getgid());   setuid(getuid());   umask(oldmask);    execl(shell, shell, "-c", command, (char *) null);   fprintf(stderr, "can't exec shell\n");   exit(127); }    both routines seem to have the functionality as described in the stackoverflow answer, and it doesn't seem unlikely the first derived from the second. 
when you change a file's metadata (permissions, ownership, timestamps, …), you aren't changing the directory, you're changing the file's inode
first write a little script to flush the iptables rules:  #!/bin/bash echo "stopping firewall and allowing everyone..." iptables -f iptables -x iptables -t nat -f iptables -t nat -x iptables -t mangle -f iptables -t mangle -x iptables -p input accept iptables -p forward accept iptables -p output accept   (you probably don't need the 'nat' and 'mangle' commands.) call it 'flush.sh' and put the script in the '/root' directory
recent versions of ghostscript include a pcl interpreter, and can work with the full range of ghostscript output formats including pdf, ps, image formats like tiff and jpeg, and all their known printers
the problem is ill-defined
it's called vim-powerline or powerline
press ctrl+d to exit out of the password prompt
the command  apt-get install -t wheezy-backports git-svn   should install git-svn.  see the notes for the -t flag in man apt-get:    -t, --target-release, --default-release  this option controls the default input to the policy engine;   it creates a default pin at priority 990 using the specified  release string
actually, the pages for the debian r-base package (for example) are here:   jessie, r version 3.1.1-1 jessie backports, r version 3.3.1-1~bpo8 stretch, r version 3.3.1-1   add the "jessie backports" to your sources.list, and you can upgrade to r version 3.3.1, at least, with just apt. 
basically you don't add, you change home directory.  usermod -d /home/ftp/root root   if you want to move existing files, use this:  usermod -d /home/ftp/root -m root   allowing root to access via ftp it not good practice, it's security hole.  even if this, i would rather recommend to create symlink to target folder from existing directory. 
there are numerous ways to do that, including the following:  sed -e '/^[:space:]*$/d' -e 's/$/.txt/' filenames.txt | xargs -d '\n' touch   this assumes that there is only one filename per line in filenames.txt
you could use logger with the -p switch to set your port to 5514.  check man logger for other suitable switches, eg -t.  echo "access denied" | logger -t myservice -p 5514   to check if port 5514 is currently associated with logstash, lsof -i :5514, or check logstash startup logs (meta!)
i ended up looking at three possible solutions, all in perl.  all three use text::csv as a base, to read in the csv.  before i settled on a prepared table package, i just tried doing it manually
this is highly platform-dependent
when you run the command:  grep -r &lt;pattern&gt; &lt;directory&gt;   it prints all the filenames as &lt;directory&gt;/&lt;filename&gt;
you can source any file you like, it doesn't have to be .zshrc
version 220-7 on debian dropped the patch that made this opt-in:  * switch to net.ifnames persistent network interfaces (on new   installations/for new hardware), and deprecate the old   75-persistent-net-generator.rules.   this came about from a proposal in debian-devel list
unzip accepts wildcards and globs
no, you can't use dd and have any semblance of safety for your data.  if you're running oracle solaris, then you can use the 'zpool split' command. please see https://docs.oracle.com/cd/e36784_01/html/e36835/gjooc.html for details 
for bridge creation with ifupdown, you should usually specify the underlying device using bridge_ports
mpv has no menus for dvd, but it works very well
the first argument of arg1:arg2 is the unix owner (user) the second argument is a group
to remove the \, use bash parameter substitution. // means replace all ..
what you describe is called a captive portal
try  rsync --size-only -avzpe ssh /mnt/xlses/split/v2/name\ with\ space root@myserver.com:/mnt/xlses/split/v2/   i took off the trailing slash / from the source directory path
you seem to have mounted the wrong partition of the server drive
create a function in ~/.bashrc:  function set-title() {   if [[ -z "$orig" ]]; then     orig=$ps1   fi   title="\[\e]2;$*\a\]"   ps1=${orig}${title} }   then use your new command to set the terminal title
there's no built-in command, but you can easily write a function that calls mkdir then cd:  mkcd () {   mkdir "$1"   cd "$1" }   put this code in your ~/.bashrc file (or ~/.kshrc for ksh users, or ~/.zshrc for zsh users)
with sed:  $ sed -e '1i\ description of the following table: ' &lt;file description of the following table: table1  1234 9555 87676 2344  
often apt-get will prefer to remove dozens of packages instead of just updating a couple of other packages.  i usually run aptitude in interactive mode, select the package i want to install with + and then inspect what other packages might be broken by this action (jump to the next "broken" package with the 'b' key
i guess that, in bash anyway, you can use declare and the -global switch to force global scope
finally i got the answer and i m share my answer with anyone  suppose my vnc server  : 192.168.100.195    install git:  yum install git   after that download novnc    $git clone git://github.com/kanaka/novnc     $ cd novnc $ ./utils/launch.sh --vnc 192.168.100.195:5901   after that you get output like:  warning: could not find self.pem starting webserver and websockets proxy on port 6080 websocket server settings:   - listen on :6080   - flash security policy server   - web server
are you sure it only lets you use one disk?  it asks you for a root disk to install the bootloader
startx is just a script that wraps xinit and sets up an environment
do you have a kernel >= 2.6.38? if not, you may want to upgrade your kernel, so it includes "the ~200 line linux kernel patch that does wonders"
try this instead:  sort -t, -k1,1 -k3.7n -k3.1,3.2n -k3.4,3.5n &lt; filename    there's no need to quote the comma delimiter the first sort-key definition uses column 1 the second sort-key definition uses column 3's "year" field, sorted numerically the third sort-key uses column 3's "month" field, sorted numerically the fourth sort-key uses column 3's "day" field, sorted numerically   sample run with an enhanced sample data file, showing the sorting:  input:  an1143,45.7,03/05/2012, an1143,45.7,02/05/2012, an1143,45.7,03/04/2012, an1143,45.7,03/05/2011, h9477,45.3,01/15/2010, dn1222,45.1,03/05/1800, j960,26.7,06/02,1990, z959,28.2,03/21/2016, h12421,27.7,06/21/2000   output:  an1143,45.7,03/05/2011, an1143,45.7,02/05/2012, an1143,45.7,03/04/2012, an1143,45.7,03/05/2012, dn1222,45.1,03/05/1800, h12421,27.7,06/21/2000 h9477,45.3,01/15/2010, j960,26.7,06/02,1990, z959,28.2,03/21/2016,  
try kwin --replace or display=:0 kwin --replace if you're not in x. source  
 if you can install from repository
for devices in /dev check the corresponding entry in /sys/class/&lt;device&gt;/device/driver
since you want an answer "without installing any extra applications like photobooth," i've tried to give a solution that doesn't depend on very much
tail -f asdf.log | while true; do if read -t 1 line; then echo $line; else echo beep; fi; done   (change the number after -t to the number of seconds of inactivity you want) 
this old workaround seems to be still working  mylibdir = $(libdir) dist_mylib_scripts = libxxx.so  
when you say priority, you probably mean the nice-level of the process
problem was solved by using gdbserver run by root
/.. points to /:  $ ls -id / 2 / $ ls -id /.. 2 /..   both have the same inode number, which happens to be 2 on this system
hash is a bash built-in command
if your shell tells you it can't find sudo then it's not installed and you will need to install it using yum install sudo
first store the password in a file called .my.cnf in the users home directory with the following format:  [mysqldump] password=secret     then, you have to use mysqldump without the -p flag to dump a mysql database (it now uses the password from the file):  mysqldump -u root database | 7z a -si backup.sql.7z    the a flag of 7z adds to the archive -si means to read from the standard input (from the anonymous pipe).  
it did that because . isn't a name that can be used to create a subdirectory.  cp -a 
you can use the audit system to log all connect() system calls.  sudo auditctl -a exit,always -f arch=b64 -s connect -k connectlog sudo auditctl -a exit,always -f arch=b32 -s connect -k connectlog   then you can search:  sudo ausearch -i -k connectlog -w --host 69.46.36.10   which will show something like:  type=sockaddr msg=audit(02/09/14 12:31:57.966:60482) : saddr=inet host:69.46.36.10 serv:4000 type=syscall msg=audit(02/09/14 12:31:57.966:60482) : arch=x86_64 syscall=connect success=no exit=-4(interrupted system call) a0=0x3 a1=0x20384b0 a2=0x10 a3=0x7fffbf8c9540 items=0 ppid=21712 pid=25423 auid=stephane uid=stephane gid=stephane euid=stephane suid=stephane fsuid=stephane egid=stephane sgid=stephane fsgid=stephane tty=pts5 ses=4 comm=telnet exe=/usr/bin/telnet.netkit key=connect   btw, i've seen that ip address being resolved from grm.feedjit.com and connection attempts being done to that on 400x ports by iphones. 
!1255:p   will do this  ! is history recall 1255 is the line number :p prints but does not execute  then you can use up-arrow to get ther previous (unexecuted) command back and you can change it as you need.  i often combine this with hg ("history grep") - my favorite alias
this answer on stackoverflow by bill karwin is exactly what you are looking for:     you have killed the process, but a dead process doesn't disappear from the process table until its parent process performs a task called "reaping" (essentially calling wait(3) for that process to read its exit status)
in bash, using sed:  if [[ $(&lt; "$file") != "asdf" ]]; then   sed -i '/^asdf$/d' "$file" fi  
i installed the linux-lts package as suggested by @mikeserv from chroot and i set it as the default boot option from the grub configuration. this way i could boot nicely into linux 3.14 and complete the installation process
you can simply run:  dos2unix &lt;filename&gt;  this will remove all the ^m characters from the file
use a fuse filesystem that allows you to browse archives like directories, such as avfs
this error message is because twitter needs oauth for authentication
i recommend using jq for all json related text processing operations
most packages will have a &lt;package&gt;-dev (for debian based) or &lt;package&gt;-devel (for red hat based) that will be the libraries needed to link against for building.  so, for example if the source says it requires libxml, in debian based systems you'll find libxml2 and libxml2-dev (use apt-cache search &lt;dependancy&gt; to find them).  you'll need the libxml2-dev to build it, and libxml2 to run it.  the ./configure step usually supports flags like --with-libxml=/usr/lib/ to point it at the correct libraries (./configure --help should list all of the options)
usually 83 is used for ext2/3/4
the btrfs-tools package adds an action to the initramfs to load the btrfs module
the shutdown command has already an embedded scheduler so you don't need a cron job for it to run at the specified time
you could try something like this:  exec 9&gt;&amp;1 output=$(grunt test | tee /dev/fd/9) exec 9&gt;&amp;-   it copies the current stdout to file descriptor 9, uses tee to replicate grunt's output to that file descriptor, then afterwards closes the temporary file descriptor. 
a typical way to do this is to use the trap command to tell the shell script to ignore sigint (generated by control-c), and then to re-enable sigint in a subshell just before your command is run.  trap "" int hosts=(machine1 machine2 machine3 machine4 machine5) for i in "${hosts[@]}" do     echo "$i"     (trap - int; ssh -q "$i" "uname -a") done  
the x11 forwarding is only forwarding windows that are spawned within your current session
from the manual page:     search this is used to find packages when you know something about the package but aren't sure of it's name
how to print a selected portion of a pdf file  using the native adobe acrobat reader   make sure the basic toolbar is visible by right clicking on a blank area of the toolbar, and placing a check mark next to basic if it is not already enabled. find the "snapshot tool" on the basic toolbar and select it. drag a box around the area you want to print
diff has more than one option related to whitespace
you could do:  printvars() (   eval 'declare() { printf declare; printf " %q" "$@"; echo; }'"         $(declare -p)" )  printvars   that could be easily extended to omit read-only variables like:  printvars() (   eval 'declare() {           [[ $1 = *r* ]] &amp;&amp; return           printf declare; printf " %q" "$@"; echo         }'"         $(declare -p)" )  
it's possible to do this without a plugin using the w command, so the buffer contents can be used in a shell command:  :w !diff -au "%" - &gt; changes.patch   (% is substituted with the path of the file being edited, - reads the buffer from stdin)  
according to the manual you should use adduser:     man useradd      description      useradd is a low level utility for adding users
terminals are controlled by escape sequences that are sent in-line with the character data to be displayed
you should first simplify your alias, there is no need to do the activate stuff
history expansion was great in the 80s (when introduced by csh) when terminals were very slow and limited
"low level formatting" was done on floppies, where you could write at different densities by choosing to organize the tracks and sectors differently
config settings for the ssh server are often in /etc/ssh/sshd_config but the first thing i would check is the location and the permissions of the public key and its parent directory that you copied to the server. noting that correct permissions  of  authorized_keys on the remote are critical for ssh to work - and hence why we use ssh-copy-id and not simply copying  the public key to the remote. to understand this it may be useful to breakdown what the ssh-copy-id does.  first thing it does is secure copy id_rsa.pub over to the target server i.e
it's impossible to reload routing table without lost network service (i think you mean you don't have to use service networking restart command to make the changes)
thanks @rubo77 for asking this, it's a great exercise
assuming you're running bash (with typical settings), running  sudo chmod 644 .*   from /usr/share/figlet would end up running  sudo chmod 644 
subsystem sftp intenal-sftp   should be "internal"
if you're only serving static files, you don't need modify the config
disown is a bash builtin (job control) just like switch, continue and history
what's happening is that google is throttling your api requests
i would suggest that your drive experienced some kind of hardware failure
with awk:  awk 'nr!=1{print x"-"$0}{x=$0}' file    nr!=1 applies on all line, except the first one print x"-"$0 print the values with dash between x=$0 set x (for the next iteration)  
invoke the busybox binary as busybox, and you get a line with the busybox version, a few more lines of fluff, and the list of utilities included in the binary.  busybox | head -1   most utilities show a usage message if you call them with --help, with the version number in the first line.  ls --help 2&gt;&amp;1 | head -1  
you can use the split+glob operator:  find 
i would counter-act your question with a series of questions of my own to know what you have done in the first place ?  a
0)  lii0 is the wan interface   1)  echo "up" &gt; /etc/hostname.lii0   2)  vi /etc/hostname.pppoe0  inet 0.0.0.0 255.255.255.255 none \ pppoedev lii0 authproto pap \ authname 'pppoeusername' authkey 'pppoepassword' up dest 0.0.0.1 !/sbin/route add default -ifp pppoe0 0.0.0.1   3)  sh /etc/netstart  
i don't know if your version of sed will be binary-clean or if will choke on what it thinks are really long lines in its input, but barring those issues, editing the string in-place should work
on linux the default is now dwarf 2 and/or 4
gpg-agent is a program that runs in the background (a daemon) and stores gpg secret keys in memory
use while read loop:  : &gt; another_file  ## truncate file.  while read -r line; do     command --option "$line" &gt;&gt; another_file done &lt; file   another is to redirect output by block:  while read -r line; do     command --option "$line" done &lt; file &gt; another_file   last is to open the file:  exec 4&gt; another_file  while read -r line; do     command --option "$line" &gt;&amp;4     echo xyz  ## another optional command that sends output to stdout. done &lt; file   if one of the commands reads input, it would be a good idea to use another fd for input so the commands won't eat it (here assuming ksh, zsh or bash for -u 3, use &lt;&amp;3 instead portably):  while read -ru 3 line; do     ... done 3&lt; file   finally to accept arguments, you can do:  #!/bin/bash  file=$1 another_file=$2  exec 4&gt; "$another_file"  while read -ru 3 line; do     command --option "$line" &gt;&amp;4 done 3&lt; "$file"   which one could run as:  bash script.sh file another_file   extra idea
depending on your distribution and kernel version the configuration of the currently running kernel can be in one of the following locations:  /proc/config.gz /boot/config /boot/config-$(uname -r)   the first one provides the proc filesystem and must be configured in the kernel config:  general setup  ---&gt;     &lt;*&gt; kernel .config support         [*] enable access to .config through /proc/config.gz  
see @bahamat's answer to this question titled: halt and poweroff options for shutdown command.     ....   halt was used before acpi (which today will turn off the power for you)*
most likely you just need to remove the world-executable permission:  sudo chmod o-x $(which command)   if the binary is owned by some group other than root, you probably want to set that to:  sudo chgrp root $(which command)  
this worked for me when i tried it on a mp3 file.  $ ffmpeg -i somefile.mp3 -f segment -segment_time 3 -c copy out%03d.mp3   where -segment_time is the amount of time you want per each file (in seconds).  references   splitting an audio file into chunks of a specified length 4.22 segment, stream_segment, ssegment - ffmpeg documentation  
try changing your script to:  #!/bin/bash function clear_secrets {   export bob=""   export john="" } while true do   clear_secrets   sleep 60 done   and then update /etc/bashrc (or where ever the default bashrc is for your system) to call this script
some vim syntaxes set certain settings when the file is opened
`w u1` - login informations for example for user u1 you can see in output something like this user     tty           login@  idle   jcpu   pcpu  what   also you can make a bash script and put in crontab for example to be run a few times per one day, with varibles  w u1, w u2, w u3 and make some otput into file  also  `/var/run/utmp` - list of current login sessions.    `/var/log/wtmp` - list of previous login sessions `/var/log/btmp` - list all the bad login attempt  
ssh is not primarily used to copy files
apparently there were missing pieces that the driver depended on, that were not auto-selected by the menuconfig
you have to update your system database i think with updatedb command 
a note of warning:  $ date -r ~/a sun 28 oct 23:12:00 gmt 2012 $ lc_all=c date -r ~/a sun oct 28 23:12:00 gmt 2012   as output, date outputs the date in the user's local format
you could run the user's shell profile like this:  
libcurl does not support the rsync protocol.  from the libcurl faq: section 3.21     3.21 protocol xxx not supported or disabled in libcurl     when passing on a url to curl to use, it may respond that the particular    protocol is not supported or disabled
the posix shell spec refers to simple commands, compound commands, command position, and the command command.  the first two reference how/when a shell command is parsed and executed
you basically have 2 choices if you want to install an alternative os
from the ssh_config man page:  hostkeyalgorithms              specifies the protocol version 2 host key algorithms that the client wants to use in order of preference
there are several tools that can do this
nautilus uses ~/.thumbnails normally
i would probably do something like this:  testing = true  if testing: ##################################################################      infile = ''' key0=0 key1=1  key1 = 1 key2=2 # comment1 #key3=3   #key4=4 #key5=5 # comment   #key6=6 # comment key7=7  key8 = 8     '''      infilelines = infile.split('\n')       class of():         def write(self, s):             print s         def close(self):             pass     outfile = of()      replacements = {         'key1' :'11repl',         'key2' :'22repl',         'key3' :'33repl',         'key4' :'44repl',         'key5' :'55repl',         'key6' :'66repl',         }   else: #########################################################################      # as proposed by csny, only open file quickly     # (file is closed after with statement)     with open('sysctl.conf') as infile:         infilelines = infile.readlines()      outfile = open('sysctl.conf.new', 'w')      replacements = {'net.ipv4.icmp_echo_ignore_all' :'1',         'net.ipv4.icmp_echo_ignore_broadcasts' :'1',         'net.ipv4.ip_forward' : '0',         'net.ipv4.tcp_syncookies':'1',         'net.ipv4.conf.all.rp_filter': '1',         'net.ipv4.conf.all.log.martiansd':'1',         'net.ipv4.conf.all.secure_redirects' : '1',         'net.ipv4.conf.all.send_redirects' : '0',         'net.ipv4.conf.all.accept_source_route':  '0',         'net.ipv4.conf.all.accept_redirects':'0',         'net.ipv4.tcp_max_syn_backlog': '4096',         }    for line in infilelines:      # if # at the beginning (neglecting whitespaces): its only a line comment     # write it directly to outfile and continue with next line     if len(line.strip())==0 or line.strip()[0] == '#':         outfile.write(line.strip())         continue      # try if this is a properly formated line like: key=val     try:         key, val = line.split('=')         key = key.strip()         val = val.strip()      # something stange happend: it was not a proper key=val line     # dont modify anything, just write the line to the new file     except valueerror:         # or comment out outfile.write to delete the strange line         # from the output config file         outfile.write(line)         continue      # maybe you want to allow line end comments like: key=val # comment?     # lets try if the value actually contains a comment     try:         val, comment = val.split('#')         comment = '# ' + comment.strip()         val = val.strip()      # there is no comment at the end of the line     # (the val.split() returns only one value and thus the unpacking fails with:     # valueerror: need more values to unpack)     except valueerror:         comment = ''       # replace the val if the according key in the `replacements` dict     # with the value stored in the key     # otherwise don't change anything     if key in replacements.keys():         val = replacements[key]      # put together the new line for the output file     line = '%s=%s   %s' % (key, val, comment)     outfile.write(line)  outfile.close()   see comments in the code
use sensors-detect to configure the missing sensors, if they are available.  at my machine, there is a second sensor device handling the per-core sensors:  [...] coretemp-isa-0000 adapter: isa adapter physical id 0:  +54.0°c  (high = +80.0°c, crit = +98.0°c) core 0:         +53.0°c  (high = +80.0°c, crit = +98.0°c) core 1:         +53.0°c  (high = +80.0°c, crit = +98.0°c) core 2:         +49.0°c  (high = +80.0°c, crit = +98.0°c) core 3:         +54.0°c  (high = +80.0°c, crit = +98.0°c)  
as far as i know, there is no way to rescue nautilus (file manager for gnome) when it hangs
if your intent is to backup a remote computer's hdd a via ssh to a single file that's on your local computer's hdd, you could do one of the following.  examples  run from remote computer  $ dd if=/dev/sda | gzip -1 - | ssh user@local dd of=image.gz   run from local computer  $ ssh user@remote "dd if=/dev/sda | gzip -1 -" | dd of=image.gz   live example  $ ssh skinner "dd if=/dev/sda5 | gzip -1 -" | dd of=image.gz 208782+0 records in 208782+0 records out 106896384 bytes (107 mb) copied, 22.7608 seconds, 4.7 mb/s 116749+1 records in 116749+1 records out 59775805 bytes (60 mb) copied, 23.9154 s, 2.5 mb/s  $ ll | grep image.gz -rw-rw-r--
i think you can use anything which is supported in the /etc/shadow file
try this:  sort -n --k3 &lt;file&gt;   for example:  $ sort -n -k3 test helix       cp9(plasmid             9586 bp    dna     helix       29-aug-2011 helix       lp25(plasmid           24437 bp    rna     linear       29-aug-2011 helix       lp28-1(plasmid         25455 bp    dna     linear       29-aug-2011 helix       chromosome            911724 bp    dna     plasmid       29-aug-2011   -n sorts by numeric value, and -k3 selects column 3. 
the direct answer is probably that vi is part of the posix standard (as @jasonwryan also mentioned in a comment), as well as the single unix specification
in gnu (e.g
 have you done anything to not start xfwm4? generally, see the haskell wiki's notes on using xfce4 with xmonad, as they probably help you with i3, too
beyond the wear and tear on the hdds i can't see any reason why this would be dangerous
it looks like the solution is to install bootlogd and put   bootlogd_enable=yes   in /etc/default/bootlogd.  references:   bootlogd - debian wiki bootlogd(8) man page bug 524761 - rsyslog doesn't log boot messages (boot.log) bug 658134 - no more bootlogs  
you could use su[yourusername]-c /usr/bin/vncserver to run the vncserver as user, not as root.  another point: in your script, there's no difference between starting and stopping the vnc server
solution part 1: configure kbd  debian uses kbd, search for blank_time in /etc/kbd/config:  # screen blanking timeout
bash explicitly disables this and a few other readline shortcuts
assuming your computer is usually stable, check for hardware problems, especially with the ram (i.e
this information is stored in:  /etc/linuxmint/info   just change this line:  edition="kde 64-bit"   to:  edition="cinnamon 64-bit"  
for i in *; do tail -2 "$i" | head -1; done &gt;&gt;file.txt   that should be sh (and hence busybox) compatible, but i don't have a non-bash available for testing atm.  edited in accord with helpful comments. 
i do the same and because i rebuild my tool drive (added/removed/updated tools/isos) quite often, i'm using (http://www.pendrivelinux.com/yumi-multiboot-usb-creator/yumi (your universal multiboot integrator))  it allows you to add/remove various distro's and tools to a usb flash drive
first method:  ok, i booted up my uefi box to check
by default, htop lists each thread of a process separately, while ps doesn't
use iotop.  it should be available in your repo for a redhat/centos/fedora machine (if it is not already installed).  it outputs a similar info as top, but instead of the cpu/memory stats, you will get the io stats (disk reads, writes and swapin).  the options -p , -u and --only might be of interest to you
why not use an array, they're meant for doing things like that.  sample[1]='1-first.with.custom.name' sample[2]='2-second.with.custom.name'  for (( i = 1; i &lt;= 2; i++ )) do   echo ${sample[$i]} done   also don't use all-capital variable names in your script to prevent accidentally using reserved variable names. 
the exact language used in the single unix specification to describe the meaning of set -e is:     when this option is on, if a simple command fails for any of the reasons listed in consequences of shell errors or returns an exit status value >0, and is not [a conditional or negated command], then the shell shall immediately exit.   there is an ambiguity as to what happens when such a command occurs in a subshell
here's an ugly awk solution; someone else may have a smarter way to do it:  awk -v pi=1.2.3.4 -v pint=eth0 -v pip=8.8.8 -vaips="8.8.10.1 8.8.10.2 8.8.10.3"  \   'begin{         split(aips, array)    }    {         gsub(/@public_interface@/, pint);         gsub(/@public_ip@/, pi);         if (/@admin_ips@/) {                 copy=$0                 for (i in array)  {                   gsub(/@admin_ips@/, array[i], copy)                   print copy                   copy=$0                 }         } else {           print;         }    }' input   this passes the variables into awk (using space-separation for the admin ips); before any input is read, awk will split that passed-in "array" into a bona fide awk array named array
to remove lines that contain either string, specifically with grep:   in one command, per jordanm's comment:  grep -ev 'success|ok$'   or:  grep -ve success -e 'ok$'   or:  grep -v 'success ok$'  in two commands:  grep -v success file | grep -v 'ok$'   example:  $ cat file success something else success ok just something else  $ grep -ev 'success|ok$' just something else $ grep -v success file | grep -v 'ok$' just something else   to remove lines that contain both strings, specifically with grep:  grep -v 'success.*ok$' file   example:  $ cat file success something else success ok just something else  $ grep -v 'success.*ok$' file success something else just something else  
here are three options:   awk and its variants (gawk, mawk etc.):  awk '{if(nr==1){print $0,"| place"} else{print $0,"| paris"}}' file.txt  perl:  perl -lne '$.==1 ? print "$_ | place" : print "$_ | paris"' file.txt  sed  sed '1 s/$/ | place/; 1! s/$/ | paris/' file.txt    
   how (where) can i find out information about them,    first you have to find out which program is bound to each port
it's specified by the opengroup (the body specifying unix) and by the linux standard base.  i don't know how well those are followed on the various unices/linuces though.  the wikipedia page is also a good reference. 
i think you are referring to removing the caret-m at the end of lines
you can use the down directive in your client configuration to fire off a custom script when the connection drops
xorriso -outdev /dev/sr0 -list_speeds   the result depends on the inserted medium. 
yes it's going over the internet to run the partial commands when you hit the tab key
for images:  you can watch images with fbi:  name        fbi - linux framebuffer imageviewer  synopsis        fbi [ options ] file ...  description        fbi  displays  the  specified  file(s) on the linux console using the framebuffer device
the -n option checks if a string is non-zero length.  if [ ..
there's no standard way.  you can avoid using a temporary variable by using a function
why not use #! /usr/bin/python2.7 when you want to use python 2.7 and #! /usr/bin/python3.4 when you want to use python 3.4?  alternatively if you want your python programs to automatically use the latest python 2.x or python 3.x, use #!/usr/bin/python2 or #!/usr/bin/python3 - they are symlinks pointing to the latest versions, 2.7 and 3.4 respectively at the moment.  btw, i have the following python interpreters installed on my debian sid system at the moment
if you attach strace to the process just when it's hung (you can get the pid and queue the command up in advance, in a spare terminal), it'll show the file descriptor of the blocking write.  trivial example:  $ mkfifo tmp $ cat /dev/urandom &gt; tmp &amp; [1] 636226   # this will block on open until someone opens for reading  $ exec 4&lt;tmp   # now it should be blocked trying to write  $ strace -p 636226 process 636226 attached - interrupt to quit write(1, "l!\f\335\330\27\374\360\212\244c\326\0\356j\374`\310c\30z\362w\307\365rv\244?o\225n"..., 4096 &lt;unfinished ...&gt; ^c process 636226 detached  
your laptop should have /sys/class/backlight
rpcinfo will try both tcp and udp connections to talk to the portmapper
the cron daemon takes crontabs from several files.  dir /etc/cron.d and file /etc/crontab are special, they can be manually edited and the daemon will always see the new version automatically
you can run the mount without any arguments to get a list of current mounts
it was coming from my use of colors. i was using the following strings to colorise my text:  class colors:     header = '\033[95m'     okblue = '\033[94m'     okgreen = '\033[92m'     warning = '\033[93m'     fail = '\033[91m'     endc = '\033[0m'   i added \001 and \002 characters, and now, it works!  class colors:     header = '\001\033[95m\002'     okblue = '\001\033[94m\002'     okgreen = '\001\033[92m\002'     warning = '\001\033[93m\002'     fail = '\001\033[91m\002'     endc = '\001\033[0m\002'   related solution post: http://stackoverflow.com/questions/8806643/colorized-output-breaks-linewrapping-with-readline/8916332#8916332 
with perl:  $ perl -f, -i.bak -ane 'print if @f &gt; 3' file   with perl > 5.20, you can use -f without -a and -n (-f implies -a and -a implies -n).  or you can use sed:  $ sed -i.bak -e '/\([^,]*,\)\{3,\}/!d' file  
here's a sed one that will give you grep-like behavior across multiple lines:  sed -n '/foo/{:start /bar/!{n;b start};/your_regex/p}' your_file   how it works   -n suppresses the default behavior of printing every line /foo/{} instructs it to match foo and do what comes inside the squigglies to the matching lines
for a while, there were two major implementations of emacs: gnu emacs and xemacs
i assume you are using linux and pam
generally, stopping and starting the system cron daemon is a bad idea
in the example that you mention in your comment it is parallel that transfers the function to the remote environment (and it works only bash)
eval printf %s${1+"'\n' \"the last arg is \${$#"\}\"}   ...will either print the string the last arg is followed by a &lt;space>, the value of the last argument, and a trailing &lt;newline> if there is at least 1 argument, or else, for zero arguments, it will print nothing at all.  if you did:  eval ${1+"lastarg=\${$#"\}}   ...then either you would assign the value of the last argument to the shell variable $lastarg if there is at least 1 argument, or you would do nothing at all
in bash, ksh or zsh:  sort -gum &lt;(grep -na5 onestring foo.txt) &lt;(grep -nb5 otherstring foo.txt) # sort by general numbers, make output unique and merge sorted files, # where files are expanded as a result of shell's command expansion, # fifos/fds that gives the command's output   this takes o(n) time, given that grep outputs already sorted things
first, this is about a lot more than just coreutils
it should be enough to modify your ~/.bash_profile so it reads:  if [ -f /bin/ksh93 ] then     renice -n 4 $$     exec -l /bin/ksh93 fi   the renice -n 4 $$ will set the nice value of the current shell ($$) to four, causing subsequent commands launched by that shell to inherit the same niceness value
you could (or do?) probably use wpa_supplicant; using its ctrl_interface configuration key, you can allow non-root users (e.g
i had the same problem, and i found that you have to set $limit to 0 to remove that limit:  echo "$major:$minor 0" &gt; blkio.throttle.write_bps_device   this removes the entry from the cgroup
the basic mail command is only a mail reader and composer, it doesn't know how to talk to a server over the network (with the smtp protocol)
when handling data, much of the time, the key is to keep only data that's relevant to your particular set of tasks, and nothing more
if command4 is currently running, it is possible to do this pretty straightforwardly:  ^z $ fg &amp;&amp; right_command5 &amp;&amp; command6   this is essentially what you were already doing to start command4 in the first place
the word boundary has a similar effect to -w, but can be used as part of the expression.     ‘\b’      match the empty string at the edge of a word.   [...]   ‘\&lt;’      match the empty string at the beginning of word.   ‘\>’      match the empty string at the end of word.   to match bar only when it's the whole word, but foo anywhere (including inside longer words):  grep -e 'foo|\&lt;bar\&gt;'  
did you get that list from here, http://msdn.microsoft.com/en-us/library/windows/desktop/ms681917(v=vs.85).aspx.     each process provides the resources needed to execute a program
dtach is a wafer-thin terminal session manager, now forked on github, or doubtless easily installed via the ports or package system for your operating system.  (of historical interest may also be the dislocate example script distributed with expect.) 
download the file you want to install.  then: yum install "whatever_the_filename_is"  if the package is not signed: yum –nogpgcheck install "whatever_the_filename_is" 
networkmanager has the functionality to manage a local dnsmasq server built in
if you only have your private key id_rsa under ~/.ssh and your public key is lost then you can retrieve the public key id_rsa.pub via  ssh-keygen -y -f ~/.ssh/id_rsa &gt; ~/.ssh/id_rsa.pub   on your local machine. this public key should be pasted to authorized_keys in ~/.ssh on the server you want to login
that gap is a tab
what you're asking for doesn't make much sense in the general case, so it's not surprising that find has no provision for it.  a symlink with a relative target is relative to the path of the symlink
somewhere in /boot, probably (not sure about mint), or else on your esp at least, you'll find a file called refind.conf
cltm might be required if your corporate proxy uses ntlm from microsoft.  after you have cntlm proxy server configured for upstream  proxy (which is your corporate proxy), just configure npm to use it:  npm config set proxy http://127.0.0.1:3128 npm config set https-proxy http://127.0.0.1:3128   you must have both http and https. most package managers work best if proxy is configured in the config file as opposed to enviroment variable which is better for running scripts from command-line.  however, your error code says "connection refused", so this could be outbound firewall, selinux blocking or wrong port to proxy host
three methods:   set (and export) the variable before launching mvn set the variable on the nohup launch:  formaven=valueformaven nohup $command &gt; logfile  use env to set the variable  command="env formaven=valueformaven mvn clean install -p $maven_profile"   
the unix approach to groups that grant various sorts of access is quite primitive - it mostly just gives write (and possibly read) type permissions, to the relevant devices
swapping only when there is no free memory is only the case if you set swappiness to 0
this is a side-effect of installation parameters
that was a hard one
i'm guessing the real problem is that you don't know what a ssid is
apt is available for fedora, and is just a port of the debian one afaik
if it's a synaptics touchpad (most are), play with its options
printf %s\\n "$-"   will list the single letter options in a single string.  that parameter can also be used like:  set -f -- ${-:+"-$-"} echo *don\'t* *glob* *this* set +f "$@"   to first disable shell -filename expansion while simultaneously saving a value for $- - if any - in $1
sawfish manages its menus with a companion program sawfish-menu
that is not such an easy problem as one might guess
if you change your password through the gui, it should automaticly synchronize the keyring that stores your wifi passwords etc
a spin lock is a way to protect a shared resource from being modified by two or more processes simultaneously
to delete all fifos in the current directory and all sub-folders use  find 
is the file a database file by chance or something that might be still "open" by a long running program or daemon?  generally, if you didn't see a decrease in disk space it's most likely that something still has the file open.  if it truly is the file system itself that is in error (which would be odd), i'm afraid you'll need to umount the disk to run fsck on it. 
you've used -print before -type d, so find print all things not satisfied the first expression.  you want to swap them:  find 
tl;dr see fd0's solution  i did look in the man page before asking, but failed to notice the relevant info, since i figured it doesn't differ significantly from that of linuxes
you can do this with the perl's built-in 'system' function:  system "/home/user/script2.pl /var/log/fw_log error &gt;&gt;/tmp/error.log";  
use wireshark:  tshark -f "udp port 53" -y "dns.qry.type == a and dns.flags.response == 0"  
after a long search i solved the problem i was facing
no, there is not. you could create you own repository, like many projects do
if you need to match the full command line (command + parameters) as you reported in your example you will have to use the -f option:  pkill -9 -f "commandname -parameters"   accordingly to the man page:    -f     the pattern is normally only matched against the process name.           when -f is set, the full command line is used.  
it seems ko_kr.utf8 works, try  lc_collate=ko_kr.utf8 sort file     how have i found this?  for loc in $(locale -a);     do echo ____"${loc}"____; lc_collate="$loc" sort file; done | pcregrep -mc1 'wa\nal (\n|[^_])*günter rohrbach\ng'  
% bindkey | grep word | egrep 'for|back' "^[^h"         -&gt; backward-delete-word "^[b"          -&gt; backward-word "^[f"          -&gt; forward-word "^[b"          -&gt; backward-word "^[f"          -&gt; forward-word "^[^?"         -&gt; backward-delete-word   so esc and then b or f, by default. 
there are two reasons lsof | wc -l doesn't count file descriptors
gedit, the default text editor for gnome, can do that
if your hdd allows, you can try to do it this way:  first write uncompressed file:   ffmpeg -f x11grab -s sz -r 30 -i :0.0 -qscale 0 -vcodec huffyuv grab.avi   here sz is your display size (e.g
if i understand correctly, you want to take the first characters of each file name until the first non-letter, and match them against the first characters of the target directory until the first _
you don't have a space between -a and -1, so ls is trying to interpret the - as an option, not as signifying an option
trap "signum=${sig};myfunc" "$sig"  
this script will do what you want (if i understand your requirements correctly).  i took the liberty of extrapolating your specification to allow the input to have one header line and then any number of lines with date/time ranges.  i’ll illustrate this, and discuss it further, below.  #!/bin/sh if ifs= read header then         printf "%s\n" "$header" else         echo 'eof on first line!' &gt;&amp;2         exit 1 fi while read start_date start_time end_date end_time other_data           # see note, below. do         start_epoch=$(date +"%s" -d "$start_date $start_time")  ||  {                 echo "error processing start date&amp;time $start_date $start_time" &gt;&amp;2                 exit 1         }         end_epoch=$(date +"%s" -d "$end_date $end_time")  ||  {                 echo "error processing end date&amp;time $end_date $end_time" &gt;&amp;2                 exit 1         }         if [ "$end_epoch" -lt "$start_epoch" ]         then                 echo "end date&amp;time $end_date $end_time is before start date&amp;time $start_date $start_time" &gt;&amp;2                 # now what?                 continue         fi         ok_seq=1        # flag: we are moving forward.         current_date="$start_date"         current_time="$start_time"         while [ "$ok_seq" -ne 0 ]         do                 # most days end at 23:59:59.                 eod_time="23:59:59"                 eod_epoch=$(date +"%s" -d "$current_date $eod_time")  ||  {                         # this should never happen.                         echo "error processing end-of-day date&amp;time $current_date $eod_time" &gt;&amp;2                         exit 1                 }                 if [ "$end_epoch" -lt "$eod_epoch" ]    # we’re passing the end of the date/time range.                 then                         if [ "$current_date" != "$end_date" ]                         then                                 # sanity check -- this should not happen.                                 echo "we're finishing, but the current date is $current_date and the end date is $end_date" &gt;&amp;2                         fi                         eod_time="$end_time"                         ok_seq=0                 fi                                                                         # see note, below.                 printf "%s %s %s %s      %s\n" "$current_date" "$current_time" "$current_date" "$eod_time" "$other_data"                 # we could also use +"%f" for the full yyyy-mm-dd date.                 current_date=$(date +"%y-%m-%d" -d "$current_date next day")  ||  {                         # this shouldn’t happen.                         echo "error getting next day after $current_date" &gt;&amp;2                         exit 1                 }                 current_time="00:00:01"         done done   discussion:   read the header line.  if this fails, abort the script.  if it succeeds, write the line to the output.  if (as your question shows) you don’t want the header in your output, remove the printf "%s\n" "$header" statement. as mentioned above: loop, reading start/end/value lines from the input until we reach the end of the input (or get a fatal error).  if you don’t want to do this, remove the while, the do, and the corresponding done. read the start date, start time, end date, end time, and other data.  other_data includes everything after the end time, i.e., val1 and val2 (and all the space between them). use the date +"%s" -d "date/time string" command to convert arbitrary date/time strings to unix “epoch times” — the number of seconds since 1970-01-01 00:00:00 (gmt).  this lets us validate input (and exit in case of error), and also gives us numbers that we can compare. (although i suppose we could just do string comparison on values formatted as yyyy-mm-dd hh:mm:ss.) if the end date/time is before the start date/time, skip this record and go to the next line.  if you’d rather do something else (like terminate) in this case, change this code. set a flag (ok_seq) that we will use to control the loop that steps through the days.  initialize the start date/time for the first day to be the start date/time for the entire period. on each output line, the start date and the end date are the same.  on most lines, the end of day (eod) time is 23:59:59.  if (same date) + 23:59:59 is greater (later) than the end-of-period date/time, then we are on the last day (output line) of the range.  set the eod time to the end time, and set ok_seq to 0 so we will exit the loop. write a line of output, including the “other data” (val1 and val2, etc.) compute the next day’s date.  set the start time to 00:00:01, which will appear on each output line except for the first.   example:  $ cat input       startdate             end date         val1    val2 2015-10-13 07:00:02 2015-10-19 00:00:00      45      1900 2015-11-01 08:30:00 2015-11-05 15:00:00      42      6083 2015-12-27 12:00:00 2016-01-04 12:34:56      17      quux  $ ./script &lt; input       startdate             end date         val1    val2 2015-10-13 07:00:02 2015-10-13 23:59:59      45      1900 2015-10-14 00:00:01 2015-10-14 23:59:59      45      1900 2015-10-15 00:00:01 2015-10-15 23:59:59      45      1900 2015-10-16 00:00:01 2015-10-16 23:59:59      45      1900 2015-10-17 00:00:01 2015-10-17 23:59:59      45      1900 2015-10-18 00:00:01 2015-10-18 23:59:59      45      1900 2015-10-19 00:00:01 2015-10-19 00:00:00      45      1900 2015-11-01 08:30:00 2015-11-01 23:59:59      42      6083 2015-11-02 00:00:01 2015-11-02 23:59:59      42      6083 2015-11-03 00:00:01 2015-11-03 23:59:59      42      6083 2015-11-04 00:00:01 2015-11-04 23:59:59      42      6083 2015-11-05 00:00:01 2015-11-05 15:00:00      42      6083 2015-12-27 12:00:00 2015-12-27 23:59:59      17      quux 2015-12-28 00:00:01 2015-12-28 23:59:59      17      quux 2015-12-29 00:00:01 2015-12-29 23:59:59      17      quux 2015-12-30 00:00:01 2015-12-30 23:59:59      17      quux 2015-12-31 00:00:01 2015-12-31 23:59:59      17      quux 2016-01-01 00:00:01 2016-01-01 23:59:59      17      quux 2016-01-02 00:00:01 2016-01-02 23:59:59      17      quux 2016-01-03 00:00:01 2016-01-03 23:59:59      17      quux 2016-01-04 00:00:01 2016-01-04 12:34:56      17      quux   observe that it has no problem rolling over, not only from one month to the next, but also from one year to the next.    note: when i wrote the above version of the script, i couldn’t figure out how to capture the white space between the end time and val1, so i was getting output that looked like        startdate             end date         val1    val2 2015-10-13 07:00:02 2015-10-13 23:59:59 45      1900 2015-10-14 00:00:01 2015-10-14 23:59:59 45      1900 2015-10-15 00:00:01 2015-10-15 23:59:59 45      1900                     ︙   so i “cheated”, by building the ‘right amount’ of space into the printf command (before the last %s).  but if you change the spacing in your input, the above version of the script will again produce incorrectly aligned columns.  i figured out how to fix it, although it’s a little messy.  replace the while … do … start_epoch=… lines with:  while read start_date start_time end_date other_data do         # $other_data includes end_time and all the following values.         # break them apart:         end_time="${other_data%%[       ]*}"         other_data="${other_data#"$end_time"}"         start_epoch=…   where end_time has been removed from the read command, and the characters between the brackets [ and the ] are a space and a tab.  so now other_data contains the spaces before val1.  then change the printf to                  printf "%s %s %s %s%s\n" "$current_date" "$current_time" "$current_date" "$eod_time" "$other_data"   (note that there is no space between the fourth and fifth %s).  so now you’re done. 
this is essentially a matter of checking a whole bag of corner cases.   a drive can appear in /proc/mounts a drive can be used as swap (use /proc/swaps) a drive can be part of an active lvm pv (use pvdisplay) a drive can be part of a dm-mapper raid group (use /proc/mdstat) a drive can be directly accessed by an application (e.g
there is no generic way to directly mount a subtree of a filesystem
it looks like dale woolridge's confirm-crypt-hook patch has been merged into mutt.   use crypt-hook rather than pgp-hook.   crypt-hook foo@bar.com 0x123456789abcde01   set crypt_confirmhook=no for that recipient
xfree86 (http://www.xfree86.org/) includes "tiny" x servers in their build
posix shell script:  inp="${domain#http*://}"   test:  for domain in 'https://foo.bar/baz' 'http://foo.bar/baz' ; do \     inp="${domain#http*://}" ; \     echo "$inp" ; \ done   output:  foo.bar/baz foo.bar/baz  
you can use -c arguments,like python -c "print 123",see python --help  usage: python [option] ..
the question, if i understand it correctly, is:     given just a debian/ directory, i.e
the problem is that the overlay packages are never stabilized (the ~ is never removed from the arch keywords in the ebuilds)
install not only copies files but also changes its ownership and permissions and optionally removes debugging symbols from executables
screen -dms name /path/to/some/process arg1 arg2   then, later, to interact with process:  screen -x name  
you can edit the file that contains the instructions to execute when assigned the ip to your network card (/etc/udhcpc/default.script)
sort the easy way with sort, tr:   arr=($(for i in {0..9}; do echo $((random%100)); done)) echo ${arr[*]}| tr " " "\n" | sort -n | tr "\n" " "   into a new array:  arr2=($(echo ${arr[*]}| tr " " "\n" | sort -n))   without help by tr/sort, for example bubblesort:   #!/bin/bash     sort () {     for ((i=0; i &lt;= $((${#arr[@]} - 2)); ++i))     do         for ((j=((i + 1)); j &lt;= ((${#arr[@]} - 1)); ++j))         do             if [[ ${arr[i]} -gt ${arr[j]} ]]             then                 # echo $i $j ${arr[i]} ${arr[j]}                 tmp=${arr[i]}                 arr[i]=${arr[j]}                 arr[j]=$tmp                      fi         done     done } # arr=(6 5 68 43 82 60 45 19 78 95) arr=($(for i in {0..9}; do echo $((random%100)); done)) echo ${arr[@]} sort ${arr[@]} echo ${arr[@]}   for 20 numbers, bubblesort might be sufficient
to overwrite the start of the destination file without truncating it, give the notrunc conversion directive:  $ dd if=out/one.img of=out/go.img conv=notrunc   if you wanted the source file's data appended to the destination, you can do that with the seek directive:  $ dd if=out/one.img of=out/go.img bs=1k seek=9   this tells dd that the block size is 1 kib, so that the seek goes forward by 9 kib before doing the write.  you can also combine the two forms
stty and older versions of who am i will issue error messages when they're not connected to a tty device
the solution is to set the netfilter packet mark which can be used by advanced routing
there are different bash processes executing each line of code and $? isn't shared between the processes
solution  mount 192.168.1.1:/share share -o nolock,nfsvers=4.1   my windows server allows all nfs protocols, centos did not pick 4.1
you can do it like so:  $ variable=$(du -smh archive.zip | awk '{print $1}')   details  awk will parse the output breaking it up into columns
redirect the output to /dev/null:  nohup ./myserver &gt;&amp; /dev/null &amp;   alternatively, if you want to discard the standard output but keep the standard error, you could use this:  nohup ./myserver &gt; /dev/null &amp;   you can find more details here if you need more control over the redirections (using bash):   http://tldp.org/howto/bash-prog-intro-howto-3.html http://tldp.org/ldp/abs/html/io-redirection.html  
in the man page of man itself (this is about as meta as it gets :) ):  man man   or to be more specific (see jordanm's comment):  man 1 man   to get the page man(1).  quoting from the above:     the table below shows the section numbers of the manual followed          by the types of pages they contain.     1   executable programs or shell commands    2   system calls (functions provided by the kernel)    3   library calls (functions within program libraries)    4   special files (usually found in /dev)    5   file formats and conventions eg /etc/passwd    6   games    7   miscellaneous (including macro  packages  and  conventions),        e.g
the syntax you are trying to use belongs to extended regular expressions, so the answer is very simple, either use egrep or include the -e flag. 
try udevinfo command  also man 7 udev  example:  [root@centos ~]# udevinfo -q all -n /dev/sda1 | grep 'id_fs_uuid=' | awk -f'='  '{print $2}' 358c8298-3889-4982-8831-817a18ae4e67  [root@centos ~]# ls -l /dev/disk/by-uuid/ total 0 lrwxrwxrwx 1 root root 10 dec  1 12:47 358c8298-3889-4982-8831-817a18ae4e67 -&gt; ../../sda1 [root@centos ~]# readlink -e /dev/disk/by-uuid/358c8298-3889-4982-8831-817a18ae4e67  /dev/sda1   another one is blkid, which has integration with udev to show uuid  [root@centos ~]# blkid  /dev/mapper/volgroup00-logvol01: type="swap"  /dev/mapper/volgroup00-logvol00: uuid="7951711f-0564-46a5-8e1c-427eff4b4115" type="ext3"  /dev/sda1: label="/boot" uuid="358c8298-3889-4982-8831-817a18ae4e67" type="ext3"  /dev/hdc: label="vboxadditions_4.1.2_73507" type="iso9660"  /dev/volgroup00/logvol00: uuid="7951711f-0564-46a5-8e1c-427eff4b4115" type="ext3"  /dev/volgroup00/logvol01: type="swap"   
trivially, assuming there are no vt100 escapes to handle, you might try pushing the output through  sed 's/\r$//; s/.*\r//'   or the awk equivalent  awk '{ sub("\r$",""); sub(".*\r",""); print}'   but this assumes your sed or awk can handle very long lines, as the carriage-returns obviously aren't newlines
no.  you can export a device file through nfs or some other network filesystems
the ./configure script returns an error regarding your c-compiler
it looks like lxdm is not present in debian wheezy; at least, it's not included in any packages according to the results of a package contents search
/proc/net/dev contains statistics about network interfaces, while /proc/&lt;pid&gt;/net/dev contains statistics about network interfaces from the process' point of view
awk -f"\t" '$4 != "na" || $11 != "na"' filename   note, awk does not edit the file in-place
those are ansi escape sequences; that link is to a chart of color codes but there are other interesting things on that wikipedia page as well
i think the answer to your question is no, although you can accomplish the same thing other ways.     in man ld.so, i see no mention of being able to use custom .conf or .cache   true, but there is mention of $ld_library_path and and --library-path, the former being more generally useful.     what's the point of the above two options of ldconfig then?   so you can create a cache without overwriting the system one, and without having to use the system confs. 
contrary to bash, zsh doesn't read .zshrc when running commands over ssh
in addition on selector-based filtering, rsyslogd can filter on patterns found in log message properties
perhaps the tcpclone tool can help you
from the fstab(5) man page:     the sixth field (fs_passno).           this field is used by the fsck(8) program to determine the order           in which filesystem checks are done at reboot  time
the general rule for username is its length must less than 32 characters
since you have plenty of room in /home, move all the stuff from /srv into /home, then (optionally) move the stuff that was in /home to the root partition.  the simplest solution, if you don't mind a few minutes' downtime, is to move /srv into the larger partition and symlink it:  mv /srv /home ln -s /home/srv /   if you really want to move /home to the root partition, then it takes a few renames
i found the answer after posting that question
the debian installer normally creates the root account plus one normal user account during installation
this is your second script in bash:  #!/bin/bash  echo "set-cookie: eee=1" echo "content-type: text"  echo "&lt;html&gt;&lt;body&gt;"  printf '%s\n' "$http_cookie"  echo "&lt;/body&gt;&lt;/html&gt;"   os.environ.get('http_cookie') gets the evironment variable called http_cookie, within bash you can easly call the variable with "$http_cookie". 
if adding one cell value is acceptable: enter the conversion factor in any empty cell (even on another sheet), select paste special, and select the approrpriate calculation below of transpose.  e.g., to convert between inches and centimeters:   enter the factor 2.54 in an empty cell; copy that cell; select the values to convert; menu edit -> paste special; under operations, select the arithmetic operation to use; for in -> cm, select multiply; for cm to in, select divide:     without any modification of the sheet's content: then you'll have to create a macro that applies a pre-defined arithmetic operation on every cell in a defined / selected range. 
awk's answer may probably work, but for some reason, it's not working for me
linux automatically detects ssd, and since kernel version 2.6.29, you may verify sda with:   cat /sys/block/sda/queue/rotational   you should get 1 for hard disks and 0 for a ssd
try:  sort -t "_" -k2 -k3 -g &lt;filename&gt;   -t "_" - field seperator is _  -k2 - 1st sort on the second column  -k3 - then sort on the third column  -g - general numerical sort 
solution found here,must give static adddress to hpilo via arp first connect to your network hpilo with cable then from linux   arp -s 192.178.0.22 mac:address:of:hp:ilo   of course use your subnet instead of 192.178.0.22,and then ping,if work telnet to hpilo. 
a simple example:  suppose you want to delete and purge messages from the testmbox mailbox, containing [delete-me] in the subject line.  you can do this:   mutt -f testmbox -e "push &lt;tag-pattern&gt;~s[delete-me]\n&lt;tag-prefix&gt;&lt;delete-message&gt;&lt;sync-mailbox&gt;\n"  this works because:    -e executes configuration commands 'push' is a configuration command that add key sequences to the keyboard buffer, i.e
make the log file a fifo (man mkfifo) and put a process on the reading side which separates its input into files of limited size.  mkfifo /path/to/logfifo.app_xy split ..
yes a program exists: lpstat - print cups status information  $ lpstat -w completed    -w which-jobs      specifies which jobs to  show,  completed  or  not-completed  (the      default)
it's very similar to the backticks ``.  it's called command substitution (posix specification) and it invokes a subshell
yes, perl is your friend
i am not familiar with this tool but from looking at the source for the livecd-iso-to-disk.sh script here, i think you've got this backwards
@manatwork's suggestion to check any aliases was correct
this issue sounds suspiciously familiar to this one from ubuntu
create a dummy package using equivs
command-line batch audio processing tools are sox(http://sox.sourceforge.net/) and ecasound(http://www.eca.cx/ecasound/)
\033 is the octal code for the esc (escape) character, which is a good hint that the echoed strings in your prompt_command are terminal control sequences
man ssh_config, check 'host' and 'hostname'
it's been my experience that no, createrepo cannot recursively walk a directory tree
you don't say why you need this new version of lsblk but there are a variety of reasons why there might be a newer version of a package available yet you cannot update to that version
i am creating a new answer because the currently accepted answer is incorrect in calling them the same.  luks adds key management to dm-crypt
the root filesystem is passed to the kernel upon boot using the root argument
have a look at the filesystem hierarchy standard (fhs), which is a standard of organising directory structure
this looks like an encoding mismatch between your remote environment and the ssh client
zsh like most modern shells have a choice between two different keyboard mappings for command-line editing: a vi one and an emacs one
the 98.2%id means that most of the time, cpu does nothing (the cpu is in idle state).  to determine how is used the cpu over time, you can use uptime command that will gives you the load average. 
sed 's/\([^/]*\)\.phtml$/mydirectory\/\1.php/' &lt;filename&gt;   will do that, if that’s what you need
you could just use git rm --cached notes.txt
i would implement it like this (probably not an xubuntu friendly way, but should work): create a startup script which will start all required program, and make that script the only "auto-started" program with xubuntu tools. script can look like this:  #!/bin/sh program1 &amp; sleep 5 program2 &amp; sleep 5 program3 &amp;   or like this, which will look better if you have multiple programs to launch:  #!/bin/sh progs=(   "program1 args"   "program3"   program2   # ... )  for prog in "${progs[@]}"; do   ${prog} &amp;  # no quotes here, because we want to support args   sleep 5 done  
an update from a colleague, which i have just tested:  12arstdyfu445!! works  it seems that for some legacy reason, the password strength rules need to be adhered to within the first 8 characters of the password.  i will do some hunting around to see if this is applicable to all aix and solaris versions, but i hadn't managed to find an answer when googling through the ibm manuals available. 
*nix systems typically have a locate utility installed
from the linked post, your original string was generated by a method such as  echo -n foo | openssl dgst -binary -sha1 | openssl base64   what this generates is a digest, with sha1 being the method of calculating the digest.  in this situation there is insufficient data to reconstruct the original string
feed the input on a file descriptor other than standard input.  find /some/path/ -type f | grep -vif blacklist | mplayer -shuffle -playlist /dev/fd/3 3&lt;&amp;0 &lt;/dev/tty   explanation of the last line: the data from grep is coming in on standard input, which is file descriptor 0
there are many possible solutions for that:   you can configure sudo not to require tty: requiretty in /etc/sudoers you can force tty allocation on command-line in these specific cases, where you need it: ssh -tt host command you can tell scp not to allocate tty by -t or -o requesttty=no command-line option: scp -t file host:path/ or scp -o requesttty=no file host:path/   the reasons why does it happen are already explained
here's what i do
chances are that if you just decode the %xx uri encodings, you'll get utf-8 encoded characters
i think lsof is the tool that should be used for
how about  cat -- "$input_file" echo "$extra_line"  
i'm not a grub2 expert (sorry) but try adding --skip-fs-probe to your grub-install line, i have found this prevents creation of /boot/grub/device.map which can cause booting to a grub prompt
on /boot partition there are installed kernels
there are several things mixed here mounting a filesystem by user and superuser, accessing files on a mounted file system and accessing the data on the "raw" device.   mounting a file system  root can always mount a file system, provided he can access the device that carries it - which it can when the kernel recognizes it
/usr/bin/sudo /bin/umount -f -a -t cifs /usr/bin/sudo /bin/umount -f -l -a -t cifs sleep 5 /usr/bin/sudo /sbin/modprobe -r -f cifs pkill nautilus  
on a system, the only thing that is really persistent is a file
you could only work around that issue with that for example:  cat &lt;(false || kill $$) &lt;(echo ok) other_command   the subshell of the script is sigtermd before the second command can be executed (other_command)
it is common practice to save the 0th argument passed to a c program main and use that as the parameter for perror &mdash; for simple programs:  #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt;  int main(int argc, char *argv[]) {     char *foo = malloc(9999999999l);     if (foo == 0)         perror(argv[0]);     return 0; }   call that program "foo", and running it illustrates the point:  &gt; ./foo ./foo: cannot allocate memory   complicated programs may add to the text (or use only the filename without the path), but keeping the program name lets you find where a misbehaving program came from.  there is no universally accepted scheme for error messages, but some widely-used programs (such as gcc) add a message category such as "error" or "warning"
you need to ensure you don't have another, more general pin priority which takes priority over your non-free-excluding rule
i don't think there's an easy way to distinguish them
ps xww gives the following output  ...     1 ?        ss     0:00 init [2]  1804 pts/0    ss     0:00 -bash ...   after the two grep's it pipes the output to cut
in addition to eboix's find command (which as it stands breaks on whitespace, i'll put a safer way or two at the end), you can use bash's extglob feature:   # turn extglob on shopt -s extglob  # move everything but the files matching the pattern mv dir1/!(*.c) -t dir2 # if you want to exclude more patterns, add a pipe between them: mv dir1/!(*.c|*.txt) -t dir2   see the bash man page for more you can do with extglob. note that this is not recursive and so will only move files in dir1 directly, not subdirectories
something simple like:  xterm -t xnotconsole -e journalctl -f   ought to work
you can use this command:   echo "scale=5; 4*a(1)" | bc -l 3.14159   where scale is the number of digits after decimal point.  reference: http://www.tux-planet.fr/calculer-le-chiffre-pi-en-ligne-de-commande-sous-linux/ 
supposing you have the size of file1 in the variable file1_sz and your head implementation supports the (non-standard) -c option:  if head -c "$file1_sz" file2 | cmp -s - file1; then     echo "file1 is a prefix of file2" else     echo "file1 is not a prefix of file2" fi  
the size of the affinity bitmask depends on the number of supported cpus in your kernel, not on the number of cpus actually present in your system; at runtime though, only the bits corresponding to a cpu present are taken into account
without extglob:  for d in */ ; do     if [ "$d" != "lib/" ]; then         cp -r lib "$d"     fi done   or just delete it afterwards..
you are missing the space between {} and ; :  find 
this information can be retrieved from the iserial entry of the verbose output of the lsusb
first of all, your given configuration of the default gateway is not valid
you need to install grub to all 3 drives using grub-install. 
one possible solution may be:  diff -s $first_file $second_file &gt; /dev/null if [ $? -eq 0 ]; then     echo "the files are identical" fi   note: it changed the question text. 
to execute shell commands inside your docker container run:  $ docker exec -it erddap bash   this will take you into the docker container at /opt/tomcat
the ^d character (aka \04 or 0x4) is the default value for the eof special control character parameter of the terminal or pseudo-terminal driver in the kernel (more precisely of the tty line discipline attached to the serial or pseudo-tty device)
the easiest way is probably to tee the message to stderr as well as stdout:  echo "script finished on date" | tee /dev/stderr \     | /usr/bin/mail -s "script complete" "myaccount@myserver.com"   tee duplicates its input to multiple destinations, including stdout
similar to your approach,  docker exec -i my_container dd of=file &lt; file_on_host   which gives you a nice status summary and doesn't write the data to stdout.  there are probably a few other options, e.g., cp /dev/stdin file (which might not work, depending on whether your container's os supports /dev/stdin) and sh -c "cat &gt; file". 
if you can easily alter the program so that it drops its privileges, then this is the best approach
if the operations are comparable to openjdk v6-b14, the pid will be available to ps when scanning the /proc virtual file system
we have found the solution on code review:  setxkbmap -option numpad:mac   so far, i don't see any crippling of my key mappings. 
perl encourages library authors to include documentation in pod format in each source file
you could switch the irssi process to use tmux, instead of the login process. 
you could run into trouble storing large files in memory, this is slightly better as it only stores matching lines, after sort has done the heavy lifting of putting the lines in order.  # input must be sorted first, then we only need to keep matching lines in memory # once we reach a non-matching line we print the lines in memory, prefixed by count # with awk, variables are unset to begin with so, we can get away without explicitly initializing { # s2, s3, s4 are saved field values   if($2 == s2 &amp;&amp; $3 == s3 &amp;&amp; $4 == s4) {     # if fields 2,3,4 are same as last, save line in array, increment count     line[count++] = $0;   } else {     # new line with fields 2, 3, 4 different     # print stored lines, prefixed by the count     for(i in line) {       print count, line[i];     }     # reset counter and array     count=0;     delete line;     # save this line in array, increment count     line[count++] = $0;   }    # store field values to compare with next line read   s2 = $2; s3 = $3; s4 = $4; } end{ # on eof we still have saved lines in array, print last lines     for(i in line) {       print count, line[i];     } }     it is customary to save awk scripts in a file. you could use this along the lines of sort -k2,4 file | awk -f script  3 id-fred   4.0  6.0  42.0   3 id-jacob  4.0  6.0  42.0   3 id-tessa  4.0  6.0  42.0 2 id-elsa   5.0  8.0  45.0   2 id-trudy  5.0  8.0  45.0   1 id-gerard 6.0  8.0  20.0    
&gt; is redirection to a file
i don't know about ack-grep but you can use find to exclude files larger than 3mb.  find 
assuming you mean the location that journald writes to, i think not
a foreground process does not necessitate user interaction
try doing this :  du -s dir   or  du -sh dir   needs -h support, depends of your os.  see   man du  
the cpio block skip method given doesn't work reliably
the traffic is going over the lo interface.  when an ip is added to a box, a route for that address is added to the 'local' table
1
it is not grep changing the output
 perl -le 'print while $_=getpwent' | sort   will give you the list of user names.   ps -eo user= | sort -u   will give you a list of user names whose corresponding uids are the effective user ids of at least one process running.   who | awk '{print $1}' | sort -u   will list the users currently logged in   printf '%s\n' "$@" | sort -u   will list the users passed as argument to your script.  now that you have those 4 lists, you can use the comm command to select which of those are common to any two given lists or appear in one but not the other.  with a shell supporting process substitution, you can also do without creating temp files.  for instance:  #! /bin/bash - comm -12 &lt;(printf '%s\n' "$@" | sort -u) \          &lt;(ps -eo user= | sort -u)   called as:  ./my-script root mythul stephane   will report which of those 3 users have running processes (assuming there's a one-to-one relationship between username and uid on your system). 
if you're using systemd you should be able to set it up as a service
i definitely prefer the edit #3 solution (see bellow).  if its not in the same shell use a while loop with condition on ps -p returning true
original answer  the gnupg plugin for vim does this:     this script implements transparent editing of gpg encrypted files
there are number of tools that will do this:    identify from imagemagick jhead jpeginfo some versions of the file command   if these programs are not installed, note that both jhead and jpeginfo are quite simple and presuming a compiler is available will be easy to build in your own user account. 
if you make both the ssd and the hdd (or partitions on them) lvm physical volumes, you put them in the same volume group, and you start creating logical volumes, then lvm will fill one of the physical volumes first, then it will start on the other one
a floppy device file is a file
looks like every mount sub-point must be exported by the nfs server in order to be visible for clients
the no shell way,  a a. . s/a//  
on linux: as root, iterate   su &lt;username&gt; -c 'echo $varname' --login    over all relevant usernames
in the long description of the many variants of how to include and exclude files, there seems to be one most important sentence:   a given file is excluded by the file selection system exactly when the first matching file selection condition specifies that the file be excluded.  according to this, you need an include option for the files you want first, so they are matched there, and the first match can no longer be an exclude
without double quotes around $pingfull, it's turning multiple lines into a single line, so you're getting the first line.  also, the rtt stats are on the last line, so get rid of the head -n 5.  for myhost in $hosts; do    pingfull=$(ping -c 5 "$myhost")    pingloss=$(echo "$pingfull" | grep loss | cut -d ',' -f 3 | grep -eo '[0-9]{1,4}')    pingval=$(echo "$pingfull" | tail -1 | cut -d ' ' -f 4)    echo "$pingval"    echo "$(date "+%y-%m-%d_%h:%m:%s") / $myhost / $pingval / $pingloss"  done  
adobe reader is no longer supported by adobe on linux since 2014
i stumbled over tea4cups (in debian the package is cups-tea4cups), where one can do exactly what i want, like this:  # tea4cups.conf [myprinter] # just the cups printer name filter: mycommand # pipes everything though mycommand, like "&lt;input&gt; | mycommand | lp" # if the printer uri is prefixed with 'tea4cups://'  
i found it - but it's bad news, unfortunately
i figured out my answer; but it requires the use of systemd.  one can enable persistent journal logging by creating /var/log/journald/; once this has been done one can view long term journal logs using journalctl. 
the natural tools for this are awk and perl (assuming you want to script: for a once-off, the natural tool is an interactive editor)
it makes no sense to encrypt a file with a private key.  using a private key to attach a tag to a file that guarantees that the file was provided by the holder of the private key is called signing, and the tag is called a signature.  there is one popular cryptosystem (textbook rsa) where a simplified (insecure) algorithm uses has public and private keys of the same type, and decryption is identical to signature and encryption is identical to verification
the tags are stored in a data container located within the mp3 audio file
there are many ways to format a usb  command line  type this command in the terminal which will help you identify the usb name i.e: sdb,sdc,etc...     sudo fdisk -l   make sure the usb is not mounted, if yes then you need to unmount it:     umount /dev/sdx   replace sdx with your device name  delete any existing partitions (from the sd card only).  enter the following on the command line (replacing x with the letter identified in step   sudo fdisk /dev/sdx    list the existing partitions by typing p. delete them by issuing the d command (repeat as needed until all partitions have been removed).   create a new partition.   type n to create a new partition.  type p to create a primary partition. type 8192 to select the sector
this task is an example of "configuration management"
introduction  the basic task of a daemon providing logins is to execute one or more commands in the correct context for a user, for that system
grep "^.*:.*:$gender" information.txt | awk -f: '{print $1}' 
if your host doesn't respond to anything, then your options to communicate with it are limited
while true; do    if [ -f $file ]; then        truecrypt -d /dev/sdj1        break    fi        $sendanemail        sleep n # change n to number of seconds to pause  done   the while loop will continue to execute forever until the break statement is ran
the puppet daemon will automatically notice changes to the puppet.conf file without needing to be restarted. simply remove the subscribe  =&gt; file["/etc/puppet/puppet.conf"] from service { "puppet" ..
note: i wrote this before the "chromebook" tag was added
like this:  { grep foo file.txt; echo end of output; } &gt; output.txt   that groups commands without starting a subshell (except with the bourne shell).  you could do:  grep foo file.txt | cat - &lt;(echo end of output) &gt; output.txt   (with ksh, bash or zsh) but that creates a few more extra processes and pipes for no extra benefit. 
screen (or tmux) is the best option for this and written for exactly this purpose
try:  df -k | grep '/$'   or you can use awk:  df -k | awk '$nf == "/"'  
/bin/true and /bin/false don't have to make any system calls other than the required exit(2)
one potential approach would be to put a while...read construct inside your functions which would process any data that came into the function through stdin, operate on it, and then emit the resulting data back out via stdout.  function x {   while read data; do     ...process...   done }   care will need to be spent with how you configure your while ..read.. components  since they'll be highly dependent on the types of data they'll be able to reliably consume
pkill might work here:  $ pkill -p 1 process.pl   this kills all processes named process.pl whose parent is pid 1, which is what happens when a process's parent dies. 
while you can create a md-device on the fly and it will sync the disks, the trouble in your case is that raids usually have a superblock on the devices in question and only serve the rest as a special device
the details will depend on what exactly you want to do, but negative lookarounds might help
shared memory is not always a protected resource
if the links are to absolute paths, no there's no way around it
the traditional way to do it is:  repoquery --repoid=&lt;whatever&gt; -a --location repoquery --repoid=&lt;whatever&gt; -a --qf '%{ui_nevra} %{location}'   ...the later allowing you to see other bits of info
this is pretty trivially done, since .srt files are just text files that contain time stamps -- all you need to do is add the length of cd1.avi to the times of all the subtitles in cd2.srt
removing old logs is the main job of logrotate
you can't grant a new group to a running process. you need to log in again to get a process with the changed group memberships.  what you can do is to launch nautilus from a different session but have it display on your existing display, something like  ssh localhost "display=$display xauthority=$xauthority nautilus &amp;"  
mtr is probably the tool you're looking for
you can setup an autocommand that executes when you open a file
all devices on unix are mapped to a device file, the serial ports would be  /dev/ttys0 /dev/ttys1 ..
thanks to @gilles, i finally saw what went wrong!  in the line, load=$cpu_load_time my intention was to extract either of $1, $2 or $3 depending on the value of cpu_load_time (which would be 1,2 (or 5) or 3 (or 15)) set via command line parameters.  this of course, wasn't happening
it look like the fault unfortunately lies in the daemon which does not flush it's stdout after writing the log data.  svlogd does only line buffering so it outputs complete lines to the log file as soon as they arrive on stdin. 
those errors are harmless because you're using a jre; the missing commands are provided by jdks only
you can execute external commands in vim by using the '!' flag:  :! date   http://www.linux.com/learn/tutorials/442419-vim-tips-working-with-external-commands 
i believe that btrfs is now the preferred filesystem if you want to allocate your whole disc (or most of it) to a filesystem
the openvpn package has a script for this in /etc/openvpn/update-resolv-conf
use ctrl+u:  from bash documentation, killing and yanking:     unix-line-discard (c-u)      kill backward from the cursor to the beginning of the current line.   ctrl+u behavior is not only controlled by the shells that have their own line editor like bash, zsh, tcsh, sh -o emacs, but also by the line discipline  of the terminal driver when in canonical mode (like in cat, or basic implementations of sh/ksh when no line-editor is enabled)
it's supported by the code comment plugin (gedit-plugins in debian)
solution as root by adonis' /etc/sudoers, i did gedit /etc/sudoers  # # this file must be edited with the 'visudo' command as root. # # please consider adding local content in /etc/sudoers.d/ instead of # directly modifying this file. # # see the man page for details on how to write a sudoers file. # defaults    env_reset defaults    mail_badpass defaults    secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"  # host alias specification  # user alias specification  # cmnd alias specification  # user privilege specification root    all=(all:all) all  # allow members of group sudo to execute any command %sudo   all=(all:all) all  # see sudoers(5) for more information on "#include" directives:  #includedir /etc/sudoers.d   done! 
you can specify   0,30 * * * * /home/myuser/myscript.sh   although i was always under the impression this would be the same as */30 * ....
this is a step-by-step guide on how to compile and install pidgin and make it work with google talk (~ hangouts) on linux: the differences between hangouts and google talk you will find on this page: https://support.google.com/a/answer/4564211 1
a typo on my part was the cause of the unreasonable behavior i was experiencing above
use the status command:  $ fish -c 'status --is-interactive; and echo yes; or echo no' no $ status --is-interactive; and echo yes; or echo no yes   also, status --is-login
this is a script i wrote a while ago, in order to get a stat(1)-like utility in aix
grep supports getting patterns from a file -f, and becomes more efficient if you also specify fixed strings (-f):  grep -f -f patterns.txt "//'mvs.dataset'"  
yes, you can extract the url from the html-source and use mplayer:  $ mplayer -ao pulse mms://proedvid.stanford.edu/videocontent/knuth/musings/981203/981203-knuth-500.wmv   the playback (audio/video) works fine on a ubuntu 11.04 system.  you can automate this a bit, e.g
this operator implements a here document, which takes text from the following lines as standard input.chances are you won’t use this redirector on the command line, though, because the following lines are standard input, so there’s no need to redirect them.rather, you might use this command as part of a script in order to pass data to a command.unlike most redirection operators, the text immediately following the &lt;&lt; code isn’t a filename;instead, it’s a word that’s used to mark the end of input.for instance, typing someprog &lt;&lt; eof causes someprog to accept input until it sees a line that contains only the string eof (without even a space following it).  note: some programs that take input from the command line expect you to terminate input by pressing ctrl+d
read data is (directly) read from the cache only if it is already there
jobs  shows the jobs managed by the current shell
this is completely untested, but it's too complex to fit in a comment, so hopefully it works.  you might be able to add a post-stop stanza which will do what you want
with thunar's built-in command line switches, you can't
some sort of wrapper would handle this unusual scenario
if curl's -k is convenient for you, you might just want to use it, actually:  curl -sk https://domain.tld/path/to/image.png | feh -   the dash here will have feh read the image data from the standard input
the "controlling terminal" aka
yum remove is not guaranteed to preserve configuration files.  as stated in the yum howto:     in any event, the command syntax for package removal is:  # yum remove package1 [package2 package3...]       as noted above, it removes package1 and all packages in the dependency tree that depend on package1, possibly irreversibly as far as configuration data is concerned.   update  as james points out, you can use the rpm -e command to erase a package but save backup copies of any configuration files that have changed
i always prefer to make scripts for gnuplot over typing in shell, doing so, you don't need multiplot
there are a few options:   use #!/usr/bin/gsed -f (assuming it is in /usr/bin) as the shebang everywhere, and make sure that your linux environments symlink this properly; remove the gnuisms; symlink sed to /usr/bin/gsed from a directory that earlier than /usr/bin in the user's $path (possibly dangerous); make a wrapper script that looks something like this:   #!/bin/sh  script=/foo  type gsed &gt;/dev/null 2&gt;&amp;1 &amp;&amp; exec gsed -f "$script" exec sed -f "$script"   ultimately there either need to be changes to at least one of the environments, or changes to the script itself. 
if you want to disable echo of the commands you type, try this:  stty -echo   you can re-enable echo using this command:  stty echo   note that the output of commands will show up in a somewhat different way, see this example session:  $ pwd /tmp $ stty -echo $ /tmp   this resulted from typing pwd, return, stty -echo, return, pwd, return. 
one solution would be a script, which changes permissions on that files using chmod and then setting you system so it would start the script on system bootup. 
if you are using apache check your httpd.conf and/or ssl.conf and add the appropriate lines.  from httpd.conf:  ##ssl sslcertificatefile /etc/certs/example.com.crt sslcertificatekeyfile /etc/certs/example.com.key sslcertificatechainfile /etc/certs/intermediate.crt   from ssl.conf  sslcertificatefile /etc/certs/example.com.crt sslcertificatekeyfile /etc/certs/example.com.key sslcacertificatefile /etc/certs/intermediate.crt   make sure permissions are correct!! permissions from /etc/certs:  -rwxr-xr-x   1 root root 1.7k oct  8 04:26 example.com.crt -rw-r--r--   1 root root 1.1k oct  8 04:15 example.com.csr -rw-------   1 root root 1.7k oct  8 04:35 example.com.key -rw-r--r--   1 root root 1.5k jul 27 19:20 intermediate.crt   other server configs can be found here: https://www.startssl.com/?app=20 
have you tried this? ftp://download.nvidia.com/opensuse/12.1/i586/ 
:~&gt; echo 123456 | rev 654321   it should work. the usage is pretty simple
you can use this to strip the first two lines:  tail -n +3 foo.txt   and this to strip the last two lines:  head -n -2 foo.txt   (assuming the file ends with \n for the latter)    just like for the standard usage of tail and head these operations are not destructive
1
have a look at this opensuse forum thread
actually after searching for long i found this solution:  /usr/local/nagios/libexec/check_nt -h &lt;host&gt; -p &lt;port&gt; -v &lt;command&gt; -l &lt;value&gt;    so i have used this in my script as :    /usr/local/nagios/libexec/check_nt -h $myhost -p 12489 -v cpuload -l 5,80,90,10,80,90 /usr/local/nagios/libexec/check_nt -h $myhost -p 12489 -v useddiskspace -l c /usr/local/nagios/libexec/check_nt -h $myhost -p 12489 -v memuse  
this will disable bluetooth service on startup:  # bluez - bluetooth daemon  description     "bluetooth daemon"  #start on started dbus stop on runlevel [0123456]   it seems that an error occured when you edited bluetooth.conf file
perl comes with a rename(1) command that is installed on most linux systems
instead of an alias, use a .curlrc file in ~zabbix
lintian is a quality assurance tool that runs automated checks on various aspects of packages conformity to the debian policy
put this:  ulimit -c unlimited   into file     /etc/profile   this may not work on all distros.  also read this articles:  http://en.linuxreviews.org/howto_enable_core-dumps  http://www.akadia.com/services/ora_enable_core.html 
found it
in case you are using gnu coreutils
when it comes to streaming media and sharing files, you have several options
as this command:  shopt -po xtrace   will generate an executable string that reflects the state of the option.  then, you may set a variable to its output, and execute the variable at the end of the script to get back.  # store state of xtrace option. tracestate="$(shopt -po xtrace)"  # change xtrace as needed echo "some commands with xtrace as externally selected" set -x echo "some commands with xtrace set"  # restore the value of xtrace to its original value. eval "$tracestate"     it is important to note that the solution above works for several options:  oldstate="$(shopt -po xtrace noglob errexit)"  # change options as needed set -x set +x set -f set -e set -x  # restore to recorded state: set +vx; eval "$oldstate"   adding set +vx avoids the printing of a long list of options.    if, for some reason, it is preferred to test the state of an option, the most idiomatic way (for bash) to test if an option is set is:  [[ -o xtrace ]]   which is better than the other two similar tests:   [[ $- =~ x ]] [[ $- == *x* ]]   with any of the tests, this works:  # record the state of the xtrace option in ts (tracestate): [ -o xtrace ] &amp;&amp; ts='set -x' || ts='set +x'  # change xtrace as needed echo "some commands with xtrace as externally selected" set -x echo "some commands with xtrace set"  # set the xtrace option back to what it was (yes unquoted!). eval "$ts"     posix  if you are limited to do it in a posix compatible way, you may use this:  # record value of xtrace: [ "$(expr "$-" : '\(.*x\)')" ] &amp;&amp; ts='set -x' || ts='set +x'  # set it back to what it was: eval "$ts"   that solves the case of changing only one option
don't have a solaris box handy, but wouldn't something like zcat file.tar.gz | tar -tv do the trick? that might need to be gzcat or gunzip -c on solaris, i'm not sure.  update: @riccardo murri points out that the default behavior of tar on solaris is not to read from stdin (which seems very un-unixish, but ce la vie), so zcat file.tar.gz | tar -tv -f - is probably what you need.  update 2: finally found what looks to be a decent site for solaris man pages, so i present to you man gunzip and man tar. 
the drivers start to appear in newer kernels. here is the problem: https://bugzilla.kernel.org/show_bug.cgi?id=109081  in case anyone wants to buy this laptop to use with linux, wait for that bug to be fixed before doing so.  answering to the question:  it would be a good idea to return the laptop if you had the same situation
definitely, the bundle-gem online manual was created from the bundle-gem.ronn file
the shell knows that ssh died and can reset the terminal.  tracing a bash shell while i kill a child ssh shows that it makes several ioctl() calls.  --- sigchld (child exited) @ 0 (0) --- ioctl(255, tiocspgrp, [52631])          = 0 ioctl(0, tiocgwinsz, {ws_row=25, ws_col=147, ws_xpixel=902, ws_ypixel=329}) = 0 ioctl(0, tiocswinsz, {ws_row=25, ws_col=147, ws_xpixel=902, ws_ypixel=329}) = 0 ioctl(0, sndctl_tmr_timebase or tcgets, {c_iflags=0x500, c_oflags=0x5, c_cflags=0xbf, c_lflags=0x8a3b, c_line=0, c_cc="\x03\x1c\x7f\x15\x04\x00\x01\x00\x11\x13\x1a\x00\x12\x0f\x17\x16\x00\x00\x00"}) = 0 ioctl(0, sndctl_tmr_stop or tcsetsw, {c_iflags=0x400, c_oflags=0x5, c_cflags=0xbf, c_lflags=0x8a31, c_line=0, c_cc[vmin]=1, c_cc[vtime]=0, c_cc="\x03\x1c\x7f\x15\x04\x00\x01\x00\x11\x13\x1a\x00\x12\x0f\x17\x00\x00\x00\x00"}) = 0  
in bash, you can use bash's built in string manipulation
it does not work because you are cating blah.png into sudo, which is not a valid password.  this should combine the needed commands onto one line:  scp ~/desktop/blah.png trusktr@50.116.4.56:~/ &amp;&amp; ssh -t -t trusktr@50.116.4.56 "sudo cp ~/blah.png /path/to/blah.png &amp;&amp; rm ~/blah.png"  
i assume the client machine is running linux.  linux has the ability to create multiple views of all or part of the same filesystem
you are probably using vi-like key-bindings in zsh without knowing it.  zsh chooses the default keyboard mode by looking at $visual and $editor
ok, solved!   get kiwi to build a cd that works in bios mode
aix sed does not understand escape sequence characters, as the aix sed document said, it only know ascii characters
assuming you have a kernel with the debugger option compiled in you can use controlaltescape
you only need:  sort -rnk1 file | awk '{print $1}' | uniq -c | sort -nk2   or if you only have number in first field:  sort -rnk1 file | tr -cs 0-9 '[\n*]' | uniq -c | sort -nk2  
i added   helpdesk:         "|/usr/bin/rt-mailgate --queue 'helpdesk' --action correspond --url http://localhost/rt"   in /etc/aliases and now receiving mails which are designated to helpdesk@doamin.lcl in rt 
i always thought that would not be a good idea
if you read the cron documentations you will see that you need to use command crontab -e and enter record like:  0 23 * * * /path/to/executable  
i wrote a script to solve this
you probably are looking for virtualenv or pyenv or some other non-system-wide method to install python
debian has a number of task-* packages, that are empty (no content), but provide dependencies to packages to fullfill a given task.  to get a neat desktop system do   aptitude install task-desktop  
in your case you're calling it from a for loop so you aren't really running anything in parallel
i came across this one tool called ttylog
for f in *.fmb; do printf '%s\n' "${f%.*}"; done    using pattern matching *.fmb to match all files end with .fmb ${f%.*} is shell syntax for parameter expansion, remove the smallest suffix matched pattern in $f
presuming that you have a dhcp server set up on your internal network, all you should need to do is to configure the vmware virtual nic to be in bridged mode; this tells vmware to act as a virtual bridge with respect to any packets the virtual machine sends out
you can do this using pam and the pam_exec.so module.  you simply add a line to /etc/pam.d/sshd to the 'session' section such as the following:  session    optional    pam_exec.so /usr/local/bin/ipset-ssh   where ipset-ssh is some script you create.  the script will be run as root
in gnome and other freedesktop.org-compliant desktop environments, such as kde and unity, applications are added to the desktop's menus or desktop shell via desktop entries, defined in text files with the .desktop extension (referred to as desktop files)
well typically mass storage devices such as usb thumb drives are mounted using a command, mount
i give up trying this
you have to change the color of your cursor line to a color other than the color of your cursor
yes, you may write an udev rule.  in /etc/udev/rules.d make a file 30-mydevice.rules (number has to be from 0 to 99 and decides only about the script running order; name doesn't really matter, it has just to be descriptive; .rules extension is required, though)  in this example i'm assuming your device is usb based and you know it's vendor and product id (can be checked using lsusb -v), and you're using mydevice group your user has to be in to use the device
that's the same as:  [ `echo hi` ] &gt; /dev/null   redirections may appear anywhere on the line.  under normal condition, it is the same as  [ hi ]   which itself is the same as:  true   that is a command that doesn't output anything and returns a success exit status.  the outcome may be different if:   the redirection fails, for instance if you've reached the limit of open files or haven't write access to /dev/null (which again shouldn't happen under normal conditions)
   i found no reliable way to detect if the internet connection is down, other than periodically pinging a bunch of external hosts that are known to be up most of the time
there are a number of ways of redirecting a command's standard input (stdin):   command &lt;file  simple redirection: stdin will be the file command &lt;&amp;n  duplicate other fd: stdin will be a duplication of fd n command &lt;&lt;word  here doc: stdin will be the script up to word other | command  pipe: stdin comes from the output of other   since there is only one stdin, only one redirection to stdin can be effective
you can use a while loop with process substitution:  while read -r line do     echo "$line" done &lt; &lt;(jobs)   to read a multiline variable, a simple way is:  # you need printf '%s\n' "$var" here because if you use printf '%s' "$var"  # on a variable that doesn't end with a newline then the while loop will # completely miss the last line of the variable. printf '%s\n' "$var" | while ifs= read -r line do    echo "$line" done   also, please don't call your variable jobs because that is a shell command and may cause confusion. 
zipinfo -1 zip.zip '*.doc'   works for me, displaying all files in sub-directories
sudoers file  you should be able to do any of these.   such as this:  john all=(all) nopasswd: sudoedit  or this:  john all=(all) nopasswd: sudoedit /path/to/file  lastly you could do it like this too:  cmnd_alias somecmd = sudoedit /path/to/file john all=(all) nopasswd: somecmd    once you have one of these definitions in place you invoke it like so:  sudoedit /path/to/file   details  you don't need to invoke it with a sudo command prefix like this:  sudo sudoedit /pat/to/file   it takes care of the sudo automatically
try to look at this similar question of turning your default file-manager into nautilus:  http://askubuntu.com/questions/47208/how-to-stop-thunar-being-default-file-browser  you should be able to remove thunar completely by running following command:   sudo apt-get purge thunar*  
you could try  pargs &lt;pid&gt;   this gives you a list of all arguments  or else use an other ps
i was just looking into this - and i tried the same thing: created /etc/lxdm/loginready from scratch, chmod +x-ed it, and inserted a logger statement in the script
you can use find:  find /usr -name '0914_jul-2014.gz' -exec mv {} /var/tmp \;   or for extremely nested directory hierarchies  find /usr -name '0914_jul-2014.gz' -execdir mv {} /var/tmp \;   although as the documentation states you must ensure that  your  $path environment  variable  does not reference the current directory (namely .) if you use -execdir 
for bash, maybe:  ..
can't you use self-contained zip/tarball from http://www.rstudio.com/ide/download/desktop? you don't have to install it, just download it, unpack it and go to bin folder and run rstudio
you can use backreference:  $ printf 'bbb\nb2b\n' | sed 's/^b\([0-9]\)/xxx\1/' bbb xxx2b   (btw, you don't need the g  flag since that regex can match only once because of the ^). 
ctrl-h is backspace, it moves the cursor one step to the left
find / -xdev -name "zi??????" -ctime -1  
use lsblk to list block devices
if you use egrep that mean grep with extended regexp syntax so to be able to transfer your pattern into sed you have to add parametr -r(--regexp-extended) or -e in some versions.  regarding to your expression you have extra \ after c so even with egrep it does not match  additionally your better use \1 instead $1 for reverse-matching.  so final command could be:  sed -rn 's:\./(rff.*)( .* -c)\$\{cond\}:./\1\2\1:gp'   or  sed -rn 's:(\./(rff\s*) \s* -c)\$\{cond\}:\1\2:gp'  
cross-compiling may be the solution for you it allows you to compile executables for one architecture on a system of a different architecture
older versions of linux kernel (&lt; 3.x)  found this thread which describes downloading the rtl8188ee wireless nic drivers, compiling them, and installing them.   realtek rtl8188ee laptop wi-fi does not work on xbuntu 12.04   excerpt of steps   download drivers from realtek site unzip, build, &amp; install  $ tar jxvf linux_mac80211_0012.0207.2013.tar.bz2 $ cd ~/desktop/rtl_92ce_92se_92de_8723ae_88ee_linux_mac80211_0012.0207.2013 $ make $ sudo make install  load the kernel module (driver)  $ sudo modprobe -v rtl8188ee    newer versions of linux kernel (> 3.x)  this driver appears to already be included
bash does cache the full path to a command
the ctime is a firm indication of the latest date at which the software might have been installed: it was installed no later than 2013-01-23
you're looking for the ignoreeof environment variable if you use bash:  ignoreeof      controls the action of an interactive shell on receipt of an eof character as the sole input.         if  set,  the  value  is  the number of consecutive eof characters which must be typed as the         first characters on an input line before bash exits
since the question is very precise, the answer is short  var=$(rm -vri files | wc -l)  update  just in case one has more interest on the subject, here is the link to command substitution 
as you found out, apt-file only searches the filenames in binary packages
run it with nice -n 20 ionice -c 3  that will make it use the remaining cpu cycles and access to i/o not used by other processes.  for ram, all you can do is kill the process when it uses more than the amount you want it to use (using ulimit). 
you can source that file in bash (or any bourne-like shell) to set them as shell variables:  source /etc/lsb-release sudo add-apt-repository "deb http://some-repo/ubuntu $distrib_codename main"  
you can do it with sed and awk:  $ sed 's/[^"]//g' dat | awk '{ print length }' 2 0   where dat is your example text, sed deletes (for each line) all non-" characters and awk prints for each line its size (i.e
see this serverfault answer: after updating with apt-get, you can check for the presence of /var/run/reboot-required
you can use script, which is run automatically every time you boot
the pinning of experimental and backport is in the repository itself (in the release files)
obviously, i wouldn't recommend deleting the old install until you're sure but it shouldn't be too hard to get a very similar install on a newer version of linux  you can dump out the list of installed packages with dpkg --get-selections and install them with dpkg --set-selections, this question on au talks about the possible pitfalls of that, but has the commands as well.  any user customisations should be in /home/username/ so you can create a new user with a same name, and copy over the files
try systemd-run:  # systemd-nspawn -d &lt;machine-root&gt; -b 3 --link-journal host  # systemd-run --machine &lt;machine-name&gt; env running as unit run-1356.service.  # journalctl --machine &lt;machine-name&gt; -u run-1356 -b -q oct 30 07:45:09 jessie-64 systemd[1]: started /usr/bin/env. oct 30 07:45:09 jessie-64 env[37]: path=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin   excerpt from the manpage:     use shell (see below) or systemd-run(1) with the --machine= switch to directly invoke a single command, either interactively or in the background.   (the command shell available since v225) 
$ echo oracle.2347263_testing_152607.csv | sed -e 's/oracle.\([[:digit:]]*\)_.*/\1/' 2347263  
for most commands a wrapper will have to be written because syslog-ng will only execute the command when it starts
mpv provides --aid, from the manual:  --aid=&lt;id|auto|no&gt;        select audio track
like the comments in this answer suggest, just edit the file /etc/shadow as root (e.g
add the --perm ( or -p ) option
 ;: commands separated by a ;  are  executed  sequentially
this question may be old, but i think i have found the perfect solution.   go to system settings > window behaviour > window rules add a new rule mark all window properties as 'unimportant' select all 'window' types like in the screenshot  in the tab 'size &amp; position', tick 'activities' and configure it as 'apply initially' and 'all activites', like in the screenshot  click 'ok'   this should set all windows to be on all activities by default. 
i think you're seaching in a wrong way
found my own answer in the keymaps man page
first off, fsck'ing a mounted filesystem is expected to produce errors
how i understand op there are some blocks of text which separated by empty lines and op wants to remove every duplicates:  awk -v rs='\n\n' -v ors="\n\n" '!seen[$0]++' file   if op wants to just remove the block try it via gnu sed:  sed -z 's~recursive-test yes;\ntest-limit{\ntests 10;\n};\nlocation "testloc" {\ntype test;\n};\nlocation "testloc2"{\ntype test;\nfile "/etc/var/test.sql";\n};\ninclude "/etc/var/test.conf";\n};~~g' file  
ok this was just stupid, and i found out using set -- will work. 
since partition e: is, and partition and f: is almost empty, you should (under windows) move what data you need that is on f: to c: and then delete the e: and f: partitions
both ssh_config (client configuration) and sshd_config (server configuration) have a ciphers option that determine the supported ciphers
in  ssh host tail -f file   the ssh client connects to the sshd server on host over a tcp connection
there are two main methods
use -d '\n' with your xargs command:  cat file | xargs -d '\n' -l1 mkdir   from manpage:  -d delim               input  items  are  terminated  by the specified character
native support  since ubuntu 11.04 and debian wheezy (7.0), debian and ubuntu have multiarch support: you can mix x86_32 (i386) and x86_64 (amd64) packages on the same system in a straightforward way
^c send the interrupt signal, which can be handled by a program (you can ignore it)  kill -9 send the sigkill signal which kills the program that you can't handle.  that's why you can't kill some programs with ^c 
if you're using debian or ubuntu you can run the checkarray script:  /usr/share/mdadm/checkarray /dev/mdx   where mdx above is your array device.  remember to unmount the filesystem first.  note, that the inconvenience of remembering and / or writing the whole path to the script can be easily avoided by e.g
you can append a / to the destination if you want to move files to a directory
rather than using system-wide /etc/fstab, i suggest using afuse
assuming that the service file actually exists, you should be able to launch it with systemctl start ipsec
the mistake was:  rc=$( curl ..
gnu find supports the -printf predicate, which supports the %f format specifier for outputting on the filename.  find -type f -name "*.c" -printf '%f\n'  
in my endeavor with linux sound i have ended up disabling autospawning of pulse audio (so it doesn't restart when shut down):  add autospawn=no to ~/.pulse/client.conf
you can have as many awk rule-action pairs as you like
in zsh:  first set hist_ignore_space in your profile and then prefix the commands you don't want stored with a space.  from the man page, the following 3 options can be used to say that certain lines shouldn't go into the history at all   hist_ignore_space don't store commands prefixed with a space hist_no_store don't store history (fc -l) command hist_no_functions don't store function definitions  
pick_host is called with "$hosts", i.e
you can tell grep to only output the filenames of files matching the search parameters, using the -l option:  function edsch {   l=$(grep -l --include "*.ebuild" -r "$1" /usr/portage/$2)    for i in ${l[@]}   do     atom $i   done }   this will produce the output you're looking for and open the appropriate files with atom. 
you may try to extract the values with grep and sed
the answer is in this thread....  exerpt:  therefore, the steps would be like this:   shrink the /home "filesystem"
you can't force a shell process to use new aliases from the outside, so the request to load the new aliases will have to come from each shell instance on each terminal.  you can make bash execute code after each command by putting that code in the prompt_command variable
here the issue is that you are surrounding the variable with double quotes ("")
cat file.json | json_pp  #perl utility cat file.json | jq 
that program probably resolves the path to that file from $home/.config/myprogram
emacs doesn't come with a mode that can create all those effects (although you can get some of them with enriched mode)
the problem is your (default changing) setting  client=yes   but you need stunnel in server mode, i.e
two answers:  a short one:  you want to use this vim script
fhs v2.3 was released ten years ago
which firmware are you talking about?  if it is the obp version that you're looking for, prtdiag -v will help you in most cases:  system prom revisions: ---------------------- obp 4.16.1 2004/09/03 04:22 sun fire v210/v240,netra 240 obdiag 4.16.1 2004/09/03 04:23     the output of prtconf -pv may also have relevant sections:  node 0xf002ce38     version: 'obp 4.16.1 2004/09/03 04:22'     model:  'sunw,4.16.1'     aligned-allocator:       relative-addressing:       name:  'openprom'  node 0xf0094d50     sunw,location:  'u55'     model:  'sunw,254-0078'     version: 'obp 4.16.1 2004/09/03 04:22 sun fire v210/v240,netra 240' + 'obdiag 4.16.1 2004/09/03 04:23  ' + 'post 4.16.1 2004/09/03 11:38'     name:  'flashprom'     compatible: 'isa-flashprom'  
not exactly
&gt; writes to a file, overwriting any existing contents
from utmp(5):  the system time has been manually or automatically updated (see date(1))
in order for the pin to be cached you need to run gpg-agent and your card should not have the forcesig bit set.  afaik, by default, the cards are shipped with the forcesig bit set, which is more secure
according to the varnish documentation, it's varnishd -v 
from the long comment chain, it appears that ntfs-3g (or possibly fuse) doesn't fully support 100ns timestamps, or at least the version in ubuntu 12.04 does not
you can use python's csv module.  a simple example:  import csv reader = csv.reader(open("test.csv", "rb")) for row in reader:     for col in row:         print col  
try   awk 'nf==3' file.txt   this will grep line with 3 field (nf). 
according to man time you should be able to use -o file to output to a file and -a to append to the file
the dummy way:  whereis -b crontab | cut -d' ' -f2 | xargs rpm -qf  
there really isn't any such command
apparently there is no way to check what tmux depth you are currently on
parsing the output of ls is not reliable.  instead, use find to locate the directories and sort to order them by timestamp
assuming a zip archive, as commonly found on ms‐dos systems, under a unix command line prompt one might do:  % unzip -p -a files.zip | awk ...   where the ellipsis are replaced by your arguments to awk
your processor does not support so many counters and too frequent switching between them, i guess.  you see in the last example the last column, where the counters are multiplexed (counted only over 33% of the time)
it is documented in the help, the node is "edit menu file" under "command menu"; if you scroll down you should find "addition conditions":     if the condition begins with '+' (or '+?') instead of '=' (or '=?') it   is an addition condition
you don't need to be root to start a user-scoped group with systemd-run:  $ systemd-run --user --scope /bin/bash    running scope as unit run-23318.scope.   $ sleep 999 &amp;   [1] 23369   you can see the unit:  $ systemctl --user status run-23318.scope * run-23318.scope - /bin/bash   loaded: loaded (/run/user/1000/systemd/user/run-23318.scope; static;           vendor preset: enabled)  drop-in: /run/user/1000/systemd/user/run-23318.scope.d       `-50-description.conf   active: active (running) since sun 2016-07-17 08:16:51 cest; 10min ago   cgroup: /user.slice/user-1000.slice/user@1000.service/run-23318.scope       |-23318 /bin/bash       `-23369 sleep 999   jul 17 08:16:51 home systemd[1056]: started /bin/bash.   jul 17 08:16:51 home systemd[1056]: starting /bin/bash.   and also with   $ systemd-cgls /user.slice/user-1000.slice/user@1000.service/run-23318.scope    /user.slice/user-1000.slice/user@1000.service/run-23318.scope:    |-23318 /bin/bash    `-23369 sleep 999  
check the mono:factory project in obs - it's not considered stable yet
you have a couple options.  first, you can launch it in screen and then ctrl-a out of the screen after it launches
accept their public key
this should do what you want:  curl https://launchpad.net/ubuntu/+ppas?name_filter=pipelight |  awk -f/ '/&gt;pipelight&lt;/{print $2}'   explanation:  the -f/ sets the filed delimiter to /, and the /&gt;pipelight&lt;/ means "run the commands in the {} only on lines matching &gt;pipelight&lt;
your proposed solution is correct
assuming the goal here is to find the lowest number divisible by integers 2 through n, trying to check every integer is massively inefficient
add 64x64 image to your homedir:  ~/.face.icon   or symply make symlink  ln -sv /var/lib/accountsservice/icons/[icon file] ~/.face.icon  
ghost4linux is what you are looking for! 
host 192.168.0.100           # and/or preferred aliases     hostname 192.168.0.100   # if 'host' is alias rather than actual hostname/ip     user herusename     forwardx11 yes     forwardx11trusted yes     ..
rpm has native support to download a package from a url
after getting a working .pac file and experimenting, i found that the file was re-downloaded when i killed the web browser and re-opened it again
while syntax is  while ( cond ) expr ;   you cannot add a ! before (  on a side note, this question would have better fit stackoverflow. 
if the remote user is using bash then $home/.bashrc should be loaded, even in non-interactive shells
zombie processes are already dead
the access to a vfat partition often gets implicitly set to read-only when there are access/read errors
first, a clarification:     it requires to have root privilege to change permission to a file
you can use pgrep with the -x flag:  kill -9 $(pgrep -x p1)   or better, with pkill you can do this:  pkill -9 -x p1   with bsd pkill:  pkill 9 -x p1  
this kind of problems is usually handled by having two stand-alone binaries: the service daemon and the user interface that communicate over a unix domain socket (or a network socket in case they are not running on the same machine)
personally, if my regular expressions were approaching this level of complexity, i would just switch the whole operation to perl
it's not possible to start a process without it being the child
after starting an ssh session, other sessions can write there too, by writing to /dev/pts/&lt;n&gt;
i'm inclined to say there is no easy way to do this
you can apply your current .config to a newer version of the kernel; they're tagged, and the make system will update it appropriately without changing what you have -- that's not a guarantee, of course; there may be some kind of incompatibility that requires a change
try first to convert it into an iso file, with mdf2iso (you have to install it) like this :  mdf2iso your_file.mdf   linux cannot mount mdf file (which is a closed format) natively. or, you can try to rename it into "your_file.iso" and mount it with the command you gave, but it's not working with every mdf image
so you want the virtual packages (?virtual) that are provided by (?reverse-provides()) an installed package (?installed)
as ckhan mentioned, jstack is great because it gives the full stack trace of all active threads in the jvm
you need a version of vim that was compiled with x support
from the bash man page:     ((expression))           the expression is evaluated according  to  the  rules  described           below  under arithmetic evaluation
if using gnu find, you can do  find /path -path '*/.*' -ls | tee output-file   edit  to avoid to show non-hidden items contained in hidden directories  find /path -name '.*' &gt;output-file   (as noted, tee could be avoided if you do not need to see the output, and -ls option should be used only if required). 
it doesn't make sense to add a value only if it is 1
you can find the centos 7/7.1/7.2 repos at http://mirror.centos.org/centos/7.2.1511/. 
this is documented in /usr/share/doc/base-passwd/users-and-groups.txt.gz:     sync      the shell of user sync is /bin/sync
of course you have to read the file, but you could  ssh user@remote "cat file" | xclip -i   of that still means to open a ssh connection and copy the contents of the file
/dev/random is not standardized
phpstorm should use the same permissions as the user that runs/ launches the script (yourself)
if you do not use a proprietary display driver with its own display controls, you can open gnome-control-center (e.g
i don't think that there is a concept of "directory created by system"
there are several reason why the output of ls would blink
openvswitch is a virtual switch
if your system has the shuf command  echo 1 2 3 4 5 | xargs shuf -n1 -e   if the input doesn't really need to be echoed via standard input, then it would be better to use  shuf -n1 -e 1 2 3 4 5  
varname='*'   though you have to be careful with where you use it; since globbing occurs after variable expansion, if you expand it carelessly it'll do the glob operation at expand-time instead
the only way i have found to do this, in regards to the filesystem change, is by working at the file level
bash uses c-style strings internally, which are terminated by null bytes
another way with tr+sed:  tr -s \\n &lt;infile | sed '$!g;s/question nr.*/\\item/'   tr squeezes all newlines and then sed appends hold space content (empty newline) to each line except the last one, replacing question nr.* with \item
all you need to retrieve the selections is the status file (from /var/lib/dpkg/status or one of its backups, /var/lib/dpkg.status*), and an updates directory alongside it
any time you have multiple processes outputting to the same terminal (or file) in parallel, you run the risk of their output getting interspersed (unless you arrange to do some sort of locking or use low-level system calls like write to files opened in append-only mode).  as a first step, you can minimize, but not totally eliminate, the problem by having each shell invocation use command substitution: run the whois command as a subprocess, capturing its output, then output everything combined into one printf operation.  xargs -0 -n 1 -p 3 -i %% sh -c 'printf "\n%s\n%s\n%s\n" " 44rbegin whois record -- " "$(whois -h whois.arin.net %%)" " 44rend whois record -- "'   even better, if you have the flock program available, you can use it to lock each call to that combined printf:  xargs -0 -n 1 -p 3 -i %% sh -c 'who="$(whois -h whois.arin.net %%)"; flock /tmp/who.lock printf "\n%s\n%s\n%s\n" " 44rbegin whois record -- " "$who" " 44rend whois record -- "'  
fast and crude guess:   permission denied
if you want genext2fs, it's easy to find; build it from source
inotify is an internal kernel facility
assuming you are using the "usual" bash with emacs bindings, using ctrlw should work.  to delete three words either press ctrlw three times or preceed it with alt3 or esc3.  for more shortcuts have a look at this list. 
the special variable a contains the result of the last answer  -&gt; 1 + 2  = 3 -&gt; a + 5  = 8 -&gt;    from the wcalc readme file     some special notes about variables - two things are reserved:          a - this variable represents the last answer, and may be used in expressions
a single error number, enospc, is used to report both situations, hence the same error message.  to keep compliance with the iso c and posix standards, the kernel developers have no choice but to use a single error number for both events
just use redirection operator &gt; at the first line:  sqlplus -s "/nolog" &lt;&lt;eof &gt;logfile conn / as sysdba @?/sqlpatch/19282021/postinstall.sql exit; eof   you can also write &gt;logfile at the beginning of the line, what is equally legal syntax in most shells, but less commonly practiced.  &gt;logfile sqlplus -s "/nolog" &lt;&lt;eof conn / as sysdba @?/sqlpatch/19282021/postinstall.sql exit; eof  
you must boot the mac into single user mode and change an admin user's password from the command line
you could try invoking x11vnc (this would be in addition to the vnc server already running that your attempting to connect to)
the xorg.conf file exists in /etc/x11.
if your file is saved as $filename, these will all give you the 4th directory
if you use bash and pipes, and are looking for an easy and dirty solution, you can try using sleep.  you can use this which act like cat but with a pause at each line
if you want to check order of actions use:  udevadm monitor --property   by doing this you get a listing of actions
your provided url downloads fine using for example:  wget "url" curl -o "url"   as mentioned in comments: quote
since the find arguments are positional a function would be a better solution.  find(){   command find "$1" -regextype posix-egrep "${@:2}" }   since you want to "overwrite" the original command you need to use the full path of find so that your new function doesn't create an infinite loop of calling itself.  by using a function instead of an alias we can use positional argument variables ($1-$n)
the first one is einval (a standard posix c error) inverted
on the links you posted about tracking /var/log/dmesg, it's only discussed on the first one, but i don't think this is really even the primary focus of these articles
what did $? say? usually, checking the return value helps
you can use the getent command with the hosts parameter like this:  getent hosts www.google.com   and count how many results this gets:  getent hosts www.google.com | wc -l   getent uses the name service switch libraries to do various name lookups
this comes from automake, specifically from its am_sanity_check macro, which is called from am_init_automake, which is normally called early in configure.ac
i stumbled upon a quite reasonable explanation today
in zsh, unlike other bourne-style shells, the results of a variable substitution are not split into words that are interpreted as wildcard patterns
the value of the make variable projname is  `pwd | grep -op '(\w|-)+' | tail -n 2 | head -n 1 | tr '[:upper:]' '[:lower:]'`   the backquote character is not special in make
press altf2 to run a command and then enter gksu nautilus (using gksu is the recommended way to open gui's with root permissions)
whoops, didn't mean for this to be an "answer your own question", but have just discovered how this works.  the mac's fn key, which is needed to access the function keys even in linux, maps fn+left and fn+right keys to home and end for you - on mac os this does that annoying "scroll to the top/bottom" thing, but in linux they work like a regular home/end keys.  problem solved!  update:  switching between the two "modes" of entry was driving me crazy (remember, fn+arrows doesn't work in os x), so i've worked out how to get left cmd+arrows working in both oss (it works by default in os x - where ctrl+a/e actually do strange things in multiline inputs like stackoverflow boxes...).  it's a ~/.xmodmap entry, and it requires that you map the right cmd to the virtualbox "host" key first.  keycode  133 = mode_switch meta_l alt_l meta_l keycode 113 = left nosymbol home keycode 114 = right nosymbol end   (you can run xmodmap ~/.xmodmap to apply the settings without a restart).  in linux, this works in terminals, eclipse, everything (presumably only when x is running.)  if you're having trouble getting this to work with a particular non-locking modifier key, take a look at the output of xev when you press it, and try swapping the keycode out for 133 above (although you may need to swap out nosymbol too, i don't know.) 
this is commonly done with tail -f:  $ tail -f file.txt   the tail utility outputs the tail of a file or stream, i.e
i would use two arrays:  awk -f, '{a[$0]=$2;if($3=="win")b[$2]++}end{for(i in a){if(b[a[i]])print i}}'  
normally modprobe loads modules from sub folders located in /lib/modules/$(uname -r)
this is standard practice for shells
bash can be invoked in various ways, including directly using its executable (/bin/bash) or a link to it; this is often the case with /bin/sh
the alias was removed in this commit.  to add it back:  alias -- -='cd -'     most of posix shells need -- for this alias work, only dash doesn't:  $ dash $ alias -='echo 1' $ - 1  
it seems that the right tool for this job is seccomp
short answer: you can’t cd to this directory.  media transfer protocol (mtp)  media transfer protocol (mtp) uses a special api that to provide limited access to files on a device
right, i had a discussion with my colleagues, and they suggested i use nfs (network file system), and am connecting winscp through another machine (linux server)
yes, it's a bad idea — and it was removed in 2008, after being deprecated in october 2006 by andrew morton:     apparently futex_fd is unfixably racy and nothing uses it (or if it does, it   shouldn't).   (thanks to alexp for finding the deprecation message.) 
the closest you can get to bleeding edge in terms of the portage tree is to use accept_keywords, found in /etc/portage/make.conf
you can use network manager with a static ip address.  if you want a system-wide setting, you can use /etc/network/interfaces for a wireless adapter
the following works for me:  u-boot&gt; setenv bootcmd 'if test ${jpsdboot} = ' \''on'\' '; then run sdboot; else run emmcboot; fi;'   i found this by trial and error
journalctl --since=today   reference 
by default, fedora 20 installs gnome-software for this purpose
grep /var/log /etc/rsyslog.conf | awk '{print $2}' | sed 's/^-//'   sed will look for the start of a line s/^ followed by a hyphen - and replace it with an empty string //. 
your shell didn't stop, the progress you sent to the background did (the iex process)
it turns out the problem was multiple things, mostly stemming from my modem/router
you'll need to install apt-doc:  sudo apt-get update sudo apt-get install apt-doc   having a separate -doc package is not unusual.  are you looking for something in particular? 
if you want to avoid that then you need a new chain:  iptables -n sshgroup1 # or reset with iptables -f sshgroup1 if it already exists iptables -t filter -a ssh -s 10.10.10.10/32 -m mac \   --mac-source 10:10:10:10:10:10 -j sshgroup1 iptables -t filter -a sshgroup1 ..
processes in state d (uninterruptable sleep) cannot be killed while they are in this state
using gnu sed  input  flood good good good good good flood good good   if you want the newly concatenated line to count against the number of chars  sed ':;/.\{5,\}$/!{n;s/\n/ /g;b}'  flood good good good good good flood good good good   if you want to count each line on its own and concatenate each line that is less to the previous   sed ':;/[^\n]\{5,\}$/!{n;$!b};s/\n/ /g'  flood good good good good good flood good good good  
first some background  there are different versions of nc, as you can find on nc(1) - linux man page or nc(1) bsd general commands manual the connection should shut down right after the transfer
glibc doesn't know anything about mime types; the api functions live at the level of desktop environment apis, and the freedesktop.org recognize that harmonizing them is an impossible task so they only specify the shell-level interface
you are using various ways to create log output, but do not mention the most important ones:  the command ssh itself has a "verbose" option -v. and more interesting, it also has a "verry verbose" option -vv. oh, and "verry verry verbose", -vvv, which may actually be too verbose!    does it give more insight to run ssh with options -v, -vv, or -vvv?  showing how much verbosity the options enable:  $ ssh -v   localhost true |&amp; wc -l  56 $ ssh -vv  localhost true |&amp; wc -l 122 $ ssh -vvv localhost true |&amp; wc -l 282  
this should do what you want:  ls|sed 's/\..*//'|sort -u|column   if your shell has the width of your terminal in $columns, then this is better:  ls|sed 's/\..*//'|sort -u|column -c $columns  
try this (chris, you're very close):  sed -i '' 's|export todo_file="$todo_dir/todo.txt"|export todo_file="$todo_dir/writing.txt"|g' ~/.todo/config  
you can use amixer
it's a bit tricky as gnome-keyring-daemon sets unique environment parameters before your session starts and this environment is used to access the daemon trough a socket
yes  sharing a printer from a linux/cups host to a windows virtual machine is easy
use a different kind of array: rather than an integer-indexed array, use an associative array, so the key (index) is what you will be checking for
if on linux, something like this should do what you are looking for:  inotifywait -m -e close_write --format %w%f -r /watch/dir |   while ifs= read -r file   do     cat &lt; "$file"   done  
i don't know about wine, but you could use attic manager
ok, so, for what it's worth, the following was successful for me:  sudo systemd-nspawn -bxd/   practically identical to yours, except i don't give the machine a name and i get an -x ephemeral btrfs snapshot of my / for the container's root.  that brought up the container's getty on my terminal's pty and i logged in to login and all
i found solution here:   http://thenerdshow.com/index30e5.html   there i've found :  $ amixer -c0 cset iface=mixer,name='input source',index=1 'front mic' # (record from front mic)   slightly modified according to my sound-card and setup (default sound-card, different items ordering) :  $ amixer cset name='input source',index=0 'rear mic'  
use double quotes to enclose your pattern:  grep "'user' =&gt; ''," your_file   i would also make use of some metacharacters to ensure the lookup is robust to the different spacing styles used by people:  grep "'user'\s*=&gt;\s*''\s*," your_file   to add different keywords to your search, you need extended regular expressions
by default the ld_library_path entry is left unset, and the system resolver libraries use the cache generated by ldconfig, which is configured by /etc/ld.so.conf.  so in your case if you didn't have any previous customisations you can simple re-edit /etc/environment and delete the line.  if your editor is not working properly you can unset ld_library_path in your shell to temporarily let it work.  note that if did have any customisations then you'll need to restore from backup. 
edited: forgot to double escape the \r in the sed line   either of these should work for you  for i in $(find 
the answer is more or less that ls is an external executable
the issue was that i didn't have openssl properly installed
unfortunately, there's not much you can do, other than replace the hard disk or get an external disk.  you can, of course, try to reduce the amount of disk space you're using, but most modern linux distros will eat 20 gigs pretty quick
so is dropbear really like the right and only choice for remote access during boot time?  i did some additional research on dracut which is used to build the initramfs image on centos and it shows the option "--sshkey " which needs to be combined with the module load option "ssh-client" in /etc/dracut.conf.  it looks to me again as if there already is a ssh-client at place and i do not need to install dropbear additionally
i don't believe you can force screen to overwrite the log
tree man page says:      -d     list directories only.    so the output of tree -d your_target_folder looks like:  ├── appengine_admin │   ├── media │   │   ├── images │   │   └── js │   └── templates ├── common ├── conf │   └── locale │       ├── ar │       │   └── lc_messages │       ├── bg │       │   └── lc_messages │       ├── en │       │   └── lc_messages │       ├── es │       │   └── lc_messages │       ├── fi │       │   └── lc_messages │       ├── fr │       │   └── lc_messages │       ├── ja │       │   └── lc_messages │       ├── pt │       │   └── lc_messages │       ├── ro │       │   └── lc_messages │       ├── ru │       │   └── lc_messages │       ├── sq │       │   └── lc_messages │       ├── sv │       │   └── lc_messages │       ├── tl │       │   └── lc_messages │       ├── tr │       │   └── lc_messages │       └── zh │           └── lc_messages ├── credit ├── geo ├── js ├── mapreduce │   ├── lib │   │   ├── blobstore │   │   ├── files │   │   ├── graphy │   │   │   └── backends │   │   ├── key_range │   │   ├── pipeline │   │   │   ├── simplejson │   │   │   └── ui │   │   │       └── images │   │   └── simplejson │   ├── operation │   └── static ├── market ├── onlinedebug ├── static │   ├── challenge │   ├── codebase │   │   └── imgs │   ├── css │   ├── for_sale_files │   ├── images │   ├── images.large │   ├── images.small │   ├── img │   ├── jquery-1.js │   ├── js │   └── yui │       ├── assets  
you don't need to use a cd, the big benefit of using network installation instead of a normal, physical medium based, installation is that you can install multiple machines at once without the need to ever insert a physical medium.  with kickstart it is also possible to automate the installation of an fedora installation, i.e
you can use grep and the pcre facility it provides to do this:  $ grep -po "(?&lt;=xxx )\s+(?= zzz)" data.txt  y1y y2y   details  this solution makes use of the lookbehind and lookahead feature of pcre, which can match fixed length strings.  the above looks behind every \w+ to see if it's xxx and head of every \w+ seeing if it's zzz
zipinfo -1 file.zip   or:  unzip -z1 file.zip   would list only the files.  if you still want the extra info for each file names, you could do:  unzip -zl file.zip | sed '1,2d;$d'   or:  unzip -l file.zip | sed '1,3d;$d' | sed '$d'   or (assuming gnu head):  unzip -l file.zip | tail -n +4 | head -n -2  
wikipedia has this entry:  since framebuffers are often designed to handle more than one resolution, they often contain more memory than is necessary to display a single frame at lower resolutions
from man bash:     when  bash  is  invoked as an interactive login shell, or as a non-interactive shell with the --login option, it first reads and executes commands from the file /etc/profile, if that file exists
i belive you are right – there is no such restriction
 the local resolver you've set up will not use your isp's resolver at all by default
if you extract the contents of the deb file, you will find in debian/templates the debconf rules for the package
the details on how to do this were found here in this blog post titled:  locking the screen from the command line in gnome 3.8.  manually triggering  the dbus-send command can be used to send this message, in this case we're sending the "lock" message to the screensaver.  $ dbus-send --type=method_call --dest=org.gnome.screensaver \     /org/gnome/screensaver org.gnome.screensaver.lock   timeout  typically this same message will be sent when you've configured for this particular timeout to occur through the desktop settings
for rpm fusion (free repository):  get the release rpm:  $ curl -o https://download1.rpmfusion.org/free/fedora/\ rpmfusion-free-release-$(rpm -e %fedora).noarch.rpm   check the archive's integrity via:  $ rpm --checksig rpmfusion-free-release-$(rpm -e %fedora).noarch.rpm   which should fail with:  [..] missing keys: gpg#key_id [..]   add key to your gpg keyring for checking:  $ gpg --keyserver pgp.mit.edu --recv-keys key_id    in case the key is not available on a keyserver you have to download it from the rpmfusion key page:  $ curl -o rpm-gpg-key-rpmfusion-free-fedora-25 'http://rpmfusion.org/\       keys?action=attachfile&amp;do=get&amp;target=rpm-gpg-key-rpmfusion-free-fedora-25'   unfortunately, rpmfusion does not use https.  compare the fingerprint with the published information on the rpm fusion key site, via a web-search and possibly check the web of trust:  $ gpg --fingerprint key_id   if successful make the key known to rpm:  $ gpg --export -a key_id &gt; rpm-gpg-key-rpmfusion-free-fedora-$(rpm -e %fedora) # rpm --import rpm-gpg-key-rpmfusion-free-fedora-$(rpm -e %fedora)   check the integrity of the package for real:  $ rpm --checksig rpmfusion-free-release-$(rpm -e %fedora).noarch.rpm   if it is ok install it:  # dnf install rpmfusion-free-release-$(rpm -e %fedora).noarch.rpm   or with older fedora versions:  # yum localinstall rpmfusion-free-release-stable.noarch.rpm   this will create config files under /etc/yum.repos.d/ and key files under /etc/pki/rpm-gpg.  note that the # means that you have to execute those commands as root.  for the nonfree rpm fusion repository you have to curl the analogous setup rpm as well.  for livna.org you have to:  $ curl -o http://rpm.livna.org/livna-release.rpm   the other steps are analogous.  in case the livna repository doesn't include the current release, yet, you can workaround that via editing   /etc/yum.repos.d/livna.repo   such that:   the mirrorlist line is commented out the baseurl is commented in and the $release variable is replaced with - say - 23   for example, most of the libraries available from livna for fedora 21 should work as-is also under fedora 23.  fingerprints  as the time of writing the following keys were used:  https://download1.rpmfusion.org/free/fedora/\   rpmfusion-free-release-25.noarch.rpm key_id: 6806a9cb key fingerprint: 286f 52f7 e9d4 7b46 3ead  d8ab a1e5 4a0f 6806 a9cb  http://rpm.livna.org/livna-release.rpm sha256: 18d08b96bc0d6912ba2e957a33ff5c50d7f8f3bae710f5186f3ebc0c78458e13 key_id: a109b1ec key fingerprint: 037b 5d9b e1b6 b673 2a23  13b5 7129 5441 a109 b1e  
it seems that i've found a solution:   at the grub prompt, hit a to append options add init=/bin/bash to the end of the kernel command line and press enter   the system will boot to a prompt like 'bash-3.2#' enter the following commands at the prompt   mount -o remount,rw / vim /etc/fstab   edit the fstab file commenting the errors by adding a # at the begining of each problematic line, save the file    reboot by pressing ctrl+alt+del   
if you look at any centos 5 or 6 system the file /etc/crontab is typically where all the action starts
you should open the menu of yakuake
to kill all bash processes, belonging to root, i used the following script:  for pid in $(pgrep -u 0 bash); do     if [ "$pid" != "$$" ]; then         kill -hup "$pid";     fi done  
if you want to delete all the files, then, on a gnu system, you could do:  cd -p -- "$destdir" &amp;&amp;   printf '%s\0' * | # print the list of files as zero terminated records     sort -rz |      # random sort (shuffle) the zero terminated records     xargs -r0 rm -f # pass the input if non-empty (-r) understood as 0-terminated                     # records (-0) as arguments to rm -f   if you want to only delete a certain number of those matching a regexp you'd insert something like this between the sort and xargs:  awk -v rs='\0' -v ors='\0' -v n=1024 '/regexp/ {print; if (--n == 0) exit}'   with zsh, you could do:  setopt extendedglob shuffle() reply=$random rm -f file_&lt;-&gt;_[a-d].bin(.+shuffle[1,1024])  
you can copy ~/.gnupg/trustdb.gpg from one machine to another.  you can also export the ownertrust values (which are the ones that matter) and import them on the new machine:  gpg --export-ownertrust &gt; otrust.txt  rm ~/.gnupg/trustdb.gpg gpg --import-ownertrust &lt; otrust.txt   see the gpg manpage for details (although the version on the website doesn't say much more than i have). 
you probably need to enable the httpd_can_network_connect selinux boolean:  run as root:  # setsebool -p httpd_can_network_connect 1  
running it with  strace -e trace=open,close,read,write,connect,accept your-command-here   would probably be sufficient.  you'll need to use the -o option to put strace's output somewhere other than the console, if the process can print to stderr
you can do that like this:  ssh -t user@192.168.20.11 "echo -en '\033]0;20.11\a';bash"  
using gnu screen is your best bet.  start screen running when you first login - i run screen -d -r, run your command, and either disconnect or suspend it with ctrl-z and then disconnect from screen by pressing ctrl-a then d.  when you login to the machine again, reconnect by running screen -d -r
here's a way to not repeat then command git part:  git () {     if [ "$1" = commit ]; then set commit -v "${@:2}"; fi     command git "$@" }   note that you should not use $1 without double quotes
think about your requirement for a moment.  do you (might you possibly) have any executable files (scripts or binaries) in your directory tree?  if so, do you want to remove execute permission (even from yourself), or do you want to leave execute permission untouched?  if you want to leave execute permission untouched, you should use chmod o-w to remove (subtract) write permission from the others field only.  also, as anthon points out, the find command given in the other answer executes the chmod program once for each world-writable file it finds.  it is slightly more efficient to say  find  top-level_directory  -perm -2  -type f  -exec chmod o-w {} +  this executes chmod with many files at once, minimizing the number of execs.  p.s
pv doesn't know about the system power states
a default value is easy to define in bash:  foo="${bar-default}" # sets foo to the value of $bar if defined, "default" otherwise foo="${bar:-default}" # sets foo to the value of $bar if defined or empty, "default" otherwise   to process your parameters, you can use a simple loop:  while true do     case "${1-}" in         -in)             infile="${2-}"             shift 2             ;;         -out)             outfile="${2-}"             shift 2             ;;         *)             break             ;;     esac done  program -in "${infile-otherfile}" -out "${outfile-otherout}" "$@"   useful reads:   parameter handling passing parameters to another script   i also recommend using getopt instead, because it is able to handle many special cases which would very quickly complicate and clutter your code (non-trivial example). 
you might find this thread and this one pretty useful.  if your wifi network uses wep encryption, then  # turn wireless card on: ifconfig wlan0 # wlan0 is your wireless interface  # connect to network iwconfig wlan0 essid &lt;name&gt; key &lt;password&gt;     # here     # &lt;name&gt; -- your access point name     # &lt;password&gt; -- your password  # then obtain ip address: dhclient wlan0   if your network uses wpa encryption then you need wpa-supplicant for that:   edit /etc/wpa_supplicant.conf with your favorite editor putting your ssid and password there:  network={     ssid="ssid_name"     psk="password" }   run wpa_supplicant -b -iwlan0 -c/etc/wpa_supplicant.conf -dwext &amp;&amp; dhclient wlan0 where wlan0 is your wireless interface
gnu coreutils nohup man page indicates that you can use normal redirection:     if standard input is a terminal, redirect it from /dev/null
this (and much much more) can be done in advanced settings of kde's window manager kwin
it is implemented using a browser plugin
your bash-completion isn't really "corrupted" - this is simply a known bug with bash-completion 2.1 and bash 4.3.  i recently answered a related question over at askubuntu and then again right here, but since i'm at it i'll also answer here so that people googling for this problem will find the answer here too.  i gave more details over at askubuntu, but essentially, to fix it, you can:   replace  [[ ${!2} == \$* ]] &amp;&amp; eval $2=${!2}   with  [[ ${!2} == \$\'* ]] &amp;&amp; eval $2=${!2}   in the function _quote_readline_by_ref in the file /usr/share/bash-completion/bash_completion (not recommended); or check out the newest git version of the bash-completion library and use that - the bug seems to be fixed in this version.   you won't get tab completion inside command substitution working again with either of these solutions, but at least, you won't see that error message any longer.  to actually get tab completion inside command substitution working, you will either have to revert to an earlier bash version (where i hear it was working), or wait for the library to truly fix that issue with bash 4.3. 
it doesn't seem that detox has an option for that
assuming bash:  % python -c "from distutils.sysconfig import get_python_lib; print get_python_lib()" /usr/lib/python2.7/site-packages % cd $(!!) cd $(python -c "from distutils.sysconfig import get_python_lib; print get_python_lib()") % pwd /usr/lib/python2.7/site-packages  
you can show completion code for a command using the complete builtin
x11perf:     the x11perf program runs one or more performance tests and reports how   fast an x server can execute the tests.      many graphics benchmarks assume that the graphics device is used to   display the output of a single fancy graphics application, and that   the user gets his work done on some other device, like a terminal.   such benchmarks usually measure drawing speed for lines, polygons,   text, etc.      since workstations are not used as standalone graphics engines, but as   super-terminals, x11perf measures window management performance as   well as traditional graphics performace
you need ssh_auth_sock in the environment of your script
take advantage of brace expansion:  du -b maybehere*/{.??,}*   i used ?? to do not match .., i.e
alsa stands for advanced linux sound architecture, i'd encourage you to poke around their project website if you're truly curious
i used sshfs to mount a directory from some ssh server, and my network connection was lost
you have to do unset mailcheck
example:  prove i'm sending a nul byte, followed by a newline:  $ echo -e \\0 | hexdump -c 00000000  00 0a                                             |..| 00000002   now i change the nul byte to an ! exclamation mark:  $ echo -e \\0 | sed 's/\x00/!/' | hexdump -c 00000000  21 0a                                             |!.|   so the trick is using \x00 as nul-byte. 
the kill command is a very simple wrapper to the kill system call, which knows only about process ids (pids)
think of it as working in steps of divsibleby units times an integer.  ignoring the random for the moment, (max-min+divisbleby)/divisibleby would be the width of the range in plain integers, instead of (unit x integer), so (max-min+divisibleby) is the width in (unit x integers)  the % is a modulo operator to give you a number inside the (unit x integer) width out of random (which will be between 0 and 32767 itself)  the /divisibleby*divisibleby part makes sure you are not getting a non-zero remainder when inside the set of (units x integers)  the +min  shifts the random number (that falls within the width) back up into the target range 
postfix executes mailbox_command with uid of the recipient
finding the transport  try using netstat -ln | grep 'mysql' and you can see how it is connected by the output
similar to iain's answer, you can also use tr:  $ echo a,b,c | tr ',' '\n' a b c   both answers assume that the csv is simple (that is, all commas are field separators)
that's relatively easy with perl:  perl -f'\s+' -lane '   push @row, [@f];   end{     @sum = @{pop @row};     @col = (0, (sort {$sum[$b] &lt;=&gt; $sum[$a]} (1..$#sum-1)), $#sum);     for $i ($row[0], (sort {$b-&gt;[$#sum] &lt;=&gt; $a-&gt;[$#sum]} @row[1..$#row]), \@sum) {       print join "\t", @{$i}[@col]     }   }'  
first, you need to find out whether the messages you want are getting sent to stdout or stderr
the following script takes its args from the command line rather than a prompt
gparted is often worth using because it helps avoid several nasty mistakes
try this, and apologies for being obvious:  cat *.cs | wc -l   or, with git:  git ls-files -z ${1} | xargs -0 cat | wc -l   if you actually want the output to look like wc output, with both individual counts and a sum, you could use awk to add up the individual lines:  git ls-files -z ${1} | xargs -0 wc -l | awk '/^[[:space:]]*[[:digit:]]+[[:space:]]+total$/{next}      {total+=$1;print}      end {print total,"total"}'   that won't be lined up as nicely as wc does it, in case that matters to you
use the ~m pattern.  ~m 1234-2345   you would need to use ~m evel to delete a single message by its number (or, of course, you could move to it and use d). 
i'll assume that the other users aren't trying to hide anything from you, they're just a bit clueless or annoying
#!/bin/bash  while : do   echo paste some input, then press control-d:   cat &gt; /tmp/sortme ; diff &lt;(sort /tmp/sortme) &lt;(sort -u /tmp/sortme) done  
short answer -- use:   startx -- vt0   longer explanation: the links and suggestions by @jimparis led me to dig a bit more into policykit and systemd, and -- crucially -- to google for "polkit startx", which led me to a result on an arch linux discussion site:     if you don't use a display manager, it means you won't have a   registered pam session for your graphical login, which means logind   won't give the correct info to polkit (it will think that there is no   active session).      a workaround for this is to start your wm on the same vt as your   consolelogin, and hence "steal" that pam session
three ways:  a) run some number of commands in one row, linked with semicolons  adb devices; adb uninstall com.package.abc; cd myprojectdir; meteor reset; rm -f -r .meteor/local; meteor run android-device   here i've kept the original "intent" of simple sequential execution
i don't know if it is in bash (the default shell)
i don't have an explanation for why they did it this way, but ${:-foo...} does have an application: it counts as a parameter substitution in places that syntactically require one, but always just expands to a literal you give
there are two questions there:   difference between su - username and su username   if - (or -l) is specified, su simulates a real login
you have a few misconceptions
hexdump -c yourfile.bin    perhaps, unless you want to edit it of course
if you specify  allow-hotplug eth0   instead of  auto eth0   in /etc/network/interfaces, then the connection will only be initiated by udev when something triggers it, instead of at every boot
model can be found using  model  ia64 hp superdome2 16s  xyz/9000/rx3440 (a)   more details information can be found usinf machinfo (starting 11iv3).  other properties are foung using getconf (see man getconf for details)  getconf long_bit 32    here i am on a 32 bit system. as pointed out by darkheart, actual configuration is given by getconf kernel_bits which return 64.   ( (a) can't remember exact return for 9000 system ) 
some specific software can be configured with --program-suffix=-my-version-suffix
usually, ftp command line clients support the configuration file ~/.netrc where you can configure credentials for remote systems, e.g.:  machine legacy.system.example.org login juser password keins   when you ftp legacy.system.example.org then you don't have to retype this information anymore.  if you need to do more automation, you can script ftp via piping commands into it, e.g.:  $ cat pushit.sh # complex logic to set # example_file= ftp &lt;&lt;eof prompt mput $example_file quit eof   sure, if the system does not support ssh, it probably does not support ftps either - but you can try it (e.g
the detection is done through libmagic which looks for specific byte sequences with magic numbers. 
this script uses a counter n to limit the attempts at the command to five. if the command is successful, $? will hold zero and execution will break from the loop.     n=0    until [ $n -ge 5 ]    do       command &amp;&amp; break  # substitute your command here       n=$[$n+1]       sleep 15    done  
convert the number to hex (in this case a) and then do:  echo -en '\xa' &gt; file  
you could move the espeak binary to something like espeak-real, and replace it with a small script that sets ld_preload before exec'ing espeak-real.  #! /bin/bash export ld_preload=/your/lib.so exec espeak-real "$@"   (stdin/out/err redirections take care of themselves.) 
gnome 3 version is stored in this file:  /usr/share/gnome/gnome-version.xml   content (on my system):  &lt;?xml version="1.0" encoding="utf-8"?&gt; &lt;gnome-version&gt;  &lt;platform&gt;3&lt;/platform&gt;  &lt;minor&gt;6&lt;/minor&gt;  &lt;micro&gt;2&lt;/micro&gt;  &lt;distributor&gt;arch linux&lt;/distributor&gt;  &lt;date&gt;2012-11-13&lt;/date&gt; &lt;/gnome-version&gt;   the file is part of the upstream package called gnome-desktop (note that some distros split it into several packages so on your distro the file may end up in a package with a different name...)  gnome developers use this file to get the de version number and display it in system settings (aka gnome-control-center)
well, incase someone is searching for this, the following parameter exists:  /proc/sys/net/ipv4/igmp_max_memberships   currently my install says 20, in the sources, i also see:  bits/in.h:#define ip_max_memberships              20   i think bumping up the system parameter may be enough, else will have to patch the header as well!  edit: looks like bumping up the system parameter does the trick. 
with the outdated acl proposal from 1993 that was withdrawn in 1997, there is no way to do this as bar could always change the permissions in a way that could prevent foo from being able to control things
bash doesn't typically care about the values of the arguments, it's more their ordering, and how they're separated on the command line, by default parsing them based on a space between each argument.  you can see this with a simple for loop construct in a shell script like so:  #!/bin/bash  echo "" echo "args: $@"  echo "" echo "parsed args:" for i in "$@"; do     echo "$i" done   example  $ ./parse.bash -f aphpscript.php -d memory_limit=120m -d apc=1 \      -d max_execution_time=120  args: -f aphpscript.php -d memory_limit=120m -d apc=1 -d max_execution_time=120  parsed args: -f aphpscript.php -d memory_limit=120m -d apc=1 -d max_execution_time=120   in the above, each iteration through the loop is "peeling off" the next argument that was passed into the script parse.bash
you could try running something like ssh -n remuser remhost kill -hup -1
the emerald window decorator isn't available in the ubuntu official repositories(mint included) anymore, unfortunately, but there are other way to acquire it.  i am not aware of any ppas for precise, but building it from source is really straightforward
i couldn't find it either
arithmetic in posix shells is done with $ and double parentheses:  echo "$(($num1+$num2))"   you can assign from that (sans echo)
combining gnu find options and predicates, this command should do the job:  find 
command -pv uses a "default value for path".  $ which ruby /home/mikel/.rvm/rubies/ruby-1.9.3-p484/bin/ruby  $ command -pv ruby /usr/bin/ruby   unfortunately that doesn't work in zsh, so based on stephane's comment, we could use getconf path:  $ path=$(getconf path) which ruby   or use command -v in place of which, as recommended in why not use &quot;which&quot;? what to use then?  $ path=$(getconf path) command -v ruby   the downside with these approaches is that if the system administrator installed a system-wide version into say /usr/local/bin or /opt/local/bin, and all users had that in path (e.g
my answer to this was to do 2 things:  first have the .bashrc line use this so that it works on osx:  [ `uname -s` != linux ] &amp;&amp; exec tmux   secondly, for ubuntu, change the terminal profile to use tmux directly, e.g.  on   check the custom command enter tmux, e.g.    for quake i also had to update preferences (right click while using it -> preferences)  changing the shell from /bin/bash    to /usr/bin/tmux, i.e
by default an entry in a repo file is enabled  eg  [base] name=centos-$releasever - base mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=os&amp;infra=$infra # baseurl=http://mirror.centos.org/centos/$releasever/os/$basearch/ gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/rpm-gpg-key-centos-6   there is no enabled line in this configuration and so the repo is enabled.  you can see what repo's are enabled with  yum repolist enabled   to temporarily enable a repo that's normally disabled you can use the --enablerepo option  eg  yum --enablerepo=foobar install xyz  
[optional]  i'm a vimer too and i feel uncomfortable with the default ctrl position so i remapped the window's meta to be an additional ctrl key
distribution  a system built on linux is called a "distribution".  distribution examples:   ubuntu debian fedora arch opensuse ...   to install a software on a distribution, you have several possibilities:   build the software from source, install the program with a "package manager".   package manager  almost each distribution use one package manager, most known are:   apt-get (debian, ubuntu) pacman (arch) yum (fedora) ...   each package manager has its syntax, type man &lt;package manager&gt;.  build from source  it will depends on the software you want to install, but in most cases:   get the sources:   go to software web page download the source (.tar.gz, .tgz, .zip..
you can run local scripts remotely by executing bash on the remote system and feeding it your script  $ ssh user@host 'bash -s' &lt; script.sh  edit  to execute commands that require using sudo on a remote machine use ssh's -t option and pass the commands to ssh
for me,  apachectl -v  works on both osx and freebsd.  if anybody has a better answer or a continuation of this answer for other operating systems, feel free to share. 
our *nix's always recommend free formats over the restricted ones..
i've taken a brief look at the source code
you can go to websites like noobslab or gnome-look for themes, icons, mouse cursors, wallpaper etc.  you need to install cairo dock for a menu like your picture.  i will also suggest you to use conky which is very interesting and useful. 
when you are doing this:  mount -t glusterfs  gluster-server-01:/volume-www  /var/www   you are initially connecting to one of the nodes that make up the gluster volume, but the gluster native client (which is fuse-based) receives information about the other nodes from gluster-server-01
try to use such next function for such situation:  copy_wdir() { mkdir -p -- "$(dirname -- "$2")" &amp;&amp; cp -- "$1" "$2" ; }   and use it as  copy_wdir aaa/deep/sea/blob.psd bbb/deep/sea/blob.psd   by the way, gnu cp has a --parents option
you don't want to use ls, you want to use shell globbing and string manipulation:  $ for f in *.rej; do    size=$(stat --printf "%s" "${f%.rej}.failed") &amp;&amp;    if [ $(stat --printf "%s" "$f") -eq "$size" ]; then      mv "${f%.rej}.failed" backup/;   fi;  done 2&gt;/dev/null   explanation  the stat --printf "%s" command will print the size a file in bytes
you have a couple of options here
the following script will give you the top-left screen co-ords and size of the window (without any decoration)
if you want to add a package, edit:  /usr/share/lxc/templates/lxc-debian   and search for download_debian()
the part after the colon is the port number, and it's not always displayed as a number since there's a list of well-known ports uses in /etc/services, so you don't have to remember if 22 is ssh or telnet
the problem is caused by vboxguestadditions_5.0.18, i believe the graphics driver is broken in it
to address your edit:  i didn't notice the edit to your question until just now
this is a shell function
i'm pretty sure there's no way to do this in full generality, because text cursors are an application feature, not a server feature like mouse cursors
.bashrc is a shell script that bash runs whenever it is started interactively
--user and --chuid works but has to be used with start-stop-daemon.  example: as root user if now execute: /etc/init.d/pythongui start it execute as username: sun  #! /bin/sh path=/sbin:/usr/sbin:/bin:/usr/bin desc="python gui - server" name=pythongui.sh daemon=/var/tmp/$name daemon_args="--options args" pidfile=/var/run/$name.pid scriptname=/etc/init.d/pythongui  [ -x "$daemon" ] || exit 0 [ -r /etc/default/$name ] &amp;&amp; 
the kernel and the nic communicate the same way the kernel (specifically, a device driver, which is part of the kernel) communicates with any other device (e.g., serial communications device (like keyboard, mouse, or rs232), disk (or disk-like mass storage device), display, security token, etc.) – they talk directly to each other.  so, yes, this happens within the nic driver.  no, driver ↔ device communication does not go through a system call.  device drivers communicate with devices, generally, through two access methods: memory-mapped i/o (mmio) and port-mapped i/o (pmio).  these are described and discussed at some length on super user in these two questions:   difference between port mapped and memory mapped access? how does a driver actually communicate with a hardware device?   see also what is a driver, and how does it work? if you need the background information.  btw, which access method is used is determined by the computer architecture.  for example, wikipedia says, “memory-mapped i/o is preferred in x86-based architectures …”  getting back to your specific question, if we assume memory-mapped i/o, the driver could test for collision with c code as simple as          if (nic-&gt;error_status &amp; collision)         {                 // we get here if there was a collision.                 (code to handle collision)                            ⋮         }  (where nic is a pointer to the nic’s mapped address) and it’s a trivial matter then for the driver to cause an error to be returned to the user process from the write() system call.    follow-up question:     does the fact that drivers are part of the kernel mean that   there is no driver ↔ kernel communication method?   that might almost be worth asking as another question (or at least doing some more research; i.e., web searches).  originally, the unix kernel was monolithic (see also monolithic kernel).  the relationship between the kernel and the drivers was like the relationship between a human body and its hands — hands are distinctive, and would never be confused with, say, elbows or lungs — but they are an integral part of the body.  even on machines that had four protection rings, unix used only two — the kernel was in ring 0 and userland was ring 3.  there are other operating systems where device drivers are analogous to knife and fork — one level removed (e.g., drivers are in one of the intermediate rings (1 and/or 2)).  i haven’t kept up with all the developments in *nix/linux (e.g., lkms), and some unices may have a greater degree of separation between the base kernel and the drivers than others.  for example, see   what is the difference between kernel drivers and kernel modules? (on unix &amp; linux) the linux kernel, kernel modules and hardware drivers  … … (on an external site)   as i say, this stuff is at the edge of my knowledge base; don’t ask me any further follow-up questions on the above.  but also, the question is semantically ambiguous.  does the body communicate with the hands?  yes, through the nervous system (and, to an extent, the skeleton).  does “the kernel” communicate with device drivers (that are part of the kernel)?  yes, in the same sense that c programs (e.g., cat, cp, ls, sed, etc.) communicate with the c library — through subroutine calls (and perhaps the occasional, judicious use of global variables).  when a user process calls an i/o-related system call (e.g., open(), close(), read(), write(), ioctl(), poll(), select(), etc.), the general-purpose syscall-handling code (in the kernel) calls the appropriate device driver routine (possibly with some intermediate logic).  filesystem-related code also calls the appropriate disk driver routines.  and the kernel at least facilitates the invocation of device-specific interrupt handlers when interrupts are received (implementations vary). 
try this:  bashman () { man bash | less -p "^       $1 "; }   you may have to hit n a couple of times to get to the actual command instead of a paragraph that happens to have the command name as the first word. 
when you do a simple export with head, an internal timestamp is initialized based on the commit's timestamp
the answer looks something like this:   awk '/hi/ { if (fnr &gt;= 5) { nextfile }; print fnr, filename }' *   change the /hi/ with your regex matching string
home partition is not required for system to be operational
you can see which ssh public key was used in the syslog.  the authentication subset of the syslog is usually at /var/log/auth.log
grub doesn't mount a drive as writable, but linux does
the modulefile man page is probably of more use to you than the module man page.  a search for "environment module examples" yields this page, which seems to have some good examples
if i understand what you're asking for i this will do
you have no check on the library
first make sure you have gnome-tweak-tool installed:  sudo apt-get install gnome-tweak-tool   then use this command from a terminal:  gnome-desktop-item-edit --create-new ~/desktop  
that is the posix specified behaviour
the easiest way to do it is with synclient.  use:  synclient -l   to list all options and their current settings and then you can use:  synclient var1=value1 [var2=value2] ...   to change the different options.  to make changes permanent you can either create a script and run it on i3 logon or edit the file /etc/x11/xorg.conf.d (if you don't have it copy it from /etc/x11/xorg.conf.d/50-synaptics.conf ). in /etc/x11/xorg.conf.d you should write your settings under:  section "inputclass" identifier "touchpad" driver "synaptics" matchistouchpad "on"   in the form:  option "var1" "value1" ...   for tap-click and vertical scroll on right you should add:  option "tapbutton1" "1" option "vertedgescroll" "0"   you can also take a look at arch linux wiki page about touchpad_synaptics  if you want more gestures take a look at touchegg 
you can use the r programming language.  here is a quick and dirty r script:  #! /usr/bin/env rscript d&lt;-scan("stdin", quiet=true) cat(min(d), max(d), median(d), mean(d), sep="\n")   note the "stdin" in scan which is a special filename to read from standard input (that means from pipes or redirections).  now you can redirect your data over stdin to the r script:  $ cat datafile 1 2 4 $ ./mmmm.r &lt; datafile 1 4 2 2.333333   also works for floating points:  $ cat datafile2 1.1 2.2 4.4 $ ./mmmm.r &lt; datafile2 1.1 4.4 2.2 2.566667   if you don't want to write an r script file you can invoke a true one-liner (with linebreak only for readability) in the command line using rscript:  $ rscript -e 'd&lt;-scan("stdin", quiet=true)' \           -e 'cat(min(d), max(d), median(d), mean(d), sep="\n")' &lt; datafile 1 4 2 2.333333   read the fine r manuals at http://cran.r-project.org/manuals.html.  unfortunately the full reference is only available in pdf
no, the programs that reject those files usually reject them on the ground that the file is not seekable (they need to access the content at arbitrary offsets, or several times after rewinding etc.)
su - username -c 'ruby -e "$(curl -fssl https://raw.githubusercontent.com/homebrew/linuxbrew/go/install)"'   i think it's obvious, but in case it isn't, replace 'username' with the name of the user you want to install linuxbrew as.  edit: in hindsight, you could get a little bit more wild and use a for loop to install this for any user that has a home directory under /home  for u in `ls /home`; do su - $u -c 'ruby -e "$(curl -fssl https://raw.githubusercontent.com/homebrew/linuxbrew/go/install)"'; done  
thanks to @jasonwryan for advice, i did the following:  first, i removed my old installation:  # rm -rf /usr/local/texlive $ rm -rf ~/.texlive2013   then i just installed lilypond with pacman, which pulled texlive-core and texlive-bin as dependencies:  # pacman -s lilypond   then i installed some optional dependencies (psutils and t1utils), followed by texlive-lang and texlive-most:  # pacman -s psutils t1utils # pacman -s texlive-lang texlive-most   both tex and lilypond work, yay for arch and pacman. 
you have your commands inside of quotation marks
the pmount (policy-based "mount") lets you do that
for file in $(ls -p | grep -v / | tail -100) do mv $file /other/location done  
man sched     conceptually, the scheduler maintains a list of  runnable  threads    for    each possible sched_priority value
you should be able to build a png file (containing a graphic rendering of your topology) from your xml file (which was created by lstopo) with the command  lstopo --input out.xml --output-format png abc.png   in fact, it may be good enough to say  lstopo  -i out.xml  abc.png   because lstopo should assume that the output format is png if the output filename has a .png extension (a.k.a
based off of @likewhoa comments above, the structure of the ebuild needed to be massaged
i found myself putting together pieces from the different answers, particularly braiam's and muru's
you can use the libumem interposition library and mdb findleaks function.  see https://blogs.oracle.com/dlutz/entry/memory_leak_detection_with_libumem and http://stackoverflow.com/questions/4656981/solaris-libumem-why-not-show-memory-leak-for-first-dynamic-allocation  
single quotes are terminated by single quotes; all other characters in between are preserved exactly as is, including backslashes
i should clarify that the code here works for linux, (note comments and post about other unices)
glibc has a configure option called --enable-kernel that lets you specify the minimum supported kernel version
i've got the rtsp streaming on '/dev/video1' working with the following command:   ffmpeg -i rtsp://admin:admin@192.168.1.142:554/ch001.sdp -f v4l2 -pix_fmt yuv420p /dev/video1.  thank you guys for the great support. 
there are few things you could do here:    first check whether you have a dropbox daemon running
debian ships a script called update-info-dir which does exactly this
your script should not output single quotes
you can install alacarte and see if it works for you. 
okay, i was able to find my own solution (ironically) because gilles wasn't explaining himself properly and making me research his cryptic comments.  step 1: use dpkg -l $package or synaptic's properties dialog to find the file that didn't get purged with the rest of the package
when you run test.sh you'll briefly have that alias available in the bash instance that starts when you run that script
   tmux by default will only run one server process per user, and this server process can have multiple sessions
sendmail is an mta (mail transport agent) available for various unix-like operating systems
don't bother with grep
since you have build the gentoo modules yourself, you most probably forgot to remove debug info from them
you should be able to get rid of the output of the libraries by piping stderr away  cvlc -q mymedia 2&gt; /dev/null   as for the commands, i'm not sure vlc accepts commands from plain stdin, but it sounds like the rc interface might be what you're looking for.  cvlc -q -irc mymedia 2&gt; /dev/null  
i would shoot for a kde based distro like opensuse or kubuntu
in researching this it does not appear that there's a method for blocking users from accessing the contents of the ppd file.   re: unable to print to networked konica minolta bizhub c280 re: how do i set the default value in a ppd
as mentioned in the comment, a lot of your difficulty is because you're trying to store a command in a variable, and then run that command later.  you'll have a lot better luck if you just run the command immediately instead of trying to save it.  for example, this should do what you're trying to accomplish:  if (( ${#file_types[@]} &gt; 0 )); then     regex="${file_types[*]}"     regex="\.\(${regex// /\|}\):"     grep -i -r "$pattern" "$@" | grep "$regex" else     grep -i -r "$pattern" "$@" fi  
subversion authentication typically has two parts
take a look at these documents from red hat
for whatever reason, i was able tonight to apt-get install autofs, where i wasn't able earlier. after some quick configuration, my issues are completely resolved.  for those interested, once i had autofs actually installed, i simply had to add  /media /etc/auto.removable --timeout=2   to /etc/auto.master, and then create a new file (/etc/auto.removable) containing:  micro -fstype=auto,uid=1000,sync,nodev,nosuid :/dev/sdf1   this allows me to plug in the microsd, then access it via
the toe command will show you the terminfo definitions on the current system
this guide might help you:   extract the rpms:  $ tar -xvzf libo_3.5.2_linux_x86_install-rpm_en-us.tar.gz  install them all:  $ cd libo_3.5.2rc2_linux_x86_install-rpm_en-us/rpms $ sudo rpm -ivh *.rpm  install the freedesktop rpm:  $ cd desktop-integration $ sudo rpm -ivh libreoffice3.5-freedesktop-menus-3.5-202.noarch.rpm   
   can someone please explain how to trigger a command line only boot of centos 7 from a usb boot stick?   how about single user mode? press tab at the centos 7 boot menu
declare is a builtin function and it's not available with /bin/sh, only with bash or zsh (and maybe other shells)
the definitive list of mounted filesystems in in /proc/mounts.  if you have any form of containers on your system, /proc/mounts only lists the filesystems that are in your present container
append works by default for a stock vsftpd install on centos with an authenticated login.  $ sudo yum -y install vsftp ftp ... $ mkdir ~/tmp; cd ~/tmp $ echo hi &gt; foo $ ftp localhost ... ftp&gt; put foo ... ftp&gt; ^z $ cat ~/foo hi $ fg append foo foo ... ftp&gt; ^z $ cat ~/foo hi hi $   you'll need to debug the ftp connection (e.g
i've not seen a way to incorporate these results into nautilus, but there are guis for search in mlocate's database
you're overcomplicating this
when you type in just a command – eg
you can use the expand() call
there is only one superuser on fedora and i.e
this will work for your input:  begin {      n=0      sep="+-------+----------+" } {     if (/^$/) {         print sep     } else if (n==0) {         print sep         print "| "$1" | "$2"    |"     } else {         print "|   "$1" | "$2" |"     }     n++ } end {     print sep }   it doesn't do any automatic alignment so it will break if any of the fields increase in width
does this look desirable to you?  // replace macros in each .js file cd('lib'); ls('*.js').foreach(function(file) {   sed('-i', 'build_version', 'v0.1.2', file);   sed('-i', /.*remove_this_line.*\n/, '', file);   sed('-i', /.*replace_line_with_macro.*\n/, cat('macro.js'), file); }); cd('..');   if so, shelljs could be interesting, it's      a portable (windows included) implementation of unix shell commands on top of the node.js api.   i'm unsure if this could be used as a full-featured login shell, though
by default, fetchmail invokes the local mail transfer agent (mta)
if you change the diff format to unified with -u the filenames will appear.  another solution might be to run a checksum program, e.g
using:  $(make) --version   works here
it's not clear from your question that you know that you can toggle monitors on and off using the "on" slider in the "displays" dialog you show
the environment is copied into the process' address space when the process is created
the solution must probably be based either on ptrace or namespaces (unshare).  ptrace-based solutions are probably less efficient then namespaces/unshare-based (but the latter technology is cutting-edge and is not well explored path, probably).  ptrace-based  umview  as for ptrced-based solutions, thanks to the comments at http://stackoverflow.com/a/1019720/94687, i've discovered umview:   http://wiki.virtualsquare.org/wiki/index.php/viewfs http://wiki.virtualsquare.org/wiki/index.php/virtual_installation_of_software   the linked docs describe how to have a "copy-on-write view" of the host fs -- that's not exactly like performing a chroot
try something along these lines:  while read firstname lastname do     fullname="$firstname $lastname"     uname=$(echo ${firstname:0:1}${lastname:0:4} | tr '[:upper:]' '[:lower:]')     echo $fullname $uname done  &lt; newemploy.txt  
use auditing.  solaris auditing (overview)     auditing generates audit records when specified events occur
it sounds like you're looking for a very crude form of revision control
the other two answers have told you—correctly!—that this is a bad idea™
the simplest way to solve it using grep only, is to pipe one more inverted grep at the end. for example:  grep -a 4 "the mail system" temp.txt | grep -v "the mail system" | grep -v '^\d*$'  
first point , ftp and sftp both are different
try this  curdir=$(pwd) for folder in /path/to/files/*; do    [ -d "$folder" ] &amp;&amp; cd "$folder" &amp;&amp; ./conv.sh done cd $curdir   or assuming you are at /path/to/files/, this also works  for f in *; do [ -d "$f" ] &amp;&amp; cd "$f" &amp;&amp; ./conv.sh; done; cd ..   you could use f{1..20} instead of * for more precision. 
just change the username to yours.  #!/bin/bash   # https://github.com/linuxmint/mint-y-theme/ # https://github.com/linuxmint/mint-y-icons/   red='\033[1;31m' green='\033[1;32m' nocolor='\033[0m'   mkdir -p ~/downloads/themes-mint/   rm -r -f ~/downloads/themes-mint/mint-y-theme-master/ rm -r -f ~/downloads/themes-mint/mint-y-icons-master/   mv ~/downloads/themes-mint/themes.zip ~/downloads/themes-mint/themesold.zip mv ~/downloads/themes-mint/icons.zip ~/downloads/themes-mint/iconsold.zip   wget -q --show-progress -o ~/downloads/themes-mint/themes.zip https://github.com/linuxmint/mint-y-theme/archive/master.zip wget -q --show-progress -o ~/downloads/themes-mint/icons.zip https://github.com/linuxmint/mint-y-icons/archive/master.zip   if ! diff -q ~/downloads/themes-mint/themes.zip ~/downloads/themes-mint/themesold.zip &gt; /dev/null 2&gt;&amp;1; then    unzip -qq -o ~/downloads/themes-mint/themes.zip -d ~/downloads/themes-mint/   cp -r ~/downloads/themes-mint/mint-y-theme-master/usr/share/themes/* ~/.themes/   sudo cp -r /home/vlastimil/downloads/themes-mint/mint-y-theme-master/usr/share/themes/* /usr/share/themes/    echo -e "themes ${red}were${nocolor} changed"  else    echo -e "themes ${green}not${nocolor} changed"  fi   if ! diff -q ~/downloads/themes-mint/icons.zip ~/downloads/themes-mint/iconsold.zip &gt; /dev/null 2&gt;&amp;1; then    unzip -qq -o ~/downloads/themes-mint/icons.zip -d ~/downloads/themes-mint/   cp -r ~/downloads/themes-mint/mint-y-icons-master/usr/share/icons/* ~/.icons/   sudo cp -r /home/vlastimil/downloads/themes-mint/mint-y-icons-master/usr/share/icons/* /usr/share/icons/    echo -e "icons  ${red}were${nocolor} changed"  else    echo -e "icons  ${green}not${nocolor} changed"  fi  
grep matches lines of input
well, the simple answer is, i guess, that your find implementation is following the posix/sus standard, which says it must behave this way
!(usagerequest.csv) is a ksh globbing operator, it only works with ksh (also with zsh -o kshglob or bash -o extglob, but those shells don't come by default on solaris).  so you need to run those commands in ksh
use the pscp tool from the putty download page:  http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html  pscp is the putty version of scp which is a cp (copy) over ssh command.  pscp needs to be installed on your windows computer (just downloaded, really, there's no install process)
it appears i overlooked my iptables firewall, the problem doesn't appear to be with ip6tables but actually proto 41 being blocked which is required for 6in4 to work, i added the following to my csfpre.sh file:  iptables -t filter -i input -p 41 -j accept iptables -t filter -i output -p 41 -j accept   connectivity appears to be maintained now. 
you are using a scalar assignment
 gconftool -s /apps/mutter/general/overlay_key -t string "super_r"   worked (after shell restart) for me
i got a answer from serverfault stackexchange
with gnu du (i.e
this can be done with the cpufreq-set command from cpufrequtils
only output from the kernel itself will be in dmesg.  the other output is from the init process and the services it starts
to debug bash or shell scripts, it's useful to either run it with bash -x or edit the script and add a line saying set -x
in general, opensuse doesn't have yum, it will have zypper.  you can install yum; however, that might not be what you want.  if you know where the repo is, you can just  zypper addrepo --refresh path-to-repo   then you can install the software using  zypper in name-of-software.   what particular piece of software do you want to install? 
that you cannot install xdotool because you are not root doesn't mean you cannot run the program, for that you don't need any special privileges.  just download and compile from source
if your login shell can't be executed on some machine, then you can't log into it over ssh, or by most other methods for that matter
your safest pick, without the need of making any changes to your current qcow disk, is adding another disk to the vm
just a small update, wine 1.4 is nowadays available in the sid repository - just run apt-get update and apt-get install wine.  original answer:  wine 1.4-0.1 is in the experimental repository
i liked the idea, so i did it
when you type command that don't exists in your system bash runs function command_not_found_handle()
if you've only deleted the partition - you stand a better chance of getting your data back
i think capture-pane might suit your needs:  tmux capture-pane -pt "$target-pane"   (see “target-pane” in the man page for the ways to specify a pane)  by default, that command will dump the current contents of the specified pane
the *.1, *.2.gz, etc
to remove the popup in slackware i ran:  removepkg /var/log/packages/xfce4-notifyd-0.2.2-i486-2  
1
.* matches all files whose name starts with .
try to delete its local database: rm -f ~/.config/banshee-1/banshee.db
sudo supports this.  $ echo hello world | sudo cat   sudo password:  hello world   the difference being that sudo asks for your user password, not the root (target user) password
just remove all cases of identityfile and then add them again explicitly:  $ perl -i -ne 'next if /identityfile/;              s#yourname#adminuser\nidentityfile ~/.ssh/id_rsa#;              print' file $ cat file user adminuser identityfile ~/.ssh/id_rsa  . . . user adminuser identityfile ~/.ssh/id_rsa installing installing   the next if /identityfile/ skips any lines matching identityfile
   head detached at c70e611   this is because when you did the git reset --hard, you were not on any branch at that time
you can use inventory_hostname magic variables in this case.  {     "atlanta"     : {         "hosts"   : [ "host1", "host4", "host5" ],         "vars"    : {             "ansible_ssh_host" : "{{inventory_hostname}}.example.com",             "b"   : false         } }  
first you can confirm that you already have the mpm_prefork module by seeing that's shipped in the apache2 package in 16.04
you are already having memory issues and processes killed because of it (oom killer); as such i do not recommend installing cacti locally.  nevertheless, the cacti idea is very valid, as will enable you to have an understanding over time of the resource usage, and establish what is your baseline of service.  cacti is also used to monitor via snmp messages, and as such it should be deployed in another server.  if you want to use cacti to monitor your servers and network equipment via snmp, you just need to install the snmp service and configure it in your server, and install cacti in another server.  how to install and configure snmp on centos  i would also investigate the xmx and xms java parameters
i had   $ a\end    at the bottom  i had to change it to   $ a\ end  
ln -s ../src include/bb   either creates a link named include/bb referring to ../src (relative to its location), or it creates a file include/bb/src referring to ../src (relative to its location)
-config file        specifies the name of an xkb configuration        file which describes the keyboard to be used.   i think this dates back from the time of xf86cfg
test if you are root, and if not, restart with sudo, for example:  #! /bin/bash  if [[ $euid -ne 0 ]]; then     exec sudo /bin/bash "$0" "$@" fi  
there's the good ol' awk staple   awk -f
assuming the rest of your command works correctly, you can just replace the last part  xargs tar -xvpf   with  (cd /certain/directory; xargs tar -xvpf)   and the tar command will be executed from this directory. this is a common useful 'trick' for executing commands relative to another directory.  note this only works in this because your tar file name (in this case, the output from the find command) is an absolute path
your problem is the "*" in [a-za-z]*, which is matching no characters. replace it by + to match at least one alpha char. 
they are not loaded automatically at start-up or any other time, although a lot of them do end up being loaded during boot
task descriptions are stored in /usr/share/tasksel/descs  the format of task descriptions is explained in /usr/share/doc/tasksel/readme.gz     the file format is a rfc-822 style stanza, with fields named task, section   description (which should include an extended description), key, packages,    enhances, test-, relevance, and parent fields.   here is an example of a description  task: graphical-games relevance: 9 parent: games section: user description: graphical games  this task provides a variety of graphical games
you will need access to the old servers too.  then you should be able to simply copy the contents using scp or, more efficiently, by creating a gzipped tar file of the content on the old servers, moving everything to the new one with scp and untaring there.  if this is going to be a repeated task, with changing content on the old servers, it might be better to use rsync
you can use the command line tool repotrack to download everything required by a given package
simply by typing tty:  $ tty  /dev/pts/20   too simple and obvious to be true :)  edit: the first one returns you also the pty of the process running grep as you can notice:  $ ps ax | grep $$ 28295 pts/20   ss     0:00 /bin/bash 29786 pts/20   s+     0:00 grep --color=auto 28295   therefore you would need to filter out the grep to get only one result, which is getting ugly:  ps ax | grep $$ | grep -v grep | awk '{ print $2 }'   or using   ps ax | grep "^$$" | awk '{ print $2 }'   (a more sane variant) 
warning: don't use gparted to resize a multi-device btrfs filesystem!  data loss likely to happen!  looks like gparted is the culprit
the solution that seems to work best for me is to edit /etc/gdm/postlogin/default
given the size differences i would not bother to combine the 250gb drive with the new 2tb drive
with rsync  what you're doing is essentially an incremental backup: your friend (your backup) already has the original files, and you want to make an archive containing the files you've changed from that original.  rsync has features for incremental backups.  cd original_and_my_changed rsync -a -c --compare-dest=../original 
test with $# the total number of arguments provided
often the driver code for linux you find at random sites (i.e., not in the vanilla kernel code, or some dedicated repo with kernel sources for a family of related devices) is way, way out of date with respect to the kernel sources you are trying to build against
you're looking for  :set splitright   you can also influence this for individual commands, e.g.  :rightbelow vsplit  
it sounds like you want env. 
first, make a backup of the existing files, just in case.  tar czf modx-old.tar.gz html/cms   then use cp to copy the new files into place
that is a difficult question to answer
you should just install the python version from the repositories
when does a job become a past job? if you turn on the system at 7:59:50 and the at daemon starts at 8:00:01, should the job be executed? what if the daemon starts at 7:59:59 but takes two seconds to read all of its files?  you decide! start your job with a time check, and abort if the time is past.  export execute_by_date=$(date +%s 'tomorrow 8:01') at tomorrow 8:00 [ "$(date +%s)" -le "$execute_by_date" ] || exit do_stuff ␄  
this page describes the interactive command in detail, and is in fact a fairly thorough tutorial
if you have an arch install disk, you can boot off it, mount your install partition and use pacstrap to install dhcpcd, similar to how you installed arch in the first place
the shell commands are executed when the config setting is read, not every time you reply
does ctrl+alt work?  found it mentioned in a bug tracker, but i can't test it myself as i don't use kde. 
bluez provides a shared library called libbluetooth.so
when you're looking for a file belonging to a package which is installed on your machine, you can use dpkg -s (equivalent to dpkg-query -s):  dpkg -s /etc/exports   in this case though it won't find anything, because /etc/exports is created by a maintainer script (and that type of file is explicitly not handled by dpkg-query, or for that matter by apt-file).  so if apt-file and dkpg -s fail to find a file, you can try to look through the maintainer scripts:  grep /etc/exports /var/lib/dpkg/info/*   this should match nfs-kernel-server's maintainer scripts; that's the package which creates /etc/exports, at least on my nfs servers. 
you will first need to reconstruct the partition table the way it was
a chroot jail is a way to isolate a process and its children from the rest of the system
sed -e 's/ \([0-9]:\)/ 0\1/'   adds a zero if a single digit occurs between a space and a colon
your */.* will only include hidden files in subdirectories
-4/-6 tells dig to only use ipv4/ipv6 connectivity to carry your query to the nameserver - it doesn't change whether to query for a records(ipv4) or aaaa records(ipv6) if that's what you intended
in linux there are many tools for that, for example lsblk, fdisk -l or parted -l.  example  $ lsblk name           maj:min  rm  size    ro  type  mountpoint sda            8:0      0   238.5g  0   disk ├─sda1         8:1      0   200m    0   part  /boot/efi ├─sda2         8:2      0   500m    0   part  /boot └─sda3         8:3      0   237.8g  0   part ├─fedora-root  253:0    0   50g     0   lvm   / ├─fedora-swap  253:1    0   2g      0   lvm   [swap] └─fedora-home  253:2    0   185.9g  0   lvm  
this does it in a safe and portable way
portable to all posix shells:  if [ -n "${foobar+1}" ]; then   echo "foobar is defined" else   echo "foobar is not defined" fi   make that ${foobar:+1} if you want to treat foobar the same way whether it is empty or not defined
from your description i suspect you're looking for enabling paste mode in vim
per your comments, you only have to descend one level deep
type grep lm /proc/cpuinfo (lm stands for long mode)  or just try booting with a 64-bit os: if you do not have 64-bit support, it will say so and not boot.  lm: long mode (x86-64: amd64, also known as intel 64, i.e
no stdout/stdin there at the pam stage
when you examine the contents of /proc/cpuinfo, the flags for the cpu will include "pae". 
the newer version of dconf-editor now lists the options.    in this example, if you click on debug, you'll see a list of other available values
you can use the stat command to check the file's modification time before and after nano
try  sudo dpkg-reconfigure console-setup   then choose your font + size :)  source 
the file fmpcb.h no longer exists in the most recent version of arb
you need to learn some sort of text editor
man bash says:     ..
you have to install ntfs-3g as said by @lgnacio.  # rpm -uvh http://download.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-5.noarch.rpm   and installing the epel repo
it does not rely on the desktop environment
trash:// is a protocol, not a location
you probably want tail -f (note that it is capitalised), which will retry opening/reading the file if it fails.  from man tail:     -f, --follow[={name|descriptor}]           output appended data as the file grows; -f, --follow,            and --follow=descriptor are equivalent     -f     same as --follow=name --retry     --retry           keep trying to open a file even when it is or becomes           inaccessible; useful when following by name, i.e., with           --follow=name   if your version of tail doesn't have -f (which is equivalent to tail -f=name --retry), you could use inotify, and wait for close_write (inotifywait is part of inotify-tools):  file=foo  while inotifywait -qq -e close_write "$foo" &gt;/dev/null; do     cat "$foo" done &gt; log   tail -f should be preferred if available, because there is a race condition when using inotifywait. 
every time a begin line is encountered, separately read the next numeric line from the file using a separate handle via getline
try xrandr --verbose
if you want a graphical solution, then you might be able to open them with open office or libre office.  there's also antiword     antiword is a free ms word reader for linux and risc os
ok, i got it now
with the kind of input you show, the only way to leverage shell expansion to substitute values into a string is to use eval in some form
after analyzing the function gotojump() described in the link: http://vim.wikia.com/wiki/jumping_to_previously_visited_locations  i figured out that you have to type the jump number in normal mode and then press ctrl+o 
i don't think it's mapping to marigold
   so between 2^63 and 2^64-1, you get negative integers showing you how far off from ulong_max you are.   no
from greg's wiki: the bash guide entry on arrays:  files=() while read -r -d $'\0'; do     files+=("$reply") done &lt; &lt;(find *.txt -print0)  there is a detailed explanation of arrays on the page that breaks this construct down element by element; it is well worth reading in full. 
main.sh  #!/bin/bash set -e  if [ ! -p in ]; then     mkfifo in fi tail -f in | java -jar app.jar   send command to the application with following syntax  echo "command" &gt; /home/user/in  
the reason is that the operating system needs memory to manage each open file, and memory is a limited resource - especially on embedded systems
i have got a perfect chain loader with syslinux, grub4dos and grub2, and here is my configs:  syslinux  label dsl kernel memdisk initrd /iso/dsl.iso append iso raw  label grub4dos kernel /boot/grub.exe   grub4dos  title paragon partition manager map (hd0,0)/iso/paragon-bootable-media.iso (hd32) map --hook chainloader (hd32) boot  title syslinux chainloader /boot/syslinux/syslinux.bin  title grub2 chainload root (hd0,0) kernel /boot/grub/core.img boot   grub2  menuentry "ubuntu 13.10 desktop iso" {   loopback loop /iso/ubuntu-desktop-amd64-13.10.iso   linux (loop)/casper/vmlinuz boot=casper iso-scan/filename=/iso/ubuntu-desktop-amd64-13.10.iso noeject noprompt splash --   initrd (loop)/casper/initrd.lz }  menuentry "tinycore iso" {   loopback loop /iso/tinycore.iso   linux (loop)/boot/bzimage --   initrd (loop)/boot/tinycore.gz }  menuentry "grub4dos" {   linux16 /boot/grub.exe }  menuentry "syslinux" {   chainloader=/boot/syslinux/syslinux.bin }  
i found the answer from this thread (http://ubuntuforums.org/showthread.php?t=2114055) over at ubuntuforums.org.  it seems with newer gigabyte mainboards (at least) there is a bios option called iommu controller that is disabled by default and gives no clue or indication as to what it is for.  enabling this setting and rebooting "magically" restores all my usb and networking problems in a 64-bit linux os (doesn't matter which one).  i am rather shocked and elated that it was such a long search for such a simple fix.  thanks everyone for your help and suggestions
if you're always interested in deleting the last 3 lines of a file you can simply do this using head.  $ head -n -# ex.txt   example  example file.  $ cat ex.txt  1 2 3 4 5   drop the last 3 lines:  $ head -n -3 ex.txt  1 2   do this and save it to the same file.  $ head -n -3 ex.txt | tee ex.txt  1 2   confirm update was applied to file ex.txt.  $ cat ex.txt  1 2  
in mysql 5.7, the password field in mysql.user table field was removed, now the field name is authentication_string
there is no command to retarget a symbolic link, all you can do is remove it and create another one
run the same command again, but include the -c option
iirc, pure posix make doesn't allow that
try this:  setxkbmap -option keypad:pointerkeys   and then the combination. 
you could use -i switch if you want to be prompted only once:  rm -ri sampledir/   from man rm:  -i     prompt once before removing more than three files, or when removing recursively.        less intrusive than -i, while still giving protection against most mistake   and use -f for "no prompt":  -f, --force        ignore nonexistent files and arguments, never prompt   so:  rm -rf sampledir/  
according to http://www.privoxy.org/user-manual/config.html#logdir, the log file should be in /var/log/privoxy
the benefit to find is that it is recursive
use another character as delimiter in the s command:  echo $srctext | sed "s|xplaceholderx|$connect|"   or escape the slashes with parameter expansion:  echo $srctext | sed "s/xplaceholderx/${connect//\//\/}/"  
   is there a way to keep the /lib folder clean?    it is not in the nature of the lib directories on a unix/linux type system to be "clean." they are aggregate directories, collectively holding all of the library files that your system needs.  they might contain libraries that you don't need any more
i installed the standard splunk light (without any add-ons), and it's enough to display and analyze postfix logs. 
this will be a bit more complicated, but combination of several pieces will make it working:  explanation   to force ssh to use $ssh_askpass program, you can't allow ssh to see the real tty
@l0b0's solution rewritten for better robustness:  printf '%s\0' index-*.txt |   sort --zero-terminated --field-separator - --key 2rn |   xargs -0r rename --verbose '     s/^index-([0-9]+)\.txt$/$1/;     $_="index-" 
this should work with gnu sed:   sed -i '1s/^/string/' file   it's different from your solution in not adding the new line.  test  before running command, the content of file is this:  some text here already   after running the command:  stringsome text here already  
starting from your first attempt, you want ${var1} expanded by the shell, and all other $ variables protected from it (so that perl expands them instead):  perl -i -pe "s/(keepme=)(.*)/\$1${var1}/ if \$
press alt + f2 and enter gconf-editor
variables are referenced by name as in var, not $var in awk
in the spirit of this i will answer my own question.  so to get this to work:   open the terminal application in centos (in the applications\accessories\terminal) select the edit\current profile (if you want to make this the default for your current profile) select the "title and command" tab and tick the option "run command as login shell"   this then ensures that when you fire up terminal it executes the .profile and .bashrc sourcing. 
well, i could not find any mutt color like configuration statements that allow to apply color information over multiple lines.  perhaps the easiest way to deal with outlook message is to setup a filter, e.g
first of all, don't add mint repositories to debian, not a good idea
bash has no such feature
solaris, or opensolaris.  a fairly interesting unix successor is the research os plan 9 from bell labs. 
this package is from the experimental distribution
(cd ~ &amp;&amp; /bin/food)  this launches it in a subshell. 
assuming it is an ext2-family filesystem:  uuidgen tune2fs -u &lt;output of uuidgen&gt; /dev/sdb1   or if you're confident uuidgen is going to work:  tune2fs -u `uuidgen` /dev/sdb1   the uuid is stored in the superblock, so a byte-for-byte copy of the filesystem will have the same uuid. 
instead of a service to do the insmod you could provide a /lib/modprobe.d/mymodule.conf with the line  install mymodule insmod /path/to/mymodule.ko     i tried this and it worked ok on a fedora 22 using as an example the existing slip module.  $ cd /lib/modules/4.2.8-200.fc22.x86_64/extra/drivers/net/slip/ $ lsmod|grep slip $ sudo modprobe slip $ lsmod|grep slip slip                   20480  0 slhc                   20480  1 slip $ sudo rmmod slip $ lsmod|grep slip $ sudo mv slip.ko.xz ~ $ sudo modprobe slip modprobe: error: could not insert 'slip': unknown symbol in module, or unknown parameter $ sudo sh -c 'echo install slip insmod /home/meuh/slip.ko.xz &gt;/lib/modprobe.d/mymodule.conf' $ sudo modprobe slip $ lsmod|grep slip slip                   20480  0 slhc                   20480  1 slip  
although underlying crypto primitives are similar, pgp file (packet) formats including keys are very different from those  used by openssl (mostly asn.1 and pem)
using perl:  perl -lane 'begin{ print("\t\tt1\tf2\ti1\tf3\tregulated f2\tfr t1"); $, = "\t" } if($f[0] =~ /00:00:t[0-9]+/){ @f[0] = $f[0]; @f[1] = $f[2]; for($i = 2; $i &lt; 7; $i++) { $_ = &lt;&gt;; @f=split(); if($i &lt; 5){ $f[$i] = $f[1] }else{ $f[$i] = $f[2] } } print(@f) }' file   expanded script (to be made executable with chmod +x script.pl and to be run with ./script.pl file):  #!/usr/bin/perl -lan begin {     print("\t\tt1\tf2\ti1\tf3\tregulated f2\tfr t1");     $, = "\t" } if($f[0] =~ /00:00:t[0-9]+/) {     $f[0] = $f[0];     $f[1] = $f[2];     for($i = 2; $i &lt; 7; $i++) {         $_ = &lt;&gt;;         @f=split();         if($i &lt; 5) {             $f[$i] = $f[1]         }         else {             $f[$i] = $f[2]         }     }     print(@f)  }   you can adjust the header by modifying print("\t\tt1\tf2\ti1\tf3\tregulated f2\tfr t1"); and the output field separator by modifying $, = "\t".  % cat file 19-08-02  name                         appel    ok    hope    local  merge   (mk)                                                         juin    nov    sept    oct 00:00:t1  t1                            299       0      24      8      3     64           f2                            119       0      11      8      3     62           i1                             25       0       2      9      4     64           f3                            105       0      10      7      3     61           regulated f2                    0       0       0           fr t1                         104       0      10      7      3     61 00:00:t2  t1                            649       0      24      8      3     64           f2                            119       0      11      8      3     62           i1                            225       0       2      9      4     64           f3                            165       0      10      7      3     61           regulated f2                    5       0       0           fr t1                         102       0      10      7      3     61 20-08-02  name                          appel    ok    hope    local  merge   (mk)                                                         juin    nov    sept    oct 00:00:t5  t1                            800       0      24      8      3     64           f2                            111       0      11      8      3     62           i1                             250      0       2      9      4     64           f3                            105       0      10      7      3     61           regulated f2                    0       0       0           fr t1                         100       0      10      7      3     61 % perl -lane 'begin{ print("\t\tt1\tf2\ti1\tf3\tregulated f2\tfr t1"); $, = "\t" } if($f[0] =~ /00:00:t[0-9]+/){ @f[0] = $f[0]; @f[1] = $f[2]; for($i = 2; $i &lt; 7; $i++) { $_ = &lt;&gt;; @f=split(); if($i &lt; 5){ $f[$i] = $f[1] }else{ $f[$i] = $f[2] } } print(@f) }' file         t1  f2  i1  f3  regulated f2    fr t1 00:00:t1    299 119 25  105 0   104 00:00:t2    649 119 225 165 5   102 00:00:t5    800 111 250 105 0   100 %   
from terminal, you type parted /dev/hda then type print as result:   number  start   end    size   type     file system  flags       1      32.3kb  107mb  107mb  primary  ext3         boot, raid  2      107mb   250gb  250gb  primary               raid   
usually, a command is run in the background with &amp;.  so sleep 100 &amp; should give you the results you are looking for.  you can also do as you posted in your answer, the problem is that when running bg you'd better tell what you want to run in the background so, after ctrl+z you should run jobs and identify your job in case there are more than one, and after that run bg %your_job_id. 
good question
there are a couple of approaches that you can pursue.   re-run ./configure with the same options you originally passed to it and then run make uninstall
i managed to work it out, so thought i would share what i did in case anyone else had a similar problem
if you have rsync (remove --dry-run to do it for real):  rsync --dry-run --remove-source-files -avhax /unencrypted/ /encrypted   otherwise, using bash4+ and gnu stat:  #!/bin/bash  set -e  shopt -s nullglob globstar  for from in /unencrypted/**/*; do     to="${from/\/un//}"     if [[ -d "$from" ]]; then         echo mkdir -p "$to"         echo chmod "$(stat -c %a "$from")" "$to"         echo chown "$(stat -c %u:%g "$from")" "$to"     else         echo cp -a "$from" "$to" &amp;&amp; echo rm "$from"     fi done  echo rm -r /unencrypted   to run it for real, remove echo from each command. 
you should read the arch wiki page on sudo.  sudo ("substitute user do") allows a system administrator to delegate authority to give certain users (or groups of users) the ability to run some (or all) commands as root or another user while providing an audit trail of the commands and their arguments.  you can install sudo from the repositories and then configure it to allow your user, jack, access to privileged commands by editing /etc/sudoers
most probably you have got a sles10 sp4.  do a rpm -v sles-release - if /etc/suse-relase does not show "5" (i.e
with gnu date, you can use the same date string format for both -d and -s options.  to convert from seconds since epoch to human readable format:  date -d '@2147483647'   to set it:  date -s '@2147483647'     with *bsd date:  # convert seconds since epoch $ date -r 2147483647  tue jan 19 03:14:07 utc 2038  # set date by seconds since epoch $ date "$(date -r 2147483647 +'%y%m%d%h%m.%s')" tue jan 19 03:14:07 utc 2038  
route is the old traditional tool and available on numerous unix systems
i used rpmfind to find what package you need:   and i see:   xorg-x11-libx11-devel-32bit-7.6-10.2.x86_64.html    include files and libraries mandatory for development
./configure - configure script basicly the script consists of lines which are checking some details about the machine on which the software will be installed
filter 'ip6 and icmp6' is all that works for me
wrap it in sh -c:  nohup sh -c 'wget "$0" &amp;&amp; wget "$1"' "$url1" "$url2" &gt; /dev/null &amp;  
with zsh:  printf '%s\n' **/*(d^om/:t)   those are glob qualifiers, a feature unique to zsh at this time.   d: include dot-files ^: reverse the following qualifiers om: order on modification time (reversed with ^) /: exclude (with ^) files of type directory. :t: a modifier that gets the tail of the file (the basename).   (if you want the full path as opposed to just the basename, just remove :t).  with bash or any shell, provided zsh is available:  zsh -c 'printf "%s\n" **/*(d^om/:t)'   or on a gnu system:  find 
perl solution, assumes input file is sorted by c1, c2, etc.
the algorithm is described in much detail in the apt_preferences man page
you could do something like this to start a process with the desired pid
most terminals can be launched using the geometry switch allowing you to specify terminal's size and position (columnsxrows+x+y) e.g.:  gnome-terminal --geometry 73x31+100+300   or  xterm -geometry 93x31+100+350   if you want to make the above permanent, copy the terminal launcher (terminal's .desktop file) from /usr/share/applications/ to ~/.local/share/applications/ and edit the exec field accordingly.  e.g
the setting that controls immediate deletion is available in dconf-editor.  org nemo preferences enable-delete.    even though the default setting is enabled it didn't work correctly
assuming you have root on the system, you can use a bind mount
you can pipe mail to vim, at least on my test system (rhel 6.7) it worked.   mail | vim -   the vim - tells vim to read from standard input  you should see output that say's:  vim: reading from stdin...   at that point just press the number of the mail item you want to read, ie 1 to read the first message,then press ctrl-d to push it forward. 
there are many ways:   esc, shift+c ctrl+o, shift+d shift+end, del shift+end, s   don't be afraid of falling back to the normal mode even for a short instant. 
i've figured it out myself:  xdotool mousemove 500 100 getmouselocation --shell mousemove restore  this briefly moves the mouse to the specified position (x=500, y=100 in this example), prints window which is the windowid on top, then moves the mouse back.  this is probably not the intended usage of mousemove, but i could not find any better way to do what i wanted. 
if your data now is on the usb stick, then that data will not be touched by installing ubuntu on you harddrive.  after booting from harddrive you probably just insert the usb stick and pull the data from the stick into your new account on the harddrive.  if for some reason that would not be possible, then there is an alternative that certainly will work: boot one last time from usb, mount the newly formatted linux partition that is on the harddrive and copy your data over from the usb stick the harddrive that way. 
you can use the pwd variable and parameter expansion constructs to quickly apply a text transformation to the current directory.  cd ${pwd/parent1/parent2}   this doesn't have to be exactly a path component, it can be any substring
to pass the array elements as arguments to the function, use the ksh syntax to expand the elements of the array as a list.  work_on_array "${myarray[@]}"   the [@] suffix makes this an array expansion
what about this :  cat your_file.txt | grep "name of device load:" | cut -d ":" -f 2 | tr -d " "   this only keeps the line you are interested in, seperates it into two fields (works only if : is only present once per line), then remove spaces. 
i don't think i understand the first part of your question based on your later comments
if you have the gnu version of more installed:  more -d -f -10 foo   this displays the file foo 10 lines at a time, pausing with a prompt messsage after each 10 lines
according to http://www.fileformat.info/info/unicode/char/10100/fontsupport.htm the following several fonts support u+10100: code2001, eversonmono (and eversonmono oblique), mph 2b damase, and penuturesu
first check the disks, try running smart selftest  for i in a b c d; do     smartctl -s on -t long /dev/sd$i done   it might take a few hours to finish, but check each drive's test status every few minutes, i.e.  smartctl -l selftest /dev/sda   if the status of a disk reports not completed because of read errors, then this disk should be consider unsafe for md1 reassembly
answered here already..
update: this awk script may be more what you are looking for:    awk -vrs='\r\n ' -vors= 1 contacts.vcf    (original post) this perl script works, though it is actually longer, even when sed is spaced out a bit; and it is quite obviously logically very similar to sed
python -m httpsimpleserver &amp;  # your python process will now be in the background serverpid="$!"                # capture its pid so that you can kill it later. watch -n /path/to/awesometestcommand arg1 arg2 # some time later... kill "$serverpid"             # make your python process go away  
you should use the mount(8) command, which is available out of the box on all linux and unix systems.  if you run mount without any additional arguments, it will list all the currently mounted partitions on your system, file system type and any mount options, such as noexec, rw, or nosuid.  eg:  % mount proc on /proc type proc (rw,nosuid,nodev,noexec,relatime) /dev/sda1 on /boot type ext4 (rw,relatime,data=ordered) /dev/mapper/basement-root on / type ext4 (rw,relatime,data=ordered)  
the installroot tool is usefull for situations like installing packages into a chroot environment
your script doesn't work because ^ introduces a control character sequence
from the manual (man bash):     when a login shell exits, bash reads and executes commands from the files ~/.bash_logout and /etc/bash.bash_logout, if the files exists
in order to forward root's e-mails to another e-mail address, you could change the line related to root in the file /etc/aliases
gedit supports vb.net syntax out of the box
first, i tried strace parent processes like systemd and xorg.bin, but i'm new to strace so i can't figure out.  then i thought it might related to permission issue (su -, sudo, ...etc)
if all goes well, your kernel should decide to "do the right thing" all by itself
in tcsh, this behaviour is turned on with set implicitcd, and not set autocd. 
you can just start the example.py with the full path to example-env/bin/python2.  alternatively change the shebang line of the example.py to use that executable, make that file executable (chmod +x example.py) and leave out python and use the full path to example.py to start it:  #!/full/path/to/example-env/bin/python2  
you should be able to use libreoffice in batch mode from the command line e.g.  libreoffice --headless --convert-to doc *.odt   or  libreoffice --headless --convert-to docx *.odt  
it sounds like something has sent mail on (and to) the machine using the local mail exchanger
you can extract a pem public key from an openssh private key using:  openssl rsa -pubout -in .ssh/id_rsa   but openssh has no tools to convert from or too pem public keys (note: pem private keys are openssh's native format for protocol 2 keys) 
you may wish to consider using a ruby package manager like rvm or rbenv  you can install different rubies and switch between them easily.  you might also want to consider trying 2.0+  sample output from rvm:  21:59:48 durrantm castle2012 /home/durrantm  $ rvm list  rvm rubies     ruby-1.8.7-p374 [ x86_64 ]    ruby-1.9.3-p125 [ x86_64 ]    ruby-1.9.3-p194 [ x86_64 ]    ruby-1.9.3-p448 [ x86_64 ]    ruby-2.0.0-p195 [ x86_64 ] =* ruby-2.0.0-p247 [ x86_64 ]    ruby-2.0.0-p481 [ x86_64 ]    ruby-2.1.1 [ x86_64 ]    ruby-2.1.2 [ x86_64 ]  # =&gt; - current # =* - current &amp;&amp; default #  * - default  21:59:50 durrantm castle2012 /home/durrantm  $ rvm use 2.0.0 using /home/durrantm/.rvm/gems/ruby-2.0.0-p481  $ rvm use 2.1.1 using /home/durrantm/.rvm/gems/ruby-2.1.1  $ rvm use 1.9.3 ruby-1.9.3-p547 is not installed.  $ rvm use 1.9.3-p448 using /home/durrantm/.rvm/gems/ruby-1.9.3-p448   get rvm at http://rvm.io/  install with its famous 1 liner:  $  \curl -ssl https://get.rvm.io | bash -s stable 
afaik there is no existing ports of this font to any outline variant
think of it as a if-then-else   {s=s?s fs $i:$i}    evaluate to    { if ( s != "" ) s=s fs $i ; ## i=3,5,7,...    else s=$i ; } ## i=1   this looks like a obscure code.  awk -f\| '{s="";for (i=1;i&lt;=nf;i+=2) {s=s?s fs $i:$i} print s}' file   is equivalent to (easiest to understand)  awk -f\| '{s=$1;for (i=3;i&lt;=nf;i+=2) {s=s fs $i} print s}' file  
you need to log in again after adding yourself to a group to get the correct privileges.  to verify with two shells:  alice $ sudo adduser test                                 alice $ su - test alice $ sudo adduser test sudo                                 test $ sudo ls                                 test is not in the sudoers file
you can use the action hold returned by access control.  for example:  /etc/postfix/main.cf: smtpd_recipient_restrictions =     check_sender_access hash:/etc/postfix/sender_access  /etc/postfix/sender_access: sender1@mydomain.com     hold sender2@mydomain.com     hold   then you can manage the release of the hold using the postsuper command.  see the following for additional details:  http://www.postfix.org/access.5.html pay close attention to description of hold action.  http://www.postfix.org/postsuper.1.html 
when a drive is kicked from a raid array, its metadata is no longer updated
i'm pretty sure you can just do:  cat ./tmp[12] | sed -f - ./wrong_file &gt;outfile   at least, that will not cause any issues if all of sed's script instructions are specific to line number
i think it's not possible
rsync doesn't try to resolve conflicts
yes, just use for restore image from clonezilla:  cat sda5.ext3-ptcl-img.gz.a* | gunzip -c | partclone.restore -d -s - -o /dev/sda5  
   systemd grabs the serial console and squelches the kernel, so i only get the bootloader messages   does it? it doesn't
ssh user@remote bash -c 'cd /home/foo/bar; shopt -s extglob; rm !(special_file)'   details  from the bash man page, this feature is called extglob. 
you have the --non-interactive option
assuming you use a recent version of zsh, ksh93 or bash and the filename doesn't contain newline characters:  # split up the filename into its parts ifs=_ read -r pjid env srcid desc date seq free &lt;&lt;&lt; "$filename"  # extract the codepage from the free text code=${free##*.} free=${free%.*}  # validate if  [[ $pjid  =~ ^[[:alnum:]]{3,8}$ ]]                                  &amp;&amp;     [[ $env   == "dev" || $env == "syt" || ..
what you are doing there is at least 'complicated'
i got this working by adjusting the escape codes to watch for in my .vimrc. i still wish i had a better understanding of how all this works, and why the sequence sent by tmux differs from what's sent outside of tmux, but this got everything working:  if &amp;term =~ "screen"   set  &lt;f13&gt;=[1;2p   set  &lt;f14&gt;=[1;2q   set  &lt;f15&gt;=[1;2r   set  &lt;f16&gt;=[1;2s   set  &lt;f17&gt;=[1;5p   set  &lt;f18&gt;=[1;5q   set  &lt;f19&gt;=[1;5r   set  &lt;f20&gt;=[1;5a   set  &lt;f21&gt;=[1;5b elseif &amp;term =~ "xterm"   set  &lt;f13&gt;=o2p   set  &lt;f14&gt;=o2q   set  &lt;f15&gt;=o2r   set  &lt;f16&gt;=o2s   set  &lt;f17&gt;=o5p   set  &lt;f18&gt;=o5q   set  &lt;f19&gt;=o5r   set  &lt;f20&gt;=[1;5a   set  &lt;f21&gt;=[1;5b endif  " use some unused function key codes to " make special key combos work in terminal map  &lt;f13&gt; &lt;c-cr&gt; map! &lt;f13&gt; &lt;c-cr&gt; map  &lt;f14&gt; &lt;s-cr&gt; map! &lt;f14&gt; &lt;s-cr&gt;  map  &lt;f15&gt; &lt;c-space&gt; map! &lt;f15&gt; &lt;c-space&gt; map  &lt;f16&gt; &lt;s-space&gt; map! &lt;f16&gt; &lt;s-space&gt;  map  &lt;f17&gt; &lt;c-bs&gt; map! &lt;f17&gt; &lt;c-bs&gt;  map  &lt;f18&gt; &lt;m-tab&gt; map! &lt;f18&gt; &lt;m-tab&gt; map  &lt;f19&gt; &lt;m-s-tab&gt; map! &lt;f19&gt; &lt;m-s-tab&gt;  map  &lt;f20&gt; &lt;c-up&gt; map! &lt;f20&gt; &lt;c-up&gt; map  &lt;f21&gt; &lt;c-down&gt; map! &lt;f21&gt; &lt;c-down&gt;  
external media/drives mounting is handled by udisks2 on most modern distros
in theory, you should be able to "undo" this installation by removing kchmviewer and all automatically installed packages:  apt-get remove kchmviewer &amp;&amp; apt-get autoremove   but pay attention to the packages removed by the second command
/proc is a filesystem because user processes can navigate through it with familiar system calls and library calls, like opendir(), readdir(), chdir() and getcwd()
i found a solution.  i copied /usr/lib64/libx* to .dropbox-dist
you have two different keymaps
install the package named as:     colortest   and enjoy coloring by running the binaries like colortest-8  colortest-16 colortest-16b and so on 
you could use xkb-switch (-n switches to next layout):  xkb-switch -n   or xkblayout-state (with set +1 to wrap around, in your case) :  xkblayout-state set +1   or xte from xautomation to simulate control_l+shift_l key press/release:  xte 'keydown control_l' 'keydown shift_l' 'keyup shift_l' 'keyup control_l'  
networkmanager should be able to do this for you
for the most part the rt kernel will make subtle changes to insure your frame time is not over run
first make sure the user that you are going to use to make the backups:   can read all the 5 folders and their content  is able to use ssh into the server with the lto ( lets call that 'remote') without authentication into an acount named ltouser
i've too have tried to use zenity and yad to accomplish guis but as soon as i wanted to do anything more complex as you're suggesting i've hit a wall where these 2 tools weren't really meant to do such tasks
quoting the image catalog:     alpha/beta/release candidate builds of debian installer for stretch         alpha 5 is most recent - a full set of installer images for all architectures          regular builds of testing / (what will be stretch)         daily builds of installer images for all architectures (small cds only)   weekly builds of installer images for all architectures (some cds, full sets of dvds and bds)   weekly builds of live images for i386 and amd64   weekly builds of openstack images for amd64       alpha 5 refers to the debian-installer release; this is a tested release with release notes and errata.  the daily and weekly builds also install testing, but they are built automatically and there are no guarantees as far as the installer is concerned.  the default desktop on netinst cds is gnome; the other images specify which desktop they install (xfce on the other alpha 5 image; the weekly live images are available with cinnamon, gnome, kde, lxde, mate and xfce).  the safer bet is to use the netinst alpha 5 cd. 
 take a copy of any live linux distro you like (i usually use my old ubuntu cd) boot live session install boot repair (on ubuntu -   sudo add-apt-repository ppa:yannubuntu/boot-repair sudo apt-get update sudo apt-get install -y boot-repair boot-repair ) let it scan everything click on recommended repair reboot your system   this works for me almost every time. 
do you start guake automatically with your desktop-session? then yes write in $home/.config/autostart/guake.desktop by the key exec exec=guake -e tmux if not cp /usr/share/applications/guake.desktop $home/.local/share/applications/guake.desktop and make the change there. 
if you can stand a rolling release, use debian testing:   it provides a nice balance between up-to-dateness and stability
i am not sure what your requirement is but from what i infer below seems to be what you require:  awk -v var="$c" '{if (nr &lt; 15 &amp;&amp; $8 &gt;0.48 &amp;&amp; $8 &lt;0.52 &amp;&amp; $9 &gt;0.48 &amp;&amp; $9 &lt;0.52 &amp;&amp; $10 &gt;0.48 &amp;&amp; $10 &lt;0.52) {print var ":" $1 " " $8 " " $9 " " $10}}' rd00$c/mergerhalos.out &gt;&gt; center_raw.dat   -v option of awk is used to pass the external bash variable's value inside awk. 
there are a couple of options that you can combine.  the -c switch sorts by time modified [1]:  -c     with  -lt: sort by, and show, ctime (time of last modification of file status information) with -l: show ctime and sort by name otherwise:               sort by ctime  the -u and -t switches can also be used:  -t     sort by modification time -u     with -lt: sort by, and show, access time with -l: show access time and sort by name otherwise: sort by access time  you could put it all together like so [2]:  ls -ltcr         # sort by and show change time, most recent last ls -ltur         # sort by and show access time, most recent last ls -ltr          # sort by date, most recent last  [1] http://unixhelp.ed.ac.uk/cgi/man-cgi?ls  [2] -r reverses the order  
you can use word notation for more readability :  kill -stop &lt;pid&gt; # pause kill -cont &lt;pid&gt; # continue working   check   man 7 signal  
searching a bit more around the web, in this archlinux forum post is said restarting, and it worked.  i just wonder why it did... 
the documentation for bash is shipped in the bash-doc tarball
you may be missing a boot loader. you'll probably want to go with dd if=/dev/sda instead of /dev/sda1
duplicate of given a git patch id, how to find out which kernel release contains it?  in short: from your "fix" link, click "commitdiff" at the top, click "raw", and look at the x-git-tag header. 
0 1 * * * cp -a /tmp/files ~username/dropbox/tmp_backups_$(date +%y%m%d)   breakdown: every day at one am make an archive copy of /tmp/files into a folder with the date as part of the name in 'username's dropbox. 
you are using grep -n which prefixes matches with line numbers, so your second pattern "^\s*'" will never match
unlike extglob, nullglob makes a huge difference in the shell behavior
the simple answer to the question in the title is "yes"
with sed:  sed 's|/[^/]\+\.ear$|/ear2.ear|' file    it seaches for line ending with .ear ($ matches the end of the line)
the answer to the question  open network manager:    set the wired connection to shared:    that's it
the awk answer:  awk '{y=substr($3,1,4); c[y]++; s[y]+=$2} end {for (y in c) {print y, c[y], (s[y]/c[y])}}' file.txt  
the problem is that when you use a common modifier like altgr, programs actually see it as being pressed when you use the altgr arrows
correction:  the default sampling interval for atop is 10 seconds; atop writes compressed binary data to '/var/log/atop/atop_yyyymmdd' every 10 minutes.  sampling intervals and log file locations can set from the command line
"closing" a tty   if systemd is not the init being used then this will not help you. sysvinit is no longer supported by arch linux   systemd's systemctl is used to control all the service units on the system
there's a simpler way of what you're doing
emacs can be built with the gtk toolkit and gtk style can be configured to emulate the kde/qt look
that's because you're not printing the process group id (pgid), you're printing the "controlling tty process group id", tpgid
make a bind mount (use busybox mount if the built-in mount does not support the --rbind option)  mount --rbind  /sdcard/shared /sdcard/whatsapp   you need to call this command on each reboot.  for a permanent solution, you can also replace the directory with a soft/hard link to the target directory:  mv /sdcard/whatsapp /sdcard/whatsapp_old    #rename if needed ln -s /sdcard/shared /sdcard/whatsapp   
sudo apt-get remove libreoffice orage brasero exfalso quodlibet gimp imagemagick ristretto xsane   orage is an xfce4 dependency in at least ubuntu, therefore removing orage will also remove xfce
in the debian policy is written that debian follows the file hierarchy standard version 2.3
simply:  rm *.txt *.csv   and if your shell supports brace expansion, you can:  rm *.{txt,csv}  
you can play with repository (%r)
the magic combination is ps axfo pid,euser,egroup,args  here is an output example on ubuntu 16.04:  $ ps axfo pid,euser,egroup,args   pid euser    egroup   command     2 root     root     [kthreadd]     3 root     root      \_ [ksoftirqd/0]     4 root     root      \_ [kworker/0:0]     5 root     root      \_ [kworker/0:0h]     6 root     root      \_ [kworker/u4:0]     7 root     root      \_ [rcu_sched]     8 root     root      \_ [rcu_bh]     9 root     root      \_ [migration/0]    10 root     root      \_ [watchdog/0]    11 root     root      \_ [watchdog/1]    12 root     root      \_ [migration/1]    13 root     root      \_ [ksoftirqd/1]    14 root     root      \_ [kworker/1:0]    15 root     root      \_ [kworker/1:0h]    16 root     root      \_ [kdevtmpfs]    17 root     root      \_ [netns]    18 root     root      \_ [perf]    19 root     root      \_ [khungtaskd]    20 root     root      \_ [writeback]    21 root     root      \_ [ksmd]    22 root     root      \_ [khugepaged]    23 root     root      \_ [crypto]    24 root     root      \_ [kintegrityd]    25 root     root      \_ [bioset]    26 root     root      \_ [kblockd]    27 root     root      \_ [ata_sff]    28 root     root      \_ [md]    29 root     root      \_ [devfreq_wq]    30 root     root      \_ [kworker/u4:1]    31 root     root      \_ [kworker/1:1]    32 root     root      \_ [kworker/0:1]    34 root     root      \_ [kswapd0]    35 root     root      \_ [vmstat]    36 root     root      \_ [fsnotify_mark]    37 root     root      \_ [ecryptfs-kthrea]    53 root     root      \_ [kthrotld]    54 root     root      \_ [acpi_thermal_pm]    55 root     root      \_ [bioset]    56 root     root      \_ [bioset]    57 root     root      \_ [bioset]    58 root     root      \_ [bioset]    59 root     root      \_ [bioset]    60 root     root      \_ [bioset]    61 root     root      \_ [bioset]    62 root     root      \_ [bioset]    63 root     root      \_ [bioset]    64 root     root      \_ [bioset]    65 root     root      \_ [bioset]    66 root     root      \_ [bioset]    67 root     root      \_ [bioset]    68 root     root      \_ [bioset]    69 root     root      \_ [bioset]    70 root     root      \_ [bioset]    71 root     root      \_ [bioset]    72 root     root      \_ [bioset]    73 root     root      \_ [bioset]    74 root     root      \_ [bioset]    75 root     root      \_ [bioset]    76 root     root      \_ [bioset]    77 root     root      \_ [bioset]    78 root     root      \_ [bioset]    79 root     root      \_ [scsi_eh_0]    80 root     root      \_ [scsi_tmf_0]    81 root     root      \_ [scsi_eh_1]    82 root     root      \_ [scsi_tmf_1]    83 root     root      \_ [kworker/u4:2]    87 root     root      \_ [ipv6_addrconf]    88 root     root      \_ [kworker/1:2]    89 root     root      \_ [kworker/u4:3]   102 root     root      \_ [deferwq]   103 root     root      \_ [charger_manager]   221 root     root      \_ [kpsmoused]   242 root     root      \_ [kworker/0:2]   506 root     root      \_ [mpt_poll_0]   509 root     root      \_ [mpt/0]   513 root     root      \_ [scsi_eh_2]   514 root     root      \_ [scsi_tmf_2]   515 root     root      \_ [bioset]   517 root     root      \_ [bioset]   662 root     root      \_ [raid5wq]   695 root     root      \_ [bioset]   736 root     root      \_ [jbd2/sda1-8]   737 root     root      \_ [ext4-rsv-conver]   802 root     root      \_ [iscsi_eh]   805 root     root      \_ [ib_addr]   806 root     root      \_ [ib_mcast]   807 root     root      \_ [ib_nl_sa_wq]   808 root     root      \_ [ib_cm]   809 root     root      \_ [iw_cm_wq]   810 root     root      \_ [rdma_cm]   824 root     root      \_ [kauditd]  1198 root     root      \_ [iprt-vboxwqueue]  1778 root     root      \_ [kworker/1:1h]  1800 root     root      \_ [kworker/0:1h]  1854 root     root      \_ [kworker/1:3]  2524 root     root      \_ [kworker/0:3]     1 root     root     /sbin/init   794 root     root     /lib/systemd/systemd-journald   848 root     root     /sbin/lvmetad -f   872 root     root     /lib/systemd/systemd-udevd  1815 systemd+ systemd+ /lib/systemd/systemd-timesyncd  1836 root     root     /usr/sbin/cron -f  1838 daemon   daemon   /usr/sbin/atd -f  1840 root     root     /lib/systemd/systemd-logind  1851 root     root     /usr/sbin/acpid  1853 syslog   syslog   /usr/sbin/rsyslogd -n  1860 root     root     /usr/bin/lxcfs /var/lib/lxcfs/  1865 root     root     /usr/lib/accountsservice/accounts-daemon  1870 root     root     /usr/lib/snapd/snapd  1875 message+ message+ /usr/bin/dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation  1888 root     root     /sbin/mdadm --monitor --pid-file /run/mdadm/monitor.pid --daemonise --scan --syslog  1890 root     root     /usr/lib/policykit-1/polkitd --no-debug  1995 root     root     /sbin/dhclient -1 -v -pf /run/dhclient.enp0s3.pid -lf /var/lib/dhcp/dhclient.enp0s3.leases -i -df /var/lib/dhcp/dhclient6.enp0s3.lease  2184 root     root     /sbin/iscsid  2185 root     root     /sbin/iscsid  2288 root     root     /usr/sbin/irqbalance --pid=/var/run/irqbalance.pid  2294 root     root     /usr/sbin/sshd -d  2566 root     root      \_ sshd: ubuntu [priv]  2602 ubuntu   ubuntu        \_ sshd: ubuntu@pts/0  2603 ubuntu   ubuntu            \_ -bash  2618 ubuntu   ubuntu                \_ ps axfo pid,euser,egroup,args  2301 root     root     /sbin/agetty --keep-baud 115200 38400 9600 ttys0 vt220  2305 root     root     /sbin/agetty --noclear tty1 linux  2568 ubuntu   ubuntu   /lib/systemd/systemd --user  2570 ubuntu   ubuntu    \_ (sd-pam)  
variables are not expanded between single quotes.  use double quotes and escape the inner double quotes:  sshpass -p "password" \   ssh username@74.11.11.11 "su -lc \"cp -r $location2 $location1\";"   or close the single quotes and open them again:  sshpass -p "password" \   ssh username@74.11.11.11 'su -lc "cp -r '$location2' '$location1'";'   bash does string concatenation automatically.  note: not tested
cut and paste is the quickest to install the package
the simplest solution on mint is to install the tomcat7 package, if tomcat 7 is good enough:  sudo apt-get install tomcat7   once that's done, you can drop your webapps in /var/lib/tomcat7/webapps and they will deploy automatically
if you want to set this system-wide (and desktop-manager agnostic), you'll want to create an entry in /etc/x11/xorg.conf.d/ for your monitor, and set: option "dpms"  off
it really depends on the application that is used to open a document
braces are not wildcard patterns
according to steve grubb's reply on the official mailing list (link to the email):  steve's answer:          is it possible that there are duplicate fields in a record?         sometimes
there isn't a way to do this using yum but you can craft a rpm command that will do mostly what you want
i had a similar problem and was scratching my head over the lack of google results (after ending up at this page a few times), so i decided to just read up on how systemd works here.  eventually i figured out that networking is actually a sysv init script (/etc/init.d/networking), which is converted to a systemd service at runtime (/run/systemd/generator.late/networking.service), so you can't just modify an existing script.  instead you have to override it with a file at e.g
remove your system wide installation of pip:  sudo apt-get purge python-pip   then install a fresh copy of pip:  curl  https://bootstrap.pypa.io/get-pip.py | sudo python   tested on ubuntu 10.04 i686  i suggest you to use virtualenv
for commands use compgen -c:  $ compgen -c bas basename base64 bashbug bash basename base64 bashbug   this output you can simply pipe through grep. 
nighpher, i'll try to answer your question, but for a more comprehensive description of boot process, try ibm article.  ok, i assume, that you are using grub or grub2 as your bootloader for explanation
login as root or su to get root prompt
based on a comment by @0xc0000022l , i found http://security.blogoverflow.com/2013/01/a-brief-introduction-to-auditd/ which seems to be useful, so adding it as a community wiki answer, in case other folks search for such questions ; i would not want them to simply move on, thinking that there was no answer here. 
so in the end, i figured out that my profile was called analog-output-headphones
try this:  sed -r "s/=~(.*)$/match(\1)/" &lt;filename&gt;   also, the error that you are getting is because sed interprets /=\~/ as a filter for the line that the operation should be performed, s/=\~/match(/ as the operation and s/$/ )/ as a flag for the operation, in this case you need to use a group and separate the expressions with a new line:  sed -re "/=\~/ {   s/=\~/match(/   s/$/ )/ }" &lt;filename&gt;   here is the relevant documentation about the command block {} from info sed  `{ commands }'  a group of commands may be enclosed between `{' and `}' characters.  this is particularly useful when you want a group of commands to  be triggered by a single address (or address-range) match.  
you could put a simple cron script together that would monitor to see if the vpnc process is still up
you could use awk on /var/log/secure or /var/log/auth.log (depending on the distro).  on my centos 7 i get the following when i log in remotely:  dec  8 21:58:20 &lt;server hostname&gt; sshd[8387]: accepted publickey for gareth from 1.2.3.4 port 58392 ssh2: rsa 55:89:f9:20:db:c6:e0:6f:ff:d4:a7   the above was for interactive login but a similar entry was created for sftp login.  therefore:  awk '/sshd.*accepted/ {print $1,$2,$3,$9,$11}' /var/log/secure   should give you:  dec 8 21:58:20 gareth 1.2.3.4  
you could try:  timeout 45 cat yourfile   see also http://stackoverflow.com/questions/5161193/bash-script-that-kills-a-child-process-after-a-given-timeout 
you can try the following, to confirm upon deleting each file first:   $ find /path/to/dir -type f -name "*.txt" -empty -ok rm {} \;   or if you feel more confident:  $ find /path/to/dir -type f -name "*.txt" -empty -exec rm {} \;  
you have a number of options:   rebuild a recent ffmpeg source package to get libavcodec57 &amp; co.; upgrade to ubuntu 16.10 which has libavcodec57; follow the vlc package approach, which is to embed the appropriate version of fmmpeg and use that instead.   the latter approach is the one i'd recommend; to get started:  sudo apt-get install devscripts dget http://httpredir.debian.org/debian/pool/main/v/vlc/vlc_2.2.4-8.dsc cd vlc-2.2.4 cc=afl-gcc cxx=afl-g++ dpkg-buildpackage -us -uc   this will tell you which other packages you need to install (if any)
there are two ways you could do this:   run vim in a screen session, and attach to that from different terminals run vim in client/server mode   further reading:   taking command of the terminal with gnu screen  using gnu screen to manage persistent terminal sessions server and client mode in vim how does vim support c/s mode?  
xfce has some support for hidpi - you can change the setting across all monitors for hidpi, but it doesn't vary between different screens in the way that it does on a retina macbook pro
x11 can adjust gamma with the command xgamma, which should come standard with x11 on most linux distros
note: i'm answering 1., since ignacio already answered 2..  in the following sudo entry:  superadm  all=(all)   all   there are four fields:   the first one specifies a user that will be granted privileges for some command(s). the second one is rarely used
du -h -d 1 /   this will display the size for all of the top-level directories in your root directory in 'human readable' format
there is no aptitude equivalent to apt-key, and there is no need for it
there are a few cases that come to mind:   missing arguments, the special argument "-", the program detects that the standard input is not a terminal, and an option (or environment variable) overrides the behavior.   for missing arguments, cat is a useful example
i found this document which explains exactly what i was looking for, i hope it's useful for some of you http://www.linuxtopia.org/online_books/linux_kernel/kernel_configuration/ch08s02.html  read the entire document, it's full of nice things, specially this:      when the topic of this book was first presented to me, i dismissed it   as something that was already covered by the plentiful documentation   about the linux kernel
unix and c have an intertwined history, as they were both developed around the same time at bell labs in new jersey and one of the major purposes of c was to implement unix using a high level, architecture independent, portable language
have you tried   rlwrap sh -c 'while read line; do echo "i read $line"; done'   rlwrap needs a command it can run, which a () syntax-induced subshell is not
label installubuntu menu label ubuntu 11.10 install linux /vmlinuz initrd /initrd.lz append boot=casper iso-scan/filename=/ubuntu-11.10-desktop-i386.iso   solved the problem.  see also there. 
use grep to find the string at the start of the line and an array to save the results:  ifs=$'\n' lines=( $(grep '^string' file.txt) )    grep '^string' file.txt finds the string string at the start of lines of file file.txt the array lines contains the matched lines, the ifs=$'\n' makes each line an array element   now you can iterate over the results using regular array operations.  for example, to find the number of lines found:  ${#lines[@]}   first element:  ${lines[0]}   second element:  ${lines[1]}   iterate over the elements using for loop:  for i in "{lines[@]}"; do ....; done  
you can do it in the .profile, .bashrc or .bash_profile files located in your home directory. 
that is the default you get if you leave it out
you can use a simple loop:  .... data="" retry=10  while [ "$retry" -gt 0 ]; do   data="$(wget -o - -q -t 1 http://hostname.domain.com:8080/beat)"   if [ $? -eq 0 ]   then     break   else     let retry-=1     sleep 30   fi done  if [ "$retry" -eq 0 ] then   exit 2 fi ....  
you could use tail  tail -n +2 input.txt &gt; output.txt  will print the lines of the file starting by the second (note the + sign) 
with gnu od:  od -vtu1 -an -w1 my.file | sort -n | uniq -c  
if you have ksh 93, you can declare x to be a reference to a variable name:  $ ksh --version   version         sh (at&amp;t research) 93u+ 2012-08-01 $ ksh -c '     envvar=foo     x=envvar     nameref x     echo $x ' foo  
solaris date does not support -d option like gnu date.  you can use perl:  $ perl -mposix=strftime -le '@t = localtime; $t[3] = 1; $t[4]--; print strftime("%m", @t)' 05     $ perl -mposix=strftime -le '@t = localtime; $t[3] = 1; $t[5]--; print strftime("%y", @t)' 2013   or if you have ksh93:  $ printf "%(%m)t\n" "last month" 05   $ printf "%(%y)t\n" "last year" 2013   updated  for @glennjackman's comment, i found a documentation in time::piece module:     the months and years can be negative for subtractions
i recommend always storing gmt dates, or if this is really inconvenient dates with timezone information
first, you need to determine whether your terminal sends different escape sequences for these key combinations
you can't
a datastore is an abstract container for virtual machine disks, and can be any supported storage medium (san, network share, local disk)
yo've not stated what your *nix is
edit, i also came across this: https://igurublog.wordpress.com/downloads/mod-pcmanfm/  i am not to familiar with pcmanfm since i don't use a gui, but if you ctrl + r to run a command in directory you should then be able to run my command below to hide the files.  to show hidden files, you just need to hit ctrl+h.  hope that helps.    you could try something like this if you are interested in an approach outside of pcmanfm:  find 
this is a problem with oxygen-gtk theme
you could pipe the output to xargs e.g.  ps -ef | grep &lt;process_name&gt; | awk '{print $2}' | xargs /bin/kill   but why doesn't your pkill command work? 
i am the kate developer who implemented the line modification system
all obtained from http://superuser.com/a/916248/151431  you can use perl  $ perl -00pe 's/^/$./' file    -00 turns on paragraph mode where "lines" are defined by consecutive \n\n. -p tells perl to print each line of the input file after running the script given by -e on it. s/^/$./ will replace the start of the line (^) with the current "line" (paragraph) number $.   you can use awk  $ awk -v rs='\n\n' -vors='\n\n' '{print nr$0}' file | head -n -2     -v rs='\n\n' sets awk's record separator to consecutive newline characters
while not a direct answer to restore all vim options to defaults, you can use :set paste to solve your issue.  what is likely happening is that vim is loading in a syntax file which is automatically formatting the file as you type
by reading in the username, agetty can automatically adapt the tty settings like parity bits, character size, and newline processing
you have two bugs:   you are comparing for a size that contains 46; you want it to be equal to 46. you are printing the entire line, when you want only the filename.   and an additional issue:  what is the point of -ltr to sort the ls output when you aren't using the sort order?  you want to do something like  ls -l | awk '$5 == "46" {print $9}' | xargs rm   except you don't want to do that, because while it might be safe at the moment, parsing ls output is unreliable
i assume you want to edit the mail before it is sent? in that case piping is not going to work because mutt receives an eof when the pipe closes
redefine "bell_msg" to include a literal "^g"
the . is the current directory
when you boot the live cd, select "expert install" (graphical or non-graphical; it doesn't matter)
i think this would work, though i do this for ssh into a linux vm and not rdesktop
tail works with binary data just as well as with text
if i read the datasheet correctly, you have one slot filled, six cores, which show as 12 processors because they are hyperthreading
don't know if things were that different in `13 but 'zfs replace' works on non-redundant pools
you can use watch command to constantly running w (every some time defined in -n parameter)
services launched by systemd at boot are ordered by dependencies
you could possibly write a script that sits behind a named pipe and dumps the contents of both staticentries.dic and dynamicentries.dic whenever it's opened and read from
check the ownership of the pid file, that's a dead giveaway. 
those are usually system-generated backup files
you'd better use time.  for example  tmp=$(mktemp) time (scp yourfile user@otherhost:/path/ ) 2&gt;$tmp awk -f'[ ms]+' '/^real/ {print "copy time: "1000*$2"ms"}' $tmp rm $tmp  
at the system call level this should be possible
if other people clean up ...  ..
you need to pass a top directory name
most dd implementations print status information upon recieving sigusr1
find traverses the specified directory tree(s), and evaluates the given expression for each file that it finds
you are using a lightweight window manager
nothing: there are three standard file descriptions, stdin, stdout, and stderr
if your shell is bash, add clear_console or reset to ~/.bash_logout
avahi is the opensource implementation of bonjour/zeroconf.  excerpt - http://avahi.org/     avahi is a system which facilitates service discovery on a local   network via the mdns/dns-sd protocol suite
this is possible with the ttable option of the route plugin, which is also integrated in the plug plugin:  pcm.mylittledevice {     type plug     slave {         pcm "hw:1"         channels 16     }     ttable [         [ 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 ]         [ 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 ]     ] }   to reduce the volume, replace the 1s with smaller values. 
one approach would be to count the options as getopts parses them
first, run a filesystem check, e2fsck -f ./system.img
this is in response to this answer:  i would not install every .deb separately - this is a terrible idea and there are much better ways
after speaking with a unix professional, the answer to this question is not definitively yes or no, however there is a good answer
traditionally, the location for this would be /usr/local (resp
this is an unabashed yes
yes, using the debian live install images
you will need a couple of steps
rax and argoffset are defined in calling.h, lines 70 and 85 respectively. 
create a file, say /etc/hosts.chat.freenode.net, that has the same format as /etc/hosts file and list all ip addresses with name in this file:  130.239.18.172 chat.freenode.net 140.211.167.105 chat.freenode.net   then add to the dnsmasq.conf the following line:  addn-hosts=/etc/hosts.chat.freenode.net   or put these two lines into /etc/hosts if dnsmasq is set to read in the /etc/hosts.  then restart dnsmasq  enjoy. 
alias git to a script you're going to write:  $ alias git=mygit   ...which lives in your path somewhere and looks like this:  #!/bin/sh if [ "$1" = "push" ] then     /bin/echo -n "enter 'yes i am sure.' to confirm: "     read answer     if [ "$answer" != "yes i am sure." ]     then         echo so indecisive...         exit 1     fi fi  git "$@"  
the following script will take your .xpm file as input and print the new desired output
write the checksum as lowercase hex digits followed by two spaces and then the filename, with one file per line
actually google did more writing an app platform / virtual machine system to run on top of linux than they did modifying linux
after some further experimenting i can confirm my claim made in one of my comments: the  config_usb option has to have value y; m is "not enough"
you need to tell sudo to change groups:  sudo -g adm tail /var/www/error.log   (as one of the appropriate users).  alternatively, you could just add the users to the adm group, it's only used for log files in debian nowadays... 
first off, don't use sudo or su to change users to run a graphical process, or you're liable to have problems down the line (~/.iceauthority changing owner is a notable issue)
you don't even need to do that.  simply log out of all users and log back in as root (root's home is /root; not within /home)  unmount the /home partition.  resize /dev/sda3 using gparted or similar.  mount /home.  run lsblk - /dev/sda3 should now be about 280gib. 
you can have a separate filesystem for /var on a new disk partition/lun created for this
you could try an alternate approach, which is to recognize your device at the udev level and use /dev/mybook-partition in /etc/fstab
su requires sharing a password
   i would like to believe that it is not installed if so why the system   returned java: /usr/bin/java?   whereis doesn't resolve the symlink
you can change it when using php mail() function, by passing an additional parameter:  &lt;?php mail('receiver@address.com', 'subject', 'message', null,    '-fnoreply@yourdomain.com'); ?&gt;   or make it default by changing sendmail_path option in php.ini:  sendmail_path = /usr/sbin/sendmail -t -i -f'noreply@yourdomain.com'  
according to this cheat sheet it would seem to come down to punctuation.  w   jump by start of words (punctuation considered words) w   jump by words (spaces separate words) e   jump to end of words (punctuation considered words) e   jump to end of words (no punctuation)   example  demo using w  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  demo using w  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  notice in the first demo how when w is continuously hit that the cursor lands on the punctuation, while in the 2nd demo the punctuation is skipped
you can run xrandr as any user running an x session
use  set -a    man page :      -a       when this option is on, the export attribute shall be set for each variable to which an assignment is performed;  
i don't believe that there's any specific command to do a syntax check, but you can run openvpn in the foreground, which should show the specific error:  openvpn --config /path/to/server.conf  
based on your issues in installing ncdu my recommendation would be to use du and sort on together.  for instance:   du /home | sort -rn (will search all files/directories under /home and sort them by largest to smallest. du -h /home | sort -rh (same but will show it in mb/kb/etc) - note this requires coreutils 7.5 or newer (sort --version to check)   you can replace /home with any directory of your choice. 
why not read line by line using while :  while read -r line do         if ! grep -fxq " $line " /etc/sysctl.conf         then         echo -e "$line" &gt;&gt; ~/testfile         fi done &lt;/etc/sysctl.conf   and replaced > with >>. 
are you looking for that part of the path based on a fixed location from the left of the path or fixed depth from the right? if you are looking from the left you can do this easily with cut by using '/' as a field separator and grabbing the fourth field like this:  find ..
this script will archive then optionally remove all folders containing "*.txt" files and nothing else.  folders=$(find 
just delete everything between the first line and the first pattern, between the second pattern and the last line:  apt-cache showpkg gdm | sed '1,/reverse depends:/d;/dependencies:/,$d'   note that this approach will fail if your first pattern occurs on the first line and doing regexes checking more than is necessary can affect performance.  a better approach:  $ apt-cache showpkg gdm |   sed -n '/reverse depends:/{     :1     n     /dependencies:/q     p     b1   }'  
you can use sed for both the tasks
first command gives rights to davis on the directory itself, the second one sets the default acl entry for new files that get created
if i understand your index generation correctly, then  awk '{print 5*(nr-1)+1" "$0}' yourfile &gt; oufile   should do it
you can use x11 forwarding over ssh; make sure the option   x11forwarding yes   is enabled in /etc/ssh/sshd_config, and either enable x11 forwarding by hand with  ssh -x remoteserver  or add a line saying   forwardx11 yes   to the relevant host entry in ~/.ssh/config   of course, that requires a working x display at the local end, so if you're using windows you're going to have to install something like xming, then set up x11 forwarding in putty as demonstrated in these references:   using putty and xming to connect to cse x11 forwarding using xming and putty use linux over windows with xming, here or here   eta: reading again and seeing your clarifications in the comments, ftp might suit your needs even better, as it will let you 'mount' sftp folders as if they're regular network drives.  see here, here, here (for windows xp/7/vista), or here (for windows 8).   
you can have a look at recordmydesktop or freeeseer. 
you can use fdisk to have an idea of what kind of partitions you have, for example:  fdisk -l    device boot      start         end      blocks   id  system /dev/sda1   *          63   204796619   102398278+   7  hpfs/ntfs /dev/sda2       204797952   205821951      512000   83  linux /dev/sda3       205821952   976773119   385475584   8e  linux lvm   that way you know that you have sda1,2 and 3 partitions
you need to create a .desktop file and place it in the right location
in bash:  echo $'scan \'lpv\',{filter =&gt; "(prefixfilter (\'mp1-eq1\')"}'   or  echo "scan 'lpv',{filter =&gt; \"(prefixfilter ('mp1-eq1')\"}'"   for longer strings this may be a more convinient alternative:  &gt; cat &lt;&lt;eot scan 'lpv',{filter =&gt; "(prefixfilter ('mp1-eq1')"} eot   with eot or \eot, depending on whether parameter expansion and quote removal (backslash) are intended or not.  usage within awk  defining this string within awk would make everything even more complex
unfortunately, there's just one control modifier supported in x11:  $ xmodmap -pm xmodmap:  up to 5 keys per modifier, (keycodes in parentheses):  shift       shift_l (0x32),  shift_r (0x3e) lock       control     control_l (0x25),  control_r (0x69) mod1        alt_l (0x40),  meta_l (0xcd) mod2        num_lock (0x4d) mod3       mod4        hyper_l (0x42),  super_l (0x85),  super_r (0x86),  super_l (0xce),  hyper_l (0xcf) mod5        iso_level3_shift (0x5c),  mode_switch (0xcb)   as you can see, although there are seperate key symbols for left and right ctrl, both of them are bound to the same modifier, control
if you have a similar system that you can use as a guide to see what the correct ownership for all of the files is, then you can boot into rescue mode, drop to a root shell, and manually restore the correct ownership to all of the files in /usr.  the quickest way may be to reinstall your os or restore from backup.  in ubuntu or similar, then there is no root password by default (the account is disabled), which is why you can't su. 
i don't think the x server reports its host name to clients
reverse depends  reverse depends means you want a list of packages that depend on a given package.  example  $ apt-cache rdepends jetty jetty reverse depends:   solr-jetty   libjetty-java   libjetty-extra-java   libjetty-extra   libini4j-java   guacamole   recursive depends  using a tool such as apt-rdepends shows what packages a given package is dependent on, plus what packages these packages are also dependent on
i know, it is out date, but will be useful for anyone in the future.  i have the same problem
i got it
http://ohse.de/uwe/ftpcopy/faq.html#timestamp     the ftp protocol, misdesigned as it is, doesn't include time zone information
the systemd way is to create a service template that starts your alternative tty login service &hellip;  [unit] description=qingy on %i documentation=info:qingy bindto=dev-%i.device after=dev-%i.device systemd-user-sessions.service plymouth-quit-wait.service  [service] environment=term=linux execstart=/sbin/qingy %i --no-shutdown-screen restart=always restartsec=0 utmpidentifier=%i ttypath=/dev/%i ttyreset=yes ttyvhangup=yes ttyvtdisallocate=yes killmode=process ignoresigpipe=no killsignal=sighup  [install] wantedby=getty.target  &hellip; and then to make sure that the autovt@.service template is an alias for this instead of for getty@.service, as it is out of the box.  ln -s qingy@.service /etc/systemd/system/autovt@.service systemctl daemon-reload  (note that this is not modifying the pre-packaged /lib/systemd/system/autovt@.service that comes in the box
incron itself doesn't offer filtering on file names, you can only monitor a directory and all of its files and its subdirectories' files recursively
there are multiple reasons why one may choose to manually compile a kernel
try mplayer, it's usually the audio and video player that supports the widest range of formats.  if you have a supposedly rtsp source which is actually an http url, first retrieve the contents of the url; you'll get a file containing just another url, this time rtsp:// (sometimes you get another http url that you need to follow too)
you can use tput reset.  besides reset and tput reset you can use following shell script.  #!/bin/sh echo -e \\033c   this sends control characters esc-c to the console which resets the terminal.  google keywords: linux console control sequences  man console_codes says:     the  sequence esc c causes a terminal reset, which is what you want if   the screen is all garbled
wget -qo- 'http://www.youtube.com/watch?v=dd7dqh8u4hc' |   perl -l -0777 -ne 'print $1 if /&lt;title.*?&gt;\s*(.*?)\s*&lt;\/title/si'   you can pipe it to gnu recode if there are things like &amp;lt; in it:  wget -qo- 'http://www.youtube.com/watch?v=dd7dqh8u4hc' |   perl -l -0777 -ne 'print $1 if /&lt;title.*?&gt;\s*(.*?)\s*&lt;\/title/si' |   recode html..   to remove the - youtube part:  wget -qo- 'http://www.youtube.com/watch?v=dd7dqh8u4hc' |  perl -l -0777 -ne 'print $1 if /&lt;title.*?&gt;\s*(.*?)(?: - youtube)?\s*&lt;\/title/si'     to point out some of the limitations:  portability  there is no standard/portable command to do http queries
as ulrich dangel points out in his comment above - the whole directory hierarchy leading to the required directory should be accessible to apache in order for it to serve the directory and its listing.  i had to chmod ~/bin/android-sdk-linux to 775 which was originally set to 770. 
file permissions do not really apply to root: programs running as root can read and write files regardless of protection settings
problem solved, i switched from using upstart to using cron
command lsof  a good option might be lsof
files in /proc are generated by the kernel, not by the mount utility
debian has a distribution channel that provides security updates only so that administrators can choose to run a stable system with only the absolute minimum of changes
you can do this, if you have a third machine where you can run a gui
here's the file you are looking for
you may use while loop..
try split --filter:  split --lines 1000 --filter 'sort ..
install ibus in the software manager:    start with command ibus-daemon.  it should already appear in the systemtray.    right-click the tray icon to access preferences, set a switch shortcut key and add layouts.  add this line to ~/.fluxbox/keys:  ibus-daemon &amp;   switch the layouts by left clicking the tray icon or by using the shortcut to see list of choices.    this solution seems to have a serious limitation in that it may lack access to some layout variants. 
your machine hostname is not resolvable from the remote host
man less tells us the following:   you  may  define your own less commands by using the program lesskey (1) to create a lesskey file
wow, some complex solutions here! i think all you need to do is this though:  find ./\$my\'dir -type d -exec sh -c 'ls "$1"' sh {} \;   instead of putting the arguments into the sh command string, just use them as arguments to sh
use -exec:  find 
http://relax-and-recover.org/  install it on the server you want to backup, then run it, it creates an iso file
you can use binutils-x86-64-linux-gnu, available in debian jessie (but not ubuntu)
you can do it with awk like  awk -f\| 'begin {ofs=fs} $6 == "a" {$7 = "0800000"} $6 == "i" {$7 = "0758000"}; 1' file1.txt   this will have awk split fields based on |, then set the output field separator to also be | when we write the lines back out
in debian, you could just call x-terminal-emulator -e /some/command, as this points to the terminal emulator configured by debian's "alternative" mechanism
here is a good starting point:  http://hints.macworld.com/article.php?story=20070715091413640  set history = 2000          # history remembered is 2000 set savehist = (2000 merge) # save and merge with existing saved  set histfile = ~/.tcsh_history  ...in .tcshrc and this line..
you should kill your display manager to switch all frontends of the xserver off
possible workaround would be to rename that directory, and force installation like this,  sudo mv /usr/share/doc/libssl1.0.0 /usr/share/doc/libssl1.0.0.backup sudo apt-get -f install   or this might also fix your problem,  apt-get install libssl1.0.0 libssl1.0.0:i386  
many tools can be handy:   -n of grep is exactly what you are looking for.  grep -n 'bla' file  alternatively awk:  awk '/bla/{print nr":"$0}' file  alternatively perl:  perl -ne 'print $.,":",$_ if /bla/' file  alternatively sed:  sed '/bla/!d;=' file |sed 'n;s/\n/:/'   
here is one way (put it in a file and execute it with any posix shell like bash or ksh):  cd ~/somefolder/ || exit 1 for f in *.png do   case $f in   (tn_*) continue ;;   (*) convert "${f}" -resize 50%x50% "tn_${f}" ;;   esac done   with modern shells the case construct could also be replaced by a terser conditional command:  cd ~/somefolder/ || exit 1 for f in *.png do     [[ "$f" != tn_* ]] &amp;&amp; convert "${f}" -resize 50%x50% "tn_${f}" done   (but this code is from memory and untested, so inspect the convert command about the actual resize-syntax, and try it in some sample directory on a few sample files first.) 
this seems to be a known bug and my-weather indicator cannot work with yahoo
you can set defaults for the home directory and login shell in the [global] section of the smb.conf configuration file:  template shell    = /bin/sh template homedir  = /home/%accountname%   note that it is %accountname% and not %u as was the case with samba 3
   is kernel space used when kernel is executing on the behalf of the user program i.e
you can accomplish this using the hold space feature of sed.  run sed with the -n option to suppress the automatic printing of input lines.  when the line containing &lt;source is seen, save the value of the name attribute in sed's hold space.  when the &lt;sourcefield line containing xyz is seen, print the contents of the hold space.  #!/bin/sh  sed -n '     /&lt;source / {              # execute block {} on lines matching "&lt;source "         s/.* name *="//       # remove everything upto name attribute value         s/".*//               # remove everything after attribute value         h                     # copy pattern space to the hold space     }     /&lt;sourcefield.*xyz/ {     # sourcefield contains xyz, execute {} block         g                     # copy hold space to pattern space         p                     # print     } ' "$@"  
my first guess was btrfs since the i/o processes of this file system sometimes take over
you could try your luck with ddrescue
no:   there is no standard way to "disable it", and the details of breakage are actually terminal-specific, but there are some commonly-implemented features for which you can get misbehavior.   for commonly-implemented features, look to the vt100-style alternate character set, which is activated by ^n and ^o (enable/disable)
the ubuntu wiki has a detailed guide
dm_mirror  is a linux kernel module
as noted, the problem is the hostname
edit: as recommended in a comment below, you can just use yum for everything and you will be fine.  check red hat's documentation for the rpm command.  basically:   rpm -uvh package_file.rpm installs/upgrades a package from a .rpm file rpm -e package_name removes a package   to install packages from red hat's repositories, use yum, whose commands are mostly self-explanatory (install, update etc...)
for commands which get input from stdin, you can use redirection:  cat &lt;-file_name  
with perl:  perl -0777 -pe 's/\q\{{[}\e.*?\q{]}\}\e//gs'   note that the whole input is loaded in memory before being processed.  \qsomething\e is for something to be treated as a literal string and not a regular expression.  to modify a regular file in-place, add the -i option:  perl -0777 -i -pe 's/\q\{{[}\e.*?\q{]}\}\e//gs' file.txt   with gnu awk or mawk:  awk -v 'rs=\\\\\\{\\{\\[\\}|\\{\\]\\}\\\\\\}' -v ors= nr%2   there, we're defining the record separator as either of those beginning or end markers (only gawk and mawk support rs being a regexp here)
look at the content of the xdg-open file, and you will notice that it is a simple shell script
@schaiba suggested renaming /etc/resolv.conf; a little better would be to make /etc/resolv.conf point to a live address without a dns server running
it is unusual to find apache running as root in any stock configuration
how the command prompt appears is determined by the environment variable ps1
if you want to see the nameservers listed by the registrar, those are available in the dns system via the root servers
it looks like it is here:  ~/.cinnamon/glass.log  
you might try the -e option
when the partition is in clean state, there is no actual fsck run, which is why the date isn't updated.  if you want to force it, the -f option does just that: sudo fsck -f /dev/sda1. 
from your live cd, try to log in as root in order to copy the data
well, opengrok for opensolaris code base but no opengrok for linux codebase, one could start one however but the cost involved in setting up and maintaining is too greater i suppose
what is shell?  in simple words, shell is a software which takes the command from your keyboard and passes it to the os.  so are konsole, xterm or gnome-terminals shells?  no, they're called terminal emulators
you can do like this:  awk '$35=$35"$"'  
processes need to have a parent (ppid)
you might be thinking of xdg-open:     xdg-open opens a file or url in the user's preferred application
i think using history completion is a much more universal way to do this  $ sudo !!   most shells have some shortcut for the previous command
the first command you posted can't give the results you show, because they don't have colons at the end; presumably you stripped them
the organization of configuration files is much less uniform than your questions seem to imply
you can configure mutt to use different from addresses (via your ~/.muttrc), e.g.:  set user_from=yes set envelope_from=yes set from=default@example.org set realname="default realname" # list of all your addresses alternates @example\.org$   you can setup some macros to explicitly switch the from before composing a new mail:  macro index \e1 "set from=foo@example.org\n" "select foo address" macro index \e2 "set from=bar@example.org\n" "select bar address" # ...   when replying to an email, you can configure mutt to automatically use the to-header as from address (this is point 2 from your question):  set reverse_name=yes   don't reuse the real name - helps when people send you crap like "foo@example.org" &lt;foo@example.org&gt;:  set reverse_realname=no   then you can set up some hooks to make things depend on header values - e.g
you must allow local connections first:  iptables -a output -o lo -j accept iptables -a output -m owner --uid-owner joe -j reject  
perl handles escape sequences, including \n for newline, somewhat more comprehensively than older unix tools.  perl -pe 's/\r\n//g'  
you can do  some process | logger &amp;   to spawn processes and have their output directed to syslog
the posters in this thread claim success although the explanation of what options need to be changed lacks detail.  http://sourceforge.net/p/davmail/support-requests/134/  i have the urls but i need more specific instructions in how to change the settings of davmail and my email clients
the syslogidentifier directive allows you to set the name of the executable name in the logs.  syslogidentifier=java # or my app name, but not both! syslogidentifier=myapp  
there are two problems to solve:   how to remove the files without interfering with your output, and where to put the output while it is being created.   if you happen to not have any dot-files in /var/backup/sql, it is simple:   just create your output named with a leading ".", add to the tar-file using the --remove-files option, and rename the output to tmp.tar.gz when done.   something like  cd /var/backup/sql tar cfz .tmp.tar.gz --remove-files * &amp;&amp; mv .tmp.tar.gz tmp.tar.gz   if you do have dot-files, then you could construct a list of the files to be tar'd and then use that list in constructing the tar-file
you can specify the section as the first argument to man:  man wait man 1 wait   these will open the bsd general commands manual for wait  man 2 wait   this will open the bsd system calls manual for wait  that's why you often see the number in parens after the command, e.g
see those numbers on the left of the output? you can use them to refer to that command with shell history expansion; ![number] in most shells.  this works both in bash and zsh:  $ echo "hello" hello $ history | grep hello  5057  echo "hello" $ !5057 echo "hello" hello $  
when i installed fedora 15 recently, there was an option for a minimal install
you can use read for interactive scripts.  for example:  echo "do you want to continue?(yes/no)" read input if [ "$input" == "yes" ] then echo "continue" fi   and you can have your if conditions to execute further based on the input provided.  edit  if you want to use this in multiple places then you can create a funtion and call wherever you want the user intervention. 
reading and writing a file is not line-atomic, and tail -f is not line-buffered
i don't have an osx awk to try this on, but it works on my linux gnu awk:  awk ' { n = match($0, /[0-9]+ *$/);   if(n){     word = substr($0, 1, n - 1); num = 0 + substr($0, n);     if(!(word in max) || max[word] &lt; num) max[word] = num   } } end{ for(word in max)print word max[word] } '   on each line we look for the starting index in the line of the regexp pattern that is a number with optional trailing whitespace
you can check "all users may connect to this network" in general settings
the short answer is because linux is really gnu/linux
this file is most likely created by the editor in which you have bitwise.c file open
i found this formula defined in rfc 3550 for the rtp (real time protocol)
have a look at the routing table of the 'physical' pc and see how traffic to these networks are routed
your best bet is to use printf
it may be useful to explain how files work at the lowest level:  a file is a stream of bytes, zero or more in length
ls -l /sys/class/block/sd?   the sd? entries are symbolic links that show how the disk is connected to the computer
some ideas, assuming interfaces are eth0 and eth1:   sniff on both interfaces at the same time for non unicast traffic
this is unrelated to cpulimit
well it is a directory and (-type d) so it gets printed
you might want to install the package mplayer-resumer
these simple gnu tools don't have config files
you can enable password-less sudo for a specific command.  # /etc/sudoers (edit with visudo) # for a specific user/command combo izuriel all=nopasswd:/bin/true # for a specific command, any user in group sudo. %sudo all=nopasswd:/bin/true  
that server is clearly running a partial or broken implementation of webdav
you can drop into single mode from grub
you can access the applets under gnome control center by appending their names to the command:  $ gnome-control-center &lt;applet name&gt;   examples  launching the sound applet?  $ gnome-control-center sound   &nbsp;&nbsp;&nbsp;&nbsp;  launching the printers applet?  &nbsp;&nbsp;&nbsp;&nbsp;  what are all the names of these applets?  $ gnome-control-center -l available panels:     background     bluetooth     color     datetime     display     info     keyboard     mouse     network     notifications     online-accounts     power     printers     privacy     region     search     sharing     sound     universal-access     user-accounts     wacom  
the reason for this pattern is that maintainer scripts in debian packages tend to start with set -e, which causes the shell to exit as soon as any command (strictly speaking, pipeline, list or compound command) exits with a non-zero status
seems that port 515 is for the earlier lpd implementation for unix printing
!! is history expansion
from the centos 6.0 release notes:     4
don't use auto-generated virtual mac addresses with your isp.  whether you are using a completely randomized mac address or a non-vendor prefix, you are running the risk that your mac address will confuse your isp's infrastructure.  the workaround is to spoof the mac address of an existing network card: preferably an old 10-base card that you never plan to use again, but any mac address that fits the following criteria will do:   is assigned to a physical network port that you actually own is not held by another vm in your infrastructure (might confuse the virtualization platform) will not be otherwise seen by the vm you are assigning it to will not be seen by any other machine on that network segment   reconfigure your virtual nic to spoof that mac address, confirm that the changes are visible to your os, and reboot your cable modem
if [ -z "$dateval" ]; then            printf "option -d must be specified\n"            exit fi if [ -z "$extensionval" ]; then            printf "option -e must be specified\n"            exit fi  
i was unable to update the mutt version, but i found a workaround - others may find this helpful, too.  including a comment with special characters lets perl and mutt choose the correct (utf-8) encoding (probably the 'ł' would suffice, but the intent gets clearer with the umlaut characters):  in the xml this is what it looks like:  &lt;?xml ..
networks:   create a single-server private network on xen. add it machine1 and machine3, one each. add two of them created at step 1 to machine2.   machine1:  ip addr add 1.1.1.2/24 dev eth1 ip route add 2.2.2.0/24 via 1.1.1.1 dev eth1 proto static   machine3:  ip addr add 2.2.2.2/24 dev eth1 ip route add 1.1.1.0/24 via 2.2.2.1 dev eth1 proto static   machine2 (router):  ip addr add 1.1.1.1/24 dev eth1 ip addr add 2.2.2.1/24 dev eth2   testing:  ping 2.2.2.2 # machine1 ping 1.1.1.2 # machine3  
from man pwd on my ubuntu:     your shell may have its own version of pwd   i use bash
is there any reason why killall procmail doesn't work?  if it's running as another user, try sudo killall procmail  if procmail keeps on being restarted, that is because your mail transfer agent (mta - e.g
cp --remove-destination "$(readlink &lt;symlink&gt;)" &lt;symlink&gt;  
use dpkg-buildpackage -a (thanks, @wouterverhelst)     -a     specifies a binary-only build, limited to architecture independent packages
you could put a shell wrapper around a call to python (put this in .zshrc or .bashrc..
what does a  ps  -p 1983  -f   # 1983 being the pid your screenshot shows   tell you about it? 
in fedora 20, there's a directory   /etc/systemd/system/multi-user.target.wants   i didn't compile from source
when i run yum list extras i get a list of only those packages which aren't installed via rhn satellite or an established repo:   # yum list extras loaded plugins: kmod, rhnplugin this system is receiving updates from rhn classic or rhn satellite. extra packages mqseriesclient.x86_64                      7.0.1-5                       installed mqseriesjava.x86_64                        7.0.1-5                       installed mqseriesruntime.x86_64                     7.0.1-5                       installed mqseriessdk.x86_64                         7.0.1-5                       installed mqseriessamples.x86_64                     7.0.1-5                       installed ca-cs-cam.noarch                           13.0.10-7                     installed ca-cs-utils.noarch                         11.2.11350.0-0000             installed gsk7bas.i386                               7.0-3.18                      installed gsk7bas64.x86_64                           7.0-3.18                      installed rhn-org-trusted-ssl-cert.noarch            1.0-2                         installed   what flavor / release are you running? i'm in rhel 5.9. 
to replace one / (escaped with \) by _:  for i in */pre.nii; do echo mv "$i" "${i/\//_}"; done   if everything looks fine, remove echo. 
generally it shouldn't matter
you can get the list of "keys" for the associative array like so:  $ echo "${!astr[@]}" elemb elema   you can iterate over the "keys" like so:  for i in "${!astr[@]}" do      echo "key  : $i"   echo "value: ${astr[$i]}" done   example  $ for i in "${!astr[@]}"; do echo "key  : $i"; echo "value: ${astr[$i]}"; done key  : elemb value: 199 key  : elema value: 123   references   how to iterate over associative array in bash  
last doesn't support reading from a pipe
you are executing commands sequentially, so the shell executes irb, waits until irb get closed and executes the next command (in your case require 'random_utils.rb')…  what you want is to provide the script to irb via stdin  irb &lt;&lt;eof require 'random_utils.rb' a = successchecker.new eof   but this will probably not do what you want as irb is for interactive use, you should consider using your normal ruby interpreter instead, e.g:  ruby &lt;&lt;eof require 'random_utils.rb' a = successchecker.new eof  
you can optimize the directory using fsck.ext4 -d on an unmounted filesystem:      -d     optimize  directories  in filesystem
you could check separately the integer and fractional parts:  #!/bin/bash min=12.45 val=12.35     if (( ${val%%.*} &lt; ${min%%.*} || ( ${val%%.*} == ${min%%.*} &amp;&amp; ${val##*.} &lt; ${min##*.} ) )) ; then         min=$val fi echo $min   as fered says in the comments, it works only if both numbers have fractional parts and both fractional parts have the same number of digits
from info ls:     '-1'   '--format=single-column'           list one file per line
you should just set  hostname=$(hostname)   in your ~/.zshrc  or as caleb pointed out there is a variable host set, so to keep your prompt portable you could also do:  hostname=$host  
the maxexpired attribute is the number of weeks after password expiration that a user is allowed to login (and change their password)
gunzip and gzcat are both convenience aliases for gzip -d and gzip -cd respectively
the key you want is favorite-apps, the schema id is org.gnome.shell
sort -k3n,3 filename | tail -5 | cut -d " " -f1,6-7   the above command will sort the file on the 3rd field
if i understand you correctly then you want to keep the whole line and just append something:  sed -r 's/^([a-z]{1})([a-z]+)([a-z]{1})([a-za-z]+)$/\1\2\3\4 -&gt; \1\l\3/' file   edit:  devnull had to remind me of it that there is an easy solution to this:  sed -r 's/^([a-z]{1})[a-z]+([a-z]{1})[a-za-z]+/&amp; -&gt; \1\l\2/' file   or, a bit more elegant (than my first try):  sed -r ' h s/^([a-z]{1})[a-z]+([a-z]{1})[a-za-z]+/ -&gt; \1\l\2/ t append b : append h g s/\n//' file  
to summarize, you want to retrieve a value out of script1.sh without running all the commands in script1.sh
   by default, file timestamps are listed in abbreviated form, using a   date like ‘mar 30  2002’ for non-recent timestamps, and a   date-without-year and time like ‘mar 30 23:45’ for recent timestamps.   this format can change depending on the current locale as detailed   below
using gsub:  awk '{gsub(/\"|\;/,"")}1' file chr1    134901  139379  -   ensg00000237683.5 chr1    860260  879955  +   ensg00000187634.6 chr1    861264  866445  -   ensg00000268179.1 chr1    879584  894689  -   ensg00000188976.6 chr1    895967  901095  +   ensg00000187961.9   if you want to operate only on the fifth field and preserve any quotes or semicolons in other fields:  awk '{gsub(/\"|\;/,"",$5)}1' file   
i've seen in the debian doc that if xorg.conf is missing (which is my case) xorg will probe your hardware on every startup
awk is particularly well suited for tabular data and has a lower learning curve than some alternatives.  awk: a tutorial and introduction  an awk primer  regularexpressions.info  sed tutorial  grep tutorial  info sed, info grep and info awk or info gawk 
if you look at the wikipedia page on the subject there are several apps mentioned.  xmove  excerpt     xmove is a computer program that allows the movement of x window   system applications between different displays and the persistence of   x applications across x server restarts.[4] it solves a problem in the   design of x, where an x client (an x application) is tied to the x   server (x display) it was started on for its lifetime
the typical way to get the file size without downloading it would be to issue a http head request and hope for the server to send the size back in the content-length header
there is a (reasonably old) thread on the suckless mailing list about this issue, that includes a patch: called pango.  there is slightly more recent version in the aur for 5.8.2:  https://aur.archlinux.org/packages.php?id=33193 
when you connect to a remove machine via ssh with x11 forwarding enabled, ssh on the server creates a .xauthority file in the user's home directory
a gui program i personally like is etherape, which has a nice graph showing current network activity with protocol and traffic amount. 
i am able to test simple dynamic-motd with fortune example on my debian jessie 8.2 host as below and found the issue to be related to a buggy behavior.  mkdir /etc/update-motd.d cd /etc/update-motd.d   created two test files as below and made them executable  root@debian:/# cd /etc/update-motd.d/ root@debian:/etc/update-motd.d# ls -l  total 8 -rwxr-xr-x 1 root root 58 dec  1 23:21 00-header -rwxr-xr-x 1 root root 41 dec  1 22:52 90-fortune root@debian:/etc/update-motd.d# cat 00-header  #!/bin/bash echo echo 'welcome !! this is a header' echo root@debian:/etc/update-motd.d# cat 90-fortune  #!/bin/bash echo /usr/games/fortune echo   however at this time, there was no change in motd
you may want to have a look at:   crypttab(5) systemd-cryptsetup@.service(8) systemd-cryptsetup-generator(8)   those work for encrypted volumes backed by block devices
because someone is a bad programmer
you need to have the program bind to the port while running as root, and then switch to your unprivileged user
you can run the application in a chroot environment i.e
1)   this first part is needed because linux needs to see this device as a modem, not as an usb storage:  vi /lib/udev/rules.d/40-usb_modeswitch.rules ... grep 1013 /lib/udev/rules.d/40-usb_modeswitch.rules  attrs{idvendor}=="19d2",attrs{idproduct}=="1013",run+="/usr/sbin/eject %k"  attrs{idvendor}=="19d2",attrs{idproduct}=="1013",run+="usb_modeswitch '%b/%k'"    2)   install wvdial (usb_modeswitch is needed to recognize the device as a 3g modem)  yum install wvdial usb_modeswitch   3)   plug in the zte k3806 usb 3g modem, see dmesg messages, just type "dmesg" in the command line:  4)   configure wvdial  if pin is: 1234 - modifiy the pin:  echo '[dialer defaults]  init1 = atz+cpin=1234  init2 = atq0 v1 e1 s0=0 &amp;c1 &amp;d2 +fclass=0  init3 = at+cgdcont=1,"ip","standardnet.vodafone.net"  modem type = analog modem  baud = 115200  new pppd = yes  modem = /dev/ttyacm0  isdn = 0  dial command = atdt  phone = *99***1#  password = vodafone  username = vodafone  stupid mode = 1  auto dns=off' &gt; /etc/wvdial.conf   5)  not needed  chmod 666 /etc/ppp/peers/wvdial  6)  not needed  plug in the zte k3806 modem &amp; network manager will pop-up for pin, type the pin then modem led turns blue..  if it didn't asks for pin.
maybe something like:  find / -name "*mysql*"   or, to find case-insensitively:  find / -iname "*mysql*"   only files? then:  find / -type f -name "*mysql*"   or just directories?  find / -type d -name "*mysql*"   maybe you want to skip other filesystems, like those in /proc or /sys:  find / -xdev -name "*mysql*"   i hope this helps
a shell is the generic name for any program that gives you a text-interface to interact with the computer
eventually i decided on $home/opt/myfooapp
bash does this for you
that code looks to be php code for configuring &amp; running tidy from within php directly
..
this is an important reason to use the $( ) instead of ` ` (see what&#39;s the difference between $(stuff) and `stuff`?)  if you nest it like this, you don't even need let or a variable:  $ echo $(date +%s) " "  $(( $(date +%s)+100 )) 1377110185   1377110285  
pts/1 is your pseudoterminal
ctrl+d does the trick for me
sed -i "s#&lt;/head&gt;#$strtoinsert\n&lt;/head&gt;#" file.html   but i'm not sure is "last appearence" means you can have several &lt;/head&gt; in your file? 
it's the priority that determines how journalctl displays messages.  based on a quick test with logger :   messages of priority debug and info are displayed "normally". messages of priority notice and warning are displayed in bold white. messages of priority err, crit, alert, emerg are displayed in bold red.   edit:  to answer the comment about how to indicate a level just by writing to stdout, yes you can, just prefix your message with &lt;n&gt; where n is a number between 0 (emerg) and 7 (debug) representing the priority.  for example the following service writes an alert message, which will thus appear in red in journalctl output :  [unit] description=loth  [service] execstart=/bin/echo "&lt;1&gt;victoriae mundis et mundis lacrima."  [install] wantedby=multi-user.target   see sd-daemon(3) and http://0pointer.de/blog/projects/journal-submit.html for more details. 
i don't have an x11 machine around so i can't verify this myself, but you might want to look at a program like xclip:     xclip is a command line interface to the x11 clipboard.   that won't exactly let you paste into your current tty, but it should at least print the contents of the clipboard to stdout
no
make sure you have 'expect' installed
you need to have spaces in the curl command
looking in  /tmp/.ipt /tmp/.rc_firewall   gives exactly what i was looking for: the iptables rules as they would normally be in a file like /etc/sysconfig/iptables.  i had earlier found this:  dd if=/dev/mem | strings | grep -i iptables   ...and fortunately, it works on the pared-down dd-wrt filesystem
when using non-printing characters in ps1, you need to wrap them in \[ and \]
the 'simple' way would be to convert the .djvu file back to multiple .tiff files (not to a multipage tiff) and then recombine them with djvubind. that however will decrease the image quality of the .djvu files somewhat as this is a lossy conversion (almost certainly when you use
you can take the following script as example:  #!/bin/sh outfile="outfile" echo "testfile1:" cat testfile1 echo "testfile2:" cat testfile2 cat /dev/null &gt; $outfile cat testfile1 | while read line; do     matchfirst="`echo $line | awk '{print $3}'`"     matchsecond="`echo $line | awk '{print $4}'`"     finded="false"     while read defline; do         tplfirst="`echo $defline | awk '{print $3}'`"         tplsecond="`echo $defline | awk '{print $4}'`"         if [ "$tplfirst" = "$matchfirst" ] &amp;&amp; [ "$tplsecond" = "$matchsecond" ]; then             echo -n "`echo $defline | awk '{print $1}'` `echo $defline | awk '{print $2}'` `echo $line | awk '{print $3}'` `echo $line | awk '{print $4}'`"  &gt;&gt; $outfile             echo &gt;&gt; $outfile             finded="true"         fi     done &lt; testfile2      if [ "$finded" = "false" ]; then         echo $line &gt;&gt; $outfile     fi done  echo "outfile:" cat outfile   usage example:  ➜ sild@$work 15:29:55 [test]$ ./replacer.sh  testfile1: 1 2 3 4 5 6 7 8 9 10 11 12 testfile2: 11 21 3 4 51 61 7 8 9 10 111 121 outfile: 11 21 3 4 51 61 7 8 9 10 11 12   is it your goal? 
some expansions happen before redirection so you have to place it directly against your tr command:  touch ~/deleted/$(echo "directory_"$(readlink -f foo)|tr '/' '\' 2&gt; /dev/null)  
you can try this link : http://www.lavrsen.dk/foswiki/bin/view/motion/loopbackdevice.  "when you install the video loopback device it will create an input - for example /dev/video5 and an output - for example /dev/video6
the s command in sed, uses a specific syntax:  s/aaaa/bbbb/options   where s is the substitution command, aaaa is the regex you want to replace, bbbb is with what you want it to be replaced with and options is any of the substitution command's options, such as global (g) or ignore case (i).  in your specific case, you were missing the final slash /, if you add it, sed will work just fine:  ➜  ~  sed 's/database_name: [^ ]*/database_name: kartable_$me/' database_name: something database_name: kartable_$me   info sed 'the "s" command' includes the full description and usage of the s command. 
defaults can be set for everything or for certain hosts, users or commands  man sudoers says :     defaults          certain configuration options may be changed from their default values at          runtime via one or more default_entry lines
replace  for file_name in `ls -al ${source_folder}*"${file_pattern}"*.csv`   with:  for file_name in "${source_folder}"*"${file_pattern}"*.csv   the output of a command in backticks, as in the first form above, is subject to word-splitting
$ apt-cache search rdiff fuse rdiff-backup-fs - fuse filesystem for accessing rdiff-backup archives   (untested)
you can look at /proc/&lt;pid&gt;/maps, /proc/&lt;pid&gt;/smaps (or pmap -x &lt;pid&gt; if your os supports) of interested process id's and compare outputs to determine shared memory regions
i'm going to take a guess on this one, but i'm pretty confident.  i bet there's a permitrootlogin yes line already in your file
this should do the job:  echo 123 | awk 'length &gt;= 3 &amp;&amp; length &lt;= 32'   if you pipe multiple lines to it, it will print lines with between 3 and 32 characters. 
try this way:  #!/bin/bash  sudo sh /opt/scripts/runp.sh &amp; sudo sh /opt/scripts/runt.sh &amp; sudo sh /opt/scripts/rund.sh &amp;  ssh sut@slave sudo sh /opt/scripts/runs.sh &amp; ssh sut@slave /home/sut/pf/server-sysfs 8989 &amp;  sudo sh /opt/scripts/runc.sh &amp;  
the exit status of a killed command should be the signal number plus 128
first order of business, find out what logs files are currently being written to:  sudo ls -ltrh /var/log/httpd   the files at the bottom of the list are the most recently modified.  the error messages generated by php are probably going to php_errors.log or error_log or ssl_error_log  try running a tail -f on these files while reproducing your error, they may reveal useful information
try  time_value=$((echo scale=3 ; echo $large / 1000) | bc )   where   scale=3 tell bc to use 3 digit after dot/comma echo $large / 1000 just compute division   please note that, once you set floating point, you have to carry it all over the place.  if $time_value above is bellow 0, it cannot be used in usual $(( )) pattern. 
   my computer has postfix server installed by default with red hat    that's basically your answer right there: redhat included a default configuration with postfix, sufficient for it to deliver mail.  how to route email is published in dns (it doesn't just turn host names into ip addresses); most likely your machine's postfix asked dns where to deliver mail for example.com (i.e., the mx records for example.com.)
on linux, assuming you want to know what is writing to the same resource as your shell's stdout is connected to, you could do:  strace -fe write $(lsof -t "/proc/$$/fd/1" | sed 's/^/-p/')   that would report the write() system calls (on any file descriptor) of every process that have at least one file descriptor open on the same file as fd 1 of your shell. 
as far as i know, you can't use the wifi as ap and client at the same time, but you can use one usb wifi as client for 2nd wan link. 
fedora installer must have a partitioning tool that will also allow you to resize that big partition
i assume that application servers are using ports [apache, mysql do] if so you can use netstat -lepunt to find out the services running in your server.  if you want to know the services are started at boot time check for init scripts in /etc/init.d/
:h user-manual | only        only : make the current window the only one on the screen
the manual describes what files (t)csh loads when it starts
ok, i finally found it
this looks like a job for gnu parallel:  parallel bash -c ::: script_*   the advantage is that you don't have to group your scripts by cores, parallel will do that for you.  of course, if you don't want to babysit the ssh session while the scripts are running, you should use nohup or screen 
you are looking for a "ring buffer"
you can use set -e inside the script, or pass -e to the interpreter when launching.  #!/bin/sh set -e   or  /bin/sh -e /path/to/script.sh   &nbsp;  http://pubs.opengroup.org/onlinepubs/007904975/utilities/set.html:     -e      when this option is on, if a simple command fails for any of the reasons listed in consequences of shell errors or returns an exit   status value >0, and is not part of the compound list following a   while, until, or if keyword, and is not a part of an and or or list,   and is not a pipeline preceded by the ! reserved word, then the shell   shall immediately exit.  
the main problem with your script is that you're opening a separate scp connection for each file, that adds a lot of needless overhead
this is because [[ takes an expression, and [ takes arguments which it translates into an expression.  [[ is syntax - it isn't a builtin command as [ is, but rather [[ is a compound command and is more akin to { or ( than it is to [.  in any case, because [[ is parsed alongside $expansions, it has no difficulty understanding the difference between a null-valued expansion and a missing operand
ok it is going to take two files.  1st file is a small script you will run on the server, it just opens a ton of listening ports using netcat  2nd file is a small script you will run on client
you can use the folllowing command:      dig yourdomain +nssearch   
not anymore  the arch linux archive contains the 4.2.5 release of the individual compontents, which you can install individually, but note that this is unsupported
the simplest way of doing this is with the timeout command
make a short script, get the filename via this line:  newestfilename=`ls -t $dir| head -1`   (assuming $dir is the directory you're interested in), then feed $filename to your ftp command, and of course, cron this script to run once a day.  if you have ncftp, you can use the following command to ftp the file:  ncftpput -uftpuser -pftppasswd ftphost /remote/path $dir/$newestfilename   without ncftp, this may work:  ftp -u ftp://username:passwd@ftp.example.com/path/to/remote_file $dir/$newestfilename  
a simple gui method:  right-click menu and then click configure.    click open the menu editor.  optionally create a new folder for your custom links
if your grep supports the -o or --only-matching flag, you could grep for the string, surrounded by any contiguous non-whitespace characters  grep -o '[^[:blank:]]*golf/tiertwo/2013-11[^[:blank:]]*' output.log /test11/golf/tiertwo/2013-11/evtlog.log   or (if it supports the perl-style \s class)  grep -eo '\s*golf/tiertwo/2013-11\s*' output.log /test11/golf/tiertwo/2013-11/evtlog.log  
i would give iotop a try (linux only)
you need to set the histtimeformat env variable
well, this is certainly subjective and up to your specific needs
you can just use places -> network gui menu in gnome to access your share
you have the commands, so put them in a script!  to run a bunch of commands on different data, put the changing data in a variable.  to run gcov and mv on all the files, there are several possible methods, including:   run gcov on all files, then move them. run gcov on one file, then move its output. run gconv on the files in a directory, then move them.   the first approach doesn't work because gcov needs to be executed in the directory containing the source files
in ubuntu, lxc-dev contains the header files, so it's the starting point for writing code using the lxc libraries
add the --max-depth parameter with a value of 0:  du -h --max-depth=0 /root/test   or, use the -s (summary) option:  du -sh /root/test   either of those should give you what you want
the file extensions registered on your system should be in /etc/mime.types
inotify-tools is a simple way of doing this
to do this on a coreos box, following the hints from the guide here:   boot up the coreos box and connect as the core user run the /bin/toolbox command to enter the stock fedora container
your issue is that roundcube is bound to port 80
you have to link gmake into the path before make, e.g
if you type alt-- 1, then alt-. the direction is reversed
i realize this is an old question, but i've been looking for the same answer myself and thought i would post at least some variety of answer for others that may be asking the same question
aix has a /proc filesystem (since about 5.1?) and you can list the open file descriptors for a pid with procfiles:  $ procfiles -n 15502 15502 : /home/guest/test    current rlimit: 2000 file descriptors                                     0: s_ifchr mode:0622 dev:10,4  ino:2584 uid:100 gid:100 rdev:28,1   o_rdonly    1: s_ifchr mode:0622 dev:10,4  ino:2584 uid:100 gid:100 rdev:28,1   o_rdonly    2: s_ifchr mode:0622 dev:10,4  ino:2584 uid:100 gid:100 rdev:28,1   o_rdonly    3: s_ifreg mode:0644 dev:10,7  ino:26 uid:100 gid:100 rdev:0,0          o_rdonly size:0  name:/tmp/foo   for open devices like a pty only the inode and major/minor numbers are given, but you should be able to easily match these with those shown by a simple ls -l /dev/pts/.  you can also install the aix toolbox for linux applications and then use the lsof command. 
with sed:  $ sed -e '   :1   $!n   /\n$/{     p     d   }   s/\n/ /   t1 ' &lt;file  
i think you know all you need to know about module aliases
maybe with:  if lsof -tac script "$(tty)" &gt; /dev/null; then   echo "i'm running under script" else   echo "i'm not" fi   you could add something like:  lsof -tac script "$(tty)" &gt; /dev/null &amp;&amp; ps1="[script] $ps1"   to your ~/.zshrc or ~/.bashrc, so the information on whether you're in script or not would be visible on your shell prompt.  alternatively, if you can't guarantee that lsof be installed you could do (assuming an unmodified ifs):  terminal=$(ps -o comm= -p $(ps -o ppid= -p $(ps -o sid= -p "$$"))) [ "$terminal" = script ] &amp;&amp; ps1="[script] $ps1"   the heuristic is to get the command name of the parent of the session leader which generally would be the terminal emulator (xterm, script, screen...). 
echo "&lt;yourcommand&gt;" &gt;&gt; ~/.bash_history  or set up an alias in your .bashrc / .bash_aliases  alias s='&lt;yourcommand(s)&gt;' so every time you input s and hit enter it executes your commands. 
i found this example, titled: acl and mask in linux
there is
du tells you how much data there is in the directory where you ran it
to comment out lines that start with start /usr/sbin/snmpmibd, use the s command with a pattern using the ^ anchor and # in the replacement text, plus &amp; which stands for the replaced text
because the doc says so:  https://www.gnu.org/software/bash/manual/html_node/bash-variables.html#bash-variables     ps3      the value of this variable is used as the prompt for the select command
use the -c option to change to the directory before archiving the file.  tar cf file.tar -c /home/albertserres/descargas file   in python this should be:  savefolder = "/home/albertserres/a.tar" srcfolder = "/home/albertserres/descargas" srcfile = "test1" subprocess.call(["tar", "rvf", savefolder, "-c", srcfolder, srcfile])  
posix requires that the operating system understand the concept of hard links but not that hard links can actually be used in any particular circumstance
i converted the font into a ttf file at some stage, which i have used on os x with some success
in short, you want something like  xrandr --output lvds --scale 1.28x1.28   (replacing lvds with the desired output name, as seen in the output of running xrandr by itself).  give it a try
after a lot of research, i found https://debian-administration.org/users/dkg/weblog/112:  copy/pasting here for longevity, all credit goes to the original author.  (i modifed the steps a little so the efi partition is only 200mb and the rest of the flash has multiple isos and shared ntfs files):  parted /dev/sdx -- mktable gpt parted /dev/sdx -- mkpart biosgrub fat32 1mib 4mib parted /dev/sdx -- mkpart efi fat32 4mib 200mib parted /dev/sdx -- set 1 bios_grub on parted /dev/sdx -- set 2 esp on mkfs.vfat -f 32 -n efi /dev/sdx2  mkdir /tmp/new-boot &amp;&amp; mount /dev/sdx2 /tmp/new-boot grub-install --removable --no-nvram --efi-directory=/tmp/new-boot/ --boot-directory=/tmp/new-boot/ --target=x86_64-efi grub-install --removable --no-nvram --efi-directory=/tmp/new-boot/ --boot-directory=/tmp/new-boot/ --target=i386-efi grub-install --removable --boot-directory=/tmp/new-boot/ --target=i386-pc /dev/sdx  
you can use tee.  tee /etc/skel/{.vimrc,.virc} &gt; /dev/null &lt;&lt;eof :set nu set incsearch :set ignorecase :set smartcase :set ts=2 eof  
i can't find a good way to do that.  what i do is type $pwd before the file name, then press tab to expand it
an easy way to find encrypted empty or weak passwords is to use a password cracker like  john the ripper
the color palettes are all hard-coded so adding custom themes to gnome-terminal built-in prefs menu is not possible unless you are willing to patch the source code and recompile the application.  one way of setting a custom color themes for your profile is via scripts
use:  cd ./-   or:  cd /absolute/path/leading/to/-   or, better:  mv ./- something-sensible cd something-sensible   the lone dash is used by a lot of commands to mean 'standard input' or 'standard output'
i have written a script to do exactly this. it basically samples ps at specific intervals, to build up a profile of a particular process
usually it is possible but how to depends on your router interface.  many router can be configured via upnp or snmp protocol
according to the xinit man page that i read, xinit (and thereby startx) looks in its command line parameters for a client program to run
here's a rough way to do what you want
you should use an array instead of a string:  args=("a" "b c") ./2.sh "${args[@]}"   when the array expansion is quoted, each element of the array is properly expanded. 
this should work:  wget -r --no-parent --reject "index.html*" http://lxr.post-tech.com/source/?v=iphone-u-boot-2010-0512  
have a look at screen or, even better, tmux.  these allow you to do exactly what you want
download any iso image from the website http://www.android-x86.org
you can parse the output of crontab -l to see if a particular crontab entry is present or not
to have a program read input from a particular keyboard, you can make it read the raw events from the right input device
well, i didn't find a way to do it without adding extra scripts, but this is the easiest way i could do it.  first add these lines to your *.conf file (make sure the up.sh and down.sh files have 755 permissions):  script-security 2 # run when connection is up up /etc/openvpn/up.sh # run when connection is down down /etc/openvpn/down.sh   here is the contents of the up.sh file:  #!/bin/sh echo $(date) &gt; ovpntime.txt   here is the contents of the down.sh file:  #!/bin/sh cat /dev/null &gt; ovpntime.txt   the up.sh script will add the connection date string to ovpntime.txt which looks something like this:   fri nov 28 03:18:46 eet 2014   and then you can compare the date to now to get the difference which is "uptime"
is this (similar to) what you see?    if so, try clicking on the activated keybinding (e.g
you probably have some non-printable characters on end of lines (eg
see this link http://www.termsys.demon.co.uk/vtansi.htm
it seems that the c compiler (probably gcc) cannot find python.h
as per the official docs (under standard interfaces):     there are some standard interfaces that may be useful across various   d-bus applications.      org.freedesktop.dbus.introspectable      this interface has one method:  org.freedesktop.dbus.introspectable.introspect (out string xml_data)       objects instances may implement introspect which returns an xml   description of the object, including its interfaces (with signals and   methods), objects below it in the object path tree, and its   properties.   so here's a very simplistic example that should get you started
answer intended for original version of question  for your one command, replacing the grep-tail-grep-if commands, try:  awk '/status change/{last=$0} end{printf "it is %sbackup\n",(last~/active/?"":"not ")}' "/apps/tests/$2"   how it works:   /status change/{last=$0}  every time that a line containing status change is found, it is saved in the variable last. end{printf "it is %sbackup\n",(last~/active/?"":"not ")}  this is executed after we have finished reading the file
there seems to be something going wrong in mussh
break is what you are looking for.  exit terminates the shell process when called
it's hard-coded in the sshd binary.  $ strings /usr/sbin/sshd |grep /usr/local/bin /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/bin/x11 /usr/local/bin:/usr/bin:/bin:/usr/bin/x11:/usr/games   in the openssh portable code, that's _path_stdpath which defaults to /usr/bin:/bin:/usr/sbin:/sbin for both root and non-root
the reason why this is permitted is related to what removing a file actually does
according to man page --action=change is the default value for udevadm.     -c, --action=action        type of event to be triggered
try this  loud_program | grep --max-count=num   then, according to my limited knowledge, loud_program receives sigpipe because it is writing to a disconnected end, which in turn could terminate loud_program
according to this debian bug report, this is due to an upstream change in consolekit between versions 0.4.1 and 0.4.2
i don't think you can
the command gensub does not change the string
missing any detail about your build process, i can only guess your modules are huge because they include debug symbols
i don't know what the guys over at cygwin/x are doing to make this fail
reset the map to its original state before applying your mods
this should work:  #!/bin/bash set -x nargs=$#  function main {     if [ $nargs -lt 1 ]; then         usage     fi      echo good }  function usage {     echo "usage: $0 &lt;outputdir&gt;"     exit 1 }  main   i left the set -x there on purpose
look in the terminfo database for your terminal for the key that sends this escape sequence
the usedns option is mostly useless
you can use:  rpm -kv xmlrpc-epi-0.54.2-1.x86_64.rpm   to display the package's signature (if it has one)
the only definitive way is to try them one by one
you don't need the cat
there does not appear to be a way using sysctls to determine if a system has hyperthreading enabled or not
this depends a lot on the communication mechanism.   at the most transparent end of the spectrum, processes can communicate using internet sockets (i.e
cdparanoia started as a patch on a cdda2wav from 1997 and never updated the cdda2wav code
finally i'm using the blog post here to solve this problem: blog post 
from your apt files, it is obvious you are using ubuntu backports
the default keyboard shortcut to switch between workspaces: alt + ctrl + [arrow key] 
use:  tmux split-window "shell command"   the split-window command has the following syntax:    split-window [-dhvp] [-c start-directory] [-l size | -p percentage] [-t          target-pane] [shell-command] [-f format]    (from man tmux, section "windows and panes")
i think what most closely fits what you're looking for is apropos (a.k.a
you can use bind -r "key" to remove the binding
this is actually a function of the terminal emulator you are using (xterm, gnome-terminal, konsole, screen)
as far as i know, the only way to show the full command line is to scroll right with the arrow keys or to use a terminal with a small font. 
there are several possibilities for how this happened
you can either download the source code and compile the package yourself, or you can downloaded the binary package for your distribution
the simplest way is to use $!
please keep in mind that not using the kernel distributed with slackware may break your system.   apart of that, compiling the official kernel is a difficult task and takes its time
from man gzip you can read that gzipped files can simply be concatenated:     advanced usage         multiple compressed files can be concatenated
github gist: how to change cursor shape, color, and blinkrate of linux console  i define the following cursor formatting settings in my .bashrc file (or /etc/bashrc):  ############## # pretty prompt and font colors ##############  # alter the default colors to make them a bit prettier echo -en "\e]p0000000" #black echo -en "\e]p1d75f5f" #darkred echo -en "\e]p287af5f" #darkgreen echo -en "\e]p3d7af87" #brown echo -en "\e]p48787af" #darkblue echo -en "\e]p5bd53a5" #darkmagenta echo -en "\e]p65fafaf" #darkcyan echo -en "\e]p7e5e5e5" #lightgrey echo -en "\e]p82b2b2b" #darkgrey echo -en "\e]p9e33636" #red echo -en "\e]pa98e34d" #green echo -en "\e]pbffd75f" #yellow echo -en "\e]pc7373c9" #blue echo -en "\e]pdd633b2" #magenta echo -en "\e]pe44c9c9" #cyan echo -en "\e]pfffffff" #white clear #for background artifacting  # set the default text color
unfortunately, for historical reasons, different tools have slightly different regular expression syntax, and sometimes some implementations have extensions that are not supported by other tools
the command you have above will (somewhat clumsily) rename all files in the current directly from *.jpg to *.jpeg, it could be modified to delete all files but is hardly appropriate to the task.  however, it sounds like you are trying to craft a suitable filename such that when the above command encounters it, it will delete everything in the current directory instead
a user who has a valid shell and no password can still log in by non-password-based methods, the most common being an ssh key
i'm guessing the real problem here is that the command you are trying to run is emacs
to have something execute only on the second monday of a month the day of week value needs to be 1 and the day of month value has to be 8-14, the hour has to be 2,6,10,14,18,22 and the minute 0
i found it: applying default permissions  from the article:  chmod g+s &lt;directory&gt;  //set gid  setfacl -d -m g::rwx /&lt;directory&gt;  //set group to rwx default  setfacl -d -m o::rx /&lt;directory&gt;   //set other   next we can verify:   getfacl /&lt;directory&gt;   output:   # file: ../&lt;directory&gt;/ # owner: &lt;user&gt; # group: media # flags: -s- user::rwx group::rwx other::r-x default:user::rwx default:group::rwx default:other::r-x  
netstat itself does not support such filtering.  you probably have to do something like:  sudo netstat -lp --inet | grep " $pid/"  
these warnings are triggered because of firmware errors
muru is right, if you check findutil changelog @line 1645        major changes in release 4.2.9, 2004-12-05           xargs now supports the posix options -e, -i and -l
when you disable packet forwarding between interfaces the forward chain is ignored at all
ok, i found how to do this at how to change gnome-shell calendar default application  just execute this in a terminal!!  gsettings set org.gnome.desktop.default-applications.office.calendar exec thunderbird   i have tested it and it works!! (it's not exaclty what i wanted but it's a start) 
you need to comment out the devicescan line, and put in lines for individual devices
beginning with mysql 5.1.26, the federated storage engine is not enabled by default in the running server; to enable federated, you must start the mysql server binary using the --federated option.  or edit your /etc/my.cnf global server configuration file and under [mysqld] stanza section, add the line:  federated   the mysqld service has to be restarted to get the federated engine enabled and this will be enabled by default for every instance/restart of mysql service. 
here is the laziest way (or homebrew way)  first install homebrew if you haven't  second brew install htop  third, done  [updated htop to htop-osx, thanks @clwen]  [updated: htop is actually an alias to htop-osx, so both will work]  [updated 27/03/2016: htop use the latest version from original author,  just tested it on el capitan works fine
try sudo ln -s dash /bin/sh
for debian wheezy, all of the entries should be wheezy or higher
 if you have gparted open, close it
i'd use sed  sed 's/^.*\(consectetuer.*elit\).*$/\1/' file   decoded the sed s/find/replace/ syntax:   s/^.* -- substitute starting at the beginning of the line (^) followed by anything (.*) up to... \( - start a named block consectetuer.*elit\. - match the first word, everything (.*) up to the last word (in this case, including the trailing (escaped)dot) you want to match \) - end the named block match everything else (.*) to the end of the line ($) / - end the substitute find section \1 - replace with the name block between the \( and the \) above / - end the replace  
this is needed if you are using dhcp v6 due to the slightly different way that dhcp works in v4 and v6.  in dhcp v4 the client establishes the connection with the server and because of the default rules to allow 'established' connections back through the firewall, the returning dhcp response is allowed through.  however, in dhcp v6, the initial client request is sent to a statically assigned multicast address while the response has the dhcp server's unicast address as the source (see rfc 3315)
just add /dev onto the list of files to archive:  ssh -n &lt;hostname&gt; sudo tar -cpvzf - --one-file-system / /dev &gt; bak.tar.gz   --one-file-system only prevents recursing into directories on different filesystems
i have been able to solve with  qstat -r | grep -cw "jobname"  which gives a 0 or 1 which then i can use inside an if statement
if your parameters are dependably separated by exactly one space each, you could use cut as follows:  echo p1 p2 p3 p4 p5 p6 p7 | cut -d' ' -f4-   # for p4 onwards echo p1 p2 p3 p4 p5 p6 p7 | cut -d' ' -f4-6  # for p4 to p6   if you want whitespace separated parameters the way awk parses them, dependably, it gets more complicated
to store the output of a command in a variable, use :  variable=$( commandfoobar )   check here 
yes the -v option should only list the transferred files/directories
since read only reads a single line of input, sans newline, you just want to check for the empty string:  read option case $option in     1 ) echo "1" ;;     2 ) echo "2" ;;     "" ) echo "lf" ;;     0 ) exit ;;     * ) echo "invalid input" ;; esac   [1] and 1 (and similarly for the other one-character classes) match the same strings as patterns. 
notify-send works like this:  notify-send [option...] &lt;summary&gt; [body]   now, as you only have one (quoted) string, that's being used for the summary and the body is empty
you could use sox
you have two solution, first you can try every link from mirror list in https:// and you could also download the official bittorent file because bitorrent include a checksum checking
the op originally asked a different question
things you find in the man pages are generally about programming, and the c api
for the sake of this conversation lets say there are 2 machines named lappy and remotey
well, according to the webgl public wiki, both firefox and chrome support webgl with nvidia gpus in x11/linux.  in my case the wrong graphic driver was selected.   ~ # eselect opengl list available opengl implementations:   [1]   nvidia   [2]   xorg-x11 *   setting it back to nvidia fixed my issues with webgl.   ~ # eselect opengl set nvidia switching to nvidia opengl interface..
putting each tuple on a separate line:  sed 's@)\s*,\s*(@)\n(@g' your_file   to apply modifications to the file (instead of printing the modified file to stdout):  sed -i 's@)\s*,\s*(@)\n(@g' your_file   to report only value3 (assuming a modified file):  awk -f',' '{print $3}' &lt;your_new_file   this assumes the values themselves don't contain ,
to introduce a 1gb /tmp that sits in tmpfs and therefore clears on boot, add this line to /etc/fstab and then reboot
a byte-order-mark would only be at the beginning of a file (not at the end)
there are several layers of problems, and they have little to with skype
no, ssh doesn't support regular expression in ssh_config (1) and the example you gave aren't regular expressions
x11 modifier handling is a bit peculiar
yes thats right,check this :     https://bugs.launchpad.net/ubuntu/+source/php-auth-pam/+bug/798571   if doesnt exist yet, it is maybe removed from repository... and also check this :     http://packages.ubuntu.com/lucid/web/php5-auth-pam   i think there's not newer version for this package.goodluck. 
unlock the account and give the user a complex password as @skaperen suggests.  edit /etc/ssh/sshd_config and ensure you have:  passwordauthentication no   check that the line isn't commented (# at the start) and save the file
   also can this script be optimized into one line command?   i'd consider using the -o option of the ps command to output (as far as possible) only the fields of interest, and then post-processing that to match the java processes and specific command argument(s) that you require - something like   ps -u $user -o uname=,pid=,args= |    gawk -vofs='\t' '/java/ {print $1,$2,substr($0,match($0,"-d(app[.]name)|(projectname)[^[:space:]]*"),rlength)}'   or perhaps something like this in perl (disclaimer: my perl knowledge is sketchy)  ps -u $user -o uname=,pid=,args= |    perl -anle 'print join "\t", @f[0], @f[1], grep /-d(app[.]name)|(projectname)/,@f if /java/'  
from the comments to the other answer, what is missing is the library linked in.  make sure ncurses-dev (or similarly named package) is installed
if you are only interested in the ip addresses but not the other gory details about the network interfaces, /sbin/ifconfig -a | grep "inet addr:" |awk '{print $2}'|cut -d: -f2 gives you all the ip addresses configured on all network interface cards and nothing else. 
this perl script stores each log line that matches the criteria (an "image/", > 100000 bytes, referrer = '-') in a hash of arrays keyed by the ip address
the hardware, the kernel and the user space programs may have different word sizes¹.   you can see whether the cpu is 64-bit, 32-bit, or capable of both by checking the flags line in /proc/cpuinfo
based on @c2h5oh's and @user1277476's answers, i came up with a solution:  $ for file in `find 
you can use the -f parameter to ls to get:     -f, --classify           append indicator (one of */=&gt;@|) to entries   i.e.:  # ln -s videos videos # ls -l lrwxrwxrwx
you could, but if any file crosses the split boundary, you won't be able to recover it
i'm the creator of that conky theme
the following command lists the lines in list_file that contain the name of an image file:  &lt;list_file xargs -d \\n file -i | sed -n 's!: *image/[^ :]*$!!p'    file -i foo looks at the first few bytes of foo to determine its format and prints a line like foo: image/jpeg (-i means to show a mime type; it's specific to gnu file as found on linux). xargs -d \\n reads a list of files (one per line) from standard input and applies the subsequent command to it
thanks to 'steeldriver', i've worked out that the answer is because posix specification forbids anything from being between {} and + after -exec. 
 you may well expect them to go up to 63 on a typical linux box. there is (was?) stdlog, but it's rarely used (i believe i never saw one). the order is important: check man bash redirection.  
this doesn't really answer your question; i suspect the reason head is slow is as given in julie pelletier's answer: the file doesn't contain any (or many) line feeds, so head needs to read a lot of it to find lines to show
you're right about permissions: each directory component must be world-executable, and the item itself must be world-readable (and probably world-executable as well if it's a directory).  an additional wrinkle is that if the path involves symbolic links, you need to make every intermediate directory that is necessary to resolve the symbolic link world-executable as well.  if you have a symlink-free path, a simple loop can do the job:  make_directory_world_accessible () {   dir=$1   case $dir in /*) :;; *) dir=$pwd/$dir;; esac   while [ -n "$dir" ]; do     chmod a+x "$dir"     slashes=${dir##*[!/]}; dir=${dir%$slashes}; dir=${dir%/*}   done }   with symbolic links, you need to look up all symbolic links manually and recurse over each directory component
the problem turned out to be that udp packets were not being passed
they're not expressions, they're filenames for files produced as follows:   printenv | sort &gt; printenv.sorted  set | sort &gt; set.sorted   that's not clear from the documentation so your confusion is understandable!  note that you may need to help diff and grep by forcing them to treat their inputs as text (with -a); environment variables can contain values which will cause them to treat their input as binary, which won't produce anything useful:  diff -a set.sorted printenv.sorted | grep -a "&lt;" | awk '{ print $2 }'   better still, use comm to compare the two files:  comm -23 set.sorted printenv.sorted   you can replace the files with process substitutions:  comm -23 &lt;(set|sort) &lt;(printenv|sort)   to avoid creating files. 
you can also use iptables to allow/restrict by udp/tcp ports on desired interfaces
you should be running firefox 45 esr, not 17-ish
there are two elements to a better solution:   shift (more) quoting   define the function using shift, like this:  function build {   local cc="$1"   local cflags="$2"   shift 2   make cc="$cc" cflags="$cflags" "$@" }   where we save the first two parameters to local variables, then shift the whole argument array by two; also, quote the "$@" expansion
once you have selected the block, you can use alt + } to indent it. 
linux does dump panics to the screen...depending on your definition of the screen.  what linux actually does is dump to the system console
the make localmodconfig command is still the right tool for the job
x11vnc perfectly works with x11vnc -display :0 -auth guess -no6 -forever -nolookup -passwd xxxx -ping 60 also have a look at the -reopen parameter in case of problem when you logoff.  i use kdm so i put this line into /etc/kde/kdm/xsetup  every needed informations are there : http://www.karlrunge.com/x11vnc/faq.html 
you could check the files' contents to make sure that a substitution will take place when sed operates on them:  find 
ingo molnar proposed a patch, but this patch wasn't accepted into the kernel tree
linux uses ttysx for a serial port device name
edit: while the following answer explains the general usage case, i should note that deleting files and directories is a special case
use type commandname
i ended up solving this problem by not connecting to the internet connection directly, but through connecting to my other machine which is already connected to wifi, thus eliminating the need to enter a username/password on the client
i'll suggest a named pipe
add this line after set -o vi:  bind -m vi-command ".":yank-last-argument # or insert-last-argument   then you can use alt+. like in emacs-mode.  or use history expansion, working in both:  !$:p  
the dhcp server configuration is wrong
when dealing with return codes "0" is a success and non-zero is failure
this behaviour is the result of the built-in suffix rules of make (in this case for legacy verions of the source code control system [1])
most recent distributions have a tool called lsb_release
not sure if i understand your question right, but in bash this could work:  for n in {22..99} ; do cp "ifcfg-eth1:$n" "ifcfg-eth1:1$n"; done   that would copy ifcfg-eth1:22 through ifcfg-eth1:99 to ifcfg-eth1:122 through ifcfg-eth1:199.  i'm not sure why you would use such files
just:  echo "$variablename"   for example for the environment variable $home, use:  echo "$home"   which then prints something similar to:  /home/username     edit: according to the comment of stéphane chazelas, it may be better if you use printenv instead of echo:  printenv home  
this seems to work...  https://wiki.archlinux.org/index.php/tmux#start_tmux_on_every_shell_login  simply add the following line of bash code to your .bashrc before your aliases; the code for other shells is very similar:  [[ $term != "screen" ]] &amp;&amp; exec tmux  
i would not wait for 5 seconds and hope that will work, you might wait too long, or too short
you might be able to use paste:  $ paste - - - &lt;data.txt 1 data      2 data      3 data    1 data      2 data      3 data    1 data      2 data      3 data  
running fsck.xfs on the partition image would be a good way to know if the file is corrupted or not.  since it is a disk image rather than a partition image, you'll need to extract the partition from the disk
from the read usage output you can actually use the -a flag.  read -p "array: " -a array  
my first thought was .bash_logout too, but that only works for login shells
i don't think it's typical that live cd's include developer tools such as make and  autoconf
you can use the addremove command to mark missing files (those prefaced with a !) as removed.  see the excellent mercurial: the definitive guide chapter on tracking files.  for future reference, there is a command to move files, hg mv. 
this depends if you are using rhn classic or the newer red hat customer portal subscription management/rhsm.  rhn classic utilized a plugin for yum, there was a /etc/yum.repos.d/redhat.repo file but it was auto-generated.  the newer subscription management/rhsm does use the file /etc/yum.repos.d/redhat.repo and it populated similar to normal yum repos, an example of this is:  [rhel-6-server-optional-fastrack-source-rpms] metadata_expire = 86400 sslclientcert = /etc/pki/entitlement/xxxxxxxxxx.pem baseurl = https://cdn.redhat.com/content/fastrack/rhel/server/6/$basearch/optional/source/srpms ui_repoid_vars = basearch sslverify = 1 name = red hat enterprise linux 6 server - optional fastrack (source rpms) sslclientkey = /etc/pki/entitlement/xxxxxxxxxx-key.pem gpgkey = file:///etc/pki/rpm-gpg/rpm-gpg-key-redhat-release enabled = 0 sslcacert = /etc/rhsm/ca/redhat-uep.pem gpgcheck = 1  
some software projects provide pre-compiled binaries for several distributions
you're only using around 7.4gb on / and have 79gb free in lvm so, yes, you can create a new lv for / (and another one for /var) and copy the files from / and /var to them
based on this response, i have done the following and it works.  sudo nano /etc/gdm/gdm.conf   in this file, i added the following line.  firstvt=7      in /etc/gdm/gdm.conf you can set what the 1st terminal should be the   graphical interface
the bsd install found on openbsd systems has this piece of code in it (from src/usr.bin/xinstall/xinstall.c):  if (!s_isreg(to_sb.st_mode))     errc(1, eftype, "%s", to_name);   this emits the error  install: /dev/fd/4: inappropriate file type or format   when it's discovered that /dev/df/4 is not a regular file
well, i just tried this on 2 machines (sun os / linux) and works on both:  in vi (&lt;> represents actions to do / to write):  :&lt;write start line number&gt;,&lt;write end line number&gt;y&lt;press enter&gt;   then move the cursor with arrow/hjkl keys on where do you want to paste.  then simply press      p or p  example:  :1,3y   this will copy line 1 through 3. 
lsb_release -a is likely going to be your best option for finding this information out, and being able to do so in a consistent way
there have been many of these over the years
sftp is a command access to file operations, with the restrictions from the account you use
do you have, and load, the file /etc/bash_complete or an equivalent directory? it defines a bunch of completions and extension facilities beyond what's built into bash
put them in a .sh file in ~/.kde/env/ (possibly ~/.kde4/env/ or similar; varies by distribution). 
have you formatted the swap partition? once you part your disk and reserve a partition for swap you have to:  sudo mkswap /dev/sdb5   after that your swap's uuid should be displayed when entering blkid command. 
let your shell expand the variable by using " instead of '.  example:  victor@pyfg:~$ line_number=2 victor@pyfg:~$ sed -n "${line_number},${line_number}p" /etc/hosts 1.2.3.4 row-2   since you're only printing a single row, you can just to it like this also:  victor@pyfg:~$ sed -n "${line_number}p" /etc/hosts 1.2.3.4 row-2  
similar to one of the answers above, if you have a copy of the directory with the correct permissions named "var" in your local directory, you can use the following two commands to restore permissions to the /var directory.  sudo find var -exec chown --reference="{}" "/{}" \; sudo find var -exec chmod --reference="{}" "/{}" \;  
i'll try and answer both your questions as they are related.  the doors to namespaces are files in /proc/*/ns/* and /proc/*/task/*/ns/*.  a namespace is created by a process unsharing its namespace
it's not /usr/bin/[ in either of the shells
the aix ftpd doesn't provide per-user umask settings
as the post related to man tor describes does the tor browser bundle cache relay information?, there is such a file with cache information in the system.     datadirectory/cached-consensus and/or cached-microdesc-consensus     the most recent consensus network status document we’ve   downloaded.    so in debian, the file with the cache tor relays is /var/lib/tor/cached-microdesc-consensus and the information there can be valid for up to 24h
the space available in the mbr itself is tiny
i don't have hp-ux available to me, and i've never been a big hp-ux fan.  it appears that on linux, a per-process or maybe per-user limit on how many child processes exists
you can do it by telling wget to output its payload to stdout:  wget -qo- your_link_here | tar xvz   to specify a target directory:  wget -qo- your_link_here | tar xvz -c /target/directory   update  if you happen to have gnu tar  wget -qo- your_link_here | tar --transform 's/^dbt2-0.37.50.3/dbt2/' -xvz   should allow you to do it all in one step. 
why not switch to text console using the control-alt f1/f2/.... keys combinations ?  
sure, with  screen -d -r   you can choose which screen to detach and reattach as usual by finding the pid (or complete name) with screen -list.  screen -d -r 12345  
i don't see how this would be feasible given html5 support is typically built into the browser directly, whereas, adobe flash is a plugin
   what i want is something that checks all hardware actually supported   by the kernel in use without taking into consideration if i am using   that hardware or not.   if you have the .config file the kernel was built with, you can download the source and run make menuconfig, which will give you an idea of a) what hardware it is possible to configure a kernel for (but see note), and b) what hardware your kernel is actually configured for.    so to do this:   download the source
no need to use non-standard process substitution (&lt;(...)) here:  sort file1 | join -o1.2 - file2 | uniq  
it's executed three times, once for each matching file
with find:  find 
from the wikipedia entry:     [the] maximum disk size supported on disks using 512-byte sectors (whether real or emulated) by the mbr partitioning scheme (without using non-standard methods) is limited to 2 tb.   2tb = 2*1024*1024*1024*1024 = 2^41 = 2^32 * 2^9, and 2^9 is 512. 
perl to the rescue:  perl -i~ -0777 -pe 's/text = "[^"]+"/text = ""/g' input-file    -i~ will edit the file "in place", leaving a backup copy -0777 reads the whole file at once, not line by line   the substitution s/// works similarly as in sed (i.e
if the command line is inaccessible to ps, i.e
for polycom phones have be  alert-info: ring answer   or have be in config  &lt;voipprot&gt;       &lt;alertinfo voipprot.sip.alertinfo.1.value="ring answer"  voipprot.sip.alertinfo.1./&gt;     you also can change that option via phone's web interface 
no, you have little control over how the private keys are configured, and you can't detect / enforce any passphrase requirement on them.  you also can't limit the size of the keys without modifying the openssh source itself (i.e
basically, it's a portability (and reliability) issue.  initially, echo didn't accept any option and didn't expand anything
a simple tracing  first, you can figure out that what actually happen when you using bash completion with cd command:  $ complete -p | grep cd complete -f _filedir_xspec cdiff complete -o nospace -f _cdrecord wodim complete -o nospace -f _cdrecord cdrecord complete -o nospace -f _cd cd   you can see a function _cd will be called when you use completion with cd
ubuntu calls the service ssh, not sshd.  service ssh restart   the service is also controlled by upstart, and not sysvinit
ssh never sends the private key over the network
from a search through the man pages, on a linux system, i find that the command supporting a --human-readable option are the following: df dir du ls rsync vdir
on unity the default window resize shortcut is alt+f8
using awk  $ awk '/}/{next;} /name:/{print;n=nr+10} nr&gt;n' file name: john apple orange grape pine name: ruben grape zebra donkey name: tom tiger red blue orange tomato cat   how it works   /}/{next;}  skip over any line containing }. /name:/{print;n=nr+10}  when we reach a line containing name:, print it and, so we know when to start printing again, set n to 10 plus the current line number. nr&gt;n  if the current line number is greater than n, then do the default action: print the line.   using sed  with very similar logic:  $ sed -e '/}/d' -e '/name:/{p;n;n;n;n;n;n;n;n;n;n;d;}' file name: john apple orange grape pine name: ruben grape zebra donkey name: tom tiger red blue orange tomato cat   how it works   /}/d  delete any line containing }. /name:/{p;n;n;n;n;n;n;n;n;n;n;d;}  if we find a line containing name:, print it, then read in the next 10 lines and delete them.   lines not falling into either the above categories are printed. 
there is no --package-name option for rpm
have color extension enabled  use something like hg log -r nnn -v -p -g (can't show colored chunks, but they are here)  changeset:   7:32bbc6bc3867 user:        al &lt;lazybadger@*&gt; date:        tue nov 20 03:51:53 2012 +0600 files:       404.php description: localization of page   diff --git a/404.php b/404.php --- a/404.php +++ b/404.php @@ -1,8 +1,8 @@  &lt;?php get_header(); ?&gt;     &lt;article class="noposts"&gt; -       &lt;h2&gt;404 - content not found&lt;/h2&gt; -       &lt;p&gt;we don't seem to be able to find the content you have requested - why not try a search below?&lt;/p&gt; +       &lt;h2&gt;&lt;?php _e('404 - content not found','fiver' ); ?&gt;&lt;/h2&gt; +       &lt;p&gt;&lt;?php _e('we don&amp;rsquo;t seem to be able to find the content you have requested - why not try a search below?','fiver' ); ?&gt;&lt;/p&gt;         &lt;?php get_search_form(); ?&gt;    &lt;/article&gt;   if you'll want to change default output - just write own style and add -t stylename to log options  note  options used:   -r define the scope of changesets to show (it can be single changeset or revset) -v (optional) verbose output: slightly change format of default output and add string with files, affected in each changeset (has no analogues in default git show) -p append diff of changes to log-output -g emit the above diff in "extended git format" (because in git show diff is always in git-format)  
don's might be better in most cases, but just in case the file is really big, and you can't get sed to handle a script file that large (which can happen at around 5000+ lines of script), here it is with plain sed:  sed -ne:t -e"/\n.*$match/d" \     -e'$!n;//d;/'"$match/{" \             -e"s/\n/&amp;/$a;t" \             -e'$q;bt' -e\}  \     -e's/\n/&amp;/'"$b;tp"      \     -e'$!bt' -e:p  -e'p;d'   this is an example of what is called a sliding window on input
note this will make your current installation un-bootable and any data in the volume group inaccessible.  first in a terminal window start   sudo fdisk /dev/sdb   then press d (the partition delete command)  then press 3 (the number of partition to delete)  then press w (write changes and exit) 
after some searching, i've found the answer:  to discover what escape sequence the key combination is triggering, follow this excellent answer:  echo "ctrlvesc/"  which displays, for me, as: echo "^[/"
the number refers to the id# of the logical cpu that the process is running on.  references   top man page  
i have found it out now
you can use whiptail or dialog    have look at this thread:  whiptail or dialog  bash shell scripting/whiptail 
basically this is the same thing as one of the very famous unix technical interview questions, known for ages:  assume someone with root access ran a command chmod -r 444 / and made the chmod binary non-executable
found out even more general solution:  http://ubuntuforums.org/showthread.php?t=2920  it is described how to modify any session manager to "see" any session type
openssh public key format is different from pem format
printf '%s\n' *   as a shell command will list the non-hidden files in the current directory, one per line
try:  awk '{print; for (i=1;i&lt;=31;i++) {x=$0; gsub(/sel0/, "sel" i, x); print x;}}' rs="" file   for example, and limited to 3 repetitions:  $ awk '{print; for (i=1;i&lt;=3;i++) {x=$0; gsub(/sel0/, "sel" i, x); print x;}}' rs="" file cr_v8_sel0 : cross cp_v8_en, cp_sel0 {    ignore_bins ig_v8_sel0 = binsof(cp_v8_en) &amp;&amp; binsof(cp_sel0) intersect {[0:3],[5:$]};  } cr_v8_sel1 : cross cp_v8_en, cp_sel1 {    ignore_bins ig_v8_sel1 = binsof(cp_v8_en) &amp;&amp; binsof(cp_sel1) intersect {[0:3],[5:$]};  } cr_v8_sel2 : cross cp_v8_en, cp_sel2 {    ignore_bins ig_v8_sel2 = binsof(cp_v8_en) &amp;&amp; binsof(cp_sel2) intersect {[0:3],[5:$]};  } cr_v8_sel3 : cross cp_v8_en, cp_sel3 {    ignore_bins ig_v8_sel3 = binsof(cp_v8_en) &amp;&amp; binsof(cp_sel3) intersect {[0:3],[5:$]};  }   how it works   print  this prints out the original version with sel0. for (i=1;i&lt;=31;i++) {x=$0; gsub(/sel0/, "sel" i, x); print x;  this loops over i from 1 to 31, makes the substitutions and prints the result. rs=""  this tells awk to read an entire paragraph at a time
i don't know if kbd is installed by default or not, but though setfont worked, i didn't have it installed; a simple sudo apt-get install kbd did the trick, and the font is back to normal.  setfont still echoes cannot find default font, though; i'm still trying to understand what's happened/what is happening. 
the problem is that you have an embedded carriage-return (cr, \r)
grep's -o will only output the matches, ignoring lines; wc can count them:  grep -io "nicolas bomber" annuaire | wc -l   or simply,  grep -ioc "nicolas bomber" annuaire   as you commented, you can match any number of whitespaces coming in between the words, using -z option,  grep -iz "nicolas[[:space:]]*bomber" annuaire | wc -l   from man grep  -i, --ignore-case     ignore case distinctions in both the pattern and the input files
to show all lvs and where they come from you can check with:  lvs -ao +devices  
try doing this:  sed '3{/^$/d;}' file   note the braces. 
to begin with, linux is not at all about security; the linux maintainers are not particularly interested in security
it looks like it was a regression introduced in meld 3.12.1
in many shells including ksh, zsh and bash, time is a keyword and is used to time pipelines.  time foo | bar   will time both the foo and bar commands (zsh will show you the breakdown)
to me this sounds like the server has been misconfigured.  as you stated, the system automatically picked up your username (gisle) upon logging in
according to the i3status man page, section titled "external scripts/programs with i3status", you can set the bar section of the .i3/config file to a shell script you write
use process substitution:  diff &lt;(cat /etc/passwd) &lt;(cut -f2 /etc/passwd)   &lt;(...) is called process substitution
   in particular, the hostname  line is what allows ssh &lt;instance&gt;.&lt;location&gt;.&lt;project&gt;?   yes
$@ should pretty much only be used in the form "$@", alone in a word
i don't completely understand your requirements: which machine are the users to be jailed on? can they do anything that doesn't involve the network? nonetheless i think i can tell you what the necessary building blocks are.  to restrict a user to specific network connections, see how to restrict internet access for a particular user on the lan using iptables in linux
with pv 1.2.0 (december 2010) and above, it's with the -a option:  here with both current and average, line-based:  $ find / 2&gt; /dev/null | pv -ral &gt; /dev/null [6.28k/s] [70.1k/s]   with 1.3.8 (october 2012) and newer, you can also use -f/--format with %a:  $ find / 2&gt; /dev/null | pv -lf 'current: %r, average: %a'  &gt; /dev/null current: [4.66k/s], average: [ 218k/s]   note that tail -f starts by dumping the last 10 lines of the file
can you make a backup of the configuration and :  yum remove openldap rpm -e openldap.package_name yum install openldap   and copy your configuration files back 
tr replaces single characters with a single character; the arguments you've given instruct tr to replace \n with \n.  to add space between paragraphs, you can replace an empty line with four newlines using sed:  ypcat netgroups | sed 's/^$/\n\n\n\n/g'  
you could check it by using the command  mount   it will give you all the mounted file systems
you should be able to accomplish this with the following code:  #!/bin/bash  lowest=046725 highest=046899 width=6  for (( seq=10#$lowest; seq&lt;=10#$highest; seq++))   do      length=`echo -n $seq | wc -c`      if [[ $length &lt; $width ]]; then        number_of_zeroes_to_add=`expr $width - $length`        for zeroes in `seq $number_of_zeroes_to_add`;         do echo -n 0;       done      fi      echo $seq   done   what this is doing is establishing a width of the number (e.g
kvm itself doesn't do anything but run the vm
the script /etc/gdm/postsession/default is run by root whenever someone quits his x session
@gareththered's comment solves the thing: sudo systemctl -l status apache2 which gives clear logs (see the body of the question), and solve the case by correcting paths to private and public keys, /etc/apache2/conf-enabled/owncloud-ssl.conf which however may be unsuitable for owncloud because of no access still in http/https  &lt;virtualhost *:80&gt;     rewriteengine on     rewritecond %{server_port} !^443$     rewriterule ^/(.*) https://%{http_host}/$1 [nc,r,l] &lt;/virtualhost&gt; &lt;virtualhost *:443&gt;     servername 127.0.0.1     sslengine on     sslcertificatefile /etc/ssl/certs/my-pubkey.perm     sslcertificatekeyfile /etc/ssl/private/apache.key     documentroot /var/www/owncloud      &lt;ifmodule mod_headers.c&gt;         header always set strict-transport-security "max-age=15768000; includesubdomains; preload"     &lt;/ifmodule&gt; &lt;/virtualhost&gt;   i restart apache2 again and do   masi@raspberrypi:~ $ sudo systemctl -l status apache2  ● apache2.service - lsb: apache2 web server    loaded: loaded (/etc/init.d/apache2)    active: active (exited) since thu 2016-06-23 19:58:00 utc; 5s ago   process: 1280 execstart=/etc/init.d/apache2 start (code=exited, status=0/success)  jun 23 19:58:00 raspberrypi apache2[1280]: starting web server: apache2action 'start' failed. jun 23 19:58:00 raspberrypi apache2[1280]: the apache error log may have more information. jun 23 19:58:00 raspberrypi apache2[1280]: . jun 23 19:58:00 raspberrypi systemd[1]: started lsb: apache2 web server.   output: http/https addresses do not work
simply use sed,  sed 's/^/    /' file   this appeands four spaces before each line
there is no difference
two options come to my mind:   own the directory you want by using chown:     sudo chown your_username directory    (replace your_username with your username and directory with the directory you want.) the other thing you can do is work as root as long as you know what you are doing
sigstop and sigkill are two signals that cannot be caught and handled by a process
assuming the unknown shell supports running an absolute command, you could try: /bin/bash  to change the default shell, i would use chsh(1)
the virsh list command only runs things running.  if you want things defined but not running then  virsh list --all   and remember each type of namespace is distinct so you may need --connect as well  e.g.  $ virsh -c lxc:/// list        id    name                           state ----------------------------------------------------   $ virsh -c lxc:/// list --all  id    name                           state ----------------------------------------------------  -     helloworld                     shut off  $ virsh -c qemu:///system list  id    name                           state ----------------------------------------------------  37    fedora24                       running  $ virsh -c qemu:///system list --all  id    name                           state ----------------------------------------------------  37    fedora24                       running  -     docker                         shut off  -     kali                           shut off  -     test1                          shut off  
you can use  iwlist &lt;interface&gt; scan   for example:  iwlist wlan0 scan   also, using pipes and egrep, and practicing a little with iwlist scan, you can extract the info you want:  iwlist wlan0 scan | egrep 'address:|essid:'  
ok, the main issue here is that there is no such thing as line 0
on unix like system root rights are defined by the user id (which is 0 for the root user)
you can use grep with -p (pcre) :  grep -p -a 1 'sometest(?!aa)' file.txt   (?!aa) is the zero width negative lookahead pattern ensuring that there is no aa after sometest.  test :  $ grep -p -a 1 'sometest(?!aa)' file.txt  sometestabcd endtest sometestdefg endtest sometestacdf endtest  
a very simplified version would be something as follows:  2 lines in config.php:  cat config.php $variable1 = 'foo with bar'; $variable1 = 'foo2 with bar2';   set bash $variable1 to last matching instance of $variable1 in config.php, just in case it has been reset
solution:   disable auto-login, i thought of this anyway logout and login again the next time i tried to connect to ssh there was a checkbox to automatically unlock this key, which i ckecked and proceeded with login voila!, after reboot i have increased security by disabling the auto-login and it does not ask me for password on ssh keyring  
cherokee removed from debian  i found this thread on the cherokee mailing list which would seem to indicate that the package has been dropped from debian all together.   http://www.gossamer-threads.com/lists/cherokee/users/24168      cherokee was removed from testing back in november, and has been    removed from unstable yesterday
the tool you want is lsof, which stands for list open files.  it has a lot of options, so check the man page, but if you want to see all open files under a directory:  lsof +d /path   that will recurse through the filesystem under /path, so beware doing it on large directory trees.  once you know which processes have files open, you can exit those apps, or kill them with the kill(1) command. 
you are talking about the screenshots provided by http://screenshots.debian.net
you want to use the -s|--protect-args option to rsync.  without it, the part after the : is passed as is to the remote shell so you can use constructs of that shell to build the list to transfer.  that way, if you know the remote shell is zsh for instance, you can do:  rsync host:'*(.)' there   to transfer only regular files
if you need to resolve (or investigate) a symlink you can use the platform independent bash library 'realpath-lib'
try this in-order to remove the file:  rm -- --append  
best would be to use zsh's zmv:  autoload zmv # best in ~/.zshrc zmv -n '(*)/index' '$1/c2_$1'   (remove -n when happy).  for a portable (posix sh) solution:  for dir in */index;  do   mv -i -- "$dir" "${dir%/*}/c2_${dir%/*}" done   (using -i as a poor man's ersatz to the sanity checks zmv does).  if you wanted to use find portably (posixly), you'd need to forget about -mindepth/-maxdepth, which you can replace with combinations of -path and -prune:  lc_all=c find 
you need the rtl8188efw.bin firmware file to be somewhere in /lib/firmware.  if it isn't packaged for centos 6.7, you can get it (along with a lot of other firmware) with:  git clone git://git.kernel.org/pub/scm/linux/kernel/git/dwmw2/linux-firmware.git   then copy it into /lib/firmware/  btw, on my debian system, it is in the firmware-realtek package with filename /lib/firmware/rtlwifi/rtl8188efw.bin  if it isn't being automatically loaded at boot time (it should be), you also need to ensure that the rtl8188ee kernel module is being loaded. 
well, gnome notifications use d-bus to pass the messages around
you need to tell the system that you have that file
freebsd's cron understands the @reboot time directive, so you can indeed have cron execute your script at startup
you should have been asked for the password during installation.  in case you do not remember your password, you can always reset your password. 
there is no ls command which will show full path information, because vms and unix are very conceptually different here
jq would do:  $ jq ".data.update" &lt;&lt;&lt; '{"data":{"update":"openelec-rpi2.arm-5.0.8.tar","folder":"releases","host":"","md5":""}}' "openelec-rpi2.arm-5.0.8.tar"   or with -r:  jq -r ".data.update" &lt;&lt;&lt; '{"data":{"update":"openelec-rpi2.arm-5.0.8.tar","folder":"releases","host":"","md5":""}}' openelec-rpi2.arm-5.0.8.tar   to get the (raw) string without quotes. 
there are two lists of options in bash
as per information on rpm.pbone.net xls2csv-1.06-14.fc19.noarch.rpm package provides:     content of rpm :   /usr/bin/convertxls2csv   /usr/share/man/man1/convertxls2csv.1.gz     so you can use convertxls2csv instead of xlsx2csv command from this package
with sed alone:  sed -i '/^* !^from_mailer$/d' file   to remove the whole line containing the exact string * !^from_mailer, with nothing before and after that string
on linux:  grep ^processor /proc/cpuinfo | wc -l  
to get more information on this error for troubleshooting purposes start by running the command:  $ journalctl -ab   this will dump some detailed logs out of the systemd journal.  additionally, there was probably another error directly in front of that one telling you what service, specifically, is having an issue
search.awk   begin {     fs = "="     cur_username = "" }  $1 ~ /user-name/ {     cur_username = $2     gsub(/^[ \t]+/, "", cur_username)     gsub(/[ \t]+$/, "", cur_username) }  $1 !~ /user-name/ {     if ((nf != 2) || (cur_username != searched_user))         next      key = $1     gsub(/^[ \t]+/, "", key)     gsub(/[ \t]+$/, "", key)      value = $2     gsub(/^[ \t]+/, "", value)         gsub(/[ \t]+$/, "", value)      values[key] = values[key] " " value }  end {     printf("user-name = %s\n", searched_user)     for(key in values) {         printf("\t%s =%s\n", key, values[key])     } }   test run:   $ awk -f search.awk -v 'searched_user="mark"' input  user-name = "mark"     acct-status-type = interim-update interim-update     acct-input-octets = 95684 95684     framed-ip-address = 0.0.0.0 0.0.0.0     acct-output-octets = 23564 23564     bonus - group.awk for grouping all the records (too bad nawk doesn't have asorti):   begin {     fs = "="     cur_username = "" }  $1 ~ /user-name/ {     cur_username = $2     gsub(/^[ \t]+/, "", cur_username)     gsub(/[ \t]+$/, "", cur_username) }  $1 !~ /user-name/ {     if (nf != 2)         next      key = $1     gsub(/^[ \t]+/, "", key)     gsub(/[ \t]+$/, "", key)      value = $2     gsub(/^[ \t]+/, "", value)         gsub(/[ \t]+$/, "", value)      users[cur_username,key] = users[cur_username,key] " " value }  end {     n = asorti(users, sorted)     prev_username = ""     for (i=1; i&lt;=n; i++) {         username_key = sorted[i]         split(username_key, a, subsep)         username = a[1]         key = a[2]         value = users[sorted[i]]         if (username != prev_username) {             printf("user-name = %s\n", username)             prev_username = username         }         printf("\t%s =%s\n", key, value)     } }   test run:  $ gawk -f group.awk input  user-name = "mark"     acct-input-octets = 95684 95684     ... user-name = "mike"     acct-input-octets = 95684 95684     ...  
does not happen when doing an upgrade to freebsd 9.2
with regard to your first question:     xyz package installs some python scripts which on execution creates .pyc    file.now on uninstallation i want to remove all the files.what would be the    postrm script to cleanly remove package?   in general a suitable postrm script is (i believe) generated automatically by debhelper and friends
whether the use of dirname $0 is a problem or not would depend on how it is used
as bichoy indicated you can use the find command to find files with a specific access, create and modification time
neither, cat, tr or head adds a newline character (urandom could, but it's random so i wouldn't trust it)
make itself has likely not much to do with the problem
you can use fc-match to see which fonts match that pattern:  # fc-match "monospace" dejavusansmono.ttf: "dejavu sans mono" "book"   to see the whole priority list matching that pattern, use:  fc-match --sort "monospace"   reference: man fc-match     fc-match matches pattern (empty pattern by default)  using  the    normal          fontconfig matching rules to find the best font available
if you can modify the source code, then use rusage data to measure the rss and record how many tcp connections are in play at the time of the measurement
the two obvious candidates would be zfs and btrfs, but as far as i know, they don't do this
() runs commands in the subshell, so by exit you are exiting from subshell and returning to the parent shell
the traditional unix command at is usually used for this purpose
so, the --exclude-from file, will be:  var/tmp/ var/cache/   and use rsync like this:  rsync -aav --delete --stats --exclude-from /excludes /home /var /usr/local /etc /backup/  
other variant with awk  awk '     nr==1{         for(i=2;i&lt;=nf;i++){             count++             if($(i-1)!=$i || count&gt;4){                 d[i]=1                 count=0             }         }      }      {         for(i in d)             $i=" "$i             print      }      ' ofs="" data.file &gt;new.file   and sed  sed -re '     s/ +//g;s/^/\n/     ' -f &lt;(         sed -r '             s/(
grep would only find lines matching a pattern in a file, it wouldn't change the file
use devilspie2 to set the window type to "utility" for selective applications
according to the official docs it sounds like you just need to prefix your scripts like this:  #!/usr/bin/env ruby   and then do one of the following things to tell rbenv which version of ruby to use:  excerpt: https://github.com/sstephenson/rbenv     choosing the ruby version      when you execute a shim, rbenv determines which ruby version to use by reading it from the following sources, in this order:         the rbenv_version environment variable, if specified
by convention, the brackets indicate something that is optional
monodevelop 4.2.2 supports visual studio 2013 solutions normally, but you will need change toolsversion in your projects
there are few ways to settle this:   sed 's/\r\?$/ a/' file_list.txt    awk '{print $0"a"}' rs="\r*\n\r*" file_list.txt awk -f'\r' '{print $1"a"}' file_list.txt  ...   widely accepted at last:     tr -d '\r' &lt;file_list.txt | do_what_ever_want  
#!/bin/bash  turns=(r ri l li u ui d di f fi b bi r2 l2 u2 d2 f2 b2)  declare -a possible for i in ${turns[@]}; do         possible[$i]=$(printf "%s\n" "${turns[@]}" | grep -v ${i:0:1}) done  next=${turns[*]} for ((i=0; i&lt;$1; i++)); do         j=$(shuf -n 1 -e $next)         turnarray[$i]=$j         next=${possible[$j]} done  echo ${turnarray[*]}    precalculate next possible moves in an assoc array possible. use shuf to choose next move from arguments.  
you can modify your insert to something like,  insert into ip_mactable (ip_address, mac) values ('$ip','$mac')  on duplicate key update mac = values('$mac')  
set nm_controlled=no and stop the network manager daemon and prevent it from restarting during boots:  /sbin/service   networkmanager stop /sbin/chkconfig networkmanager off   now populate your /etc/resolv.conf file according to your needs.  otherwise, set nm_controlled=yes and leave the networkmanager daemon running
i use mutt to do that, like this
load is not equal to cpu usage
you didn't specify a shell
simply have the user run  newgrp wheel   this will start a new shell with the group id changed to that of wheel
in bash  dsn=5.7.1 $ grep $dsn /var/log/maillog | awk '{print $6}' | awk -f: '{print $1}'   returns:  p937blksdh3   of the line you posted,  i'm guessing that is the message id?  ok, it's not one line
try removing the single-quotes from the command3 creation line:  command3="tar -cvzf "$pimpurl"shisha_"$hour"_"$minute"_.data.tar.gz "$mailurl   when you execute that line by hand, the shell removes the quotes before tar ever sees the arguments.  you're not inserting spaces in the filename, therefore quotes are not necessary
original input file  assuming the following input format:  http://www.google.com,  www.google.com,  google.com  yahoo.com   with a result looking like this:  google.com : 3  yahoo.com : 1    it's hard to determine the entire situation you're in but given the output you're showing us i'd be inclined to convert the input file first so that all the lines are of the form:  google.com google.com google.com yahoo.com   and then run this file through the following set of commands:  $ grep -v "^$" data.txt | \       sed -e 's/,$//' -e 's/.*\.\(.*\)\.\(.*\)$/\1.\2/' | \       sort | uniq -c       3 google.com       1 yahoo.com   you can clean up the format of the output so it matches what you want like this:  $ grep -v "^$" data.txt | \       sed -e 's/,$//' -e 's/.*\.\(.*\)\.\(.*\)$/\1.\2/' | \       sort | uniq -c | \       awk '{printf "%s : %s\n", $1, $2}'       google.com : 3       yahoo.com : 1   edit #1  the op had a follow-up question where he changed the inputs in the example
you can filter out everything but directories using grep this way:  ls -l | grep '^d'   the ^ indicates that the pattern is at the beginning of the line
you'll find the full list of vimscript functions at :help functions; you can also directly go to the help of a particular function via :help submatch()
the error is typically caused by too many ssh/scp starting at the same time
the @reboot entry is started when cron is started, but that doesn't mean everything necessary to run your bundle application is up and running
      debian 3.2.60-1+deb7u3 x86_64 gnu/linux   867mbps 802.11ac intel 7260 card, dual band 5ghz + 2.4ghz wireless 2x2 ac + bluetooth4.0      your kernel is too old
try:  $ ssh lab_desktop -l 2200:lab_server:22 -vvv $ ssh -y &lt;username&gt;@localhost -p 2200  
i'm not sure the dpkg format, itself, can do what you require.  however you can make use of preinstall scripts
   1) do i just type cp .bash_profile .bash_profile.orig into the   terminal right after i open it?    yes
you can use env your-command to avoid interference from the shell.  example:  $ env kill -l  1 hup      2 int      3 quit     4 ill      5 trap     6 abrt     7 bus  8 fpe      9 kill    10 usr1    11 segv    12 usr2    13 pipe    14 alrm 15 term    16 stkflt  17 chld    18 cont    19 stop    20 tstp    21 ttin 22 ttou    23 urg     24 xcpu    25 xfsz    26 vtalrm  27 prof    28 winch 29 poll    30 pwr     31 sys        another way is to use the path of command as follows:  $ which kill /bin/kill     $ /bin/kill -l  1 hup      2 int      3 quit     4 ill      5 trap     6 abrt     7 bus  8 fpe      9 kill    10 usr1    11 segv    12 usr2    13 pipe    14 alrm 15 term    16 stkflt  17 chld    18 cont    19 stop    20 tstp    21 ttin 22 ttou    23 urg     24 xcpu    25 xfsz    26 vtalrm  27 prof    28 winch 29 poll    30 pwr     31 sys       so, by using env or specifying the path/location of command you can avoid interference from the shell. 
the address specified in -l is used by the remote host (b)
[edit: concluding thoughts regarding the processor choice]   amd vs amd:   richland does a much better job than trinity here. kaveri cannot compete with richland's idle mode power dissipation (at least for now). the gpu of the a10-6700 may be overrated, but it's a bit sad it won't be used much
run ls -l /path/to/mdrun_d and ls -lc /path/to/mdrun_d to see when the executable was last modified and when its inode was last changed
you can check whether the library is linked against pthread at least by using ldd
if you log in in text mode then start a gui session with xinit or with the wrapper script startx, then xinit does the following things:   start an x server (typically through the script /etc/x11/xinit/xserverrc). usually run some scripts in /etc/x11 (typically /etc/x11/xinit/xinitrc), depending on how it's set up. run ~/.xinitrc, if it exists
various internet control message protocol (icmp) packets may be "related" to some protocol's connection (or an attempt at such), but these icmp packets are different than the protocol that caused them, hence the "related" notion
the wording is obscure, but the advice is to modify the man.local file itself rather than override macros found in that file.  a good place to start is with the documentation: 5.21 writing macros (the gnu troff manual)
environment variables containing functions are a bash hack, i don't think zsh has anything similar
it's for tunneling software
the classic standard for this is from posix, utility argument syntax (thanks to @illuminÉ for the updated link)
lvm doesn't change the way you format a partition
there is a universal tool that can do defragmentation on linux called shake
probably a duplicate from dereferencing hard links  by default, a single copy of hardlinked data should be included in your archive. 
can you elaborate on what your end goal is? it seems like you have an odd need and an even more curious need of a "widescale solution." perhaps you're trying to streamline some mini-pc installation process?  can you chroot into your sdb os (maybe with qemu if a different architecture)? if so, that would be the best option
i think you can try using wget --no-clobber, but as mentioned above, you probably want to look into using a solution that is based on rsync rather than http
chhmcusr -i "name=foobaruser,description=proooba"   "proooba" is the new gecos field  "foobaruser" is the username 
no you're only able to do these types of inserts:  insert into table (artist, album, track, length)  values  ("$artist", "$album", "$track1", "$length1"),  ("$artist", "$album", "$track2", "$length2"), ("$artist", "$album", "$track3", "$length3"),  ("$artist", "$album", "$track4", "$length4"), ("$artist", "$album", "$track5", "$length5");   but you can always write a script that will generate the above using whatever regular expressions you desire
on the screenshot you provided, with the live cd selected, click the little cd icons on the right
i finally managed to figure out a work around
a simple loop will do the trick:    for((i=1;i&lt;32;i++));do cat chr$i.txt | sed 's/.\{5\}/&amp; /g' &gt; output$i.txt; done  
symbolic link files take more space
try this :  perl -0ne 'print $&amp; if /^host.*?identityfile\s+\k[^\n]+/ms' file  
generating a locale requires two files, a locale definition and a character map
ok, so this issue was caused by my use flags being too restrictive in make.conf: i had use="-jpeg -png".  once i removed the above use flags and rebuilt all packages which needed rebuilding with sudo emerge --update --newuse @world, my desktop background can back after logging out and back in again.  thanks to "iamben" in the #gentoo room on irc for nudging me in the right direction on this one! 
just redirect the grep's output to a file:  grep -a3406 -p 'molecular' *.log &gt; new_file   you can then process the new file and split it on the file name change (or just pipe the output to the splitting script)
thank you stephen ! so i did that:  i added this line to /etc/apt/sources.list: deb http://http.debian.net/debian/ jessie main contrib non-free  then, i ran this command: apt-get install firmware-b43-installer  just a reboot and it works ! 
du -s command should run under solaris as well as any decent unix compliant os
in the good old days, and 20 years on, you can use editres to view and even change the athena widget resources in a real xterm
the problem was rather simple, i needed to select analog stereo duplex to get the mic and speakers working for things like skype calls
*emphasized text*since all the child processes are still a part of the session id (sess in ps output) we could exploit that fact using this command:  $ parent=6187 $ ps -eo sess:1=,pid:1= |sed -n "s/^$parent //p"   this should return to us all the process ids of the child processes spawned from lb load
mbr is a partitioning scheme (a layout for how partitions appear on disk)
find can take -o for "or", so you can combine your two find commands like so:  find 
i am answering to my own question now because i finally found a workaround for this problem.  i found out that it is possible to reorder the devices by unloading the drivers and then loading them in correct order.  first method (bruteforce):  so the first method i came up with was simple to bruteforce the driver reload with init.d script.  following init script is tailored for debian 6.0 but the same principle should work on almost any distribution using proper init.d scripts.  #!/bin/sh -e  ### begin init info # provides:          reorder-nics # required-start: # required-stop: # default-start:     s # default-stop: # short-description: reloads the nics in correct order ### end init info  # # this script should reload the nic drivers in corrected order. # basically it just unloads and then loads the drivers in different order. #  echo "reloading nics!"  # unload the drivers modprobe -r driver_0        # eth0 nic interface modprobe -r driver_1        # eth1 nic interface  # load the drivers in corrected order modprobe driver_1 modprobe driver_0  #eof   then the script must be added to proper runlevel directory
so, it looks like you're not really asking a question around build frameworks, but rather a specific question about how to determine if a certain line exists in a text file?  if you want to find out if the string foo exists in a file, then:  if grep -q foo thefile; then    # it's there else    # otherwise fi   should do the trick. 
for a simple router, there are really only two steps that need to be done.  enable routing  the first step is to enable routing in the kernel
ah, it's not the systemd-logind feature where each user gets it's own cgroup
thanks to stéphane-chazelas, one possible answer is to add --bind-interfaces
it appears skype use socks or https proxies
you don't need to run wpa_cli , just configure your wpa_suppplicant.conf through wpa_passphrase then connect :  wpa_passphrase &lt;ssid&gt; &lt;passphrase&gt; &gt;&gt; /etc/wpa_supplicant/wpa_supplicant.conf   or:  sudo sh -c 'wpa_passphrase &lt;ssid&gt; &lt;passphrase&gt; &gt;&gt; /etc/wpa_supplicant/wpa_supplicant.conf'   then:  wpa_supplicant -b -i &lt;interface&gt; -c /etc/wpa_supplicant/wpa_supplicant.conf dhclient &lt;interface&gt;   alternative methode :  you can use nmtui the network manager text user interface ; run nmtui then configure your network .  also you can use wicd-curses , install it then run wicd-curses from the terminal , it's the easy way to configure/connect to your network from the terminal 
the pc bootup process is a fairly complicated affair.  first, the bios goes through several levels of self-tests to make sure its basic hardware and memory are in working order, and gives the user a chance to access its setup screen (and possibly other options such as boot sequence, but those aren't standardized.  second, it checks its configured boot sequence for the first device to try booting from
obviously, if you know how to run any command as root, you can run an editor
you don't need to, but you should
the standard way to do this with most shells (and therefore most portable) is with backquote (`) and since the arg you have to ssh does not need quoting, but the result probably would you'd write:  uptime="&#96;ssh $linux_server cat /proc/uptime&#96;"  or you can be specific to bash (and a few other shells, but not as universal as backquote) by using the $() as:  uptime="$(ssh $linux_server cat /proc/uptime$)"  note that since backquotes use the same thing to delimit the command, they cannot be nested
have you tried installing the required version with gem?  $ gem install rake --version 0.9.2.2  
well i've found templorary workaround
from https://answers.launchpad.net/ubuntu/+source/pitivi/+question/132343:     simple! select your clip, click the ungroup button in the timeline toolbar, select the video (not the audio), and delete it (or move it).     just select the audio instead of the video.  tested in pitivi 0.96 
from the lspci output i can only see one intel graphics card, make sure there is a amd card and that it is enabled in bios
ubuntu no longer uses the /var/log/messages file by default
the liberation font doesn't seem to have this symbol
you can use a two-step procedure then - first, use the clonehd command to create a vdi image:  vboxmanage clonehd aaaa.vmdk --format vdi aaaa.vdi   (have a look also at other options to clonehd, like --variant
try vim-slime, an environment inspired by emacs's slime mode
the short answer is: a process can only be brought to the foreground in the terminal it was started in
try:  sort -t "|"  -k 2   by leaving out the -n, you sort on the whole string between '|' characters not just the first number that can be made out of that string (2013). 
you running chrome by any chance on the computer with the ip 192.168.1.105? it would appear that chrome attempts to do a prefetch using icmp to opendns.  http://productforums.google.com/forum/#!topic/chrome/spzcfoxr7m4     please see the help reference
try using sort with the -o/--output=file option instead of redirecting the output
interestingly enough, my vsftpd writes the versino string to stdin
update  the permission error (below) boiled down to removing the '-a' (--archive) flag from the rsync command, to prevent it from trying to preserve ownership and permissions on the files copied.  after doing the local 'dd' test, a low-level io error was detected, probably caused by a faulty disk, resulting in a filesystem corruption
i can comment on gnome's "application is not responding" dialog, but not directly answer your question.  it seems that both metacity and mutter use meta_display_ping_window() function to determine the status of a window (read the doc comment in display.c)
here's what happens:   find finds the matching directory ./test 02. find executes the rename command on that directory. rename renames test 02 to test_02. find tries to descend into the directory test 02
there is the grsecurity patchset (included in selinux, but doesn't have the latter's horribly complicated mac permission system) for the linux kernel which offers the option of allowing only the owner (and root) to see his/her processes
i read through the kernel sources, especially drivers/base/firmware_class.c, and discovered that   config_fw_loader_user_helper    would activate the udev firmware loading variant (obviously only usable for loadable modules when udev is running)
include the key in your regexp.  if you know exactly how it is written, then you can use a positive lookbehind assertion and it's easier:  perl -pi -e 's/(?&lt;=^\$vip_ip=).*/192.17.200.100/' your_file   otherwise, you must include the matched key in the replacement text using $1:  perl -pi -e 's/(^\$vip_ip\s*=).*/$1192.17.200.100/' your_file  
you can set variables in awk from the shell like so:  $ somevar=4 $ echo | awk -v my_var="$somevar" '{print "my var is " my_var}' my var is 4   references   can we use shell variables in awk?  
i found the source of the problem
read-only is just that - reading from the disk
first of all, here's how:     first do almost as you did before, but no subtraction - and add one to the count.  dd  count=132552704 &lt;/dev/sda &gt;img  next print the partition table at a sed process which can screen out the ones which you're removing.   sed will write a delete command to a second fdisk which has opened your img file for every partition from sda4 and on.  fdisk -l img | sed -e'/sda4 /,$id' -e'g;$aw' | fdisk img   there is no 3
there is an official package now for this task called app-portage/portpeek
the only thing i can think of is v to reverse selection (when nothing is selected this acts as select all), then a to add all selected items to playlist (select current playlist from the menu that pops up). 
no, for one thing it will break on filenames containing newlines
from the man page:   caveats   when writing compressed data to a tape, it is generally  necessary to pad the output with zeroes up to a block  boundary
relatively recent dmesg versions provide a follow option (-w, --follow) which works analogously to tail -f.  thus, just use following command:  $ dmesg -wh   (-h, --human enables user-friendly features like colors, relative time)  those options are available for example in fedora 19. 
you can use tee
there isn't a standard offset per-se, as of course you can start the partition wherever you want
i'd recommend you install procmail or some other mail processor
try set assume_always_yes variable to yes.  set assume_always_yes = yes pkg bootstrap   this information written by pkg when invoke yes | pkg bootstrap -f:     please set assume_always_yes=yes environment variable to be able to   bootstrap in non-interactive (stdin not being a tty)  
you can use date to print date timestamp and store it with log message.  $ tz='europe/warsaw' date wto, 23 kwi 2013, 17:11:48 cest $ tz='america/los_angeles' date wto, 23 kwi 2013, 08:11:56 pdt $ date --universal wto, 23 kwi 2013, 15:13:14 utc   use tzselect to find time zones. 
from http://www.supergrubdisk.org/wiki/sgd_bootscript_usb_boot_from_cdrom  title try usb hd0 boot rootnoverify (hd0) chainloader +1 boot   and  title try usb hd1 boot map (hd0) (hd1) map (hd1) (hd0) liveswap rootnoverify (hd0) chainloader +1 boot   i only know that it is possible
sudo -u &lt;username&gt; &lt;command&gt; 
the fix for that is to fix your application.  nohup doesn't send anything to anyone
i wouldn't try it on a cd (although it might well be that my old buffering fears are outdated), but it works fine on a usb key; for example:  curl -l http://cdimage.debian.org/debian-cd/8.6.0/amd64/iso-cd/debian-8.6.0-amd64-netinst.iso | sudo dd of=/dev/sdf   downloads the current debian network installer and writes it to the sdf key.  this works because dd reads by default from its standard input, if no if parameter is given
the default recursion depth limit in wget is 5
the structure of a process in linux is defined by the task_struct structure  there are many fields in that structure
download all these packages (i took the centos 6.6 versions from rpmfind.net)   nss-3.16.1-14.el6.x86_64.rpm nss-util-3.16.1-3.el6.x86_64.rpm nss-softokn-3.14.3-17.el6.x86_64.rpm nss-softokn-freebl-3.14.3-17.el6.x86_64.rpm nss-tools-3.16.1-14.el6.x86_64.rpm nss-sysinit-3.16.1-14.el6.x86_64.rpm   and install them all in one go with rpm -uvh nss-*.rpm.  that satisfies the dependencies of p11-kit-trust that yum couldn't figure out how to resolve on its own.  after that, yum update can update ca-certificates and install p11-kit-trust (for dependencies). 
sed would work:  sed \     -e 's/base\/1/base\/6/' \     -e 's/base\/2/base\/7/' \     -e 's/base\/3/base\/8/' \     -e 's/base\/4/base\/9/' \     -e 's/base\/5/base\/10/' \     -e 's/base\/0/base\/5/'   i think you have to put the "base/0" case last, otherwise, the 5 -> 10 case kicks in as well. 
refresh on windows does a bunch of different things depending on the application
the chsh command only lets you change your login shell from a shell that's listed in /etc/shells, to a shell that's listed in /etc/shells
you should use a function instead an alias, becaue aliases don't support parameters, make something like that:  killport(){   sudo kill -9 $(sudo fuser -n tcp $1 2&gt; /dev/null);  }   now put this function in your bash configuration file, eg ~/.bashrc and then run:  source  ~/.bashrc   and you're done  hth 
as far as i know, iftop can not show which processes are using the bandwidth
gnu grep's -w will only consider the 26+26+10+1 (ascii letters, digits and underscore) as word constituents
next time, try a magical thing called search engine before asking.  see here:   http://www.howtogeek.com/howto/linux/security-tip-disable-root-ssh-login-on-linux/ 
you could try sudo find / -name "studio.*".  the way this command works is simple:   sudo runs the find command as superuser (supersuser do) so you can check all the directories in the file system including the locked ones. find searches a given location (/ in our case) for a given file or directory. / is the parameter that dictates find where to search (in the whole file system). studio.* is what to search for ..
you probably can't do that.  emacs is a lisp interpreter that runs an editor (which is written in emacs lisp), so every time you use emacs, you have access to the the lisp interpreter itself.  that interpreter can do all kinds of things: create/remove files or directories, change access rights etc..
just do it in the awk, forget xargs.  awk '{total += $2} end {print total}'   but you need tto run awk only once, with all of the loop's output piped into it
i wouldn't have known the answer except google was there for me:  from here (needs free subscription):     linux is following the tradition set by unix of counting time in   seconds since its official "birthday," -- called "epoch" in computing   terms -- which is jan
ext2 and family (including ext4) reserve an attribute for compression but don't implement it
you are correctly using the skype aur package
maybe:  tail -n +1 -f file | awk '{printf "\r%lu", nr}'   beware that it would output a number for every line of input (though overriding the previous value if sent to a  terminal).  or you can implement the tail -f by hand in shell:  n=0 while :; do    n=$(($n + $(wc -l)))   printf '\r%s' "$n"   sleep 1 done &lt; file   (note that it runs up to one wc and one sleep command per second which not all shells have built in
the top command lists the priority of running processes under the pr heading
check the output from the fc-list command (in a terminal window):  /usr/share/fonts/ttf/liberationmono-italic.ttf: liberation mono:style=italic /usr/share/fonts/ttf/veramono.ttf: bitstream vera sans mono:style=roman /usr/share/fonts/ttf/dejavusansmono-oblique.ttf: dejavu sans mono:style=oblique /usr/share/fonts/otf/linlibertine_m.otf: linux libertine mono o:style=mono  /usr/share/fonts/otf/linlibertine_m.otf: linux libertine mono o:style=mono   for example:   /usr/share/fonts/otf/linlibertine_m.otf       file name :                                             separator linux libertine mono o                        font name (note, remove the initial space) :                                             separator style=oblique                                 the font 'style'   font style is normally one of regular (or normal), italic (or oblique), monospace (or mono), book, and combinations of these are valid.  the middle value ('font name') is normally the name you'd want to use
assuming this isn't a typo, the install section in your typo service file contains a typo
i assume you wish to run a specific executable with the old library
nail was renamed to heirloom mailx
maybe with :  zypper what-provides libqtnmedia.so.2  
i don't know offhand the exact format you're trying to parse
this time the problem was basically in front of the monitor, but nevertheless i found an option to be set:  apt-get -o acquire::compressiontypes::order::=gz update   adding --print-uris shows that apt-get is now trying to fetch gz instead of bz2.  however, as initially stated, that was not the main problem, because the command still fails, not being able to retrieve the gz file which is definitely available. usually apt-get searches for several types and should be able to fetch the gzipped version if only that is available.  the problem here was that pow was installed on the mac. the network connection to the pi made pings to the outside world possible and any wget downloaded a page -- but not the real one but the pow page from the mac
input files:   yahoo.net.txt gougle.com.txt reddit.com.txt   contents of yahoo.net.txt:  user1-yaho0 pas,,   contents of gougle.com.txt:  user1-google pas"wor,d   contents of reddit.com.txt:  user1-reddit pas\wor\d   with this input, the following quick and dirty script does the job:  #!/bin/bash  echo "\"account\",\"login name\",\"password\",\"web site\",\"notes\"" &gt; output.csv num=0 for f in `find 
you can do that by using lsof to check which tcp ports are in state listen and used by sshd:  [jenny@willow ~]$ sudo lsof -itcp -stcp:listen | grep sshd sshd       1084     root    3u  ipv6 0xffffff0003fed888      0t0  tcp *:ssh (listen) sshd       1084     root    4u  ipv4 0xffffff0003fed5b0      0t0  tcp *:ssh (listen) sshd      47607    jenny    7u  ipv6 0xffffff00510a0888      0t0  tcp localhost:12345 (listen) sshd      47607    jenny    8u  ipv4 0xffffff00410062d8      0t0  tcp localhost:12345 (listen)   the top two are the ssh daemon, the two below are a tcp tunnel
there are two ways to interpret the question: you want the completion while you are typing the names before the closing } (in effect performing completion of files in another directory); or, you want the completion to expand and substitute the (valid) names after the closing }
you probably wanted to use random % 90 rather then &amp;
given the 755 permissions, make sure that the appropriate users own their respective writespaces! 
check this :  auto-apt run ./configure  
according to man journalctl journalctl reads in journal files as created by systemd-journalctl.service.  according to man systemd-journalctl.service the config file is located at /etc/systemd/journald.conf and it places journal files at /var/log/journal/[machine-id]/*.journal if it exists, otherwise it places them in /run/log/journal/[machine-id]/*.journal.  those seem like the relevant files to you
lightdm is an x display manager that aims to be lightweight, fast, extensible and multi-desktop
the sshfs filesystem is built on top of the sftp protocol
you will need bos.net.ipsec.rte to be able to use an iptables like solution.  check your current installation with:  michael@x071:[/home/michael]lslpp -l bos.net.ipsec.rte   fileset                      level  state  type  description (uninstaller)   ----------------------------------------------------------------------------   bos.net.ipsec.rte         6.1.9.45    c     f    ip security   if it is already installed, you can check if it is active, or inactive using:  active:  michael@x071:[/home/michael]lsdev -c | grep ipsec ipsec_v4    available       ip version 4 security extension ipsec_v6    available       ip version 6 security extension   inactive:  root@x064:[/]lsdev -c | grep ipsec   that is no output, meaning it has never been activated, or  root@x072:[/]lsdev -c | grep ipsec ipsec_v4   defined         ip version 4 security extension ipsec_v6   defined         ip version 6 security extension   some output meaning there maybe some configuration, but it has been deactivated.  here are some examples of how you can switch on/off ipsec for v4 and-or v6 ipsec.  root@x072:[/]lsdev -c | grep ipsec ipsec_v4   defined         ip version 4 security extension ipsec_v6   available       ip version 6 security extension root@x072:[/]mkdev -l ipsec_v4 ipsec_v4 available root@x072:[/]rmdev -l ipsec_v6 ipsec_v6 defined root@x072:[/]lsdev -c | grep ipsec ipsec_v4   available       ip version 4 security extension ipsec_v6   defined         ip version 6 security extension   now to stopping nfs per client (defined as an ip address)  let's take the ip address 192.168.111.222 as the address of the client i want to stop. there are different actions that can be taken - permit and deny are the common ones - we can be a bit fancy though and use block-port that creates a new dynamic deny rule each time a port tries to connect - this way you can see how active the unique mount requests are:  we need to focus on port 2049  root@x072:[/]grep nfs /etc/services nfsd-status      1110/tcp               # cluster status info nfsd-keepalive  1110/udp                # client status info picknfs          1598/tcp               # picknfs picknfs          1598/udp               # picknfs shiva_confsrvr  1651/tcp                # shiva_confsrvr shiva_confsrvr  1651/udp                # shiva_confsrvr #nfs                    2049/tcp                # network file system - sun microsystems #nfs                    2049/udp                # network file system - sun microsystems 3d-nfsd          2323/tcp               # 3d-nfsd 3d-nfsd          2323/udp               # 3d-nfsd mediacntrlnfsd  2363/tcp                # media central nfsd  mediacntrlnfsd  2363/udp                # media central nfsd    note: to use smit(ty) use:  smitty ipsec4   and then use advanced...->add                           add an ip security filter rule  type or select values in entry fields. press enter after making all desired changes.                                                          [entry fields] * rule action                                        [shun_port]             + * ip source address                                  [192.168.111.222] * ip source mask                                     [255.255.255.255]   ip destination address                             [0.0.0.0]   ip destination mask                                [0.0.0.0] * apply to source routing? (permit/inbound only)     [yes]                   + * protocol                                           [tcp]                   + * source port / icmp type operation                  [any]                   + * source port number / icmp type                     [0]                      # * destination port / icmp code operation             [eq]                    + * destination port number / icmp type                [2049]                   # * routing                                            [local]                 + * direction                                          [inbound]               + * log control                                        [no]                    + * fragmentation control                              [0]                     + * interface                                          [all]                   +   expiration time  (sec)                             [300]                    #   pattern type                                       [none]                  +   pattern / pattern file                             []   description                                        &lt;g port on nfs request]   or from the command line:  /usr/sbin/genfilt -v 4  -a 's' -s '192.168.111.222' -m '255.255.255.255' -d '0.0.0.0' -m '0.0.0.0' -g 'y' -c 'tcp' -o 'any' -p '0' -o 'eq' -p '2049' -r 'l' -w 'i' -l 'n' -t '0' -i 'all' -e '300' -d 'block incoming port on nfs request'   and either in smit, or from the command line - activate the rule  mkfilt -v4 -u   and to see the configured rules  lsfilt -v4 -o   and to see any (maybe) dynamic rules  lsfilt -v4 -a -o   ** comment i cannot yet add: in case you need a change right now - as this only affects future connections to the port you can use the commands:  nfs.clean; sleep 2; rc.nfs   to stop, then restart nfs services
the uniutils package has the program uniname
as you can see in /etc/issue, you're using centos 5.3
alternatives  alternatives is a tool that will manage the locations of the installed software using links under the control of the alternatives tool
technical  yes, you can absolutely copy a luks header from one disk to another
copy the file to the same dir as pkgbuild and then add its filename to the source array.  otherwise i'd suggest you just look at the build procedure in the pkgbuild file and then build it manually
get a suitable ubuntu install cd with the packages you need to install the desktop environment (e.g
here a shorty with strong xz compression  cd /ur/directory/where/the/content/is backupfile="`date +"%y-%m-%d`"; targetdir="/where/u/want" [ ! -f "$targetdir/$backupfile".tar.xz ] &amp;&amp; tar -xjvf "$targetdir/$backupfile".tar.xz *  
the guest has no direct access to the host clock
method 1#  find networkmanager configuration file and add/modify following entry in centos5 it is in /etc/networkmanager/nm-system-settings.conf or /etc/networkmanager/system-connections/ and edit your dsl connection file :  [ipv4] method=auto dns=8.8.8.8;4.2.2.2; ignore-auto-dns=true   note:- if [ipv4] not work then try with [ppp]  method 2#  you can change permission of /etc/resolve.conf so that it can't be write by other services or you can use chattr  method 3#  create a script as mention below in /etc/networkmanager/dispatcher.d/ and don't forget to make it executable:  #!/bin/bash # # override /etc/resolv.conf and tell # networkmanagerdispatcher to go pluck itself. # # scripts in the /etc/networkmanager/dispatcher.d/ directory # are called alphabetically and are passed two parameters: # $1 is the interface name, and $2 is "up" or "down" as the # case may be.  # here, no matter what interface or state, override the # created resolver config with my config.  cp -f /etc/resolv.conf.mydnsoverride /etc/resolv.conf   entry of /etc/resolv.conf.mydnsoverride  nameserver 8.8.8.8  
it seems these "morphology"s are were made having a black background as a basis
i found makefile2graph, i don't test it, from the same author there is a a similar tool makegraphdependencies written in java instead of c. 
it looks like a restart did it. 
by commonly used rules of specifying command-line parameters, a dash in front of an argument makes it interpreted as a short option.  more precisely, -.mount is interpreted as 6 consecutive options, equivalent to: -
yes:  awk '$1 &lt; prev { print prev } { prev = $1 }'   this prints prev for every line where the first field is less than the value stored in prev (which is 0 initially), and stores the first field in prev in all cases. 
you can use the -f, --force option of ln to have it remove the existing symlink before creating the new one
with gnu sed:  sed -e 's/[[:alpha:]]+/\u&amp;/3'   would capitalise the third sequence of letters from each line.  to capitalise every third sequence of letters in each line:  sed -e 's/(([[:alpha:]]+[^[:alpha:]]+){2})([[:alpha:]]+)/\1\u\3/g'   to capitalise every third sequence of letters in the whole input, with gnu awk:  awk -v rs='[^[:alpha:]]+' -v ors= '    nr % 3 == 0 {$0=toupper(substr($0,1,1)) substr($0,2)}    {print $0 rt}'   or with perl:  perl -mopen=locale -pe 's/\p{alpha}+/++$n % 3 == 0 ? "\u$&amp;" : "$&amp;"/ge'   while the [[:alpha:]] character class can be a bit random on some systems (for instance on gnu systems, that includes many numerals with the exclusion of the arabic ones (0123456789)), perl's \p{...} is based on unicode character properties
you can structure this as an if/else chain
you could issue these commands (they're in ex mode):  :.,$d :w! stuff2.txt   the problem now is that vi has an internal representation of stuff.txt that is the same as the file stuff2.txt
a default install of apache will serve all urls pointing to it if no virtual hosts have been defined
help('topics') shows the table of contents of a shorter version of python's reference manual
there's nothing special about the /mnt directory
the reason it didn't work with $java_home is that $java_home isn't the same thing as $java_home/bin
ctrl+z is actually a feature of the generic terminal interface in the kernel, not of bash
(extracted answer from edit)  i got the result of the search by letting it run overnight
gentoo is a linux distribution that compiles packages from sources
you can use nfsv3 to map on user and group ids
from wikipedia:     as of version 13, linux mint gives users the choice between cinnamon and mate, as their default desktop environment in the main release edition, with ubuntu as its base
not sure if this would work well for your 400mb file, but here are some cli one liners that would do the trick.  if you're looking for entries for a specific date, grep -c can probably do what you need.  otherwise, you could probably use sed:  sed -n '/date1/,/date2/p' filename   for example with an input file "test":  day 0: foo day 1: hello day 2: world day 3: blah   you could run  [me@mybox tmp]$ sed -n '/day 1/,/day 2/p' test day 1: hello day 2: world  
click on it, it will start downloading in browser
background on kvm  i think this is partly due to expectations with kvm
ttys are files that you can use just like any other
exit or sending end-of-file (^d) should terminate the shell. 
the match operator can take multiple arguments, allowing very flexible rules
i found a solution, combining two sources and a bit of my knowledge, here is a what you have to do, to get remix os running using fedora 24, from your local ext4 volume, without any legacy bios requirement, using uefi and gpt partitions only.   create ext4 partiton on your hard drive (using gparted), you will install remix os on it later use rufus (using wine or windows) to repartition your flash drive as gpt with uefi support, and create a bootable iso on it (using rufus as well) boot from your flash drive on your laptop (be sure to disable secure boot) press 'e' key in grub that loaded from your flash drivereplace the src= data= create_data_img=1 part with install=1 debug= like this, but do not touch anything else
you can look at the return code from the ssh command
you're looking for apropos; on my system apropos luks points me to cryptsetup(8), luksformat(8) and a number of other relevant manpages.  apropos, which is equivalent to man -k, looks in the installed manpages' names and descriptions for the search text given on its command line
i found the solution:   process p = rt.exec(new string[]{"/bin/sh", "-c", "sqlite3 /home/ubuntu/testingdb.sqlite .dump &gt; /home/ubuntu/success11.sql"});   it gives full dump file of sqlite database.. 
you already have a pure regex answer but here's a more grepish one:  grep -i ^occ file   the -i flag tells grep to do case insensitive matching
you can use awk to add it all up.  awk '{ arr[$2] += $1} end {for (key in arr) {printf "%4s %s\n", arr[key], key}}' file1 file2   explanation   { arr[$2] += $1} set array index of our string aka $2 to += the number $1 end when we're done {for (key in arr) {printf "%4s %s\n", arr[key], key}} loop through it all and print it out.   what i did to test it  file1    7 umslipped   1 umslippersmouthwashand   3 umslobagas  35 umslopogaas   5 (umslopogaas  15 (umslopogaas)   1 umslower   6 umsmall   2 umsnag   2 um[snaps  13 umsnootchie   2 umsnow  84 umso  14 um-so ##   file2   14 um-so ##  84 umso   2 umsnow  13 umsnootchie   2 um[snaps   2 umsnag   6 umsmall   1 umslower  15 (umslopogaas)   5 (umslopogaas  35 umslopogaas   3 umslobagas   1 umslippersmouthwashand   7 umslipped   output    10 (umslopogaas   12 umsmall    6 umslobagas   28 um-so    2 umslippersmouthwashand   30 (umslopogaas)   70 umslopogaas   26 umsnootchie    4 umsnag  168 umso    4 um[snaps   14 umslipped    4 umsnow    2 umslower  
systemd has something called 'targets' which can be thought of as the runlevels of init. prefdm.service will be run with the "default.target" which is set by default to "graphical.target".  so, by setting the default target to "multi-user.target" (aka
source it into current shell session. 
you can bind the completion command to any key sequence
i would use:  netstat -punta | grep &lt;src port&gt;   it will give you pids and binary name for each 
selecting text should put that text in your primary selection buffer; this means you may be able to middle-click to paste it into another window. 
if security is your concern, keep in mind that httpd in openbsd is chrooted by default, which means that in case of a potential compromise of your web server, the attacker will stay in the chroot jail of your webserver, isolated from the rest of your system, therefore minimizing the effects of the breach.  as far as mount options go, you could mount the partitions where binaries are not expected to be executed as noexec (for example, user /home directories)
the argument of --exclude-dir is a pattern that is matched against a directory's base name, i.e
there is jabber telnet bot that is bot that provides jabber to telnet gateway
in the end i restarted the system prior to checking xkill
what you actually want to do is clone the repository
install curlftpfs  opkg update; opkg install curlftpfs   then create a script that will run after every boot of the router  vi /etc/rc.d/s99tcpdump   the content of s99tcpdump  #!/bin/ash  mkdir -p /dev/shm/something curlftpfs ftpusernamehere:ftppasswordhere4@example.com /dev/shm/something/ tcpdump -i wlan0 -s 0 dst 192.168.1.200 or src 192.168.1.200 -w "/dev/shm/something/tcpdump-`date +%f-%hh-%mm-%ss`.pcap" &amp;   make it executable  chmod +x /etc/rc.d/s99tcpdump   reboot router, enjoy.  p.s.: looks like "-s 0" is needed because there could be messages like: "packet size limited when capturing, etc." - when loading the .pcap files in wireshark  p.s.2: make sure the time is correct because if not, the output filename could be wrong.. 
after printing out the plugin path from the source i found out that pluma looks for plugins in ~/.local/share/pluma/plugins
the best kind of approach here is to do something like:  mysqldump --defaults-extra-file=/path/to/auth.cnf ...   where auth.cnf looks like:  [client] user=the-user password=the-password   then make sure the file is only readable by whomever is meant to run that script
here's a small script that checks for the battery level and calls a custom command, here pm-hibernate, in case the battery level is below a certain threshold.  #!/bin/sh  ########################################################################### # # usage: system-low-battery # # checks if the battery level is low
you could add this function to your .bashrc or other startup file (depending on your shell)
the issue that /dev/md0 doesn't have a partition table is not relevent to your problem
gcc  on gcc (man gcc) the checks are enabled by     -fstack-protector       emit extra code to check for buffer overflows, such as stack smashing attacks
the card is now useless, hope that you don't have any important data on it
it looks like you screwed up the path setting (used to locate programs)
ruby works well for this:  ruby -e '   argv.each do |filename|     data = file.read(filename).strip.split(",")     groups = data.group_by {|n| n}     groups.each_pair do |n, nums|       # you don't really say what your input filenames look like       # i will assume they end with ".txt"       f = filename.sub(/\.txt$/, "#{n}.txt")       file.write(f, nums.join(" ") + "\n"}     end   end ' filea.txt fileb.txt ...  
in simple terms, you can think of make as having a (possibly large) number of steps, where each step takes a number of files as input and creates one file as output.  a step might be "compile file.c to file.o" or "use ld to link main.o and file.o into program"
simplified approach with awk  awk '/r1/ {print "=&gt;" $0;next} /r2/{print "*" $0;next} 1' text.file  [jaypal:~/temp] cat text.file  r1 12 324 3453 36 457 4 7 8 r2 34 2342 2525 25 25 26 26 2 2 r3 23 2342 32 52 54 543 643 63 r4 25 234 2342 4 234242  [jaypal:~/temp] awk '/r1/ { print "=&gt;" $0;next} /r2/{print "*" $0;next}1' text.file =&gt;r1 12 324 3453 36 457 4 7 8 *r2 34 2342 2525 25 25 26 26 2 2 r3 23 2342 32 52 54 543 643 63 r4 25 234 2342 4 234242 [jaypal:~/temp]    breakout of pattern {action} statements:   /r1/ { print "=&gt;" $0;next} : this means lines having /r1/ the action of printing =&gt; will be done
to see the current speed of each core i do this:  watch -n.1 "cat /proc/cpuinfo | grep \"^[c]pu mhz\""   this displays the cpu speed of each core in real time.  by running the following command, one or more times, from another terminal one can see the speed change with the above watch command, assuming speedstep is enabled (cool'n'quiet for amd).  echo "scale=10000; 4*a(1)" | bc -l &amp;   (this command uses bc to calculate pi to 10000 places.) 
missing loop conditional  your syntax is invalid
it's a patch that undoes the earlier patch
ignoring directory patterns is fairly painless
actually only nm_controlled="no" (or is it "false" ?) does anything.  putting "yes" (or is it "true" ?) is the same as not having the line at all: for network devices supported by networkmanager it will manage them; for those unknown to networkmanager it will ignore them anyway. 
put it in quotes like  grep '&amp;amount' file   so the &amp; isn't interpreted by the shell to put the grep in the background and then try to run the command amount  or alternately, you could escape it so it won't have the special meaning to the shell:  grep \&amp;amount file  
 please don't set the security level to medium!  this is a battle i've been fighting; there's no need to do this
the obvious is:  parallel -j 2 do_copyinprimary ::: "${primary_partition[@]}" &amp; parallel -j 2 do_copyinsecondary ::: "${secondary_partition[@]}" &amp; wait   but this way the secondary does not wait for the primary to finish and it does not check if the primary was successful
i don't see any advantage to hard links.     with hardlinks, you can move the original file (rename it) as needed without needing to recreate the link.   that strikes me as a bug rather than a feature
by mac i assume you're asking about modify, access, and change timestamps
the hash is a separator between the ip of the server that replied to your request, and the port it's service was running on.  you got your reply from the server 161.43.32.162 and it's dns service was running on port 53
that's usually done with makefile rules, e.g., given test.c, you would be able to do this (even without having a makefile):  make test   likewise, there are predefined rules for g++, given test2.cc, you could do the same thing:  make test2   but in either case, you probably need libraries
enable the mod_mono control panel.  in httpd.conf, add  &lt;location /mono&gt;   sethandler mono-ctrl   order deny,allow   deny from all   allow from 127.0.0.1 &lt;/location&gt;   you will need to modify the addresses that can access it in the allow from line.  reload httpd and now you can go to http://some.website.domain/mono
if you're running 32-bit windows 7 on a 64-bit processor, then virtualbox can run a 64-bit guest with a few caveats:     3.1.2
this how you can install java manually: download java  step 1: download java for your system (i.e for 32 bit or 64 bit machine)  step 2: open terminal and go to path where java is downloaded
try  awk -f: '$3 &gt;= 1000 &amp;&amp; $3 != 65534 { printf "%s -- %s\n",$1,$5;}' /etc/passwd   you can also use print  print $1 " -- " $5  
here's a way
output from  "man 1 passwd":  --stdin       this option is used to indicate that passwd should read the new       password from standard input, which can be a pipe.   so to answer your question, use the following script:  echo -n "enter the username: " read uname  echo -n "enter the password: " read -s passwd  adduser "$uname" echo "$password" | passwd "$uname" --stdin   i used read -s for the password, so it won't be displayed while typing.  edit: for debian users -stdin won't work
if you are operating at the x level (as in gilles' question), then use xdotool like so:  xdotool key keystroke_specifier   where keystroke_specifier can be something like "a" or "f2" or "control+j"  edit: i missed your response to gilles' question, sorry
it depends a lot on the directory and distro in question
you can just use % for current file
you have two issue there, first are spaces which are left in your variables when you perform the read with ifs='='
(by the way, i've never seen the spelling "getty"
naming convention:   grub (some of it) stays in the mbr. grub (rest of it) are several files that are loaded, from /boot/grub (for example: that nice image that appears as a background in grub is not stored on the mbr)   notes:   the answer is considering an mbr setup, grub can be used in other setups. in an efi setup things get hairy, grub can be used, but so can be the kernel itself as its own efi stub.     grub (some of it) is installed in the mbr
the redirects are processed from left to right
using the -column or --columns=column option of pr  -column, --columns=column        output column columns and print columns down, unless -a is used.        balance number of lines in the columns on each page   so either  pr -t -2 yourfile   or  pr -t --columns=2 yourfile    for example, augmenting your entries with some random dictionary words,  $ cat &lt;&lt; eof | pr -t -2 &gt; apple &gt; banana &gt; `shuf -n28 /usr/share/dict/words` &gt; grape &gt; guava &gt; eof apple                               overachieves banana                              wickerwork cottonmouths                        supersonic adapter's                           draftiest boudoir's                           insisting cruised                             programs mousetrap                           parcel shticks                             basically tlc's                               coruscates conduction                          jones geeing                              ty gloamings                           bondage investing                           candelabra's radiotherapists                     inchon's clasp's                             grape critters                            guava  
execute the following command in the terminal:     pcmanfm --desktop-pref   that gets the desktop preferences window opened
   i have a dir in /home called backups so i am looking to omit that directory from the backup using say -x /home/backups
the solution was:  i installed all these 32 bits packages:  yum -y install glibc.i686  libstdc++.i686 libxrender-0.9.8-2.1.el7.i686 alsa-lib-1.0.27.2-3.el7.i686 dbus-glib-0.100-7.el7.i686 gtk2.i686 libxt-1.1.4-6.1.el7.i686   i changed the gtk2-2.24.22-5.el7.i686 package to the gtk2.i686 to do not get this error of conflicting lib's.  the answer of christian bock: i think it could resolve too that issue of installing thunderbird 31.4 on centos7, but only these packages here are required to run the thunderbird.  the comment of christian bock; also helps to resolve these issue, by seeing what package provides the library:  yum whatprovides libraryname   
remove the allow-hotplug eth0 in your config then,  thus it would wait for network config to be completed. 
to disable the first hda device, add the line  options snd-hda-intel enable=0,1   to some .conf file in /etc/modprobe.d/. then reload the driver, or reboot. 
the output mentions it dumped core
do the build, then list the .o files
i find something here about the ctrl on virtualbox guest: https://www.virtualbox.org/ticket/122  it seems a problem on gnome desktop environment with virtualbox.  on fedora23-workstation (gnome3), i set caps lock as additional ctrl in gnome-tweak-tool
you could check if the usb is mounted before sleeping
any user, including root, can forward their local email by putting the forwarding address in a file called ~/.forward
with no centralized user administration, the "best" way i see is for you to force all servers to use the same gid and uid for each user. now ..
assuming that you mean you don't want to match \r, you could just specify that you're after a tab or a space and nothing else:  grep -p '[\t ]$' file    since you're on osx, your grep won't have -p, so you could instead try:  grep -e $'\t'"| $" file    alternatively, you can use the posix character class:  grep  '[[:blank:]]$' file   as explained in man wctype, the [[:blank:]] character class "realizes the isblank(3) classification function" and, as explained in man isblank, that is:     isblank()       checks for a blank character; that is, a space or a tab.   finally, you could also use another tool instead:      sed -n '/[\t ]$/p' file      perl -ne 'print if /[\t ]$/' file   
an image is a raw (literal, byte for byte) copy of a filesystem
use the -prune option to skip that directory  find ~/.jenkins/jobs/subco -path ~/.jenkins/jobs/subco/myapp -prune -o -name '*.jar' -exec rm -r {} +  
because when you use just *net* (without any quoting or escaping), it will be expanded by the shell as the (existing) net file/directory in the current directory before the find command run
you could (perhaps) use:  du --max-depth=1 -h some_target_directory | sort -hr   given the version of the tools has the options available.  to skip the total; something like:  du --max-depth=1 -h some_target_directory | sort -hr | tail -n +2  
you'll need to run something like gnu screen on the rhel box if you want to be able to re-connect to the ssh session to your bsd box.   ssh to rhel run screen ssh (from within screen) to bsd if/when the ssh to rhel dies, ssh back in and reconnect to the screen session with screen -d -rr or similar.   see the screen man page for details about the various re-attachment options
if you just want to concatenate all installed man pages into a single file, you could do:  cat /usr/share/man/man?/*gz &gt; all.gz   you should also include any/all dirs that can be found in the environment variable $manpath or which can be found in the output of the command manpath.  you can then read the concatenated manpages as a single file by running  man -l all.gz   this is just a compressed text file so you can decompress it and edit to your heart's content
looks like "blacklists/redirector/domains" is actually a filename, not part of the file's content
it is related to uefi (if you choose to boot in that mode)
+8 (to sort on the part of the line starting with the 9th field) or +8 -9 (to sort on the 9th field) is the deprecated sort key specification syntax
geany appears to use grep under the hood for searching within files, and it provides an extra options: field to pass additional arguments to the grep command
i've done something like this in the past.  ps -a -o etime,pid,user,args| grep init   returns  180-04:55:20    1 root     init [5]   which is easily parse-able in perl. i used split and pop to parse it.  the format is [[dd-]hh:]mm:ss 
you know how to set the variable in a shell, but for the record you can write:  export _java_options='-dawt.usesystemaafontsettings=on'   and all programs you start from this shell session after that will have the variable set.  if you want it to be set for every shell you start afterwards, add that line to ~/.profile as well
you can only have a single core.excludesfile; the last setting is the one that's used
super_l is an x keysym
the -- is working for tools which use getopt(3) to process command line arguments and many api that parse posix style options.  from the manual page of getopt(3):     the interpretation of options in the argument list may be cancelled by the option `--' (double dash) which causes getopt() to signal the end of argument processing and return -1
you can re-map keys with xmodmap
you need to manually edit the file fstab
following the handbook, after you select a region, a list with countries in that region will pop up
open your favorite terminal and stay as normal user
this doesn't look like a physical hard drive, more likely it's a lv (logical volume) or an encrypted partition or something like that
most terminal programs like xterm, urxvt, gnome-terminal have an option to change the starting working directory of the shell.  if you are using gnome-terminal there is a special command line switch you have to provide to start the shell in a user defined directory
not stock, but here are a few tool i have used before:   primes (usually in your distributions games package) just simply fork off a few dozen and it will generate primes from now until forever. stress: http://people.seas.harvard.edu/~apw/stress/ cpuburn: http://patrickmylund.com/projects/cpuburn/  
on my fairly up-to-date arch laptop, /tmp/.x11-unix/ is a directory with one entry: x0, a unix-domain socket.  the x11 server (usuall xorg these days) communicates with clients like xterm, firefox, etc via some kind of reliable stream of bytes
it's not clear exactly what you want
you need to run cloc on the source package, not on the binary package — cloc_1.60-1.1_all.deb is the binary package.  this works:  dget -d http://httpredir.debian.org/debian/pool/main/c/cloc/cloc_1.60-1.1.dsc cloc cloc_1.60.orig.tar.gz   and shows        12 text files.        7 unique files
scriptonaut, probably your problem has nothing to do with samba, but has to do with port forwarding/nat
the definition of the root user dictates that it has control over all files on the disk, irregardless of the user's &amp; groups that own said files &amp; directories.  many unixes, such as solaris, used to have a limitation where users could not be in more than 15 groups
rather than using match, if you wish to allow logging in from a single host, the following works for me (in sshd_config):  allowusers *@192.168.0.4   it only allows users logging in from 192.168.0.4, using any login on the target
from man bash, in the invocation section:     when  bash is invoked as an interactive login shell, or as a non-inter‐          active shell with the --login option, it first reads and executes  com‐          mands  from  the file /etc/profile, if that file exists
i don't use kde (i use gnome), but this may help:  you'll need a program called xte from the xautomation package.  create a bash script with this in it:  #!/bin/bash xte "str `date +%d`"   save it and make it executable.  create a keyboard shortcut in kde that launches your script.  now all you have to do is type your keyboard shortcut in any program and it will type out the date for you!  edit: if you have trouble getting this to work (like i had), try adding a short delay before the script runs xte:  #!/bin/bash sleep 0.3 xte "str `date +%d`"  
i don't know off the top of my head if this is the cause of your problem, but in general application *.desktop files need to be in specific places to be fully recognized
most standard shells provide a way to do simple text substitution within shell variables
i use app-portage/elogviewer
bool(){ return "$((!${#1}))"; }  if bool "$var" then : do true else : do false   just set a variable to anything but not-null for the above to work, though [ -n "$var" ] would be shorter, if not as obvious.  in general when a script interprets an environment variable to be either true or false, it will interpret any value at all to be true (and sometimes use said value to configure some option) or else a null value as false
i think you can just download the tazpkg
in zsh $path is tied (see typeset -t) to the $path array
that segment is for if you were building a script to compile glibc automatically in order to run it on this system
go to system>preference>mouse, in the "double-click timeout" section set the double-click speed
bash knows nothing about elf
yes, if you are already able to use ssh, sshfs should work
if you want to create a whole ipv6 address from a mac (and a given prefix), you could use the excellent ipv6calc tool by peter bieringer.  the following command creates a link-local ipv6 address (fe80:: prefix) from a mac address:  $ ipv6calc --action prefixmac2ipv6 --in prefix+mac --out ipv6addr fe80:: 00:21:5b:f7:25:1b fe80::221:5bff:fef7:251b   you can leave most of the options away and let the command guess what to do:  $ ipv6calc --in prefix+mac fe80:: 00:21:5b:f7:25:1b no action type specified, try autodetection...found type: prefixmac2ipv6 fe80::221:5bff:fef7:251b   for debian distros, ipv6calc is in the main repository. 
after trying a lot of different things, i ended up with this: just do right click on the application's tray icon (usually a little calendar) and click "refresh"
the beep tool controls the pc speaker, i.e., the tiny speaker on the motherboard itself.  other sound devices cannot be controlled by beep. you have to play some actual sound file, or synthesize the sound on the fly (try using the synth effect of sox). 
you can install screenlets: http://en.wikipedia.org/wiki/screenlets
just swap \0 and \n:  find ..
use proxycommand:  sshpass -p server_password ssh -oproxycommand="ssh -w %h:%p $gateway" $server   it will run the sshpass from your local host. 
from what you have posted it doesn't seems like you under stand how memory works in linux
use ack without a --type predicate:  ack &lt;search pattern&gt;   it ignores binary files and searches all textual files regardless of file type. 
the "more correct" depends on your distribution
the quick answer (assuming this is a bash script as tagged) is no, variables are not shared between separate shell instances
if you want to get a server to "look like something else", you should have an awareness of passive os fingerprinting
most programs that produce color will, by default, only produce it when the output is to a terminal, not a pipe or file
first option: airodump-ng  http://stackoverflow.com/questions/17776383/reading-realtime-output-from-airodump-ng  airodump-ng [monitor mode device] -w [file] --write-interval 5 -o csv   this will write a file [file]-01.csv which updates every 5 seconds
read the comment at the beginning of the file.   * interleave     allocate memory interleaved over a set of nodes,  *                with normal fallback if it fails.  *                for vma based allocations this interleaves based on the  *                offset into the backing object or offset into the mapping  *                for anonymous memory
if you want to run a x command on a remote system and and show the client on your local system the solution is rather simple:   you have to ensure that your x server accepts connection via tcp, nowadays this is typically disabled as it is a security problem
you could try printf "%s\n" 'username:encryptedpassword' | sudo chpasswd -e - that may be able to bypass the password checking enforced by pam.  the password must be pre-encrypted, e.g
it turns out, that what i want to do is not possible. from the parallels plesk forums:     you can't "bind" domain names to ports
if rpm command is supported, you can do   rpm -qf /usr/bin/vncserver   which shoud list you the vnc package 
xbacklight  $ xbacklight +30% # increases brightness by 30 percent $ xbacklight -30% # decreases brightness by 30 percent   dbus way  $ dbus-send --session --print-reply \       --dest="org.gnome.settingsdaemon" \       /org/gnome/settingsdaemon/power \       org.gnome.settingsdaemon.power.screen.setpercentage \       uint32:&lt;percentage&gt;   example  set brightness to 30%:  $ dbus-send --session --print-reply \       --dest="org.gnome.settingsdaemon" \       /org/gnome/settingsdaemon/power \       org.gnome.settingsdaemon.power.screen.setpercentage \       uint32:30    or to decrease brightness by a step (~7)    $ dbus-send --session --print-reply \       --dest="org.gnome.settingsdaemon" \       /org/gnome/settingsdaemon/power \       org.gnome.settingsdaemon.power.screen.stepdown   to increase brightness by a step (~7)    $ dbus-send --session --print-reply \       --dest="org.gnome.settingsdaemon" \       /org/gnome/settingsdaemon/power \       org.gnome.settingsdaemon.power.screen.stepup   if it says as follows your os may be too old
this is not quite what you need but close
trying many possible combinations of settings i solved it but the conclusion is that there is something amiss with xfce's session manager settings or gui.  what i have verified is:   as stated in the question, when this problem happens, under settings/login window/security - "enable automatic login" is checked, like so:      enable timed login is not checked.   the odd thing is that in order to avoid typing username &amp; password after logging out it is enough to check 'enable timed login'
this can be an aproach:  $ awk '/^ora/ {split($0,a,"."); next} {print a[2], a[2]$1, $2, $4}' a abc abc1 online servera abc abc2 online serverb xyz xyz1 online servera xyz xyz2 online serverb xyz xyz2 online serverc   explanation   /^ora/ applies for lines starting with ora
with recent-ish linux (or any system with recent gnu coreutils), call split --filter.  &lt;decrypted.bin split -b 16 --filter='openssl --args "$file" &gt;&gt; decrypted.bin'   independently-encrypted blocks sounds like ecb, so openssl enc -d aes-128-ecb may be what you're after.  if you have a strange mode that the openssl command line tool doesn't support, you may be better off using a tool that supports that strange mode
this dates all the way back to the very first edition of unix, where all the standard file names were only at most 6 characters long (think passwd), even though this version supported a whooping 8 characters in a file name
set -- $args set the positional arguments base on content of $args
the x input device maintainer for fedora &amp; x.org upstream has posted a guide to elographics touch screen setup on linux. 
man pages date back to unix first edition
i don't see which system to address specifically, but if yours is using resolvconf, try the following as root (su - or sudo -i):  echo 'nameserver 10.165.74.2' &gt;&gt; /etc/resolvconf/resolv.conf.d/head resolvconf -u   there is a warning in that file which states that manual changes will be overwritten; but, in context, the message applies to /etc/resolv.conf, not /etc/resolvconf/resolv.conf.d/head.  this should place the desired name server first in the list
i believe the solution is to modify the local policykit definitions
do you have apt-get installed? if so... apt-get update apt-get install gnome-shell this command will make sure that gnome-shell is installed and latest version  or better yet...  apt-get upgrade just upgrade everything  i don't run linux mint, but anyway, this is how you do it
i think you're confused about terminology.  an "environment variable" is merely a shell variable that any child processes will inherit.  what you're doing in your example is creating a shell variable
set  keepcache=1   in yum.conf  then future rpms should stay under /var/cache/yum 
sfdisk -d dumps the partition table but not the rest of the boot sector, so if there was a bootloader on the disk it won't be restored
use double quotes to echo a variable  localhost:~ $ a=5 localhost:~ $ echo "$a" 5 localhost:~ $ echo '$a' $a localhost:~ $ echo "a &amp; b" a &amp; b   or backslash \ to escape and not use quotes   localhost:~ $ echo a \&amp; b a &amp; b localhost:~ $ echo \$a $a  
in your particular example, br0 is consuming the packets from eth0 and the vlan code is not getting them
using gawk1 (with glenn jackman's suggested record separator):  awk 'begin { rs="" } /\&lt;test\&gt;/ { print $40,$41,$42 }' file size: 944856 kb  1
the issue  let us start by defining a server name:  $ servername=somename   now try:  $ echo "$servername_log_20150312"  $   the above returns nothing because (a) underline is a legal character in a shell variable name, and (b) we never defined servername_log_20150312.  now consider:  /server/directory/$servername_log_20150312*   after variable expansion, this becomes:  /server/directory/*   after pathname expansion, the above becomes every file in the directory.  two solutions  because this sort of thing is common, the shell has brace notation for variables:  $ echo "${servername}_log_20150312" somename_log_20150312   other ways of separating the name from the characters which follow are possible:  $ echo "$servername""_log_20150312" somename_log_20150312   documentation  from man bash, a variable name may contain any combination of alphanumeric characters and underscores but must start with an alphabetic character:     name   a word consisting only of alphanumeric characters  and  underscores,  and           beginning  with  an alphabetic character or an underscore
i suspect what you have is a firmware, rather than a driver
   -s/--silent           silent or quiet mode
strictly what you asked for:  sed 's/\([^:]\+\)/&lt;a href="\1"&gt;\1&lt;\/a&gt;/' input.txt     awk -f ':' -vofs=':' '$1="&lt;a href=\""$1"\"&gt;"$1"&lt;/a&gt;"' input.txt     while ifs=':' read -r url text; do echo "&lt;a href=\"$url\"&gt;$url&lt;/a&gt;:$text"; done &lt; input.txt   but for real html generating you also have to take care of html encoding:  perl -mhtml::entities -pe 's!([^:]+)(.*)!"&lt;a href=\"".($t=encode_entities($1))."\"&gt;$t".encode_entities($2)!e' input.txt  
you're already using the right command, and by the sounds of the latest comments, it works. 
after having been pointed to the keyword "tiling", and doing a quick search, i found a thread that pointed in the right direction:  "did you look under settings > window manager tweaks > accessibility (tab) > [tick] automatically tile windows..." ..
i don't know if that functionality is offered by typical installers, but it is easy enough to do from a live cd (or live usb or whatever)
i personally use the following bash function to do this:  so() {     local tmpdir="$(mktemp -d)"     local tmprc="$(mktemp)"     cat &gt; "$tmprc" &lt;&lt; eof ps1='\\$ ' cd "$tmpdir" eof     env - home="$home" term="$term" bash --rcfile "$tmprc"     rm -rf "$tmpdir" "$tmprc" }   here is what it does, in order:   create a temporary directory (to use as our working directory in the clean environment); create a temporary file (to use as our bash rc file); in the rc file, add lines which:  set the ps1 prompt to the prompt terminator followed by a space, which keeps it relevant in case we want to have a copy of our output on the q&amp;a site; change into the temporary directory we created.  invoke a new instance of bash, which:  initially has an empty environment except for $home and $term (env - ...); reads its rc file from the temporary file we created earlier (--rcfile).  once bash has exited, remove the temporary files we created.   obviously this is not totally foolproof, that is, you can still access other parts of your system
in the bash shell, !45 returns that command from the command history (or !32 or !873).     an event designator is a reference to a command line entry in the   history list
most software build processes use make
you need to install tp_smapi-dkms, just do  apt-get install tp_smapi-dkms  when finished, use lsmod | grep tp_smapi to check if module is loaded, to adjust the charge thresholds,  do something like this  echo 40 &gt; /sys/devices/platform/smapi/bat0/start_charge_thresh echo 60 &gt; /sys/devices/platform/smapi/bat0/stop_charge_thresh   add these lines to /etc/rc.local to run them at boot.  this module works at least on x220. 
ok i will feed the bears just once
as noted by anthon the -i option does not work that way
you should try something like:  flac -c -d -force-raw-format --endian=little --signed=unsigned input.flac | \   lame -r --little-endian --unsigned \        -s 44.1 [other encoding options here] - output.mp3   on the flac side:   -c means output to stdout -d decode -force-raw-format --endian=little --signed=unsigned force raw, little-endian, unsigned output   on the lame side:   - read from stdin (this is nearly standard) -r read raw pcm data --little-endian --unsigned match what lame outputs -s frequency: match that parameter with what your flac file contains you might need --bitwidth if your flac file isn't 16bits/sample   concerning the endian-ness and signed-ness, not sure what the "native" format you have is (or how to determine that) - try a few combinations
using the commands shutdown and reboot respectively
i found the solution. first the iommu group must be identified; in my case is 11(i found it using lspci and reading pci address,in my case it is 05:05:0)  find /sys/kernel/iommu_groups/ -type l|grep \/11 /sys/kernel/iommu_groups/11/devices/0000:00:14.4 /sys/kernel/iommu_groups/11/devices/0000:05:06.0 /sys/kernel/iommu_groups/11/devices/0000:05:05.0   so we have to add 05:05 and 05:06 (the two pci cards of the group) to qemu,with libvirt
first responder, but this happens at the hardware/firmware level and is not strictly a function of iw.  there's no standard that i am aware of, just common practice
the xev output shows a keypress event for the alt_l key with state 0x400
it means that grep should search for abc string only at the beginning of the line or after space, moreover this string has to end with another space or the end of the line.  in other words someone wanted to search for a strings which form whole words
the arch wiki has some example aliases and generic commands that will work in the majority of .bashrc files providing you are using systemd and have sudo installed.  this highlights the problem with the approach you are seeking, and one of the undesirable side effects of copying and pasting someone else's idea of a standard configuration into your shell 's config
according to netfilter documentation, redirection is a specialized case of destination nat
yours
bash maintains the list of commands internally in memory while it's running
i like hddtemp, which provides a pretty standard way of getting the temperature for supported devices
centos's installer, anaconda, supports a couple of different installation methods that you can use to help your remote administrator
i recommend to use yaourt as a package management tool
it is not a problem of ssh-agent, but of your windows client (providing ssh-agent interface)
you must log out and when you are at logging screen choose cinnamon:   
ldom is the sun/oracle hypervisor layer for sparc machines, and so only works on sparc hardware (v9 or higher)
just make it:  echo "adding username and password..."   ssh "root@${dssassocarray[$key]}" 'cat &gt; /etc/smbcredentials' &lt;&lt; eof username=$username password=$password eof  
it can be done easily with a good combination of sed and xargs.  find 
the standard spelling is “framebuffer”, without space
the two processes are sudo on the one hand, and cp on the other
with bash you can do as follows:  #!/bin/bash #let's look for an a in our handful of files string="a" for file in aa ab bb cc dd ad ; do   #note the placement of the asterisks and the quotes   #do not swap file and string!   if [[ "$file" == *"$string"* ]] ; then      echo "$string in $file"   else      echo "no match for $file"   fi done   edit: simplification with bash's regex matching, as suggested by @jeffschaller:  if [[ "$file" =~ $string ]] ; then  
you should never parse /etc/passwd directly
obviously, percona and mysql are closely related (certainly going by the former's web page), so apt thinks it should stop it
no, there aren't any general solutions
debian does not install anything into /usr/local, in the sense that official debian packages are forbidden to touch that hierarchy
your pv is 17926 physical extents large (with 4mib pes, that's 70.02 gib), which means it doesn't take the full extent of the partition.  possibly the partition was enlarged after the pv was created
to list available valid login shells for use at time, type following command:  cat /etc/shells   example:  pandya@pandya-desktop:~$ cat /etc/shells # /etc/shells: valid login shells /bin/sh /bin/dash /bin/bash /bin/rbash /bin/ksh93   for information about shell visit wikipedia. 
i would like to write this as a comment instead of an answer, but i can't yet so please don't ding me, community.  there is nothing wrong with the pieces you have posted so far
ntfs-3g can read alternate data streams in ntfs
you can use the rpm command to find out information about a particular package:  $ rpm -qi php name        : php                          relocations: (not relocatable) version     : 5.3.8                             vendor: fedora project release     : 3.fc14                        build date: wed 28 sep 2011 01:40:37 pm edt install date: wed 04 jul 2012 12:42:03 pm edt      build host: x86-12.phx2.fedoraproject.org group       : development/languages         source rpm: php-5.3.8-3.fc14.src.rpm size        : 3773261                          license: php signature   : rsa/sha256, wed 28 sep 2011 10:20:06 am edt, key id 421caddb97a1071f packager    : fedora project url         : http://www.php.net/ summary     : php scripting language for creating dynamic web sites description : php is an html-embedded scripting language
the size of the directory (as seen with ls -ld /var/lib/php/sessions) can give an indication
if you are on ubuntu or another debian-derived distro, you can install strigi-utils for cli tools to work with strigi
unfortunately this is more involved than just editing the /etc/inittab now
you might get somewhere browsing the torvalds git tree, eg for the file time/hrtimer.c
about the only thing you can do is verify that the hardware on your end isn't the source of the potentially faulty hardware
the linux kernel source tarball and git repository includes the code for all supported architectures, such as arm.  the subdirectory documentation/arm/ contains some arm related documents which you should probably have a look at before going further.  the arm specific code is located in the arch/arm/ subdirectory (some arm specific drivers may be in the drivers/*/ subdirectories).  thus go ahead and download the normal kernel tarball from kernel.org and start by reading documentation/arm/readme which starts as follows:     compilation of kernel      in order to compile arm linux, you will need a compiler capable of    generating arm elf code with gnu extensions
castaglia's answer is easier to use with proftpd, and works on any system.  as a more general solution for debian packages (including ubuntu), you can find the configure options in the debian/rules file (that link takes you directly to the version used in 14.04):  conf_args := --prefix=/usr \          --with-includes=$(shell pg_config --includedir):$(shell mysql_config --include|sed -e 's/-i//') \          --mandir=/usr/share/man --sysconfdir=/etc/$(name) --localstatedir=/var/run --libexecdir=/usr/lib/$(name) \          --enable-sendfile --enable-facl --enable-dso --enable-autoshadow --enable-ctrls --with-modules=mod_readme \          --enable-ipv6 --enable-nls --enable-memcache --with-lastlog=/var/log/lastlog --enable-pcre $(developt)   to find this yourself, go to the launchpad page for proftpd-dfsg, click on "code" at the top of the screen, then on the branch for the release you're interested in, then on "browse the code"
tr can do that:  tr -d \" &lt; infile &gt; outfile   you could also use sed:  sed 's/"//g' &lt; infile &gt; outfile  
backing up system files on unix type systems is generally not done on a file by file basis.  if you are trying to migrate a system to new hardware, just boot the old machine with a live image such as knoppix and use dd to image your hard drive partitions to a remote machine over the network or to an external hard drive
create a file /etc/vnc/xstartup with the following content:  #!/bin/bash unset session_manager exec /etc/x11/xinit/xinitrc   and give it the read and execution permissions to all users:  chmod 0755 /etc/vnc/xstartup   then this script will be executed by any user's vnc server 
not all shells define a variable uid
to clarify, the lf (aka \n or newline) character is the line delimiter, it's not the line separator
it does this to take advantage of the previously-installed terminal description for gnu screen.  both tmux and screen provide applications with (more or less) the "same" terminal descriptions to simplify connecting from different terminals
instead of cancelling just use alt+f  (or on ubuntu alternatively ctrl+-> to move the cursor to the end of the first word and then press ctrl+k to delete everything to the end of the line.  now you are ready to complete your command. 
i don't believe there is any difference in terms of their content
did you set enabled="true" in /etc/default/sysstat (it is false by default on installation in ubuntu and maybe other distros)?  then you should be able to start it with sudo service sysstat restart 
the gnome-terminal program sticks that nub there itself
you could use awk for that.  command | awk '{ if (/pattern/) { print &gt; "match" } else { print &gt; "nomatch" } }'  
bash has a precommand hook
libusb is a library to interact with usb devices in the same manner that curses is a library to interact with text terminals, alsa (more precisely its libasound component) is a library to interact with audi devices, etc
remember iwlist is deprecated!  use the iw tool.  iw dev wlan0 scan ...     ht operation:      * primary channel: 6      * secondary channel offset: no secondary      * sta channel width: 20 mhz  
you can look at which packages the package manager knows to be dependent on this by using:  apt-get remove -s libgtk-3-0   the -s option makes sure this is a simulation so nothing is actually removed. 
very roughly:  # cp /etc/passwd /etc/passwd.bak # just in case you e.g
just undo your changed option values: 'list' is a boolean flag whose inverse is 'nolist'
if you specify a block size (512 bytes) of less than the block size of the disk (often 4096 bytes, but nowadays maybe more), the block will be partially written, so that the contents of the rest of the block must be preserved before writing.  this is because disk blocks cannot be written to with only 512 bytes, but you have to write a full block at once (4096 or larger)
you are using whats called kernel mode setting (kms) to make sure that your intel graphic drivers are loaded early in the boot process, therefore making the "fancy" boot screen display correctly.     kernel mode-setting (kms) shifts responsibility for selecting and   setting up the graphics mode from x.org to the kernel
there are many variations in the syntax of the tar command
you could use this function:  gedit() { /usr/bin/gedit $@ &amp; disown ;}   it:   makes a function which can be called with gedit launches gedit (using the full path /usr/bin/gedit), passing all the arguments/files given to it using $@ &amp; disown sends it to background and disown detaches it from the terminal/shell.  
try   &lt;application name="emacs*" class="emacs*" type="normal"&gt;     &lt;position force="yes"&gt;         &lt;x&gt;0&lt;/x&gt;         &lt;y&gt;0&lt;/y&gt;     &lt;/position&gt;     &lt;size&gt;         &lt;height&gt;600&lt;/height&gt;         &lt;width&gt;1024&lt;/width&gt;     &lt;/size&gt;     &lt;decor&gt;no&lt;/decor&gt;     &lt;maximized&gt;no&lt;/maximized&gt; &lt;/application&gt;   the &lt;height&gt; and &lt;width&gt; need to be in the &lt;size&gt; tag.  from the example configuration of openbox  &lt;position force="no"&gt;   # the position is only used if both an x and y coordinate are provided   # (and not set to 'default')   # when force is "yes", then the window will be placed here even if it   # says you want it placed elsewhere
there is still space required for the filesystem's internal usage (superblocks, etc)
according to this video:  https://www.youtube.com/watch?v=tmxiejvzcia#t=02m00s  go to:  applications -> settings -> settings manager -> window manager tweaks -> cycling -> cycle through windows in a list 
on *bsd:  date -r 1234567890   on linux (specifically, with gnu coreutils ≥5.3):  date -d @1234567890   with older versions of gnu date, you can calculate the relative difference to the utc epoch:  date -d '1970-01-01 utc + 1234567890 seconds'   if you need portability, you're out of luck
try using the globstar option in bash; i believe that zsh has a similar option.  $ shopt -s globstar $ echo pylib/**/pyerector.py pylib/pyerector.py pylib/pyerector/pyerector.py   you can read more about it in the manpage. 
to answer 1), start with  ps -u tomass -o pid,time    (depending on you context, you may wish to select time (cpu time), etime (elapsed time))  to answer 2), try  ps -u tomass -o state,pid | awk '$1 == "r" { printf "kill %d\n",$2 ;}' | ksh   you really want to kill running process ? 
if you have strace  strace -v -e execve cmd   if the values of the variables are too long you can increase the string size with -s  strace -v -s 10000 -e execve cmd  
#!/bin/sh # runs a command with gsed substituting for sed  set -e  mkdir -p /tmp/temp-path ln -fs `which gsed` /tmp/temp-path/sed export path=/tmp/temp-path/:$path eval "$@"  
as others have commented i don't believe this is possible in runlevel3
add single-quotes around the remote command:  $ ssh root@192.168.100.195 'echo "hello gourav how are you" &gt;&gt; /g.txt'   edit: yes, as @andrew miloradovsky noted, use &gt;&gt; rather than &gt; for appending rather than writing anew. 
the screenshots in the question do not show dtterm (some people are confused by the ability to set the term environment variable to dtterm, xterm, etc., while using other programs, supposing that those other programs are identical to dtterm, xterm).  here's a screenshot for instance from oracle's documentation:    given that, it is unclear what actual terminal was being used.  @jeff-schaller noticed the position of the scrollbar in the second screenshot and guessed that op was expecting the terminal to skip down to the bottom of the scrolling area when typing into it
one way to go is to create a second disk image, add it to your guest os and copy files from one to the other
if your laptop has more than 3.5gb of ram installed, you will want to install a 64 bit edition in order to take advantage of the full amount of ram.  general use of x64 operating systems is becoming more and more widespread
the short form and the long form that are on the same line are the ones that are equivalent.  so, -e command is equivalent to --rsh=command, and -v is equivalent to --verbose.  the grouping of commands is by similarity of function, so --verbose, --info, and --debug are all related to the verbosity of the program as it runs
you may have success using /dev/stdout as the filename and piping the output of your application to gzip.  /dev/stdout is a symlink to /proc/self/fd/1.  similarly, you may be able to use /dev/stdin as a filename and pipe the output of gzip to the application.  i say may, because the application may be expecting a seekable file that it writes to (reads from), but /dev/std{in,out} will not be seekable
the file /proc/$pid/stacks shows kernel stacks
in the repo file, add a line that says:  includepkgs=google-chrome*  this will only allow updates and installs of packages named google-chrome* from that repo, all other packages will be ignored
crontab -e  it will open a configuration file in editor and you then add your line to the end:  * * * * * /usr/bin/sh t.sh 
   make a wrapper for process which i capture their standard output and pump to the journal via syslog.   such wrapper already exists and is called systemd-cat.  you may use it as follows:  systemd-cat -t app1 /home/myself/logtest/app1 &amp; systemd-cat -t app2 /home/myself/logtest/app2 &amp;   the argument to -t is an arbitrary identification string, analogous (equivalent) to syslog's identifier.  it is also possible to use systemd-cat in a shell pipeline like this:  /home/myself/logtest/app1 |&amp; systemd-cat -t app1 &amp;   (the |&amp; is a bash construction to pipeline both stdout and stderr.)  however, the first form is preferable as it avoids spawning an extra process and doing an extra copy of all logged data. 
it is not completely sure what you are asking, but an alias just expands to what is in the alias
this site provides an interactive way to see what permissions bits are set when various bits are set/unset.   http://permissions-calculator.org/   the "calculator" looks like this:  &nbsp;&nbsp; 
to match on the content of a shell variable in bash, zsh or ksh93:  re='^[0-9]+(,[0-9]+)*$' [[ $string =~ $re ]] &amp;&amp; echo matches   posixly:  case $string in   ("" | *[!,0-9]* | ,* | *, | *,,*) ;;   (*) echo matches;; esac   bournely:  expr " $string" : ' [0-9]\{1,\}\(,[0-9]\{1,\}\)*$' &gt; /dev/null &amp;&amp;   echo matches   to match on lines of input:  grep -xe '[0-9]+(,[0-9]+)*'   we use + (or the bre equivalent \{1,\}) to match 1 or more digits
you don't have to escape space in sed command, just use double quote in echo command to avoid word splitting:  $ domsp=$(echo "$dom" | sed "s/^0*/ /"); echo "$domsp"  1  
i don't know that limiting cpu to the whole system is something that's possible without a lot of hacking, but you can easily limit the amount of cpu used by a single process using cpulimit  the only way i can think of you being able to use this effectively is writing a wrapper script (can't really call it a script, it's so small) for the applications which you know are resource hogs
that's because the /etc/hosts is simply a file on your debian server that it utilizes for its own name resolution
   if i open a file without closing it and continue to stream data there, is it better than if i open, write and close for each new piece of data?   no
amdgpu consists of a device driver which is part of linux since 4.3 and a xorg driver, which you're both currently missing
you need the tr after you read the plaintext file:  #!/bin/bash printf "generating random file &gt; plaintext \n" cat -v &lt; plaintext | tr "a-z" "b-y" &gt; generatedtext   in your question plaintext is redirected to tr not cat
the issue is caused by the sensible plugin:line 93
it cares about the spacing
to find out what commands are masked by aliases, do something like this:  alias | sed 's/^[^ ]* *\|=.*$//g' | while read a; do   printf "%20.20s : %s\n" $a "$(type -ta $a | tr '\n' ' ')" done | awk -f: '$2 ~ /file/'   explanation  alias alone lists defined aliases and sed extracts their name
the capture kernel runs on the same host
if you did set -ovi then repeat as set +ovi the effect of one will be reversed by the other.  what you actually did was activate the verbose option set -o v which shows history (if set) as well.  the most important values set are printed by echo "$-", which is usually just himbh in interactive shells.  a longer list of values is printed either by set -o or set +o
something like:  head -n8 file1 | cat - file2 &gt; file2."$$" &amp;&amp; mv file2."$$" file2  
there's no need to do that, it's already in a variable:  $ echo $pwd /home/terdon   the pwd variable is defined by posix and will work on all posix-compliant shells:     pwd      set by the shell to be an absolute pathname of the current working directory, containing no components of type symbolic link, no components that are dot, and no components that are dot-dot when the shell is initialized
   how can i fill the free space with zeroes in ubuntu 12.04 (ext4)?   it's rather simple:  dd if=/dev/zero of=/some/path/to/zerofile bs=128m count=numof128mblockstofillthediskwith  you'd better have some space left untouched with that commands, say 1 %
you have to have a repository with proper structure and it should be built and signed with proper tools. here are some tutorials that might help you in this, ubuntu repo questions 
i think you could remove the configuration manually
for configuring a catchall mail in zpanel you need to do some changes in the postfix database.   create a mail account in which you want to get bounce mails. then login to your phpmyadmin with mysql root user then select postfix database. after this you will see alias table select that table. you will see your mailbox which you have created earlier copy that and change user@domain -> @domain and then save. ok done now you will get un routed mail for your domain in your mailbox.  
you can create an /etc/sysconfig/network-scripts/route-eth0 file with the content like this if you use multiple routes:  default via 192.168.0.1 dev eth0 10.10.10.0/24 via 192.168.0.1 dev eth0 172.16.1.0/24 via 192.168.0.1 dev eth0   for the default gateway you need to add this line :  gateway=198.245.49.254   to the file /etc/sysconfig/network  link: https://access.redhat.com/site/documentation/en-us/red_hat_enterprise_linux/5/html/deployment_guide/s1-networkscripts-static-routes.html 
try this  script -c 'pacman-color -syu' file.log   idea taken from here. 
you can use freerdp with multimedia redirection     freerdp: a remote desktop protocol implementation      freerdp is a free implementation of the remote desktop protocol (rdp),   released under the apache license
in vim, you can do:  :%s/&lt;head\b[^&gt;]*&gt;/&amp; &lt;meta foo="bar"&gt;/g   you could also do this in gnu sed, which would possibly be more fitting:  for file in *.html; do     sed -i 's/&lt;head\b[^&gt;]*&gt;/&amp; &lt;meta foo="bar"&gt;/g' "$file" done   be warned, -i breaks symlinks. 
   i don't understand why $namefile* takes these names.as far as i know * calls the the argument which the script receives.   $namefile expands to the value that you passed in (probably "hw")
can you please post the contents of your .bashrc/.zshrc?  it will be easier if i can see how exactly your path is setup.  on my system, (because i put the dart folder in /applications), the location of the pub binary on my system is:  /applications/dart/dart-sdk/bin  also in order to execute pub, i have to do like so:  $ ./pub 
assuming you just wanted to delete all string starting with "perro", you can use:  sed 's/perro[^ ]*//g' *-a.log   if you want to edit the file in place, you can use -i option with sed, like  sed -i sed 's/perro[^ ]*//g' *-a.log   update  if you don't want to have multiple spaces, you can use:  sed -i sed 's/perro[^ ]*//g' *-a.log | tr -s " "   sample data,  rahul@rahul: cat a.log foo perro-b perro-c bar perro-14 cmd  perro-x perro-dhfn abc xyz abcd perro-14  rahul@rahul: sed 's/perro[^ ]*//g' a.log | tr -s " " foo bar  cmd  abc xyz abcd  
from a security perspective, the answer is that in current distros you can't tell which application it is
there is no formal definition of window belonging to the window manager or “opened on his own”
$ t1="23:42" $ t2="02:10" $ e1=$( date -d "$t1" +%s ) $ e2=$( date -d "$t2" +%s ) $ if (( e1 &gt; e2 )); then e2=$( date -d "$t2 tomorrow" +%s ); fi $ date -d@$e1 tue oct  6 23:42:00 edt 2015 $ date -d@$e2 wed oct  7 02:10:00 edt 2015   to find the difference, if you don't need fractional hours, use shell arithmetic, otherwise pipe to bc  $ diff=$(( (e2 - e1)/3600 )) $ echo $diff 2 $ diff=$( echo "scale=2; ($e2-$e1)/3600" | bc) $ echo $diff 2.46  
it needed to have another instance of mono already installed, so apt-get install mono-gmcs did the job
hardware differences may be accounted for by bios settings; review the bios on each system for differences
/proc/$pid/maps  /proc/$pid/mem shows the contents of $pid's memory mapped the same way as in the process, i.e., the byte at offset x in the pseudo-file is the same as the byte at address x in the process
here is a oneliner that simply loops until the port is open
you can use -i flag to sed which will edit inplace and also take backup:  sed -i.bak "1 s/^.*$/$new_header/" inputfile  
if you want all setup all the limiting stuff you mention i would suggest to use proftpd
channel.setpty(true) did the trick 
i ended up giving them two options on my "getting started" page
how about something like  netstat -6tnlp | awk '/\/beam / {print $4}' | tr -d :   there's probably a neater way, and that line depends on there being only one ipv6 socket bound to a process called beam. 
use postfix config parameter "recipient_delimiter"
lvs | fgrep "mwi"   "m" means: mirrored 
write it as a shell function (e.g
you can set up compinit to expand parameters in your ~/.zshrc:  zstyle ':completion:*' completer _expand _complete autoload -uz compinit compinit   this is a minimal setting, if you have compinit already enabled, it should be sufficient to add _expand to the settings of completer  there is also the expand-word widget that is by default bound to ^x* (ctrl+x *) that essentially does the same as the same binding in bash.  note: both methods only work on the current word.    as an alternative, in zsh you can actually do what you asked for in your original question: turn a relative path into an absolute path
on newer debian and ubuntu systems, your keyboard settings are put in /etc/default/keyboard and shared between x and the console
this will generally work
i also use stat to get a ls-like output but i use a different approach to format the output: i use tab as a delimiter (allows for easier parsing afterwards, if needed), format the time via stat and finally filter the output with numfmt (included in gnu coreutils >= 8.21 2013-02-14) to get nice file sizes:  stat --printf="%a\t%a\t%h\t%u\t%g\t%s\t%.19y\t%n\n" * | numfmt --to=iec-i --field=6 --delimiter='     ' --suffix=b   note the delimiter used for numfmt is also a tab (to input in terminal hit ctrl+v then tab). this is what the output looks like:  drwxr-xr-x  755 2   don users   4.0kib  2013-05-17 03:37:02 150905-adwaita-x-dark-light-1.3 drwxr-xr-x  755 8   don users   4.0kib  2011-10-13 07:30:39 adwaita slim drwxr-xr-x  755 3   don users   4.0kib  2013-05-17 19:26:41 away drwxr-xr-x  755 5   don users   4.0kib  2013-05-17 03:09:14 elementary -rw-r--r--  644 1   don users   539kib  2013-05-10 00:32:14 gdm.jpg -rw-r--r--  644 1   don users   1.5mib  2013-05-19 04:30:16 gnome-shell-3.8.2.tar.xz drwxrwxr-x  775 4   don users   4.0kib  2013-05-18 18:34:38 gnome-themes-standard-3.8.1 -rw-r--r--  644 1   don users   3.7mib  2013-05-18 18:30:06 gnome-themes-standard-3.8.1.tar.xz drwxrwxr-x  775 17  don users   4.0kib  2013-05-18 18:37:05 gtk+-3.8.2 -rw-r--r--  644 1   don users   14mib   2013-05-18 18:30:56 gtk+-3.8.2.tar.xz drwxr-xr-x  755 13  don users   4.0kib  2013-05-18 02:41:51 mediterraneannight-2.02 -rw-r--r--  644 1   don users   603b    2013-05-19 20:07:26 python-pytaglib.tar.gz -rw-r--r--  644 1   don users   442kib  2013-05-19 00:33:27 stripes.jpg   note: as per cwd's comment, on osx, coreutils commands are gstat and gnumfmt. 
using cut:  cut --complement -f 2-3 &lt;file&gt;  
if ("$myvar" == "") then   echo "the string is blank" endif   note that in csh, it is an error to attempt to access an undefined variable
from here:     msfvenom is a combination of msfpayload and msfencode, putting both of these tools into a single framework instance
the pwconv command automagically backups the /etc/passwd in a file called /etc/passwd-.  try to restore this file and rename /etc/shadow to /etc/shadow-. 
this is the default, if i understand your question
after having posted this all around the globe, a user (hiciu) in arch linux forum did provide the solution.  apparently it's the systemd service that had privatetmp=true:     ...if true, sets up a new file system namespace for the executed processes...   removing the option did fix the issue.  you can learn more about adventures to resolving the issue, here. 
you cannot create span for wildcard tdm410p
first note that you can ssh into a network device only from a machine that is connected to the same network as the target device
there's a debug trap that can be called before every command is run  eg  trap 'echo -e "\nstarted at: $(date)\n"' debug   so if i do that:  $ trap 'echo -e "\nstarted at: $(date)\n"' debug $ pwd  started at: thu aug 18 11:59:33 edt 2016  /home/sweh $ echo hello  started at: thu aug 18 11:59:35 edt 2016  hello $ sleep 100  started at: thu aug 18 11:59:37 edt 2016   it's not rewriting the prompt, but you can see how it can be made to output stuff before every comamnd
this problem stems from the fact that rhel wants 64-bit libraries to be installed to the /usr/lib64 directory, rather than the default /usr/lib directory.  mapserver 6.2.1 uses autoconf, and includes a --libdir option
it's more easily done with perl:  perl -0777 -pi -e 's{/\*.*?\*/}{/* new comment */}s' file.c   would replace the first occurrence of /*...*/ with the new comment.  sed processes the text one line at a time, so you can't match a multi-line text, unless you do add the other lines to the pattern space (or you use -z with recent versions of gun sed):  sed -zi 's|/\*.*\*/|/* new comment */|' file.c   or portably (assuming short files):  sed -e :1 -e '$!{n;b1' -e '}' -e 's|/\*.*\*/|/* new comment */|' file.c   however note that since sed doesn't support the *? non-greedy operator of perl, that means that it will match from the first occurrence of /* to the last occurrence of */, so it would replace /* comment 1 */ some c code /* comment 2 */ with /* new comment */.  doing it with sed is possible but more painful
like this:  nc -z hostname 22 &gt; /dev/null echo $?   if it's 0 then it's available
rows="4"; montage -geometry 2550 -tile 1x$rows *.jpg output.jpg   geometry -> you need to know the original picture width, or at least give this a good value so the quality could be enough  tile -> how many "columns x rows" will the output have? (from the original jpg files) - $rows could be calculated with "ls -1 *.jpg | wc -l" if one folder contains all the jpg files
it is clear from information provided that the problem is (at least partly) that your current preferences are not sensible
answer from thrig's comment on op
from man bash:     process substitution        process substitution is supported  on  systems  that  support        named  pipes  (fifos)  or  the  /dev/fd method of naming open        files
you could emulate the same thing by replacing your xargs by a ksh script
in fact, modifying mount is possible, as i learned from the existence of mount.ntfs-3g
there is a guide on linux gazette for a six-headed x11 system.  it works by giving a different serverlayout in the xorg.conf, grouping the different screen, mouse, keyboard
you can put an inotify watch in the directory that will contain the core file
i think you can get away with using split's --filter=command.  ..
it's not the job of iptables to drop a packet when the port is closed, that's the job of the normal network stack (as without iptables)
i don't think there is a way to limit swap space, unless you modify the program to only request non-swappable memory, which even if possible would probably be impractical.  however what you can and should do is limit the total amount of memory available to the process
the issue is that (for whatever reason) the output from nvidia-settings -query gpucoretemp under xfce does not contain the string gpu
according to ibm's aix documentation for ftpd, there is a -ff flag which:     disables checking for both a privileged port and an ip address that matches the one used for the control connection when the client requests the server to connect back to a specific client port
picasa for linux (which actually was picasa for windows packaged with wine) is discontinued.     so today, we’re deprecating picasa for linux and will not be maintaining it moving forward.   your best option would be to run a recent version in wine. 
i don't work with opensuse, but as i know, there is no logs on trashcan.  but if content of a directory change, his modification time have to change too.  at all, there is a few possibility to restore something, but:   you have to stop immediatly your disk activity (in root: mount -o remount,ro /home if /home is the mountpoint of partition) you have to know what you want to restore, there is a few tools for doing that job, but you have to inform them about what to search for. if / (root) is the partition to work on, you have to use another way, like live-usb in order to be able to work on read-only partition. preferably copy whole partition to another before of working on.   modifying trashcan behaviour to ask him to make log is possible too, but this depend on which desktop environment you are using.  there are essentially two widely used file-manager:   nautilus on gnome konqueror on kde   i use nautilus
you just need to run set +x  from man set:  using + rather than - causes these options to be turned  off.  
the inc_append_history option, if set, causes a more immediate write of history entries
it looks like hid_multitouch might be your driver.  before blacklisting, try the following:  modprobe -r hid_multitouch  if this works then add it to the blacklist 
if you want to forward all of a user's mail, not just the mail from cron, solaris does support ~/.forward
you need to remember that pkg and ports register installed software in the same place (an sqlite database in /var/db/pkg)
at last, after almost six weeks of frustration, and numerous attempted solutions based on suggestions by kind friends and internet question sites, i have solved the problem (i think -- i am cautiously optimistic)
vagrant does not keep any logs
with gnu (for -readable and -iname) find:  find 
kernel versioning is independent of distro versioning, except to the extent that distros include patches of their own
the initial port of linux for amd64 only supported a 40-bit virtual address space, divided in 512gb for the process and 512gb for the kernel
yes
apt-get makes use of dpkg to do the actual package installations
it sounds like you want exim's address rewriting.  in the rewriting section of your exim config file, you will probably want something along the lines of this:  pi@bar.com foo@bar.com ffr   you may need to adjust the flags ("ffr") to the specific behavior you want.  more generally, see: http://www.exim.org/exim-html-current/doc/html/spec_html/ch-address_rewriting.html   raspbian  specifically, in raspbian, edit /etc/exim4/exim4.conf.template, adding the following in the rewrite configuration section.  pi@bar.com foo@bar.com ffr   if you prefer all outgoing email to be from foo@bar.com, regardless of original sender, use this line instead.  * foo@bar.com ffr   next, run sudo update-exim4.conf, then check to make sure it worked with exim -brw pi@bar.com
fedora updates regularly break the functioning of broadcom wireless devices
well, right now i may suggest only 'brute force' solution
file tells you “non-iso extended-ascii text” because it detects that this is:   most likely a “text” file from the lack of control characters (byte values 0–31) other than line breaks; “extended-ascii” because there are characters outside the ascii range (byte values ≥128); “non-iso” because there are characters in the 128–159 range (iso 8859 reserves this range for control characters).   you have to figure out which encoding this file seems to be in
l is not able to connect to b, but is b able to connect to l? you didn't say, but i will assume no.  if a is your only way to communicate between b and l then you will definitely have to log in to a at some point
in the general case, this could be difficult to do
alt+scrollwheel.  so in my case i had pressed alt+two fingers on mouse pad. 
try the following two commands and see what you get:  echo "$(printf 'a')" echo '$(printf 'a')'   essentially, single quotes will give you your "original raw string", while anything in double quotes will be evaluated before being assigned to your alias.  however, you might notice that the single quotes around 'a' are missing from the output of second command
i always use klist instead to list the contents of keytab files out instead of ktutil.  example #1 - klist  $ klist -kt /etc/somedir/conf/some.keytab keytab name: file:/etc/somedir/conf/some.keytab kvno timestamp         principal ---- ----------------- --------------------------------------------------------    5 08/25/15 11:18:35 app/host1.dom.local@td.com    5 08/25/15 11:18:35 app/host1.dom.local@td.com    5 08/25/15 11:18:35 app/host1.dom.local@td.com    7 08/25/15 11:18:35 app/host2.dom.local@td.com ...   example #2 - process substitution  you can also use a redirect to ktutil's stdin like so:  $ ktutil &lt; &lt;(echo -e "rkt /etc/somedir/conf/some.keytab\nlist") ktutil:  rkt /etc/somedir/conf/some.keytab ktutil:  list slot kvno principal ---- ---- ---------------------------------------------------------------------    1    5 app/host1.dom.local@td.com    2    5 app/host1.dom.local@td.com    3    5 app/host1.dom.local@td.com    4    7 app/host1.dom.local@td.com  
~/.subversion/config   you can also change it there.  edit: for clarity, that's a text file, not a program. 
there are three elements to the process of determining whether a disk "runs linux"   make a list of partitions to check mount each partition  check each partition for some "magic" files  unmount each partition   for step 1, you can use 'parted' called via subprocess.check_output() and parse the return value.  for step 2 and 4 use 'mount' resp
there are a couple of tools you can use to check the layout of a disk to see how it's partitioned
install ? looks like you only got one jar file, so just launch it is fine:  java -jar drjava-stable-20100816-r5366.jar  edit  you could put a shortcut on your desktop, put these things to ~/desktop/xx.desktop:  [desktop entry] name=what ever genericname=what ever exec=java -jar /absolute/path/to/drjava.jar icon=gedit type=application   just double click on the desktop icon to launch it
check out lsyncd.     lsyncd watches a local directory trees event monitor interface (inotify)
the documentation of the network manger project points out that it's the dekstop environment authors' responsibility to integrate nm-connection-editor with their guis:     most desktops provide a control center or settings utility that integrates with networkmanager
assuming:  hour=09   just use that:  grep "\.$hour" file   with the single quotes in your example, the variable is not interpreted as variable
i'm going to ignore the aspect of why you're doing this, and assume you already know the caveats — if not, know that many isps might block port 25 and some smtp servers will block request from dynamic ip addresses.  a little-known feature of bash is that you can direct output to /dev/tcp/hostname/port and it'll connect to the server
the structure :w !cmd means "write the current buffer piped through command"
sed ":a;/\r$/{n;s/\r\n//;b a}"   this will match all lines that have '\r' at the end (followed by '\n')
very close, yes
you'll find different scripts in order to do that on ubuntu forum
according to the documentation, something like this should work:  pcm.dmix_front {     type dmix     ipc_key 12345     ipc_key_add_uid 0     slave.pcm "hw:0,0" } pcm.dmix_rear {     type dmix     ipc_key 67890     ipc_key_add_uid 0     slave.pcm "hw:0,1" } pcm.quad {     type multi     slaves {         a { pcm dmix_front channels 2 }         b { pcm dmix_rear  channels 2 }     }     bindings [         { slave a channel 0 }         { slave a channel 1 }         { slave b channel 0 }         { slave b channel 1 }     ] }  
the sed command "i" expects \ followed by text, as explained in the output of bsd sed when given the command you provide above.  however, it only expects one line of text
you can use bash process substitution:  while ifs= read -r line; do   ./research.sh "$line" &amp; done &lt; &lt;(./preprocess.sh)   some advantages of process substitution:   no need to save temporary files. better performance
they are not aliases
this one is well hidden :-)  to remove the kde event notification   go to kde system settings select "application and system notifications". choose kopete messenger in event source,  select "status change" and uncheck all options.   to remove the event in the kopete chat window   in kopete, go to menu settings / configure... select behavior / chat  uncheck "show events in chat window".  
posixly, you can use ls  if ls town-*.swf &gt;/dev/null 2&gt;&amp;1 &amp;&amp;    ls city-*.swf &gt;/dev/null 2&gt;&amp;1  then   mkdir towns fi   or shorter if condition:  if ls town-*.swf city-*.swf &gt;/dev/null 2&gt;&amp;1   even if your shell supports brace expansion:  if ls {town,city}-*.swf &gt;/dev/null 2&gt;&amp;1  
crontab -u user -l will list the crontab to stdout.  crontab -u user file will load file as crontab for user.  now the only thing that is missing is a way to identify your "jobs".  "addjob" will add a line to the output of the current crontab and read it as new crontab.  "disablejob" will just put a comment in front of your job-line,  "enablejob" will remove a comment from your job-line. 
your example almost works perfectly - it's not export that's the problem, but the use of xargs.  try:  echo -e "foo=3\nfoobar=4" &gt; .env; export (cat .env);  env | grep foo   the reason is that a command substitution separates arguments on newlines, and xargs removes them:  &gt; count (cat .env | xargs) 1 &gt; count (cat .env) 2  
you can check the setting for an interface, say eth0, with ethtool:  $ sudo ethtool eth0 | grep wake     supports wake-on: pumbg     wake-on: g   from the ethtool man page you can disable it with   $ sudo ethtool -s eth0 wol d   where this gets configured depends on what you use to start your network. archlinux gives some examples (for turning it on, but the reverse should be clear) for netctl, systemd, nmcli (networkmanager), and udev. 
if you use strace you can see how a shell script is executed when it's run
firstly, on fedora, both auditd and auditctl come from the same package (unconfusingly named audit)
as an example, to send a search of "foo" with sz checked and nz unchecked:  curl -d "search_term=search&amp;search=foo&amp;sz=on&amp;nz=off" http://site.com/search.php  
sudo sanitizes environment before running any command, so unless you save the desired environment variable in /etc/sudoers using env_keep the varible will not be preserved by sudo.  alternately, for a single command, you can do:  sudo lang=en_us.utf-8 some_command   in order to preserve the current environment:  sudo -e some_command  
do a cat /proc/cpuinfo and look at the results:  processor       : 1 vendor_id       : genuineintel cpu family      : 6 model           : 23 model name      : genuine intel(r) cpu           u4100  @ 1.30ghz stepping        : 10 cpu mhz         : 1200.000 cache size      : 2048 kb physical id     : 0 siblings        : 2 core id         : 1 cpu cores       : 2 apicid          : 1 initial apicid  : 1 fdiv_bug        : no hlt_bug         : no f00f_bug        : no coma_bug        : no fpu             : yes fpu_exception   : yes cpuid level     : 13 wp              : yes flags           : fpu vme de pse tsc msr pae mce cx8 apic mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe nx lm constant_tsc arch_perfmon pebs bts aperfmperf pni dtes64 monitor ds_cpl est tm2 ssse3 cx16 xtpr pdcm xsave lahf_lm bogomips        : 2593.48 clflush size    : 64 cache_alignment : 64 address sizes   : 36 bits physical, 48 bits virtual power management:   a lot of the information that you are looking for can be inferred from this. 
qemu-kvm -hdb &lt;device&gt;, where &lt;device&gt; is the usb stick (e.g
svmon   e.g.  # svmon                size      inuse       free        pin    virtual memory       131072     114552      16520      34191     151562 pg space     655360      78472                 work       pers       clnt      other pin           30911          6          0       3274 in use        83264      31288          0   or vmstat as already shown (vmstat -v) 
you can almost definitely just do:  alias &gt;&gt;./bash_aliases  
use tcpdump.  tcpdump -w httpdebug.pcap -i eth0 port 80 will sniff all packets heading to or from port 80 on the eth0 interface and output them to httpdebug.pcap, which you can then read at your leisure, either with tcpdump again (with multiple -x options, refer to the tcpdump manpage ) in console if you're feeling masochistic, or with wireshark
a loop device just turns a file into a block device
don't parse ls
du summarizes the disk usage directory by directory
maybe you are looking for  df .   when you are in the directory you want to know the mountpoint of? 
first of all, you should be aware that it is very important which storage engines do you use.  lets assume that both of your mysql servers have the same version
assuming your original date is "month-day-year" (september 2, 1832), something like this might work:  $ date -d $(sed "s/-/\//g" &lt;&lt;&lt; '9-2-1832') +%y-%m-%d 1832-09-02   explanation  the date command, even at the current 8.25 version, won't accept a date of the format you list ('9-2-1832', a month-day-year date string with hyphens as separators).  $ date -d '9-2-1832' +%y-%m-%d date: invalid date ‘9-2-1832’   but date will accept a month-day-year date string with slashes as separators.  $ date -d '9/2/1832' +%y-%m-%d 1832-09-02   you can use sed to swap the hyphens for slashes like so.  $ sed "s/-/\//g" &lt;&lt;&lt; '9-2-1832' 9/2/1832   then you can put the sed command in a subshell to put everything together.  $ date -d $(sed "s/-/\//g" &lt;&lt;&lt; '9-2-1832') +%y-%m-%d 1832-09-02  
i found a way:  diff --git a/src/ls.c b/src/ls.c index 680a7c3..d316eb6 100644 --- a/src/ls.c +++ b/src/ls.c @@ -4226,7 +4226,7 @@ print_color_indicator (const struct fileinfo *f, bool symlink_target)     /* check the file's suffix only if still classified as c_file
one way is to use per-user groups (i.e
first of all, dns is primarily a udp service, not a tcp service
i tried a search for freebsd ip tools ipv6
tac is useful to reverse the line order of a file - (also bsd tail -r can reverse the line order)    tac file | awk 'p { if( p&gt;$1 ) print p-$1; else print p } { p=$1 }'    if, for some reason, you can't use tac or want to use awk exclusively, you can use awk to read the entire file into memory via an array, and end{} process the array in reverse order
i think its name is "toggle scale" on the keyboard shortcuts settings. 
in this case when you have no physical access to the remote server, you must get in touch with all those includes and excludes
i imagine you had a yum update bringing the "command line" column
awk (also check awk info) is beautiful with that sort of question
the fuser utility is bound by standards as below:  the rational for this to have diagnostic information output to stderr
to make your ssh client ignore your configuration file, use ssh -f /dev/null username@example.com
a storage pool of type dir is a directory path
similar to archemar's suggestion, you could script this with ed:  printf %s\\n ${linenr}m${addr} w q | ed -s infile   i.e.  linenr                      #  is the line number m                           #  command that moves the line addr=$(( linenr + 1 ))      #  if you move the line down addr=$(( linenr - 2 ))      #  if you move the line up w                           #  write changes to file q                           #  quit editor   e.g
glibc upgrades often require restarting running daemons (because the name service switch [nss] abi changes, or just to get the daemon to actually used the upgraded version)
what you want is a multiseat xxorg configuration
first of all, crtime is tricky on linux
tmux new -d -s my-session 'echo window-1 pane-1; sleep 8' \; \           split-window -d 'echo window-1 pane-2; sleep 6' \; down-pane \; \             new-window -d 'echo window-2;        sleep 4' \; next-window \; \                 attach \;   the above is a running example of the general idea ..
gnu (gnu is not unix) is an operative system, created by richard m
your best best is to set up a secure shell daemon on the system (if it's not already running) and use paswordless keypair authentication
you could also consider an approach using join since you want sorted output in the end
you could use :  find 
to detect an ssh session, use $ssh_client.  to distinguish between local and remote sessions, there are two possible approaches: client-side or server-side
make sure netcat is installed on the debian server, and use proxycommand in your local ssh configuration (~/.ssh/config).  host kubuntu_desktop   proxycommand ssh debian_server nc localhost 1234  
systat(1), top(1) and ps are your best choices.  at some point you were able to mount procfs on openbsd - see mount_procfs(8) but this was recently removed from the standard configuration
given you can download the source rpm (srpm) i'd download that and use rpmbuild to rebuild it myself.  step #1 - install any dependencies  this will interrogate the downloaded srpm and install anything that maybe missing.  $ sudo yum-builddep --nogpgcheck netbsd-rump-20130704-2.1.src.rpm  loaded plugins: fastestmirror loading mirror speeds from cached hostfile  * base: mirror.team-cymru.org  * epel: mirror.steadfast.net  * extras: ftpmirror.your.org  * updates: mirrors.gigenet.com checking for new repos for mirrors getting requirements for netbsd-rump-20130704-2.1.src no uninstalled build requires   step #2 - setup rpmbuild  install the rpm developer tools.  $ sudo yum install rpmdevtools   setup your rpmbuild area.  $ rpmdev-setuptree   step #3 - install developer tools  install the developer tools (gcc, etc.).  $ sudo yum install gcc   you can also install a developers group, for example, "c development tools and libraries".  $ yum groups list | grep dev    development and creative workstation    c development tools and libraries    development tools    rpm development tools  $ yum groups install "c development tools and libraries"   step #4 - rebuild netbsd-rump  now we rebuild rump.  $ rpmbuild --rebuild netbsd-rump-20130704-2.1.src.rpm    step #5 - install the resulting rpm.  $ sudo  yum localinstall \     $home/rpmbuild/rpms/x86_64/netbsd-rump-20130704-2.1.x86_64.rpm   references   centos rpm tutorial part 1 - building your own rpms  
there is a utility which will lookup user information regardless of whether that information is stored in local files such as /etc/passwd or in ldap or some other method
edit unfortunately, my initial test was a bit hasty
you can use aptitude to check which packages provides an specific site:  aptitude search '?origin(unofficial multimedia packages)' p   2mandvd                         - video dvd creator                          p   2mandvd:amd64                   - video dvd creator                          p   2mandvd-data                    - video dvd creator (data files)             p   aac-enc                         - fraunhofer fdk aac codec library - fronten p   aac-enc:amd64                   - fraunhofer fdk aac codec library - fronten p   aacgain                         - lossless mp4 normalizer with statistical a p   aacgain:amd64                   - lossless mp4 normalizer with statistical a p   aacplusenc                      - high-efficency aac (aac+) encoder
good way  normally you can't do this with grep but you can use other tools
idea #1 - directory already exists  try running the command rpm -uvh --test /downloads/crontabs-1.10-33.el6.noarch.rpm first to see if it reports anything out of the ordinary
use:  sed '/^&lt;?xml/d' filename   under gnu sed, \? means zero or one of the preceding character
you can download the rpm here.  i successfully installed the noarch rpm on my fc16 kde environment.  sudo yum localinstall /path/to/stackapplet-1.5-2.noarch.rpm  or  sudo rpm -uvh "https://launchpad.net/stackapplet/1.5/1.5/+download/stackapplet-1.5-2.noarch.rpm"  the applet shows up in the system widget on my panel. 
you can use the tool iostat to collect the disk utilization information
i was successfully able to get xvfb running without root
find "$dir" -printf "%s %p\n" | sort -n | tail -1 | {     read -r size name     printf "maximum file size: %d\n\t%s\n" "$size" "$name" }   since the read occurs in a subshell, i'm using braces to group the read command with the printf command
most unix tools, like split, are file format agnostic
the formatting in the index is controlled by the index_format setting -- it's generated by mutt
i found a complete answer (which is well in line with the answer by permat and ramesh) on https://forums.gentoo.org/viewtopic-t-733367-start-0.html:     ciaranhearne: "basically i had to define dmix as a plugin before i   could use it"   while this worked great with just alsa, i couldn't get pulsaudio/apulse to work (for skype)
smbpasswd can do several things, and one of its main purpose is to let an user change his password (even he's working on a remote client machine).  for instance, on a workstation, a client can type this to change his password:  smbpasswd -r pdc.mydomain.com   -r needs the pdc dns name, and one may also use -u in case the smb login name is different from the unix login name.  so, as you can see, smbpasswd is also a client tool. 
you can build a patched cp and mv which then both support the -g switch to show progress
if you check reading from /dev/urandom gives eof after 33554431 bytes and follow the discussion, it points to another bug report where ted tso states...     ...that commit 79a8468747c5 causes reads larger than 32mb results in a   only 32mb to be returned by the read(2) system call
editors can follow one of two strategies when you save a file.   create a new file, then move it to replace the old one
as there are more ways to achieve the goal, i list two cli options, where apt is, subjectively, the best and recommended:  1st choice: apt (and apt-get)  sudo apt install ./long-package-name.deb   note, that i specifically mean apt, not apt-get, because it does not auto-complete the file names, otherwise you may of course do this, if you insist on using apt-get, e.g
the easiest method i can think of is to make a ~/bin directory inside your $home, add a symlink ~/bin/gcc to /usr/bin/gcc-4.4 or wherever your gcc-4.4 is located, and make sure ~/bin is at the beginning of your $path like this:  export path=~/bin:$path  
you can run bindkey with no arguments to get a list of existing bindings, eg:  # enter vi mode chopper:~&gt; bindkey -v  # search for history key bindings chopper:~&gt; bindkey | fgrep history "^[oa" up-line-or-history "^[ob" down-line-or-history "^[[a" up-line-or-history "^[[b" down-line-or-history   in emacs mode, the binding you want is history-incremental-search-backward, but that is not bound by default in vi mode
no there is no chance of losing during compression
   how do i know if my distro of choice supports it?   it's been in the kernel since 2004, so one way or another they all do
use the mktemp utility to create a temporary file with an unpredictable name
based on your answer, it sounds like you're actually trying to avoid typos.  the best way to do this, is to put  set -u   at the top of your shell script.  then, instead of a typo expanding to an empty string, it is a fatal error.  if $btest; then     echo "is active" fi  # =&gt; is active   versus  set -u if $btest; then     echo "is active" fi  # =&gt; typo.sh: line 4: btest: unbound variable     alternatively, if you want to assign defaults to variables, it's usually best to do all the assignments at the top of the script like this:  : ${btest:=false}   finally, if you really want to type out a default value every time, you could use  if ${btest:-false}; then     echo "is active" fi  
try:  auto dummy0 iface dummy0 inet static    address 10.10.0.1    netmask 255.255.255.0    post-up ifconfig dummy0 multicast  
to allow unauthenticated login over ssh using pam, all of the following must be configured:   the user account must have “no password” set
you can run a program simply by typing its name (and enter, of course).  to run a program "in the background", giving you control of your terminal again, you can append &amp;.  so:  gvim /etc/hosts    # runs gvim and waits until it's finished   but:  gvim /etc/hosts &amp;  # runs gvim and returns control to the terminal   therefore, this can be used to start three programs, one after the other:  kontact &amp; rekonq &amp; something_else &amp;   if you can type fast enough they'll appear to start simultaneously
the reasons are largely historical and pragmatic and date back to the technology that was incumbent in the 1980s and 1990s when much of the work on distributed systems architecture was being done:   nfs is an open standard and is supported on pretty much every unix system built from the late 1980s onwards
i made one tweak:  $ synclient maxdoubletaptime=100   it was by default set to 180. 
there are various ways you can check whether the user is root (to then set the ps1):   the user's name, using $user, $(whoami) (the output of $(whoami)
it is possible for the terminal.app to start a specific shell for new windows instead of your login shell
i don't know we can filter with engine id in netflow records
(the below is from ubuntu, but the same technique obviously works on debian as well)  $ apt-cache show screen package: screen priority: optional section: misc installed-size: 950 maintainer: ubuntu developers &lt;ubuntu-devel-discuss@lists.ubuntu.com&gt; original-maintainer: axel beckert &lt;abe@debian.org&gt; architecture: amd64 version: 4.1.0~20120320gitdb59704-9 depends: libc6 (&gt;= 2.15), libpam0g (&gt;= 0.99.7.1), libtinfo5 suggests: iselect (&gt;= 1.4.0-1) | screenie | byobu filename: pool/main/s/screen/screen_4.1.0~20120320gitdb59704-9_amd64.deb size: 645730 ...   if the package exists, information will be displayed
if you use tc gui, you should set some favorite volumes -- you can read more about it here
looking into the readme indeed helps sometimes :)  this behaviour is intentional to give different users the chance to have their own settings.  in short the nvidia-settings config file is stored in ~/.nvidia-settings-rc and can be executed by calling nvidia-settings --load-config-only at startup.  for more details, here's the relevant part of the readme:     4) loading settings automatically      the nvidia x driver does not preserve values set with nvidia-settings   between runs of the x server (or even between logging in and logging   out of x, with xdm, gdm, or kdm)
to suppress stdout:   yourcommand  1&gt;/dev/null    to supress stderr  yourcommand  2&gt;/dev/null   since bash 4 you can suppress both:  yourcommand &amp;&gt;/dev/null   you could also disable kde's debug information with kdedebugdialog tool and disable output for selected modules (or all debug output). 
you can use ifconfig -a or ip a l. 
there is an "trackerbird 1.0.2" addon in thunderbird
the update-grub command is just a script which runs the grub-mkconfig tool to generate a grub.cfg file
loop over the input
i try to start it via normal service call:# service openvpn start work  no, that's not normal
you can search through the cached package meta data:  yum -c search mysearch   this way yum won't update the local meta data, therefore your search will be a little bit faster.  i prefer to create a local file with all the packages doing this way:  yum list all &gt; yum-package-list.log   then i can grep what i'm searching:  grep -i mysearch yum-package-list.log   that's all...  from time to time i'll execute again the yum list all, to update the list.  important note  from the fedora manual   list item   by default, current versions of yum delete the data files and packages that they download, after these have been successfully used for an operation
the different parts can be put in shell functions :  awkfilter() {     awk '{ if ($8 ~ "isad") {print $2, $5, "se"} else {print $2, $5, "ant"} }' $1 }  toupper() {     tr [:lower:] [:upper:] }  dosort() {     sort -t' ' -s -k3 }  awkfilter "/var/log/apache2/other_vhosts_access.log" | grep -v '127.0.0.1' | tr '[' '\0' | toupper | dosort   then you could make things optionnal more easily :  dosort() {     rev=""     if [ "$2" == "reverse" ]     then         rev='-r'     fi     sort -t' ' -s -k$1 $rev }   when your command-line is starting to be really long, writing it in a script and breaking it in parts (with functions) is usually really helpfull. 
your test probably isn't long enough to average out the overhead of running cp, so i don't know if that's a good test
i just checked on my centos 5 system - after:  chgrp kmem /usr/sbin/dmidecode chmod g+s /usr/sbin/dmidecode   it is still not possible to get dmidecode working - the group kmem has only read-rights for /dev/mem - it seems there is a write involved to get to the bios information.  so some other options:   use sudo use other information sources (e.g
   this is due to mesa-dri broken packages you can try one by one   commands on terminal to fix this issues.   $ sudo apt-get autoclean $ sudo dpkg --purge --force-all libgl1-mesa-dri $ sudo dpkg --purge --force-all libgl1-mesa $ sudo dpkg --purge --force-all libgl1-mesa-glx:i386 $ sudo dpkg -r --force-all libgl1-mesa-dri $ sudo dpkg -r --force-all libgl1-mesa-glx $ sudo dpkg -r --force-all libglapi-mesa:i386 $ sudo dpkg -r --force-all libgl1-mesa-dri:i386 $ sudo dpkg -r --force-all libgl1-mesa-dev $ sudo dpkg -r --force-all libqt4-opengl-dev $ sudo dpkg -r --force-all libgl1-mesa-dri $ sudo apt-get -f install $ sudo apt-get update $ sudo apt-get upgrade $ sudo add-apt-repository ppa:gregory-hainaut/pcsx2.official.ppa $ sudo apt-get update $ sudo apt-get install pcsx2   after that pcsx2 configuration and installations steps are according to as shown in tutorial. 
 first, unlikely you have 96x96 existing picture, so most of the case you need to convert
stty susp tells the terminal driver what character (actually what byte), when received unescaped from the terminal (via the wire if a real terminal, or written to the master side of a pseudo-terminal in case of a terminal emulator or sshd...), when isig is on, causes a sigtstp to be sent to the foreground job.  there's no key or keyboard involved here
if the screen and input devices (keyboard and mouse or trackpad) froze, the first place to start by looking would be in /var/log/xorg.0.log (assuming that xorg is running on the first display server).  if that doesn't yield any immediate clues, the next logs to check would be /var/log/messages.log and /var/log/dmesg.log
processing xml as text is generally not a robust solution, but if you insist on doing it then you could perhaps make use of sed's hold space  e.g.  sed -e '/&lt;id&gt;[0-9]*&lt;\/id&gt;/h' -e '/&lt;root&gt;/{x;p;x;}' file.xml  
well, you can tell if your cpu has fpu capabilities with the data stored in /proc/cpuinfo and filter it with grep fpu  $ grep "fpu" /proc/cpuinfo  fpu     : yes fpu_exception   : yes flags       : fpu vme de pse ...   and for info, what type of cpu are you playing with? :)  edit for arm proc, look for vector floating point unit (vfp), some info here.  ex:  # cat /proc/cpuinfo processor       : armv6-compatible processor rev 7 (v6l) bogomips        : 697.95 features        : ..
in your dockerfile for the container, you can specify various environment variables to be persisted through containers.  for example, in this case, you would add this snippet before the cmd entrypoint:  [...] env java_home /usr/lib/jvm/java/bin [...]   see this link for more details: https://docs.docker.com/engine/reference/builder/#/env 
standard sed can't call a shell (gnu sed has an extension to do it, if you only care about non-embedded linux), so you'll have to do some of the processing outside sed
in solving this issue, the information provided at http://www.ivarch.com/blogs/oss/2007/01/resize-a-live-root-fs-a-howto.shtml was pivotal
you can check using :  for user in $(awk -f: '{print $1}' /etc/passwd);  do      printf "%-10s" "$user" ; su -c 'umask' -l $user 2&gt;/dev/null done   to avoid checking system user do :  for user in $(awk -f: '( $3 &gt;= 500 ){print $1}' /etc/passwd);  do      printf "%-10s" "$user" ; su -c 'umask' -l $user 2&gt;/dev/null done   output:  ram       0022 shyam     0022 suraj     0022 vinayak   0022 javed     0022  
re-install initscripts (as root):  apt-get --reinstall install initscripts   to figure this out for yourself in future:  apt-file search /etc/init.d/skeleton   you may need to install apt-file and run apt-file update as root first. 
git uses isatty() to check whether stdout is a tty: this is used to see if a pager must be used (pager.c) as well as colors (color.c). 
just run mount without args. mount |grep export 
at first you need to unmount the second device again, before you proceed with the following steps:  you will have to add the device /dev/vdb into your logical volume group volgroup, you can do this using vgextend.  vgextend volgroup /dev/vdb   after this you can first grow the logical volume lv_root to the size of the group, using lvextend.  lvextend /dev/mapper/volgroup-lv_root -l+49g   then you need to grow the file system on the logical volume with fsadm.  fsadm resize /dev/mapper/volgroup-lv_root   here are more details about resizing the file system: grow file system 
so, you can have the output appear in the other terminal—though i doubt you really want to
use grep like this:  $ grep -v -x -f -f forbidden.txt input.txt   that long list of options to grep means   -v invert the sense of the match, i.e
you're in zsh, not bash.  in zsh, repeat (inspired from csh repeat) is a construct used to repeat commands.  repeat 10 echo foo   would echo foo 10 times.  if you want to call your  repeat, you'd need to quote it so that it's not taken as the repeat reserved word.  $ echo $zsh_version 5.0.2 $ 'repeat'() echo "$*" $ type -a repeat repeat is a reserved word repeat is a shell function $ repeat 2 echo foo foo foo $ "repeat" 2 x 2 x   best would be to use something else for your function name though. 
it looks like you want to insert the content of that file after the last occurrence of &lt;path start="process_.  you could do:  awk '   /path start="process_/ {print saved $0; saved=""; n++; next}   n {saved = saved $0 rs; next}   {print}   end{system("cat tmp.xml"); printf "%s", saved}' process.xml   though that would mean storing the part of the file from the last occurrence of path start="process_ to the end in memory.  or you could slurp the whole files in memory with:  perl -0777 -pe 's/.*path start="process_.*?\n\k/&lt;stdin&gt;/se                ' process.xml &lt; tmp.xml   a variant that checks for the &lt;/fork&gt; on the next non-empty line:  perl -0777 -pe 's{.*path start="process_[^\n]*\n\k(?=\s*&lt;/fork&gt;)}{&lt;stdin&gt;}se                ' process.xml &lt; tmp.xml   a variant that aligns the indentation and adds an extra newline character if missing in tmp.xml:  perl -0777 -pe 's{(?s:.*)(^\h*).*path start="process_.*\n\k(?=\s*&lt;/fork&gt;)}{  $insert = &lt;stdin&gt;;  $indent = $1;  $insert =~ s/^/$indent/gm;  $insert =~ s/\n?$/\n/;  $insert}me' process.xml &lt; tmp.xml   with  -0777 -pe 'code' file, perl runs the code, with $_ being the content of the file and prints that $_ (here modified by the code) afterwards.  in there, we have just one substitution command s{pattern}{replacement}flags.  the trick to get the last occurrence of the pattern in all those commands is the leading greedy .* (here under the s flag so it also matches newline characters)
you can use the --init-file option like this bash --init-file &lt;(echo "echo hello")
$home is an environment variable that is set on user login
netstat with -p switch will show you which programs listen to which ports or use network connections at any given time
there are essentially two options for going through the whole directory tree:  either you can use find(1):     find 
you can setup a simple local caching dns server with dnsmasq, and add to the configuration file one or more lines     ignore-address=&lt;ipaddr&gt;      ignore replies to a-record queries which include  the  specified address
when you run an executable file ( or rather in unix/linux world - a file with executable rights/flag on) like so :   $ ./jdev  you then mark with . that you want to run a file inside your working directory (directory that you are currently in) that is named jdev and has executable rights for the user that is launching it (you have to note that it can still be a link to other file, you can check that by typing ls -l jdev in the terminal)  ( see file permissions in linux/unix )  when you run it as   $ jdev  then most likely there is jdev installed somewhere on the system and you have it in $path ( e.g
as christopher suggested, archivemount can achieve this
vcard is not only executable by root, but also by any member of the group root
for fedora, try this.  disclaimer: this is mostly copy-pasted from here.  i'm not really sure if this will work (i don't use fedora), but it will help you install hal, and maybe it will
yes, you can by enabling menu select:  zstyle ':completion:*' menu select zmodload zsh/complist ... # use the vi navigation keys in menu completion bindkey -m menuselect 'h' vi-backward-char bindkey -m menuselect 'k' vi-up-line-or-history bindkey -m menuselect 'l' vi-forward-char bindkey -m menuselect 'j' vi-down-line-or-history  
either rpm -q httpd or /usr/sbin/httpd -v should work. 
as described here should be enough to   timedatectl set-timezone &lt;your_time_zone&gt;  
the files and subdirectories of the directory also need to be group-owned by the group.  the directory's owner (or root) needs to:  chgrp -r groupname /path/to/directory chmod -r ug+rwx /path/to/directory find /path/to/directory -type d -exec chmod g+s {} +   making the directories setgid (e.g
this doesn't work because the redirection is executed by the shell, not by the command it applies to
there are utility commands named last and lastb to list the logins and attempted logins on most unix distributions
you have to use the --tags option of git push
this is unfortunately impossible without hacking on dolphin
you're missing a space after 644.  also, 644 is probably not what you want on a directory
when you have multiple versions in a yum repo, yum will always get the latest version with just a bare yum install example. 
chances are that the command's output is buffered
yes and no:   yes, you can do that with mock
please go through this blog as i think it exactly describes what you need : how-to-update/upgrade-kernel-for-puppy-linux i think this site could also help you.
you could use the following steps as normal user  tar xvjf gmp-6.1.0.tar.bz2 cd gmp-6.1.0 ./configure --prefix=${home}/gmp/6.1.0 make  make install   this will install gmp in ~/gmp/6.1.0
touch is specified as changing file access and modification times; changing the change time is a side-effect of the change to the file's metadata, and touch doesn't have any control over that (see also the futimens() and utimensat() functions used by touch).  -a and -m are understood in this context: by default touch changes both access and modification times (and the system updates the change time); with -a, it only changes the access time, with -m, it only changes the modification time.  you can see the difference if you specify a time other than the current time: the access and/or modification times will be changed to the value you specify, but the change time will be updated to the current time. 
you're running into zfs's compression
   can i force yum to use old version of repository so that the package can be found?   no you just kind of have to go based on what the repo has available
neither efficiency nor builtinness is the biggest difference
you just need to escape the dot in your sed command and everything will be fine. like this:  sed 's/\.$//'   because in the case you don't escape it, .$ will match to any character at the end of string.  also you can put all your sed + grep + cut into just one sed:  sed 's=/[^/]*$==;s/\.$//' filename  
adsf—appropriately "a dead simple fileserver"—seems like a great solution to this:  $ gem install adsf fetching: adsf-1.2.0.gem (100%) successfully installed adsf-1.2.0 parsing documentation for adsf-1.2.0 installing ri documentation for adsf-1.2.0 done installing documentation for adsf after 0 seconds 1 gem installed $ $ adsf [2015-12-06 08:24:03] info  webrick 1.3.1 [2015-12-06 08:24:03] info  ruby 2.1.2 (2014-05-08) [x86_64-linux] [2015-12-06 08:24:03] info  webrick::httpserver#start: pid=811 port=3000  
it is not possible to hide the existence of a file if the user could list it:  $ ls -l permtest/insidedir/doesexist -rw-r--r-- 1 root root 0 aug 10 01:55 permtest/insidedir/doesexist   even if both directories (permtest and insidedir) are own by root and have only x permissions:  $ sudo ls -la permtest/insidedir/ total 8 d--x--x--x 2 root root 4096 aug 10 01:55 . d--x--x--x 3 root root 4096 aug 10 01:54 .. -rw-r--r-- 1 root root    0 aug 10 01:55 doesexist   $ ls -la permtest/ ls: cannot open directory permtest/: permission denied  $ ls -la permtest/insidedir/ ls: cannot open directory permtest/insidedir/: permission denied  
the least effort method is mdns (multicastdns).   mac os x and ios have bonjour built in which implements mdns. for windows mdns resolution can be obtained via apple's bonjour print services for windows
you can use the pax command (a standardized replacement for tar and cpio)
thinkpads are very popular with linux users, so there's a lot of documentation out there. the standard resource for thinkpad users is thinkwiki.  it's quite likely that a standard distro install will be sufficient
there is no support for ip address sets in the known_hosts file
all of the global keyboard shortcuts are in "settings -> system settings -> shortcuts and gestures -> global keyboard shortcuts"
this will drop you into an initramfs shell:   start your computer
use 121.241.34.208/30, which is equivalent to 121.241.34.208/255.255.255.252
assuming you are on ubuntu - which uses dash to run system scripts:    that file, /etc/update-motd.d/00-header, is executed by /bin/dash, (not /bin/bash,) which is pretty minimalistic (and fast) - it seems to not support the "\e" in this place - use "\033" instead.  it is different in when to expand escape codes. 
since the sudoers file permits the specifying of hostnames in the rules, sudo needs to know what the name of your ubuntu machine is.  because of this, sudo collects a list of all interfaces on your ubuntu machine (loopback and "real")
sleep.target is specific to system services
you do not want to do this
evolve os is built from scratch and is an independent linux distribution
update-alternatives changes the application to use to open a web browser, not the application to use to open a web page
in general linux has very good support for network devices
so, i gather you want to check a process with a given name, and do some choice based on if it's running or not, and how long it has been running?  to find the process id of the process, you could grep the output of ps, or use pidof as in the example linked in the comments, or similarly, use pgrep
add option -i when running ssh-copy-id
try using libtrashcan
just press ctrl + h
you are almost there you just need to make sure traffic gets back to b
i just found that tmux seems to expect xterm keycodes, not minding the screen terminal type
you can use eyed3 which is a great utility for handling id3 tags
from the linux mint forum i found the following post, extract, compress in right-click menu
   mimeopen -a 'picture.jpg'   this is what you need  it will give you output like this  please choose an application      1) shotwell viewer  (shotwell-viewer)     2) firefox web browser  (firefox)     3) image viewer  (eog)  
mplayer has -softvol-max option that allows to amplify loudness
crontab -r should remove the current user's crontab
eval does a printf of its arguments and then runs it as a command
assuming you already have the package installed, rpm -q --whatprovides /usr/lib64/libglut.so.3 will show the name of the package providing the file.  (inapplicable as you don't want to use yum) : if not already installed, then yum provides /usr/lib64/libglut.so.3 or simply yum provides 'libglut*' will search the yum repos and provides the information. 
note that you don't have to read the file beforehand, sed has the r command that can read a file:  $ printf -v var "%s\n" "s1random stuff" "s2 more random stuff" "s1 final random stuff"  $ echo "$var" s1random stuff s2 more random stuff s1 final random stuff  $ sed '/^s2/r file.txt' &lt;&lt;&lt; "$var" s1random stuff s2 more random stuff line 1 line 2 s1 final random stuff  
after extensive study of the openvpn manual, i have found an answer for my question:  i you don't want the routes to be executed automatically, but to be handled by your own tool, use the following option:      --route-noexec           don't add or remove routes automatically
disable built-in keyboard and trackpad with inputclass  one can disable the built-in devices by setting the ignore option in an input class to true or on
the ups output should be regulated, and its either going to be at the specified/configured voltage, or at 0
assuming you have physical access to the server, you can either create a live medium which has a headless boot routine including an ssh-server to be started and then access the server via these ssh-credentials or - the simpler approach - in case you have a monitor and a keyboard available, plug them in and simply boot into the system.  then mount the original hard drive and edit the /etc/group file accordingly (i.e.: sudo:x:&lt;integer_number&gt;:&lt;username&gt;).  as a hint for the future: imho having an active root account (i.e
method #1 - dpkg.log  you can look through the /var/log/dpkg.log files but this could be problematic since these files are rotated by logrotate and can get deleted over time
you use bg normally to run programs in the background, which has no console interaction, like most program with a graphical user interface
i would use awk:  $ awk 'nr&gt;1{$1=$1"_i1"}1;' test.txt          a1a a1b a1c a1d a1e  tr6764_c0_g2_i1 0.00 0.02 0.00 0.00 0.00 tr25644_c0_g1_i1 0.00 0.00 0.00 0.00 0.00 tr4897_c0_g1_i1 58.50 177.26 130.35 8.52 102.66 tr900_c0_g2_i1 0.00 0.00 0.00 0.00 0.00   or, if you need to keep the whitespace unchanged, perl:  $ perl -pe 's/\s/_i1$&amp;/ if $.&gt;1' test.txt          a1a a1b a1c a1d a1e  tr6764_c0_g2_i1    0.00    0.02    0.00    0.00    0.00    tr25644_c0_g1_i1   0.00    0.00    0.00    0.00    0.00    tr4897_c0_g1_i1    58.50   177.26  130.35  8.52    102.66   tr900_c0_g2_i1     0.00    0.00    0.00    0.00    0.00      
it happens to be finally very simple because of my backup file
do not use this option if your x server is accessible from the open internet
you can use perl:  $ perl -e 'print pack "i&gt;", shift' $(( random &lt;&lt; 17 | random &lt;&lt; 2 | random &gt;&gt; 13 ))  
at one point this was implemented as a patch to gnome-terminal, then later added to vte (the library which both use for almost all of their functionality).  for instance, in 2012, steve zesch commented in an early bug report for mate terminal   mouse scroll wheel does not work in apps using curses
preamble  this worked for me
what kind of snmp-capable device are you going to monitor (with ip address my_ip_address)?   the snmp "community string" is kind of like a password
it's trying to call javac, the java compiler
i found the answer
windows will overwrite the boot sector whenever you install it, upgrade it to a new version, or use tools like bootrec /fixmbr, bootrec /fixboot, or the older fdisk /mbr
it should be  #!/usr/local/bin/osh   if your shell is in /usr/local/bin
usb 2.0 or 3.0 is a hardware specification and has little to do with the os
curl can display the file the same way cat would
-k doesn't work like that, it works like this:  put   -u username:password  in the sample.txt file and do  curl -k sample.txt "http://localhost:4502/content/dam/my folder" 
in the kickstart file you're looking for:  ignoredisk --only-use=sda   this will cause every disk except sda to be ignored by the install.    the sd letter should remain the same (since it's based off of which sata port is used).  if you also don't specify autopart or part sections in your kickstart the install will pause before it wipes your drive (to ask how you want to partition
add to ~/.config/gtk-3.0/gtk.css:  .window-frame {   box-shadow: none;   margin: 0; }   (via https://bbs.archlinux.org/viewtopic.php?pid=1416334#p1416334)  i had to restart x for it to take effect - sighup awesome was not sufficient. 
yes
circular i/o loop implemented with tail -f  this implements a circular i/o loop:  $ echo 1 &gt;file $ tail -f file | while read n; do echo $((n+1)); sleep 1; done | tee -a file 2 3 4 5 6 7 [..snip...]   this implements the circular input/output loop using the sine algorithm that you mentioned:  $ echo 1 &gt;file $ tail -f file | while read n; do echo "1+s(3*$n)" | bc -l; sleep 1; done | tee -a file 1.14112000805986722210 .72194624281527439351 1.82812473159858353270 .28347272185896349481 1.75155632167982146959 [..snip...]   here, bc does the floating point math and s(...) is bc's notation for the sine function.  implementation of the same algorithm using a variable instead  for this particular math example, the circular i/o approach is not needed
i'd use perl for that, or at least awk.  perl -ne '     begin {         print "\"job name\", \"time\", \"schedule\", \"machine\", \"description\", \"command\", \"\n";     }     chomp; s/^\s+//; s/\s+$//;     if (($_ eq "" || eof) &amp;&amp; exists $fields{insert_job}) {         print "\"", join("\", \"", @fields{qw(insert_job start_times days_of_week machine description command)}), "\"\n";         delete @fields{qw(insert_job)};     }     if (/^([^ :]+): *(.*)/) {$fields{$1} = $2} '   explanations:   the begin block is run once at the beginning of the script, the rest runs for every input line. the line that begins with chomp strips off leading and trailing whitespace. the first if line triggers on empty lines (paragraph separators), if the field insert_job is present. the delete line removes the insert_job field
maybe this is not obvious enough from the documentation, but: once you have that bootable usb media and boot it to the live environment, there is a window with two big choices: try fedora or install to hard drive:    hopefully, everything should be clear from there
in case of doubt, use 0xda (“raw / nōn-filesystem data”).  that will always work, and be ignored by virtuall all oses, so geli can just use the corresponding block device. 
there are multiple methods:  ls only  ls lazer_??????   ls and egrep  ls | egrep '^lazer_.{6}$'   find  find 
one option is to search with prefixed spaces, such as: /  alias, where there are two spaces before the word "alias" to prevent false positive matches where "alias" appears as part of another sentence
to answer your question, it is not working because greek characters are non-latin, unicode characters, and:     unlike par, fmt has no unicode support, ...   https://en.wikipedia.org/wiki/fmt  additional notes  the second part of your question on how-to, unfortunately,  although there seems be a fairly recent technical report regarding how to wrap unicode, for example heninger, unicode line breaking algorithm , 2015-06-01 http://www.unicode.org/reports/tr14/ however this seems to be specification only, no actual implementation or mention of software how-to examples
log in as "normal" user (using x11-forward), then su - -c yast2. 
okay, so i was having exactly the same problem, which is what brought me to this question
case is only for pattern matching, it won't do arithmetic evaluation (except maybe if you consider zsh's &lt;x-y&gt; extended pattern matching operator)
you may put default configurations in /etc/skel so that useradd(8) can copy files in /etc/skel whenever it creates new user's directory by '-m' option.  note that this is used only for the new-user
ask it.  $ python -v python 2.6.4  
you can connect to the host using sftp -r and then get the directory
just replace all routers by one manualroute that points directly to the new mx:  begin routers redir:   driver = manualroute   domains = *   transport = remote_smtp   route_list = * 12.34.56.78   here 12.34.56.78 - is an ip-address of your new mx where all messages should go. 
rm /dev/root   don't over think it 
i'm not on hp-ux, so this has only been checked against xd(1):  xd -b -an -v $filename    -an prevents the offset from being shown -b defaults to single bytes, (octal for od, hex for xd) -v prevents identical lines from being replaced with *   (a lot of systems, mine included, have od but not xd
yes if you choose an install option it will start the process of installing to disk which could overwrite your hard drive if that process is completed.  instead you could: the following link will show you how to setup a persistent usb installation of linux mint
-you can just add the definitions on the "/etc/samba/smb.conf" on the final of the file the definitions that permit share the folder on the samba, like this simple sample...    [shared]       path      = /home/user/shared    &lt;= here we just put the                                           path of the folder                                           that we goes share.       available = yes       browsable = yes       public    = yes       writable  = no   ...where we just stay defined the shared folder, with this definitions the folder are disposable, can be browsable, are public everyone can access it! but is not writable is just for read no have write access!!! this shared folder on the network. 
it is not clear what you mean when you contrast "command" and "line"
what script writes to what log file, depends on the script
what about  /dev/mapper/myvgname--vg-images /images  ext4    defaults 0       1   in fstab ?  (i assume you have formated it ext4 ) 
if you are using bash, you can use the fc command to display your history in the way you want:  fc -ln -1   that will print out your last command
i think you've already noticed that some sort of "server" is needed
you can use   gunzip -r personal   which works the same as   gzip -d -r personal   if gzip on your system not have the -r option (e.g
do it like this:  sed -i "/$variable/c \\${variable}1" file.txt   changes:   if you have a \ before a $, it makes the shell insert a literal $ in the string
$ readlink /sys/class/net/wlan0/device/driver ../../../../bus/pci/drivers/ath5k   in other words, the /sys hierarchy for the device (/sys/class/net/$interface/device) contains a symbolic link to the /sys hierarchy for the driver
no, there is no safe way to do this in the long term
with gnu sed:  sed -z 's/dcr/&amp;\ncheck/2' &lt;input &gt;output   for non-uptodate versions:  sed '/dcr/{p;s/.*/1/;h;g;/^\(\n1\)\{2\}$/s//check/p;d}' &lt;input &gt;output   if there are more than 1 occurence dcr in line:  sed ' /dcr/{p       x                               # tests if already have met pattern       /^\(\n\a\)\{2\}/!{              #+apropriate times and, if so, cancel         x                             #+the rest of commands         s/dcr/\a/g                    # exchange dcr by \a symbol         s/^[^\a]*\|[^\a]*$//g         # delete everything before &amp; after it           s/[^\a]\+/\n/g                # substitute everything between by \n         h         g         /^\(\n\a\)\{2\}/s/.*/check/p} # add 'check' for double pattern       d}' &lt;input &gt;output  
bash conditional expression -v var check if shell variable named var is set.  when using [[ -v $1 ]], you actually checked whether a variable named by content of $1 was set
at it's most basic; it allows traffic in both directions if you first request something. you probably can't ping because the state isn't allowing any return data.  see: user-land states 
this doesn't answer your question as stated, but it solves the underlying problem: you can upgrade to matlab 2016b, which supports gcc 4.9. 
linux provides a tmpfs device which any user can use, /dev/shm
sure
i think  # pvdisplay   shows you the physical device(s) corresponding to all your volume groups.  inter alia, my system shows, for example  --- physical volume ---   pv name               /dev/sdc6   vg name               olddebian   pv size               186.26 gib / not usable 638.00 kib   allocatable           yes    pe size               4.00 mib   total pe              47683   free pe               5443   allocated pe          42240   pv uuid               qcpayu-guwx-ssil-u2i9-26cq-qhqf-fgoyd4   this is the only one of my vgs that corresponds to a raw partition
echo always outputs to its stdout1
ok, that makes things a bit clearer
ended up with hpn-sshand pigz.  tar -cf - -c [relativefolder] [filename] | pigz | ssh px "pigz -d | tar xf - -c [remotefolder]"  improvement by power of ten.  for reference, installing hpn-ssh and pigz on ubuntu 14.04 is easy as:  # hpn-patched ssh from ppa sudo apt-get install python-software-properties sudo add-apt-repository ppa:w-rouesnel/openssh-hpn sudo apt-get update -y   sudo apt-get install openssh-server ssh -v # should have 'hpn' in it somewhere  # pigz sudo apt-get install pigz  
in addition to gilles answer,  if you still have the iso image, you could use cmp instead of checksums
you do want to mount a cd read-only with:  mount -f hsfs -o ro /dev/sr0 /cdrom   i have never used any solaris machines with multiple cds myself, but i assume you can use /dev/sr1 etc
you can capture usb traffic with wireshark. from it's wiki:       to dump usb traffic on linux, you need the usbmon module, which has existed since linux 2.6.11
it's not possible! not for that command, but you can create a sudo user with all all: no password, search online on how to cerate a sudo user to run sudo commands without password
if the positions are not important, you can sort the files and then, perform a diff
mode_switch is the old-style (pre-xkb) name of the key that is called altgr on many keyboard layouts
to do a single file:  $ avconv -i m.m4a m.mp3   to do a batch you could wrap this in a for loop:  $ for i in *.m4a; do     avconv -i "$i" "${i/.m4a/.mp3}" done   this will take all the files that are present in the current directory with the extension .m4a and run each of them through avconv
the proper way i found out on ubuntu was sudo fuser -a -k /usr/lib/gvfs. check more details with man fuser command. 
try this:  sed 's;1/0;hetero;g' my_filename 
please, see the body of my question in the thread how to get this package in texlive 2016 of debian? and particularly the section my workflow about in texlive 2016
with sed:  sed -e '$s/updated/eof/' file  
you could use the terminal multiplexer tmux to run your program in any terminal
this is possible in ubuntu using upstart and the oom score configuration option.     oom score      linux has an "out of memory" killer facility
what about something like this:  ls -ltr --group-directories-first  
perl to the rescue:  $ perl -p00e 's/\n,/,/g' file playerid,yearid,gamenum,gameid,teamid,lgid,gp,startingpos gomezle01,1933,0,als193307060,nya,al,1,1 ferreri01,1933,0,als193307060,bos,al,1,2 gehrilo01,1933,0,als193307060,nya,al,1,3 gehrich01,1933,0,als193307060,det,al,1,4 dykesji01,1933,0,als193307060,cha,al,1,5 cronijo01,1933,0,als193307060,ws1,al,1,6 chapmbe01,1933,0,als193307060,nya,al,1,7 simmoal01,1933,0,als193307060,cha,al,1,8 ruthba01,1933,0,als193307060,nya,al,1,9   i assumed here, that the split is always just before comma ,. 
try this:  #!/bin/bash while :; do     ping -c 1 8.8.8.8 &gt;/dev/null 2&gt;&amp;1     if [ $? = 0 ]; then         break     else         echo 'no internet'     fi     sleep 1 done mpg123 /home/user/file.mp3   it will show you 'no internet' message if there is no ping response
here is a little awk script i came up with that should search for lines matching your indexes
in kde the reference cd burning software is k3b, which is packaged in debian as k3b.  on the command-line you'd probably use cdrkit (the main package is called wodim). 
you could use some_command as your test condition.  while ! some_command; do sleep 1; done   the condition will remain true as long as some_command exits with an error.  or a more verbose way if you want to do additional checks:  while ! some_command do      # add more if desired     sleep 1 done  
the tree utility does not currently support sorting by size. 
the documentation for the sha2 utilities points to the documentation for md5sum which says     for each file, ‘md5sum’ outputs by default, the md5 checksum, a space, a flag indicating binary or text input mode, and the file name
when i write more complex bash scripts, i use a little function to run commands that will also print the commands run into a logfile:  runthis(){     ## print the command to the logfile     echo "$@" &gt;&gt; $log     ## run the command and redirect it's error output     ## to the logfile     eval "$@" 2&gt;&gt; $log  }   then, in my script, i run commands like this:  runthis "cp /foo/bar /baz/"   if you don't want a command printed, just run it normally.  you can either set the $log to a filename or just remove it and print to stdout or stderr
you didn't specify what certfile looks like in the first line
i tested the answer from upgraded to ubuntu 15.10 wily and get qnativeimage: unable to attach shared memory segment with the following command:  qt_graphicssystem=native dolphin   and it works! the ui doesn't have the bug anymore
it's quite simple to test this
you can stop "captive-login" with the following steps:   first delete sudo rm /usr/bin/captive-login or make backup. create a new captive login executable: sudo nano /usr/bin/captive-login write the following:  #!/bin/bash exit 0  permissions for the new captive-login executable: chmod 777 /usr/bin/captive-login   these steps work for me, i don't know if this bug is already solved. 
httr depends on the openssl and curl package. the openssl package needs as system requirement libssl-dev  ------------------------- anticonf error --------------------------- configuration failed because openssl was not found
it is given at boot time by your bootloader, for example grub.  to see with which arguments your kernel was started, do this:  $ cat /proc/cmdline   for me, this ouputs:  boot_image=/vmlinuz-3.5.0-13-generic root=/dev/mapper/crypt-precise--root ro   so the initrd/initramfs will try to mount my /dev/mapper/crypt-precise--root (encrypted lvm) logical volume as /.  you can re-configure grub to load other operating systems from your harddrive using the same kernel (multi-boot) or edit this line runtime by pressing e while selecting (not yet booting) the grub entry.  for recent debian-based distributions, changing it permanently works like this:  (be careful, you may not be able to boot into your original operating system again!)  in the file /etc/default/grub set some grub_cmdline_linux="root=/dev/mydevice" yourself and update grub by doing update-grub.  however, i recommend you to configure multiboot, otherwise it's not possible to change or update your grub configuration again easily. 
just remove the apt-listbugs file in the /etc/apt/preferences.d directory
it means that one or more lines were suppressed, because they are identical to the previous line; in this case, it means that the line starting at 00001e0 is all zeroes, same as that starting at 00001d0.  to determine the number of deleted lines, you need to look at the addresses involved and the length of each line; in this case, a single line was deleted.  if you're using od, this is controlled by the -v flag
please download memstick image from here (or you can use amd64 of course)
on debian, ubuntu and derivatives, you can use the rename perl script:  rename 's/(?&lt;=-)([0-9]+)/sprintf "%03d", $1/e' prefix-*.ext   some systems may have this command installed as prename or perl-rename
if pipes on your system are bidirectional (as they are on solaris 11 and some bsds at least, but not linux):  cmd1 &lt;&amp;1 | cmd2 &gt;&amp;0   beware of deadlocks though.  also note that some versions of ksh93 on some systems implement pipes (|) using a socket pair
use the -f flag to tail (assuming you have tail from gnu coreutils):  tail -f file-that-does-not-exist   from man tail:     -f     same as --follow=name --retry    --retry           keep trying to open a file even when it is or becomes inaccessi‐           ble; useful when following by name, i.e., with --follow=name    -f, --follow[={name|descriptor}]           output appended data as the file grows; -f, --follow, and --fol‐           low=descriptor are equivalent  
from nfs server, try  netstat -an | grep 2049   you should see something like        *.2049               *.*                0      0 49152      0 listen 10.12.13.97.2049      10.12.13.90.914       49640      0 49640      0 established    first line saysthat  nfsd (service number  2049) is listening on all interfaces  *.2049 listen next line says there is a connection from distant host 10.12.13.90 so connection goes on 10.12.13.x network   you will connect with network using netstat -in  name  mtu  net/dest      address        ipkts  ierrs opkts  oerrs collis queue lo0   8232 127.0.0.0     127.0.0.1      711988047 0     711988047 0     0      0 aggr1 1500 10.12.13.0     10.12.13.97     102780417 0     171623103 0     0      0 aggr2 1500 10.22.33.0     10.22.33.97     2944376600 0     2272441510 0     0      0   hence nfs is using aggr1. 
sort -k 1.2bn &lt; file   sorts numerically on a key starting with the 2nd character of the 1st field ignoring leading blanks (and ending at the end of the line, but that doesn't matter for a numerical sort which only considers the initial sequence of decimal digits).  note that if there's a tie, like in between these two lines:      f91he*-k92ha      7.242      3.910   4.88e+04 --   f91he*-f91hz      7.237      7.122   7.85e+05 --   then, the order will be based on the last-resort sort that compares the two lines fully as strings.  with some locales, blanks would be ignored in first instance for comparing strings in which case the f91 one would come before k92 (as f sorts before k)
based on some ideas from a few comments, i managed to cobble together a truly ugly hack that seems to work
the idea behind this is to ensure you don't receive packets targeted for the previous program listening on that port
there are three reasons, history, purpose and philosophy
from the uniq manpage:  description      discard all but one of successive identical lines from input (or standard input), writing to output (or standard output).   here the critical word is "successive"
first, get the dimensions of the base and watermark images:  #!/bin/bash infile="$1" outfile="$2" wmfile="watermark.png" basew=`identify -format '%w' "$infile"` baseh=`identify -format '%h' "$infile"` wmw=`identify -format '%w' "$wmfile"` wmh=`identify -format '%h' "$wmfile"`   then, calculate how many complete tiles we can fit over the base image:  tilew=$(($basew / $wmw * $wmw)) tileh=$(($baseh / $wmh * $wmh))   this uses integer arithmetic, so the multiply operation doesn't counteract the divide
you could achieve this by adding the following iptables rule that effectively drops the incoming echo requests on any ppp device:  iptables -a input -p icmp --icmp-type 8 -i ppp+ -j drop   this rule should be added before any rule that allows the icmp traffic
the -print0 action only attaches itself to the last test (-iname *.avi in this case)
well, the generic case that works with any command that writes to stdout is to use xargs, which will let you attach any number of command-line arguments to the end of a command:  $ find … | xargs grep 'search'   or to embed the command in your grep line with backticks or $(), which will run the command and substitute its output:  $ grep 'search' $(find …)   note that these commands don't work if the file names contain whitespace, or certain other “weird characters” (\'" for xargs, \[*? for $(find …)).    however, in the specific case of find the ability to execute a program on the given arguments is built-in:  $ find … -exec grep 'search' {} \;   everything between -exec and ; is the command to execute; {} is replaced with the filename found by find
# udevadm control --reload-rules  
find 
from the gnu find manual page:     -iname pattern           like -name, but the match is case insensitive
you can not
you're on the right track
the mouse is normally accessible under linux as a device under /dev/input and there is a virtual device /dev/input/mice that allows you to receive input from all mice in the system through a single device.  this mouse device is not normally connected to the standard input of any process though
you have a conflicting version of httpd-tools, apparently from a source other than the official centos repositories
pipe the output to:  perl -pe 's/^(.*\0)(\d+)\n/$2 $1/s'   which will output for each match: the count, a space, the filename, \0, as requested in the comment. 
there are a few ways to tell without root privileges, many of them tricky/hacky:  using /dev/disk/by-id:  find /dev/disk/by-id/ -lname '*sdx'   if this responds with something like /dev/disk/by-id/usb-blah-blah-blah, then it's a usb disk
i would simply use rsync
ls -ll /usr/bin/env shows that the symbolic link is broken
i think you are looking for xargs? so say i want to find all the .bak files in a dir and delete them
there are quite a few issues with your code
try this, it will help you
dpkg-repack 
you can use openssl to encrypt and decrypt using key based symmetric ciphers
with the starting point of running  sepolgen /path/to/binary   which gives you:  app.fc app.sh app.if app.spec app.te   to create a new selinux file context to apply to a parent directory that holds files your program/daemon will modify, you edit the app.te file and add :  type app_var_t; files_type(app_var_t)   the first line declares the new type and the second line calls a macro that does some magic and makes it a file type (turns out you cannot use a process context line app_exec_t on a file or directory), see "selinux types revisited" for more info on the different types  once you have the type declared, you need to tell selinux that your app is allowed to use it, in my case i added  allow app_t app_var_t:dir { add_name remove_name write search}; allow app_t app_var_t:file { unlink create open rename write read };   those two lines basically say, allow the app_t type which is the domain  of my app, to write/search/etc directories with the context app_var_t and allow it to create/open/delete/etc files with the context app_var_t  the last part of the puzzle is to somehow tell selinux which folder(s) and file(s) should get each type, you do this by editing the app.fc file (fc => file context)  this file only has two lines in my case:  /srv/bot/app        --  gen_context(system_u:object_r:app_exec_t,s0) /srv/bot(/.*)?          gen_context(system_u:object_r:app_var_t,s0)   the first line points straight to the binary as deployed on my servers, so this one gets the app_exec_t context.  the second line means:      apply app_var_t to the directory /srv/bot and also to all files inside the dir /srv/bot   note how the first line has -- between the path and the call to gen_context
if you set your hostname in /etc/sysconfig/network then the system will automatically set your hostname for you every time you boot.  this magic is done in /etc/rc.d/rc.sysinit
that's not an error
with parted you can see unallocated space if you use print free parted command, like parted /dev/sda print free.  or issue parted /dev/sda command, and then inside parted type print free.  example  # parted /dev/sda gnu parted 2.1 using /dev/sda welcome to gnu parted! type 'help' to view a list of commands. (parted) print free model: dell perc h710 (scsi) disk /dev/sda: 3999gb sector size (logical/physical): 512b/512b partition table: gpt  number  start   end     size    file system     name  flags         17.4kb  1049kb  1031kb  free space  1      1049kb  211mb   210mb   ext4                  boot  2      211mb   4506mb  4295mb  3      4506mb  8801mb  4295mb  linux-swap(v1)  4      8801mb  3999gb  3990gb  ext4         3999gb  3999gb  1032kb  free space  
if i understand your logic correctly, how about this:  while true; do   highest_cpu="$(ps -eo %c --sort -%cpu | awk 'nr==2 {print $1}')"   if [ "$highest_cpu" -gt 8 ]; then       notify-send 'cpu alert!' "$highest_cpu"       ...   fi   ... done   if you need a non-integer cpu usage threshold, the following bash-only solution should work:  if [[ "$highest_cpu" &gt; 9.3 ]];then ...  
if your system has the perl-based rename command you could do something like   rename -- 's/(\d+)-(\d+)/sprintf("%d-%03d",$1,$2)/e' *.jpg   testing it using the -v (verbose) and -n (no-op) options:  $ rename -vn -- 's/(\d+)-(\d+)/sprintf("%d-%03d",$1,$2)/e' *.jpg 0-10.jpg renamed as 0-010.jpg 0-19.jpg renamed as 0-019.jpg 0-1.jpg renamed as 0-001.jpg  

   will it die on its own at some point (not likely from what i understand)   not unless amazon has some daemon set up to do that sort of thing.     can i rejoin it somehow?   nope. edit: looks like the program reptyr can do it, but it's not a standard command, so you'll have to install it yourself.     ..
there are different ways of rating video edition software, and depending on which attribute (features ? user-friendliness?) you want to focus on, the answer to your question will be different.  assuming you mean "which open source video edition software is the most complete (it terms of features)", then the answer is probably cinelerra.  to get an idea of how it compares to other video edition software, i suggest you have a look at the appropriate wikipedia page. 
the recycle volume status is a particular state in the lifecycle of a tape
tee exists for this purpose; it takes a filename argument and writes the data it reads from stdin to both stdout and the file:  $ prog 2&gt;&amp;1 | tee file  
you can implement that using python and the pycurl library
the debian way is:  dpkg-reconfigure keyboard-configuration dpkg-reconfigure console-data   to make the change visible in x (else reboot):  /etc/init.d/hal restart  
brace expansion happens very early during expansion (first thing, in fact), before variable expansion
on an elf system, a core file is almost certainly a valid elf file.   $ readelf -a core  elf header:  magic:   7f 45 4c 46 01 01 01 00 00 00 00 00 00 00 00 00   class:                             elf32  data:                              2's complement, little endian  version:                           1 (current)  os/abi:                            unix - system v  abi version:                       0  type:                              core (core file)  machine:                           intel 80386  [...]   a platform specific number of "notes" are added to a notes segment so that a debugger can  find its way around, e.g
that won't work
   "is networkmanager absolutely required for managing network interfaces?"    no
the program sl purposely ignores sigint, which is what gets sent when you press ctrl+c
i don't see why you're using a while loop
i recently needed this too, and came up with this:  ssh -o preferredauthentications=password -o pubkeyauthentication=no example.com  
you can certainly change the daemon function to set the group or you can write your own mydaemon function to do it.  or in a simplest possible way just call the runuser command that daemon() uses to start your program with particular uid and gid 
yum install gstreamer-plugins-ugly.x86_64   solved it. 
in the simplest case where you want all gene names to have _n appended even if they only appear once, you can do:  $ awk '$4=$4"_"++a[$4];' file.gff  chr1 66999638 66999638 sgip1_1 1 + chr1 66999251 66999251 sgip1_2 1 + chr1 33545778 33549778 azin2_1 1 + chr1 8376144 8380144 slc45a1_1 1 + chr1 16765166 16769166 necap2_1 1 + chr1 33544713 33548713 azin2_2 1 + chr1 25069759 25073759 clic4_1 1 + chr1 33544729 33548729 azin2_3 1 + chr1 50487626 50491626 agbl4_1 1 - chr1 92349836 92353836 tgfbr3_1 1 -   note that that will change the field separator to a single space
replace ; with + at the end
the login binary is pretty straightforward (in principle)
delete or rename your wine profile directory
the hexdump shows there's only spaces (20) in the name, but there are also spaces after the second part
you can find the screenlog.0 file in screen's current working directory (cwd)
i had the same problem a while ago.  solution:   fixing your configuration: create file /etc/polkit-1/localauthority/50-local.d/50-mount-as-pi.pkla with the following contents:  [media mounting by pi] identity=unix-user:pi action=org.freedesktop.udisks.filesystem-mount resultany=yes  fixing your init script:   add a variable containing the user you would like to run udisks-glue as:  name=udisks-glue pidfile=/var/run/udisks.pid daemon="/usr/bin/udisks-glue" daemonuser=pi &lt;-- add this line  modify start-stop-daemon invocations to use the $daemonuser variable:  start)      log_daemon_msg "starting automounter" "$name" --&gt; start-stop-daemon --start --exec $daemon --chuid $daemonuser     log_end_msg $?     ;; stop)       log_daemon_msg "stopping automounter" "$name" --&gt; start-stop-daemon --stop --exec $daemon --user $daemonuser     log_end_msg $?     rm -f $pidfile     ;;   (note: i removed the -- -p $pidfile part from the first invocation
i can answer only for ubuntu. in ubuntu the root user has a locked password
you are hitting a vmware player limitation.     vmware player takes advantage of the latest hardware to create virtual machines with up to 4 virtual processors, 2 tb virtual disks and up to 64 gb of memory per virtual machines
#!/bin/bash  line='eval $(perl -i$home/foo/lib/perl5 -mlocal::lib=$home/foo)'  if ! grep -qf "$line" file.txt ; then echo "$line" &gt;&gt; file.txt ; fi   the $(...) will return the result of the command, not the errorlevel value
the exact details may depend on the filesystem, but conceptually, yes, the acls are metadata stored in the file inodes just like traditional permissions, dates, etc.  since the size of acls can vary, they may end up being stored in separate blocks
rsync -a --no-specials --no-devices would tell rsync to skip these files
i'm not exactly sure what you meant with "alsa or pulseaudio", i assume you meant pulseaudio over alsa
if i understand correctly, you want playback on your build in sondcard and capture (microphone) from external usb device.  your external device is listed as card 2: device 0 and your build in soundcard as card 0: device 0  i think your asound.conf should look something like this:  pcm.!default {   playback.pcm   {     type hw     card 0     device 0   }    playback.capture   {     type hw     card 2     device 0   } }  
the problem may be your driver
both apt-get and aptitude are convenient front-ends for the underlying dpkg command, the debian package system
this works for me in emacs 24:  (setq transient-mark-mode t)  (defun foo ()   (interactive)   (push-mark (point))   (forward-char 2)   (activate-mark))  
man and grep are your friends.  $ man bash | grep -c2 '&lt;('    process substitution        process  substitution  is  supported  on systems that support named pipes (fifos) or the /dev/fd method of naming open files
people usually want to see what they're typing (unless it's a password) :-)  the terminal accepts input at any time, and buffers it until an application reads it
i would use an initramfs
actually, tar may exclude files with --anchored     patterns match file name start   but then you have to write the whole file path (which also changes with cd):  $ cd /where/source/lives $ tar -cf master.zip --anchored --exclude={source/install.sh,readme.md} -- *   if you need some flexibility, use find. the list of files to be compressed may be created with this command, the ! -name readme.md rejects the base readme.md file :  $ path="/path/to/files" $ find "$path/" ! -path  "$path"/readme.md -print   be careful with the slashes /, they do matter. if that contains the correct list of files to compress, then just inject that to tar (add a 0 to -print and create the tar command):  find "$path/" ! -path  "$path"/readme.md -print0 | tar --no-recursion --null -t- --exclude=install.sh -v -cf master.zip   note that tar is using the --null option to match the -print0 of find.  as find is providing all the recursion needed, use tar's --no-recursion option.  also, the file install.sh is still being excluded in tar (which might as well have been removed with find, but that is just personal preference).  in production, remove the -v option to get a less verbose tar command.    to decompress (instead of compress as above), use this:  tar -xf master.zip --anchored --exclude={source/install.sh,readme.md}   or, if you use the second option to create the compressed file, the files excluded will not be inside master.zip and all you would need to do is:  tar -xf master.zip      
this can be done by use of xbindkeys+xdotool.  one has to be careful: if your string, say my-string, contains the letter "r", binding xdotool type string to r would cause a loop! to avoid this, i disable xbindkeys, then call xdotool, then enable xbindkeys back
i found out what to do: if i hold fn + f12, it shows boot options
one way could be to use a custom command for listing files
right click on your wallpaper and you'll see something like this popup menu:   select "lock widgets" and the toolbox will disappear
to backup a qcow2, you have to quisece the filesystem (if it's running and qemu-guest-agent is running on the guest) and convert it to raw
the best way of finding out disk consuming, is using graphical software like baobab:  launch it with sudo baobab /   
if the file is created for enough short amount of time, you can run the following command on separate terminal before running the script:  while true; do cat /tmp/drush_* 2&gt;/dev/null &amp;&amp; break; done   where /tmp/drush_* is your pattern
the data passing through the pipe is not written or read to and from the filesystem
as far as i could investigate there are not major issues with the lpd feature, but maybe the reason on this issue tracker ticket. 
at least on debian and ubuntu, the resize command, when applied to a full height region performs a horizontal resizing.  if it works for you, then first split vertically, next perform a resizing of the width, then split horizontally. 
this is due to the following line in the main %files section of the yum.spec file:  %(dirname %{compdir})   meaning that rpm first substitutes %{compdir} and then executes dirname with the result as argument in a shell
help is a bash builtin and it provides you only with the details of other bash builtins from buildtime.  the source for help is generated at compile time from the def files in the builtin directories of the bash source tree
you can use shift command like this:   shift for arg in "$@" do     cat "$arg" done   
if you delete the user account, then the user no longer exists
if you can download a debian package this site might help to build an opkg file from it.  if rpm is the only available format you might have success running that through alien first. 
with gnu recode:  recode html &lt; file  
you can use  setfont /usr/share/kbd/consolefonts/$font  to change the font in the console, and then to revert back, just  setfont  once you determine where suse keeps these fonts, with  locate consolefonts  pick a larger one to set and away you go...  there is more detail here: https://wiki.archlinux.org/index.php/fonts#console_fonts 
[ $# -lt 2 ] || echo "at least 2 arguments are needed" &amp;&amp; exit 1   checks whether the number of arguments is strictly less than 2, and if it's not, outputs "at least 2 arguments are needed"
there is no option to use locate to find selected type of file (like directory), but you can use syntax from your question - dropnot$ to find lines that ends with dropnot
it is not quite clear from the questions how the various fields may vary
your arithmetic evaluation syntax is wrong
the tcp/ip protocol will not work without arp so that is always available
if public key authentication doesn't work: make sure that on the server side, your home directory (~), the ~/.ssh directory, and the ~/.ssh/authorized_keys file, are all writable only by their owner
as hinted by @markplotnick, there is no /sys or /proc interface for this
the bitmap line in /proc/mdstat indicates how much memory is being used to cache the write-intent bitmap.  basically, in raid setups with redundant devices, mdadm can use a "bitmap" to keep track of which blocks may be out of sync (because they've been written to)
yes, it is possible
i've tried a totally different approach is to use scrapy, however it has the same problem! here's how i solved it: so: python scrapy - mimetype based filter to avoid non-text file downloads?     the solution is to setup a node.js proxy and configure scrapy to use   it through http_proxy environment variable.      what the proxy should do is:         take http requests from scrapy and sends it to the server being crawled
freebsd:  sysctl debug.kdb.panic=1   linux (more info here):  echo c &gt; /proc/sysrq-trigger  
you could use an associative array:  declare -a versions for value in "${ruby_versions[@]}"; do     versions["${value##*::}"]=1 done printf "%s\n" "${!versions[@]}"     1.7.4 1.7.13 2.1.1   or with a pipeline:  mapfile -t versions &lt; &lt;(printf "%s\n" "${ruby_versions[@]}" | sed 's/.*:://' | sort -u) printf "%s\n" "${versions[@]}"     1.7.13 1.7.4 2.1.1  
old question, but the cleanest solution for vim in zsh was to add the alias to ~/.zshenv, the file that zsh loads for all shells, login, interactive, or otherwise
i manually edited the fedoras /boot: i appended a few things to the "/boot/grub/menu.lst"!!! and i could boot in to ubuntu!  the fedora's "/boot/grub/menu.lst" before editing it:   # grub.conf generated by anaconda # # note that you do not have to rerun grub after making changes to this file # notice:  you have a /boot partition
trying to run source-highlight as suggested in the linked question produces this error:  $ source-highlight -o stdout -i .bashrc --out-format=esc source-highlight: could not find a language definition for input file .bashrc   that's because .bashrc is not recognized automatically by source-highlight,  a quick look through its manual shows that it has the -s flag to set a language, so what you need is:  source-highlight -s bash -o stdout -i .bashrc --out-format=esc | less -r  
you may probably check the environment variable named desktop_session. 
special (and afaict) slightly under-documented behaviour in iputils ping: you ping yourself.  if you ping 0 this is what happens (heavily edited and commented for clarity):  if (inet_aton(target, &amp;whereto.sin_addr)) == 1) {     // convert string to binary in_addr } // inet_aton returns 1 (success) and leaves the `in_addr` contents all zero.  if (source.sin_addr.s_addr == 0) {         // determine ip address of src interface, via udp connect(), getsockname() }  // special case for 0 dst address if (whereto.sin_addr.s_addr == 0)         whereto.sin_addr.s_addr = source.sin_addr.s_addr;   inet_aton() isn't posix, but i'm assuming it copies the behaviour of inet_addr() when less than 4 dotted-decimals are being converted
i have used this, http://www.supergrubdisk.org/rescatux/, in the past, i believe thats what your looking for, it allows you to choose which partition to install/repair grub on
-not and -delete are gnu extensions.  there's no reason why you'd want to use -not, when there's a shorter standard equivalent: !.  for -delete, you'll have to invoke rm with the -exec predicate:  find 
many irc networks offer connections via ssl/tls
ok, so i've figured out how i can do this with gary johnson's help on the google groups vim_use group
linux normally doesn't do any locking (contrary to windows)
most programs use the environment variable tmpdir, and fall back to /tmp if there isn't enough room there.  tmpdir=/var/tmp ./jdev_suite_121200_linux64.bin   if the program has /tmp hardcoded, you can make /tmp larger.  mount -o remount,size=4g /tmp  
bash has both an interactive mode and a batch mode
telnet reads from ~/.telnetrc at startup, but that won't help you with typing long hostnames
modify your kernel boot parameter by setting the root=/dev/sdax option
if you install yum-utils, that will give you yum-debug-dump which will write those variables and more debugging info to a file
if you can set the file with  gsettings set org.gnome.desktop.background picture-uri file:///path/to/the/file   then you can get the file with  gsettings get org.gnome.desktop.background picture-uri   that will give you a string like 'file:///usr/share/images/desktop-base/desktop-background.xml' which is nice but needs to be parsed before we can directly use it as an argument to another shell command
have you tried this:  sed 's/&lt;[/]*td.*&gt;//' file_name  
many distributions have some facility for a minimal install; essentially where you manually select only those packages that you explicitly wish to install
that's what slots are for
i asked this question on serverfault, because i hadn't gotten an answer here, and this was the answer i got, it basically contains docs links
 if gparted only has to extend the partition or filesystem into unused space (immediately following the partition), then it should be safe to let it extend the partition and/or fs. if, however, it has to move any partitions around to make space for resizing, you'll have to boot with a gparted live cd see the man page for resize2fs (which is the command-line tool gparted will use to grow an ext2, ext3, and ext4 filesystem) for more details about resizing those filesystems.  for ext2/3/4, growing a filesystem is generally not a problem and can safely be done while the fs is mounted.  shrinking a filesystem, however, is more troublesome and should be done while the fs is unmounted
use bind9 and configure it to not answer recursive queries
as you discovered, ! doesn't trigger history expansion inside single-quotes.  you could use printf with a format string containing the ! symbols in single quotes
if you're on bash (or another bourne-like shell), you can use type
the tmux command for prefix + , can be seen in the list of command, which is displayed when you press prefix + ?  default should look like this:  bind-key          , command-prompt -i #w "rename-window '%%'"  just cut off the '-i #w' part from there to get the empty value as default suggestion when renaming.  that is, put this line in your tmux.conf:  bind-key          , command-prompt "rename-window '%%'"  and reload the tmux config/ restart the tmux 
by looking at /etc/cups/printers.conf, i found out that connection refers to deviceuri
no, that nesting of substitution operators is unique to zsh.  note that with zsh like with (t)csh, you can also do ${pwd:t:s/trunk/latest/}.  though bash also supports those csh history modifiers for history expansion, it doesn't support them for its parameter expansions.  here with bash, use a temporary variable:  var=${pwd##*/} var=${var//trunk/latest}  
with awk:  awk '{getline l; printf "%d %s\n%d %s\n", ++i, $0, i, l}' &lt;in &gt;out  
simply append the * character to the a variable, instead of the loop counter:  for i in {1..5} do   a+='*'   echo "${a}" done   note that a="${a}*" instead of a+='*' works just as well, but i think the += version is neater/clearer.  if you want to do this with a while loop instead, you could do something like this:  while (( "${#a}" &lt; 5 )); do   a+='*'   echo "$a" done   ${#a} expands to the length of the string in the a variable.  note that both of the above code snippets (as well as the code in the question) assume that the a var is empty or not set at the start of the snippet
from this question, this might work:  iconv -f iso-8859-1 -t utf-8 infile.txt &gt; outfile.txt  
here's an abuse of bash arrays; it splits the timestamp apart and creates array entries based on the yymmdd order, then prints the array back out in order.  declare -a array for file in foo.*.bar do   [[ $file =~ foo.([[:digit:]]{2})([[:digit:]]{2})([[:digit:]]{2}).bar ]] &amp;&amp; \     {       index="${bash_rematch[3]}${bash_rematch[2]}${bash_rematch[1]}"       array[$index]="$file"     } done  for index in "${array[@]}" do   echo $index done  # or printf "%s\n" ${array[@]}  
xterm, whose conventions were established many years before firefox, and even the web, was invented, is controlled by application resources
it turns out that the tunnel should have an ipv6 address on the source host, not the target host (the peer), for this simple ping test to work.  function tunnel {   local name="$1" self_ipv4="$2" self_ipv6="$3" ipv4="$4" ipv6="$5"   ip tunnel add "$name" mode sit ttl 64 remote "$ipv4" local "$self_ipv4"   ip -6 addr add "$self_ipv6"1 dev "$name"   ip -6 route add "$ipv6"/64 dev "$name" metric 1   ip link set "$name" up }   the tunnel setup commands would then be:  :;  tunnel tun6in4 10.239.143.35 2002:0aef:8f23:: 10.238.249.113 2002:0aee:f971:: :;  tunnel tun6in4 10.238.249.113 2002:0aee:f971:: 10.239.143.35 2002:0aef:8f23::  
this is a classic problem in concurrency: when allocating a resource, you need to atomically determine that the resource is free and reserve it, otherwise another process could reserve the resource between the time you check that it's free and the time you reserve it.  do use losetup's automatic allocation mode (-f), and pass the --show option to make it print the loop device path.  ld=$(sudo losetup --show -f /tmp/1m)   this option has been present in util-linux since version 2.13 (initially added as -s, but --show has been supported in all released versions and recent versions have dropped the -s option name)
i don't know what distribution you are using, but on my kubuntu 11.04 machines i just enable it using the system settings / application appearance / gtk+ appearance tab in the usual way, choosing oxygen-molecule from the widget style dropdown list. 
vmlinux  this is the linux kernel in an statically linked executable file format
   are ( and ) the operators that group commands, and create subshell?   no, the document refers to the operators to group expressions using test:  test 0 -eq 0 -a \( 0 -eq 1 -o 1 -eq 1 \)      if they are obsolete, what are their replacement?   their replacement are () and {}, which, similarily, group commands at the shell's level:  test 0 -eq 0 &amp;&amp; (test -0 -eq 1 || test 1 -eq 1) test 0 -eq 0 &amp;&amp; { test -0 -eq 1 || test 1 -eq 1; }   it's pretty easy to see the pattern: every operator used in test for expressions is replaced with the shell's equivalent for commands.     should test "$1" -a "$2" be replaced by test "$1" &amp;&amp; test "$2", or by (( test "$1" &amp;&amp; test "$2" ))?   it should be replaced with test "$1" &amp;&amp; test "$2"; (()) is used for arithmetic expansion and has no bearing with commands' exit status, as its purpose is to evaluate arithmetic expressions
it sounds like the package(s) were configured so that the httpd.conf file(s) were not declared to be "config" files
i realized that the macosx terminal.app doesn't read .bashrc
everythink about your list you can find in file /var/lib/mailman/lists/name_of_list/config.pck
what i ended up doing was similar to scott's answer but had a few extra steps.  create file /etc/sysconfig/network-scripts/ifcfg-he-ipv6 with:  device=he-ipv6 type=sit bootproto=none onboot=yes                         # set to "no" if you prefer to start the tunnel manually ipv6init=yes ipv6tunnelipv4=216.66.80.26        # server ipv4 address (this the he london tunnel server) ipv6addr=2001:xxx:xxxx:xxx::x/64   # client ipv6 address   also ensure that /etc/sysconfig/network contains:  networking_ipv6=yes ipv6_defaultdev=he-ipv6   the tunnel comes up quickly every time and survived upgrades to f15 and f16. 
with sed:  sed '$!n;/remove/!p;d' infile   this pulls the next line into pattern space (if not ! on la$t line) and checks if pattern space matches remove
use single quotes instead of double quotes:  alias rdir='mkdir -p ./$(cat /dev/urandom | tr -cd 'a-z0-9' | head -c 8)/'   now, the statement is evaluated every time the alias is called
your configuration seems to be correct, but it's difficult to parse a gif file :) commands you showed are ok
you could do (with gnu grep):  grep -po '\[\s*--?(?!-)((?&gt;[^][]+)|\[(?1)*\])+\]'   which on the text of your question gives:  [-a] [ -ab] [-abc ] [-a foo -b bar -c=biz end] [--a [-b[-c]] -d foo]   the idea being to use pcre and its recursive matching operators as described in pcrepattern(3) for matching nested [...]. 
depending on your platform, ttylinux is maybe something for you:     this smallest ttylinux system has an 8 mb file system and runs on i486   computers within 28 mb of ram, but provides a complete command line   environment and is ready for internet access.   started in 2001 and latest release is from 2015-03-05 so it is still maintained. 
it does ask me for the password:   $ ls -l fifo prw------- 1 glopes users 0 out 11 03:59 fifo $ ssh-add fifo enter passphrase for fifo:   then load the key from another terminal:  $ cat id_rsa &gt; fifo   or try the following one-liner:  $ (cat id_rsa &gt; fifo &amp;); ssh-add fifo   right on the terminal, without calling $ssh_askpass, like the manual says:     if ssh-add needs a passphrase, it will read the passphrase from the current terminal if it was run from a terminal
use this with bash:  find $1 -name "* *.xml" -type f -print0 | \   while read -d $'\0' f; do mv -v "$f" "${f// /_}"; done   find will search for files with a space in the name
rename the outer directory out of the way, move the inner one to the name you want, and then delete the (now empty) outer directory:  $ mv com to-delete $ mv to-delete/com com $ rmdir to-delete   you could also mv com/com/* com and remove the inner directory, if you don't have too many files and none of them are dotfiles, but the above is more general and more efficient. 
this works as expected out of the box on my system
how about using a re-write rule to block the 192.168.1.7 system from reaching the subdirectory?  rewriteengine on rewritecond   %{remote_addr}   ^192\.168\.1\.7$  [nc] rewritecond   %{request_uri}   ^/ldap/manager/.* [nc] rewriterule   ^(.*)$           -                 [r=404,l]   edited from the original answer; this now sends back a 'forbidden' error code. 
the ! character invokes bash's history substitution
i don't have the full output pre-grep because my scrollbuffer filled up, but:  # ip addr show dev eth0 |grep 192.168.[12] inet 192.168.1.1/16 scope global eth0 inet 192.168.1.2/16 scope global secondary eth0 inet 192.168.1.3/16 scope global secondary eth0 inet 192.168.1.4/16 scope global secondary eth0 inet 192.168.1.5/16 scope global secondary eth0 ...   and this solved it:  ip addr del 192.168.1.1/16 dev eth0  it was most likely a side-effect of some fiddling i was doing with openvpn configurations a while back. 
set the shell's noclobber option:  bash-3.2$ set -o noclobber bash-3.2$ echo hello &gt;foo bash-3.2$ echo hello &gt;foo bash: foo: cannot overwrite existing file bash-3.2$   
mv is the wrong tool for this job; you want cp and then rm
i take it you want the system/library calls which are made from a particular program, not all of them.  strace shows all the external calls from an executable program
ok, it seems i missed it on first try in lspci manpages.  note: run the command as root/sudo otherwise a lot of detail is ommitted including the lnk output shown below.  lspci -vv displays a lot of information, including link width:  01:00.0 vga compatible controller: nvidia corporation g92 [geforce 8800 gt] (rev a2) (prog-if 00 [vga controller])             [...]             lnkcap: port #0, speed 2.5gt/s, width x16, aspm l0s l1, latency l0 &lt;512ns, l1 &lt;1us                     clockpm- surprise- llactrep- bwnot-             lnkctl: aspm disabled; rcb 128 bytes disabled- retrain- commclk+                     extsynch- clockpm- autwiddis- bwint- autbwint-             lnksta: speed 2.5gt/s, width x8, trerr- train- slotclk+ dlactive- bwmgmt- abwmgmt-  
echo &gt;file would have been the straightforward solution
   without the new rules nothing is laced into the db and thus established,related will never match anything.   this is false.   there are five userland states (there are more in kernel space), and while an established or related connection does logically need to begin with a new packet, you do not need any explicit new rule to produce such a connection (you do need an explicit accept which implicitly includes new packets, however)
if there is no session connected to osx, there will be no sshd process. try if this is working:  ssh localhost   if not:  systemsetup -setremotelogin on   if it works, you've got network/firewall problem. 
it can be done with awk using " as the field separator
here's another solution:  sed 's/^&lt;[^&gt;]*&gt;//g' file.txt | tr '\012' '|' | awk -f'|' '{ofs=fs; print $3,$2,$1}' 9251000014|220095|operation successful.   if you want to strip the trailing . you could do that either with the sed or the awk (no need for both)
to see another users sudo permissions you can use: sudo -l -u &lt;user&gt;
i don't know why changing the kernel name would have made a difference (perhaps sd*1 runs after sd* allowing a bit more time for work to get done?), but udev doesn't like long-running actions in events:     starting daemons or other long running processes is not appropriate for   udev; the forked processes, detached or not, will be unconditionally killed   after the event handling has finished.   original nohup suggestion  i originally suggested nohup before fully reading my own links :) -- which suggest that this may not actually work  udev rule:  action=="add", subsystem=="block", kernel=="sd[a-z]1" symlink+="usbflash", run+="/path/to/mywrapper.sh"   mywrapper.sh (note: if you don't redirect the output nohup may litter your directory with a nohup.out file):  #!/bin/sh nohup /path/to/myscript.sh &gt;/log/myscript.log 2&gt;&amp;1 &amp;   then myscript.sh can be what it is.  newer systemd suggestion  the third link below suggests firing off a systemd service when the device is plugged in
as indicated in the comment to the question man rsnapshot says:     exit values         0  all operations completed successfully         1  a fatal error occurred         2  some warnings occurred, but the backup still finished    so you can modify your command line for example:  rsnapshot ..
to solve this problem go to system settings -> desktop effects  and uncheck sliding popups animation 
check out why does the &#39;bin&#39; user need a login shell?  it says this pattern for system users is   common in debian, and not so much in other distributions. considered a bug / genuine security issue by several people. required in order to run cron jobs as that user, and perhaps also by some scripts if they use su -c to run as this user
(define-key key-translation-map (kbd "m--") (kbd "m-/"))   if you use the kbd macro, you can use the string representation of the desired key sequence from the c-h k help text. 
if you do not want to limit the scrolling region (see my other answer), you can also use the carriage return to go back to the beginning of the line before printing the next line
if i understand correctly, your problem is you cannot find a way to use a shell alias to interact with screen directly
run it all as a single command:  $ sqlite3 stylish.sqlite "select * from styles;" &gt; somefile.txt   example  $ sqlite3 addons.sqlite "select * from icon;" &gt; somefile.txt  $ cat somefile.txt  1|32|https://addons.cdn.mozilla.net/img/uploads/addon_icons/354/354399-32.png?modified=1369154804 1|64|https://addons.cdn.mozilla.net/img/uploads/addon_icons/354/354399-64.png?modified=1369154804   using tee  if you want to see the output as it's being written to the file you can use tee instead.  $ sqlite3 addons.sqlite "select * from icon;" | tee somefile.txt 1|32|https://addons.cdn.mozilla.net/img/uploads/addon_icons/354/354399-32.png?modified=1369154804 1|64|https://addons.cdn.mozilla.net/img/uploads/addon_icons/354/354399-64.png?modified=1369154804  
if you have a mountpoint command:   mountpoint -q /local/mount/point || mount ...  
to use the nano-receiver with a different (but compatible) mouse, you'll need to use a tool such as solaar (which is packaged for arch) to pair your new mouse with the receiver.  as to your second question, there is a universal protocol, bluetooth hid; but bluetooth mice are more expensive than mice using proprietary protocols. 
please consider editing /etc/profile
i too have wondered this and was motivated by your question!  i've collected how close i could come to each of the queues you listed with some information related to each
i'm assuming a bash shell, or similar, since there is no shell listed in the tags.  to check if you are in an interactive shell:  [[ $- == *i* ]] &amp;&amp; echo 'interactive' || echo 'not interactive'   to check if you are in a login shell:  shopt -q login_shell &amp;&amp; echo 'login shell' || echo 'not login shell'   by "batch", i assume you mean "not interactive", so the check for an interactive shell should suffice. 
depending on the command:   someone may have written a function to generate possible completions of arguments, including options
traditionally, unix mail is delivered right to your machine (because if your email address is lazer@machine.example.com, surely you have a shell account on machine.example.com)
you can also launch the browser with nohup and then close the terminal window with the following:  nohup chromium-browser &amp;   this way, the browser will launch and detach from the console, that can then be closed quietly. 
this should be doable
you can send a sigstop to the process (most shells use ctrl-z for this), which will tell the present process pause it's current state
it does this (really) because the shell's developers decided it would be helpful
it's easier if you spread it out a little:  watch -ben5 '     lsof /mnt/unfs &amp;&amp;     ps    -o tty= -p "$(lsof -f p0 /mnt/unfs | sed -e "s/p//")" |     xargs -i terms sudo sh -c '\''         printf "\n\33[97;101m%s\33[31;49m%s\33[97;101m%s\33[39;49m\n" \                "get out of unfs" " cd ~ " "now!" &gt;/dev/terms'\'''   it's pretty difficult for me to understand what's going on here exactly
use the gnu debugger, gdb, or something similar. 
if you don't care about paravirtualization, then compiling a minimalistic kernel for a kvm guest is the same as compiling a minimalistic kernel for hardware
when input file is seekable (like reading from regular file) or un-seekable (like reading from a pipe), sed (and other standard utilities) will behave differently (read input files section in this link).  quote from the doc:     when a standard utility reads a seekable input file and terminates   without an error before it reaches end-of-file, the utility shall   ensure that the file offset in the open file description is properly   positioned just past the last byte processed by the utility.   so in:  (sed '/y/ q'; echo aaa; cat) &lt; test   sed performed quit command before reaching eof, so it left file offset at beginning of zzz line, so cat can continue printing the remain lines (gnu sed is not posix compliant in some condition, see below).  and continuing from the doc:     for files   that are not seekable, the state of the file offset in the open file   description for that file is unspecified   in this case, the behavior is unspecified
to debug problems with scheduling or applications performance on linux, it is a good start to run task under perf stat
if you have an awk that supports regular expressions for the record separator rs, it can be done like this:  awk 'begin { rs = " +| *\\\\?\\n" } 1'   the advantage of this is that we are not snarfing the entire file into memory and doing some regex replacement; your input could be gigabytes long.  we basically treat the file as having two record separators: either one or more spaces, or else zero or more spaces followed by a newline, which may be preceded by an optional backslash.  having delimited the records this way, all we have to do is output them followed by the default output record separator (ors), which, of course, is newline
"everything" is bracketed, but there are several unknowns
man is calling less; the only control at the man level is choosing which options to call less with.  less's search case-sensitivity is controlled by two options.   if -i is in effect, then searches are case-insensitive: either a or a can be used to match both a and a. if -i is in effect but not -i, then searches are case-insensitive, but only if the pattern contains no uppercase letter.   if you make -i a default option for less, then all searches will be case-insensitive even in man pages.  man-db passes extra options to the pager via the less environment variable, which less interprets in the same way as command line options
try ls -l /tmp/lijunda and all you will see is the names of the files within—you won't be able to open the files, or even see the file size, permissions, etc
if you'd like to reuse your code sample, it could look something like:  #!/bin/bash  case "$1" in  start)    /path/to/hit.sh &amp;    echo $!&gt;/var/run/hit.pid    ;; stop)    kill `cat /var/run/hit.pid`    rm /var/run/hit.pid    ;; restart)    $0 stop    $0 start    ;; status)    if [ -e /var/run/hit.pid ]; then       echo hit.sh is running, pid=`cat /var/run/hit.pid`    else       echo hit.sh is not running       exit 1    fi    ;; *)    echo "usage: $0 {start|stop|status|restart}" esac  exit 0    naturally, the script you want to be executed as a service should go to e.g
assuming this is the php53 stock from centos, you can safely remove the php53 package
try this:  sudo service dovecot stop   and to completely remove dovecot:  sudo apt-get remove dovecot-imapd  
one way to do it:  cut -d: -f5 /etc/passwd | \     sed 's/\..*//' | \     sort -i | \     uniq -ci | \     sort -rn  
my apologies, i figured out that the columns are overwritten by the -o.  here is what you were looking for:  ps -e -o user,pid,%cpu,%mem,vsz,rss,tty,stat,start,time,command,etime,euid  
the hosting system should not matter, calling a web service is the same (in fact, that's one of the points of setting up a web service).  php has built in soap objects (manual entry for it)
developing on a virtual machine can be a good idea if you cannot dedicate a machine to a different os
one way to do it would be to install mutt
that's not a bug that upgrading will fix, but an error in your setup
at the time the sshd process on the remote computer forks to run /usr/bin/xterm there are very few environment variable set
the screen swapping is done with a terminal control code
i would try this
to list all mangle iptables rules by specification:  iptables -t mangle -s   this will list the rules as you specified them, for easy copy paste
you can use awk for the job:  $ curl -o example.vcf http://qt.gitorious.org/qt-mobility/contacts/blobs/raw/\ d7f10927176b8c3603efaaceb721b00af5e8605b/demos/qmlcontacts/contents/example.vcf  $ gawk ' /begin:vcard/ { ++a; fn=sprintf("card_%02d.vcf", a);          print "writing: ", fn } { print $0 &gt;&gt; fn; } ' example.vcf writing:  card_01.vcf writing:  card_02.vcf writing:  card_03.vcf writing:  card_04.vcf writing:  card_05.vcf writing:  card_06.vcf writing:  card_07.vcf writing:  card_08.vcf writing:  card_09.vcf  $ cat card_0* &gt; all.vcf $ cmp example.vcf all.vcf $ echo $? 0   details  the awk line works like this: a is counter that is incremented on each begin:vcard line and at the same time the output filename is constructed using sprintf (stored in fn)
i don't believe this information is kept anywhere
you need to add the route to the gateway first:  ip -6 route add 2004::3 dev eth0  
the formats section of man tmux has a complete list of the values that you can use in your status line
i found a couple of tutorials which shows how this can be achieved:  solution 1 - using fast cgi instead of mod_php  solution 2 - runn a single instance of apache, and run one instance of php as a module, and other installs as cgi.  hope it helps others. 
ls -lhad phpmyadmin-3.3.5-english   the -d flag is used to tell ls that you want to show the properties of the given directory, not its contents. 
just use time when you call the script
my shortest method uses zsh:  print -rl **/*(.om)   if you have gnu find, make it print the file modification times and sort by that
you can try disable the gnome shortcuts in edit -> keyboard shortcuts, so the window won't eat up the function keys.  there seems to be a known gnome-terminal bug relating to this.  alternatively if this doesn't work, you will have to use another terminal that explicitly sends function keys as control codes to the terminal
here's the version from my english manpage:   -r, --root chroot_dir      apply changes in the chroot_dir directory and use the      configuration files from the chroot_dir directory.   in other words, instead of editing /etc/passwd and friends, you're editing chroot_dir/etc/passwd.  for example, you might boot a live cd, mount the hard drive as /mnt, and then use -r /mnt to edit its users. 
it's the same thing
off the top of my head i can think of 4 ways of doing this, but i wouldn't recommend any of them!   use linux namespaces; inside each per-user namespace bind-mount the per-user file over the top of the base file. create a per-user chroot environment with the base file symlink'd to the target file run a fuse based filesystem and mount this over the top of the base file have the base file be a named pipe with a daemon process handling read/write to the per-user file.   but all of these are complicated to setup and fragile and i wouldn't recommend them
1 - install gnome-shell from synaptic package manager  2- restart pc  3 - select gnome3 from the gdm login screen 
you can always pass the array to the function and rebuild it as an array within the function:  #!/usr/bin/env bash  foo () {     ## read the 1st parameter passed into the new array $_array     _array=( "$1" )     ## do something with it.     echo "parameters passed were 1: ${_array[@]}, 2: $2 and 3: $3"  } ## define your array array=(a 2 3 4 5 6 7 8 7 6 5 4 3 2 1) ## define two other variables var1="foo" var2="bar"  ## call your function foo "$(echo ${array[@]})" $var1 $var2   the script above produces the following output:  $ a.sh parameters passed were 1: a 2 3 4 5 6 7 8 7 6 5 4 3 2 1, 2: foo and 3: bar  
this is side effect of --inplace option
the perl cgi module has a escapehtml function that makes it pretty easy:  perl -e 'use cgi qw(escapehtml); print escapehtml("&lt;hi&gt;\n");'   or to do an entire file:  perl -p -e 'begin { use cgi qw(escapehtml); } $_ = escapehtml($_);'  filename  
inside awk you don't have direct access to shell variables, you need to pass them as an options, so change awk command to something like:  awk -v sf="$scalingfactor" '{printf($1"\t"$2"\t"$3"\t"$4*sf)}'  
here's the solution on non-embedded linux and cygwin:  cp -as source copy   note that source must be an absolute path
you can use :reg to view all actions in vim then paste that deleted lines by pressing "2 ctrl + p  read more  
you're missing a file which would be used to default the locale in the absence of $lang or $lc_all (or all of the more specific $lc_whatever) being set.  on older glibc, it's /usr/lib/locale/locale-archive. because gnu/linux is chaotic, you should use strace to determine which files are expected in the particular versions in use on your machine:   strace -e file locale execve("/usr/bin/locale", ["locale"], [/* 36 vars */]) = 0 access("/etc/ld.so.preload", r_ok)      = -1 enoent (no such file or directory) open("/etc/ld.so.cache", o_rdonly)      = 3 open("/lib/libc.so.6", o_rdonly)        = 3 open("/usr/lib/locale/locale-archive", o_rdonly|o_largefile) = 3   ----------------------comments added 1 day later:  "ltrace -s" should be okay, since it shows syscalls.  otherwise, "ltrace" is not very helpful (i.e
i stumbled across your question while having the same problem and i've found a solution.  i assume that, you as well as i installed cscope_maps.vim in your .vim/ directory
you shouldn't need the for loop at all.  find 
afaict, the only problematic widgets are:  vi-backward-delete-char vi-kill-line vi-backward-kill-word   so you could do  zle -a kill-whole-line vi-kill-line zle -a backward-kill-word vi-backward-kill-word zle -a backward-delete-char vi-backward-delete-char  
the most common cause of touchpad issues on arch linux, including the one you are describing, is not installing the synaptics touchpad driver
as @thomasdickey said, networking may not be completely started when userland programs start to run
try a differfent program; maybe this will be more accurate:  df -h  
the pypdf library makes this sort of things easy if you're willing to write a bit of python
i had the same problem with helvetica bitmap fonts
finally i finished myself  this is the answer     useradd -m -d /home/testuser/ -s /bin/bash -g sudo testuser  
the best you can do is hash the password
patches are applied1 with the patch command
i figured out a hack
there is no need to use trap here. you actually want to make xinit run without a terminal, thus making sigint to be avoided after ctrl-c.  run x server like this:  startx &amp; disown; exit   and edit /etc/x11/xwrapper.config so that a specific user can run x. 
instead of going to the internet, you could go to a local debian repository.  this link explains how to setup a debian repository.  you would then have to find how to set your netboot image to get the packages from your local repository
..
using character class [[:alpha:]] to match uppercase and lowercase and the negation [^[:alpha:]] to match all others:  sed -r 's/^([^[:alpha:]]*)([[:alpha:]]+)([^[:alpha:]]+[[:alpha:]]+[^[:alpha:]]+)([[:alpha:]]+)([^[:alpha:]]*)/\1\4\3\2\5/' file.txt   example:  $ sed -r 's/^([^[:alpha:]]*)([[:alpha:]]+)([^[:alpha:]]+[[:alpha:]]+[^[:alpha:]]+)([[:alpha:]]+)([^[:alpha:]]*)/\1\4\3\2\5/' &lt;&lt;&lt;'i 4want5to%change' to 4want5i%change  $ sed -r 's/^([^[:alpha:]]*)([[:alpha:]]+)([^[:alpha:]]+[[:alpha:]]+[^[:alpha:]]+)([[:alpha:]]+)([^[:alpha:]]*)/\1\4\3\2\5/' &lt;&lt;&lt;'4i 4want5to%change' 4to 4want5i%change  $ sed -r 's/^([^[:alpha:]]*)([[:alpha:]]+)([^[:alpha:]]+[[:alpha:]]+[^[:alpha:]]+)([[:alpha:]]+)([^[:alpha:]]*)/\1\4\3\2\5/' &lt;&lt;&lt;'spring&amp;summer^winter' winter&amp;summer^spring  
if you're familiar with vim, this is probably the best option for you
this should work  find 
the commands that read stdin are almost all of the filter family, i.e
by default, the paste commands use the " (“unnamed”) register
then answer is that sudo has a bug
add the missing trailing slash to your proxypass and proxypassreverse directives:  proxypass / ajp://server.ip.addr:8013/ proxypassreverse / ajp://server.ip.addr:8013/  
accessing files  there are various ways to do this, but the simplest is probably to use nautilus.  installation  to access samba shares through nautilus install the gvfs-smb package, available in the official yum repositories.  $ yum search gvfs-smb loaded plugins: auto-update-debuginfo, langpacks, refresh-packagekit =============================================================== n/s matched: gvfs-smb ================================================================ gvfs-smb.x86_64 : windows fileshare support for gvfs   if it's not installed:  $ sudo yum install gvfs-smb   then from nautilus, press ctrl+l and enter smb://servername/share in the location bar to access your share
sometimes compression might be useful in x over ssh sessions.  ssh -x -c -ocompressionlevel=9 me@my.server.local mandelbulber   here's how i launch mandelbulber on my desktop pc but utilizing my server performance to calculate fractals. 
the easiest way to see this is to use something like od -c which prints all characters:  $ echo 123456 | od -c 0000000   1   2   3   4   5   6  \n 0000007 $ printf 123456 | od -c 0000000   1   2   3   4   5   6 0000006   as you can see, echo prints an extra \n but printf doesn't
yes, there are several ways to accomplish this with the find command
it's a full linux system, so in an xterm you can:  # cat /proc/cpuinfo # cat /proc/meminfo   for the resolution, it's 800x480
fat may not be a posix-style filesystem, that doesn't mean that you shouldn't be allowed to store executables on it and run them directly from it
you need to make use of capture groups
a squid can be used for this, however there are some issues you should watch out for :   squid doesn't yet support caching of partial content, so if your app uses range requests instead of downloading the whole file, you'll have some issues
finally, i've found the answer by myself searching in this invaluable knowledge database of stackexchange unix &amp; linux!!!  in addition to the answers to the questions above, i've also used the accepted answer to this question: read two text files, concatenate each line  and here is the answer to my question above:  #!/bin/bash xuser=$(who | grep ' \:[0-9]' | awk '{print $1}') xdisplay=$(who | grep ' \:[0-9]' | awk '{print $5}' | sed 's/[(|)]//g') echo "$xuser" &gt; /tmp/xusers.txt echo "$xdisplay" &gt; /tmp/xdisplays.txt while read -r -u3 xuser; read -r -u4 xdisplay; do     display="$xdisplay" xauthority=/home/"$xuser"/.xauthority su "$xuser" -c "notify-send 'message multi-user'" done 3&lt;/tmp/xusers.txt 4&lt;/tmp/xdisplays.txt  
wubi doesn't work with windows 8
the -i/--in-place flag edits a file in place
have a look at time. that should give you all the information you need. 
use /dev/urandom
you can ask password by means of gui prompt with the help of -a, --askpass.  from the manpage:  -a, --askpass                  normally, if sudo requires a password, it will read it from the user's terminal
that is the total number of blocks taken up by the files, although i would expect the total to be 8 instead of 12 (using 1k blocks)
if you don't mind using vlc (which livestreamer is based on):  vlc --start-time $((10*60)) "http://www.youtube.com/watch?v=w87foag8fjk"   where --start-time is given the time offset in seconds.  for livestreamer i don't see any available option right now to add this functionality
just if anyone finds this old question, there is a solution to that mentioned in a bug report linked from another unix.stackexchange question
if you have to copy a large number of files, or have large files, rsync over ssh will be much faster than scp. 
   either mount /dev/sd0a to /var/www or configure your web server to use   /mnt/usbhdd instead of /var/www
according to wikipedia,     the notion that filenames preceded by a 
you can use grep:  grep 'group_name_here' /etc/group   this only lists supplementary group memberships, not the user who have this group as their primary group
using eval is wrong in the first place
panel settings are saved here ~/.config/xfce4/panel but you could also try the xfce4-settings-manager.  and to learn how it works you can just download many nice looking examples from here http://xfce-look.org/ and look into the config files that come with these themes. 
you can create a desktop file in ~/.local/share/applications, add something like the following contents:  [desktop entry] name=teamspeak comment=teamspeak exec=/path/to/teamspeak.sh icon=/path/to/teamspeak-icon.png terminal=false type=application startupnotify=true   this is included in the instructions here
no, ssh has nothing to do with mac addresses
here is a posix way to prune any non readable directory with find :  find 
you can't store binary data (binary data generally refers to data with arbitrary byte values, not only byte values that form valid characters but is not special otherwise) in bash variables as bash doesn't support storing the 0 byte value in its variables (and remember you can't pass such strings in arguments to commands as those are nul delimited strings).  you can in zsh though
i tried installing the slovak keyboard on my cinnamon and could get the { symbol with altgrb:    if that doesn't work for you, you might need to change the keyboard's options:    then, choose the key that sets the 3rd level:   
http://www.xfree86.org/current/xlsclients.1.html 
 no. money.   most linux distributions are mostly posix compliant, but there's no formal posix stamp on them since nobody thinks it's a good idea to either go through that procedure, or pay the required fees, or both
it seems likely that linux mint's grub is still installed to the mbr, while its /boot partition got deleted
mounting a hdd  to mount a hdd that's physically connected to your system, you first need to identify the device handle that's been assigned to it
sure they can (and do) work (qemu stands for q&#8203;uick emu&#8203;lator), but will be much slower than their native couterparts - i.e
thanks to rhel support, the clear solution has been discovered
the ` has been called many things including a back-tic, backquote, inverted comma, quasiquote, and grave accent.  it is important to note that quotes, tics, and the like affect how the shell treats variables
caleb was right about passing the correct display variable
i had the same problem
command is "deja-dup-preferences" just create a menu item on whatever desktop you are using that executes the above command and a gui will open up on your desktop 
set the crontab as:  @reboot the-script 0 0 * * 1 the-script 0 0 1 1 * the-script   to have it done on mondays and at each boot
if you just want to toggle the menu bar, there's already a command for that (m-x menu-bar-mode)
i just guessed at some variations of the menu command and this worked  zstyle ':completion:*' menu yes select  
i've solved it ;  namefile=$1 i=-1 for n in $namefile* do exdatefile=$(ls -l $namefile* | head $i | tail -1 ) i=$(($i -1)) ifs=' ' array_datefile=($exdatefile) echo "the file ${array_datefile[8]} was modified ${array_datefile[5]} ${array_d$ unset exdatefile done   the output is ;  the file hw1_evening_sun.txt was modified may 29 2008 the file hw1_morning_sun.txt was modified may 29 2008 the file hw1_out_si_wire.txt was modified may 29 2008 the file hw1_script.sh was modified jun 2 15:20 the file hw1_script2.sh was modified jun 2 15:16 the file hw1_sun1.txt was modified may 29 2008 the file hw1_sun2.txt was modified may 29 2008  
downloading source code from debian repositories is as simple as running apt-get source &lt;package&gt;
if this is an ext3 filesystem, you can extend it to the lv size by running:   resize2fs /dev/system/var   if this anything else than ext3, use the appropriate tool, e.g
what do you mean by saying "default is been set to windows 7 " ?  if you still have grub bootloader on your mbr:  you should change the default os on your system's grub configuraton file which is in this path : /boot/grub2/grub.cfg  in this line :   set default="num"   you can change the num to an integer which shows the menu-entry of fedora on your bootloader menu
the file you need to remove, or edit if you prefer, is: kateschemearc, which is usually located in a folder like $home/.config/ (the name of your .kde file may be .kde4 or something similar).  remove that file and all default colour schemes are restored. 
http://playtowatch.com/watch/75uz5scw_tm/how-to-install-codeblocks-on-linux-kali-linux.html  i had the same problem and followed the tutorial below the video.  first download the wxwidgets source for linux
you should be able to use the following line to run a job every 3 hours:  0 */3 * * * /home/wlogic/shscripts/diskcheck/diskspacecheck.sh   to check whether your cron job ran, check your syslog or cron log
 tar -xvf tarball.tar.gz my/folder/im/extracting    this extracts the archive member my/folder/im/extracting at the location my/folder/im/extracting
thanks to the #btrfs channel on irc (full reference), i found out the following:   these subvolumes subvolumes are created under the subvolid=0 subvolume, which is not mounted by default to create such subvolumes, first mount that top-level subvolume, and then create the subvolume under it   for instance, in my scenario:  # mount uuid=280d6f04-6ad0-4647-96b9-580aec12bbdc -o subvolid=0 btrfs-sys/ # tree -l 2 /mnt/btrfs-sys/ /mnt/btrfs-sys/ └── @     ├── boot     ├── etc     ├── opt     ├── srv     ├── tmp     ├── usr     └── var  
if an attacker can boot a live cd in your environment, your environment is not secure
technically, there's no such thing as a "reserved port".  in tcp/udp, the only way to "reserve" a port is to actually bind() a socket to it
it looks like you are using a weird shell in your mingw environment - and not bash
awk -v ofs='\t' '$4 !~ /^[pm]irna/ { $4 = "rfam" } ; { $4 = $4 ; print }' file   this does exactly what you asked for - if field 4 doesn't match the regexp ^[pm]irna, set it to rfam
   incompatibilities and such   what do you mean by that?  before installing, dpkg first checks if all dependencies of the .deb package(s) to be installed are satisfied
orig=$ps1 ps1="\[${txtund}${green}\]local\[\[${reset}\]"; ps1+="\$(prompt_git \"\[${white}\] on \[${violet}\]\")"; ps1+="\[${reset}\]"; ps1+="\[ - \u\$: \]";   i have escaped both the colors as well as the final line of text
using awk for this would work, but it's kind of deer hunting with a howitzer
not exactly what you ask, because you don't have a new real window or tab.  you can start screen on the server (if available), so that you can multiplex your server sessions.  after that you have still a single screen window, but if you do ctrl+a c, you create a new screen window, and switch between the windows with ctrl+a 0, ctrl+a 1.  you have the added advantage that you can disconnect from the server leaving the two (or more) sessions alive (ctrl+a d), then restore them later (screen -dr). 
services are scripts that reside in /etc/init.d
martin- very similar setup on my end, except with a pair of nvidia gt9800's - circa 2008!
the results from file are not perfect; the command looks for predictable patterns to determine file types
you are confusing what posix calls a "simple command" which is a non empty sequence of optional assignments, optional redirections and optional words (including a command name and its optional arguments), and "command" as it is used in the bash manual command synopsis which is here just a command name.  should you really want to use assignments here, you can simply run :  aaa=1 command echo hello   if there is no command at all but just an assignment, there is no much point using the command command, given the fact there is no builtin or command to search in the path in the first place
 use the pam_tally2 module of pam(already built-in on pam package) add the following line on the /etc/pam.d/system-auth file   auth required pam_tally.so onerr=fail deny=5 unlock_time=21600    where:   deny=5: number of tries onerr=fail: default behavior if something weird happens to pam unlock_time: number of seconds to unlock again the account.   now, is just use pam(usepam=yes) on sshd. 
the -a option tells ssh-keygen to generate host keys
the default gui uses gvfs to mount removable drives and other dynamic filesystems
i usually list out the contents of the rpm and filter it using /bin/
i don't know of any utility that can give you this information directly, but you can get it by using a few different utilities.  shortest route:    udevadm info -q all -p /sys/bus/usb/devices/6-0:1.0   this will give you output of which one of the lines will look like the following (obviously this output won't match your system):  e: device=/proc/bus/usb/006/053   then run lsusb and look for the device at bus 006 device 053 (from the 006/053 in the above line), this will be your device.  .  for more info, you can poke around in that /sys/bus/usb/devices/6-0:1.0 if you want
a block special file or block device is:     a file that refers to a device
lsusb is actively querying the devices on the usb bus as far as i am aware.  you can also used the dmesg command to see the history of the devices insertion, and sure that is not interactive.  you can also use lsinput  sudo apt-get install input-utils sudo lsinput  
the path of least resistance is to tell your shell on the solaris box what the escape sequences sent by putty mean
the comment from stéphane chazelas provides the hint to the answer.  according to bridge-nf frequently asked questions bridge-nf enables iptables, ip6tables or arptables to see bridged traffic.  as of kernel version 2.6.1, there are five sysctl entries for bridge-nf behavioral control:   bridge-nf-call-arptables - pass bridged arp traffic to arptables' forward chain. bridge-nf-call-iptables - pass bridged ipv4 traffic to iptables' chains. bridge-nf-call-ip6tables - pass bridged ipv6 traffic to ip6tables' chains. bridge-nf-filter-vlan-tagged - pass bridged vlan-tagged arp/ip traffic to arptables/iptables. net.bridge.bridge-nf-filter-pppoe-tagged - pass bridged pppoe-tagged ip/ipv6 traffic to {ip,ip6}tables   you can disable netfilter firewall blocking with:   # sysctl -w net.bridge.bridge-nf-call-iptables=0 # sysctl -w net.bridge.bridge-nf-call-ip6tables=0  
juxtaposition binds more tightly than the -o operator
install a separate ssh daemon - either another copy of openssh or e.g
regular expressions are not the same as shell glob patterns
despite its name, rm doesn't remove file
echo "- - -" &gt; /sys/class/scsi_host/host0/scan   (where 0 is the scsi host bus you want to scan.)  here is a short article. 
   why does a linux distribution have gcc installed in advance?   a linux distribution is rather vague
you can try:  dig www.ign.com a +short | grep -oe "\b([0-9]{1,3}\.){3}[0-9]{1,3}\b" &gt; a.list   in your bash script
logrotate has the rotate parameter that specifies how many logs to save. 
i'd make heavier use of <a href="http://www.tldp.org/ldp/abs/html/io-redirection.html" rel="nofollow" title="advanced bash-scripting guide: chapter 20
with gnu mv:  find path_a -name '*aaa*' -exec mv -t path_b {} +   that will use find's -exec option which replaces the {} with each find result in turn and runs the command you give it
this looks like a bug in several shells, it works as expected with ksh93 and zsh.  background:  most shells seem to run the while loop inside the main shell and   bourne shell suspends the whole shell if you type ^z with a non-login shell  bash suspends only the sleep and then leaves the while loop in favor of printing a new shell prompt  dash makes this command unsuspendable  with ksh93, things work very different:  ksh93 does the same, while the command is started the first time, but as sleep is a buitin in ksh93, ksh93 has a handler that causes the while loop to fork off the main shell and then suspend at the time when you type ^z.  if you in ksh93 later type fg, the forked off child that still runs the loop is continued.  you see the main difference when comparing the jobcontrol messages from bash and ksh93:  bash reports:  [1]+  stopped                 sleep 1  but ksh93 reports:   ^z[1] + stopped                while true; do echo .; sleep 1; done  zsh behaves similar to ksh93  with both shells, you have a single process (the main shell) as long as you don't type ^z, and two shell processes after you typed ^z
you are looking for the tty command, which prints the file name of the terminal connected to standard input. 
you error is in your script
perhaps:  sed 's/\(\(^\|:\)123@example\.com:\)\([^:]\+\)/\1foo/'   given there is no escaped delimiters in the value.  sed 's/\(\(^\|:\)123@example\.com:\)\([^:]\+\)/\1foo/'          |     |         |                |     | |  | |           |     |         |                |     | |  | +----- h
stuff in /usr/local usually supersedes stuff in /usr, so i'm a bit confused as to why you would install libraries there to have a "a nice custom distro", but then not want to compile against them
first of all, that ^m is a carriage return (\r), not a newline (\n)
i guess it depends what kind of pentesting you want to do
you have the ssh program
when you add keys to an authorized_keys file you have several options to restrict what that key can do
dovecot or courier is probably your best bet.   http://wiki2.dovecot.org/pop3server http://www.courier-mta.org/install.html#pop3  
the sequence s/&lt;[^&gt;]*&gt;//g is a command to the sed processing engine; it tells it to do a "search and replace"
if everything works, all should be installed
most likely, you're not going to want to replace the existing python, since that would probably break the existing os software.  you could either build a package for python 2.7, and have it install as /usr/bin/python2.7, or install in another location like /usr/local/bin/python
this isn't necessarily unix/linux specific, so you are probably better asking this on stack overflow
if you want to use apt-get remove for a file contained in a specific package you can do:  apt-get remove $(dpkg  -s /usr/bin/mysql | cut -d ':' -f 1)   (replace /usr/bin/mysql, with whatever file you were looking for to remove)  using this, apt-get will still ask if you really want to remove the package (that dpkg found), sometimes you realise you did not want that after you see the package name 
the only different between them is cursor position
for some reason, you have to touch some files during the make process
as for understanding the message, the lock file is used to stop more than one package manager trying to modify the system at once
simply with this command for cache directory location: apt-config shell cache dir::cache and this command for cache/archive directory location: apt-config shell cache dir::cache::archives 
what you're looking for is xpud; a distro with the tagline: "the shortest path to the cloud"
this may be false hope, but undo seems to be possible with the 7.16 rpm source from fedora, likely the debian packages sources, with the yank and pull features, and some strategic tweaks.  for example, the = command, in sc.c, line 1140,  one line change,               case '=':                 if (locked_cell(currow, curcol))                     break;                 /* set mark 0 */                 savedrow[27] = currow;                 savedcol[27] = curcol;                 savedstrow[27] = strow;                 savedstcol[27] = stcol;                  /* btiffin, yank current cell to buffer 0 */                 yankr(lookat(currow, curcol), lookat(currow, curcol));                  (void) sprintf(line,"let %s = ", v_name(currow, curcol));                 linelim = strlen(line);                 insert_mode();                 break;   the call to yankr places the current cell contents in the '0' buffer, as would say the 'x' command, or 'yy'
use grep -l to just get the filename of the matching file and not the matching text, then combine it with vim:  vim "$(grep -l some_pattern file_names)"  
according to this thread, it's the behavior posix specifies for using "set -e" in a subshell.  (i was surprised as well.)  first, the behavior:     the -e setting shall be ignored when executing the compound   list following the while, until, if, or elif reserved word,    a pipeline beginning with the ! reserved word, or any    command of an and-or list other than the last
   why it's vda    because it's a virtual disk
the apparent problem is that op dislikes the way terminal and iterm2 show (or do not show) the alternate screen
setting globignore has no influence on ls, and the ls manual doesn't mention globignore, because ls doesn't care about globignore
type mysql &gt;/dev/null 2&gt;&amp;1 &amp;&amp; echo "mysql present." || echo "mysql not present."  
so you can get explicit about the way the shell goes about locating commands in a few different ways
the linked answer in the other answer is really old and there are many changed things since then
this sed command should do the trick
i once used to have those defined in my .bashrc:  export e="\e["  function cls          { echo -n "${e}h${e}j${e}0m"; } function rcls         { echo -n "${e}h${e}j${e}s${e}h${e}j${e}0m${e}u${e}j"; } # not quite yet ! # rcls only works when no funny codes have been issued in between, i.e
try this patch
on a gnu system:  awk '{"date -d "$1" +%s"|getline one; "date -d "$2" +%s"|getline two; \          print $1, $2, two-one}' file.txt    "date -d "$1" +%s"|getline one gets the seconds since epoch (using gnu date) for field 1, save in variable one "date -d "$2" +%s"|getline two does the same for field 2, and save the result as variable two print $1, $2, two-one prints the field one, two, and subtraction of variable two and one   example:  % cat file.txt 18:37:12 18:37:31 0 18:37:01 18:37:18 0  % awk '{"date -d "$1" +%s"|getline one; "date -d "$2" +%s"|getline two; print $1, $2, two-one}' file.txt 18:37:12 18:37:31 19 18:37:01 18:37:18 17  
the command to start it up is mutter --replace  the command is to be saved in a .sh file and later a .desktop file is to be added to the xsessions directory
syntax is unchecked and unexamined, so i have no idea what it does or if it works
first off
if you have the following command:  command &gt; file   the standard output (fd 1) of the command command is redirected to the file file
with the &amp; inside the loop it will start a new process in the background and as fast as it can do it again without waiting for the first process to end
whoever can read the file will get the password
no
ok, so you want to zip two iterables, or in other words you want a single loop, iterating over a bunch of strings, with an additional counter
technically, i686 is actually a 32-bit instruction set (part of the x86 family line), while x86_64 is a 64-bit instruction set (also referred to as amd64).  from the sound of it, you have a 64-bit machine that has 32-bit libraries for backwards compatibility
you have to install that script in one of the directories of $path
use the find command to execute shred recursively:  find &lt;dir&gt; -type f -exec shred {} \;  
all software are programs, which are also called source packages
on debian-based systems (including ubuntu), packages create users using maintainer scripts, usually postinst
just copy the partitions that you need and the mbr if you need it too.  the mbr is stored in the the first 512 bytes of the disk.  dd if=/dev/sdx of=/path/to/mbr_file.img bs=512 count=1   copy each partition  dd if=/dev/sdx1 of=/path/to/partition1.img bs=512  dd if=/dev/sdx2 of=/path/to/partition2.img bs=512  dd if=/dev/sdx3 of=/path/to/partition3.img bs=512  
sum=$(   awk 'begin {t=0; for (i in argv) t+=argv[i]; print t}' "${arrvalues[@]}" )   with zsh (in case you don't have to use bash), since it supports floating point numbers internally:  sum=$((${(j[+])arrvalues}))   with ksh93:  if you need the kind of precision that bc provides, you could pre-process the numbers so that 12e23 is changed to (12*10^23):  sum=$(   ifs=+   sed 's/\([0-9.]*\)[ee]\([-+]*[0-9]*\)/(\1*10^\2)/g' &lt;&lt;&lt; "${arrvalues[*]}" |     bc -l )  
 with solaris 10, you might try gamin which has a solaris port here. with solaris 11 and newer, there is the native and more efficient fen (file event notification)
 $ ls a b c d $ rm $(except b d) $ ls b d    that can't work, at least not reliably, because "except" cannot decide how the shell will split (and further expand) its output before passing it to the rm command.  to answer your question, printf doesn't use $ifs
have a look at man usermod it shows the -c option which is used to modify the comment field for an account in /etc/passwd.  example:  usermod -c "raspberry pi user account" pi   to update the comments field for the 'pi' user account. 
you can check whether the module you are trying to insert is present or not using   $ modprobe -l | grep usbcore   generally all the modules are present in the path /lib/modules/&lt;kernel-version&gt;/kernel/  if present, you can then insert the module using modprobe or insmod command.  $ insmod &lt;complete/path/to/module&gt;   edit: if modprobe -l option is not there, you can run the following find command to list all the modules:  root@localhost#  find /lib/modules/`uname -r` -name '*.ko'   
kiss implementation in awk:  awk '     fnr == 1 {         n=nf;print;next     }      fnr == 2 || fnr == 3 || fnr == 6 {         for (i=1;i&lt;=nf;i++) a[i]+=$i;     }      fnr == 4 || fnr == 5 || fnr == 7 {         for (i=1;i&lt;=nf;i++) b[i]+=$i     } end {         for (i=1;i&lt;=n;i++) printf("%8s", a[i]); print "";          for (i=1;i&lt;=n;i++) printf("%8s", b[i]); print "";     } ' file  
with tcsh 6.17.01 and above:  set globdot du -s -- *   with older ones:  du -s -- * .[^.]* ..?*   (interestingly, that works better than its posix counterpart (* .[!.]* ..?*) because in tcsh (and in zsh in csh emulation (cshnullglob option)), contrary to posix shells, those pattern that don't match any file get expanded to nothing instead of themselves)  with standard find:  find 
this is complex enough that i would use a full fledged programming language to do it
from the applications screen (move your mouse to the top-left corner), open settings (type "settings" and click on the icon), then keyboard, and click on the shortcuts tab
i love explaining this kind of thing through visualization
in bind -p listing, i can see the command is called edit-and-execute-command, and is bound to c-xc-e in the emacs mode. 
if the dynamic dns service you're using only allows ttl's of 3600, then your only option is to switch providers
prompt_command+="hey.sh;"      prompt_command                 if  set,  the  value  is  executed  as a command prior to issuing each primary                 prompt.     note: environment variables vs shell variables  by default, prompt_command is not an environment variable
another option is to be more specific about what you are grepping for
a single quote would be \x27  awk -f, '{print "\x27"substr($4,1,9)"\x27" }'  
right off the bat make a dd disk image of the drive, and work with that instead of the drive itself
the disvantages of using nohup would be:   no stdout messages
you should be able to just kill the script by name using the pkill command.  $ pkill -9 dispatcher.sh   excerpt from man page  pgrep, pkill - look up or signal processes based on name and other                 attributes  options        -signal        --signal signal               defines the signal to send to each matched process
you could use  find /proc/[0-9]*/fd/ -name 24 2&gt; /dev/null | wc -l   or, if you insist on using ls (this should be one of the few examples where it is safe to do so):  ls /proc/[0-9]*/fd 2&gt;/dev/null | grep -c '^24$'   your first attempt failed because you were redirecting the output to a file (&gt; output.txt) which means that the grep would never match since it had no output to match against
according to this answer, ffmpeg can be used.  (below is a simplified answer based on the one linked above.)   to keep data after a start point (up to the end):  ffmpeg -i input -c copy -ss start_time -map 0 output to keep data between two time points:  ffmpeg -i input -c copy -ss start_time -to end_time -map 0 output to keep data of a certain duration after a certain point:  ffmpeg -i input -c copy -ss start_time -t duration_time -map 0 output to keep data of a certain duration after beginning:  ffmpeg -i input -c copy -t duration_time -map 0 output to keep data from beginning up to a time point:  ffmpeg -i input -c copy -to time_point -map 0 output    time may be a number in seconds, or in hh:mm:ss[.xxx]    to join files, create a file called join.txt with the content  file 'path-to-input1' file 'path-to-input2' file...etc   then   ffmpeg -f concat -i join.txt output   or:  to join mpeg files (including transport files)   ffmpeg -i "concat:input-1|input-2" -c copy -bsf:a aac_adtstoasc output     as a gui solution:  kadenlive, pitivi and openshot cannot cut and save a video without transcoding.  avidemux prior to 2.6.10 doesn't work ok with this kind of files.  to get avidemux 2.6.10/latest in ubuntu,      sudo add-apt-repository ppa:rebuntu16/avidemux+unofficial      sudo apt-get update      sudo apt-get install avidemux2.6-gtk avidemux2.6-qt4   some more dependencies are needed to make it work:  avidemux3-core-2.6.10-yymmdd-runtime avidemux3-plugins-common-2.6.10-yymmdd-plugins avidemux3-qt4-2.6.10-yymmdd-runtime avidemux3-plugins-qt4-2.6.10-yymmdd-plugins avidemux3-cli-2.6.10-yymmdd-runtime avidemux3-plugins-cli-2.6.10-yymmdd-plugins avidemux3-settings-2.6.10--yymmdd-settings   see more details in this answer.  i have also tested avidemux-qt4 2.6 in manjaro, it can be found in aur.  also, latest avidemux for win32 works installed in wine, as indicated here:  http://avidemux.org/nightly/win32/   to join files, use file-open to add first file, and then file-append for the rest.  to save: file - save. 
you can use ps -o ruser= or ps -o uid=:  $ ps -p 930 -o ruser= root $ ps -c cron -o ruser= root $ [[ $(ps -c cron -o uid=) -eq 0 ]]; echo $? 0   -p matches by pid and -c by command name
method 1:   to run the "df -h" command as root:  su -c "df -h"   this will prompt the user for root password.  method 2:  alternatively, in /etc/sudoers find this line:  root    all=(all) all  and duplicate it for your user johnsmith that you want to give admin privileges:  johnsmith    all=(all) all  this way, johnsmith will be able to run any command requiring root rights, by first typing "sudo" in front of the command:  sudo df -h   method 3:  you can use ssh to execute a command on the same machine:  ssh root@localhost "def -h"   will execute the same command in your server
try this line:  readlink -f `which command`   if command is in your $path variable , otherwise you need to specify the path you know. 
as indicated by derobert, debian packages which are maintained in a vcs are supposed to indicate this in a pair of vcs-... fields in their source package.  the best tool to use this information is debcheckout in the devscripts package.  debcheckout -d gnome-disk-utility   will show you gnome-disk-utility's repository information, and if you then want to check the source out,  debcheckout gnome-disk-utility   will do that for you. 
if you have htop you can press shift+k to toggle the display of kernel threads
in sles zypper is the equivalent to apt in debian and yum on rhel
the first problem in your code is that you are parsing ls
i would look at trying a latter version of the driver manager, 2.2.14 is from 2008
debian's stance is that, beyond certain critical system components which are considered required¹, there is no preferred software
you can boot you other systems like this:  $ qemu-system-x86_64 -hda /dev/sdb -m 2g -enable-kvm  \     -net user,hostfwd=tcp::10022-:22 -net nic   assuming that /dev/sdb has a working grub installation.  the -net enables simple networking support (tcp/udp but no icmp) and creates a port redirection for ssh (you can then connect to local port 10022 on the host to ssh into the vm)
 check which libraries postfix requires:  rpm -q --requires postfix  check which libraries that compat rpm provides:  rpm -q --provides mariadb-compat # (please check the name)  if compat does provide what is needed, you can delete the 5.5
try this guy =) :  sed -n 'line_num p' | bash   or   "$(sed -n 'line_num p')"  
if you were using a tool like ecryptfs that decrypts file "on-the-fly", you could mount and share the decrypted data in a "visible" folder, and also separately share the encrypted data in the ".private" folder.  the "visible" folder's decrypted data is only visible while mounted, and it doesn't take up any extra disk space since it's not a hard on-disk decrypted copy (that would be extremely insecure)
i figured it out
it is not exactly clear what you are asking
the font is donald knuth's computer modern
the reason why you see this is because the developer of gnu find chose to provide a "reasonable" behavior for find when no path is given
with some hints from here, i managed to get the following to work:  script=/path/to/script  num=$(dbus-send --print-reply --dest=org.kde.kwin.scripting \   /scripting \   org.kde.kwin.scripting.loadscript \   string:"$script" |   awk 'end {print $2}' )  dbus-send --print-reply --dest=org.kde.kwin.scripting \   /$num \   org.kde.kwin.scripting.run  
   from my exercises with the revert command i made the observation that the abort option works very similar to the one of the rebase command in that it tries to reconstruct the pre-operational state of the current branch.   you're on the right track:   git revert --abort rolls the sequencer state back, so the workspace and history end up as they were before the start of git revert; git revert --quit only removes the sequencer state, so the workspace and history remain as they are (with a partial revert in progress but forgotten about).   from my quick experimentation, if a revert needs manual intervention, git revert --quit only forgets the previous commits; revert_head remains in place so you still need to --continue or --abort
to get you started:  i=0 for file in tl*.jpg do     printf -v counter "%05d" $i     mv $file photo$counter.jpg     i=$((i+1)) done   the printf command ensures the counter has leading zeroes
there are several usual notations for ipv4 and ipv6 addresses
yes "some text" | head -n 100000 &gt; large-file   with csh/tcsh:  repeat 10000 echo some test &gt; large-file   with zsh:  {repeat 10000 echo some test} &gt; large-file   on gnu systems, see also:  seq 100000 &gt; large-file   or:  truncate -s 10t large-file   (creates a 10tib sparse file (very large but doesn't take any space on disk)) and the other alternatives discussed at "create a test file with lots of zero bytes".    doing cat file &gt;&gt; file would be a bad idea.  first, it doesn't work with some cat implementations that refuse to read files that are the same as their output file
if you directly use strings under a for loop, it will work per-word (here on one word: the whole content of $test since it's quoted), not per-character
you can use app-portage/genlop for this.  genlop -l --date some_date   will list all packages merged on or after that date
it's a bash script rather than python-apt, but i have found dpkg-offline which contains similar logic
you have to give the parameter -x a screen command, i think you want to "stuff" a minecraft-server command to the screen session.  screen -r minecraft -p 0 -x stuff "stop $(printf '\r')"   the printf send a carriage return, so the command "stop" gets executed
gross hack, not really tested:   add the following line to /etc/pam.d/gdm:  # update the sudo ticket; proceed whether this succeeds or fails session [success=ignore new_authtok_reqd=ignore] optional pam_exec.so seteuid /usr/local/sbin/update_sudo_ticket  content of /usr/local/sbin/update_sudo_ticket:  #!/bin/sh dir=/var/run/sudo/$pam_user if [ -d "$dir" ]; then touch "$dir"; else mkdir "$dir"; fi    you must have the tty_ticket option turned off in /etc/sudoers (otherwise, it doesn't make sense anyway: a gdm login wouldn't count for whatever you do in a virtual terminal in your x session).  i don't guarantee that this works
if all you want to do is add text to the last line, it's very easy with sed
instead of using nohup, you could have your script ask these questions interactively and then background and disown the remainder of whatever else it has to do.  example  $ more a.bash  #!/bin/bash  read a echo "1st arg: $a" read b echo "2nd arg: $b"  ( echo "i'm starting" sleep 10 echo "i'm done" ) &amp; disown   sample run:  $ ./a.bash  10 1st arg: 10 20 2nd arg: 20 i'm starting $   check on it:  $ ps -eaf|grep a.bash saml      6774     1  0 01:02 pts/1    00:00:00 /bin/bash ./a.bash saml      6780 10650  0 01:02 pts/1    00:00:00 grep --color=auto a.bash   10 seconds later:  $ i'm done  
to protect your data you have to have key, of any sort, which you can guard and control physically and be separately from your secret data
script is based on op's sample data.  sed '     s/\s\s\+/:/g     s/\([a-z)]\)\s\([(0-9a]\)/\1:\2/g     ' file.txt |  column -s: -t    first change easy found separator (2 or more \spaces) by : second find remaining possible separators:   between low letter and digit after ) before a  format string with the column's separator :  
figured it out at last
a more refined approach consists in creating a udev rule, triggered only when the right hardware is present, to launch the needed btattach command from a systemd service
linux doesn't use file extensions to decide how to open a file, but linux uses file extensions to decide how to open a file.  the problem here is that “linux” can designate different parts of the operating system, and “opening a file” can mean different things too.  a difference between linux and windows is how they treat application files vs data files
besides uninstalling the appropriate drivers (which might fail to work since some devices act as usual mouse devices and only need specific drivers for more sophisticated features and your list of installed drivers suggests this) you can also disable the device via the xinput tool or by explicitly matching in xorg.conf.  to disable the device using xinput, you'll have to determine the devices xinput id:  $ xinput ⎡ virtual core pointer                      id=2    [master pointer  (3)] ⎜   ↳ virtual core xtest pointer                id=4    [slave  pointer  (2)] ⎜   ↳ synps/2 synaptics touchpad                id=10   [slave  pointer  (2)] ⎜   ↳ tpps/2 ibm trackpoint                     id=11   [slave  pointer  (2)] ⎜   ↳ my annoying touchscreen                       id=14   [slave  pointer  (2)] ⎣ virtual core keyboard                     id=3    [master keyboard (2)]     ↳ virtual core xtest keyboard               id=5    [slave  keyboard (3)]     ↳ power button                              id=6    [slave  keyboard (3)]     ↳ video bus                                 id=7    [slave  keyboard (3)]     ↳ sleep button                              id=8    [slave  keyboard (3)]     ↳ at translated set 2 keyboard              id=9    [slave  keyboard (3)]     ↳ thinkpad extra buttons                    id=12   [slave  keyboard (3)]     ↳ hid 0430:0005                             id=13   [slave  keyboard (3)]   in this example, »my annoying touchscreen« has the id 14
pushd, popd, and dirs are shell builtins which allow you manipulate the directory stack
the headers in an http request must use crlf (windows) line endings
firstly, according to the file system hierarchy standards, the location of this installed package should be /opt if it is a binary install and /usr/local if it's a from source install.  pure binaries  these are ready to use binaries
i find it interesting that you able to modify new connections, but not existing ones..
tar's default mode is to preserve ownership and permissions on archive creation; i don't believe there's even an option not to store the data
from the fedora project's wiki page on anaconda networking:     if both ipv4 and ipv6 configuration is enabled, failing ipv4   configuration of activated device means that activation is considered   as failing overall (which corresponds to require ipv4 addressing for   this connection to complete checked in nm-c-e or   ipv4_failure_fatal=yes in ifcfg file).   putting it another way it's saying that if a connection is setup for both ipv4 and ipv6, with this option set to yes, the setup of the said connection will be reported as failed, even if ipv6 is setup, and ipv4 is not. 
if you are including binary data (pictures) you will want to create a version 3.0 package.  you put the additional files inside the debian/ directory and either move them from the debian/rules script using install -d -m 644 debian/filename $(destdir)/path/to/install/to or using the debian/install file to list the file and the path to install it to like debian/filename path/to/install/to. 
bindsym $mod+j+f [class=firefox] focus bindsym $mod+j+e [class=emacs] focus   you can get the class argument for any currently window with the following command:  xprop -name &lt;window title&gt; | grep wm_class   this will return something like  wm_class(string) = "emacs", "emacs"   the second string, here emacs is the argument for the class parameter. 
you should call find with absolute directories' names, for example:  find "$pwd"/ -iname '*.txt'  
usually maillog written by syslogd, not by sendmail itself, so you should send sighup to syslogd 
i've found a solution on my own by deep reading man lsof
grep -iarn -c3 word .   this will search the current directory and all subdirectories (just like your find 
ran into the same problem.  turns out the problem is solved by adding the disable_interactive option next to pam_mount.so in the config files ( /etc/pam.d/common-{auth,session}).  it comes right after pam_mount.so and the options are separated with spaces (from the so file name and between each two options).  when the pam_mount.so code gets executed upon a login,  it'll receive the password from the top of the stack and use that password to decrypt your volume.  when you're doing su from a root session, no password is required and therefore pam_mount.so will not get any password
one reason for inodes to be fixed-size is that in the traditional unix filesystem format (which e.g
i can answer the question of "how do they even manage to both read the password?"  a device file named /dev/tty exists
you're going to have to copy all the data around anyway
improving terdon's answer, you don't even need to invoke those two processes (hostname and cut)
you can't do what you state in a useful way, but there's undoubtedly something that's close enough and that will do what you really want.  even if you arranged to create the directory, the www-data user would still not be able to access /some-path/subdirectory, because the subdirectory can only be accessed through the parent directory
solved
gnu grep has the ability to exclude globs from its recursive searches built in
reinstalling qt packages solves the problem.. 
ok, i've found a way, though it does not look very clean ;)  i'll start from the end - running this one-liner will tell you the truth:  grep "usb.*pci" /proc/acpi/wakeup | cut -d ':' -f 2- | while read aaa; do find /dev/.udev -name "*$aaa*" -print -exec grep "$aaa" /proc/acpi/wakeup \; -exec echo \; ; done   nice, isn't it? and here is, how it works:   the beginning should be obvious: grep "usb.*" /proc/acpi/wakeup extracts from the list only usb devices that have a known sysfs node. cut -d ':' -f 2- leaves just the ending (numbers) after 'pci:' on each line. then, for each ending (aaa=0000:00:1d.2 and so on), try to find an udev device symlink that contains the string. for each device symlink found, the find command :  prints the name of udev symlink, &lt;-- this is the most useful part executes grep to display the line from /proc/acpi/wakeup that corresponds to the found device, appends a blank line for output clarity.    so, thanks to the meaningful naming of device symlinks by udev, you can tell which usb device is the keyboard, mouse etc
this document appears to be incorrect or long-obsolete
since wine is a re-implementation of the windows api - you're looking for a re-implementation of the macintosh api or various "kits" that apple provides to let osx apps link to the system frameworks
there's an alternative to compiling your scripts
there is a log file located here, /var/log/dpkg.log:  $ head -10 /var/log/dpkg.log 2013-04-03 07:57:59 startup archives unpack 2013-04-03 07:58:01 upgrade libpoppler19 0.18.4-1ubuntu2 0.18.4-1ubuntu3.1 2013-04-03 07:58:01 status half-configured libpoppler19 0.18.4-1ubuntu2 2013-04-03 07:58:01 status unpacked libpoppler19 0.18.4-1ubuntu2 2013-04-03 07:58:01 status half-installed libpoppler19 0.18.4-1ubuntu2 2013-04-03 07:58:01 status half-installed libpoppler19 0.18.4-1ubuntu2 2013-04-03 07:58:01 status unpacked libpoppler19 0.18.4-1ubuntu3.1 2013-04-03 07:58:01 status unpacked libpoppler19 0.18.4-1ubuntu3.1 2013-04-03 07:58:02 upgrade libpoppler-glib8 0.18.4-1ubuntu2 0.18.4-1ubuntu3.1 2013-04-03 07:58:02 status half-configured libpoppler-glib8 0.18.4-1ubuntu2  
i found this oracle article about oom killer (out of memory killer) answer a half of your question, specially in 'configuring the oom killer' chapter. i extract from there two important commands (i think):   disable oom killer root@host:~# sysctl vm.overcommit_memory=2 exclude a process from oom killer root@host:~# echo -17 &gt; /proc/&lt;pid&gt;/oom_adj   other very interesting answer is 1.4 in this faq from stress project page, it says:     1.4 why is my cpu getting hammered but not my ram?   this is because stress if faily conservative in its default options
while mail may not be able to, and you don't have pine or mutt you probably do have mailx
you didn't read the man page carefully, it also said:     any part of the pattern may be quoted to force the quoted portion to be matched as a string
you're storing your authentication data in a file
as you have discovered you cannot use rsync with a remote source and a remote destination
i think you should be able to use the --copy-unsafe-links option on rsync to copy file data where the symlink points outside of the synchronized folder space but sends just the symlink when the file pointed to is also being synced
bash is the wrong tool altogether
i'm not able to try any of these but i did find this link which discusses a method for increasing the log level during chromium's boot up:   true verbose boot?   this thread might also be relevant, titled: chromium os‎ > ‎how tos and troubleshooting‎ > ‎ kernel faq
set options you want (see help with ? key), then save them with w  so, to get something like old top back, press zv1w    mine ~/.toprc currently looks like this:  top's config file (linux processes with windows) id:i, mode_altscr=0, mode_irixps=1, delay_time=1.500, curwin=0 def fieldscur=¥&amp;kš³Ž»œ@·º¹56ÄfÅ')*+,-./0128&lt;&gt;?abcghijlmnopqrstuvwxyz[\]^_`abcdefghij     winflags=192820, sortindx=18, maxtasks=0, graph_cpus=1, graph_mems=2     summclr=1, msgsclr=1, headclr=3, taskclr=1 job fieldscur=¥Š¹·º(³ŽÄ»œ@&lt;§Å)*+,-./012568&gt;?abcfghijklmnopqrstuvwxyz[\]^_`abcdefghij     winflags=163124, sortindx=0, maxtasks=0, graph_cpus=2, graph_mems=0     summclr=6, msgsclr=6, headclr=7, taskclr=6 mem fieldscur=¥º»&lt;œŸ¿ÀÁmbnÃd34·Å&amp;'()*+,-./0125689fghijklopqrstuvwxyz[\]^_`abcdefghij     winflags=163124, sortindx=21, maxtasks=0, graph_cpus=2, graph_mems=0     summclr=5, msgsclr=5, headclr=4, taskclr=5 usr fieldscur=¥Š§šª°¹·ºÄÅ)+,-./1234568;&lt;=&gt;?@abcfghijklmnopqrstuvwxyz[\]^_`abcdefghij     winflags=163124, sortindx=3, maxtasks=0, graph_cpus=2, graph_mems=0     summclr=3, msgsclr=3, headclr=2, taskclr=3 fixed_widest=0, summ_mscale=2, task_mscale=1, zero_suppress=0  
maybe sed '1s/.\(.*\)/\1/' myfile? 
red hat enterprise linux - how do i install copy paste easy way ssl/https? (its not rocket science anyway!).  1) ask your domain provider to give you three license files which is like  a) certificate   -----begin certificate----- miievtcca6wgawibagis   b) key  -----begin rsa private key----- miiepqibaak   c) intermediate (root ca)  -----begin certificate----- miielzccax    they will send you attached file or email plain encoded data   2) download them or make them in your server stored like below.  [root@ip-10-210-144-105 conf]# pwd /etc/httpd/conf [root@ip-10-210-144-105 conf]# tree . ├── ca-bundle │   └── root.crt ├── httpd.conf ├── magic ├── ssl.crt │   └── crt.crt └── ssl.key     └── key.key   3 directories, 5 files  3) red hat has already https prepared, just use httpd.conf as usual for your port 80 http
an easy way to establish file/url associations without messing around with the gui, and that works on all freedesktop.org compliant de/dm/wm is using xdg-query.  with xdg-query you can, query what application is associated with a determined mime/file/url, change it, and install new ones
add a mirror to the file /etc/pkg.conf:  installpath = http://ftp.eu.openbsd.org/pub/openbsd/5.9/packages/amd64/  
for commands that do not have an option similar to --color=always, you can do, e.g
a socket is just a logical endpoint for communication
with respect to checking if the process is already running i'd change what you're doing slightly and use pgrep instead.  $ pgrep -f connection_manager.sh   example  $ pgrep -f connection_manager.sh 16293   the -f switch allows pgrep to match the entire command line and not just the first part.  command line arguments  for this you have a couple of methods
put this in your .bashrc:  for rc in ~/shell/*.sh do     
if you look at the hardware for a home router you will find that all the ports exist on the same interface
i was searching and searching and finally found the reason
simple use:  find 
the utility you may be thinking of is the namei command
you are looking for ncurses. 
if you have already collected the grep output in a file, you could output a numbered list with:  cat -n myfile   if you only want the number of lines, simply do:  wc -l myfile   there is absolutely no reason to do:  cat myfile | wc -l   ...as this needlessly does i/o (the cat) that wc has to repeat
if gnu timeout is not available you can use expect (mac os x, bsd, ..
you can move the cursor to any x,y co-ordinate with the tput cup command  eg  tput cup 10 3   will take you to line 10, column 3  (co-ordinates start at 0,0 as the top-left)  so a simple script such as  clear echo line 1 echo line 2 echo line 3 tput cup 1 5 echo another line tput cup 10 0   will result in output similar to  line 1 line another line line 3         $   (where the $ is your prompt).  the first tput command moves the cursor back up to the earlier line allowing the echo to overwrite what was already there. 
i'm afraid not
bash is an interpreter; it accepts input and does whatever it wants to
this is an easy job for sort, use the unique (-u) option of sort:  % sort -u file1.txt hello hi how are you i am fine today is monday   to save it in file2.txt:  sort -u file1.txt &gt;file2.txt     if you want to preserve the initial order:  % nl file1.txt | sort -uk2,2 | sort -k1,1n | cut -f2 hi how are you hello today is monday i am fine  
this turned out to be less difficult than it seemed
here's a hacked together script that will do what you want.  $ ( echo -e "&lt;html&gt;\n&lt;body&gt;"; \     for i in {1..4}.png;do echo "&lt;img src="$i"&gt;"; done ; \     echo -e "&lt;/body&gt;\n&lt;/html&gt;" ) | tee 4v.html &lt;html&gt; &lt;body&gt; &lt;img src=1.png&gt; &lt;img src=2.png&gt; &lt;img src=3.png&gt; &lt;img src=4.png&gt; &lt;/body&gt; &lt;/html&gt;   to display the resulting file, 4v.html:  $ xdg-open 4v.html   and the final product:  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  adjustments  if you want to use a different series of .png images merely change the arguments to the for loop.  for i in {1..4}.png;do echo "&lt;img src="$i"&gt;"; done   the files are named 1.png, 2.png, 3.png, and 4.png in my example
the part of your interface config, namely inet6 2001:5c0:1103:5800::/56 in ip addr listing, means two things:   2001:5c0:1103:5800:: is assigned to your interface - you can ping6 it to find out it's valid, whereas 2001:5c0:1103:5800::1 won't respond /56 serves for routing purposes, and means only that if you want to send something to the network with that prefix (inet6 2001:5c0:1103:5800::/56), it should go out using the tun interface
i could reproduce the problem on my system. your main problem are the acl restrictions of your host. for this reason change the acl attributes of the libvirt-qemu user :  sudo setfacl -r -m u:libvirt-qemu:rwx /media/cl   change the mode settings for filesystem /host  from passthrough to mapped.    why? that's the reason why:  your guest system runs as libvirt-qemu user and your acl settings restrict the permissions of this user.  user:libvirt-qemu:--x   the correct output of getfacl should be :  user:libvirt-qemu:rwx  
from the filesystem hierarchy standard,     /var contains variable data files
using a binary array as the indicator function of each subset:  #!/bin/bash  # prepare the indicator, set to all zeros
there is an easy way to install netflix now
write :w and your file will be saved. 
i think reset would definitely fix it.  consider looking into man page.  example:  [m0nhawk@terra:~]&gt; cat /dev/urandom êiÉè;┤Ü)måÇ▐¿÷¢§ôwdo┘&amp;!π¡ [└█┼░▒┬┐@├err▒:·]&gt; c▒├ /de┴/┤r▒┼do└   and resetfixes this. 
bash stores strings as byte strings, and performs operations according to the current lc_ctype setting
what are exactly your "unused files", and why do you want to delete them? if you run out of space in /var, "yum clean all" should get rid of the yum cache (grows quite big)
take, for example, these two files:  $ cat file1 http://google.com example.com http://foobar.org  $ cat file2 example.com google.com foobar.org unique.url   i would just use a tool like sed to remove everything up to the last occurrence of //
i haven't checked that you will get what you want with it, but the first thing i'd try is the audit subsystem
first answer: the gnu way  gnu cp -a copies recursively preserving as much structure and metadata as possible
if all you want to do initially is capture all the output from the device you can use  tail -f /dev/ttyusb0   as this will wait until the device exists then read from it
i assume you have a file with the various strings you are looking for
two possible solutions that spring to mind.  1
i think it's better to handle this programmatically rather than trying to move the cursor around:  awk '/^[[:digit:]]+$/ { if (length(prev) &gt; 0) { print prev }; prev = $0 } !/^[[:digit:]]+$/ { print (length(prev) &gt; 0 ? prev : "") "," $0; prev = ""} end { if (length(prev) &gt; 0) { print prev } }'   will produce the output you're after
use more spaces around [ and ] 
on debian-derivatives, it's handled through the alternatives system:  $ ls -l /usr/bin/vim lrwxrwxrwx 1 root root 21 jun 11  2010 /usr/bin/vim -&gt; /etc/alternatives/vim $ ls -l /etc/alternatives/vim lrwxrwxrwx 1 root root 18 jun 11  2010 /etc/alternatives/vim -&gt; /usr/bin/vim.gnome   the package post install script (the thing that runs when dpkg says "configuring package x") told the alternative system about a new alternative for vim
the perl function kill(0,$pid) can be used.  if the return code is 1 then the pid exists and you're allowed to send a signal to it.  if the return code is 0 then you need to check $!
actually, the files should not be owned by www-data because that means nginx can modify them, which in most cases is not what you want (unless it is a cms that needs to self-update.)  so all the files should be owned by deploy.  if it is a cms and you need to write in a few folders, then those very few (one?) folders should indeed be own by www-data
you are using lvm2 (logical volume manager)
you are almost there, just do it in the loop:  awk '{for(i=2;i&lt;=nf;i++){if(nr==1)h[i]=$i;else if($i&gt;0.1)x[i]++}}end{for(i in x){print h[i]": "x[i]}}'  
if it is not, you would need to bind glob-expand-word to a key sequence
this depends on what you mean by compress
from the findutils find manpage:     if no expression is given, the expression -print is used (but you should probably consider using -print0 instead, anyway).   (-print is a find expression.)  the posix documentation confirms this:     if no expression is present, -print shall be used as the expression.   so find . is exactly equivalent to find 
i think this article will include everything you need.  http://www.deckle.co.uk/squid-users-guide/transparent-caching-proxy.html  and yes, squid is often used as a transparent proxy, in fact many isps implement it unbeknownst to the users in order to reduce traffic.  you should set this up inside your network though, don't put the cache outside the network on the internet (proxies have a bad habit of being heinously abused)
you need to find a group that only you and that user is part of, and give correct permission to the group, not the world.  could be easier with access control lists, if available. 
i changed two files to fix this:   /boot/grub/grub.conf -- remove nomodeset /etc/x11/xorg.conf -- replace vesa with intel  
you might be stuck using a kickstart to define the partition with the encryption type instead of using the graphical install interface. 
it can be done by adding custom actions to policykit
i would take a step further (inspired by this post):  cat /var/log/kern.log |grep usb |tail -2| awk '{print $3}' | awk -f: '{ print ($1 * 3600) + ($2 * 60) + $3 }' # =&gt; 18:23:24 --&gt; 66204   so, after i had:  66204 66020   you could then do:  echo $((66204-66020)) # =&gt; 184  
you need to register as a developer to download the scl 
using sed  this will print only lines that start with a positive number:  sed -n 's/^\([[:digit:]][^ ,]*\).*/\1/p'   combined with one of your pipelines, it would look like:  h5totxt hsli0.126.h5 | harminv -vt 0.1 -w 2-3 -a 0.9 -f 200 | sed -n 's/^\([[:digit:]][^ ,]*\).*/\1/p'   how it works   -n  this tells sed not to print any line unless we explicitly ask it to. s/^\([[:digit:]][^ ,]*\).*/\1/p  this tells sed to look for lines that start with a positive number and print only that number.  in a regex, ^ matches only at the beginning of a line
this is a question that i was going to post here a few weeks ago
it can be done with reboot function (man 2 reboot).  import ctypes libc = ctypes.cdll['libc.so.6'] rb_power_off = 0x4321fedc rb_autoboot  = 0x01234567  def shutdown():     libc.reboot(rb_power_off)  def reboot():     libc.reboot(rb_autoboot)  
there seems to be nothing wrong
use pkill:  pkill blob   that would kill all processes matching the pattern blob.  another approach would be killall, but you should call it with -r so that the pattern is interpreted as a regex:  killall -r blob  
look for mimeapps.list
you should be using mkinitramfs, not mkinitrd
use the project https://github.com/google/skicka, on the readme you can find the instructions to make it work. 
did you check manual page for sudo? the third synopsis example shows  sudo [...] [-u user name ] [var=value] -i | -s [command]    the command part is the thing you are looking for
the typical way to run-some-command-on-the-changing-of-the-directory is via the chpwd hook function (or list of functions named in the appropriately named chpwd_functions array):  % function chpwd () { pwd }   % cd ~/tmp /users/jdoe/tmp % pushd /etc /etc ~/tmp /etc % chpwd_functions=( chpwd_do_ls ) % function chpwd_do_ls () { ls } % cd / / applications ...  
the root user should always exist by default.  if you installed over pxe it's likely that you used a kickstart file.  if that's, true the kickstart file could have the root password in cleartext (this is a bad practice, but still possible)
note that [[ ]] is not in either bourne or posix sh
from man bash     expansion          expansion is performed on the command line after it has been split   into words
i don't think you can map capslock from within vim
if you look at the purpose of /var as given in the filesystem hierarchy standard, it says:     /var contains variable data files
another one... for older nics, the command mii-tool is awesome 
we can distinguish unix the trademark from unix the code-base.  at&amp;t  unix was initially developed at bell labs, owned by at&amp;t
just make your own launcher e.g
your configuration should basically work, but i'd like to make a few suggestions:  first off, i think you want to use attr, not attrs
yes, there are two ways to set hard limits even though not very mainstream since the purpose of the scheduler is to make sure a task completes as fast as possible.   cpulimit, which is not standard in most linux distributions. taskset, which allows you to bind a certain application to a specific core
once upon a time, i was using this simple shell script as a cron job, as you say, at the end of the day.  #!/bin/sh  screen -ls \   | awk '/\(attached\)/{print $1}' \   | while read line ; do       screen -d $line ;      done   screen -d (power detach) also sends a hangup signal to the parent process of screen (usually closing the containing terminal)
it might suffice to use watch:   $ watch tail -n 15 mylogfile.txt  
it was easier than i thought, just installing the systemd-sysv package made all the necessary changes:     breaks: sysvinit-core    description-en: system and service manager - sysv links    systemd is a replacement for sysvinit
you can see where httpd is configured to look for it's configuration files using the -v switch:  $ httpd -v server version: apache/2.2.15 (unix) server built:   feb 13 2012 22:31:42 server's module magic number: 20051115:24 server loaded:  apr 1.3.9, apr-util 1.3.9 compiled using: apr 1.3.9, apr-util 1.3.9 architecture:   64-bit server mpm:     prefork   threaded:     no     forked:     yes (variable process count) server compiled with....  -d apache_mpm_dir="server/mpm/prefork"  -d apr_has_sendfile  -d apr_has_mmap  -d apr_have_ipv6 (ipv4-mapped addresses enabled)  -d apr_use_sysvsem_serialize  -d apr_use_pthread_serialize  -d single_listen_unserialized_accept  -d apr_has_other_child  -d ap_have_reliable_piped_logs  -d dynamic_module_limit=128  -d httpd_root="/etc/httpd"  -d suexec_bin="/usr/sbin/suexec"  -d default_pidlog="run/httpd.pid"  -d default_scoreboard="logs/apache_runtime_status"  -d default_lockfile="logs/accept.lock"  -d default_errorlog="logs/error_log"  -d ap_types_config_file="conf/mime.types"  -d server_config_file="conf/httpd.conf"   you can also use the command lsof to see what files a unix process is accessing
in the context of a unix or linux process, the phrase "the stack" can mean two things.  first, "the stack" can mean the last-in, first-out records of the calling sequence of the flow of control
i don't know about "most effective" as that's rather opinion-based
you can use the env command to start a process with a clean environment
you can use the following css fragment
   when you're using ext4, you can check for badblocks with the command e2fsck -c /dev/sda1 or whatever
it's probably writing to stderr (file descriptor 2) instead of stdout (file descriptor 1, the default)
time zone data 2016a already takes this into account:     america/cayman will not observe daylight saving this year after all.        revert our guess that it would
in updatedb.sh line 175 gives a hint:   pruneregex=`echo $prunepaths|sed -e 's,^,\\\(^,' -e 's, ,$\\\)\\\|\\\(^,g' -e 's,$,$\\\),'`    there the $prunepaths is handled like plain text, the ' ' characters are replaced and no escaping is possible.  to ensure the space survives that line 175, you must denote it without explicitly mentioning it
yes, if you care about the exit code of the compound statement
wrap the script in a shell script and run the shell script instead.  #!/bin/bash  ### xrandr command to set display size downsized xrandr -s 800x600  ..
install sshpass with below commands.     wget http://dl.fedoraproject.org/pub/epel/6/x86_64/sshpass-1.05-1.el6.x86_64.rpm    rpm -ivh sshpass-1.05-1.el6.x86_64.rpm   now login with ssh     sshpass -p ‘password’ ssh root@ip  
in a word: binfmt_misc
according to posix:     definition of a pathname:      a string that is used to identify a file
you could try making the device node manually
freebsd and gnu sort have a -v option for that.  sort -v &lt; filename   gnu ls has a -v option
this can be accomplished with emacs rectangles' string-rectangle function.  m-x string-rectangle     here's an example:  update: my example is for 3 items.  select the region starting just after the first **  to just before item 3 (see pic)
since i was unable to find an answer anywhere on how this is done, i did some experiments, including booting from live usbs of both cinnamon and mint
yum upgrade forces the removal of obsolete packages, yum update may or may not also do this
wowza should really be run as a different user
systemd is the default init system in jessie, even when upgrading
looking at /proc/meminfo will show the "dirty" number shrinking over time as all the data spools out; some of it may spill into "writeback" as well
this is shell specific
when you run this script without any options, getopt will return false, so it won't enter the loop at all
yes, you can treat the device file as a raw device file, and read/write data from/to it using the same apis used to access normal files
set environment variables in ~/.profile, e.g
you can also use below bind key:  bind -m vi-insert '".": yank-last-arg'   or:  bind -m vi-insert ".":insert-last-argument   to get the nth arguments:  bind -m vi-command '"\e-": yank-nth-arg'   now you can use &lt;alt&gt;n &lt;alt&gt;- to get nth argument from previous command. 
i rtfmed the rsync man page again and this time i found what seemed to be the crucial kernel of knowledge:     note that the --include/--exclude command-line options do not allow the full range of rule parsing...   i took that to mean that pointing to files for exclude/include would have the same result
before fedora 17  none of the red hat distros prior to fedora 17 included the ability to do dist-upgrades as you've asked
the best way to get i3 installed and running from a gnome3 desktop is, first to install i3:  apt-get install i3   other packages may also be useful:  apt-get install feh xautolock xbacklight   then, in the gdm3 after selecting a user, just choose the i3 desktop.  my advice is to keep as much from your gnome desktop
sudo systemctl disable avahi-daemon to disable boot time startup.  a few other options are systemctl list-units for a list of all known units, systemctl enable to enable boot time startup, systemctl start to start the service from terminal, but not enable boot time loading and systemctl stop to stop a service which has been started
you can do this using netem
you should try pdftotext (comes under ubuntu in the package poppler-utils). it is a commandline converter
well usually you would only see execution upon exiting a shell if you've manually configured this
boot another clean os, mount the file system and fix permissions.  as your broken file system lives in a vm, you should have your host system available and working
i have a standard function i use in bash for this very purpose:  # check if we're root and re-execute if we're not. rootcheck () {     if [ $(id -u) != "0" ]     then         sudo "$0" "$@"  # modified as suggested below.         exit $?     fi }   there's probably more elegant ways (i wrote this ages ago!), but this works fine for me. 
you can see all shortcuts under "keyboard" in the "settings" and add custom ones.  and you can change the key for the applications menu in the gnome tweak tool. 
any of these should work:  sudo rm \&gt; sudo rm '&gt;' sudo rm "&gt;" sudo find 
as i already stated in a comment, env doesn't fit the requirement as it only shows exported variables.  processing set output to filter out anything that doesn't look like a variable definition is an unreliable hack
output is for packets that are emitted by the host
if there are updates to the kernel, glibc or systemd, you may want to restart so the updated versions are in use
after experimenting with the bios settings i finally was able to get linux to boot using wol! apparently i had to enable both power on by pci devices and power on by pcie devices for it to boot under linux using wol
this is trivial in awk:  $ awk '{if(nr&gt;1){for(i=2;i&lt;=nf;i++){$(i)=$(i)-10;}}print;}' data.txt  id  a   b   c   d   e 1 -9 -8 -7 -6 -5 2 -8 -7 -6 -5 -4 3 -7 -6 -5 -4 -3 4 -6 -5 -4 -3 -2 5 -5 -4 -3 -2 -1 6 -4 -3 -2 -1 0 7 -3 -2 -1 0 1 8 -2 -1 0 1 2 9 -1 0 1 2 3 10 0 1 2 3 4 11 1 2 3 4 5 12 2 3 4 5 6 13 3 4 5 6 7 14 4 5 6 7 8   to preserve the column alignment, you could pipe through column:  $ awk '{if(nr&gt;1){for(i=2;i&lt;=nf;i++){$(i)=$(i)-10;}}print;}' data.txt |       column -t id  a   b   c   d   e 1   -9  -8  -7  -6  -5 2   -8  -7  -6  -5  -4 3   -7  -6  -5  -4  -3 4   -6  -5  -4  -3  -2 5   -5  -4  -3  -2  -1 6   -4  -3  -2  -1  0 7   -3  -2  -1  0   1 8   -2  -1  0   1   2 9   -1  0   1   2   3 10  0   1   2   3   4 11  1   2   3   4   5 12  2   3   4   5   6 13  3   4   5   6   7 14  4   5   6   7   8  
try umount -f /media/sdb1 or umount -l /media/sdb1.  if all else fails you can manually edit /etc/mtab to remove the offending mount entry. 
if you want to see the file name and line number, posixly:  find 
awk will do it:  awk '     begin {         priority["ok"] = 10         priority["critical"] = 20     }     /^$/ {next}     /^checking/ {var = $nf}     {         if (priority[status[var]] &lt; priority[$nf])             status[var] = $nf         if ($nf == "critical")             crit[var ":" $4] = 1     }     end {         for (var in status)             print var, status[var]         for (c in crit) {             split(c, ary, /:/)             printf("critical at %s for %s\n", ary[2], ary[1])         }     } '   outputs  $var ok $var2 ok $var3 critical critical at results3 for $var3  
it's part of the tcp (or udp, etc.) header, in the packet
sed processes input line by line
try nmblookup &lt;wins-hostname&gt;. 
you can set the index_format variable to include all manner of different details about each message
no
you'll have to define a new option. first, make a new symbol file e.g
maybe i miss a point, but if your original request is basically the same with this:  grep -l "mytext" *   then its perl equivalent could be written as:  perl -ne 'if(/mytext/){print"$argv\n";close argv}' *   note to readers: the following code is updated according to the owner comments, not fully compatible with the original question.  #!/usr/bin/perl  @list_code=qw{ over 100 elements here }; @original=@argv;  foreach $ele (@list_code) {   @argv=@original;   @found=();   while (&lt;&gt;) {     if (/\q$ele\e/) {       push @found,$argv;       close argv;     }   }   print "$ele found in ",scalar @found," files : \n",join "\n",@found,''; }  
where is /lib/firmware?  the final resting place for your edid mode firmware should be under /lib/firmware/edid
you could use alt+> to go back to the end of your history then search again, but maybe you knew that, and it's not what you want.  unfortunately, i don't think there's a way to make it wrap around.  i can't see anything about it in man bash or man readline.  we could try writing a readline macro, but there's no variable telling us what line of history we're on.  so short of that, here's some other suggestions that you might find viable alternatives:    if your terminal is configured to send ctrl+s, (e.g
the solution was to boot the computer using the usb stick, and then run boot repair, which i only just learned about.  it was easy to install via repository, and the process was very clear
first, note that the -z test is explicitly for:     the length of string is zero   that is, a string containing only spaces should not be true under -z, because it has a non-zero length.  what you want is to remove the spaces from the variable using the pattern replacement parameter expansion:  [[ -z "${param// }" ]]   this expands the param variable and replaces all matches of the pattern  (a single space) with nothing, so a string that has only spaces in it will be expanded to an empty string.    the nitty-gritty of how that works is that ${var/pattern/string} replaces the first longest match of pattern with string
use hexdump(1)  $ hexdump -x /usr/bin/hexdump  0000000    feca    beba    0000    0300    0001    0700    0080    0300 0000010    0000    0010    0000    5080    0000    0c00    0000    0700 0000020    0000    0300    0000    00a0    0000    b06f    0000    0c00 0000030    0000    1200    0000    0a00    0100    0010    0000    107c 0000040    0000    0c00    0000    0000    0000    0000    0000    0000 0000050    0000    0000    0000    0000    0000    0000    0000    0000   ... 
i've found the answer
follow the same basic instructions in phunhehe's post except instead of xdg-open you can use kioclient exec https://mail.google.com/mail/?view=cm&amp;fs=1&amp;tf=1&amp;to=%t&amp;su=%s&amp;%u
check your .ssh/config file and/or create a ssh wrapper script:  echo '#!/bin/sh\nssh -v -v $*' &gt; custom_ssh chmod +x custom_ssh git_ssh="./custom_ssh" git clone [...]   and check the debug output of ssh. 
if your keyboard lacks the menu key, the equivalent key combination is shift+f10
gconftool-2 -t string -s /desktop/gnome/background/picture_options scaled # background style gconftool-2 -t string -s /desktop/gnome/background/picture_filename pathtoimagehere # background file  
take a look at the archlinux wiki on slim, especially this sections: enabling slim and multiple environments. 
update the below didn't make the problem go away, but upgrading to linux kernel 3.16 has had a dramatic improvement!  i solved this while figuring out a related problem! why is my laptop-mode configuration being ignored?  it turns out that the default "min cpu freq" is set to 0% for intel pstate devices
the construction &lt;(tac file) causes to shell to:   create a pipe with a name  on systems such as linux and sysv which have /dev/fd, a regular pipe is used, and /dev/fd/&lt;the-file-descriptor-of-the-pipe&gt; is used as the name. on other systems, a named pipe is used, which requires creating an actual file entry on disk.  launch the command tac file and connect it to one end of the pipe. replace the whole construction on the command line with the name of the pipe.   after the replacement, the command line becomes:  grep whatever &lt; /tmp/whatever-name-the-shell-used-for-the-named-pipe   and then grep is executed, and it reads its standard input (which is the pipe), reads it, and searches for its first argument in that.  so the end result is the same as with...  tac file | grep whatever   ...in that the same two programs are launched and a pipe is still used to connect them
a simple solution with some more information:  ls -hago | column   also interesting (but without the links shown): this will show all files with human-readable sizes in columns:  ls -sh   these commands will do the job:  ls -lah | awk '{print $5, $9$10$11}' | column -t | column   or   ls -hago --color=no| sed 's/^[^ ][^ ]* *[^ ][^ ]* \( *[^ ][^ ]*\) ............/\1/' | column   with coloring it works too, but doesen't look so ordered:  if [ -t 1 ]; then color=yes; else color=no; fi ls -hago --color="$color"| sed 's/^[^ ][^ ]* *[^ ][^ ]* \( *[^ ][^ ]*\) ............/\1/' | column  
only command line options with one hyphen are possible in the exec field.  exec=sh -c "gourmet --gourmet-directory $home/my/custom/path/ %f"  should work. 
i presume one could always safely and uniformly declare and initialize variables as follows:  declare a="" declare -p a # output: declare -- a="" declare -i b=0 declare -p b # output: declare -i b="0" declare -a c=() declare -p c # output: declare -a c='()' declare -a d=() declare -p d # output: declare -a d='()'   given that there seems to be differing behavior accross different releases of the bash shell.  when one doesn't provide an explicit initialization value while declaring a variable the result might not what one expects as demonstrated in the following example with local variables:  function foobar {   declare a   declare -i b   declare -a c   declare -a d   declare -p a b c d   a=a   b=42   c+=(c)   d+=([d]=42)   declare -p a b c d } foobar # output: # declare -- a="" # declare -i b="" # declare -a c='()' # declare -a d='()' # output: # declare -- a="a" # declare -i b="42" # declare -a c='([0]="c")' # declare -a d='([d]="42" )' declare -p a b c d # output: # bash: declare: a: not found # bash: declare: b: not found # bash: declare: c: not found # bash: declare: d: not found   in the case of local variables and late initialization everything works as expected
this is presently a known bug in virt-manager - see the email thread at https://www.redhat.com/archives/virt-tools-list/2016-january/msg00007.html.  in the meantime, i'll find another way round the problem. 
in the large script, in which the above function was integrated to work as part of it, and prior of defining the hpf_matrix function, the ifs has been changed to ifs=, without taking care to reset it back before using the unquoted command substitution in the function!  an explanation on using unquoted command substitution ($(...)) without setting $ifs here: http://unix.stackexchange.com/a/88259/13011.  a solution to this also here: http://unix.stackexchange.com/a/92188/13011. 
the x11 protocol defines a keycode as a 8-bit value in the range [8,255]
core files are written for post mortem of crashed processes, you must find out what is happening (a segmentation fault or other crash might signal a serious security vulnerability!).  as the file is written after the program crashed, they can safely be removed at any time
assuming that 10.0.2.15 is your dns, from any of the servers in 10.0.4.0/24 network, use the following command to verify this:     dig www.google.com @10.0.2.15   this command will try to resolve google.com (or any hostnames you want to try) using the nameserver 10.0.2.15
you could use perl
gnome-weather uses libgweather underneath which in turn uses several gweatherproviders (defined in gweather-weather.h) to get weather information for your particular geo-location:    * gweatherprovider: ....  * @gweather_provider_metar: metar office, providing current conditions worldwide  * @gweather_provider_iwin: us weather office, providing 7 days of forecast  * @gweather_provider_yahoo: yahoo weather service, worldwide but non commercial only  * @gweather_provider_yr_no: yr.no service, worldwide but requires attribution  * @gweather_provider_owm: openweathermap, worldwide and possibly more reliable, but requires attribution and is limited in the number of queries ....   you could look into the source code and see how they do it: weather-metar.c, weather-iwin.c, weather-yahoo.c, weather-yrno.c, weather-owm.c
after some research i learned how to use xbindkeys
you are right, even with minimal installation, the current freebsd requires a minimum of 600 mb, especially if you go for a amd64 release.  there is still some options left:   using an "old" 7.x or 8.x (i386) release  i tried to install an "old" 7.3 (i386) with everything to minimal and it took 270 mb.  assuming your machine is old enough, you will not care about a 64 bits system and maybe this old (but sturdy) system would be small enough for your needs. installing a nanobsd  this is a way of generating a bare-minimal system image from a living one.  you will choose exactly what to keep, but this is no ordinary click-type installtion
if you only want to free up the mount point, and don't care about terminating the ssh connection, you can run fusermount -z /mount/point
to restore the ext4 partition and its data, i thought about creating one, disk-wide ext4 partition
the same tools that you can use for other files (generally) can also be used on block devices
try:   n=0; for f in *; do d="subdir$((n++ / 1000))"; mkdir -p "$d"; mv -- "$f" "$d/$f"; done   n keeps track of how many files have been moved
don't parse ls
with gnu sed, which supports replacing all occurrences from particular count  $ echo label=\"123 \"456\" 789\" \"ab c\" e f gh | sed -e 's/"/\\"/2g; s/\\("[^"]*)$/\1/' label="123 \"456\" 789\" \"ab c" e f gh   all " (expect first ") are replaced with \" and then \ is removed from last \"   if gnu sed is not available, remove \ from first \" as well  $ echo label=\"123 \"456\" 789\" \"ab c\" e f gh | sed -e 's/"/\\"/g; s/\\"/"/; s/\\("[^"]*)$/\1/' label="123 \"456\" 789\" \"ab c" e f gh   note: some sed versions use -r option instead of -e for extended regex   with perl  $ echo label=\"123 \"456\" 789\" \"ab c\" e f gh | perl -pe 's/(^[^"]*"|"[^"]*$)(*skip)(*f)|"/\\"/g' label="123 \"456\" 789\" \"ab c" e f gh   here, the string up to first " and string from last " to end of line are skipped while the remaining " are replaced with \" 
xscreensaver has a -watch option:  -watch&nbsp; &nbsp;    prints a line each time the screensaver changes state: when the screen blanks, locks, unblanks, or when the running hack is changed
as a prerequisite, the gnome shell extension has to be installed where gnome-shell can find it
if your system has proper kernel modules loaded, it should be enough to run eject /dev/sr0 (assuming /dev/sr0 is the printer's virtual cdrom device - see dmesg to check this)
if you look at your pfiles output for file descriptor 10, you'll notice that the file is a fifo; this is also evidenced by the p type in your ls listing
you can run python + tools from your home directory. go to https://www.continuum.io/downloads to get anaconda which has all of these packages listed here: http://docs.continuum.io/anaconda/pkg-docs including libffi, openssl, and zlib.  once you install, restart your terminal and wallah
you can use command keyword in authorized_keys to restrict execution to one single command for particular key, like this:  command="/usr/local/bin/mysync" ...sync public key..
one option may be to remove the "r" formatoption, with:  :set formatoptions-=r   and also possibly other options, all of which i found at: http://vi.stackexchange.com/questions/1983/how-can-i-get-vim-to-stop-putting-comments-in-front-of-new-lines 
you can't do this with the obvious scale=0 because of the way that the scale is determined.  the documentation indirectly explains that dividing by one is sufficient to reset the output to match the value of scale, which defaults to zero:     expr1 / expr2 the result of the expression is the quotient of the two expressions
a simple awk filter could be used.  we know, from ps aux output that vsz is column 5 and rss is column 6 so we can do  ps aux --sort rss | awk '$5 == 0 &amp;&amp; $6 == 0'   that will only display the fields where both values are zero.  if you also want the header  ps aux --sort rss | awk 'nr==1 || ($5 == 0 &amp;&amp; $6 == 0)'  
of course you can use montage from the imagemagick suite of utilities
the problem is somewhat similar to accessing the x display and finding the location of the x cookie file
when you use the :! command, a new shell is spawned from within vim
with sox(sound exchange); if you have two files with similar bitrates or already set to one channel:  play -m a.mp3 b.mp3   otherwise:  play -m "|sox a.mp3 -p remix 0 1-2" "|sox b.mp3 -p remix 1-2 0"   what this does is simply play the output of two sox commands which output to pipe(-p); the first one remixes l/r to r and the second remixes l/r to l
try:  $ echo "ibm, inc.:app-vm-core:4.4.2.0:04," | sed '/^ *ibm/s/,//' ibm inc.:app-vm-core:4.4.2.0:04,   or:  $ echo "ibm, inc.:app-vm-core:4.4.2.0:04," | sed 's/^\( *ibm\),/\1/' ibm inc.:app-vm-core:4.4.2.0:04,  
one way to do this with sed is to generate a sed script:    tmpfile=/tmp/nainita.$$ exec 3&lt; file2 grep -n "tid\.setnr" file1 | while ifs=: read n junk do         ifs= read -r line &lt;&amp;3  ||  break         printf "%sc%s\n%s\n" "$n" '\' "$line" done &gt; "$tmpfile" exec 3&lt;&amp;- sed -f "$tmpfile" file1 &gt; modified_file1 rm -f "$tmpfile"    exec 3&lt; file2 opens file2 for reading on file descriptor 3. the grep -n finds the lines in file1 that contain tid.setnr, by line number.  this gets piped into a while loop. while ifs=: read n junk   while … read … means read a line at a time, repeatedly, as long as there is information to read (i.e., stopping when it reaches the end of the data). ifs=: read n junk means read everything up to the first : (which will be the line number from grep -n) into n, and the rest of the line (the old tid.setnr data line) into junk, which we ignore, because we don’t care about it.  ifs= read -r line &lt;&amp;3 reads a line from file descriptor 3 (file2), doing everything that we know how to do to tell the shell not to mangle it, and put it into a variable called line. …  ||  break says, if the above read fails (presumably due to end of file), break out of the loop. the printf writes a sed change command, addressed to line number n, saying that that line should be replaced with the content on the line variable. done &gt; "$tmpfile" marks the end of the while loop and specifies that the standard output of the entire loop is $tmpfile.  this will end up looking like this:  13c\ &#x23;.tid.setnr := 1254 22c\ &#x23;.tid.setnr := 9056   note that the while loop terminates as soon as it gets an eof from either input.  therefore, if file1 has more tid.setnr lines than file2, the extra ones will go unchanged (i.e., c commands for them will not be generated).  similarly, if file2 has more tid.setnr lines than file1, the extra ones will be ignored.  unfortunately, this discrepancy will not be reported, although adding that capability would not be very hard.  exec 3&lt;&amp;- closes file descriptor 3. sed -f "$tmpfile" file1 &gt; modified_file1 runs sed on file1, reading commands from $tmpfile and writing output to modified_file1.   this should do what you want.  obviously, change the filenames if you want.  you should run this “as is” once, and then look at the modified_file1 file (or simply change the sed command not to redirect its output, so it writes to the screen) and verify that the output is what you want.  then you can change the sed command to sed -i to edit file1 in place (if that’s what you want to do).  if the sed command gives an error like “too many line numbers”, try splitting the script file ($tmpfile) into smaller files.  i suggest starting with a size under 100 commands; e.g., 90 commands, which is 180 lines, since each command is two lines.  you can do this manually, with a text editor1, but there’s a tool written specifically for this job.  it is, intuitively, called split.  the command  split --lines=180 "$tmpfile"   will split the script into files in the current directory called xaa, xab, xac, ….  the first n−1 will be 180 lines long; the last one will be whatever it needs to be (≤ 180) to make up the total.  for example, if you have 500 instances of tid.setnr, then your script will be 1000 lines long, and you will get six x files — xaa, xab, xac, xad, and xae will each have 180 lines, and xaf will have 100.  now do  sed -f xaa file1 &gt; modified_file1aa   if you still get “too many line numbers”, go back and try it again with a smaller number of --lines.  if it doesn’t report an error, look at modified_file1aa and see whether it looks like the first 90 tid.setnr lines have been changed.  if it looks ok, then do  sed -f xab modified_file1aa &gt; modified_file1ab sed -f xac modified_file1ab &gt; modified_file1ac sed -f xad modified_file1ac &gt; modified_file1ad sed -f xae modified_file1ad &gt; modified_file1ae sed -f xaf modified_file1ae &gt; modified_file1af   modified_file1af is now your final modified_file1.  if you want to play experiment, you can   try larger numbers of --lines until you find out what the maximum is. try  sed -f xaa -f xab -f xac -f xad -f xae -f xaf file1 &gt; modified_file1_test   but that probably won’t work. if you do the above experiments, i encourage you to tell us the results.   if you only need to do this one time, you’re done.  but, if you need to do this repeatedly, change the last two lines of the code block at the top of this answer to  split --lines=180 "$tmpfile"            &lt;--- (using a number that works for you, of course) cp file1 modified_file1 for f in x* do         sed -i -f "$f" modified_file1 done rm -f "$tmpfile" x*  as i mentioned earlier, the -i option tells sed to edit the specified file in place (i.e., write the changes back out to the input file).  or, even simpler,  split --lines=180 "$tmpfile" for f in x* do         sed -i -f "$f" file1 done rm -f "$tmpfile" x*   if you don’t need to keep your original file1 intact.  note that the usage synopsis for split is  split [option]… [input [prefix]]  and its default behavior is to create files called prefixaa, prefixab, prefixac, etc.  in other words, the default prefix is x.  if you might have other files whose names begin with x, you should define prefix to be something that will be unique (e.g., prefix=nainita.$$. or prefix=/tmp/nainita.$$.) and then change the above to  split --lines=180 "$tmpfile" "$prefix" for f in "$prefix"* do         sed -i -f "$f" file1 done rm -f "$tmpfile" "$prefix"*   ______ 1 if you’re a glutton for punishment, you could do it with sed — but why play with fire? 
sudo iotop gives you a nice, top-like overview of all disk io activty like this:    to install, use sudo apt-get install iotop 
do not put spaces around the "=" character in the final_amount line: variable assignment in shells does not support such spaces because this would conflict with things like command_name = arg2
certanly task can be done by sed  sed '/20150408 13:29:28/,/20150408 17:55:02/! d' log_files   but if lines did not have exact 20150408 13:29:28 script will print nothing and if its did not have exact 20150408 17:55:02 file will print every lines till the end. so the better is use date compare by script:  limit1=$(date -d "20150408 13:29:28" +"%s") limit2=$(date -d "20150408 17:55:02" +"%s") while read -r logdate logtime logline do     logsec=$(date -d "$logdate $logtime" +"%s")     if [ $limit1 -le $logsec -a $limit2 -ge $logsec ]     then         echo $logdate $logtime $logline     fi done &lt; log_files  
this is caused by your client rather than the server
delete the headers and what you'll have left is gzip-compressed data that can be decompressed with gzip -d or zcat. e.g
dolphin does not seem to be able to use the disconnection methods of the various protocol it uses. 
izkata's comment revealed the answer: locale-specific comparisons
i don't have lubuntu installed to test but maybe:    to configuration file ~/.config/openbox/lubuntu-rc.xml adding the lines below :  &lt;!-- option to maximize all normal window when launched--&gt; &lt;application type="normal"&gt; &lt;maximized&gt;true&lt;/maximized&gt; &lt;/application&gt;   removal of this was suggested as a way to stop it from doing so here
i would look in /etc/profile.d/ for the offending alias.  you could also do the following to find it:  grep -r '^alias command' /etc   this will recursively grep through files looking for a line beginning with alias command.  if all else fails, put this at the end of your ~/.bashrc  unalias command  
suppose you've set up successfully a bcache, you are already working on it, put there a lot of important data too big to simply backup and start over, when you realized, that you'd better replace the caching device
press machine &gt; group and you can rename the group
after removing the s permission i was able to load the library correctly
don't copy multiple lines of text, to paste
you have a raid controller there, not a bare-disk scsi controller
the rsync program does exactly that
you could either set up auditing or use dtrace
the link editor command language appears to be described in the at&amp;t unix™ pc model 7300 unix system v programmers guide, chapter 17: the link editor.  i found a copy of the programmer's guide (pdf) at http://www.tenox.net/docs/
based on the comments to my original question, make rsync output to stdout with the -i flag and use a non string check condition to see if anything actually changed within the error code check
chromium can also use the mozilla plugins
i'm sure there are other ways to do this..
you can either explicitly specify the environment variables you want at the top of your crontab, or you can source your environment from somewhere.  to add environment variables explicitly, you can use a line like this at the top of your script (after the hashbang):  foo=bar   to source them from a file, use a line like this:  
   question one: do ubuntu and redhat (or all linux in general) use the same drivers?   essentially, but not exactly
i found a very nice solution: rlpr
short:   terminfo won't take you there, won't help there is no reliable way to determine what encoding a terminal actually uses starting from unicode literals is the way to go, provided that you know what encoding to want to use on the terminal the user has to know what locale is appropriate and what encoding the terminal can do the c standard has functions for converting "wide" characters which you will have available on any unix-like platform (see for example setlocale, wcrtomb and wcsrtombs)  
you can match on multiple patterns like so:  awk '/jun/ || /july/ || /aug/' &lt;(ls -lrh)  this returns all matches for either jun, july, or aug. you don't require the print statement as that is awk's default action. 
use ./ before your filename:  scp ./test.json-2014-08-07t11:17:58.662378 remote:tmp/   that make scp know it's a file
using zathura with tabbed might help here:  tabbed provides a "simple generic tabbed fronted to xembed aware applications" and zathura is a simple pdf viewer that is xembed-aware.  a much more heavyweight approach would be letting a browser provide the tabbing while having the chapters displayed using plugins, e.g
here is the ubuntu wiki entry on how to disable the middle mouse button. this should work on any system using x.     example: disabling middle-mouse button paste on a scrollwheel mouse      scrollwheel mice support a middle-button click event when pressing the   scrollwheel
there's no option for that in updatedb.conf
there are things (usually in the kernel, like the nfs threads, swap files, bind mounts, etc.) that can keep a filesystem busy that won't show up in fuser.  if you try to fsck a filesystem that is mounted, it will get corrupted
in your constellation /mount_folder is the base directory where subdirectories will be mounted by the indirect mount-map auto.ext-usb.  see man 5 autofs for further details.  example:  usbdisk -fstype=vfat,uid=yourworkingusername :/dev/disk/by-id/thediskid   if you cd /mount_folder/usbdisk your usbdisk will be mounted there (i assume it is vfat formatted).  you can use /etc/fstab instead - but then you will to have to mount "by hand".  the entry in /etc/fstab looks like this:  /dev/disk/by-id/thediskid /mount_folder vfat defaults,user,noauto 0 0   after that you can mount the usb-disk as ordinary user with mount /mount_folder
this appears to be an issue with quoting
zsh by default asks you for confirmation, when you try and run any command called rm with * as a whole word on the command line (a feature inherited from tcsh though in tcsh it's not enabled by default).  $ rm -rf * zsh: sure you want to delete all the files in / [yn]?   if you have to use bash, with recent versions of bash, you could do something approaching by using extdebug and the debug trap:  shopt -s extdebug check_for_rm_star() {   case $1 in     (rm*[\ /]"* "* | rm*[\ /]\*)       read -p "check_for_rm_star: are you sure? " -n1 answer &lt; /dev/tty &gt; /dev/tty       echo &gt; /dev/tty       [[ $answer == [yy] ]]   esac } trap 'check_for_rm_star "$bash_command"' debug   that's a simplistic one that would work for rm * and the most common cases but not for instance for rm "*" or /bin/rm * or : $(rm *), but you get the idea
you have two processes reading from /dev/pts/2
here's the script i ended up using:  #!/bin/bash set +x src=$1 bck=$src/.snapshots cur=$bck/current dat=$(date +%y-%m/%y%m%d) dst=$bck/$dat par="-ap --chmod=a-w,o-rwx --no-owner"  lnk="--link-dest=$cur --link-dest=$dst.changeset" cmp="--compare-dest=$cur --prune-empty-dirs" xcl="--exclude-from $bck/.rsyncignore" log="$bck/log/$dat" lgp="--log-file $log"  mkdir -pm750 $dst.incomplete mkdir -pm750 $dst.changeset.incomplete mkdir -pm750 $(dirname $log)  rsync $par $cmp $xcl $lgp.change.log $src/ $dst.changeset.incomplete | tee $log.change.out mv $dst.changeset.incomplete $dst.changeset find $dst.changeset -type d -empty -delete rsync $par $lnk $xcl $lgp.log $src/ $dst.incomplete | tee $log.out mv $dst.incomplete $dst rm -f $cur ln -s $dat $cur   it will create snapshots in a dst=$1/.snapshots/yyyy-mm/yymmdd fashion, and $dst.changeset will contain only the non-empty directories containing files that have been created or modified
   name   chvt - change foreground virtual terminal      synopsis   chvt n      description   the command chvt n makes /dev/ttyn the foreground terminal
tmux sets the $tmux variable to point to the socket, so you can do something like  if [ -z "$tmux" ] then   .... fi   the stuff inside the test will only be run if the variable is not set - ie you're not already inside a tmux session. 
i’ve got a solution that’s written for posix shell compliance, but i’ve tested it only in bash, so i don’t know for sure whether it’s portable.  and i don’t know zsh, so i have made no attempt to make it zsh-friendly.  you pipe your command into it; passing a command as argument(s) to another command is a bad design*.  of course any solution to this problem needs to know how many rows and columns the terminal has.  in the code below, i’ve assumed that you can rely on the lines and columns environment variables (which less looks at).  a more reliable method is to look at the output from stty size.  note that this command must have the terminal as its standard input, so, if it’s in a script, and you’re piping into the script, you’ll have to say stty size &lt;&amp;1 (in bash).  capturing its output is even more complicated.  the secret ingredient: the fold command will break long lines the way the screen will, so the script can handle long lines correctly.  #!/bin/sh buffer=$(mktemp) rows="$lines" cols="$columns" while true do       ifs= read -r some_data       e=$?        # 1 if eof, 0 if normal, successful read.       printf "%s" "$some_data" &gt;&gt; "$buffer"       if [ "$e" = 0 ]       then             printf "\n" &gt;&gt; "$buffer"       fi       if [ $(fold -w"$cols" "$buffer" | wc -l) -lt "$rows" ]       then             if [ "$e" != 0 ]             then                   cat "$buffer"             else                   continue             fi       else             if [ "$e" != 0 ]             then                   "${pager:="less"}" &lt; "$buffer"                   # the above is equivalent to                   # cat "$buffer"   | "${pager:="less"}"                   # … but that’s a uuoc.             else                   cat "$buffer" - | "${pager:="less"}"             fi       fi       break done rm "$buffer"       * why is passing a command as argument(s) to another command a bad design?  i
i am not sure if this answers your question, but i found this perl script that claims to do exactly what you are looking for
if your source directory is aaa and your target directory is /path/to/bbb this could satisfy your requirement:  rmdir aaa ln -s /path/to/bbb aaa   now anything put into aaa will instantly be present in bbb, because they are effectively the same place. 
it is not important how much swap is ussed unless it is full
nice launches a new command with a modified nice level (lower priority than it would have otherwise had, or higher priority if you have permission)
you need to run the shell as the user, not the curl or the which command.  there are several ways this can be done, including:  sudo -u user bash -c 'curl -l https://get.rvm.io | bash'   and  curl -l https://get.rvm.io | sudo -u user bash   if you want to do it interactively, you can use sudo's -s option to override the fact that they don't have a valid shell
if you run bash as:  ld_debug=bindings bash   on a gnu system, and grep for bash.*tinfo in that output, you'll see something like:     797:     binding file bash [0] to /lib/x86_64-linux-gnu/libtinfo.so.5 [0]: normal symbol `up'    797:     binding file bash [0] to /lib/x86_64-linux-gnu/libtinfo.so.5 [0]: normal symbol `pc'    797:     binding file bash [0] to /lib/x86_64-linux-gnu/libtinfo.so.5 [0]: normal symbol `bc'    797:     binding file bash [0] to /lib/x86_64-linux-gnu/libtinfo.so.5 [0]: normal symbol `tgetent'    797:     binding file bash [0] to /lib/x86_64-linux-gnu/libtinfo.so.5 [0]: normal symbol `tgetstr'    797:     binding file bash [0] to /lib/x86_64-linux-gnu/libtinfo.so.5 [0]: normal symbol `tgetflag'   you can confirm from the output of nm -d /bin/bash that bash is using those symbols from tinfo.  bringing the man page for any of those symbols clarifies what they're for:  $ man tgetent name    pc, up, bc, ospeed, tgetent, tgetflag, tgetnum, tgetstr, tgoto, tputs -    direct curses interface to the terminfo capability database   basically, bash, more likely its readline (libreadline is statically linked in) editor, uses those to query the terminfo database to find out about terminal capabilities so it can run its line editor properly (sending the right escape sequences and identify key presses correctly) on any terminal.  as to why readline is statically linked into bash, you have to bear in mind that readline is developed alongside bash by the same person and is included in the source of bash.  it is possible to build bash to be linked with the system's installed libreadline, but only if that one is of a compatible version, and that's not the default
that package doesn't exist in the current debian stable (squeeze), but it's in testing (wheezy)
use rpm's query command with the configfiles option:  rpm -qc flow-tools  
based on your comment:     i mean i would like to know 'how bash is executing each and every line of shell script' when running a .sh file..   if you are using bash, then what you're looking for is:  bash -x ./filename.sh   or  bash -x ./filename.sh &gt; log.txt   alternatively you can add:  set -x   to the content of filename.sh. 
a possible solution is for example with awk and reading /etc/shadow and /etc/group (i assume you don't need system users and i am trying to exclude them and locked users):  awk -f":" 'nr==fnr {     if ($2 !~ /\!/ &amp;&amp; $2 !~ /\*/) {         m[$1] = "";     }     next; } {     for (i in m) {         if ($4 ~ i || $1 == i) {             m[i] = m[i] $1 " ";         }     } } end {     for (i in m) {         print i ":", m[i];     } }' /etc/shadow /etc/group   you can remove if ($2 !~ /\!/ &amp;&amp; $2 !~ /\*/) condition to list all user accounts, and also note that existence of ! or * in /etc/shadow means the user is not be able to use a unix password to log in (but the user may log in the system by other means e.g
let me throw in some more arguments why the transition is rather slow (but there is definitely one):  first of all it is sometimes very difficult for customers to switch from one unix vendor to another
you can make a file as big or as small as you want - especially on a linux tmpfs.  df -h /tmp     filesystem      size  used avail use% mounted on tmpfs            12g  472k   12g   1% /tmp   we can just make a sparse file.  for cmd in  \        'dd bs=1024k seek=20k of=' \        'ls -slh ' do      eval "$cmd/tmp/file"         echo done    &lt;/dev/null     0+0 records in 0+0 records out 0 bytes (0 b) copied, 0.000152051 s, 0.0 kb/s  0 -rw-r--r-- 1 mikeserv mikeserv 20g dec 24 20:19 /tmp/file   see? it's using 0 blocks of disk space, but its apparent size is 20 gigabytes.  you can then just fdisk /tmp/file
@wurtel's comment is probably correct: there's a lot of overhead establishing each connection
try to uninstall syncdrive completely and then  try to correct broken dependencies,  sudo dpkg -p syncdrive sudo apt-get install -f  
red hat uses bash as its shell; aix will use a modified commercial-unix bourne shell or various out-of-date (and buggy) versions of ksh depending on version (as of aix 4, it was either a buggy ksh88 or a buggy clone thereof)
modules: use modules-load.d(5) for autoloading – if it's still necessary (with linux 3.5, almost all hardware-specific modules are autoloaded, including kvm)
try this:  alias ll   or this:  type ll  
i'm going to use firefox as an example, because its open source and easy to find the information for, but this applies (probably with slightly different lists of ports) to other browsers, too.  in august 2001, cert issued a vulnerability note about how a web browser could be used to send near-arbitrary data to tcp ports chosen by an attacker, on any arbitrary ip address
you have to change lang variable in current shell.  put  export lang=en_us.utf-8   in your shell rc file ( for bash it is ~/.bashrc ) and restart the terminal session ( or just source the rc file one more time with source ~/.bashrc or even just restart bash with exec bash )  note, that you have to generate this locale before.  also you can use export lang=c.  also there are other lang variables (from man bash):     lang   used to determine the  locale  category  for  any  category  not           specifically selected with a variable starting with lc_.    lc_all this  variable  overrides  the  value  of lang and any other lc_           variable specifying a locale category.    lc_collate           this variable determines the collation order used  when  sorting           the  results  of pathname expansion, and determines the behavior           of  range  expressions,  equivalence  classes,   and   collating           sequences within pathname expansion and pattern matching.    lc_ctype           this  variable  determines  the interpretation of characters and           the behavior of character classes within pathname expansion  and           pattern matching.    lc_messages           this  variable  determines  the locale used to translate double-           quoted strings preceded by a $.    lc_numeric           this variable determines the locale  category  used  for  number           formatting.  
if you have the "suid" version of busybox, you could try to make the date command execute as root like this:  file /etc/busybox.conf:  ... [suid] date = ssx root.root ...  
tl;dr  the working solution is using patchelf (if you have to deal with non-matching glibc versions: in the host system and the one nix libs have been linked with), see the second half of my story.  trying the usual approach  trying to use ld_library_path  well, i have set up an environment variable for this in ~/.bash_profile:  nix_link=/home/ivan/.nix-profile export ld_library_path="$nix_link"/lib   but that's not all!  now there are problems with linking with different versions of libc:  $ ldd -r ../valencies  ../valencies: /lib64/libc.so.6: version `glibc_2.15' not found (required by ../valencies) ../valencies: /lib64/libc.so.6: version `glibc_2.14' not found (required by ../valencies) ../valencies: /lib64/libc.so.6: version `glibc_2.14' not found (required by /home/ivan/.nix-profile/lib/libgmp.so.10)     linux-vdso.so.1 =&gt;  (0x00007fff365ff000)     /usr/local/lib/libsnoopy.so (0x00007f56c72e6000)     libgmp.so.10 =&gt; /home/ivan/.nix-profile/lib/libgmp.so.10 (0x00007f56c7063000)     libffi.so.5 =&gt; /usr/lib64/libffi.so.5 (0x00007f56c6e54000)     libm.so.6 =&gt; /lib64/libm.so.6 (0x00007f56c6bd0000)     librt.so.1 =&gt; /lib64/librt.so.1 (0x00007f56c69c7000)     libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007f56c67c3000)     libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007f56c65a6000)     libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f56c6211000)     /lib64/ld-linux-x86-64.so.2 (0x00007f56c74f1000) symbol memcpy, version glibc_2.14 not defined in file libc.so.6 with link time reference    (/home/ivan/.nix-profile/lib/libgmp.so.10) symbol memcpy, version glibc_2.14 not defined in file libc.so.6 with link time reference    (../valencies) symbol __fdelt_chk, version glibc_2.15 not defined in file libc.so.6 with link time reference   (../valencies) $    sorting out 2 versions of glibc  the most surprizing error here is:  symbol memcpy, version glibc_2.14 not defined in file libc.so.6 with link time reference    (/home/ivan/.nix-profile/lib/libgmp.so.10)   because nix must have installed the version of glibc which is used by its libgmp!  and indeed, the glibc from nix is there:  $ ldd -r /home/ivan/.nix-profile/lib/libgmp.so.10     linux-vdso.so.1 =&gt;  (0x00007fff0f1ff000)     /usr/local/lib/libsnoopy.so (0x00007f06e9919000)     libc.so.6 =&gt; /nix/store/93zfs0zzndi7pkjkjxawlafdj8m90kg5-glibc-2.20/lib/libc.so.6 (0x00007f06e957c000)     libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007f06e9371000)     /lib64/ld-linux-x86-64.so.2 (0x00007f06e9da7000) symbol _dl_find_dso_for_object, version glibc_private not defined in file ld-linux-x86-64.so.2 with link time reference (/nix/store/93zfs0zzndi7pkjkjxawlafdj8m90kg5-glibc-2.20/lib/libc.so.6) /home/ivan/.nix-profile/lib/libgmp.so.10: error while loading shared libraries: __vdso_time: invalid mode for dlopen(): invalid argument $    probably, glibc was not available to the user, so when i ran my binary, the system's glibc was loaded first
you can use find with the -perm predicate
try to google it. there was already an answer about kde, there it is (it's an exact duplicate i think) http://superuser.com/questions/422072/how-can-i-add-komodo-to-my-start-menu 
i used the command sudo ufw allow 3389/tcp and then restarted using sudo /etc/init.d/xrdp restart to solve this same issue on a pi
 the kernel manages the memory, so kernel code has access to both kernel and user space
while ! (ping -c 1 -w 1 8.8.8.8 &gt; /dev/null); do   sleep 1 done echo "&lt; 1 sec reply received...exiting"  
   "if it quacks like a keyboard and types like a keyboard it must be a   keyboard."   that's not always true
use the -p or --persist option:  gnuplot --persist -e 'plot sin(x)'   this will keep the window open until manually closed
you can do it in screen the terminal multiplexer.   to split vertically: ctrla then |. to split horizontally: ctrla then s (uppercase one). to unsplit: ctrla then q (uppercase one). to switch from one to the other:  ctrla then tab   note: after splitting, you need to go into the new region and start a new session via ctrla then c before you can use that area.  edit, basic screen usage:   new terminal: ctrla then c. next terminal: ctrla then space. previous terminal: ctrla then backspace. n'th terminal ctrla then [n]
with awk:  awk ' /odb_actiavtion successful/{printf "%s\nchanges has been updated to all servers\n", $0} /odb_actiavtion unsuccessful/{printf "%s\nno change\n", $0} ' &lt;in &gt;out   with sed:  sed -e '   /odb_actiavtion successful/a\   changes has been updated to all servers   /odb_actiavtion unsuccessful/a\   no change ' &lt;in &gt;out  
there is no way to "tell a terminal" to "reformat" the scrollback buffer
an ioctl goes to a driver, so the most important thing to figure out what an ioctl is doing is which driver is handling it.  what you've read about type, number and data_type is a convention that driver writers are supposed to use when choosing ioctl numbers
that's an odd request!  i'd use find + awk to grab a file in the deepest directory:  bash-3.2$ deepest=$(find / -type f | awk -f'/' 'nf &gt; depth { &gt;     depth = nf; &gt;     deepest = $0; &gt; } &gt; &gt; end { &gt;     print deepest; &gt; }')   using ${deepest} in your mv command is left as an exercise but the following five lines may help you further:  bash-3.2$ echo "${deepest}" /developer/sdks/macosx10.6.sdk/system/library/frameworks/ruby.framework/versions/1.8/usr/lib/ruby/gems/1.8/gems/activesupport-2.3.5/lib/active_support/vendor/tzinfo-0.3.12/tzinfo/definitions/america/argentina/buenos_aires.rb  bash-3.2$ echo "${deepest%.*}" /developer/sdks/macosx10.6.sdk/system/library/frameworks/ruby.framework/versions/1.8/usr/lib/ruby/gems/1.8/gems/activesupport-2.3.5/lib/active_support/vendor/tzinfo-0.3.12/tzinfo/definitions/america/argentina/buenos_aires  bash-3.2$ echo "${deepest%/*}" /developer/sdks/macosx10.6.sdk/system/library/frameworks/ruby.framework/versions/1.8/usr/lib/ruby/gems/1.8/gems/activesupport-2.3.5/lib/active_support/vendor/tzinfo-0.3.12/tzinfo/definitions/america/argentina  bash-3.2$ echo "${deepest##*/}" buenos_aires.rb  bash-3.2$ echo "${deepest##*.}" rb     following update to question:     find -type d [...] "this would only find the directory. [...] how could this be solved in the most simple way?"
setting autoedit=yes, composing will go directly to the message editor without prompting for recipient or subject.  note that you must also have edit_headers set.  as @lcd047 mentions, this feature inhibits all the send hooks before calling the editor. 
add the following to your xorg.conf:  section "inputclass"    identifier     "wheel emulation"    matchispointer "on"    matchproduct   "trackpoint"    option         "emulatewheelbutton" "2"    option "emulatewheel" "on" endsection   and then reboot
you can use the find command to find all files that have been modified after a certain number of days.  for example, to find all files in the current directory that have been modified since yesterday (24 hours ago) use:  find 
does drush mung backticks and vertical bars?  if not, you could use  cd `ls | grep foo- | head -n 1`   if backticks don't work, but |, $, ( and ) do, then you could change the above to  cd $(ls | grep foo- | head -n 1)   if | doen't work, but $, ( and ) do, then you could do  cd $(myprog)   where myprog is a script that you write to determine the directory name.  also -- i don't understand how you might be able to use find to help you do a cd, but, can you end your -exec with a +? 
setting your hostname:   you'll want to edit /etc/hostname with your new hostname. then, run sudo hostname $(cat /etc/hostname).   setting your domain:   then, in /etc/resolvconf/resolv.conf.d/head, you'll add then line search your.domain.name (not your fqdn, just the domainname). then, run sudo resolvconf -u to update your /etc/resolv.conf (alternatively, just reproduce the previous change into your /etc/resolv.conf).   both:  finally, update your /etc/hosts file
would grep be ok?  grep -r matrixcal /location/of/your/code  
localinstall is intended to install packages you have on your local filesystem
you could tie sudo authentication to the knowledge of a secret key managed by ssh-agent
in ubuntu gnome, the recent documents are stored in ~/.recently-used.xbel
i'd prefer to build a new list and replace an old one with a new:  nodes="127.0.0.1 1.2.3.4 1.2.3.4 " nodes_out= for node in $nodes do      ping -c 1 $node &gt;/dev/null 2&gt;&amp;1 &amp;&amp; nodes_out+=$node done nodes=$nodes_out  
these are logical volumes, so you can resize them using lvresize.  however, that is just the resizing of the underlying block device, you still have to resize the filesystem on top of it, and the way to do this will depend on the filesystem type and its initial configuration.  most commonly used linux filesystems support online resizing, ext2-based use resize2fs and xfs uses xfs_growfs. 
use find's -printf command to output both the time (in a sortable way) and the file, then sort
edit: ok
2nd all= on all hosts (if you distribute the same sudoers file to many computers) 
two tips:   you can't escape a single quote within a string quoted with single quotes
there's often confusion between process forking and execution.  when you do at the prompt of a bash shell.  $ sh -c 'exec env ps'   the process p1 issuing that $ prompt is currently running bash code
the application binary is called gpk-application
you can use the date utility to write the timestamp of a file, and the current time, as seconds elapsed from the epoch, then format a string to convert the seconds of the difference in days with bc:  echo "scale=2; ($(date +%s)-$(date -r file +%s)) / (3600 * 24)" \   | bc  
this is a bug.  the actual root cause is somewhat deeper: systemd's reload logic is flawed
yes, by setting loglevel to verbose, you would see logs like the following,   sshd[1199]: connection from 192.168.56.1 port 45811  sshd[1199]: found matching rsa key: xxxx  sshd[1199]: postponed publickey for root from 192.168.56.1 port 45811 ssh2 [preauth]  sshd[1199]: found matching rsa key: xxxx  sshd[1199]: accepted publickey for root from 192.168.56.1 port 45811 ssh2  
lets break it down into a number of steps.  we are going to write a function that will return the next number
from the manual:     if arguments remain after option processing, and neither the -c nor the -s option has been  supplied,  the  first argument  is  assumed to be the name of a file containing shell commands.   so bash date means "read the date file and execute the shell commands it contains"
create a file with the following content:  alias my_alias1 recipient1@email, recipient1@email alias my_alias2 recipient3@email, recipient4@email   source it from your mutt config with source path/to/alias_file.  here you go! 
if by "prompt" you are referring to the gnu screen prompt by ctrl-a and :, that gets cleared by ctrl-u
kde has a device integration framework called solid.  you can see the api documentation for it here: http://api.kde.org/4.14-api/kdelibs-apidocs/solid/html/index.html  when you click suspend, solid sends a dbus message to upower (http://upower.freedesktop.org/), the underlying framework, requesting a suspend.  you can simulate a suspend from the command line by doing   qdbus org.kde.solid.powermanagement /org/freedesktop/powermanagement suspend  
yes
there is the option -n, and many more in the manual page, worth reading. 
 in your configuration you allowed:   usera to run any command as any user userb to run fdisk as vinoth  fdisk by default requires root privileges to access the devices, you cannot run it as usera, ie
resolvconf is pointing it out to a local software running in port 53 in the local machine.  to find it out which one:  sudo netstat -anlp | grep :53   as we have found out, it is the avahi  daemon.  to trace dns resolution, also following command is useful:  dig +trace www.cnn.com   if you want to control your dns setting yourself, specially in server cases (i have notice you said mint), i would recommend doing away with resolvconf  you can uninstall it with:  dpkg --purge resolvconf   then, if you got the ip via dhcp leave it as it is, otherwise fill in your dns servers in /etc/resolv.conf
this sounds like something which could perhaps be perfectly solved with rsync
what you refer to as a windowing system is more commonly referred to as a display server.  the differences between display servers are well documented
the value for serveraliveinterval means that "if no data has been received from the server within this time then send a null message to the server".  similarly, clientaliveinterval means that "if no data has been received from the client within this time then send a null message to the client".  the default values are typically 0 which means these functions are disabled.  the main use of this is to prevent intermediate routers and firewalls from thinking a session is idle, and dropping it
using the libfaketime software could be a solution  sudo apt-get install faketime faketime '2006-09-20' wine example.exe  
i doubt that your display manager doesn't let you choose, but i don't like neither gnome nor kde, so i don't know what you'll be running, but you can try some others
i found the following on a semi-related stackoverflow question; the answer i needed didn't actually quite answer the question there (and was not selected as the correct answer) so i figured i'd post it here for others to find easier.  yum list installed package_name  this command returns some human-readable output, but more importantly returns an exit status code; 0 indicates the package is installed, 1 indicates the package is not installed (does not check whether the package is valid, so yum list installed herpderp-beepbopboop will return a "1" just as yum list installed traceroute will if you don't have traceroute installed)
you have to create a your_application.desktop file and then copy to /usr/share/applications/
while read -d: dir do     [ -d "$dir" ] || echo "missing: $dir" done &lt;&lt;&lt;"${path%:}:"   read -d: dir reads input into variable dir, breaking the input at :.  [ -d "$dir" ] tests for the existence of the directory  || only executes the statement that follows if the preceding statement returned false.  &lt;&lt;&lt;"${path%:}:" provides input to the loop using a here-string
don't be surprised that your regexps with a \n don't match: the \n is the line separator, it's not in the line
there are two basic approaches one can use when dealing with fields: i) use a tool that understands fields; ii) use a regular expression
you can just chain &amp;&amp;'s, no need to nest conditionals here:  [ -f /etc/bash_completion ] &amp;&amp; ! shopt -oq posix &amp;&amp; 
if it is not configured for "tiny", nano can display printable characters for tab and space, but it has no special provision for newline.  this is documented in the manual:     set whitespace "string"   set the two characters used to indicate the presence of tabs and spaces
in my tmux.conf:  bind | split-window -h  bind "-" split-window -v  for splite, un push ctrl+b and after ctrl+- ou ctrl+|  so i think for you ctrl+b and ctrl+v 
if [[ $(uname -s) == linux ]] then     dothis else     dothat fi  
it is known as carriage return
(\w+ ) will match a word or part of word
just untar (tar xf kernel-sources.tar.whatever) it into /usr/src - or anywhere else for that matter.  just remember that if you want to use the symlinks /lib/modules/kernel/{build,source} that point to the kernel build and source tree, respectively, as created by make modules_install, you'll need to either keep the sources at the same place, or update the symlinks accordingly.  that said, if you are planning anything else than just one-off kernel compilation, clone linus' or any other git tree and use that instead of the tarballs
depending on your os
i believe /proc/pid/limits is the file you should check
   do i have to delete those partitions and reinstall mint?   absolutely not, you can do this from mint while it's running.  first, turn the swap off -- swapoff -a
sure, use envsubst   it's part of gnu get text  envsubst &lt; source &gt; destination  
try find /dir -type d -name "your_dir_name".  replace /dir with your directory name, and replace "your_dir_name" with the name you're looking for.  -type d will tell find to search for directories only
split your command so that line number in error message will give you a hint  egrep -o "[)+,]dic([1-2]?[0-9xy];[1-2]?[0-9xy])([pq][0-9][0-9];[pq][0-9][0-9])" input | \   cut -c 2- | \ tr '(' '\t' | \  tr ')' '\t' | \   tr ";" "\t" | \   awk 'begin {ofs = "\t"} {print $2,$3,$4,$5}' &gt; dicentrics   looks like you have problem due to unescaped braces () in egrep statement
try:  alias -g ll='2&gt;&amp;1 | less'   you had an space in alias assignment, causing the alias failed. 
is this linux?  if so you could try the following:  # sysctl vm.swappiness=100   and then either use a program(s) that uses lots of ram or write a small application that just eats up ram
look in /proc/cpuinfo
cd "$(dirname ~/home/blah/file.zip)"   $( is a form of command substitution
put this in your "/etc/apt/preferences":  package: * pin: release a=stable pin-priority: 900  package: * pin: release o=debian pin-priority: -10   this is from man apt_preferences where p means pin-priority:  500 &lt; p &lt;=990    causes a version to be installed unless there is a version available belonging to the target release or the installed version is more recent  p &lt; 0    prevents the version from being installed   see this debian wiki page for something gentler than the manpage. 
stty lnext only affects the terminal device line discipline internal editor (the very limited one you get when running applications like cat that don't have their own line editor)
just for fun:  python -c 'import sys,fileinput,re;sys.stdout.writelines(re.sub("stuff", "changed", l, 1) for l in fileinput.input() if re.search("patternmatch", l))' file   don't do it:) use sed/perl/awk 
it is technically possible to delete ., at least on ext4 filesystems
checking the reverse dependencies on the other packages reveals the cause:  $ apt-cache show python-nose | grep depends depends: python-pkg-resources, python2.7, python (&gt;= 2.6.6-7~), python (&lt;&lt; 2.8), python2.6   there is already a bug reported about the issue. 
while root does not have access, a user in the sudo group can still run privileged commands - it seems the error is not in sudo, but elsewhere in the sudo chshcommand (e.g
either you are patient and stick with what you have, or you find an official backport, or you find some unofficial backports, or you build your own package
you can check this or better you can check man page for screen which is a good reference and says:     backtick id lifespan autorefresh cmd args...   backtick id      program the backtick command with the numerical id id
i would google their part number (see the content of /sys/class/block/sd&lt;x&gt;/device/model) next to slc or mlc, as i don't think that kind of information is exposed to the operating system and thus may not be queried automatically. 
i suppose that you are confused by cat command (and shell redirection), and not by find one.  find 
judging by the question you pose you probably haven't seen problems where threads provide an advantage over the standard processes.  there are problems like high-frequency trading for example where system becomes sensitive to the number of context switches in the system as well as switching from user to kernel mode and back
stop using hosts.allow / hosts.deny entirely and reconfigure sshd to prohibit logins using a password.  users can only get in via keys now. 
as far as i know, installing on a headless computer is something which can be done using a variety of tricks
the linux kernel build-system provide many build targets, the best way to know about it is probably to do a make help:  configuration targets:   config      - update current config utilising a line-oriented program   nconfig         - update current config utilising a ncurses menu based program   menuconfig      - update current config utilising a menu based program   xconfig     - update current config utilising a qt based front-end   gconfig     - update current config utilising a gtk based front-end   oldconfig   - update current config utilising a provided .config as base   localmodconfig  - update current config disabling modules not loaded   localyesconfig  - update current config converting local mods to core   silentoldconfig - same as oldconfig, but quietly, additionally update deps   defconfig   - new config with default from arch supplied defconfig   savedefconfig   - save current config as ./defconfig (minimal config)   allnoconfig     - new config where all options are answered with no   allyesconfig    - new config where all options are accepted with yes   allmodconfig    - new config selecting modules when possible   alldefconfig    - new config with all symbols set to default   randconfig      - new config with random answer to all options   listnewconfig   - list new options   olddefconfig    - same as silentoldconfig but sets new symbols to their default value   kvmconfig   - enable additional options for guest kernel support   tinyconfig      - configure the tiniest possible kernel   as jimmij says in the comments, the interesting parts are in the oldconfig related targets.  personally, i would recommend you to go for silentoldconfig (if nothing changed in the .config file or olddefconfig if you updated your .config file with a new kernel. 
ntfs does have file permissions
in first close it can be:  awk -f"[][ ]*" -v it=300 '{     sub(":"," ",$2)     gsub("/"," ",$2)     "date +%s -d \""$2"\""|getline d     if (d-f&gt;it) {         f=d         if (nr!=1)             print s/n          s=n=""         }     n++     s+=$nf     }' log.file    -f"[][ ]*" used as fields separator to strip square brackets additionally -v it=300 set variable (interval in seconds) sub,gsub remove symbols from field to prepare it for date command format date convert field into second (from epoch) |getline d puts above into d variable  
when a named pipe is created, via mkfifo (or however else you can do it), it creates a pipe "file" that remains in place until it is removed (or, in some cases, until your machine reboots, if you forget to remove it)
you will have to do in this way:  ubuntu-app-launch dialer-app tel:///###-###-####  
try renaming window 4   switch to window 4:  control+b 4 rename window: control+b , control+u mynewname   (thats a comma in the middle)  or: control+b :rename-window mynewname 
there are oh so many reasons to have multiple swap areas (they don't need to be files), even if you only have a single spindle.  20-20 hindsight: you deployed a machine with a single swap area, then eventually realised it's not enough
i would use awk for this  awk '/^-config2/ {print $2}' file   it print the second argument of lines starting with -config2
that output 0m4.968s looks like the default format for bash's builtin time
the simplest tool to use i think is pax, as it has a -d option which says not to recurse when given a directory.  so to copy just directories, doing it in steps, so you can validate that the directories are copied do not copy the files as well you can do  find somewhere -type d | pax -wd  &gt; archive.tar tar vtf archive.tar ( cd somewhere_else &amp;&amp; tar xpf - ) &lt; archive.tar   once you are happy, you can remove the intermediate printing of the contents of the archive (the tar vxf archive.tar) and replace the intermediate archive.tar file with a pipe. 
you can move the logic from the rule section into an action  awk '{total=$3+$4+$5; per=total/3; if (per&gt;80) print}' stud    2       george      90        95       82    4       dennie      89        92       90   note that this attempts to evaluate the column headers arithmetically - which "works" because in awk, non-numeric fields are treated as zero when you try to do arithmetic on them - but would cause the header line to be printed if, for example, you changed the test to per&lt;80
there are quite a few:   vimprobable - webkit and vim-like keybindings
you're having problems because your shell is trying to expand * into the list of files, but it can't since you don't have rights to read the directory.  i can think of two things that would work  sudo bash -c "rm directory/*"   in this case, the * isn't expanded by you, but by root, who can read the directory  or  sudo find directory -type f -exec rm {} \;   the above will only delete files, not directories (otherwise it would delete directory along with it's contents), but feels less error prone to me.  edit: in the first option, i had accidentally written directory.* instead of directory/* 
it is typical for programs to force the "some_string" part to be the last argument so that .abc.ksh "some_string" -a "sample text" is an error
iif you ran apt-get update and only that after you added the respository, then you have not updated blender, rather the references to it
just export it:    #!/bin/bash  export myvar=myvalue sh -c 'some_code_here'  
you can add it to the file .profile or .bashrc or your current shell profile file (located in your home directory)
find the full patch of the version of rpc.statd that is running, and get it's md5sum
i'm assuming that you have rsyslog running on the local machine and that it's forwarding logs to your remote log server.  from the rsyslog documentation, it looks like you can define an input module to do exactly what you are wanting
documentation/devices.txt in the kernel source code documents the allocation process and lists all the allocated device numbers
if you just want to select a voice before doing tts, you can use text2wave  echo 'hello world' | text2wave -eval '(voice_kal_diphone)' &gt; hello.wav   text2wave is a festival script itself, so you could fairly easily customize it.  you can do similar with the festival command line:  festival '(voice_ked_diphone)' '(saytext "hello world")' '(exit)'   but that unfortunately does not work along with the --tts option. 
if the following doesn't work...  cd ./target_dir     set -- *     onedrive-cli put "$@"   then it's probably because you need a put for every argument in which case this might:  {    printf 'one-drive-cli'       printf " put ///%s///" * } | sed 's|'\''|&amp;"&amp;"&amp;|g;s|///|'\''|g' | 
in the shell [ is an alias for the test command
i use this udev rule from the arch wiki:  kernel!="sd[a-z][0-9]", goto="media_by_label_auto_mount_end"  # import fs infos import{program}="/sbin/blkid -o udev -p %n"  # get a label if present, otherwise specify one env{id_fs_label}!="", env{dir_name}="%e{id_fs_label}" env{id_fs_label}=="", env{dir_name}="usbhd-%k"  # global mount options action=="add", env{mount_options}="relatime" # filesystem-specific mount options action=="add", env{id_fs_type}=="vfat|ntfs", env{mount_options}="$env{mount_options},utf8,gid=100,umask=002"  # mount the device action=="add", run+="/bin/mkdir -p /media/%e{dir_name}", run+="/bin/mount -o $env{mount_options} /dev/%k /media/%e{dir_name}"  # clean up after removal action=="remove", env{dir_name}!="", run+="/bin/umount -l /media/%e{dir_name}", run+="/bin/rmdir /media/%e{dir_name}"  # exit label="media_by_label_auto_mount_end"  just change the "sd[a-z][0-9]" in the first line to avoid clashes with your other drives... 
the fujitsu_laptop module dans control acpi for fujitsu-siemens laptops does not appear to have fan control code (as of today) see:  http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=blob;f=drivers/platform/x86/fujitsu-laptop.c  (you can look at the thinkpad acpi code in the same directory, it has a fan subdriver)  i don't think it's possible to achieve what you want to do with your hardware. 
posixly:  for arg do   shift   [ "$arg" = "-inf" ] &amp;&amp; continue   set -- "$@" "$arg" done  printf '%s\n' "$@"   the above code even works in pre-posix shells, except the original almquist shell (read endnote)
the /etc/sudoers config file doesn't configure the su command, which will always prompt for credentials in accordance with whatever's in /etc/pam.d/su
if the [, ] are balanced and not nested, you could use gnu awk as in:  gawk -v rs='[][]' '    nr % 2 == 0 {gsub(/\s/,"")}    {printf "%s", $0 rt}'   that is use [ and ] as the record separators instead of the newline character and remove blanks on every other records only.  with sed, with the additional requirement that there be no newline character inside [...]:  sed -e :1 -e 's/\(\[[^]]*\)[[:space:]]/\1/g;t1'   if they are balanced but may be nested as in blah [blih [1] bluh] asd, then you could use perl's recursion regexp operators like:  perl -0777 -pe 's{(\[((?:(?&gt;[^][]+)|(?1))*)\])}{$&amp;=~s/\s//rsg}gse'   another approach, which would scale to very large files would be to use the (?@{...}) perl regexp operator to keep track of the bracket depth like in:  perl -pe 'begin{$/=\8192}s{((?:\[(?{$l++})|\](?{$l--})|[^][\s]+)*)(\s+)}   {"$1".($l&gt;0?"":$2)}gse'   actually, you can also process the input one character at a time like:  perl -pe 'begin{$/=\1}if($l&gt;0&amp;&amp;/\s/){$_=""}elsif($_ eq"["){$l++}elsif($_ eq"]"){$l--}'   that approach can be implemented with posix tools:  od -a n -vt u1 |   tr -cs 0-9 '[\n*]' |   awk 'begin{b[32]=""; b[10]=""; b[12]=""} # add more for every blank        !nf{next}; l&gt;0 &amp;&amp; $0 in b {next}        $0 == "91" {l++}; $0 == "93" {l--}        {printf "%c", $0}'   with sed (assuming no newline inside the [...]):  sed -e 's/_/_u/g;:1' -e 's/\(\[[^][]*\)\[\([^][]*\)\]/\1_o\2_c/g;t1' \     -e :2 -e 's/\(\[[^]]*\)[[:space:]]/\1/g;t2' \     -e 's/_c/]/g;s/_o/[/g;s/_u/_/g'   are considered white space above any horizontal (spc, tab) or vertical (nl, cr, vt, ff...) spacing character in the ascii charset
this has been fixed in the latest kernel  [drm:__gen6_gt_force_wake_mt_get] error timed out waiting for forcewake old ack to clear   https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=c11e5f35ab490bd30591563816fbc83526521777  no need to revert the commit, just update your kernel.    you can see this for yourself by downloading the kernel, and looking at /drivers/gpu/drm/i915/intel_pm.c lines 240 - 260 and comparing them to the patch mentioned on this link.   https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=c11e5f35ab490bd30591563816fbc83526521777  https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1080360 
after backing up (step 1) and unmounting (between 2 and 3), run fsck to ensure that the filesystem is healthy:  e2fsck -f /dev/mapper/existingext4   other than that, the steps are ok.     what should i choose for $sectors? is this step even necessary?   this step is necessary, otherwise the partition would still show up at the old side
sh -c "cd /tmp/sub_dir/pertinent_dir/../  \ &amp;&amp; zip -r pertinent_dir.zip pertinent_dir/*"  
netstat  there's a process there, your userid just isn't privy to seeing what it is
try a younger kernel, perhaps something from "sid" (aka unstable). 
use lspci as root with different verbosities (-v to -vvv); the most verbose setting will show bus speeds and irq (i don't know about the agp rate - no machines with agp graphics here).  e.g.  lspci:   06:00.0 ethernet controller: realtek semiconductor co., ltd
both manage a limited resource
if you just want one extension, in one directory, why not just use regular globbing?  rsync /home/you/rsync_this/*.jpg user@server:/remote/folder/   you can even copy multiple extensions with:  rsync /home/you/rsync_this/*.{jpg,png,gif} user@server:/remote/folder/  
from your dev box you could likely just use telnet if it's a tcp port:  telnet sc-host01.vip.slc.qa.host.com 9042 telnet sc-host01.vip.slc.qa.host.com 9160   if you get a timeout error, then the port is blocked. 
there are 2 ways, which i normally use  option 1:  before booting up ubuntu, inside virtualbox ubuntu vm settings, specify a share folder
perhaps you could use the -m option (long version --remote-option), which does not seem to be checked by the client rsync
the other solution1 has some inconveniences: - it requires root access - it's a global change so it affects all users - upgrading sound-theme-freedesktop restores the file  for the record, the proper way to do it (and avoid all of the above) is via a custom sound theme that disables2 the default sound file used by gnome-screenshot (the name of the file is screen-capture.oga corresponding to the screen-capture event - hardcoded in gnome-settings-daemon and gnome-screenshot). create the custom theme directory:  mkdir -p ~/.local/share/sounds/__custom   create the .disabled file:  touch ~/.local/share/sounds/__custom/screen-capture.disabled   add the index.theme:  cat &lt;&lt; 'eof' &gt; ~/.local/share/sounds/__custom/index.theme [sound theme] name=__custom inherits=freedesktop directories=. eof   set __custom as default theme name:  gsettings set org.gnome.desktop.sound theme-name '__custom'   or, if you're using cinnamon:  gsettings set org.cinnamon.desktop.sound theme-name '__custom'   and enjoy the silence...    1: yeah, i know it's actually my solution but at the time of posting it on the arch forums i was just being lazy...  2: a pseudo file format ".disabled" is used for disabling sounds in a theme that inherits from another theme
in gtk+ applications you can simply press ctrl+shift+u, type in the hex and press enter
you misunderstand
./script runs a file called 'script' in the location ./ - which translates to 'here' (i.e
you can do it with just find and awk:  find 
this simple awk:  awk -f"|" '{ofs="|"}$2=$2*1' file   ofs defines the output field separator
this should work:  find 
i wrote a script
exit is a shell special built-in command
i believe the related man page is, xkillclient
note that that syntax is inherited from the bourne shell.  after the variable name, you can have either in to have the list of elements explicitly given, or do, to loop over the positional parameters.  for i in 1 2 3 do   echo "$i" done   or  set 1 2 3 for i do   echo "$i" done   having the do in both cases (even if it's not strictly  necessary in the first one) makes for a more consistent syntax
  go to tunnels under "connection > ssh > tunnels" in the configuration menu  you would put the "-d9999" port number in the source port box and select the dynamic option below
mp3info only edits the id3v1 tags, you need to use a program like eyed3 or id3v2 that supports id3v2  more comfortable is to use musicbrainz picard to tag your mp3 files (uses the mutagen library underneath).  since mp3info only supports id3v1, it cannot delete/wipe the id3v2 info embedded in the mp3 streams. 
you can have the shell expand the file's contents before passing them to sed:  sed -e "s/$(cat needle.txt)/replace/" subject.txt   note the use of double quotes.  this will make sed interpret any regex metacharacters from needle.txt as regex metacharacters and not ordinary characters
the process substitution is roughly equivalent to this.  example - mechanics of process substitution  step #1 - make a fifo, output to it  $ mkfifo /var/tmp/fifo1 $ fmt --width=10 &lt;&lt;&lt;"$(seq 10)" &gt; /var/tmp/fifo1 &amp; [1] 5492   step #2 - read the fifo  $ cat /var/tmp/fifo1 1 2 3 4 5 6 7 8 9 10 [1]+  done                    fmt --width=10 &lt;&lt;&lt; "$(seq 10)" &gt; /var/tmp/fifo1   the use of parens within the heredoc also seems ok:  example - just using a fifo  step #1 - output to fifo  $ fmt --width=10 &lt;&lt;foo &gt; /var/tmp/fifo1 &amp; (one) (two foo [1] 10628   step #2 - read contents of fifo  $ cat /var/tmp/fifo1 (one) (two   the trouble, i believe you're running into is that the process substitution, &lt;(...), doesn't seem to care for the nesting of parens within it.  example - process sub + heredoc don't work  $ cat &lt;(fmt --width=10 &lt;&lt;foo (one) (two foo ) bash: bad substitution: no closing `)' in &lt;(fmt --width=10 &lt;&lt;foo (one) (two foo ) $   escaping the parens seems to appease it, a little:  example - escaping parens  $ cat &lt;(fmt --width=10 &lt;&lt;foo                  \(one\) \(two foo ) \(one\) \(two   but doesn't really give you what you want
you can force another round of evaluation with eval, but that's not actually necessary
i think it's important to note that the cat isn't the problem in my comment above, but shell redirection
there is a undocumented parameter to udhcp which sends it to the background and allows to boot.  udhcpc -b  
blocking lan access: if pf.conf knows what your lan subnet is, you can selectively block traffic from it
you can remove config file prior to upgrade, and then upgrade
you can access the command line arguments in your shell script with the special variables $1, $2 until $9
you can download the source for python-2.7.10 from the python.org site. once you extract .tar.xz archive you will find the include directory that contains the missing missing header files
you can—the program zcat (or gzip -cd) to write the decompressed data to stdout
the configure script requires a leading '-' before those i and l options:  --with-tcltk-includes=-i/opt/activetcl-8.6/include --with-tcltk-libs=-l/opt/activetcl-8.6/libs                       ↑                                              ↑ 
you forgot to loopback in the entry you have made. it should be like this.  menuentry 'linux, with linux core repo kernel' --class arch --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-core repo kernel-true-0f490b6c-e92d-42f0-88e1-0bd3c0d27641'{   load_video   set gfxpayload=keep   insmod gzio   insmod part_msdos   insmod ext2   set root='hd0,msdos8'   if [ x$feature_platform_search_hint = xy ]; then     search --no-floppy --fs-uuid --set=root --hint-bios=hd0,msdos8 --hint-efi=hd0,msdos8 --hint-baremetal=ahci0,msdos8  0f490b6c-e92d-42f0-88e1-0bd3c0d27641   else     search --no-floppy --fs-uuid --set=root 0f490b6c-e92d-42f0-88e1-0bd3c0d27641   fi  loopback loop1 /ubuntu/disks/root.disk       set root=(loop1)    echo  'loading linux core repo kernel ...'   linux /boot/vmlinuz-linux root=uuid=0f490b6c-e92d-42f0-88e1-0bd3c0d27641 ro  quiet   echo  'loading initial ramdisk ...'   initrd  /boot/initramfs-linux.img }  
packages known by your system / offline  you can use apt-cache to query the apt cache
from w3m faq:     w3m starts with black characters on black background
how to double each line: see here... as to your second request, just save 1st field and the entire line into variables then do the first change, set the 1st field to the initial value and print then restore the line content, do the second change, set the 1st field again to the initial value and print:  awk '{t=$1;l=$0;gsub(/3/, "2");gsub(/4/, "1");$1=t;print} {$0=l;gsub(/3/, "1");gsub(/4/, "2");$1=t;print}' infile  
cisco routers has telnet open by default
the [a-z] part isn't what matches the number; it's the *
i simply went to screensaver preferences:    made sure that activate screensaver when computer is idle was checked
there isn't a command that i've ever seen that will act as "open with..." but you can use the command xdg-open &lt;file&gt; to open a given &lt;file&gt; in the application that's associated with that particular type of file.  examples  opening a text file:  $ xdg-open tstfile.txt $   resulting in the file tstfile.txt being opened in gedit:  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  opening a libreoffice writer document:  $ xdg-open tstfile.odt  $   resulting in the file tstfile.odt being opened in writer:  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  what apps get used?  you can use xdg-mime to query the system to find out what applications are associated to a given file type.  $ xdg-mime query default $(xdg-mime query filetype tstfile.txt) gedit.desktop calibre-ebook-viewer.desktop  $ xdg-mime query default $(xdg-mime query filetype tstfile.odt) libreoffice-writer.desktop calibre-ebook-viewer.desktop   this is a 2 step operation
if i understand your question i think you need to install ubuntu on your pendrive as "persistent." i will then retain installed apps, bookmarks etc. 
i found the solution with the help of alienth and this site :  when you want to send some application which is running in foreground to background, you need to execute these two commands:  # [ctrl-z] [1]+  stopped                 ./your_app  # bg   after this your process will continue its execution in background. 
i use runit's chpst tool for tasks like this
the shell parameter expansion ${!name@} or ${!name*} could do the trick,  $ foo=bar $ var_name=(${!foo@}) $ echo $var_name" = "$foo foo = bar   although feasible i can't imagine the utility of this ... 
you may be able to use grep's -f aka (--file) option, with process substitution to "regexify" some of the patterns
opensuse build service perhaps?  don't let the name opensuse fool you, it supports other distros as well
this script takes two (optional) arguments, the directory to partition, and the parition size
it's reasonable to ask why the dd command doesn't first check whether its target contains a mounted filesystem, and then prompt for confirmation or require a special flag
it's in glibc library scanf.c source  glibc stands for gnu c library
no i do not believe there is any way to distinguish between the aliases coming from the system or from your .myaliases file
type in the shell: pydoc modules . this will list modules and you can grep the module which you want. found on stackoverflow here 
check this   $awk -f"[&gt;|&lt;]" '{print $5,$9}' input.txt 5 ukraine 3 vietnam 3 taiwan 3 netherlands 3 south korea 3 great britain   using sed commnad  $ sed "s#&lt;tr&gt;&lt;td&gt;\(.\)&lt;/td&gt;&lt;td&gt;\(.*\)&lt;/td&gt;&lt;/tr&gt;#\1 \2#" input.txt 5 ukraine 3 vietnam 3 taiwan 3 netherlands 3 south korea 3 great britain  
turns out richard was right
here is the answer:  on centos1:  sudo ifconfig eth1 192.168.1.191 netmask 255.255.255.0 up sudo touch /etc/sysconfig/network-scripts/ifcfg-eth1  sudo vi /etc/sysconfig/network-scripts/ifcfg-eth1    device="eth1" ipaddr=192.168.1.191 netmask=255.255.255.0 network=192.168.1.0 broadcast=192.168.1.255 nm_controlled="yes" onboot="yes" type="ethernet"   then:  sudo ifup eth1   on centos1 who ssh to this server:  sudo -u apache ssh root@192.168.1.191"pwd"   then apache can ssh to 192.168.1.191 and you can do whatever you want :) 
awk '     $1 == "group" {printf("\\section{%s%d}\n", $1, $2); next}     {for (i=1; i&lt;=nf; i++)          if ($i ~ /^[0-9][0-9][0-9]$/) {             printf("\\testdetails{%d}\n", $i)             break         }     } '    update based on comment:  awk '     $1 == "group" {printf("\\section{%s %d}\n", $1, $2); next}     {       title = sep = ""       for (i=1; i&lt;=nf; i++)          if ($i ~ /^[0-9][0-9][0-9]$/) {           printf("\\subsection{%s} \\testdetails{%d}\n", title, $i)           break         }         else {           title = title sep $i           sep = fs         }     } '   
how do you like this one? i hope it is what you needed.  sed -e 's/\([0-9]\+\)/(\1, 0)/g'   test  echo "hello:123: world hello:783: world hello:479: world" | sed -e 's/\([0-9]\+\)/(\1, 0)/g'   result     hello:(123, 0): world      hello:(783, 0): world      hello:(479, 0): world  
dumping to clear text  you can use this technique to dump a man page out to a text file.  $ man -p cat ls &gt; manpg_ls.txt   the above technique is just changing what pager man uses
for video data  you can use the -dvd-video option to genisoimage/mkisofs to enable the creation of udf structures required for video playback
you can process content of a file line by line, using bash while loop:  i=1  while ifs= read -a line; do   printf "line number %d:\n" $i   printf "%s\n" "${line[@]}"   let i++ done &lt; "file.txt"   each line is stored in array line, you can get each element of array line by syntax:  echo "${line[n]}"   where n is the order of element in array. 
you could - probably
netcat is not a specialized http client
this captures the information that you want from the last line of file:  $ ifs=, read -r a b c var_1 var_2 d e f h var_3 extra &lt; &lt;(tail -n1 file) $ echo $var_1  $var_2  $var_3 tmx6bp 075 179583   how it works   ifs=,  this temporarily sets the field separator to a comma. read -r a b c var_1 var_2 d e f h var_3 extra  this reads in the fields to the listed variables
since you are in centos, you could use the yum as suggested here.  yum remove $(yum list installed | grep php | cut -d' ' -f1 | tr "\n" " ")  
from man rsync     --delete         this  tells  rsync to delete extraneous files from the receiving         side (ones that aren’t on the sending side), but  only  for  the         directories  that  are  being synchronized
try running this code snippet:  if [[ 5 &lt; 20 ]] then     echo "5 &lt; 20, as expected" else     echo "5 is not less than 20, but why?" fi   and the output would be 5 is not less than 20, but why?
why don't you thoroughly read the wiki page that you linked:     packages in arch linux are built using the makepkg utility and   information stored in pkgbuilds
metadata is information about data
a common bottleneck for slow page load times is often the dns resolution
an empty permission set can be represented with -:  setfacl -dm o::- mydir   this doesn't appear to be documented, so i don't know how portable it is
if polling is okay you could look at the time on mtab:  import time, os last = none current = none  for x in range(0,60):     if last == current:         current = os.stat('/etc/mtab').st_mtime         print('current updated: ', current)         print('no changes...')     else:         last = current         print('last updated: ',last)         print('something was mounted or unmounted')     time.sleep(1)   you could also use filecmp or difflib to see if there are any changes, and parse what kind of changes occurred if you go with this route. 
process tree  while the process is running try to use ps with the f option to see the process hierarchy:  ps axuf   then you should get a tree of processes, meaning you should see what the parent process of the gzip is
the package maintainer lists the dependencies for a package when they create the specifications file
just to share, this is what i have done:  there is no need to perform grub-install since all the files are already there
you don't really want to do this in bash, but because you asked, this is how you could split it up.  #!/bin/bash re='^[0-9]+$' for x in `/usr/bin/ls -l --time-style=+'%s' /var/indexes | sort -k3,3 | awk '{print $3 $7}'` do read -a nm &lt;&lt;&lt; "$x" if [[ ${nm[0]} =~ $re ]] ; then    echo "found one " ${nm[1]} fi done   it's easier in awk like so:  /usr/bin/ls -l --time-style=+'%s' /var/indexes | sort -k3,3 | awk '($3 ~ /^[0-9]+$/){print $7}'   really, the right solution is find w/ -nogroup as suggested by paul h.. 
you have ash or bash so you can use json.sh
the right answer is sandy bridge, after digging a bit in intel's site. 
if you need to figure out what happened during the installation of a package, the information is there.  this file is unlikely to contain any information that would affect your privacy
use  export nameofuser=`who am i | awk '{print $1}'`   or   export nameofuser=`logname`  as $user can change if you call the script using sudo, etc.  http://stackoverflow.com/questions/4598001/how-do-you-find-the-original-user-through-multiple-sudo-and-su-commands 
i checked uname manual (man uname) and it says the following for the "-a" option:    print all information, in the following order, except omit -p and -i if unknown   in ubuntu, i guess, options "-m", "-p" and "-i" (machine, processor and hardware-platform) are returning the machine architecture
option 1  you could use registers to do it and make a keybinding for the process.  yank the word you want to replace with yw
your question indicates that this problem file is on an nfs-mounted filesystem, and nothing you do from your rhel client successfully touches the file.  this suggests that the problem has to do with the interface between your client and the nfs server.  it may be necessary to login directly to the server to manipulate the file, or at least access it from a workstation running a different os. 
for getting details of network transactions, you have got a implementation of a netflow generator for freebsd or linux:  ng_netflow     name        ng_netflow - cisco's netflow implementation      description        the ng_netflow node implements cisco's netflow export protocol on a        router running freebsd
page cache, sometimes referred to as disk cache, is a transparent ram buffer for access to and from on-disk files
after searching "everywhere", i found an archlinux forum post dating april 2015:  the following css needs to be placed in ~/.config/gtk-3.0/gtk.css   .header-bar.default-decoration {     padding-top: 3px;     padding-bottom: 3px; }  .header-bar.default-decoration .button.titlebutton {     padding-top: 2px;     padding-bottom: 2px; }   i changed paddings to 1px and now it's great!  note: my hunch was right! it is css related 
this doesn't seem to be possible, so i wrote up an xslt to do it
libapt-front was removed from debian in 2009, and as a result from ubuntu too (perhaps a little later)
by default, xserver-xorg pulls in xserver-xorg-video-all, which pulls in all the video drivers.  if you know which driver is appropriate, you can install it along with xserver-xorg, and it will satisfy the alternative dependency on xorg-driver-video, avoiding the xserver-xorg-video-all dependency altogether; thus for an intel igp:  apt-get install xserver-xorg xserver-xorg-video-intel   if you want to make doubly sure that xserver-xorg-video-all isn't installed, you can use something like  apt-get install xserver-xorg xserver-xorg-video-intel xserver-xorg-video-all_   (note the underscore, which instructs apt-get to purge the package).  to avoid installing the libdrm* packages, you need to avoid libgl1-mesa-dri which depends on all of them (with no easy workaround, so if you want dri support you need all three implementations, unless you use equivs — but they're quite small)
there are a few things wrong here
the status is servfail, it looks like something is wrong with your dns server (it doesn't return anything), and 10 seconds is just dig's timeout
this is likely a readline thing
yes, gnome overrides the xkb x settings
although some terminal programs have support for splitting, you won't be able to access this functionality from the shell which is running in a different layer and doesn't have access to the software displaying it.  what you can do is use a terminal multiplexer such as gnu screen or tmux that allow you to run multiple shells in "panes" inside a console.  screen has been around since the dawn of time and works, but lately the project has falled into dis-repair and it's not being well maintained
if you look into drivers/usb/serial/makefile, you'll see that config_usb_serial_qualcomm is responsible for this driver.  execute make menuconfig and goto "device drivers"->"usb support"->"usb serial converter support"->"usb qualcomm serial modem" 
this should work:  mkdir pretty_name &amp;&amp; tar xf ugly_name.tar -c pretty_name --strip-components 1   -c changes to the specified directory before unpacking (or packing)
ok, so there are a few issues with your approach.  you are exporting a function, which is not portable between shells
well, i costumarily use bashmount to mount usb sticks
you can use apt-get install to do what you want
you can purge the journal by either un-mounting, or remounting read-only (arguably a good idea when cloning)
alias cgrep='grep -nr --color'   usage:  $ cgrep somestring /path/to/dir/or/file/with*/possible/*wild.card   also one of my favorites:  $ pgrep some-hanging-process   will list all pids of processes that match the name of some-hanging-process which you can use in following situation:  $ kill $(pgrep some-hanging-process)  
ok - this is not right on target, but you may achieve your goal by building a rpm
the idea is just to construct a new function to express your wanted custom behavior (and bind the key to it).  either with lambda ("anonymous", in place) or with defun (in this case, you give it a name, and you can refer to it with the name).  to define an interactive "command", you need to prepend (interactive) to the body.  for example:  ..
python demo.py -some arguments &amp; ( sleep 120; kill -tstp "$!")  &amp;  fg %1   will first background python, then start a backgrounded shell that sleeps for 120 seconds before sending python the -tstp - or the suspend signal
you can tell apt-get to install a specific version of a package
you can use screen command and start a job such as compiling kernel such as :  screen -r -s your_session_name   then press entern to return to session  for exit to session : ctrl+a+d  for listing your sessions:  mohsen@debian:~$ screen -ls there is a screen on:     30473.compilekernel (03/06/2015 05:59:05 am)    (detached) 1 socket in /var/run/screen/s-mohsen.   for detatch to your session:  screen -dr 30473   when you don't use session name screen itself uses the following format and it's very hard to multiple session for your server:  pid.tty.host   such as :  30522.pts-0.debian  
a perl solution:  $ perl -ple 's/\\\.1\\\.(7|8|9)/\\.1\\.10/' file | uniq rewiteengine on rewritecond   %{remote_addr}   !^192\.168\.1\.10$  [nc] rewritecond   %{remote_addr}   ^192\.168\.1\.5$  [nc] &lt;/directory&gt;   if you want edit inplace, you can try:  perl -i.bak -nle 'next if $count and /!\^/;s/\\\.1\\\.(7|8|9)/\\.1\\.10/ and $count++ if /!\^/;print' file  
no, lxc, docker, and lxd, are not quite the same
the quick answer is put the commands that you type in a file, for example, chres, then, at the prompt, tell the shell to execute the commands like this:  $ sh chres   if you want to be able to execute the command from any directory, put the command into your personal bin directory ($home/bin) and make it executable (~ expands to the full path of your home directory:  $ mkdir -p ~/bin $ mv chres ~/bin $ chmod +x ~/bin/chres   make sure $home/bin is in your path
test file content:  start cmd:&gt; cat file 999,999,999,999.99 999999999999.99 9,999,999,999,999.99 9999999999999.99 0 0.00 00 00.00  grep -e '^(0|0\.[0-9]{1,2}|'\ '[1-9][0-9]{0,2}(,?[0-9][0-9][0-9]){0,3}(\.[0-9]{1,2})?|'\ '[1-9][0-9]{0,2}(,[0-9][0-9][0-9])*(\.[0-9]{1,2})?)$' file 999,999,999,999.99 999999999999.99 9,999,999,999,999.99 0 0.00  
wget follows redirects automatically
i will use this simple command to get the window id in hex format  wmctrl -l | grep -i xterm | awk '{print $1}'   for decimal format, bc command can be used for conversion  echo "ibase=16; `wmctrl -l | grep -i xterm | cut -c 3-11 | tr a-z a-z`" | bc  
with zsh, you could do:  n=0; cp 00802_bla_aquarium_?????.jpg(^e:'((n++%4))':) /some/place   posixly, same idea, just a bit more verbose:  # put the file list in the positional parameters ($1, $2...). # the files are sorted in alphanumeric order by the shell globbing set -- 00802_bla_aquarium_?????.jpg  n=0 # loop through the files, increasing a counter at each iteration. for i do   # every 4th iteration, append the current file to the end of the list   [ "$(($n % 4))" -eq 0 ] &amp;&amp; set -- "$@" "$i"    # and pop the current file from the head of the list   shift   n=$(($n + 1)) done  # now "$@" contains the files that have been appended. cp -- "$@" /some/place   since those filenames don't contain any blank or wildcard characters, you could also do:  cp $(printf '%s\n' 00802_bla_aquarium_?????.jpg | awk 'nr%4 == 1') /some/place  
turns out all i had to do was restart my homehub
you can resolve which filesystem a directory or file is on with the command df, and if you include the -t option, the output will include the filesystem type.  $ df -t /tmp filesystem     type 1k-blocks    used available use% mounted on /dev/sda3      ext4  38715020 5073600  31674780  14% /   in the above example, the /tmp directory is on an ext4 filesystem, not tmpfs. 
gnu tar supports "--wildcards" option.  tar tvfz file.tar.gz --wildcards '*/.htaccess'  
as slm already indicated you can test for $f to be a regular file
macports has dash, which is what debian uses
from man 1 ssh  -t  force pseudo-tty allocation
find 
the drive is probably mounted with the errors=remount-ro option, and there are read or write errors while running the rsync
what part of your webserver is even doing dns lookups? most webserver configurations explicitly disable reverse dns lookup of each incoming user, for speed (because dns is slow in general).  as patrick notes, nscd is doing the right thing and respecting the positive ttl values
you should be able to achieve this by setting up a bridge between your two network interfaces.  assuming your integrated ethernet interface is eth0 and that the on via the usb adapter is eth1, a configuration like this in /etc/network/interfaces should work (provided you've installed the bridge-utils package and that your kernel supports it):  auto lo br0 iface lo inet loopback  iface eth0 inet manual  iface eth1 inet manual  iface br0 inet dhcp     bridge_ports eth0 eth1   if you run ifconfig, you should then see a br0 interface (probably with the mac address of eth0 if i remember well)
a for loop:   for f in *.c; do cp -- "$f" "$otherdir/old#$f"; done   i often add the -v option to cp to allow me to watch the progress. 
just for completeness, you dont need all those (") nor the final $(echo ...). here's the simplified version of your assignments that produce the same effect:  startime=$(date +"%t") endtime="$startime today + 10 seconds" call="date -d '$endtime' +'%h:%m:%s'"   note how you dont need to quote when doing var=$(...) but you do usually with var="many words":  a=$(echo 'a    b'); echo "$a" # result: a    b   inside (") a (') has no special significance, and vice-versa, eg:  a="that's nice"; echo "$a" # result: that's nice a='that "is nice'; echo "$a" # result: that "is nice  
$ sudo grubby --info=all | grep -b1 '^kernel=' | grep -b1  `cat /proc/cmdline | awk -v rs=" " '/^boot_image=/ {print substr($0,12)}'`$ | head -n1 index=0 $    reference:    http://superuser.com/questions/462737/where-can-i-find-the-linux-kernel-file http://stackoverflow.com/questions/30524468/how-to-extract-value-of-root-variable-from-kernel-commandline http://unix.stackexchange.com/questions/124462/detecting-pattern-at-the-end-of-a-line-with-grep  
i would just pass that through a second grep to remove them:  grep -r --exclude={\*~,\*.map} "ok" bar/ | grep -vp '(?&lt;!debug)\.js'   the -v reverses the match, printing lines that don't match the pattern and the -p enables perl compatible regular expressions which let us use negative lookbehinds
type the following  :r filename_to_paste   this will paste the contents of the file after the line on which the cursor is present.    if you need to copy/paste smaller range of lines/block of text from one file to other, you can also do the following assuming one file is opened in vim already   open 2nd file using :sp (split) or :vsp(vertical split) do a normal yy (yank) commands in the other file do p (paste) command back in the 1st file, as the register (place where yanked text is stored) is common to both the files. press ctrl+w twice to switch between splited files.  
resizing partitions into the free space after them works pretty well with gparted
to navigate to the section under the cursor, you use ctrl] (that's a right bracket, not a j):  jumping around  the text contains hyperlinks between the two parts, allowing you to quickly jump between the description of an editing task and a precise explanation of the commands and options used for it
there's a tip in the sudo man page which explains how to do something like this
this should work:  for i in serverlist;do    ssh $i "usermod --password $(echo my_new_password | openssl passwd -1 -stdin) username" done   usermod doesn't prompt but the password needs to be encrypted first. 
first, you need to quote the dollar signs that are supposed to be interpreted by the shell
the linux documentation project has a description of the linux filesystem hierarchy where they explain the different folders and their (partly historical) meaning
turn on the null_glob option for your pattern with the n glob qualifier.  list_of_files=(*(n))   if you're doing this on all the patterns in a script or function, turn on the null_glob option:   setopt null_glob   this answer has bash and ksh equivalents.  do not use print or command substitution! that generates a string consisting of the file names with spaces between them, instead of a list of strings
ln -s lib /usr/lib64   if there is a directory /usr/lib64 then this creates a symbolic link /usr/lib64/lib → lib (the link is broken because it's looping: it's pointing to itself), otherwise this creates a symbolic link /usr/lib64 → lib (so the target is /usr/lib).  so you don't actually need to go looking for that link: you know where it is.  nonetheless, if you happen to want to find a symbolic link knowing its name, you can use  find / -name lib -type l   if you happen to want to find a symbolic link knowing its target, you can use  find / -lname lib   if you want to limit the matches to broken symbolic links, you can use one of  find / -l -lname lib find / -xtype l -lname lib  
that is not easily possible
your problem is that perl is using buffered input, so reads ahead beyond the lines you want to consume
you're experiencing samba bug 4715, reported as debian bug #612503
rsync was designed exactly to solve this problem:  [$]&gt; rsync -av --ignore-existing dira/ dirb/  
the point of marking packages as having been automatically installed is so that aptitude will know to only keep them if they are required by something else
enclose your alias in single quotes instead of double quotes.  alias dockereval='eval $(docker-machine env)'   double quotes allow expansion of variable (in bash at least) while single quotes don't 
as for as i can find only e5 xeons are supported with the sb_edac module  http://www.spinics.net/lists/linux-edac/msg00846.html 
yes:  $ tmux attach -d || tmux new  -d is necessary to behave like  screen -d, ie, detach everybody else.  connect by ssh, then attach or create could be something like:  $ cat bin/stmux #!/bin/sh exec ssh -t $@ 'tmux attach -d || tmux new' $ stmux my.remote.box  
the trailing newlines are stripped before the value is stored in the variable
seeing as df doesn't seem to be working for you, try running this in the root directory of the mounted filesystem/disk
you can't export a function or a variable to a parent shell, you can only export to the shell running the script or to child shells.  for a script to change the environment of your current shell, you need to run the script with source or .
tail normally follows the file descriptor (--follow=descriptor), which becomes inaccessible when the log file is rolled or the file is moved away
as lk- said, the -name option of find will treat the argument as a glob, not a regular expression.  whether a string is interpreted as a glob or a regex or just a plain string depends on what is being used to do the interpreting
this got me wondering and i had a look at the linux kernel source (i'm assuming your question is about linux).  it appears the answer's more difficult than you'd expect
put the commands that you want to run as the other user into a separate file, user2commands, and then do  sudo su - user &lt; user2commands  if you don’t want to have a separate file, consider:   sudo su - user &lt;&lt; eof     commands to be run as the other user         ︙ eof  
there is an application called bleachbit it has following features:   clear the memory and swap on linux delete broken shortcuts on linux delete the firefox url history without deleting the whole file—with optional shredding delete linux localizations: delete languages you don't use
you cannot do this with ufw directly, but you need to add the right iptables rules to /etc/ufw/before.rules.  i suggest you to learn iptables
the konsole profile contains settings specific to konsole eg terminal font, text colour, background colour, settings for shorcuts to manipulate tabs etc.  /etc/passwd defines the default shell for the user, of which bash is just the most common option
it would be much easier with regular expression if you have the gnu find,  find 
using the same structure as your original script, you just need to iterate over the $@ array (that's the list of arguments given in the command line):  #!/usr/local/bin/bash set -e if [ "$#" -lt 1 ] then echo  "please insert at least one argument" exit else echo -e "\c" fi   for file in "$@" do     if [ -h  "$file" ]     then          echo "$file is a symbolic link"     else              echo "$file is not a symbolic link"     fi done   a simplified version of the same thing would be:  #!/usr/bin/env bash [ "$#" -lt 1 ] &amp;&amp; printf "please give at least one argument\n" &amp;&amp; exit  for file  do     [ -h "$file" ] &amp;&amp; printf "%s is a symbolic link\n" "$file" ||          printf "%s is not a symbolic link\n" "$file" done  
to get a complete description of all the active services, try:  ifconfig | pcregrep -m -o '^[^\t:]+:([^\n]|\n\t)*status: active'   this simple regex should filter out only active interfaces and all their information
to concatenate files you use  cat file1 file2 file3 ...   to get a list of quoted filenames sorted by time, newest first, you use  ls -t   putting it all together,  cat $(ls -t) &gt; outputfile   you might want to give some arguments to ls (eg, *.html).  but if you have filenames with spaces in them, this will not work
normally the answer would involve classpaths and the -cp argument, but the documentation for this particular project makes the issue clear:     extract the jar file and lib folder to   a directory of your choosing.   those other three jars are expected to be in a subfolder called lib, not in the same directory as the "main" jar. 
i think option 3 as you have described above is probably your best bet
obviously, it will be difficult to download software if your network is not working
if you use the default mailserver (sendmail), you should add the -f argument to the sendmail_path in php.ini 
preamble  you probably don't want to invest time into preventing people from disassembling your code: instead focus on making your project better, so that once your competitors have figured out how you did feature x, your software already has feature y...  the reasoning is simple:  if you have a dull project, then nobody will care to disassemble it and you have invested all the time for nought. otoh, if your product is cool, an armada of hackers will spent time to figure out how you did it
assumptions:    you have control over this file and are not in danger of malicious code you want to set these variables your current shell   you could redirect your commands to a temp file and execute that:  tmp=$(mktemp) {     grep somedir installfile     grep 'export perl5lib' installfile } &gt; "$tmp" 
according to this, https://wikidevi.com/wiki/r8712u your chipset does not supports monitor mode.  not all combinations of hardware/software support wifi monitor mode
on linux at least,  kill -- -1   will send the sigterm signal to every process it can  except for the calling process (so the process running that kill command which could be the shell if kill is built-in there (it usually is on posix shells) or the process running a standalone kill command) and the process of pid 1.  note that it does it as part of the kill() system call, so it's more reliable than using commands like pkill or killall (or the traditional killall command sometimes found as killall5 on linux traditionally used for that) that first list the processes and then kill them as those would miss the processes that have been spawned in the mean time.  so it sounds like exactly what you want.  trap '' term # ignore sigterm ourselves though it wouldn't be needed               # in most shells kill -- -1 sleep 1 # leave processes some time to exit cleanly on sigterm kill -s kill -- -1 # removes the remaining processes or those                     # that have started since without giving them                    # a chance to clean-up. exit   should kill everything but the process of id 1.  you can experiment with it by running:  unshare --mount-proc -mpf   that starts a shell in a separate pid and mount namespace (with a new /proc (as used by ps/pkill/killall)) where that shell has pid 1.  outside of linux, kill -- -1 should work on every system at killing most processes, but the list of processes that are exempt from the killing can vary from system to system. 
definitely keep it open! the only reason to close it would be to keep it synced, but you can call sync by hand if you are scared of power outages
first of all; "kill -9" should be a last resort.  you can use the kill command to send different signals to a process
since nobody's answered yet, and after tedious hours of googling and testing, i got some grasp of the subject, i'm going to answer it...  since framebuffer device interface is a quite general one, there could be more fb devices in principle
did you notice the line lv status not available in the output of lvdisplay?  before you can access the volume group, you will need to activate the volume group using:  vgchange -a y   after the volume group is active you can mount the filesystem within the volume group. 
the preferred method is the following:   making a backup of the data making a backup of the software selection performing a fresh installation using the livecd/liveusb of the new release restoring the data restoring the software selection   that way you have the greatest chance of getting a new working system
to add all lines from filename to filename1 using sed command you can do the following:  sed r filename1 filename   please note however that the result will be slightly different from the output in your question, namely:  name  class1 class2 class3 lee      92     94     88 chancy   91     85     95 dora     99     77     96 jefferry 84     98     90 cindy    11     22     54 chester  48     12     84     edit  some additional sed information useful for this question:   to add filename after 4th line of filename1:  sed '4 r filename' filename1 to add filename after line which starts from "dora" in filename1:  sed '/^dora/ r filename' filename1 to add filename after 4th line and remove any blank lines from filename1:  sed '/^$/d;4 r filename' filename1  
i may have found something:  the ls command on os x has this switch:    -o      include the file flags in a long (-l) output.   the result is:  $ ls -o info.plist -rw-r--r--  1 root  wheel  compressed 15730 11 jui 15:02 info.plist   i just checked (experimentally) that du always reports 0 for hfs+ compressed files.  copying compressed files uncompress them; so logically du reports the correct file on a copied, uncompressed file.  here is an explanation for the behaviour of du:  hfs+ file compression     in mac os x 10.6, apple introduced file compression in hfs+.   compression is most often used for files installed as part of mac os   x; user files are typically not compressed (but certainly can be!).   reading and writing compressed files is transparent as far as apple's   file system apis.      compressed files have an empty data fork
you can configure cups defaults for your account by running the lpoptions command
because you are doing buffered io and the page cache works in whole pages, which are 4k on pcs, or 8 512 byte sectors
uim  first released in 2005, uim is a multilingual input method library with interfaces to gtk and qt, as well as anything that supports xim (and more)
if you aren't worried about losing any / all the files from either partition, you can set up an ubuntu-only environment extremely easily: simply download the ubuntu iso (here), and select "erase everything and install" when prompted.  if you want to keep everything on your ubuntu partition, that's not too difficult if your ubuntu partition is set up with lvm
for your particular question this command will work
sed's api is primitive - and this is by design
   by system clock i mean the clock that tells the time down right of the panel    "system clock" generally refers to the clock maintained by the kernel; applications such as date and gui clocks such as the one you refer to make calls to it like this.     why, out of all the processes that the system runs, does the clock need a shared memory segment?   there's probably dozens of different gui and de based clocks available for linux so there's no way to say specifically
the command wc aka
   am i then right to think that any pair of processes can be piped to each other?   not really.  the pipes need to be set up by the parent process before the child or children are forked
you could assign a shortcut to a command like:  xclip -o -sel p | tr '[:lower:][:upper:]' '[:upper:][:lower:]' | xclip -i -sel c; xdotool key shift+insert   this assumes shift+insert pastes from clipboard (if that's not the case, replace shift+insert with ctrl+v)
short: you don't do this.  long: here's why   a unified-diff is a script, using line-numbers and counts which tie-in to the content of the diff. it's possible to manually make simple changes to this script (i do...), but a unified-diff is mainly useful with the patch program, and patch checks for consistency between the parts of a diff, and patch will reject the parts which it finds are inconsistent.   these lines contain line-numbers and counts:  @@ -1,7 +1,6 @@ @@ -9,3 +8,6 @@   and the counts must match the number of leading + or - marks in the remaining lines of the diff.  so you don't do this manually
making /dev/null a named pipe is probably the easiest way
is this process interfering with other processes on your system? why do you want to limit the cpu bzip2 uses?  you can use the nice command to change a process's priority:  $ nice -n 19 bzip2 &lt;file&gt;   additionally, you can try lowering the bzip2 compression level:  $ bzip2 -1 &lt;file&gt;  
you need to add the new defaut gatway , remove the old one then save routing information to a configuration file:  route add default via xx.xx.xx.xx route del default via yy.yy.yy.yy ip route add default gw xx.xx.xx.xx ip route del default gw yy.yy.yy.yy   the new gatway = xx.xx.xx.xx  the old gatway = yy.yy.yy.yy  save routing information:  nano /etc/network/interfaces   add the following line:  gateway xx.xx.xx.xx   restart networking:  /etc/init.d/networking restart  
gedit can be a great editor when extended with gedit-plugins    
you can use sed
if you have redhat subscription then the answer is described at this page.  option 1
ls -d shows information about a directory or symbolic link - with this information being (in simple terms) it's respective path
bash has a built in "timer"
chown in fact returns zero when run under fakeroot
chaos' answer is what some doco says
the code in your post will execute the file file/commands/crontab_file and redirect the standard output to the file $pwd/tmp
you can share /usr/local
i was going to suggest hacking e2fsck to disable the specific checks for a last mount time or last write times in the future
eudyptula-boot is quite handy for this; its introductory blog post has more details, but basically it allows you to boot a vm using the kernel you wish to test, and your existing filesystems (using overlayfs)
set up an init file that will source the user's init file at the start, and then do whatever else you want:  $ cat env.sh 
i'd split you task into two steps: getting emails and parsing emails, because second step depends of first one, if you cannot get emails then you have nothing to parse. first step depends of mx records and ways you can access mx server
there are a few things wrong with this snippet, but surprisingly, the double file check isn't one of them.  first, the $() construction around find is wrong, as @ericrenouf shows
old question, but saying this for anyone who might have the same issue i had:  on ubuntu 16.04 (and probably other systemd systems) the unattended-upgrades is not triggered by cron anymore
try  cat /etc/*-release  or  cat /proc/version  or  lsb_release -a 
no, the manual page for loadkeys says you cannot, in the warning section:     note that anyone having read access to /dev/console can run loadkeys   and thus change the keyboard layout, possibly making it unusable.   note that the keyboard translation table is common for all the   virtual consoles, so any changes to the keyboard bindings affect all   the virtual consoles simultaneously.      note that because the changes affect all the virtual consoles, they   also outlive your session
if i understand correctly, what you want to accomplish is to prepend the current date to every line that is output by grep
you can use the tree utility for this:  tree -l 2  
if you have a set of directories that you want to incorporate into a iso file you can do it using this command:  % mkisofs -o ~/my_iso.iso -r -j -hide-rr-moved -v "title of iso" \        -graft-points "directory1/=/home/me/dir1" "directory2/=/home/me/dir2"   the above command switches are as follows:  -o = name of output .iso file -r = set permissions to 0 -j = output's iso using joliet format (useful for windows users of the final iso) -v = volume id  -hide-rr-moved = hides the directory rr_moved to .rr_moved -graft-points = specifies names of locations in iso and what goes into                  them from local system   hiding files  i believe you could modify the above and add the switch -hide-joliet &lt;pattern&gt;
yes each applications typically has it's own permissions set via "permission bits" on the actual application
there's really not enough information, but from the messages it seems that you have given xorg a configuration file containing a literal ${prefix} where it expects an actual directory name such as /usr.  that probably reflects a quoting problem in whatever build-script you are using, since a shell would be doing the substitution of ${prefix} while xorg's parser is not able to do this.  xorg is reading configuration files from /usr/share/x11/xorg.conf.d, including one containing the fontpath information
the service command is part of the sysvinit-utils package.  install it with:  apt-get install sysvinit-utils   but most probably, it is already installed in /usr/sbin/service.  if it's missing in your $path, add this line to your ~/.bashrc:  path=$path:/usr/sbin  
method #1: vim  i believe you can do what you want with the following keyboard commands in vim, as follows.  note: =, the indent command can take motions.  so:   gg to get the start of the file = to indent g to the end of the file   putting it all together: gg=g.  method #2: without vim  this isn't a vim solution but i came across this perl script titled latextidy.pl which might be more useful if you have multiple files you have to do this with.  the original script and a copy on pastebin:   http://bfc.sfsu.edu/latextidy-0.31.pl http://pastebin.com/p7vv0gma   example  to run it you'll need to make it executable after downloading it and then just run it passing it the name of a latex file.  download  $ curl -o latextidy.pl http://bfc.sfsu.edu/latextidy-0.31.pl   % total    % received % xferd  average speed   time    time     time  current                                  dload  upload   total   spent    left  speed 100  4755  100  4755    0     0   1201      0  0:00:03  0:00:03 --:--:--  1334   permissions and running  $ chmod +x latextidy.pl $ ./latextidy.pl &lt;some_latex_file.tex&gt;  
you can always write a cronjob that calls a script that conditionally calls crontab -l &gt; oldcrontab and then executes crontab file
systemd mountpoints support more flexible configuration of at least when to mount each point
when you want bash to stop logging your commands, just unset the histfile variable:  histfile=   all further commands should then no longer be logged to .bash_history.  on the other hand, if you are actually supplying passwords as arguments to commands, you're already doing something wrong
find has a little bit of sophistication to deal with this case:     if the expression contains no actions other than -prune, -print is performed on all files for which the expression is true.   so explicitly print just the parts you want:  find -type d \( -iname old -prune -o -iname backup -prune -o -iname .git -print \)   avoids searching the old and backup trees at all. 
it's unneeded
tl;dr;   use   ls --color=always &gt; /dev/null 2&gt;&amp;1 &amp;&amp; alias ls='ls --color=always' || alias ls='ls -g'`   details.... [...] are only needed to evaluate conditional expressions (stats of files, string comparisons, numeric comparisons; see conditional expressions in bash(1))
the file /sys/devices/system/cpu/cpu0/cpufreq/cpuinfo_max_freq contains the maximum frequency in khz (that directory, /sys/devices/system/cpu/cpu0/cpufreq, also contains a bunch of other cpu-frequency related information)
technically you can achieve this. though, kernel do not have any built-in user-interface.  you need to follow steps as:  1
i use these settings with urxvt in my ~/.screenrc:  termcapinfo rxvt-unicode ti@:te@ termcapinfo rxvt ti@:te@ termcapinfo rxvt 'hs:ts=\e]2;:fs=07:ds=\e]2;screen07'   those allow for scrollbar and mouse wheel to do "the right thing™"
so you are logged into a machine myclient and have ssh access to another machine myserver
you should be able to dd if=linux.iso of=/dev/sdx, where x is the letter for your usb device
it depends on which architecture (i386, amd64, etc.), which media (cd/dvd/bd, usb-hdd, netboot, etc.), which release (jessie, wheezy, etc.), or which firmware (bios, uefi, etc.) you want to boot to run debian installer.  for debian jessie iso images for intel pc bios based architecture, you will use isolinux boot loader
to quit less, type q.  also, check out man less, or type h from within less for some more, useful bits of information.  in general, assuming man has been properly installed, man xyz will tell you how to use the xyz tool
if you ask file for just the mime-type you'll get many different ones like text/x-shellscript, and application/x-executable etc, but i imagine if you just check for the "text" part you should get good results
you don't need to suspend vim history
if you are not a member of the group assigned to the directory, then if you modify any permissions, you will lose setgid on that directory.  options   you could change your umask before you create the directory, avoiding the need to modify the permissions on the directory after you create it
according to http://www.vim.org/download.php, sun solaris vim is included in the companion software: http://wwws.sun.com/software/solaris/freeware/.  vi has had the :ve[rsion] command going back at least as far as 1979, so it should work on any solaris release. 
sensible-browser does the following:   if the browser environment variable contains anything, it splits the value using : and each substring is tried as a candidate for a browser (so you can set browser to be your favourite browser's executable); if you're running gnome, it tries running gnome-www-browser, which you can configure using update-alternatives --config gnome-www-browser (as root) to point to your favourite browser; if that fails, or you're not running gnome, it tries running x-www-browser, which you can configure using update-alternatives --config x-www-browser (as root) to point to your favourite browser; if that fails, it tries running www-browser, which you can configure using update-alternatives --config www-browser (as root) to point to your favourite browser (but it's supposed to be a text-mode browser such as lynx or w3m).   none of the alternatives take their value from your desktop environment's default; that explains why they ignore the browser you've configured. 
use sed.  note that you won't be using 0 indexed positions, but starting from 1
with gnu date you can do it as simple as this:  date --date="3min"   but busybox seems not so smart (yet)
i don't know about any ready-to-use modules, but i built something like that with event handlers
something like this?  ssh user@server /sbin/ifconfig -a  
the most portable way (not knowing what shell runs your /etc/rc.local) would be to add  $shell -c "sleep 10; ifup eth0" &amp;   to your rc.local
logrotate uses crontab to work
with apt-get you do   apt-get install -t wheezy-backports qt4-qmake   i don't think the :amd64 is necessary, unless amd64 is not the standard arch for your machine
way to find the specific driver name   lspci | grep -i network   i am not sure whether that device is on the pci or usb bus but you can try the following.   use lsusb or lspci to find information about the device lookup that device for the corresponding module ("driver") make sure that module is loaded and available with lsmod and modprobe   another idea would be to use lsmod and diff to find out which modules are going missing when your laptop uses sleep mode
look for /boot/config&lt;...&gt; file (belongs to kernel deb package)
su requires the password of the account whose privileges you are trying to assume (apparently root in this case)
here is an awk solution that goes out of its way to prevent printing the second a:  awk '$1 == "a" { if (!head) print; n=head=1; next } $1 !~ /^[0-9]/ { n=0 } n' ascii_file   replace "a" with "b" to get those results, etc.  output:  a 1 2 3 1223 4 5   if you wanted a loop, you could do it like this:  for letter in a b c; do   echo   awk -v letter="$letter" '$1 == letter { if (!head) print; n=head=1; next } $1 !~ /^[0-9]/ { n=0 } n' /tmp/a done   which would have this output:  a 1 2 3 1223 4 5  b 1 2 3 5 3344 1223  c 1 2 34 123   (note the echo line
afiak, only the new mindstorms ev3 run linux-based firmware
there are lots of options!!!  summary  $ echo "$((20.0/7))" $ awk "begin {print (20+5)/2}" $ zcalc $ bc &lt;&lt;&lt; 20+5/2 $ bc &lt;&lt;&lt; 'scale=4;20+5/2' $ expr 20 + 5 $ calc 2 + 4 $ node -pe 20+5/2  # uses the power of javascript, e.g
install the dependencies?  rhel 5.9 is in end of production phase 3
so vim 7.3 is new enough that there isn't much information about the lua integration
the most simple solution for me was to install gnome-disk-utility in synaptic manager.  then, starting 'disks' follow this procedure
has hinted at by jari laamanen, the solution lies in this buffalo.nas-central.org thread:  i have added root to a new group, which happend to be blocked from ssh access in the file /etc/sftponly
here is a more robust form that correctly handles spaces (or even newlines) in filenames and directory names.  find 
since you are already using awk, perhaps the simplest way is to do the float comparison within this language as well:  max_load=10.0 if ! &lt;/proc/loadavg awk -vmax_load=$max_load '{ exit $1 &gt; max_load }' then     echo alert fi   note that there is a bit of trickery going on: the ! operator reverses the test
like this perhaps  perl -pe 'use posix qw(strftime); s/^(\d+)/strftime "%f %h:%m:%s", localtime($1)/e'   
use wait
the compose definitions ($xcompose, ~/.xcompose or a file under /usr/share/x11/locale) are loaded by each client application, not by the x server
jq 
the question is how to determine what linker flag to use from inspection of the source file
you could check if you are running in a graphical terminal and only set tmout if you are not
   dd if=/dev/zero of=/dev/sda bs=4096 count=4096   q: why 4096 is particularly used for counter?   this will zero out the first 16 mib of the drive
you can use apt-show-versions for this
way tl;dr  your diagram is essentially correct.  /dev/&lt;device&gt; files  i think the most basic way to start answering your question is with what /dev/&lt;device&gt; files are
you'll need to use a conditional for this.  %if 0%{?suse_version}      # any version of suse buildrequires: libx11-devel %else buildrequires: xorg-x11-libx11-devel %endif   further information can be found from opensuse and fedora wikis respectively. 
just use:   disown -r    it will kill all processes and you don't need to restart your machine. 
partially solved, although vmware tools did not install properly, the xorg drivers for vmware were installed but xorg.conf wasn't pointing to those drivers.  i changed the driver from default vesa to vmware.. full list of resolutions is now available under gnome settings
a file is an identifier for accessing data
though it is not the best answer, i found something that works by adding the following to my exclude-list.txt file:  *synctest/excludetest/*   i found the answer here:  http://sourceforge.net/p/s3tools/bugs/81/  it is not intuitive, and i think it is a bug
if you mean learn linux as in getting to know the source code, you may want to try linux from scratch 
i believe this is the command you need:   date '+%y%m%d%h%m%s'  
if you have a terminal whose description "looks" like xterm, screen assumes it does everything like xterm
export makes a variable something that will be included in child process environments
i suggest these two:   http://www.oldlinux.org/  and a more straightforward one from this site that contain linux kernel 0.01, 0.10, 0.11,...,0.98:   http://www.oldlinux.org/linux.old/  and the other:  http://www.codeforge.com/article/170371 
you can insert ctrl-v somewhere in the abbreviation to avoid the abbreviation occur
according to the webpage, it uses pdftotext for pdf previews
afaik there isn't a way to specify your media path in the config file
the self maintenance method is to vacuum the logs by size or time.  retain only the past two days:  journalctl --vacuum-time=2d   retain only the past 500 mb:  journalctl --vacuum-size=500m   man journalctl for more information. 
you can use disown, it is a bash builtin:     disown [-ar] [-h] [jobspec ...]      without options, each jobspec is removed from the table of active   jobs
cat ./text | awk ' { if ( length &gt; x ) { x = length; y = $0 } }end{ print y }'   upd: summarizing all the advices in the comments  awk 'length &gt; max_length { max_length = length; longest_line = $0 } end { print longest_line }' ./text   
there is no other performance penalty except disk access speed and latency (delay before the first byte is read) in accessing your files.  when accessing a lot of data the system will be busy transporting this data using the usb (b)us and its access to it (e.g
in order to read /proc/[pid]/mem, a process must now ptrace_attach to it
most systems have the logger utility, which knows how to talk to syslogd
try  awk 'nr%12 == 1 { min=$5 ; line=$0; }      { if ($5 &lt; min) { min=$5 ;line=$0; } }      nr%12 == 0 { print line ;}      end { if (nr%12) print line ;} '    this basically reset min every 12 lines (1,13,25, ...), compute min, and print it for line 12,24,36,...  end statement print last min if number of line is not a multiple of 12.  note that you can one line this statement, call it with  awk '....' input_file.txt  
this isn't working because iconv first creates the output file (since the file already exists, it truncates it), then starts reading its input file (which is now empty)
the command man -k queries against a pre-compiled database and not the manual pages themselves.  i suspect that entries may have been made in the database (see man mandb for details) for pages that don't actually exist
rm -r is expected to be slow as its recursive
thanks to jeff schaller
create myfilewithcommands.txt:  php index.php import file1 --offline php index.php import file2 --deleteunused php index.php import file3   then run parallel like this:  parallel -j 3 -- &lt; myfilewithcommands.txt  
those aren't processes, they're threads
date --date 'jul 16 1991' +%a   see man date, specifically the section on output formatting. 
because the parent process is not making any library calls...  like strace, there is a flag to follow child process.  check the man page;      -f     trace child processes as they are created by currently traced processes as a result of the fork(2) or clone(2) system calls
your compressed tar file is smaller than its contents.  ls prints file sizes in bytes by default. du -k prints file sizes in kilobytes.    to make ls print file sizes in kilobytes, use the -k flag. 
in a shell script:  if [ -t 0 ]; then   echo stdin is a terminal fi   in a perl script:  print "stdin is a terminal\n" if -t;   in c:  if (isatty(0)) puts("stdin is a terminal");   they all do the same, do a tty specific ioctl and return true unless the ioctl fails with a enotty error
you can not export the parent's environment into any of it's children, once the child has been forked
you want to do the rename backwards:  counter=$((final_number + 1)) for index in {final_number..0}; do   mv "icon_${index}.icns" "icon_${counter}.icns";   let counter--; done  
 s settings c config advanced user preferences disable keymenu press x to toggle press e to exit  
the text displayed before the login prompt is stored in /etc/issue (there's a related file, /etc/motd, that's displayed after the user logs in, before their shell is started)
go for alternate: .
you will need to either create a port forwarding on the nat router, but beware because then its open to the whole internet, or you need to have something connecting out to allow you in.  for example one thing what i like to do is to submit the following command behind a nat.  ssh -r 10022:127.0.0.1:22 me@myserver.com   this command connects to myserver.com and opens port 10022 there
just drop this binary into that flash drive fat's root directory under the name of shellx64.efi, or get yourself a copy of refind usbflash image which would also serve as a decent boot manager. 
from user mode linux: skas mode:     if you run ps, you will notice only four processes per uml rather than the dozens that you see in tt mode
i was blindly focused on ghostscript, but thanks to stephen, i found out it seems due to a bug in qpdf
your use of 'parent folder' is a little confusing, this will find all the folders (actually directories) in a given path, without traversing the entire tree, that are made up only of a-z.  find /given/path -type d -maxdepth 1 -regextype sed -regex ".*/[a-z]*"  for example, to do the current directory,  find 
check out :help 'showbreak':  'showbreak' 'sbr'   string  (default "")                     global   the global means that there's no buffer- or window-local value.  you have to either   work around this with a set of :autocmds that switch the option based on the entered buffer
since you mention using / for searching, i will assume you are using vi-mode keys
&lt;?php   $command = "grep -ri 'abcdef' ./*";   $output = shell_exec($command);   echo "$output";   echo "grep job over."; ?&gt;   change to suit your required grep search.  save as grep.php
as folks already noted, put the /bin only in jsx_home or path, not both
it is a known flaw of "command expansion" $(...) or `...` that the last newline is trimmed.  if that is your case:  $ output="$(head -- "$file"; echo x)"     ### capture the text with an x added. $ output="${output%?}"                    ### remove the last character (the x).   will correct the value of output. 
the old-fashioned way was to use postedit   postedit=$'\e[0m'   (and by the way this isn't bash, don't use a debug trap to simulate preexec: zsh is where it's from) but since zsh 4.3.11 you can use the command line syntax highlighting facility
if your software do a critical job you have to write a service file and put it under /etc/init.d that when computer goes down your script start stop function in that script which you need to clean up to not mess up your program
you can do that like this:  find 
this solution works on a 64 bit machine
you can try it this way,   find /usr/lib -maxdepth 1 -type l -iname "*lib*" -print \    | xargs -p1 -i{} -- sh -c 'echo -n " {} =&gt; " &amp;&amp; realpath "{}"'  
the easiest way of doing this is to include a shell script in /etc/bash_completion.d/
this will be the directory with the contents of your tarball
like most commands, alt+. takes a numeric argument
you can use the builtin command, bind to map a keyboard shortcut so that it executes a command/shell script.  example  say we want to run the command, pwd, when we press the f12 key.  $ bind '"\e[24~":"pwd\n"'   now when i press f12 at my prompt, $:  $ pwd /home/saml   determining keyboard shortcuts  you can use the following technique to determine the escape code for a given keyboard shortcut
you can use the mate desktop environment + compiz grid plugin to get this result. 
you can stop the process with ctrl-z
see customize the xfce menu at the xfce site. 
this answer to the first linked question has the almost-throwaway line at the end:     see also %g for rounding to a specified number of significant digits.   so you can simply write  printf "%.2g" $n   examples:  $ printf "%.2g\n" 76543 0.0076543 7.7e+04 0.0077   of course, you now have mantissa-exponent representation rather than pure decimal, so you'll want to convert back:  $ printf "%0.f\n" 7.7e+06 7700000  $ printf "%0.7f\n" 7.7e-06 0.0000077   putting all this together, and wrapping it in a function:  #!/bin/bash  # function round(precision, number) round() {     n=$(printf "%.${1}g" "$2")     if [ "$n" != "${n#*e}" ]     then         f="${n##*e-}"         test "$n" = "$f" &amp;&amp; f= || f=$[ $f+$1-1 ]         printf "%0.${f}f" "$n"     else         printf "%s" "$n"     fi }   test cases  for i in $(seq 12 | sed -e 's/.*/dc -e "12k 1.234 10 &amp; 6 -^*p"/e') do     echo $i "-&gt;" $(round 2 $i) done   test results  .000012340000 -&gt; 0.000012 .000123400000 -&gt; 0.00012 .001234000000 -&gt; 0.0012 .012340000000 -&gt; 0.012 .123400000000 -&gt; 0.12 1.234 -&gt; 1.2 12.340 -&gt; 12 123.400 -&gt; 120 1234.000 -&gt; 1200 12340.000 -&gt; 12000 123400.000 -&gt; 120000 1234000.000 -&gt; 1200000  
in general, most utilities have options that begin with -
/proc/$pid/environ does update if the process changes its own environment
there are several options
to get all the info provided by ls -l for a single file or folder, use the -d option and specify the file:  ls -ld filename  
i have modified your script and this one works now
mplayer dvd://1 -dvd-device /path/to/copy_on_hdd/ -dumpaudio -dumpfile audio.ac3 
i don't think there's a general, cross-platform answer
i think you've missed bootloader
grep '123\.123\.123\.123.*\(\.php\|\.html\)' logfile   unless of course the .php or .html precedes the ip address:  grep '\(\.php\|\.html\).*123\.123\.123\.123' logfile   you can always craft a regex that does both, but a simple option is just to use two greps:  grep '123\.123\.123\.123' logfile | grep '\.php\|\.html'   note the \. which i originally forgot matches an actual dot, while a dot on its own matches any character
the common protocols http, ftp and sftp support range requests, so you can request part of a file
yes
hmm
assuming that you can boot to the sd card, you might try using dd to write the iso image to the sd card
you basically have 2 options.   use the local authentication system of each machine, and push out credential changes to all of them. use a centralized authentication server.   1
if you have a stop condition on your tshark you can simply pipe the output into |sort -u
using spaces fixes your problem.  if [ "$1" = 1 ];     then     shift         mv "$@" ~/lab/sun elif [ "$1" = 2 ];     then     shift         mv "$@" ~/lab/moon elif [ "$1" = 3 ];     then     shift         mv "$@" ~/lab/earth fi   though this is neater:  #!/bin/bash  action=$1 shift files=("$@") case $action in     1) mv -- "${files[@]}" ~/lab/sun     ;;   2) mv -- "${files[@]}" ~/lab/moon    ;;   3) mv -- "${files[@]}" ~/lab/earth   ;; esac  
kdm is a display manager: it's the program where you type your credentials and get logged in
if there is nothing to be done after curl:  while true; do   avconv ..
if you manage patches often, then you may be interested in quilt
https://www.freebsd.org/doc/en/books/handbook/updating-upgrading-freebsdupdate.html, section 24.2.3.3:  portmaster -af  forget about "quickly" though
i recommend creating an upstart script.  first you want to create the script itself: sudo nano /etc/init/ts-server.conf  copy and paste this skeleton and make any changes you need:  # description "start and stop the ts server"  console log # log events to console  exec start-stop-daemon --start --chdir /home/teamspeak/server/ --chuid teamspeak \     --exec /home/teamspeak/server/ts3server_startscript.sh start   start on runlevel [2345] # tell when to start stop on runlevel [^2345] # tell when to stop  respawn # block excess respawn respawn limit 20 5 # ditto   save that file, go to /home/teamspeak/server/ and create a file ts3server_upstart.shcontents:  #!/bin/bash /home/teamspeak/server/ts3server_startscript.sh start   save, mark it as execuatable, done! it'll start on boot, and can be manually started/stopped/restarted using sudo service ts-server start, sudo service ts-server stop, and sudo service ts-server restart, respectively.  edit: this may not actually stop teamspeak
there are few differences between elf executables on different platforms
what i would do :  for i in "${array[@]}"; do     ping -c1 "$i" &amp;&gt;/dev/null &amp;&amp; echo "$i on" || echo "$i off" done  
what a sad thing having a vm without internet access :( i think that you should talk to your boss and tell him that without internet access you can't properly update your linux distro, and this can lead to potential security issues.  anyway, you can browse the arch linux official package list from here: https://www.archlinux.org/packages/  you can download a package by clicking on its name and then click to "download from mirror"
you can't bring a variable's value from a subshell to its parent, not without doing some error-prone marshalling and cumbersome communication.  fortunately, you don't need a subshell here
since you opened a quotation ' and pressed enter, the shell is wanting you to close the quote
unset the global_rcs option
the concept of operators origins from the second generation of computers
you can very well do it just by  vim  
drives give this information via smart
the options in all caps are what gets written into the configuration file for the kernel you will be building (which make menuconfig generates)
rule of thumb, at least on debian-flavoured systems:   /usr/local for stuff which is "system-wide"&mdash;i.e
here's not so concise bash script:  #!/bin/bash  v4dec() {         for i; do                 echo $i | {                         ifs=./                         read a b c d e                         test -z "$e" &amp;&amp; e=32                         echo -n "$((a&lt;&lt;24|b&lt;&lt;16|c&lt;&lt;8|d)) $((-1&lt;&lt;(32-e))) "                 }         done }  v4test() {         v4dec $1 $2 | {                 read addr1 mask1 addr2 mask2                 if (( (addr1&amp;mask2) == (addr2&amp;mask2) &amp;&amp; mask1 &gt;= mask2 )); then                         echo "$1 is in network $2"                 else                         echo "$1 is not in network $2"                 fi         } }  v4test 10.1.2.3 10.0.0.0/8 v4test 10.1.2.0/24 10.0.0.0/8 v4test 192.168.0.1 10.0.0.0/8 v4test 10.0.0.0/7 10.0.0.0/8   output:  10.1.2.3 is in network 10.0.0.0/8 10.1.2.0/24 is in network 10.0.0.0/8 192.168.0.1 is not in network 10.0.0.0/8 10.0.0.0/7 is not in network 10.0.0.0/8  
rather than simply use term=screen, the screen program has a feature which you could use to set different values of term
yes, the addresses are different (they are both load balancers so both will send you to different servers depending on where you are &amp; when you query) but both urls should retrieve the same packages, so yes, you can add the contrib &amp; non-free pools to the deb line you're already using to get the same result.  you can check what you're getting by visiting the archive with your web browser to see the dates on the files, particularly the files in the indices directory at (http/ftp server of your choice)/debian/indices/  if they've got current dates (preferably some time in the past 24 hours) then check the timestamps on the files
compile your source file prog.c with:   $ gcc prog.c   this will generate an executable named a.out
this requires sudo priviledges:  sudo chvt 1  
try ssh-keyscan domain-name and it'll output the public key for you. 
the only thing coming close to what you want is option to display your current cursor position
the "sender", as exim sees it is the envelope-from address, and that was in domain returns.groups.yahoo.com
xdg-mime is part of a collection of scripts called xdg-utils, "a set of common interfaces for desktop environments (de)"
you are pretty close
you are probably best off scripting something
you don't say which shell you're using, so assuming bash, you just do  #!/bin/bash  /path/to/other/script arg1 arg2 rc=$?   the variable rc now contains the return code from your other script
you could run as root  env - scriptname  this will clear your environment before running the script, however, it will also keep your shell
the man page for bash provides two good solutions.....which can be put in your .*rc files   export histfilesize=0 export histsize=0   these can also be entered on your login shell manually as well and it will have the same effect. 
it's not the kernel that's generating the initramfs, it's cpio
you will receive in destination_dir files with full path from /  find /path/git_directory -type f -iname "*.py" \                          -exec cp --parents -t /path/destination_dir {} +   other solution is rsync  rsync -rr --prune-empty-dirs \       --include="*.py" \       --include="**/" \       --exclude="*" \       /path/git_directory /path/destination_dir  
full disk encryption is usually done using the dm-crypt device mapper target, with a nested lvm (logical volume manager) inside
there is a very useful nautilus extension called nautilus-open-terminal that does just what you asked
you could try taking a look at the ~/.xsession-errors file
your question is a bit confusing
i saw your previous question , if you want some environment variable to be set before executing any programs , edit /etc/profile (provided you're using bash) , add everything you need
   now, i believe with setuid any user could execute the script.   not quite
i like cuonglm's approach of probing the shell's capabilities to determine its version based on what is known to be different between versions
just ${i}  ./processing &lt; base.ppm &gt; picture${i}.ppm   example  $ cat foo #!/bin/bash for i in {1..5} do     echo ./processing base.ppm picture${i}.ppm done $ ./foo ./processing base.ppm picture1.ppm ./processing base.ppm picture2.ppm ./processing base.ppm picture3.ppm ./processing base.ppm picture4.ppm ./processing base.ppm picture5.ppm $  
use this:  "${index}_${lumarr[lum]}"   generally:   interpolate all variables using ${...} notation. unless you expressly want to use word-splitting, always enclose variable interpolations in double-quoted strings.  
if you're using bash(1), you can use the compgen builtin:  $ compgen -abc -a function   -a for aliases, -b for builtins, -c for commands and -a function for shell functions
turns out revert-all-at-newline is the answer
check your single quotes
fig
for install linux distros on usb driver first you need to change the driver format to ext4 then install debian as it is ! like on other place !   but in a simple way you can use universal usb installer
the glob must be left unquoted for it to be treated as a glob
it sounds like you want etckeeper from joey hess of debian, which manages files under /etc using version control
you can write a simple for-loop   time -p bash -c "for (( i=0; i&lt;10; i++ )); do command1; command2; done;"   note that i used bash instead of sh for the loop. 
for some reason samba started to mangle the file names containing a colon
change your policies to accept for starters.  $ iptables -p input accept $ iptables -p forward accept $ iptables -p output accept   afterwards things should look like this:  $ iptables -l chain input (policy accept) target     prot opt source               destination           chain forward (policy accept) target     prot opt source               destination           chain output (policy accept) target     prot opt source               destination        this get's you working (maybe) but you still have all those rules to deal with
on the assumption that you are using bash, ksh, zsh, or another similar shell, you can background the process, then run disown
this method will recreate your tar archive, and append the finished part to the existing file
most unices do not have a concept of file creation time
args
ubuntu 13.10 is a supported branch of ubuntu, which means it receives critical security updates for all packages.  the openssl package you have installed is not a vanilla openssl v1.0.1e, but v1.0.1e-3ubuntu1.4 as you can see in the package's profile.  the -3ubuntu1.4 part means the package has been modified by the maintainer for some reasons (perhaps security patches from upstream versions).  if you now look at the changelog of this specific maintainer-created version, you will see that all issues that have been found since the v1.0.1e was realeased are in deed fixed in this maintainer-created version.  long story short, your openssl package is up-to-date from the security point of view, so you do not need to update. 
my issue was putting the wrong scancode, the rule shouldn't be  keyboard_key_1b=playcd   but  keyboard_key_7003a=playcd   you really do require evtest for this (the 'scancodes' provided by showkey -s is not the one you're looking for) 
by default, the openssh server will look for authorized keys in .ssh/authorized_keys and .ssh/authorized_keys2 unless you set a different value for authorizedkeysfile in the configuration file at /etc/ssh/sshd_config.  for the rest, i can't see any key file in the directory listing
eos should support xdg-mime command which you can use to change the default file manager
actually, strictly speaking, x11 is the communication protocol between an x client application and an x server
simple with awk, if the join field is unique:  awk -f"|" 'a[$1]++' file1 file2    -f"|" sets pipe as delimiter a[$1]++ is a condition
there is an option for that in the recent cinnamon versions
yes
 the uuencode is :  uuencode  name &lt; sourcefile maybe just need a final empty line : add ; echo -e "\n\n" ; before the closing parenthesis, and try again?-    so in your case:  ( cat bodytext.txt; uuencode backup.tar &lt; backup.tar ; echo -e "\n\n" ; ) | mail -s "backup" myemail@myserver.com   another way is using mutt which handles attachments better, and knows about mime types, etc:  mutt -s "the subject" -a backup.tar -- myemail@myserver.com &lt; bodytext.txt  
as i'm sure you know, ubuntu is based upon debian (ubuntu releases are rebased against debian testing periodically) and a there is a lot of similarity between the two
pkill -f &lt;application_na&gt;   will kill all the processes that contain the pattern &lt;application_na&gt; in their names.  man pkill 
it's quite simple.  you have to add the following option on the vsftpd.conf file  chroot_local_user=yes   the documentation inside the configuration file is self-explanatory:  # you may specify an explicit list of local users to chroot() to their home # directory
if the two disks are /dev/sda and /dev/sdb, run both grub-install /dev/sda and grub-install /dev/sdb
when you clone a linux installation, you need to change a few things that should be unique (see some tips in moving linux install to a new computer)
it looks like something is wrong with the installation of wcd, and you are executing the wcd binary directly
tcsh is organized differently from bash (no surprise)
try this:  pgrep name | xargs kill   if you use pgrep name | kill, the ouput of pgrep name is feed to stdin of kill
i put your sample data into a file called farmer.txt, and ran the following perl script:  #! /usr/bin/perl -a -n  if (/banana/) {   @produce=grep(/banana/,split(/,/,$f[2])) ;   print join("\t",@f[0 .
your shell, or whatever process was in the foreground, was already reading the terminal to which is was attached, which was /dev/ttys011
yes, you can
the amount of paging space is fixed (but configurable) on any given system, so having smaller pages means that you have more pages available
right click on an existing application shortcut in the panel and you will get a context menu with "application launch bar settings" at the top, this is what you want. if you do not have any existing shortcuts preset..
sudo_askpass is supposed to be a binary that prompts the user for a password
those are emacs keybindings, and you can enable them for gtk applications.  echo 'gtk-key-theme-name = "emacs"' &gt;&gt;~/.gtkrc-2.0 gconftool -t string --set /desktop/gnome/interface/gtk_key_theme emacs  
xattr -d requires you to specify which attribute you want to remove
it looks like i needed to add the folderfilter setting under [repository local] and [repository remote] for it to work
since you don't want a trailing +, you could do:  fold -w3 | paste -sd+ -   that is, fold the lines on 3 character width, and paste those 3 character lines with themselves with + as the delimiter which in effect is like changing every newline character but the last one into a +
if pick outputs of filename per line, you can set ifs to contain a newline only
to get ls to display the folder name instead of listing its contents, use its -d argument such as:  ls -ld ~  
you can try this in .htaccess or apache config.       addtype text/plain .log  
if the flash has a filesystem on it and you just want to open a file but bypass the cache for io to that file, then open it with the o_direct flag
a find expression is basically a list of predicates (boolean conditions)
can you try this as your service file.  [unit] after=wpa_supplicant.service dbus.service networkmanager.service requires=wpa_supplicant.service dbus.service networkmanager.service  [service] type=oneshot remainafterexit=true execstart=/bin/true execstop=myshutdownexecutable  [install] wantedby=multi-user.target   i managed to get my script running with this - the wireless connection was being torn down by wpa supplicant and dbus even thought networkmanager was still running. 
on glibc, the default timezone is kept in /etc/localtime
if you need a .deb customized on the fly  mkdir /tmp/bb cd /tmp/bb apt-get source busybox sudo apt-get build-dep busybox cd busybox-1.20.0/ fakeroot debian/rules build make -c debian/build/deb/ menuconfig # enable passwd fakeroot debian/rules binary   but probably the best would be to add a custom package inside debian/control and the relative config under debian/config/pkg/  (i'm not using debian 7 but guess it is similar)  edit  you can use fakeroot debian/rules debian/build/deb/.built and fakeroot debian/rules binary-arch_busybox to build the deb target only 
how about using the su command?  $ whoami user1 $ su - user2 password: $ whoami user2 $ exit logout   if you want to log in as root, there's no need to specify username:  $ whoami user1 $ su - password: $ whoami root $ exit logout   generally, you can use sudo to launch a new shell as the user you want; the -u flag lets you specify the username you want:  $ whoami user1 $ sudo -u user2 zsh $ whoami user2   there are more circuitous ways if you don't have sudo access, like ssh username@localhost, but sudo is probably simplest, provided that it's installed and you have permission to use it. 
use gparted from a live cd/usb to move your partitions around (you can't do this from the mounted linux itself)
one method is to use printf:  $ awk '$1 ~/top/ {printf "%s ",$5;} $1 ~/mem/ {printf "%s ",$4;} $1 ~/swap/  {print $4;}' top-output 3:36, 9594508k 0k   printf offers flexible formatting and it does not, unless you explicitly tell it to, print a newline character
use arrays.  if you don't need to handle the possibility of newlines in your filenames, then you could get away with  mapfile -t abc_files &lt; &lt;(find -l some/dir -name \*.abc | sort) mapfile -t xyz_files &lt; &lt;(find -l other/dir -name \*.xyz | sort)   then  ./program --abc-files "${abc_files[@]}" --xyz-files "${xyz_files[@]}"   if you do need to handle newlines within filenames, and have bash >= 4.4, you can use -print0 and -d '' to null-terminate the names during array construction:  mapfile -td '' abc_files &lt; &lt;(find -l some/dir -name \*.abc -print0 | sort -z)   (and similarly for the xyz_files)
the first thing you want to do is to create a udev rule which corresponds to the nic you're plugging in and out. plug in nic  udevinfo -a -p /sys/class/net/yourdeviceskernelname   make the udev rule match the output of above:  sudo nano /etc/udev/rules.d/10-usb-nickernel=="yourdev*", attr{address}=="11:22:33:44:55:66",  name="usb"  then create a systemd-networkd unit to match the nic.  sudo nano /etc/systemd/network/10-usb.network [match]name=yourdeviceskernelname [network]dhcp=v4 #for example see more on networkd  here. 
a thread titled a renewed plea for inclusion of zone.tab offers some explanation of what zone.tab is used for.  its main use seems to be to show a map of cities and their locations, to allow a user to pick their timezone by clicking on a city near them.  with that in mind, it doesn't need to know all of the aliases for each city, knowing one preferred way of referring to it is sufficient
since posting this question i have studied the entire guide that i linked to above, as well as the majority of the cgroups.txt documentation and cpusets.txt
yes, yum can do that, although you might need the valuable yum-utils package installed
confirmation is a weak way to achieve the result you want: not deleting files you didn't want to delete
sounds like all you want to do is extract your .deb archive, add your .desktop file and the rebuild the package
i think i find the answer
the following code will do what you want.  while read -r server _; do ssh -n -o stricthostkeychecking=no root@"$server" "grep -e 'version|project' /etc/component10/version" &gt;&gt; /tmp/component_ver.txt; done &lt; serverfile  
i wrapped the command kill -9 $(ps -ef | awk "/service_name/{print \$2}") with a '`' character and ran it using my utility and it worked like a charm
   can someone confirm (or deny) my assumption?   yes, both are same.  unix mbox format is used by asyncos when messages are archived (in anti-spam and anti-virus configuration) and logged (in the message filter log() action).  mbox is traditional unix mailbox format
your .profile is only read when you log in interactively
is possible to upgrade using option "match what target has" using the gui,i don't know if is possible even with cli.     software distributor administration guide: hp-ux 11i v1, 11i v2, and 11i v3 > chapter 2 installing software   "match what target has examines your current installed product database to match your existing filesets with new filesets (those with the same names) that you are going to install
this has not at all to do with bash, but it depends on the completions programmed in the package bash-completion.  from some comments in the file /etc/bash_completion.d/mount:  # mount(8) completion
the bash construct $(command) will expand into the output of command
you can check the configuration file in /etc/networkmanager/system-connections directly
yes, you may delete files from that folder manually
cygwin : unix :: peaches : trombone (that was on my gre ;)   given how dramatic cygwin changes can be, i'd be really wary of having it done without my explicit consent
add it to /etc/fstab with the appropriate options:  /dev/md0 /mnt/raiddrives ext4 defaults 0 2   the third value is the filesystem type (i've specified ext4 here but you need to use the correct one for your situation), the fourth is the options, the fifth is the dump level (leave it at 0) and the sixth is the filesystem check pass (0 to disable fsck, 1 for the root filesystem, 2 for the others).  dump is a filesystem backup tool, but you're extremely unlikely to use it
tar cvzf - file1 file2 dir1 dir2 | ssh user@remotesystem "cat &gt; /big/partition/rescue.tgz"   would be my preference
the short answer is, you're better off writing a temporary file and opening that
you can use chfs like :  chfs -a size=*newsize* /filesystem   for example  chfs -a size=2g /tmp   that will set /tmp to 2gb of space  for more info take a look at chfs' man page 
you can't, given the user creating the directory has sufficient permission to write on the parent directory.  you can instead leverage the inotify family of system calls provided by the linux kernel, to watch for the creation (and optionally mv-ing) of directory shop in the given directory, if created (or optionally mv-ed), rm the directory.  the userspace program you need in this case is inotifywait (comes with inotify-tools, install it first if needed).    assuming the directory shop would be residing in /foo/bar directory, let's set a monitoring for /foo/bar/shop creation, and rm instantly if created:  inotifywait -qme create /foo/bar | \              awk '/,isdir shop$/ { system("rm -r -- /foo/bar/shop") }'    inotifywait -qme create /foo/bar watches /foo/bar directory for any file/directory that might be created i.e
in the openssl manual (openssl man page), search for rsa, and you'll see that the command for rsa encryption is rsautl
i'm not aware of a way to change luks keys without cryptsetup
so basically you want server1 to act as your jumpbox, so you need one stanza for server1:  host server1 hostname server1.net user server1-user-name identityfile /path/to/.ssh/server-1-ssh-key   then you need a stanza for server 2 that jumps through this one:  host server2 hostname 10.0.0.10 user server2-user-name forwardagent yes proxycommand ssh server1 nc %h %p 2&gt; /dev/null identityfile /home/server1-user-name/.ssh/server2-ssh-key  
this will give you better results:  (cd /storage/sqlbackup; du -sh * | sort -h)   (note the -h parameter to sort). 
another perl solution, use time::piece module like @choroba's answer:  $ perl -mtime::piece -pe ' begin {$today = localtime-&gt;ymd." ".localtime-&gt;hms}     s!($1)!&lt;font style=background-color:red&gt;$1&lt;/font&gt;!g     if /&lt;td&gt;(.+?)&lt;\/td&gt;/g and $1 lt $today; ' in.txt asfsaf&lt;td&gt;&lt;font style=background-color:red&gt;&lt;/font&gt; kjycasfd fkzf&lt;td&gt;2014-05-09 lkjafsa sdfg&lt;td&gt;2014-05-13 asdf sfjlaslfsaljf &lt;td&gt;&lt;font style=background-color:red&gt;&lt;/font&gt; dijizlof   update  if you have several past date in one line, try:  $ perl -mtime::piece -pe '     begin {$today = localtime-&gt;ymd." ".localtime-&gt;hms}         @days = $_ =~ /&lt;td&gt;(.+?)&lt;\/td&gt;/g;         for $d (@days) {           $_ =~ s!$d!&lt;font style=background-color:red&gt;$d&lt;/font&gt;! if $d lt $today;       }' in.txt &lt;tr&gt;&lt;td&gt;&lt;font style=background-color:red&gt;2014-04-24 00:01&lt;/font&gt;&lt;/td&gt;&lt;td&gt;2014-06-24 00:01&lt;/td&gt;&lt;td&gt;&lt;font style=background-color:red&gt;2014-05-13 00:00&lt;/font&gt;&lt;/td&gt;&lt;/tr&gt;   explanation   we save all date in a line in @days array. for each date, we check if it less than today then replace it.  
   insecure file owner 1000, 0 (root) suggested.   user 1000 has read and write permission over the swap file
you can use apt-cache search
simply switch your repos to testing and do a full upgrade:  # cp /etc/apt/sources.list{,.bak} # sed -i -e 's/ \(stable\|wheezy\)/ testing/ig' /etc/apt/sources.list # apt-get update # apt-get --download-only dist-upgrade # apt-get dist-upgrade   make sure you stay plugged in for the duration of the last command, though
tinymce is a javascript library for html so you need to create html and put it onto web browser.  the javascripts are located in /usr/share/tinymce/www, you can create link in document root of your web server. 
with gnu sed you could do something like:  sed '/^\\input{\(.*\)}$/{s//\1/;s/'\''/&amp;\\&amp;&amp;/g;s/.*/cat&lt;'"'&amp;'/e}"   (that is build a cat&lt;'the-file' command (escaping the quotes in the file name if needed) and use the e flag of the s command (which is gnu specific) to evaluate that command). 
the first column mean the signal that is sent
from the design and implementation of the freebsd operating system chapter 6.12 page replacement:     the kernel divides the main memory into five lists:         wired: wired pages are locked in memory and cannot be paged out.   typically these pages are being used by the kernel or the   physical-memory pager, or they have been locked down with mlock
debian uses tasksel for installing software for a specific system
if you want the duration in seconds, at the top use  start=$seconds   and at the end  duration=$(( seconds - start ))  
the most appropriate command would appear to be zdump.  $ zdump /etc/localtime  /etc/localtime  wed aug  7 23:52:25 2013 edt  $ zdump /usr/share/zoneinfo/* | tail -10 /usr/share/zoneinfo/singapore    thu aug  8 11:52:48 2013 sgt /usr/share/zoneinfo/turkey       thu aug  8 06:52:48 2013 eest /usr/share/zoneinfo/uct          thu aug  8 03:52:48 2013 uct /usr/share/zoneinfo/universal    thu aug  8 03:52:48 2013 utc /usr/share/zoneinfo/us           thu aug  8 03:52:48 2013 /usr/share/zoneinfo/utc          thu aug  8 03:52:48 2013 utc /usr/share/zoneinfo/wet          thu aug  8 04:52:48 2013 west /usr/share/zoneinfo/w-su         thu aug  8 07:52:48 2013 msk /usr/share/zoneinfo/zone.tab     thu aug  8 03:52:48 2013 /usr/share/zoneinfo/zulu         thu aug  8 03:52:48 2013 utc   you can also interrogate these files using the file command:  $ file /etc/localtime  /etc/localtime: timezone data, version 2, 4 gmt time flags, 4 std time flags, no leap seconds, 235 transition times, 4 abbreviation chars  $ file /usr/share/zoneinfo/singapore /usr/share/zoneinfo/singapore: timezone data, version 2, 8 gmt time flags, 8 std time flags, no leap seconds, 8 transition times, 8 abbreviation chars  
this trash file is unrelated to postfix
you can try dd, like dd if=/path/to/slax.iso of=/dev/sdb bs=1m 
i was surprised to discover that my mac book air does have a /dev/sdt character special device
it appears that the device i'm using doesn't like the two wifi dongles connected in the order that i had them connected
try using find's -print0 or -printf option in combination with xargs like this:  find /music -iname "*\.mp3" -print0 | xargs -0 mpg321   how this works is explained by find's manual page:     -print0      true; print the full file name on the standard output, followed by a null character (instead of the newline character that -print uses)
if you have gnu grep, you can use perl regular expressions, which have a negation construct.  grep -a1 -p '^(?!.*ignore me).*needle'   if you don't have gnu grep, you can emulate its before/after context options in awk.  awk -v after=3 -v before=2 ' /needle/ &amp;&amp; !/ignore me/ {     for (i in h) {         print h[i];         delete h[i];     }     until = nr + after; } {     if (nr &lt;= until) print $0; else h[nr] = $0;     delete h[nr-before]; } end {exit !until} '  
find does not sort its output
i don't know of any portable way to do this
there are 2 approaches that i can think of off the top of my head
probably your wildcard does not work because:   there were no matches for the wildcard from the location you gave, or there was more than one match.   the usual approach (in a shell) to moving frequently among subdirectories is to use the cdpath feature, as well as pushd and popd
it seems to be a purely arbitrary choice
rpm and deb packages contain archives of the files to install (cpio archives in the case of rpm, tar in the case of deb)
on the general tab of preferences, there is an option labelled "apply changes in a terminal window".  while this is likely a bit more detail than you'd like, i haven't found a way to automatically enable the 'mid-level' detail that the 'details' selectors show.  but you can see what's going on, at least
in the ? view, you can cursor to the folder you want to pick and press space.  if you're in a place where you can just type the name (e.g
do i understand correctly?  you want to establish a vpn connection as soon as you log in?  there's a pam-module that sounds promising:     pam-openvpn is a linux pam-module which works together with openvpn.   with this pam-module it is possible to establish vpn connections when   a user logs into a system and tear down the connection when the user   logs off
this depends on your locale settings
first correct the syntax of your command, place the semicolons correctly
you can strip out all of the bits you don't want by piping the output through sed:  wc -l ~location/folder/folder/*.log &gt; ~/log.info cut -d "/" -f9 ~/log.info | sort | sed 's_/.*/__;s_\.log$__'  
x takes up a new slot in the kernel data structures that are used for the virtual consoles, exactly for the reason to allow ctrl alt number to switch between the consoles and the x session.  this virtual console is not the console you started x from, but a different one
a process is any running program with its own address space.  a job is a concept used by the shell - any program you interactively start that doesn't detach (ie, not a daemon) is a job
"are there other commands which prints only the shell variables, without the functions?"  in man bash, in section shell builtin commands (in the set section) it says: "in posix mode,  only  shell variables  are listed."  (set -o posix; set)  
you can loop over the array's keys and extract the corresponding values:  awk '{my_dict[$1] = $2} end { for (key in my_dict) { print my_dict[key] } }' zen   to get output similar to that you'd get with a python dictionary, you can print the key as well:  awk '{my_dict[$1] = $2} end { for (key in my_dict) { print key ": " my_dict[key] } }' zen   this works regardless of the key type. 
the short answer is that it doesn't.  mv is defined to:     perform actions equivalent to the rename() function   rename() doesn't copy content, it simply renames it on disk
yes, you can automate the authentication with your raspberry pi using ssh.  as prerequisites the following is required:   you have enabled ssh on the pi
few things:     -add some kind of the timestamp to the job.      -don't redirect anything to the /dev/null .      -set a $mailto notification to send output to the required team   we are using nagios for this and also cronwatch 
statusline can be modified to include variable names.  for example, i'm using the statline plugin, so my statuslineis:  statusline=[%{statlinebufcount()}:%n] %&lt;%1*[%f]%*%2*%h%w%m%r%* %y[%{&amp;ff}%{g:statline_encoding_separator}%{strlen(&amp;fenc)?&amp;fenc:g:statline_no_encoding_string}] %5*%{&amp;paste?(g:statline_show_paste_string):''}%*%5*%{&amp;list?(g:statline_show_list_string):''}%*%=%-14( l%l/%l:c%c%v %)%p %4*%{exists('g:sfe_availablescms')?sfestatus():''}%* %3*%{exists('g:loaded_syntastic_plugin')?syntasticstatuslineflag():''}%*%3*%{statlinetabwarning()}%*%3*%{statlinetrailingspacewarning()}%*   all of which is concatenated by the plugin itself.  in your case, you can use:  let hostname=system('hostname -s') set statusline+=%f\ %p\ %c:%l\ %{hostname}  
you can use the bash(1) built-in compgen   compgen -c will list all the commands you could run. compgen -a will list all the aliases you could run. compgen -b will list all the built-ins you could run. compgen -k will list all the keywords you could run. compgen -a function will list all the functions you could run. compgen -a function -abck will list all the above in one go.   the above command lists all the available commands for an user based on his privileges set
it's hard to ask a question about linux distros in general, because some might..
mknod was originally used to create the character and block devices that populate /dev/
type finger username ..
the keycodes are in [src]/drivers/tty/vt/defkeymap.map:  # default kernel keymap
 there are systems not shipping bash by default (e.g
that's how sudo works
a good way to demonstrate linux features and for others to play around with, is to boot off a live cd for your linux distribution
summary:  the shell performs parameter substitution on strings in double quotes but not on strings in single quotes
no, it is not safe, ubuntu repositories are not compatible with debian
this won't (can't) work - the sub-shells you're using to determine the latest file only get executed once
first thing to try is yum clean packages
use grep for a much simpler solution
depends on the situation really
you could use lsof:     /usr/sbin/lsof -p $$ -a -d 1   the above would list just file descriptor 1 for just the current process:  command  pid user   fd   type device size/off node name bash    5054 matt    1u   chr  136,1      0t0    4 /dev/pts/1  
generally speaking, you as a normal user of the system do not work directly with libtool at all
my content hoster helped me and found a solution, which might not work at 100% but 90% (100% is the total reload of the server).  first, since i had recreated a customized /vhost/ directory with my backed up contents in there (it would not be your case), i deleted /vhosts/.  second, i ran this from ssh: usr/local/psa/bootstrapper/pp11.0.9-bootstrapper/bootstrapper.sh repair  my hoster said:     that utility should at least make apache function normally again, but   there will be some oddities that can't be avoided
in most cases, [ is a shell builtin and is equivalent to test
here is a quick and dirty shell "one-liner" with example output:  $ join -j2 &lt;(cd sub1; wc -l *) &lt;(cd sub2; wc -l *) | awk '$2!=$3' file3.csv 5 1 file4.csv 1 5 total 11 17   the total line is an artifact from the output of wc
the question is based on a misconception about the generality of proc filesystems
you need to install the broadcom-sta drivers:  apt-get install broadcom-sta-dkms linux-headers-$(uname -r)   (this will install the driver's source code, your kernel's support headers, and build and install the kernel module).  you appear to be running an older kernel, so the required headers and support packages are not longer available from the repositories
[ and test are synonyms (except [ requires ]), so you don't want to use [ test:  [ -x /bin/cat ] &amp;&amp; echo 'cat is executable' test -x /bin/cat &amp;&amp; echo 'cat is executable'   test returns a zero exit status if the condition is true, otherwise nonzero
su -c "command and args" username  
it seems like an undocumented feature of disown
upgrading like that is not really supported
#!/bin/bash  function upsearch () {     test / == "$pwd" &amp;&amp; return || test -e "$1" &amp;&amp; echo "found: " "$pwd" &amp;&amp; return || cd .
for the first part of the question, i've looked and couldn't find a better way to detach a usb driver than what you're already doing with libusb.  as for the second part of the question, udev can react to driver loading, but not force a specific driver to be assigned to a device.  every driver in the linux kernel is responsible for one or more devices
you can group and use logical operators with find, but you have to escape the parens so you could look for all files and links like  find \( -type f -o -type l \) &lt;other filters&gt;   so if you wanted all files and links whose name starts with t you could do  find \( -type f -o -type l \) -name 't*'   you only need the parens if you want to group things and combine with other opeators, so if you have no other search criteria you can omit them 
you must search for &lt;td&gt;n
rsync is probably the best tool for this
to run your own dns, you would have to:   understand how dns works
if the php script creates the file in the current directory, change to the desired output directory:  */45 * * * * cd /path/where/file/to/save &amp;&amp; /path/to/php /path/to/file.php   if the php script creates the file in your home directory, you might be able to pretend your home directory is elsewhere — but if it also tries to read other files from your home directory, then it will also read these files from elsewhere.  */45 * * * * home=/path/where/file/to/save /path/to/php /path/to/file.php  
when you log in, the file ~/.profile is read by the login shell (ksh for you)
if csv.gz.md5 was generated using md5sum csv.gz &gt; csv.gz.md5, then you can check using md5sum -c cvs.gz.md5.  $ echo hello world &gt; something.abc $ md5sum something.abc &gt; something.abc.md5 $ md5sum -c something.abc.md5 &amp;&amp; echo yay || echo nay something.abc: ok yay $ echo garbage &gt;&gt; something.abc $ md5sum -c something.abc.md5 &amp;&amp; echo yay || echo nay something.abc: failed md5sum: warning: 1 computed checksum did not match nay  
as for what's wrong with your script, you are replacing a or a with ab and d or d with dk, so any pre-existing b or k would not be affected; sed is not looking for it
system calls per se are a concept
one approach would be to make use of ls to give us a list of the files, but we want this list to be guaranteed to show only 1 file or directory per line
the shell searches the execute path ($path) for programs when you give it a command to run
i don't know the direct way but i do it like below.  grep -rl &lt;pattern&gt; &lt;folder&gt;  | wc -l   use the manual page to identify the purpose if each option.  i hope it helps. 
   screen -dms workspace; screen -s workspace -x stuff $'ps aux > output-x\n'   i first create a detached session with the -d switch, i called my session workspace
the problem is in using my aliased cat which adds the special characters.  instead of  cat variables/user-extensions.js | sed -e 's/css/xxx/' &gt; x   use  sed 's/css/xxx/' variables/user-extensions.js &gt; x  
you don't have an ssh daemon running
in awk, there are two main separators: the field separator, and the record separator
wrapping the url in single quotation marks should do the trick
yes, it works, i have a similar setup
patterns are matched by the shell, not by the command, so what you tried had no chance to work: first the shell expands * to all files (not just the extensionless ones: you never said anything about the files not having a . in their name), and *.md to all files whose name in .md; then the shell passes the concatenation of the two lists to the mv command.  in zsh  in zsh, run the following command once (put them in your ~/.zshrc for the future):  autoload -u zmv # you don't need the following two now, but put them also in your .zshrc alias zcp='zmv -c' alias zln='zmv -l'   you can then run zmv to rename files according to a pattern
you just need to remove manually this tcl-modules package, but pkg_delete is asking for a complete package name (with version).  to remove your old tcl-modules package, first get its complete package name:  $ pkg_info -ai |grep tcl-modules tcl-modules-8.6.x  tcl common modules   then remove it:  $ pkg_delete tcl-modules-8.6.x  
i would cheat and put a couple of netcat's and a tee in the pipeline:  nc -k -l -p $localport -c "tee file.out | nc 127.0.0.1 $portforwardport"   where $localport is an arbitrary port to point your java process at and $portforwardport is your ssh port forward port number
i see two options
to repeat the whole file n times with a numerical suffix from 1 to n added at each repetition:  n=999 i=1 while [ "$i" -le "$n" ]; do   sed "s/\$/$i/" &lt;inputfile   i=$((i+1)) done &gt;outputfile   to repeat each line n times with a numerical suffix from 1 to n:  awk -v n=999 '{for (i=1; i&lt;=n; i++) print $0 i}' &lt;inputfile &gt;outputfile  
kde simply uses the x server's keyboard mapping facility (xkb)
you can try:  yum -y install net-snmp net-snmp-utils net-snmp-libs  
the solaris echo   $ echo -e foo -e foo   does not work like most some other echo commands:  $ bash $ echo -e foo foo  $ which echo /usr/bin/echo $ type -t echo builtin   the bash builtin version works as expected, the ksh builtin keeps the solaris behaviour (echo behaviour is usually system dependent in ksh when options are used). a plain echo should work in ksh, no -e:  $ ksh $ echo -e "foo\nbar" -e foo bar $ echo "foo\nbar" foo bar   so you have a solaris problem, rather than a sendmail problem :-)  you could try printf as a more portable way of doing this. 
after chattr +i, you can't edit the directory
i don't think you can with tr because the replacement set is truncated to the length of the match set, and changing color requires some control characters.  not impossible with sed tho:  tail -f file.log  | sed s/\001/\\x1b[32m\|\\x1b[0m/g   1b is hex for octal 33, oft seen in things like color prompts because the shell likes octal (but to get "unprintable" control characters through sed, use hex)
there's a lot going on in that fragment of code
in the first case you're asking cp to copy /tmp/a and its contents to /tmp/b; so first a is copied, to /tmp/b/a, then a's contents are copied into /tmp/b/a.  in the second case you're asking cp to copy . and its contents to /tmp/b; using the same thought process as above, we can think of this as copying . first, to /tmp/b/. (i.e. /tmp/b), then copying .'s contents into /tmp/b/..  there is no short reference for the current directory which can work in all cases, since the current directory may have different names (using symlinks)
taking the r case as an example, with  command="remote show origin"   followed by  git -c "$d" "$command"   git sees three arguments, -c, the value of d, and remote show origin, instead of the five it expects (remote, show and origin separately instead of remote show origin).  with bash, simply removing the quotes will fix this:  git -c "$d" $command   with zsh, you need to split the string using  git -c "$d" $=command   (thanks ilkkachu and gilles!). 
since the documentation is fairly explicit, i would simply file a bug report.  comparing with bwk (one-true-awk or original-awk), it behaves as the documentation implies
well if there's no packaged binary for your distro you can try building the package from source
summarizing from this ask ubuntu answer, it is a bad idea to run as root because:   you are much more prone to mistakes or software bugs
there's an example in the abiword man page:  abiword --to=rtf --to-name=fd://1 something.doc  
to remove a repository, you have to do 2 things:   remove it from sources.list.  if it was added by add-apt-repository then you will find it in its own file in /etc/apt/sources.list.d, not in the main sources.list.  sudo rm /etc/apt/sources.list.d/nemh-systemback-precise.list  optional: stop trusting the key  use apt-key list to list trusted keys
apt-get install &lt;package_name&gt;/testing apt-get install -t test &lt;package_name&gt;      the first will not attempt to upgrade any packages on your system, so if specific dependencies are not met, the install will fail
it exists for broadly the same reasons rm will allow you to delete the filesystem root, or dd will allow you to overwrite the physical hard drive:  linux and unix have a long history of giving you all the ammo you need when you really insist on shooting yourself in the foot.  less flippantly, when something has gone badly wrong during a package install, whether due to a badly built package or an outage at the worst possible moment, it's possible to wind up with your package manager's dependency database in gridlock -- ie, it can't resolve the problem because attempting any of the solutions would violate the dependencies of the other packages involved
from a link given on gmane site:      it would be nice to be able to click "load profile", select "purist" (loading the fonts from the kde global   settings), then have an option to update the current custom settings to match that profile, and then   tweak those settings for kmail by checking the "use custom fonts" check box
as this post from arch linux forums suggested, the problem was with virtualbox rather than any other component
i would suggest using user tags, which is a characteristic of aptitude (apt binary doesn't have this) would help with that
you can use a while construct to loop over the patterns from file2 and then use -m 1 with grep to stop after first match on file1:  while ifs= read -r i; do grep -fm1 "$i" file1; done &lt;file2    -f treats the pattern literally -m 1 makes grep to exit after first match   shell loops are usually not efficient, but given the pattern list is small it is usable in this case.  faster alternative, xargs:  xargs -a file2 -n1 -p2 -i'{}' grep -fm1 {} file1   use more parallel processes (-p) for more patterns.  example:  % while ifs= read -r i; do grep -fm1 "$i" file1; done &lt;file2 my colour is red my colour is blue  % xargs -a file2 -n1 -p2 -i'{}' grep -fm1 {} file1 my colour is blue my colour is red  
the following works in bash 4.2:  list=( /&lt;root_path&gt;/&lt;process_two_path&gt;/logs/* ) echo "${list[-1]}"   if your bash is an older version:  list=( /&lt;root_path&gt;/&lt;process_two_path&gt;/logs/* ) echo "${list[${#list[@]}-1]}"  
i don't think it is possible to obtain such information after the process has already finished.  if you know beforehand that you will need that information, you can run the command as  time &lt;command&gt;   e.g.  ~&gt; time sleep 1  real        0m1.003s user        0m0.002s sys         0m0.001s  
webmin is providing a web based file manager.    however, it is using the java plugin so has some trouble with recent browsers and jvms
the pypdf library in python makes it easy to rearrange pages in a pdf file
before the shell starts processing any data, it needs to make sure all the input and output is squared away
the md5deep tool was developed for precisely this purpose
vivian, you can easily do this by using virtualbox or any kind of virtualization software
i think this is limitation or bug in current rpm/rpmbuild versions
for((i=2;i&lt;=$#;i++)); do     wc "${!i}" done  
gzip -l foo.gz | awk 'nr==2 {print $2}' prints the size of the uncompressed data.  if lc_all=c gzip -l foo.gz | awk 'nr==2 {exit($2!=0)}'; then   echo foo is empty else   echo foo is not empty fi   alternatively you can start uncompressing the data.  if [ -n "$(gunzip &lt;foo.gz | head -c 1 | tr '\0\n' __)" ]; then     echo "foo is not empty" else     echo "foo is empty" fi   (if your system doesn't have head -c to extract the first byte, use head -n 1 to extract the first line instead.) 
xargs allows easy parallel processing
try: emerge --fetchonly x11-drivers/xf86-video-nouveau the file should be in /usr/portage/distfiles/  ref.: gentoo handbook 
easy
if i understand your question correctly, you need to source or . your files
chsh is setuid, so it can run in a context that means users can perform actions with root's privilege
the kernel sees the physical memory and provides a view to the processes
generally, one uses the shutdown command
the /tmp and /var directories are the ones that many system programs write to a lot, and depend on being writeable
you can use getent to display the group's information
if your switch is a managed switch, then you can use lldpctl from the lldpd package (on debian/ubuntu) to know its mac address.  the lldp package is described as follows:     lldpd is a 802.1ab implementation (lldp) to help you locate neighbors of all your equipments.   the man page for lldpctl shows how to use it:  name      lldpctl — control lldp daemon  synopsis      lldpctl [-d] [-l location] [-p policy] [-o poe] [-o poe] [interface ...]  description      the lldpctl program controls lldpd(8) daemon.       when no specific option is given, lldpctl displays the list of       discovered neighbors along with some of their advertised capabilities.      if some interfaces are given, only those interfaces will be displayed. ...   references   lldp website additional packages for other distros  
to convert october to 10, for example (i have swedish locale)     date -jf %b oktober '+%m'  
it's possible to do with fuse, but would probably be cleaner with custom tools.  solution  with apt-get-able tools the following kludge is possible:  mkdir mnt xmount --in dd --out vdi disk.img mnt  mkdir mnt2 vdfuse -f mnt/disk.vdi   mkdir mnt3 fuseext2 -o "rw" mnt2/partition1 mnt3   explanation  the basic idea is that fuse can be used to separate a full disk image in place into files that point to it's partitions
seems to work! thanks @cas (see comments on question)
use pam_limits(8) module and add following two lines to /etc/security/limits.conf:  root hard nofile 8192 root soft nofile 8192   this will increase rlimit_nofile resource limit (both soft and hard) for root to 8192 upon next login. 
that command looks ok
you realise that you're making at least two whois requests (so sending many more packets and loading one or more whois sever somewhere) for every packet that goes through your network interface?  here, i'd use tshark assuming the ip address geolocation database is installed and properly configured:  tshark -lq -t fields -e ip.geoip.src_country -e ip.geoip.dst_country |   gawk -f '\t' -v clear="$(tput clear)" '   begin{procinfo["sorted_in"] = "@ind_str_asc"}   {     count[$1 ? $1 : "unknown"]++     count[$2 ? $2 : "unknown"]++     printf "%s", clear     for (c in count)       printf "%5d %s\n", count[c], c   }'  
can you try this setup:  iptables -t nat -a input -p tcp --dport 5000 -j dnat --to-destination 192.168.2.3:5000 iptables -t nat -a srcnat -j masquerade   you can see more examples here. it should work, but why are you trying implement at firewall level anyway?  if you have a webserver at your host 192.168.2.14 why don't you just add redirect to the right address at your .htaccess, for example? it will be the easiest and robust way to do, i can highly recommend it instead. 
the z option is for .tar.gz (gzipped) files. bzip2'd files (the .bz2 suffix) use a different tar option: j.  try  tar -xjvf teamspeak3-server_linux_amd64-3.0.12.2.tar.bz2   or (auto-detection has been around a couple of years)  tar -xvf teamspeak3-server_linux_amd64-3.0.12.2.tar.bz2   further reading:   compression support  
i presume that by “non-english letters” you mean letters other than the 26 unadorned letters of the latin alphabet
you're more than likely running into a snag on the permissions
you should be able to do this using --new-file switch
the problem was that i forgot to include ",pty" as an option for exec:"/usr/sbin/pppd ..." so pppd was silently crashing. 
this is actually a known and currently open bug
doh! i just realized after asking my problem is not the @ it's the - this works  grep -r thanks -- *     
you are looking for the desktop-file-validate tool provided by the desktop-files-utils package in your distribution
rmdir ./--bindir\=/    or   rm -fr ./--bindir\=/  
&lt;&lt; always includes a trailing newline (except for an empty here document).  you'd need to do either:  printf %s 'echo "bla bla" ifcon' &gt;&gt; file   or use a command that removes the trailing newline character instead of cat:  awk '{printf "%s", l $0; l=rt}' &lt;&lt; eof &gt;&gt; file echo "blah bla" ifcon eof   (or perl -pe'chomp if eof')  or, where here-documents are implemented with temporary files (bash, zsh, pdksh, at&amp;t ksh, bourne, not mksh, dash nor yash), on gnu/linux systems, you could do:  { truncate -s-1 /dev/stdin &amp;&amp; cat; } &lt;&lt; eof &gt;&gt; file echo "blah bla" ifcon eof  
debian likes to split applications into small units, even when 99% of people would want to install everything, for the sake of the 1% with unusual needs
the most common way to verify the integrity of downloaded files is to use md5 checksums
you can follow the instructions in the mongodb official site   first, import the mongodb public gpg key  sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv ea312927  add a source.list configuration file   debian 7 (wheezy)  echo "deb http://repo.mongodb.org/apt/debian wheezy/mongodb-org/3.2 main" | sudo tee /etc/apt/sources.list.d/mongodb-org-3.2.list       debian 8 (jessie)  echo "deb http://repo.mongodb.org/apt/debian jessie/mongodb-org/3.2 main" | sudo tee /etc/apt/sources.list.d/mongodb-org-3.2.list    reload aptitude cache  sudo apt-get update  and finally install the desired version of mongodb  sudo apt-get install -y mongodb-org=3.2.10 mongodb-org-server=3.2.10 mongodb-org-shell=3.2.10 mongodb-org-mongos=3.2.10 mongodb-org-tools=3.2.10   
you need to add noauto option to the /boot line of your etc/fstab, so the system would not try to mount it each time it boots.  you need to mount the /boot partition before system updates as the lack of files in their places according to the package manager database may disrupt the booting
in bash, you can create loops using the builtin command for iterating through a range:  for i in {5..12} do      specmd file${i}.awe done   there are more option in for for other similar situation, i will leave here a link for that.  http://www.cyberciti.biz/faq/bash-for-loop/ 
the line you are looking for is:  if [ x"${feature_menuentry_id}" = xy ]; then   menuentry_id_option="--id" else   menuentry_id_option="" fi   gives you the value of feature_menuentry_id and if it's equal to y then it will add the --id parameter to your menu entries:  menuentry 'ubuntu 14.04 trusty tahr (on sda5)' --class ubuntu --class gnu-linux --class gnu --class os --id 'gnulinux-simple-fe3a2033-d77c-4d8c-ba04-3bb27b267dc2' {   if it's not, then it will leave it as is:  menuentry 'ubuntu 14.04 trusty tahr (on sda5)' --class ubuntu --class gnu-linux --class gnu --class os 'gnulinux-simple-fe3a2033-d77c-4d8c-ba04-3bb27b267dc2' {   the --id parameter for menuentry isn't defined in the manual for menuentry, but one can haphazardly guess is the uuid for the partition the kernel is supposed to boot from. 
the reason why you cannot just mount the partitions is because you have a disc image not images of individual partitions
if the shared library you depend upon is installed in /usr/local/lib rather than /usr/lib (or similar) then i suspect it's not part of any package managed by the dpkg package manager
you'll need to create a kernel package (make tar-pkg)
the script fifo_remote.pl lets you send commands to irssi by using a named pipe  http://www.update.uu.se/~zrajm/programs/irssi-scripts/fifo_remote.pl-0.5 
this one-liner should help:  ls -l /proc/[0-9]*/fd/* |grep /dev/ttys0   replace ttys0 with actual port name  example output:  lrwx------ 1 root dialout 64 sep 12 10:30 /proc/14683/fd/3 -&gt; /dev/ttyusb0   that means the pid 14683 has the /dev/ttyusb0 open as file descriptor 3 
if you're looking for a way to check from a script, you can do either of these:   run tput cols and tput lines, as manatwork suggests check the values of $lines and $columns   but if you want the details, here we go:  for virtual terminals (xterm, et al) there is an ioctl() system call that will tell you what size the window is
i think you refer to killing the gdb buffer rather than closing a frame (which in emacs refers to a window)
as stated in ssh-add's man page, the -l option allows you to view the public keys of the identities ssh-agent currently maintains
the equivalent to your original sequence would be:  for i in {1..20} do    cmd $i || break done   the difference with amit's answer is the script won't exit, i.e
swapping is what happens when the programs you're running allocate more memory than your machine's physical ram
the first one won't work as if $null_terminated is empty or unset, find will complain about that empty extra argument.  find -mindepth 1 -maxdepth 1 ! \( "${args[@]}" \) $null_terminated   would work but only if $null_terminated doesn't contain any wildcard characters or characters from ifs.  doing it:  if [[ -p '/dev/stdin' ]]; then   extra_args=(-print0) else   extra_args=() fi  find -mindepth 1 -maxdepth 1 ! \( "${args[@]}" \) "${extra_args[@]}"   wouldn't have the problem.  bourne/posixly, you could do:  set -- find 
"clearing" and "restoring" the screen is actually a function of the terminal emulator you are using (xterm, gnome-terminal, konsole, screen)
it doesn't get much faster than using the system request (sysrq) functionality and then triggering an immediate reboot.  this is a key combination understood by the kernel.  enable sysrq:  echo 1 &gt; /proc/sys/kernel/sysrq   now, send it into reboot.  echo b &gt; /proc/sysrq-trigger   b - immediately reboot the system, without unmounting or syncing filesystems.  note:  although this is a reboot it will behave like the power has been cut off, which is not recommended.  if you want to sync and umount the filesystems before hand then use:  echo s &gt; /proc/sysrq-trigger echo u &gt; /proc/sysrq-trigger   or if you just want to power off the system then:  echo o &gt; /proc/sysrq-trigger     magic key combinations  there are also key combinations to use that are interpreted by the kernel:  alt+sysrq / print screen+command key  command keys:  r - take control of keyboard back from x. e - send sigterm to all processes, allowing them to terminate gracefully. i - send sigkill to all processes, forcing them to terminate immediately. s - flush data to disk. u - remount all filesystems read-only. b - reboot
ultimately, no matter what you do, rm has to run unlink on every single file that you want to remove (even if you call rm -r on the parent directory)
looks at this soa:   http://stackoverflow.com/a/15213255/438544   it mentions these three links:   http://shallowsky.com/blog/linux/kernel/sysfs-thermal-zone.html http://lwn.net/articles/268958/ http://www.mjmwired.net/kernel/documentation/thermal/sysfs-api.txt   they mention that on newer systems you should have all thermal information under:  /sys/class/thermal/thermal_zonen/temp   where n is a number starting from 0.  on my xubuntu 13.04, i have two:  thermal_zone0  thermal_zone1   note that my cpu is quad-core, from cpuid:  processor name string: amd phenom(tm) ii n950 quad-core processor   so it's not giving me temp per-core
that seems to be the good old form feed character, described in man ascii as:  oct   dec   hex   char ------------------------------------------ 014   12    0c    ff  '\f' (form feed)   (not mentioned there, but ^l's code is the same 12.)  then in bash any of these should work:  grep -v $'^\f' file  grep -v $'^\cl' file  grep -v $'\x0c' file  
you can use pip or easy_install to install python modules.   $ pip install &lt;package-name&gt;   edit:  i tried installing urllib2 package and it told me that the real name of requirement urllib2 is urllib3
a board support package may have pieces spread out in the kernel, but the typical parts are in arch/, and if your board requires drivers that aren't already part of the kernel, there may be some pieces in drivers/.  each arch/ is set up a bit differently
 create a partition using fdisk  fdisk /dev/sdx   commands:   to create the partition: n, p, [enter], [enter] to give a type to the partition: t, 7 (don't select 86 or 87, those are for volume sets) if you want to make it bootable: a to see the changes: p to write the changes: w  create a ntfs partition on /dev/sdx1:  mkfs.ntfs /dev/sdx1  mount it wherever you want  mount /dev/sdx1 /mnt/myntfsdevice   
just install this package:  $ sudo yum install nautilus-open-terminal   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  references   gnome sources nautilus “open in terminal” on fedora/centos/red hat (rhel)  
a hid (“human interface device”) is a device that is intended to allow humans to interact with the computer, such as a keyboard, a mouse, a monitor, a microphone, a loudspeaker, etc.  usb defines a number of standard device classes: types of devices with some common properties
the error message no rule to make target dl_params.inc, needed by angfrc.o. means, that the makefile specifies the file dl_params.inc as a dependency for the building of the file angfrc.o
getent ahosts uses getaddrinfo() and extracts from the addrinfo struct the values of ai_addr, ai_socktype, and ai_canonname and prints them out in order as: ipv4/ipv6 address, socket type, and canonical name (if it has one).  sock_stream (reliable stream-oriented service or stream sockets) sock_dgram (datagram service or datagram sockets) sock_seqpacket (reliable sequenced packet service), or sock_raw (raw protocols atop the network layer).  
the regex pattern you have contains:   non-capturing group, (?:) zero width negative lookahead, (?!)   which are only supported by grep with pcre, perl compatible regular expression (-p)  so you need grep -p, and to capture only the matched portion, -o:  % grep -po '(?:([bcdfghjklmnpqrstvwxzy])(?!.{1,2}\1)){3}' &lt;&lt;&lt;'foobarspfb' rsp  
sed g   is a well known one-liner for that.  performance-wise, the most effective with the standard unix tool chest would probably be:  paste -d '\n' - /dev/null   if you don't want to add an empty line after the last line:  sed '$!g'   to add the empty lines before the input lines:  paste -d '\n' /dev/null -   or:  sed 'i\ /'  
   i would like to extract the only the value of atlas_icv (etiv) (i.e =   1144730 mm^3)   given this file:  : mri_segstats.c,v 1.75.2.9 2013/02/16 00:09:33 greve exp $ cwd  cmdline mri_segstats --subject sub1 --etiv-only  sysname  linux hostname dev-optiplex-780 machine  x86_64 user     dev userobust  0 atlas_icv (etiv) = 1144730 mm^3    (det: 1.701803 )   i can use this sed:  sed -n 's/.*(etiv) = \([0-9].*mm^3\).*/\1/p' atlas 1144730 mm^3   if you want to extract that value from output to stdout, just use a pipe, like so:  cat atlas | sed -n 's/.*(etiv) = \([0-9].*mm^3\).*/\1/p' 1144730 mm^3   in your case i guess it would look like:  mri_segstats --subject sub1 --etiv-only | sed -n 's/.*(etiv) = \([0-9].*mm^3\).*/\1/p'     sed --version sed (gnu sed) 4.2.2  
one thing went wrong: the use of sudo with that command
no, you can't update a compressed archive using tar.  but, if your script is creating the archive (using touch), you can update it and compress it later
bash can match regular expressions with the =~ operator in [[ ..
in linux/unix the user with user id 0 is such a super administrator
this depends on your audio setup
i suggest you read doc/motion.txt
you can using fstab module.  its documentation here.  example:  fstab = fstab()  for entry in fstab.entries:     pprint.pprint(entry)  
the screenshot recipe you are asking about uses the gnome-utils package
gathering from the information about the shell that was used (eshell), it appears that the streaming aspect of this shell is the culprit
the culprit was a symlink at /etc/profile.d/virtualenvwrapper.sh  the solution was to either remove that symlink or, better, uninstall the package:  yum remove python-virtualenvwrapper  
/var/cache is not a free-for-all like /var/tmp
command &amp; echo $! &gt; file fg &gt; /dev/null   if there's no job control, first turn on monitor mode with  set -m   more about monitor mode here: turning off the monitor mode in bash. 
in both bash and zsh (and (t)csh where that feature comes from), provided that history expansion is enabled:  man !!:0   (admittedly, it's not really shorter than man curl). 
as of linux 3.18, the qnx4 filesystem driver only supports reading
using the tool wmctrl you can get all the above information, specifically the -d switch.  example  $ wmctrl -d 0  * dg: 5760x900  vp: 0,0  wa: 0,25 1440x826  workspace 1 1  - dg: 5760x900  vp: 0,0  wa: 0,25 1440x826   2  - dg: 5760x900  vp: 0,0  wa: 0,25 1440x826  n/a 3  - dg: 5760x900  vp: 0,0  wa: 0,25 1440x826  n/a   details  one line is output for each desktop, with the line broken up into space separated columns.   the first column contains an integer desktop number
from the wikipedia article on streams:  excerpt        the linux kernel does not include streams functionality
looks like a regular shell function definition and invocation
darkstat serves my purposes nicely
start the program xev in a terminal
you should consider using sudo with the nopasswd config.  see man 5 sudoers  ex:  host_alias     local=192.168.0.1 user_foobar    local=nopasswd: /etc/init.d/apache2  
for your use-case you only need to install xauth (and its dependencies) on the distant machine, and the applications you want to run along with their dependencies
the line which causes the error is date =$(date), that error is sent to stderr
if the mount is busy it shouldn't be able to unmount*.  an easy way to make a mount busy is to have at least one process with its cwd under the mount point.    *lazy unmounts will still return but it shouldn't actually unmount until the filesystem is no longer busy. 
i never did this, but i will try to help basing on other se site.  basically following this answer you should be good to go by modifying udev files and providing scripts:  /etc/udev/rules.d/00-usb-keyboard.rules  attrs{idvendor}=="09da", attrs{idproduct}=="0260", owner="yourusername" action=="add", run+="/home/yourusername/.bin/usb-keyboard-in_udev" action=="remove", run+="/home/yourusername/.bin/usb-keyboard-out_udev"   /home/yourusername/.bin/usb-keyboard-in_udev  #!/bin/bash /home/yourusername/.bin/usb-keyboard-in &amp;  #!/bin/bash sleep 1 display=":0.0" home=/home/yourusername/ xauthority=$home/.xauthority export display xauthority home your_command_here   /home/yourusername/.bin/usb-keyboard-out_udev  #!/bin/bash /home/yourusername/.bin/usb-keyboard-out &amp;   /home/yourusername/.bin/usb-keyboard-out  #!/bin/bash sleep 1 display=":0.0" home=/home/yourusername/ xauthority=$home/.xauthority export display xauthority home your_command_here   all these scripts should have executable permission (chmod +x).  according to the answer:      usb keyboard vendor and product ids should be changed as per the   output of the command lsusb (for example, my lsusb output have this   for my usb keyboard: bus 001 device 006: id 09da:0260 a4 tech co.,   ltd)   i hope this works for you. 
you can use the first form but you need to put a whitespace after [[
this seems to be from prezto defining a function overriding diff
you'd need to use the ksh extended glob operators (a subset of which is available in bash with shopt -s extglob and with zsh with set -o kshglob) to get the equivalent of regular expressions (though with a different syntax: *(x) for the equivalent of x* here):  shopt -s extglob # for bash # set -o kshglob # for zsh printf '%s\n' "${myvar//[[:alpha:]]*([[:alnum:]-])/}"   or with zsh extendedglobs where the equivalent of regexp * is #:  set -o extendedglob printf '%s\n' ${myvar//[[:alpha:]][[:alnum:]-]#}   a few notes:   ${var/pattern/replacement} replaces only the first occurrence
if it's amazon ami linux first you need to stop nginx service:  sudo service nginx stop   than you should disable it with:  sudo chkconfig nginx off   and if you like, uninstall it:  sudo yum remove nginx   hth 
you could start by timestamping the data as you receive it into a logfile:  awk '{print strftime("%y.%m.%d.%h%m%s ") $0}' &lt;/tty/usb0 &gt;&gt;logfile   you can choose a format that is easy to parse
i'm not a beagle board user, so the first thing you want to do is make sure you have an appropriate kernel source
it's not the kernel that's preventing bad memory accesses, it's the cpu
@umair i am not sure why sdb is showing as removable , could you post the o/p of this script  for device in /sys/block/* do     if udevadm info --query=property --path=$device | grep -q ^id_bus=usb     then         echo $device     fi done  
&amp;&amp; executes the command which follow only if the command which precedes it succeeds
was this file created by conky or by what other program?   it looks like it was created by the conky weather program
i knew i was grasping at straws, but unix never fails!  here's how i managed it:  bash$ gdb --pid 8909 ... loaded symbols for /lib/i386-linux-gnu/i686/cmov/libnss_files.so.2 0xb76e7424 in __kernel_vsyscall ()   then at the (gdb) prompt i ran the command, call write_history("/tmp/foo") which will write this history to the file /tmp/foo.  (gdb) call write_history("/tmp/foo") $1 = 0   i then detach from the process.  (gdb) detach detaching from program: /bin/bash, process 8909   and quit gdb.  (gdb) q   and sure enough...  bash$ tail -1 /tmp/foo while true ; do echo 1 ; echo 2&gt;/dev/null ; sleep 30 ; done   for easy future re-use, i wrote a bash script, automating the process. 
this worked for me  myvar="present value: 4" expr match "$myvar" '.*\([0-9]\)'   output:  4  
the wheezy changelog lists all the package updates in each point release
the man page of bash says:     ! ~    logical and bitwise negation   signed numbers are usually stored in two's complement representation:  ... -4 = 1100 -3 = 1101 -2 = 1110 -1 = 1111  0 = 0000  1 = 0001  2 = 0010  3 = 0011 ...   this means if you take a number like 2 it is bitwise interpreted as 0010
in terminal this worked:   echo "192.168.1.0/24" | sed  -n 's/0.24/2/p'    in script this works:  str="192.168.1.0/24" newstr=$(sed  -n 's/0.24/2/p' &lt;&lt;&lt;$str)   to replace last digit of any ip address:  str="192.111.12.20" newstr=$(awk -f"." '{print $1"."$2"."$3".2"}'&lt;&lt;&lt;$str) echo $newstr  
in /etc/ssh/sshd for computer b set:  allowtcpforwarding yes tcpkeepalive yes   from computer a:  $ ssh -r 2222:localhost:22 ip.of.computer.b   from computer b:  $ ssh localhost -p 2222   note that 2222 is an arbitrary high-port number i picked
fedora running gnome uses simple heuristics to work out if an update is a os/system update or an application update
general info  the facilities local0 to local7 are "custom" unused facilities that syslog provides for the user
when you run  git branch --set-upstream v3.9.1 origin/master   you're telling git that you want your local v3.9.1 branch to track master on the remote
   why does reading a device require admin permissions?   firstly there are couple of issues here   mount'ing the physical storage device and the partitions it contains. accessing and manipulating the files on it.   if the filesystem is permissions based, e.g
launch the program as so:  gtk2_rc_files=/path/to/your/theme/gtkrc application-command  i got this from here, which has some additional information about more complicated scenarios. 
you probably wanted to pipe ls -l into grep, for which fish uses a pipe character the same as other shells (for once):  ls -l | grep html   this is the same thing you would have written in bash
i found a dirty but working solution      &lt;html&gt;&lt;head&gt; &lt;/head&gt; &lt;script type="text/javascript"&gt; var searchurl = "%u"; var newsearchurl = searchurl.replace("http://",""); var newsearchurl = newsearchurl.replace("/",""); var redirectto = "http://www.google.com/search?hl=en&amp;q=" window.location = redirectto + newsearchurl &lt;/script&gt;   put it in (backup for security the old file) /usr/share/squid/errors/yourlocale/err_dns_fail 
#!/bin/bash thing() {    local foo=$(asjkdh) ret="$?"    echo "$ret" }   this will echo 127, the correct error code for "command not found".  you can use local to define more than one variable
if you currently using grub2 you can simple run this command:  update-grub                            # it's an ubuntu alias for following command # or grub-mkconfig -o /boot/grub/grub.cfg   # it'll work on all distributions that uses grub2   this update automatically grub entries. 
the question was somedays old, and i did not submit it but it was still in my browser window.  in the meantime i have evolved a somewhat hacker brute-force solution
you may be able to do what you want by piping awk's output into a while read loop
ifs stands for input internal field separator - it's a character that separates fields
you've already tagged the question awk, so make use of it:  awk '{if (nf&gt;=2) {print &gt; "list-ok.txt"} else {print &gt; "list-notok.txt"}}' filename   another way of saying the same would be to make use of the ternary operator:  awk '{f=nf&gt;=2?"list-ok.txt":"list-notok.txt"; print &gt; f}' filename  
here's something i cobbled up using the csv module:  #! /usr/bin/env python3  import csv, sys  word_list = ['fcv=demelog','fcv=voyapro','fcv=naisjdf','fcv=naismc','fcv=decoide','fcv=decoccm','fcv=travide','fcv=travccm','fcv=equiccm','fcv=mariccm']  csvin = csv.reader (sys.stdin, delimiter=';') csvout = csv.writer (sys.stdout, delimiter=';') for row in csvin:     word_list_fck = [row[0]] + word_list     fmd_start = row[1:].index(row[0]) + 1     row_fcv = row[:fmd_start]  # split fcv from fmd     row_fmd = row[fmd_start:]     out_row = [entry if entry in row_fcv else ''  for entry in word_list_fck]     out_row = out_row + [row_fmd.pop(0) if out_row[i] != '' else '' for i in range(len(word_list_fck))]     csvout.writerow (out_row)   example output:  $ python3 test.py &lt; test.txt fck=83;;;fcv=naisjdf;fcv=naismc;;;;;;;fck=83;;;fmd=1422811694,;fmd=1422811694;;;;;; fck=83;fcv=demelog;;;;;;;;;;fck=83;fmd=1423134370;;;;;;;;; fck=83;fcv=demelog;;;;;;;;;;fck=83;fmd=1422292546;;;;;;;;; fck=83;fcv=demelog;;;;;;;;;;fck=83;fmd=1421774352;;;;;;;;; fck=83;;;;;;fcv=decoccm;;;;;fck=83;;;;;;fmd=1422853444;;;; fck=83;;fcv=voyapro;;;;;;;;;fck=83;;fmd=1422270462;;;;;;;; fck=83;fcv=demelog;fcv=voyapro;;;;;;;;;fck=83;fmd=1422183999,;fmd=1422206234,;;;;;;;;   notes:   i rely on the first element in the row (fck=83 in the example cases) to be the entry separating the fcvs from the fmds
after a little more research, all roads appear to lead to virtualgl (docs), although i have yet to try it (setup instructions are somewhat..
in xfce terminal go to edit, hover your mouse over copyand press `ctrl+c.  same goes for paste.  kill process gets automatically reassigned to ctrl+c+shift. 
you should use the crontab command so that the daemon notified about the chanage and parse errors can be warned about
you need to run ifup -a to bring up the network interfaces after modprobing e1000e
solution:   dumb ap / access point only  http://wiki.openwrt.org/doc/recipes/dumbap 
got it after all.  first - run dmesg command -- a new scsi device is recognized (usually sdb1)
gparted is a nice gui tool for resizing partitions, or ext partitions at any rate
to search for a parenthesis character, pass backslash+parenthesis to ack.  both backslash and parentheses are special in the shell, so you need to quote them when you're entering them in a shell script or on the command line
for real time monitoring you can use inotify-tools
your files are on an nfs mount (a "network share" if you prefer)
the guide that you presented tells you how to set these variables globally - for all users
just enclose variable in braces:  echo -e "${red}note: blabla${nc}".   see more detail about parameter expansion.  see also great answer why printf is better than echo? if you care about portability. 
just go to your kernel source directory, make the changes you want, and make, then make modules_install.  that's all it takes.  if you want to build only one specific module, use:  make m=path/to/module/directory   for instance (from the kernel toplevel directory):  make m=fs/ext4 make m=fs/ext4 modules_install   to activate the changed modules, you must unload then re-insert them
if you use a http head request, only the headers will be returned.  here's a sketchy approach (assuming you have a list of urls). threshold=expr 100 \* 1024  for url in ${list_of_urls} ; do         size=`curl -s --head ${url} | grep 'content-length:' | cut -d ' ' -f 2`       if [ ${size} -gt ${threshold} ] ; then           curl -s ${url}     fi     done    
as far as i know there are no tablets available the comes with linux preinstalled
monkeying with the algorithm for tab complete to rip a couple items out of the pool is more complicated than you imagine
the problem is that when you repeatedly use sed in this way, you keep appending to the shared object file ~/toolchain/usr/lib/libc.so
the second command does "work", but the history is not enabled for non-interactive shells which is why it returns nothing in your script.  $ cat nohistory.sh #!/bin/bash set -o | grep history history   .  $ ./nohistory.sh history         off   .  $ cat history.sh #!/bin/bash set -o history set -o | grep history history   .  $ ./history.sh history         on     1  set -o | grep history     2  history  
this should be possible, for example if your initrd was created using dracut:  https://fedoraproject.org/wiki/how_to_debug_dracut_problems     additional dracut boot parameters      the following boot parameters are also available to further assist with debugging boot issues.      rd.shell       drop to a shell, if the initramfs fails.      rd.break=[cmdline|pre-udev|pre-trigger|initqueue|pre-mount|mount|pre-pivot|cleanup]      drop the shell on defined breakpoint (use egrep 'rd.?break' /usr/lib/dracut/modules.d/99base/init.sh to find the breakpoints supported by your dracut version)    however, since initrd is usually very limited and uncomfortable i would install a rescue image, like systemrescuecd and boot it via additional bootloader entry:  https://www.system-rescue-cd.org/sysresccd-manual-en_easy_install_systemrescuecd_on_harddisk 
vim has an event you can bind to for this, focusgained, combine this with the redraw! command (the ! causes the window to be cleared first)   :au focusgained * :redraw!   the syntax here can be read as 'automatically run the command (au is short for autocmd) :redraw! when i get the event focusgained for any file matching the pattern *'.  to make this permanent add it to your ~/.vimrc (the leading : isn't needed in vimrc).  to test events you can use a more 'obvious' command like  :au focusgained * :q!  
as the file is utf-8 you could run isutf8
you have to create device nodes into /dev with mknod
this is not possible
that's not possible
normally it should work, but since the version of openvpn client on fedora 4 is pretty old you might encounter some inconsistencies regarding option names and usage.  yes scp can used to copy openvpn client configs and certificates to the new fedora 19 client. 
an awesome shell script written some time ago by a friend: livre.  you'll be interested in the --book and --inner options. 
i recompiled the kernel making sure that neither of config_sysfs_deprecated nor config_sysfs_deprecated_v2 were set.  however, after a few retries with config_ide not set (and a kernel which failed to find any harddrives), it turned out i had to config_ide set as well as some more kernel config options found 'under' the deprecated ata/atapi support
the boost packages are slotted, so you can actually have more than one version installed.  to emerge that version, simply issue:  emerge -a =dev-libs/boost-1.39.0   if you want to remove the newer version (quite dangerous, you could have a lot of stuff dependent on it), you could:  emerge --unmerge =dev-libs/boost-1.46.1-r1   and run a revdep-rebuild afterwards.  to switch your environment from one version to the other (if you kept both), use eselect boost list/set. 
this is a matter of trust, relaying means that the mailhost you connect to will send your mail to  other domains
 you use your favorite partition tool (fdisk, cfdisk, parted) in order to change the partition id. you make the partition a valid lvm partition with pvcreate. you make the new pv available with vgcreate or vgextend.   not complicated at all
this can be done by using a custom dlagent
"inode" is the informal term that refers to whatever on-disk chunk of data a unix-file-system uses to hold the information pertaining to a single file
headerbar/csd  actually, a section of the code that i found via reddit and posted above, namely  headerbar entry, headerbar spinbutton, headerbar button, headerbar separator {     margin-top: 2px; /* same as headerbar side padding for nicer proportions */     margin-bottom: 2px; }   does modify the headerbars/csds
a better option than providing the password on the command line at all is to make a ~/.my.cnf file with the credentials in it:  [client] password=something   that way they are also protected against someone looking at the ps output, or your shell history.  that said, you can turn off the watch title entirely with the -t or --no-title option, which will:     turn off the header showing the interval, command,  and  current                 time  at  the top of the display, as well as the following blank                 line.   you do lose a little more information than you were wanting, but it's not hugely vital
the short answer: ultimately, i just installed the newest version of php onto my system
i got an easy way to do the same using gksu nautilus.  using this had helped me to obtain root privilages without using any terminal or so. 
why not remove the password temporary and print the resulting unsecure pdf with lpr:  pdftk secure.pdf input_pw own output - | lpr   if you don't want that this command is listed in bash command history:  set +x history &lt;commands&gt; set -x history   or  &lt;whitespace&gt;&lt;command&gt;   or use a script (adapted from here):   #!/bin/bash unset password prompt="enter password:" while ifs= read -p "$prompt" -r -s -n 1 char; do     [[ $char == $'\0' ]] &amp;&amp; break     prompt='*'     password+="$char" done pdftk secure.pdf input_pw "$password" output - | lpr   source for disabling bash history 
as per jordanm's comment, it was likely missing dependencies (perl-based) in the testing repository
forget about reisub
for a heavy weight solution, you can spin up an amazon ec2 instance
via alsa emulation  i don't have a debian 6.0.x box to test on, but i think this way will probably work
a "plugin" in omz is just a script
there is a --max-size option to rsync which will exclude files from over a certain size from being copied from one directory to another
i think this does what you want; it accepts an awk variable named "factor" that is can easily be set to whatever you want:  awk -v factor=8.06573 '{printf "%2.9f %2.9f\n", $1 * factor, $2 * factor}'    with the given input, it outputs:  34.193855762 35.948152037 34.220472671 33.078365303 34.585043667 33.260650801 33.961562738 36.169959612 34.176917729 33.126759683 33.329209506 32.667819646 34.765716019 35.694888115 35.765059966 36.507107126  
you can calculate it yourself for your system with simple command  $ find /usr/share/man/ -type f -exec ls -s {} + 2&gt;/dev/null | head | while \   read -r file; do printf "%-40s" "$file"; \   man "$file" 2&gt;/dev/null | wc -lwm; done | sort -nrk 4   which returns on my box        (file)                             (lines) (words) (chars) /usr/share/man/man1/zshall.1.bz2          27017  186394 1688174 /usr/share/man/man1/cmake.1.bz2           22477  106148 1004288 /usr/share/man/man1/cmake-gui.1.bz2       21362  100055  951110 /usr/share/man/man1/perltoc.1.bz2         18179   59783  780134 /usr/share/man/man1/cpack.1.bz2            9694   48264  458528 /usr/share/man/man1/cmakemodules.1.bz2    10637   42022  419127 /usr/share/man/man5/smb.conf.5.bz2         8306   49991  404190 /usr/share/man/man1/perlapi.1.bz2          8548   43873  387237 /usr/share/man/man1/perldiag.1.bz2         5662   37910  276778 /usr/share/man/e                           1518    5919   58630   where columns represent number of lines, words and characters respectively
 shift+pageup (and pagedown)  works here, without any special settings... have a look at man urxvt:  pointerblank: boolean    true: blank the pointer when a key is pressed or after a set number    of seconds of inactivity
based on your comments to @sahibprime's answer, you should use etckeeper  from the home page:     etckeeper is a collection of tools to let /etc be stored in a git, mercurial, bazaar or darcs repository
for this i would write a function:  s() {     ssh "really-really-long-hostname$1" }   then call it like so:  s 10037   further reading:   in bash, when to alias, when to script, and when to write a function?  
at a bash prompt, type the following commands and do the steps listed after each one:  set -o | grep history   if you get "history off" then add this line at the end of your ~/.bashrc:  set -o history   next try:  echo $histfile echo $histsize echo $histfilesize   if the first one is blank or /dev/null, add this line to the end of your ~/.bashrc:  histfile=$home/.bash_history   if either of the last two print 0, set them to some number like the default of 500:  histfilesize=500 histsize=500  
service accounts are typically locked, i.e
  \jdbc.driverclassname=oracle.jdbc.driver.oracledriver   what your script has actually output is   -djdbc.driverclassname=oracle.jdbc.driver.oracledriver a carriage return &nbsp;\ (note the space) a newline   why has your script printed a carriage return?  because your input file does not have unix-convention newlines, but has crlfs instead, and the carriage return at the end of each line has been considered part of the second array variable.  why is whitespace like a carriage return being appended to a variable by read?  because you changed ifs.  some words to the wise:   use printf, not echo &mdash; especially, as here, when you are passing echo things that look like command-line options and things with backslashes in. diagnose these sorts of problems by passing the output through hexdump -c, cat -v, or od -t c -t x1. if you don't have dos2unix, it is easy to do the equivalent with tr, sed, or perl.  
the easiest way i found was to select all torrents in transmission, then go to the menu torrent > set location and then choose the desired location for torrents
your problem is that the script in your .../bin directory is execed in another shell environment - its environment does not survive its execution and so the x() { ..
the opensolaris package repository includes an administration gui called visual panels you can install by running pkg install osolvpanels and then it will appear under the system->administration menu in gnome as "services" or you can start it with the command vp svcs. 
turns out to be a character encoding issue with the dashes, which is confused from copy &amp; pasting
note: i am unable to test this answer.  assuming that you want to shut off bluetooth and not just the indicator light, the rfkill utility does what you want
it stands for exponential weight moving average
i always go with the oracle/sun java and try to not use the openjdk version
i have use opensuse for several years and have dabbled in ubuntu and other distributions.  what to expect:   centralised configuration is possible using yast
with lots of research and googling i found that i need to follow the below steps:   create your own linux distribution
on a rpm based system:  $ repoquery -l perl-extutils-embed   lists the files in the package:  /usr/share/man/man3/extutils::embed.3pm.gz /usr/share/perl5/extutils/embed.pm   therefore, you're looking for embed.pm.  on ubuntu (which i believe is close enough to debian in this case):  $ apt-file search embed.pm   searches for a packages that provides the given file, which returns:  perl-modules: /usr/share/perl/5.18.2/extutils/embed.pm   therefore, i believe you need to install perl-modules. 
you were pretty close with your example
later edit: only this one does what jan needs: thank you huygens;  find 
in zsh, there's an auto_pushd option
you will need to join them first
[[ is bash reserved word, therefore special expansion rules such as arithmetic expansion are applied, not like in case with [
there are various ways to do this, but in generally you are going about this problem backwards
the following command will do it for you
the best way to learn aix would be to obtain an account on a machine that's running it
redefine sudo as a function:  sudo() if [ "$1" = init ] &amp;&amp; [ -n "$ssh_client" ]; then   echo &gt;&amp;2 "never use init when ssh"   return 1 else   command sudo "$@" fi   if you want your aliases expanded after sudo, you can still add a  alias sudo='sudo '   it will still call our sudo function. 
i happened to find the answer on serverfault in which we can modify image/sda-pt.parted in image folder produced by cloning before the iso file is made to overcome this problem
missed a space:  pb_acl="acl="`echo $imgreq | jq -r '.data.acl'`                                   ^  
following @don_crissti's comment, it turns out that passing an empty magicfile to file will make it fall back to detect the default ascii.  so file -m /dev/null extra.module.php will do the trick in this case and will output the desired     extra.module.php: utf-8 unicode c++ program text, with crlf line terminators  
probably this is leftover behavior from long ago when bash first implemented oldpwd
lsof is only able to report files currently open by processes
freebsd's termcap definition for "xterm" omits the alternate-screen escape sequence
you source the utils script before you set the value of the environment variable, so the global variable $silent_mode is empty
have a look at /etc/x11/xsession.d/50x11-common_determine-startup:  if [ -z "$startup" ]; then   if [ -x /usr/bin/x-session-manager ]; then     startup=x-session-manager   elif [ -x /usr/bin/x-window-manager ]; then     startup=x-window-manager   elif [ -x /usr/bin/x-terminal-emulator ]; then     startup=x-terminal-emulator   fi fi   so basically, this tries to find an x11 session manager (something like gnome-session), and if that fails, try to find any window manager, and if even that fails, just run a terminal emulator.  most likely you had no session manager installed and no window manager either
found the answer: the fedora iso contains a guid partition table with a partition layout very similar to that of os x
i think that what you need is a port forwarder.  set up a port forwarder on the public v2 listening to port 80, and forwarding to h port 8080
your cut is effectively removing the information you are looking for from the input you feed to grep
assuming you're using opengl, the gpu should be installed on the host where the x server is running
at least for linux, who &lt;arg&gt; &lt;arg&gt; will display the host you connected from.  $ who hates java error    pts/3        2013-11-20 08:35 (underground)   the hp/ux man pages indicate the same is true for that operating system
one of the most easy/efficient way to control what a user can do is lshell.     lshell is a shell coded in python, that lets you restrict a user's environment to limited sets of commands, choose to enable/disable any command over ssh (e.g
found a solution which works for gtk apps (but not qt)
i'm not sure the disk drives write cache is going to fix the issue for you as it sounds like you are using a loop device
you can upload with python as well:  import imaplib  # an alternative for imap4_ssl is imap4 if you're doing this locally imap = imaplib.imap4_ssl(your_2nd_server, its_imap_portnumber)   imap.login(user_name, password)   and then for each message you downloaded:  imap.append(mailbox, [], delivery_time, message)   you have to get the delivery time out of the message header for this. 
whohas package &#40;link&#41; may help you.  example  % whohas pidgin|grep "pidgin " macports    pidgin                                 2.10.6                                                       https://trac.macports.org/browser/trunk/dports/net/pidgin/portfile slackware   pidgin                                 2.7.11-i486-3sl                    slacky.eu                  slackware   pidgin                                 2.7.0-i486-1                       salixos.org                slackware   pidgin                                 2.7.0-i486-1                       slackware.com              openbsd     pidgin                                 2.9.0-gtkspell          8.3m                                  openbsd     pidgin                                 2.9.0              8.3m 16-aug-201                            mandriva        pidgin                             2.10.6-0.1.i586                                              http://sophie.zarb.org/rpms/a6ec6cd30f5fa024d14549eea375dba4 fink        pidgin                                 2.10.6-1                                                     http://pdb.finkproject.org/pdb/package.php/pidgin freebsd     pidgin                                 2.10.6                             net-im                    http://www.freebsd.org/cgi/pds.cgi?ports/net-im/pidgin freebsd     e17-module-everything-pidgin           20111128                           x11-wm                    http://www.freebsd.org/cgi/pds.cgi?ports/x11-wm/e17-module-everything-pidgin netbsd      pidgin                                 2.10.6nb5          10m  2012-12-15 chat                      http://pkgsrc.se/chat/pidgin ubuntu      pidgin                                 1:2.10.0-0ubuntu2
personally, i don't like yum plugins because they don't work a lot of the time, in my experience.  you can use the yum history command to view your yum history.  [root@testbox ~]# yum history loaded plugins: product-id, rhnplugin, search-disabled-repos, subscription-manager, verify, versionlock id     | login user               | date and time    | action(s)      | altered ---------------------------------------------------------------------------------- 19 | jason &lt;jason&gt;  | 2016-06-28 09:16 | install        |   10   you can find info about the transaction by doing yum history info &lt;transaction id&gt;
i've not used this extension myself, but i would guess that ^v-tab might work
posixly:  sed 's/[^[:alnum:]_-]//g'   will remove everything is not alpha numeric characters in your current locale, _ and -.  $ echo 'foo-bar     |' | sed -e 's/[^[:alnum:]_-]//g' foo-bar   but if you want to print everything until first space:  sed -e 's/^\([^ ]*\) .*/\1/'   or awk:  awk '{print $1}'  
you need to add 0 or 2 into /sys/module/hid_apple/parameter/fnmode.  there seems to be some confusion regarding what the difference between the two values might be
it seems to be related with environment variables.  if you set the proxy in your profile (as environment variables), then probably when issuing sudo, these variables don't get loaded.  if you succeed doing so with su, then probably you're using su - (that's the way to load the environment variables of root).  to get loaded these variables (for a normal user) &mdash;if my assumptions are right&mdash; you should use the option -e of sudo
this uses your command to find the infected files, and gives the list to xargs, which runs an expression on the first line.  find * -type f -name "*.php" -exec grep -l "cnajwp =" {} \; | xargs sed -i -e '1s/^(&lt;\?php) \$ocnajwp =.*$/\1/'   according to your input-file sample, this should do the trick.  since in the meantime you have found files, where the infection was placed slight differently, and you have ended up with some files, where both first lines contain &lt;?php, you could run the following to clean up those files:  find * -type f -name "*.php" -exec \ gawk -i inplace 'nr==2 &amp;&amp; /^&lt;\?php$/ {next} 1' {} \;  
phantomjs respects fontconfig directories and even the old font.dir/font.scale postscript font configuration
gwd="${cwd#.}"  your sed command didn't work because it wanted to read the file defined in $cwd
yes, this is called gatewayports in ssh
unless the script is changing it's uid, which requires the script to have the suid bit set in it's permissions, it is running as the user who invoked it
you need to put the nohup before the command that launch  firefox, so it needs to looks like that:  &gt;$ nohup firefox 
i would not use an usb webcam for it
the perl-way:  #!/usr/bin/perl  opendir(dir,".") or die "$@:$!"; while ($in = readdir(dir)) {   next unless -f $in;   ($out = $in) =~ s/[^a-za-z0-9._-]//g;   warn "$@:$!" unless rename $in, $out; } closedir(dir);   the regex filters only a-za-z ..
to use the framebuffer as console you need the fbdev module
you don't say what version of red hat you're using, you can check like this:  $ cat /etc/redhat-release  fedora release 19 (schrödinger’s cat)   you likely have some old version of fedora on it
look at my question. this is related to yours
this isn't the best way to do it
the place for this is in /opt for "add-on application software packages" - these are packages that do not come with the distribution/os.  http://www.pathname.com/fhs/pub/fhs-2.3.html#optaddonapplicationsoftwarepackages 
using xmlstarlet, you could delete all the string nodes under the root node whose name attribute is not profile:  $ xml ed -d '/resource/string[@name != "profile"]' string.xml &lt;?xml version="1.0"?&gt; &lt;resource&gt;   &lt;string name="profile"&gt;my profile&lt;/string&gt; &lt;/resource&gt;   add -o after ed if you don't want the xml declaration line. 
to disable the writing of access times, you need to mount the filesystem(s) in question with the noatime option
you are missing a -l to turn on the long listing format and -t to sort by modification time.  do:  alias ll='ls -lt --color=auto --time-style=long-iso'   to include hidden files too:  alias ll='ls -alt --color=auto --time-style=long-iso'   to reverse the order of sorting, oldest first, add -r:  alias ll='ls -ltr --color=auto --time-style=long-iso' alias ll='ls -altr --color=auto --time-style=long-iso'  
in bash:  $ type -a time time is a shell keyword time is /usr/bin/time   you called time, cause bash invoked time built in keyword instead of external /usr/bin/time command
the command to set the system time is date
bash  as you already noticed bash won't match a . at the start of the name or a slash
there is package fdupes in linux (for example, it is present in debian repository)
you could redirect the manpage to awk and extact the part:  man wget | awk '/^ *-b *.*$/,/^$/{print}'        -b        --background            go to background immediately after startup
yes.  actually there are lots of ways
i think that you are looking for mirror option for wget, -m.  wget -m http://www.example.com/  
ranges:  you can do it with the following command:     :66,70s/^/#   for comment, and for uncomment:     :66,70s/^#/   obviously, here we're commenting lines from 66 to 70 (inclusive).  hope this helps. regards. 
/etc/resolv.conf is built from pieces that are in the directory /run/resolvconf/interface (actual location on current debian and ubuntu) /etc/resolvconf/run/interface (old location, still existing via a symbolic link on debian)
try:  sed -e '/^a1$/,+1d' "filename"   this means from /^a1$/ to the next line, delete  the ^ and $ ensure you match the whole line, so a hidden a1 will not be matched. 
the main differences are:   wget's major strong side compared to curl is its ability to download recursively. wget is command line only
you can use either of these, depending on what you're trying to display:  $ echo "lol llol" | grep -e "\blol" lol llol  $ echo "lol llol" | grep -eo "\blol" lol   putting the regex in quotes solves your matching problem
per jasonwryan's comment, while the default type=simple works for many systemd service files, it does not work when the script in execstart launches another process and completes, as is the case with graphite's carbon-cache.py
as for /etc/network/interfaces, when you install wpa-supplicant, a script hook is installed in:    /etc/network/if-down.d /etc/network/if-post-down.d /etc/network/if-pre-up.d   /etc/network/if-up.d,    the hook is called wpasupplicant and is a symlink to /etc/wpa-supplicant/ifupdown.sh, that invokes in turn /etc/wpa-supplicant/functions.sh.  this hook will be invoked by runparts in ifup / ifdown, and the script the symlink points too tests wether the interface is wireless or not
by trial and error i figured out that the following redefinition works:  (defun show-notification (notification) "show notification
you can instruct the filesystem to perform an immediate fsck upon being mounted like so:  method #1: using /forcefsck  you can usually schedule a check at the next reboot like so:  $ sudo touch /forcefsck $ sudo reboot   method #2: using shutdown  you can also tell the shutdown command to do so as well, via the -f switch:  $ sudo shutdown -rf now   note: the first method is the most universal way to achieve this!  method #3: using tune2fs  you can also make use of tune2fs, which can set the parameters on the filesystem itself to force a check the next time a mount is attempted.  $ sudo tune2fs -l /dev/sda1 mount count: 3 maximum mount count: 25   so you have to place the "mount count" higher than 25 with the following command:  $ sudo tune2fs -c 26 /dev/sda1   check the value changed with tune2fs -l and then reboot!  note: of the 3 options i'd use tune2fs given it can deal with force checking any filesystem whether it's the primary's (/) or some other.  additional notes  you'll  typically see the "maximum mount count:" and "check interval:" parameters associated with a partition that's been formatted as ext2/3/4
you can use a special wildcard syntax with :set &lt;key&gt; to let vim automatically recognize xterm-style modified keys:  if &amp;term =~ '^gnome' execute "set &lt;xup&gt;=\e[1;*a" execute "set &lt;xdown&gt;=\e[1;*b" execute "set &lt;xright&gt;=\e[1;*c" execute "set &lt;xleft&gt;=\e[1;*d" execute "set &lt;xhome&gt;=\e[1;*h" execute "set &lt;xend&gt;=\e[1;*f" execute "set &lt;pageup&gt;=\e[5;*~" execute "set &lt;pagedown&gt;=\e[6;*~" execute "set &lt;f1&gt;=\eop" execute "set &lt;f2&gt;=\eoq" execute "set &lt;f3&gt;=\eor" execute "set &lt;f4&gt;=\eos" execute "set &lt;xf1&gt;=\eo1;*p" execute "set &lt;xf2&gt;=\eo1;*q" execute "set &lt;xf3&gt;=\eo1;*r" execute "set &lt;xf4&gt;=\eo1;*s" execute "set &lt;f5&gt;=\e[15;*~" execute "set &lt;f6&gt;=\e[17;*~" execute "set &lt;f7&gt;=\e[18;*~" execute "set &lt;f8&gt;=\e[19;*~" execute "set &lt;f9&gt;=\e[20;*~" execute "set &lt;f10&gt;=\e[21;*~" execute "set &lt;f11&gt;=\e[23;*~" execute "set &lt;f12&gt;=\e[24;*~" endif   see :help xterm-function-keys and :help xterm-modifier-keys. 
with a large enough value of 'undolevel', vim should be able to undo the whole day's changes
you have several directories that are mounted over other directories (the second mount on /mnt/arcserver shadows the first one and so on, and the mounts on /mnt shadow the prior mounts on /mnt/arcserver)
the issue is due to the difference between the dns name using capitals, and a interaction between bind changes and (now) buggy script/commands due to issues with case sensitivity.  this url check_dig is case sensitive, together with this one  check_dig: expected answer is now incasesensitive should shine a light in similar problems at the application/scripting level.  this is where the change that provoked the aforementioned behaviour in bind 9.9.5 is documented: case-insensitive response compression may cause problems with mixed-case data and non-conforming clients 
as far as elegance is concerned, i'd modify two things in your command:   as mentioned in comment by chris, you can use -q instead of output redirection. use one grep instead of two:  if netstat -an | grep -q " $address:$port .* established"; then   
take a look at pam-tmpdir and pam-mount.  pam-mount mounts and unmounts directories when pam sessions are started and finished (which includes when users log in and out).  pam-tmpdir creates a user-specific temporary directory each time someone logs in, which may come in handy if you're trying to isolate users from each other.  note that in any case there may be daemons which have files in /tmp that they expect to keep around longer than a user's session; so i'd recommend going with a user-specific temporary directory, using either pam-mount or pam-tmpdir. 
by default xvfb will create a unix domain socket for clients to connect
when a script invokes another script, variables of the parent script can be exported, and then they'll be visible in the child script
save output of your command:   cat sections/sem092 | sort -k 2 | awk '{ print $2 }' | uniq -c &gt; firstpart.txt   save this line in file searchinstructorname.sh:   cat $1 | while read line; do      instructorid=`echo $line | awk '{print $2}'`      name=`grep $instructorid instructorlist | awk '{print $2 " " $4}'`     echo "$line $name"   done   this script assume that firtspart.txt line look like:   5 t00005   and that instructorlist is the name of file with 6 field.  finally try:  bash searchinstructorname.sh firstpart.txt   it should works.    this is the version with a single script:   cat $1 | sort -k 2 | awk '{ print $2 }' | uniq -c | while read line; do      instructorid=`echo $line | awk '{print $2}'`      name=`grep $instructorid $2 | awk '{print $2 " " $4}'`     echo "$line $name"   done   save these lines in searchinstructorinfo.sh and run:   bash searchinstructorinfo.sh sections/sem092 instructorlist  
indeed there is
afaik you end up having no mirrors configured in your /etc/apt/sources.list if you skipped the corresponding questions during system setup
you can pass the source code on gcc's standard input
since you're root, you could always strace -f -e execve -p her_bash_pid
fc-match is the utility to use
kate  you can pipe into kate, using command | kate -i.  from $ man kate:     -i, --stdin        read the contents of stdin   kwrite  you can pipe into kwrite with command | kwrite -i.  from $ kwrite --help:  -i, --stdin                read the contents of stdin.   gvim  somewhat facetiously, you can also pipe into gvim with command | gvim -. 
afaik, you can't
try this:  batch=ab1234 awk -v batch="#batch job.*${batch}" '($0 ~ batch),/#--.*/' filename  
xdotool(1) can do that
xstat() work, currently statx(), was revised in 2016.   http://lwn.net/articles/685791/ http://lwn.net/articles/686106/   the process was a bit more disciplined this time (less bikeshedding, agreement to drop controversial attributes as they can always be added later)
if the cursor is already on line 12, then a simple   :4y p   does it for me. 
one moderately ugly way to do it is  grep -v pattern file &gt;file.tmp; diff -c file.tmp file   or replace -c with -c num for num lines of context
   q1: does this mean i'm using gnome 3.8.4?   yes you're using gnome 3.8.4 from that gnome-shell output
the mount output would show noatime if atime were disabled.  perhaps the problem with atime is due to a filesystem that does not support it? 
nogroup is the group analog to the nobody user
here is one way to achieve it:  $ cat parent.sh #!/bin/sh  echo parent.sh running  ./child.sh     $ cat other.sh #!/bin/sh  echo other.sh running  ./child.sh     $ cat child.sh #!/bin/sh  parent="$(ps -o comm= -p $ppid)"  if [ "$parent" != parent.sh ]; then     echo this script should be directly executed by parent.sh, not by $parent     exit 1 fi  echo "child.sh proceeding"     $ ./parent.sh parent.sh running child.sh proceeding     $ ./other.sh other.sh running this script should be directly executed by parent.sh, not by other.sh   note that this is only checking if the immediate parent process is the expected one
you need to read up on the screen command (here's a quick google result)  screen allows you to leave a remote connection running and come back to it for reasons exactly as you describe
perhaps something like this:  rewriteengine on rewriterule   ^/make/lores/some/(.+)  http://example.com/login/$1      [r,l]   this will handle the rewriting to the new url
i recommend you to use apt-file to search for the package that contains a specific file.  if you invoke  apt-file search listings.sty   you should find the package that contains listings.  on my system it's contained in texlive-latex-recommended that you have already installed.  to play it safe i would execute  texhash   to update latex's directory tree.  if you can't get it working after that i'm pretty sure that something else is wrong. 
so
your echo statement should really output newlines not the sequence \ followed by n
well, that p4 chipset is the reason for the driver name
ntfs has windows aces
first of all, you must not have several esps
finally.  imuxsock: add ruleset support  done in rsyslog v8.17
   "á" is 341   no, it isn't
   after some research, i think i've got enough information to post an answer to my own question.   in gnome shell 3.6 and earlier, the old gnome-screensaver program was present, and if gdm was not running, gnome-screensaver would be invoked - allowing you to lock the screen.  starting in gnome shell 3.8 (included in fedora 19), gnome-screensaver support has been dropped completely
from the man page:     ssh-keygen can create rsa keys for use by ssh protocol version 1 and dsa, ecdsa or rsa keys for use by ssh protocol version 2
cp doesn't have this option
well, after performing the following:  arcconf delete 1 logicaldrive all arcconf tast start 1 device all intialize arcconf create 1 logicaldrive name storage1 blah..blah...   i now have what i'd expect:  root@system:~# lsscsi -s | grep adaptec [0:0:0:0]    disk    adaptec  storage1         v1.0  /dev/sda   11.9tb [7:0:0:0]    disk    adaptec  storage2         v1.0  /dev/sdc   11.9tb   problem solved
square box is usually for characters which absent in your current font
because apart from returning 0 it also handles help and version options, plus it contains some comments inside.  you can figure it by yourself by cloning the sources from github, and looking at the content of coreutils/src/true.c. 
you can start a console gui session remotely: run startx
command line ranges can be use to select a specific line that needs to be edited. then substitute pattern can be used to perform the edit (append).  for example, to append text "hi" at the begining of line 3:  vim -c "3 s/^/hi/" -c "wq" file.txt   to append text "hi" at the end of line 3:  vim -c "3 s/$/hi/" -c "wq" file.txt   to find more options and explanations:  vim -c "help cmdline-range"   some more examples  to find a search string "hi" and append string " everyone" on line 3:  vim -c "3 s/\(hi\)/\1 everyone/" -c "wq" file.txt   to find a search string "hi" and prepend a string "say " on line 3:  vim -c "3 s/\(hi\)/say \1/" -c "wq" file.txt   in case the line number is not known,  to append first occurrences of string "hi" on every line with " all":  vim -c "1,$ s/\(hi\)/\1 all/" -c "wq" file.txt   to append all occurrences of string "hi" on every line with " all":  vim -c "1,$ s/\(hi\)/\1 all/g" -c "wq" file.txt   for more info about substitutions:  vim -c "help substitute"  
when you have nested tmux sessions, it is the first ("outermost", oldest) that gets the ctrlb+d key sequence to detach.  you can set up tmux to send its prefix key to the "inner" session like this (in your ~/.tmux.conf):  bind-key b send-prefix   this will send the prefix ctrlb (or whatever you use as prefix) when you press ctrlb+b, so ctrlb+b is basically "the prefix for the inner (of two) tmux sessions".  sending ctrlb+b+d will then detach the inner tmux session.  splitting the pane of the innermost session: ctrlb+b+"  the above assumes two nested sessions
it looks like acx100/acx111 drivers probably won't ever be in the mainline kernel
you can also do cat /etc/*-release to see info about the distribution version and name.  $ cat /etc/*-release distrib_id=linuxmint distrib_release=12 distrib_codename=lisa distrib_description="linux mint 12 lisa"   source: linuxg.net 
i don't quite understand what you are asking here.  maybe you could try something like this?  echo cd `pwd` &gt; /tmp/file  
try:  dpkg-reconfigure tzdata   that should allow to set the timezone for the system (make a copy of the selected timezone file onto /etc/timezone).  more generally, it can be difficult to figure out which package you need to configure to change a setting as it's not always obvious
if you're downloading packages manually, then it's easiest to install them with pacman:  pacman -u curl-7.26.0-1-x86_64.pkg.tar.xz   that way they'll also get tracked like any other package
with zsh 4.3.11, you can use the z parameter expansion flag to split a string value according to the normal shell parsing rules while discarding comments (c option to z) and treating newlines as normal whitespace instead of replacing them with semicolons (n option to z)
it's only in the 32bit version of cygwin at present, so i assume you're installing and running the 64bit one.  not everything has been ported to the 64bit builds.  as you can see from this package search, the nfs-server package is present in the x86 build, but from this search, not in the x86_64. 
this might be an option: store the command and args in an array, then execute it after  # build the command cmd=( ls         -f       # -a   # comment out this option temporarily         -l     ) # $cmd is now an array with 3 elements  # execute it "${cmd[@]}"  
a .deb file is simply a zipped and tarred file, like a .tar.bz2 or .tar.gz, so you can use tar to unzip it
the -prune primary tells find not to recurse under a directory.  find -l -path ~/.wine/dosdevices -prune -o -type f -name 'my favorite movie.*' -print   if you want to use -lname in your condition, you can't use the -l option, because -l causes most predicates to act on the target of the link, including -lname
use mod_deflate.  add this to your apache config:  loadmodule deflate_module /usr/lib/apache2/modules/mod_deflate.so &lt;location /&gt;     addoutputfilterbytype deflate text/html text/plain text/xml text/css &lt;/location&gt;   obviously if the path your system uses for apache modules differs then you'll need to use the correct path. 
i can understand your confusion, i've been there :)  lets start with the fact that pulseaudio, like jack are sound servers in a sense, with different aims in mind though
call time myprogram.  this reports wall clock time, user time and system time
( exec sh -i 3&lt;&lt;script 4&lt;&amp;0 &lt;&amp;3                                        ⏎     echo "do this thing"     echo "do that thing"   exec  3&gt;&amp;- &lt;&amp;4   script )   this is better done from a script though with exec $0. or if one of those file descriptors directs to a terminal device that is not currently being used it will help - you've gotta remember, other processes wanna check that terminal, too
accessing shell variables  all exported shell environment variables are accessible like so:  $(mybasedir)   example  say i have this makefile.  $ cat makefile  all:     @echo $(foo)   now with no variable set, big surprise, we get nothing:  $ printenv | grep foo $  $ make   $   with the variable just set, but not exported:  $ foo=bar $ printenv |grep foo foo=bar  $ export -p | grep foo $  $ make   $   now with an exported varible:  $ export foo $ export -p | grep foo declare -x foo="bar"  $ make  bar   reading input from user  sure you can read input from the user within a makefile
chris' answer would work if the process is long-lived, and you have time to go inspect it, but if it's a short running command, it may be difficult to catch it while the process is still alive.  another way you could approach this is to put a 'wrapper' around the program.  lets say the program being called is /usr/bin/someprog.   move /usr/bin/someprog to /usr/bin/someprog.orig. create /usr/bin/someprog as a script such as:     &nbsp;  #!/bin/sh echo "my pid: $$" &gt;&gt; /tmp/someprog.log ps -ef --forest &gt;&gt; /tmp/someprog.log exec /usr/bin/someprog.orig    and then chmod a+x /usr/bin/someprog   this will dump a process tree and put it in /tmp/someprog.log
i wouldn't be using that repository with fedora 19
don't use password authentication
the description sounds almost as though you might need to configure /etc/gai.conf
beside the ld_preload tricks
yes, this is possible
the type detection information isn't actually embedded in the file program, the file program just reads the magic file and then searches the signatures in that file to see what matches.  the magic file exists both as a compiled version, magic.mgc, and as the original source that is human readable and is just called magic
#!/bin/bash #example of menu programs while true; do     echo "*******************"     echo "1.date"     echo "2.list of users"     echo "3.open a file"     echo "4.delete a file"     echo "5.exit"     echo "*******************"      echo "enter a choice[1-5] :"     read choice     case $choice in         1) echo "today date is : `date`";;         2) who ;;         3) `touch file`;;         4) `rm -rf kk`;;         5) break ;;         *) echo "wrong choice
iotop is your friend (assuming your server runs linux). 
in the sshd config man page man 5 sshd_config:   maxauthtries      specifies the maximum number of authentication attempts permitted      per connection
it is also possible to decompress it using standard shell script + gzip
in bash, with context of two arguments test command, -a file and -e file are the same
you're just missing the closing double quote:  $ var1=hello $ space='  ' $ var2=wissam $ var="$var1${space}$var2" $ echo "${var}" hello  wissam   note that variable names are case-sensitive too. 
like thrig commented, the command to run external commands is command.  your new function could look like:  function who() {   command who "$@" | fgrep -v user }  
you can use the page up/page down keys. 
control_l, up,   control_l|button4 control_l, down, control_l|button5 shift_l,   up,   shift_l|button4 shift_l,   down, shift_l|button5   in your .imwheelrc should do the trick
as i said in my comment, the command you posted works fine on my lmde (pcregrep version 8.31 2012-07-06)
you can only use * on its own or in domain names
you can also use tar -zxvf &lt;tar filename&gt; &lt;file you want to extract&gt;  -x: instructs tar to extract files. -f: specifies filename / tarball name. -v: verbose (show progress while extracting files). -z: filter archive through gzip, use to decompress .gz files.  
you haven't added any sudo rule, so you can't use sudo for anything.  the command adduser username sudo adds the specified user to the group called sudo
that's file number descriptor
.. is a directory entry in the current directory
it's an unwieldy feature to switch on and off (you have to restart x to do it), but you may be interested in setting up a so-called "virtual viewport"
ask pkg-config.  $ pkg-config --modversion gtk+-2.0 2.24.18  
i'd use perl:  perl -mposix -pe 's{\b\d{10}(?=\d{9}\b)}{   strftime("%y-%m-%d %t.", localtime $&amp;)}ge'   (here giving the time in local time, use gmtime instead of localtime for gmt times) 
your guess is correct.  the source code looks like this:  if (v_flag)     fprintf(stderr,             _("pass completed, %u bad blocks found
how ctrl+c works  the first thing is to understand how ctrl+c works.  when you press ctrl+c, your terminal emulator sends an etx character (end-of-text / 0x03). the tty is configured such that when it receives this character, it sends a sigint to the foreground process group of the terminal
like many words, “x11” can have multiple meanings.  “x11” is, strictly speaking, a communication protocol
have a look at "comprehensive server guide" - https://wiki.archlinux.org/index.php/comprehensive_server_guide 
the ip route del command looks not wrong to me
there is no real general answer
you can set the columns variable to limit the width of the display, e.g., if you set it to 12, it will format your example into a single column:  columns=12 select opt in "${options[@]}"; do case $reply in 1) check_update; break ;; 2) reinstall_theme; break ;; 3) font; break ;; 4) wall; break ;; 5) check_update_tool; break ;; 6) all_done=1; break ;; *) echo "invalid option" ;; esac   produces  =========================== tool for theme =========================== choose an option:  1) check theme update 2) reinstall theme 3) install font 4) install wallpaper 5) check tool update 6) quit #?    the bash manual describes columns:     used by the select command to determine the terminal width when printing selection lists
export foo=bar   is not supported by the bourne shell
fedora has a good page about this here: http://fedoraproject.org/wiki/fedoralivecd/usbhowto 
let's say you have a config directory locally that corresponds to a config directory on your device, and that you only make changes locally before syncing them to the device, then rsync is a good tool to perform the sync.  to sync the local directory to the device's directory:  $ rsync -av config/ someuser@device.address:path/to/config/   to delete files on the device that are not any longer present in the local config directory, add the --delete flag to rsync:  $ rsync -av --delete config/ someuser@device.address:path/to/config/   swap config/ and someuser@device.address:path/to/config/ to instead back up the config directory from the device to a local directory (it was slightly unclear what direction you wanted to go in the question). 
you are not doing what you think you're doing
there is more than one problem with the script, plus the problem statement needs some clarification:   the gsub call has the regular expression in the wrong parameter updating $1 has no effect on $0 (the value used in the print statement) op did not clarify if the intent was to leave the last occurrence on a line untouched, or only the last line containing the date (the latter is more likely).   here is a script which incorporates those fixes and assumptions:  #!/bin/sh awk ' begin { row=0; fixup = -1; } {     before[row] = $0;     gsub("2016/01/30 14:52:51: ", "", $0);     if ( $0 != before[row] ) {             fixup = row;     }     after[row++] = $0; } end {     if (fixup &gt;= 0) {             after[fixup] = before[fixup];     }     for (n = 0; n &lt; row; ++n) {             print after[n];     } } '   (using two arrays is less efficient, but allows further modification with less effort than without the before array).  i tested this by making an input file (foo.in):  1awk '{gsub(//,"2016/01/30 14:52:51: ",$1);print}' 2awk '{gsub(//,"2016/01/30 14:52:51: ",$1);print}' 3awk '{gsub(//,"2016/01/30 14:52:51: ",$1);print}' 4awk '{gsub(//,"2016/01/30 14:52:51: ",$1);print}'   and running the script like this:  ./foo &lt;foo.in   and got  1awk '{gsub(//,"",$1);print}' 2awk '{gsub(//,"",$1);print}' 3awk '{gsub(//,"",$1);print}' 4awk '{gsub(//,"2016/01/30 14:52:51: ",$1);print}'  
depending on how many files there are you could do something like:  for pat in *_pattern_*; do     cat -- "$pat" &gt;&gt; "${pat%%_pattern_*}".ext done   this will loop over all the files in this directory that contain _pattern_ and cat the contents of each appending to a file whose name is everything before _pattern_ appears in the string, then adding the .ext extension.  if there are too many files this won't work though 
you need to combine the output of stderr and stdout prior to piping it to logger
you're looking for set reply_self = no (which should be the default, but confirm you and/or your distro hasn't changed it)
i couldn't find any nice method of obtaining the version info, the only thing i could think of is using strings on the xargs binary:  strings $(which xargs) $freebsd: src/usr.bin/xargs/strnsubst.c,v 1.7 2004/10/18 15:40:47 cperciva exp $ $freebsd: src/usr.bin/xargs/xargs.c,v 1.57 2005/02/27 02:01:31 gad exp $ @(#)program:xargs  project:shell_cmds-187 [...]   in addition to that, you can go to opensource.apple.com and navigate to the appropriate source file for your version of os x
fatrace -t -f o &gt;&gt; /var/log/filesopened.log  
since it's a fuse fs mounted on the mountpoint, you use the ordinary fuse unmount method:  fusermount -u /home/sh/srv/mtp   if that fails, you can try:  fusermount -u -z /home/sh/srv/mtp  
try exporting function, then calling it in a subshell:  showword() {   echo $1 }  export -f showword echo this is a sample message | xargs -d' ' -t -n1 -p2 bash -c 'showword "$@"' _  
if i understand your question right your grep is going to produce a bunch of strings like this:  href="http://reddit.com/r/bacon/foo"   and you want to turn each of them into something like:  http://i.imgur.com/foo.jpg http://i.imgur.com/foo.png http://i.imgur.com/foo.gif   it's not particularly graceful, but you could just do:  sed "s .*/r/bacon/\(.*\)\".* http://i.imgur.com/\1.jpg\nhttp://i.imgur.com/\1.png\nhttp://i.imgur.com/\1.gif "   example:  timp@helez:~/tmp$ cat bacon.lines  href="http://reddit.com/r/bacon/foo" href="http://reddit.com/r/bacon/bar" timp@helez:~/tmp$ cat bacon.lines | sed "s .*/r/bacon/\(.*\)\".* http://i.imgur.com/\1.jpg\nhttp://i.imgur.com/\1.png\nhttp://i.imgur.com/\1.gif " http://i.imgur.com/foo.jpg http://i.imgur.com/foo.png http://i.imgur.com/foo.gif http://i.imgur.com/bar.jpg http://i.imgur.com/bar.png http://i.imgur.com/bar.gif  
i believe you can use wireshark to determine why these packets are being retransmitted
ionice [-p] &lt;pids/&gt;   for example:  $ ionice -p `pidof x` none: prio 0   this means x is using the none scheduling class (best effort) with priority 0 (highest priority out of 7)
how about fold? it's part of coreutils...  $ tr -dc 01 &lt; /dev/urandom | fold -w 30 | head -n 5 001010000111110001100101101101 000101110011011100100101111000 111010101011100101010110111001 111011000000000101111110110100 110011010111001110011010100011   or if that's not available, some flavour of awk:  $ tr -dc 01 &lt; /dev/urandom | awk \$0=rt rs=.\{,30} | head -n 5 000100010010001110100110100111 101010010100100110111010001110 100011100101001010111101001111 010010100111100101101100010100 001101100000101001111011011000   or you could just do something with a loop...  $ for line in $(seq 1 5) &gt; do &gt;     echo $(tr -dc 01 &lt; /dev/urandom | head -c 30) &gt; done 100101100111011110010010100000 000000010000010010110111101011 010000111110010010000000010100 001110110001111011101011001001 001010111011000111110001100110   i'm sure there are other ways..
you can use the mp4box tool to do this:  mp4box -add alfa.mp4 -add bravo.srt:txtflags=0xc0000000 -new charlie.mp4   example  this will mark the subtitle stream in the output file as forced.  however, this mark will only be recognized starting with vlc media player 3.0.0-20161101 (nov 2016).    i have seen mentions to this post on the ffmpeg mailing list about a patch that implements disposition for ffmpeg:  ffmpeg -i alfa.mp4 -i bravo.srt -c copy -c:s mov_text -disposition:s forced charlie.mp4   however after having tried it with both "forced" and "default", the subtitles marked by ffmpeg are not recognized as forced by vlc. 
grab this handle, and drag it up:   
try this:  ssh user@remotehost.domain sudo cat /path/to/restricted_file &gt; /local/path   if your sudo requires typing in a password you will want to add -t just after the ssh in order to type in the sudo password.  what this does is run sudo cat file on the remote host, redirecting the output to a local file
perl:  perl -ne '     begin {$width = 10}     while (length) {         ($word = substr($_,0,$width)) =~ s/^\s+|\s+$//g; # trim whitespace         $word ||= "-";         print $word, " ";          substr($_,0,$width) = "";     }     print "\n"; ' file  
linux standards base is a set of apis that are guaranteed to be available on an lsb compliant installation
if you know for sure that some character will never occur in the first file then you can use paste.  example of paste using default delimiter tab:  paste file1 file2 | while ifs="$(printf '\t')" read -r f1 f2 do   printf 'f1: %s\n' "$f1"   printf 'f2: %s\n' "$f2" done   example of paste using @:  paste -d@ file1 file2 | while ifs="@" read -r f1 f2 do   printf 'f1: %s\n' "$f1"   printf 'f2: %s\n' "$f2" done   note that it is enough if the character is guaranteed to not occur in the first file
wbinfo(1) can query user account details, including group membership.  wbinfo -i username shows (brief) user info
the following works in case of ubuntu
apt-cache showpkg shows detailed information about potentially installable packages
if the order of the patterns is fixed then you can easily use grep as in:  grep -e 'pattern1.*pattern2.*pattern3'   but in case that all patterns must be present and they may appear in any order then you get combinatorical complexity; e.g
well..
it's an old question, but curious others can consider the command 'newusers'
use c-x h (mark-whole-buffer), then'm-| (shell-command-on-region), then use @kotte's suggestion above to run gcc -x c -o tmp_prog - &amp;&amp; tmp_prog  or here's an elisp function that does it:  (defun compile-and-run-buffer()   "compiles the code in the buffer using gcc, run the exe and remove it."   (interactive)   (shell-command-on-region    (point-min)    (point-max)    "gcc -x c -o emacs_tmp - &amp;&amp; ./emacs_tmp &amp;&amp; rm emacs_tmp"))  
to ignore the .git directories and everything underneath them you need a construct like this  find 
to get the uid from the username, use id -u:  $ id -u root 0 $ id -u lightdm 112 $ id -u nobody  65534   but you are re-inventing the wheel
the ser2net control port is mapped to tcp port 12345 on the device running ser2net
it turned out that rather than using tab i had to use ctrlx ctrlu  see the compl-function docs for more. 
1) in general, files in /var/www should be owned by root:www-data and chmod 644, while /var/www itself and all subdirectories should be chmod 755.  they should not be writable by the www-data user unless absolutely necessary (and that goes triple for executable files) because files which are writable by www-data can be modified by an attacker who manages to compromise the web server itself or a script run by the web server (unless you're using suexec, in which case they'll have the permissions of the script's owner rather than the web server, which generally isn't much better and may be much worse)
this situation comes from a misunderstanding of what ssmtp is doing
a gateway would need to be configured in your interfaces file; e.g., something like  iface wlan0 inet static     address 192.168.x.y     gateway 192.168.x.z     netmask 255.255.255.0   would work (where x is your network number, y the address for your host, and z the address for your gateway)
ok, i can't get the packet imported into wireshark (there must be some headers extra or missing, not bothering to figure that out) but, this is ipv6
from the conky man page.  cpu (cpun)     cpu usage in percents
i don't know why your code does not work for the presented inputs
you can use \ to split long commands over multiple lines.  example:  #!/bin/bash  echo "hello world!" echo \ "hello world!"   running this script results in  $ ./test.sh   hello world! hello world!   in your case you can use something like  #!/bin/bash      gnome-terminal \ --tab --title="zookeeper" --profile hold -e "sh -c '/home/benu/downloads/kafka_2.11-0.8.2.2/bin/zookeeper-server-start.sh /home/benu/downloads/kafka_2.11-0.8.2.2/config/zookeeper.properties'" \ --tab --title="kafka" --profile hold -e "sh -c 'sleep 5; /home/benu/downloads/kafka_2.11-0.8.2.2/bin/kafka-server-start.sh /home/benu/downloads/kafka_2.11-0.8.2.2/config/server.properties'" \ --tab --title="ssc" --profile hold -e "sh -c 'sleep 15; cd ~/gitnewssc/benu-ssc-binaries; ./startssc.sh'" --working-directory="/home/benu/gitnewssc/benu-ssc-binaries" \ --tab --title="ssc-binaries" --profile hold --working-directory="/home/benu/gitnewssc/benu-ssc-binaries" \ --tab --title="ssc-db" --profile hold --working-directory="/home/benu/ssc-v2/ssc-db"  
try this :  echo "today's date is: $(date)" day=$(date +"%u")  if ((day &gt; 5)); then    echo "weekend"         else    echo "working day" fi   i use (( )) bash arithmetic  or less readable :  echo "today's date is: $(date)" day=$(date +"%u")  if [[ day -gt 5 ]]; then    echo "weekend"         else    echo "working day" fi  
you appear to have mentioned all of the possibilities
debugging symbols just add extra information to an executable that helps when running a debugger such as gdb
   i attempted using parameter substitution which seemed like the easiest   way to go   it is the easiest way to go (just keep in mind that, as the name suggests - and as pointed out in a comment, the shell expands a parameter/variable ); use ${var%-*} to (reluctantly) remove suffix (in this case starting from the last -):   for f in ./*-uniq.tar.gz do printf %s\\n "${f%-*}"    done   or ${var:offset:length} to remove the last n characters (where length is a negative integer):  for f in ./*-uniq.tar.gz do printf %s\\n "${f:0:-12}" done  
to remove the xsi:schemalocation entry, leaving the rest of the file intact:  $ sed 's/xsi:schemalocation="[^"]*"//' "$path/${word}_lop.xml" &lt;hello version="4.2" xmlns="http://www.bacd.org/hello-4_2" xmlns:xsi="http://www.w3.org/2001/xmlschema-instance" &gt;       &lt;!-- some data here  --&gt;  &lt;/hello&gt;   s/xsi:schemalocation="[^"]*"// is a substitute command
that is a feature of the shell that remembers how you got to where you are. if you have realpath installed you can do:  $ realpath  /home/dazz/test/1   and lacking that if you have python:  $ python -c "import os; print(os.path.realpath('.'))" /home/dazz/test/1   or readlink (from coreutils):  $ readlink -f . /home/dazz/test/1   or /bin/pwd (not the shell built-in pwd):  $ /bin/pwd /home/dazz/test/1  
you need to add a line such as the following to your .muttrc:  save-hook 
you can access the disk image and its individual partitions via the loopback feature
well, i've been prompted to put this as an answer by @derobert     the problem you have is aufs...
use a here string  ./program_name &lt;&lt;&lt; 'my input string'   or a here document (longer, but standard):  ./program_name &lt;&lt;eof my input string eof  
if the only problem is shared libraries, then the simplest thing is to recompile the program with static linking, giving you one big executable which doesn't need any shared libraries.  alternatively, you could find the shared libraries (with ldd) and copy them over
you can set username and password directly, but it doesn't work when you use an account-hook, so probably the account-hook doesn't work.  an account-hook consists of a regexp for the mailboxes, and those commands which should be executed if a mailbox matches the regexp.  since the commands (set imap_user, set imap_pass) are not executed, we can assume that the regexp didn't match your mailboxes.  you are using 'imaps://mail.domain.net:993/inbox/' which is very specific
bash does not do multi-dimensional arrays
so looking through the bugs for harden i found the following two bugs.   https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=782978      subject: rm: harden -- roqa; no longer useful   date: sun, 19 apr 2015 20:12:06 -0400   the maintainer thinks it would be best for it to be removed:   https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=760449      hi   i agree with you
first, we have to find out what is the problem
short answer: you don't.  long answer: from the man pages:     apt (advanced package tool) is the command-line tool for handling   packages
the only reason i can see why it wouldn't work is if there are no files with spaces in their names
sed inline answer:  find ./files -mtime +90|sed '1s/^/files stuck in queue:\n/'  
in zsh, i often do:  cd /path/to/somefile(:h)   (h for head).  if somefile is a symlink, you can also do:  cd somefile(:a:h)   to get to the directory where the target of the symlink may be found.    the zsh equivalent of chris' now bash-only solution would be:  cd() {   [[ ! -e $argv[-1] ]] || [[ -d $argv[-1] ]] || argv[-1]=${argv[-1]%/*}   builtin cd "$@" }     in zsh, you can also redefine what "words" ctrl-w removes.  in zsh, "words" in the context of the word-based motion/transpose/delete widgets  are sequences of alnums plus the characters in the $wordchars variable which by default includes /.  you could remove / from $wordchars so that ctrl-w only deletes one path component:  wordchars=${wordchars/\/}   another useful extension is the select-word-style widget which you can use to interactively choose between different word styles.  autoload select-word-style zle -n select-word-style bindkey '\ew' select-word-style   then pressing alt-w allows you to choose between different word styles.  $ cd /blah/blih&lt;alt-w&gt; word styles (hit return for more detail): (b)ash (n)ormal (s)hell (w)hitespace (d)efault (q)uit (b), (n), (s), (w) as above with subword matching ?  
you can use bash's echo or /bin/echo from gnu coreutils in combination with iconv:  echo -ne '\x09\x65' | iconv -f utf-16be   by default iconv converts to your locales encoding
from the man page with a different binding.  unbind c-d                                                                                                                                                                                                                             bind -n c-d confirm-before -p "kill-pane #p? (y/n)" kill-pane     -n tells tmux that you don't need to enter the prefix before. 
simply write nothing to the file:  :&gt; "$filenametarget"   this will empty the file if it already exists, and create it (empty) if it doesn't
the easiest way is to enable system call auditing  see the following link for details，  http://serverfault.com/questions/199654/does-anyone-know-a-simple-way-to-monitor-root-process-spawn  if you're monitoring all processes, just remove the -f uid=0 part  logs are written to /var/log/audit/audit.log 
pids do wrap around in normal usage
you don't need sudo to fix that, try pkexec,  pkexec nano /etc/hosts pkexec nano /etc/hostname   after running pkexec nano /etc/hosts, add your new hostname in the line that starts with 127.0.1.1 like below,  127.0.0.1   localhost 127.0.1.1   your-hostname   and also don't forget to add your hostname inside /etc/hostname file after running pkexec nano /etc/hostname command,  your-hostname   restart your pc
yes it is possible if you are using cups
grep -e '\b6\b'  \b is a "word boundary"  edit: after pointing @nobar in the right direction, he found/pointed out the shortcut-option -w (word-regexp) in the manpage, which simplifies the above to:  grep -w 6   if used a lot, you could use a function similar to  wgrp(){ grep -w "$1" "$2"; }  note (to @glenn-jackman): if you don't quote "$2" here, you can use the function as a pipeline filter
you need a build automation tool, of which many exist
1) download the rpm for redhat 6:  http://hplipopensource.com/hplip-web/install_wizard/index.html  2) remove the old hplip packages  3) install the downloaded package, it works!! :) 
grep -fxf list -v /etc/remotedomains &gt; remotedomains.new mv remotedomains.new /etc/remotedomains   the -v tells grep to only output lines that don't match the pattern.  the -f list tells grep to read the patterns from the file list.  the -f tells grep to interpret the patterns as plain strings, not regular expressions (so you won't run into trouble with regex meta-characters).  the -x tells grep to match the whole line, e.g
try using certutil to install a certificate.  some examples that used to work back when chrome did not support installation of certificates from the ui.  more usage examples and a detailed description  hope this helps
who and last only show if you're logged in
the manpage for init describes the contents of /etc/default/init, and says:   cmask      the mask (see umask(1)) that init uses and that every             process inherits from the init process
you can create a section [color] in your ~/.gitconfig with e.g
i think the best thing to is to ensure that process b only copies files which have been fully transferred by process a
you can set the priority for a particular user in /etc/security/limits.conf file.  root       hard/soft     priority    10   this way u can set hard or soft limit for any particular user
put some text into the file ~/.plan and try finger again:  $ finger yeti                                       login: yeti                             name: yeti directory: /arpa/tz/y/yeti              shell: /bin/ksh on since wed apr  2 15:24 (utc) on pts/149 mail last read mon mar 31 11:08 2014 (utc) no plan. $ echo mwhuaaaaahahahahahahahahahaaaa..
sure—partitions are mounted wherever you specify in /etc/fstab
use basename:  #!/bin/bash  basename -- "$0"   if you want to assign it to a variable, you'd do:  my_name=$(basename -- "$0")  
cron approach  if you have sudo privileges you could stop/start the cron service
actually, the temperature is not stored anywhere
to print a pcl code directly without filtering with cups these commands should be used and have to work:   lpr -l filename lp -o raw filename   i prefer this method over converting it to pdf but a totally free script/technique would be interesting to know of
separate a partition for windows (either primary partition or logical).  install windows to that partition, and when it's done, boot with your livecd and fix grub.  how to recover linux boot after that?  boot with another system, e.g your fedora livecd, chroot into your root partition, and run grub-setup /dev/xxx to install the boot loader and re-build your grub menu file (to add loader for windows 7).  mount:  mount /dev/xx /mnt/xx   chroot:  mount --bind /dev /mnt/xx/dev chroot /mnt/xx   now fix grub:  grub-mkconfig &gt; /boot/grub/grub.cfg grub-setup /dev/xx   i've done this multiple times, it is both possible and easy. 
$_ will work in (at least) interactive dash, bash, zsh, ksh (though apparently not in a conditional statement as requested) and mksh shells
lenny is so far out of date that you may as well upgrade it anyway
no
i don't think you can, easily, tell it "temporarily stop caching"
the resize2fs does not support shrinking of a mounted file system:     description          the resize2fs program will resize ext2, ext3, or ext4 file systems
to accomplish that, you need to put eth0 and eth1 into bridge mode on the pc and give 1 ip to the bridge interface (not on the individual eths)  here are the basics about bridging on linux, to get started http://www.tldp.org/howto/bridge-stp-howto/index.html  depending on your distro there might be a faster/better way to do bridging.  now, the wireless ip range you mentioned, cannot be specified via some configuration
there is a new html5 version, which runs fine under chrome, no need to use phone for voice.  open it at:  https://app.gotomeeting.com  or if you want to directly open the meeting using the id:  https://app.gotomeeting.com/index.html?meetingid=&lt;id&gt;   then you can create a web app in chrome, clicking in the sandwich icon, then more tools > add to the desktop.  you can use your webcam and see shared desktops.  you'll need a chrome extension to share your desktop.  gotomeeting said the html5 is their future platform and missing features will be added. 
you can define functions in  awk like:  awk -f'[-,]' '   function abs(v) {return v &lt; 0 ? -v : v}   {print abs(360*($4-$1)+30*($5-$2)+($6-$3))}'  
the -h/-hold option is to keep the terminal emulator window open once the applications started in it (shell or other) has exited
$ sed ':again;$!n;$!b again; :b; s/{[^{}]*}//g; t b' file3 this is  that wants  anyway.   explanation:   :again;$!n;$!b again  this reads in the whole file.  :again is a label
apple works pretty hard to make sure that this can only be done through their tools, and they do not release itunes for linux
don't check if your platform is fedora-based
since you're mixing a package that was provided by slackbuild with one that comes from the official website i'd be inclined to remove the previous package first
those are ansi control sequences
sudo is an additional program which may or may not be installed on a system
it's nothing harder than connecting to the linux machine, setting display variable to connect to the running x server and running an image viewer
when you run ls without arguments, it will just open a directory, read all the contents, sort them and print them out.  when you run ls *, first the shell expands *, which is effectively the same as what the simple ls did, builds an argument vector with all the files in the current directory and calls ls
the application you are looking for is macof which is part of the dsniff toolkit
use the lpoptions command.  that writes settings to ~/.cups/lpoptions or, if run as root, in the system-wide /etc/cups/lpoptions file.  these settings are used when submitting jobs via lp or lpr, hence changes take effect immediately without the need to restart services. 
not in a way which allows you to restore them
of course you can
if you have control over the wrapper program, then make sure that it doesn't invoke a subshell
if you have cue set to use k3b in in the filetype settings, k3b will automatically split the file if you open the cue file, and allow you to re-rip. 
when you expand your sedi variable, what is happening is that the '' is passed to sed as an argument, rather that creating an empty argument as expected.  the best way i can see around this is to make your sedi variable an array:  if $darwin; then     sedi=(sed -i '') else     sedi=(sed -i) fi   and use like this:  "${sedi[@]}" "s/version =.*;/version = \"${lver}\";/g" version.java   otherwise, i think the only way to turn your '' into an actual empty argument is to use eval with your original declaration:  eval $sedi '"s/version =.*;/version = \"${lver}\";/g"' version.java   however this is a somewhat nasty solution since you have to add an extra layer of quotes/escapes to the rest of the command
there is a script on the arch wiki pacman tips page for finding files not owned by any package
although /dev/urandom is extremely slow and as such not suitable for overwriting large amounts of data (entire disk), it might do for small regions.  example overwriting 8mib:  dd bs=1m count=8 iflag=fullblock if=/dev/urandom of=/dev/destroyme   alternatively you can use shred:  shred -v -n 1 -s 8m /dev/destroyme   you can also use losetup to create devices of specific size and offsets, and overwrite them with utilities that don't have their own size / offset options.  losetup --find --show --offset 0 --sizelimit $((8*1024*1024)) /dev/destroyme # will print /dev/loopx cat /dev/urandom &gt; /dev/loopx losetup -d /dev/loopx  
as you can see from ip rule help, there is no replace:  $ ip rule help usage: ip rule [ list | add | del | flush ] selector action ...   so you have to delete the rule then add its replacement
unfortunately, there currently is no maintainer for this plugin.  however, there are lots of popular editors that support this one way or another
when i installed mint after wiping ubuntu, i remounted my backed up ubuntu /home partition
history
email was designed back when computers did not have a permanent, fast network connection to each other, on the model of postal mail
the shuf command (part of coreutils) can do this:  shuf -n 1000 file  
fdisk just makes partitions; it's up to other things like your kernel command line and the contents of /etc/fstab to decide how to use them
the command find used with -exec option will return the status code of the grep command
depending on why you want to do this, there may be another way.  if the setgid bit of a directory's permissions is set, then all files created in that directory will be owned by the same group that owns the directory.  $ chgrp specificgrp . $ chmod g+s . $ touch newfile $ ls -l newfile -rw-r--r-- 2 gowtham  specificgrp  4096 sep  5 14:48 newfile $ ls -ld . drwxr-sr-x 2 gowtham  specificgrp  4096 sep  5 14:48 .  
ssh already takes care of this
it is in the ! shell variable:  my-app &amp; echo $!  
according to your apt-cache policy output, they're still in the archive (aka available), so dpkg won't forget about them
you can use a backslash:  % alias ls ls -a % ls # ls -a output here % \ls # plain ls output here   for shell builtins, there turns out to be a gotcha:  a leading backslash prevents both aliases and builtins from being used, but an internal backslash suppresses aliasing only.  % alias cd pushd % cd /tmp /tmp /tmp  % c\d % dirs ~ /tmp   (i'm tempted to call that another argument against using the csh family of shells.) 
the gnu c library has a reference manual that includes documentation for all or most of the data structures in the standard library and extensions
imagine that you are a developer/package maintainer, etc
stat(1) can show many file associated attributes by specifying special format strings to it's -c option
you can define a widget that calls your script:  my-script_widget() my-script its args zle -n my-script_widget bindkey '\ej' my-script_widget   but why would you want to call your script directly from the zle?  if it displays anything, it will mess up the display
update: this appears to have been fixed after an update from 4.2 series kernel to 4.3 series kernel.  yay!  i no longer need to disable wayland.    tldr: disable wayland in /etc/gdm/custom.conf
the easy way:  for f in /some/path/*; do     if [ -f "$f" ]; then         mv "$f" /some/other/path     fi done   the slightly more complicated way:  find /some/path -mindepth 1 -maxdepth 1 -type f -exec mv {} /dome/other/path \;  
locate -e0 '*/pg_type.h' | xargs -r0 cat   locate pg_type.h would find all the files with pg_type.h in their path (so for instance if there was a rpg_type.horn directory, you'd end up displaying all the files in there).  without -0 the output of locate can't be post-processed because the files are separated by newline characters while newline is a perfectly valid character in a file name.  cat without arguments writes to stdout what it reads from stdin, so locate | cat would be the same as locate, cat would just pass the output of locate along
one way phpmyadmin is configured with apache is through an apache alias directive, if you comment that directive out - it should disable  phpmyadmin
i couldn't find any debootstrap-like software
summary   if you are using ubuntu, it probably changed around 2005, when the default character set changed from iso 8859-1 to utf-8. us alternative international adds some dead keys.     the dead key settings depend on your locale and character set.  for example:   en_us.utf-8 is defined in /usr/share/x11/locale/en_us.utf-8/compose iso 8859-1 is defined in /usr/share/x11/locale/iso8859-1/compose    if you look in them using grep, you can see there is a difference:  $ grep '&lt;dead_acute&gt; &lt;c&gt;' /usr/share/x11/locale/en_us.utf-8/compose  &lt;dead_acute&gt; &lt;c&gt;                    : "ć"   u0107 # latin small letter c with acute  $ grep '&lt;dead_acute&gt; &lt;c&gt;' /usr/share/x11/locale/iso8859-1/compose &lt;dead_acute&gt; &lt;c&gt;            : "\347"    ccedilla   namely:   latin1 encoding: ', c = ç utf-8 encoding: ', c = ć   the git logs ((en_us.utf-8) (iso8859-1)) show it has been this way since at least 2004.    the difference between us international and us alternative international is defined in /usr/share/x11/xkb/symbols/us.  namely, the us alternative international layout adds these extra altgr dead keys:   dead_macron: on altgr-minus dead_breve: on altgr-parenleft dead_abovedot: on altgr-period dead_abovering: on altgr-0 dead_doubleacute: on altgr-equal (as quotedbl is already used) dead_caron: on altgr-less (altgr-shift-comma) dead_cedilla: on altgr-comma dead_ogonek: on altgr-semicolon dead_belowdot: on altgr-underscore (altgr-shift-minus) dead_hook: on altgr-question dead_horn: on altgr-plus (altgr-shift-equal) dead_diaeresis: on altgr-colon (alt-shift-semicolon)   for example:   us international: altgr+- = ¥ us alternative international: altgr+-, a = ā     utf-8 became the default encoding:   red hat 8.0 "psyche", released september 30, 2002 reference ubuntu 5.04 "hoary", released april 8, 2005 reference debian 4.0 "etch", released as "stable" april 8, 2007 reference 1 reference 2  
lynx has a "dump" mode, which you can use with watch:  $ watch lynx https:/www.google.com -dump     from man lynx:     -dump  dumps  the  formatted  output  of  the default document or those           specified on  the  command  line  to  standard  output
you don't say which distro or version of the cron daemon you are running, but it is likely that your cron maintains system crontab files (/etc/crontab) and also per-user crontab files.  the file that you are seeing when you run crontab -l (as root) is probably /var/spool/cron/crontabs/root which is where you want to make your changes, by using crontab -e  without further information on your distro version or cron daemon, i won't go on, but it is possible you have broken the /etc/crontab as it has a slightly different syntax to the per-user crontab files
linux's auditd can get the information for points 1 and 2.  assuming you are running rhel/centos 6 and have an nfs share mounted as /mnt/nfs/foo:  $ tree /mnt/nfs/foo /mnt/nfs/foo |-- a |   `-- foo |-- b     `-- bar   you will need to define the following rules in /etc/audit/audit.rules:  # delete existing rules -d # set buffer size -b 320 # log read and write operations -w /mnt/nfs/foo -p r -k read -k nfs -w /mnt/nfs/foo -p w -k write -k nfs   and then reload the auditd service with /etc/init.d/auditd reload.  once that is done you can use ausearch and aureport to read the event logs generated by auditd:  $ cat /mnt/nfs/foo/a/foo $ echo 'test' &gt; /mnt/nfs/foo/b/bar $ ausearch -k nfs | aureport -f file report =============================================== # date time file syscall success exe auid event =============================================== 1
sed '/from/,$!d;/./!q' &lt;infile   ...the above expression instructs sed to delete from output all lines which do !not fall within the range of /from/ through the $last line
the linked example is a zlib stream
the kinfocenter command pops up a screen which details the system configuration
if cat /proc/5589/smaps 2&gt;/dev/null 1&gt;/dev/null; then      echo readable ;  fi   or to read less  if head -n 1 /proc/5589/smaps 2&gt;/dev/null 1&gt;/dev/null; then      echo readable ;  fi   update:   i think you need to combine both checks in your script: 1) if [ -r /proc/5589/smaps ] 2) if cat /proc/5589/smaps 2>/dev/null 1>/dev/null;  so that first you check file permissions and then check a result of reading a proc file
they serve the same purpose (pass the given env vars to the command)
you can think of a function like this, with some error check to add  common_prefix() {   local n=0   while [[ "${1:n:1}" == "${2:n:1}" ]]; do     ((n++))   done   echo "${1:0:n}" }  
curl writes the output to stderr, so redirect that and also suppress the progress:  curl -v --silent https://google.com/ 2&gt;&amp;1 | grep expire   the reason why curl writes the information to stderr is so you can do: curl &lt;url&gt; | someprgram without that information clobbering the input of someprogram 
perl script.  set the file name in $in in place of genome.txt or give the name as argument.  name the script counter.pl and give it executable rights, and run it as ./counter.pl  chmod 755 counter.pl ./counter.pl   or alternatively  chmod 755 counter.pl ./counter.pl genome.txt   counter.pl:   #!/usr/bin/perl  use strict; use warnings;  my $in = $argv[0] || 'genome.txt'; # input file name  open (my $f, '&lt;', $in) or die "cannot open input file $!"; my $n = 0; my %fd = (); my @fd = ();  while (&lt;$f&gt;) {         # trim         s/^\s+//;         s/\s+$//;         next if (!$_); # skip empty lines         my @x = split(/\s+/, $_);         # 1st line, open files         if ( ! $n++)  {            my $fd = 0;            for (@x) {               open ($fd{$_}, '&gt;', "output$_.txt")                  or die ("cannot open file $!")                   if (!exists($fd{$_}));               $fd[$fd++] = $_;            }         }         else { # write data            die ("should have " 
i think i found it:  cat a.xml | grep  "\+[[:space:]]\+"  
don't do this, the directory is owned by libselinux1 and some packages depend on it
i believe you can override the .crt file that git uses like this:  $ git config --system http.sslcainfo "/etc/pki/tls/certs/ca-bundle.crt"   you can disable ssl checks all together (not recommended):  $ git config --system http.sslverify false  
you can use jq to process json files in shell.  for example, i saved your sample json file as raul.json and then ran:  $ jq .message.temperature raul.json  409.5 25.1 409.5 $ jq .message.humidity raul.json  null 40 null   jq is available pre-packaged for most linux distros.  there's probably a way to do it in jq itself, but the simplest way i found to get both the wanted values on one line is to use xargs
the client picks which key to send
the umask, in the way you mean it, is a property of the login shell
edit .bashrc  nano ~/.bashrc   add alias notes='cd ~/project/notes' and save file.  run 
you need to make an uimage with your new kernel: make uimage and copy it to e.g
htop is unaware it is running on a kernel level virtualized environment (dreamhost vps is using vserver technology)
you can always do:  sudo env "path=$path" godi_console   or even:  sudo "path=$path" godi_console   as sudo does treat leading arguments containing = characters as environment variable assignments by itself as well.  as a security measure on debian, /etc/sudoers has the secure_path option set to a safe value. 
sounds like you want to use a real disk, and not a "virtual disk" (aka .vdi for virtualbox).  note: on some systems the "vboxmanage" command is case sensitive and would be spelled vboxmanage.  vboxmanage internalcommands createrawvmdk -filename /my-vbox-real-disk.vmdk -rawdisk /dev/your_disk  "filename" points to a "link" file that you will attach to the virtual guest
what you're asking about isn't really a graphics api, it's just terminal control characters.  there's a lot of history behind it, but terminals back in the day were teletype machines
yes, it is possible to get/extract deb directly from distro's iso image (iso of an installation disk)
the reason your example fails is because of the way the shell's word splitting works
all the tools mentioned in other answers work basically the same way and just differ in presentation
http://www.opensource.apple.com/static/iso/darwinx86-801.iso.gz 
you can't exactly do it with a command line option, but what you can do is redirect stdin like so:  $ ftp -n ftp.backupte4.rsyncbackup.info &lt;&lt; eof &gt; quote user bapte &gt; quote pass b2p7ua2 &gt; put somefile  &lt;-- this is the command you want to execute &gt; quit &gt; eof   or you can put it in a script:  #!/bin/sh ftp -n ftp.backupte4.rsyncbackup.info &lt;&lt; eof quote user bapte quote pass b2p7ua2 put somefile quit eof   finally you could use lftp:  lftp -u bapte,b2p7ua2-e "your command;quit" ftp.backupte4.rsyncbackup.info   http://lftp.yar.ru/lftp-man.html 
after posting it on 3 forums and searching everywhere..
if you don't have write permission in the parent directory, you can't make any changes in the parent directory; this includes deleting the target directory, and creating a symlink.  in any case, ln won't overwrite a directory, even with -f. 
that is almost certainly the extended partition that contains your logical ones
first a clarification, x is not a window manager, it is a windowing system
ps can fit your needs:  ps -eo pid,command,etime   to get information for a specific process:  ps -o command,etime -p pid  
according to archwiki, you can run this to disable crash dump journaling:  # ln -s /dev/null /etc/sysctl.d/50-coredump.conf # sysctl kernel.core_pattern=core  
you can do it with:  awk '{print nf}' filename 
the important things are your data!  programs (and the rest of the system) can always be re-installed from scratch from dvd and your distro's repositories
try this one:  find "$root" -type d -mtime -1 ! -path "$root/bin*" -exec find "{}" -maxdepth 1 -type f -executable  \;   it's not just one find run, however maxdepth should accelerate the result. 
   why is this ethernet here? i am using wifi, not an ethernet.   because you're not capturing in monitor mode; on most operating systems, the only way to get 802.11 headers, rather than fake ethernet headers, on a wi-fi capture is to capture in monitor mode
mint (assuming you are using mint and not mint debian) can use ubuntu repositories
found this method on superuser:   sudo dpkg --remove --force-remove-reinstreq libssl-dev  
via awk  awk 'nr==fnr{a[$4]=$0;next}{print a[$1]}' file2.txt file1.txt   or sorted output via join:  join -o 2.1 2.2 2.3 2.4 -2 4 &lt;(sort file1.txt) &lt;(sort -k4 file2.txt)  
fedora uses as standard the gnome desktop
as per filesystem hierarchy standard, /sbin is a place where     utilities used for system administration (and other root-only commands) are stored.   and yes, iwconfig may be needed by some startup scripts before /usr/ is mounted (if it uses a different partition) - therefore the place for it is not /usr/sbin/. 
you can use screen  suppose you have logged in using ssh, then simply run following command to create screen session called 'mysession'  screen -s mysession  in case your connection disconnected, then you can simply attach your session using:  screen -x mysession  check this link for more information about screen 
you want man 2 open for the c library interface, not man 3 open. it is indeed in manpages-dev (not manpage-dev)
i haven't got dump1090 or a receiver to confirm any of this
as usual?  { eval `ssh-agent`; ssh-add /path/to/my/key; } &amp;&gt;/dev/null  
you could edit the grub executable and replace the title with a string of the same length
i recommend to create a dedicated user for that share and specify it in force user.  create a user (shareuser for example) and set the owner of everything in the share folder to that user:  adduser --system shareuser chown -r shareuser /path/to/share   then add force user and permission mask settings in smb.conf:  [myshare] path = /path/to/share writeable = yes browseable = yes public = yes create mask = 0644 directory mask = 0755 force user = shareuser   note that guest ok is a synonym for public. 
key directories  in unix/linux there are 2 directories that are critical to the system in terms of what makes one system unique when compared to another system
i think the piece you're missing is the interactive form
if you want to do that, you have to mount the desired share to a local directory. for example, if your shared folder is \\10.10.1.1\my-shared-folder, then execute  mount -t smbfs -o username=name,password=password //10.10.1.1/my-shared-folder /mnt/smbshare   and remember, you have to first create the directory where the share will be mounted (in the example above, /mnt/share). 
take a look at the output of lsof | grep 'bash.*cwd'
to flesh out what eightbittony points out about logrotate:  logrotate is a stand alone program you can run from the command-line
yes you can disable it in the crons or remove the package that provides updatedb
end+enter will insert a line after the current one
the obvious solution is to build glibc 2.9, copy that over as well (do not overwrite the existing one!), then run javafx with ld_library_path="/old/glibc/libraries:$ld_library_path" prepended
i found a solution
similar text as ls -ldb * could be produced by (ksh, bash, zsh) $'...', as this:  echo $'\0122016\0122016'   which is just a bunch of new-lines (oct 012, hex 0x0a) and years.  if limited on the shell you could use, then use printf :  printf '\0122016\0122016'   note that the above code does not include the last /
newer syntax for suse linux enterprise 11 sp2 (and opensuse ?)  the best way would be to create a shell script that will call your php script
with zsh and with the mult_ios option on (on by default), in:  echo hi 2&gt;&amp;1 1&gt;/dev/null | cat   the 1&gt; /dev/null | cat is seen as a multiple redirection of echo's stdout.  so echo's stdout is now redirected to both /dev/null and a pipe to cat (as if using tee).  to cancel that multiple redirection, you can do:  echo hi 2&gt;&amp;1 &gt;&amp;- &gt; /dev/null | cat   that is, closing stdout (cancelling the piping) before redirecting to /dev/null  or use a command group or subshell like:  {echo hi 2&gt;&amp;1 1&gt;/dev/null} | cat  (echo hi 2&gt;&amp;1 1&gt;/dev/null) | cat   that way, echo's stdout is only redirected explicitly once (the pipe redirection is applied to the group/subshell and inherited by echo).  or you can disable multios altogether:  (setopt nomultios; echo hi 2&gt;&amp;1 &gt; /dev/null | cat)   alternatively, you could use process substitution instead of a pipe:  echo hi 2&gt; &gt;(cat) &gt; /dev/null   beware however that when job control is off (like in scripts), the cat process will be running asynchronously (as if started with &amp;). 
if you are explicitly looking for hidden files use a pattern that starts with dot,  ls .*vim*   then there's no need for the -a flag. 
iptables can do this easily with the snat target:  iptables -t nat -a postrouting -j snat \     -o eth0 -p tcp --dport 80 --destination yp.shoutcast.com \     --to-source $stream_ip  
this was a result of one of its dependencies: font-config, which sets the default font for many things. 
here's another awk way (which,  i now see, is just an uglier version of @costas's):  $ awk -f'[- ]' '($1~/name/){k=$2}($1~/school/){print k,$nf}' file john ny tom tx lilly la rosy wa     you can also use grep:  $ grep -op '^(name-\k\s+|school.*\s+\k.*)' file | paste - - john    ny tom tx lilly   la rosy    wa   in your particular example, of course, you could just look for capital letters:  $ grep -eo '[a-z]{2,}' file | paste - -     or perl:  $ perl -lne '$n=$1 if /^name-(\s+)/; /^school.*\s+(.+)/ &amp;&amp; print "$n\t$1"' file   or another perl:  $ perl -007ne 'print join "\n", (/name-(\s+?)\s.*?state\s+(..)\n/gsm)' file | paste - -  
try the -e python instead of &amp;&amp; python to get gnome-terminal to run python instead of bash, see its man page 
it wasn't a matter of re-hashing passwords at all
a url linking to file:/// will try to access that file on the user's pc, not the server.  you must link to the file directly through the filesystem as your server allows, whether that be with a relative path ../../srv/protected/book1.pdf or absolute /srv/protected/book1.pdf  make sure your document_root in apache is setup in a way that will allow these directories to be accessed (sym links or the data residing inside of the root). 
you should issue the command:   chroot /chroot_dir /bin/bash -c "su - -c ./yourscript.sh"  
smartmontools is the package you are looking for
it's stored in the rpmdb, with the name of gpg-pubkey and the version as the first 8 hexadecimal characters of the fingerprint. 
guessing from the gentoo wiki, editing ntpd_opts in /etc/conf.d/ntpd probably does the trick (regardless of the question if -g is advisable, no idea). 
basically these are two questions.   you can install any distribution onto a usb-drive or stick
here's a perl script that does the job
this has nothing to do with the desktop environment you are going to use an this answer remains valid.  basically you need to gather the names xorg uses/gives your devices and monitors, then you combine devices and monitors to "seats"
with pcregrep:  pcregrep -mo 'return \[\k[^]]*'   multiline match on return [ followed by a sequence of non-] characters but only output the part to keep (to the right of \k). 
provide (in addition to your main package) separate packages aapt and zipalign
du -ch /home/bzz/.cache*   will give you the total size of all files which starts with .cache in /home/bzz/. 
i would have said that it is simply tail call optimization, but in fact (as the last link points out), bash doesn't optimize tail calls
you need to quote the variable expansion in double quotes:  mkdir "$i"  (using single quotes '$i' would create a directory named $i)  if the names can start with -, you should also add -- after the last option argument, indicating that all other arguments are not options, which means in this case they are  directory names:  mkdir -- "$i"  or, with option -v (verbose) for example:  mkdir -v -- "$i" 
a small further investigation learned that the base versions are stored in the kernel source in /usr/src/etc
if you squint, vm security looks a lot like lan host security
well, openssh private keys with empty passphrases are actually not encrypted
with grep:  grep -en '.{12}' file   for lines at least 12 characters long.  with several files:  find 
/usr/etc is usually unused on most systems
given that the repository you're interested in is in your apt sources, you can find the information on the packages available there in the files apt downloads; for the line  deb http://ftp.de.debian.org/debian jessie main non-free   these would be respectively   /var/lib/apt/lists/ftp.de.debian.org_debian_dists_jessie_main_binary-amd64_packages /var/lib/apt/lists/ftp.de.debian.org_debian_dists_jessie_non-free_binary-amd64_packages   (assuming you're on amd64)
you can do something like,  0 0 * * 5  /usr/bin/python /var/scripts/plw.pl &amp;&amp; /bin/bash /path/to/run_once.bash   note : &amp;&amp; /bin/bash /path/to/run_once.bash will only run if previous command run successfully
you could put the read and your case in a while loop and break out of it when the condition is satisfied:  while : ; do   echo "yes or no?"   read ans    case $ans in     [yy]*)         echo "yes"         break         ;;     [nn]*)         echo "no"         break         ;;     *)         echo "yes or no only"         ;;   esac done   the while : ; do ..
they are on the two keys to the right of p: pressing the first with alt gr produces "«", the second produces "»". 
if you can pxeboot your vm (this will involve setting up dhcp and tftp if you haven't already done so) then you could boot up a rescue cd image (imo clonezilla makes an excellent rescue/backup/recovery cd), and back it up.  pxe boot isn't strictly necessary, either
the steps i was doing were right at all
"a package manager is working" means that something is holding a lock on /var/lib/dpkg/lock and/or/var /cache/apt/archives/lock
yes
go to this address and check: https://helpx.adobe.com/flash-player.html  also, you youtube you could go to https://www.youtube.com/html5 and enable the html5 player and youtube will work better. 
you can easily associate the .py files with idle
in %.x : %.y kind of rules, % acts like a indicator of common substring
as you written in the comment code line, the following is working:  bytecount=$( exec 3&gt;&amp;1 ; dd if=$file bs=1 skip=$skippedbytes | tee -a &gt;(wc -c &gt;&amp;3) -a $file.output | ssh sshconnection 'cat - &gt;&gt; /remote/dir/mytarget.txt.output' &gt; export.output 2&gt;&amp;1 ; 3&gt;&amp;1 )   so adapt this knowledge and use this refactoring:  exportfile(){    file=$1    skippedbytes=$2    useratserver=$3    targetdir=$4    targetfile=$5    rm export.output     bytecount=$( exec 3&gt;&amp;1 ; dd if=$file bs=1 skip=$skippedbytes | tee -a &gt;(wc -c &gt;&amp;3) -a $file.output | ssh ${useratserver} "cat - &gt;&gt;$targetdir/${targetfile}" &gt; export.output 2&gt;&amp;1 ; 3&gt;&amp;1 )     echo "read bytes: $bytecount"    cat export.output  }  exportfile mysource.txt 9 sshconnection /remote/dir mytarget.txt  
you should do the following:  apt-get purge mysql-server mysql-common mysql-client-&lt;version&gt; rm -rf /var/lib/mysql rm -rf /etc/mysql*   then you can reinstall in full. 
based on mel boyce's answer, here's what worked for me
most dot files have a name that resembles the application that uses it
in addition to the ps1 environment variable, the prompt_command environment variable also affects your prompt. from the bash man page:     if set, the value is executed as a command prior to issuing each primary prompt   it is that command that is adding the unwanted content to your prompt
update instead of 331 version, check what's current version of nvidia-current package
that is unlikely going to work, as the suggestion in the comment is both incomplete (you cannot just specify some directory) and incorrect (--env:... should be -env:..
add this repo:  $ sudo add-apt-repository ppa:bumblebee/stable $ sudo apt-get update   then install bumblebee:  $sudo apt-get install bumblebee  
there is no crond.service on arch linux
i did as schaiba said, so:   backup your sensitive stuff (for me only /home dir) reinstall operating system  
10 minutes is very much long-term as far as linux's scheduler is concerned
you're not subscribed to redhat updates, therefore you will not be receiving any updates to any of the core packages
just handle it like you handle the others that take an argument (image and version)
a local cd can act as an apt repo, just as if it were a distant server.  if you don't want apt-get to search the cd, comment out the relative line in /etc/apt/sources.list. 
i had the same problem on linux mint 13 and the same output on xev, namely control_l + f was mapped to control_l
i believe there may be some files still held open by some processes
tl;dr  the shellshock vulnerability is fully fixed in   on the bash-2.05b branch: 2.05b.10 and above (patch 10 included) on the bash-3.0 branch: 3.0.19 and above (patch 19 included) on the bash-3.1 branch: 3.1.20 and above (patch 20 included) on the bash-3.2 branch: 3.2.54 and above (patch 54 included) on the bash-4.0 branch: 4.0.41 and above (patch 41 included) on the bash-4.1 branch: 4.1.14 and above (patch 14 included) on the bash-4.2 branch: 4.2.50 and above (patch 50 included) on the bash-4.3 branch: 4.3.27 and above (patch 27 included)   if your bash shows an older version, your os vendor may still have patched it by themselves, so best is to check.  if:  env xx='() { echo vulnerable; }' bash -c xx   shows "vulnerable", you're still vulnerable
ubuntu is fully up to the task
the command ip link delete dummy0 is what you would use to delete it at the command line
you could use fail2ban for that! fail2ban is a program that scans logfiles for certain events and then adds firewall rules according to those events.  http://www.fail2ban.org/wiki/index.php/howto_fail2ban_with_modsecurity2.5 
the dpkg man page has     package flags          reinst-required                 a package marked reinst-required  is  broken  and  requires    reinstallation
just put double quotes around output file name:  awk -f: '$3 &gt; 22 { print $0 &gt; "file44" }' file  
as the final edits revealed, the problem is unrelated to the dollar sign, but is caused by the content of deststr, which is not 192.168.1.3 192.168.1.4 but rather two lines, one containing only 192.168.1.3 and the other containing only 192.168.1.4, both lines bveing terminated with a newline character
you are correct in saying that, when you open a terminal, you are using a shell
posixly:  find /var/warehouse/* -type f \( -name "*.avi" -o -name "*.mkv" \     -o -name "*.flv" \     -o -name "*.mp4" \) \     -exec basename {} \;   or you can combine find with sed:  find /var/warehouse/* -type f \( -name "*.avi" -o -name "*.mkv" \     -o -name "*.flv" \     -o -name "*.mp4" \) | sed -e 's!.*/!!'  
i don't have an rsnapshot setup to test this on
the short answers are, yes, it was done for compatibility (lots of programs referenced /bin/sh and /bin/ed), and in the early days /bin and /usr/bin contained totally disjoint sets of files
ps does not hide the password
the issue with this was that the package that provided the .so file was not installed.  yum provides [.so] yum install [name of providing rpm]   alternatively using yum dependencies are resolved on their own, so  yum install [package]   should have been sufficient.  basically when possbile, use yum not rpm. 
i found projects called linux serial sniffer, jpnevulator, and moni
alias useryyy='sudo su useryyy -c "cd /a/path/that/only/useryyy/has/access; /bin/bash"'  
this error happens because you have some yum repository configuration in /etc/yum.repos.d/ that lists a gpg key like this:  gpgkey=file:///etc/pki/rpm-gpg/rpm-gpg-key-puias  this configuration is telling yum that the gpg key for the repository exists on disk
how about  awk '   begin {fs="\n"; rs="\n\n+"}   {for (i=1;i&lt;=nf;i++) a[i] = a[i] == ""? $i : a[i]"\t"$i; next}   end {for (i in a) print a[i]} ' file.ex   testing:  awk ' &gt;   begin {fs="\n"; rs="\n\n+"} &gt;   {for (i=1;i&lt;=nf;i++) a[i] = a[i] == ""? $i : a[i]"\t"$i; next} &gt;   end {for (i in a) print a[i]} &gt; ' file.ex efifc1a nhdw4s  jfhg hygg4a  wesf3a  gsfar hdy5d   fjfhyr     if you're not stuck on using awk, you could do it using autogen's columns command and the transpose command described here transposing rows and columns e.g
a system can have a uefi firmware and still boot os in legacy bios mode
the easiest way is to use grub-emu
the simplest way with find is:  find / -daystart -mtime +41 -mtime -408 \   -printf "%m %n %u %g %10s %ty-%tm-%td %ta %th:%tm:%ts %h/%f\n" | awk '($7=="fri"){print}'   adjust the -printf as required, i've made it look close to ls -l here. %t (and %a %c) let you use strftime() formatting for timestamps, %ta being the day of the week
   jvm startup time is quite slow, and incurs a heavy toll on scripting 
if you know you have gnu find, use -quit  to make it stop after the first match.  portably, pipe the output of find into head -n 1
debian contains too much software for a single dvd
i managed to get it going with the steps on the ubuntu forums, for clarity here is what i did:   sudo apt-get install gtk-recordmydesktop pavucontrol opened the pulse audio volume control dialog: applications &gt; sound &amp; video &gt; pulseaudio volume control opened gtk-recordmydesktop in gtk-rmd start a recording in volume control goto the recording tab and change the recordmydesktop entry to 'monitor of '   this is what seems to have worked for me. 
two things you need to know:  1) systemd boots towards the target given by "default.target"
just found the answer myself (after googling hours to find the answer in a small but very important sentence in a private blog post about ubuntu):  disable (means stop the daemon or kill the process) networkmanager (or in some distros network-manager) because it does take control over the (w)lan adapters, blocking it for other programs.  after doing this, hostapd can create the access point by initialising nl80211 correctly. 
well, at least keeping passwords in git is surely a bad idea.  it'd be better using .config file for that
when you type tmux in a shell, the shell looks for an executable called tmux in one of the directories enumerated in the path variable (it's a colon-separated list of directories)
if you could call mknod arbitrarily, then you could create device files owned and accessible by you for any device
you'll need the remote hands to get into the system via the console and run telinit 3 or telinit 5 if either of those were the runlevels you were using previously. 
netcat doesn't log anything.  redirecting the output of netcat to a file breaks your setup because that output is supposed to go to the ssh process
try using awk:  awk -f'"' '{ print $2 }' conf.txt  
given this inputfile:  x1 a1,b1,c1,d1 x2 a2,b2,c2,d2 x3 a3,b3,c3,d3 x4 a4,b4,c4,d4   with sed (using bash ansi-c quoting for clarity):  sed $'s/,/ +\\\n\t/g' inputfile     x1 a1 +     b1 +     c1 +     d1 x2 a2 +     b2 +     c2 +     d2 x3 a3 +     b3 +     c3 +     d3 x4 a4 +     b4 +     c4 +     d4   sed needs to see a backslash before the newline, otherwise you get an "unterminated s command" error 
the easy answer is to define a macro which gets substituted into both locations.  %define my_common_requires package-1, package-2, package-3  buildrequires: %{my_common_requires} requires:      %{my_common_requires}   this also lets you manually define something that needs to be in one of the two lines but not both. 
ubuntu can run on ram, but it requires some manual changes:  https://wiki.ubuntu.com/boottoram 
with gnu awk:  tail -fn+1 ~/.bash_history | awk '   /^#/{printf "%-4d [%s] ", ++n, strftime("%f %t", substr($0, 2)); next}; 1'  
yes, you can accomplish this by adding a menu entry to the grub boot loader menu.  you can add a custom grub menu entry by editing /etc/grub.d/40_custom,  example of custom menuentry:   exec tail -n +3 $0 # this file provides an easy way to add custom menu entries
this behaviour is called "programmable completion"
your setup seems ok.  but you may need to modify the selinux file context database, or change the selinux type of certain file
perl has a nifty "paragraph mode" (-00) where records ("lines") are separated by a blank line instead of a single \n character
solaris 10's default manpath is /usr/share/man
let us look into the performance diagram to understand the various layers in which netstat command is useful for debugging
the one thing i use that the initial space for is if i want to be able to restart an older commandline that starts with the same command  (!ls e.g.) and i need to be able to re-execute the older one, but not the newer.  the other time i use it is in the (seldom) cases i give a password on the commandline, i rather not have those stored in the .bash_history file once i exit bash. 
found in man man there is environment variable man_keep_formatting that need to be non empty, but it's not on that server. 
the application gmail uses for chat is actually googletalk (or hangouts, or whatever they've rebranded it to this week); from there, it's quite simple to deduce that the protocol you want is, in fact, googletalk
rsh is remote shell and it is unencrypted, that's why you should disable it.  i don't know which os you are talking about, but for rhel (like sr_ already stated) edit /etc/xinetd.d/rsh and set disable = yes.  after that restart xinetd and you're done.  though i think, rsh should be disabled by default
i managed to find a workaround using the prompt_command variable and the rcfile.txt file mentioned in the question
i realized that this happens only when i have a webex session
a crontab created with crontab -e and listable with crontab -l should not have a user specified for the command
i would start it normally and use "renice" afterwards...  however i was able to make a quick hack together with "su" which works:     sudo nice -n -20 su -c command_to_run user_to_run_as   (if you don't have to give sudo a password - perhaps because you've already just given it - you may add an "&amp;" to put the whole thing in the background.)  since you already become root with the sudo-command, su won't ask you for a password
argh and grumble
  there are two classes of builtins:   some commands have to be built into the shell program itself because they cannot work if they are external.  cd is one such since if it were external, it could only change its own directory; it couldn't affect the current working directory of the shell
the meaning of the term channel is explained earlier on the same page under the heading "file structure related system calls":      a channel is a connection between a process and a file that appears to the process as an unformatted stream of bytes   as in unix "everything is a file", this includes file descriptors to regular files, but also different kinds of sockets, pipes, fifos etc. 
i found out why by redirecting the output of the ps command to a file
you'll need to determine where in the disk image your partition starts
this sounds like the user you're running has the default group set to yuri
all the answers are great but i resolved this problem using a different approach, i used the command to add only one default gateway, but fail if there is already one
since you mention synaptic: debian puts all documentation under /usr/share/doc/package, except for man pages and info manuals
you don't
virtualbox is using a virtualised video card and not any of the physical video cards in your machine
open system -&gt; preferences -&gt; keyboard shortcuts. disable (or reset) the show the panel's "run application" dialog box.  now add a new shortcut and set alt+f2 to the command you would like to start
your domain's dns (a record) has to point to your hosting ip
just use the different perl interpreter
i finally found the best method for me to start kali without reinstalling grub to my hdd
something like following   path {     reaches = 10.132.165.95/255.255.0.0     server = 127.0.0.1     server_type = 5     server_port = 1084 }  
use the -t option:   -t, --files-from file        get names to extract or create from file   note that it doesn't work with ~ as alias for home directory, you need to specify the folder explicitly. 
you can install grub (instead of the whole os) on a usb stick or cd and use that for booting
get the source  wget "http://www.sentex.net/~mwandel/jhead/jhead-2.97.tar.gz"   untar the source  tar xzf jhead-2.97.tar.gz   or, get and untar the source in one step  curl "http://www.sentex.net/~mwandel/jhead/jhead-2.97.tar.gz" | tar xz   now you have a directory called jhead-2.97
the find command is the primary tool for recursive file system operations. use the -type d expression to tell find you're interested in finding directories only (and not plain files)
you really can't unless you have a special usb chip that is able to switch from being usb host to usb guest
your diagram is good except for the labels on the vertical black line between the bridge and "dell pe860"
linux can read (and write) to many filesystems, including ntfs, which is likely how your windows partitions are formatted
defining aliases or functions to simplify commands you use often is the standard way
this is the command to install say on ubuntu:  sudo apt-get install gnustep-gui-runtime   on other distros, you have to replace apt-get with yum or whichever package manager you have.  how i found it: if you run any command that is not installed in ubuntu (bash), then it will automatically tell you how to install it
main advantages amd64 over i386   64-bit integer capability additional registers additional xmm (sse) registers larger physical address space in legacy mode sse/sse2   for more details look at wiki page.  what about performance?  actually performance will grow up to 20-30% in general case
do you have an intel graphics chipset? i was getting what sounds like the same problem on my thinkpad x200s running ubuntu 10.10, and this workaround (from 2008!) fixed it for me: http://ubuntuforums.org/showpost.php?p=6105510&amp;postcount=12 
from the human monitor interface of qemu (ctrl-alt-2 if using sdl output), issue:  info qtree   for each virtio-scsi disk, you'll see:          bus: virtio-bus           type virtio-pci-bus           dev: virtio-scsi-device, id ""   and for virtio-blk:          bus: virtio-bus           type virtio-pci-bus           dev: virtio-blk-device, id ""   from within the guest, if a linux guest,  $ ls -l /sys/class/block/?d[a-z] lrwxrwxrwx 1 root root 0 aug  2 21:16 /sys/class/block/sda -&gt; ../../devices/pci0000:00/0000:00:04.0/virtio0/host2/target2:0:0/2:0:0:0/block/sda lrwxrwxrwx 1 root root 0 aug  2 21:16 /sys/class/block/vda -&gt; ../../devices/pci0000:00/0000:00:05.0/virtio1/block/vda   the first one above is a virtio-scsi, the second a virtio-blk. 
warning: by the end of this answer you'll probably know more about linux than you wanted to  why reboot and poweroff require root privileges  gnu/linux operating systems are multi-user, as were its unix predecessors
i haven't myself checked that out, but you should be able to blacklist the autofs4 module.  that means you should add  blacklist autofs4   into a modprobe config file, e.g
libxml2 is the runtime shared library, suitable for running already-compiled programs that use that library
the problem seemed to be that the os on my machine was the same as the live image on the thumb drive i used to install it. when i called calamares it was attempting to reinstall the entire operating system again. the reason for the disk space issue was that calamares needed root privileges.  my takeaway from this is that my distro (maui) simply isn't quite ready to be used out of the box and requires manual building/installation of packages. 
solarized gives very specific colours
use unzip -p:  unzip -p 2015-11-21-raspbian-jessie.zip 2015-11-21-raspbian-jessie.img | dd of=/dev/sdb bs=1m  
the simple way is to use rm -i the way @orion describes
   many online references often talk about color names that are not defined on my system   those probably are defined, but they are x11 colors; once upon a time you could find them in /lib[64]/x11/rgb.txt
did you try adding the -c parameter?  excerpt from wget manual:     -c   --continue      beginning with wget 1.7, if you use -c   on a non-empty file, and it turns out   that the server does not support   continued downloading, wget will   refuse to start the download from   scratch, which would effectively ruin   existing contents
just edit the config file /etc/dhcp/dhclient.conf and add also request  # custom dhcp option (72 = www-server) also request www-server;   the value is avaible in /var/lib/dhcp/dhclient.lease 
what you're doing is bad
find 
i don't know the answer to the first part of your question
i never had much luck with the abstracted configurations, mainly due to my lvm + mdadm setup and not updating my kernel the "distro way"
you can attach to the session from "another terminal" (including another ssh connection)
ls and many other programs detect whether their output (or sometimes input) is attached to a terminal by calling the c function isatty(stdout_fileno)
tl;dr  find "$dir" ! -type l -print0 |   sudo -u "$user" perl -mfiletest=access -l -0ne 'print if -r'   you need to ask the system if the user has read permission
the first error is because you're passing both -h newc and -c
always use double quotes around variable substitutions and command substitutions: "$foo", "$(foo)"  if you use $foo unquoted, your script will choke on input or parameters (or command output, with $(foo)) containing whitespace or \[*?.  there, you can stop reading
i have not tried it, but here's a link for bluetooth networking with linux, or this tutorial (both found via a google search for bluetooth networking linux). 
$ pkill xfce4-panel done !  in order to save it, you should save your session at the log out.  and i just found that on the xfce wiki:     how do i disable the taskbar in xfce 4.2?      just don't run it at startup…         if you use the session manager, kill the taskbar, save your session   on logout, and the taskbar will be gone when you'll log back   in.   if you don't use the session manager, comment out the xftaskbar4 line   in your $sysconfdir/xdg/xfce4/xinitrc or ~/.config/xfce4/xinitrc.   if you use the session manager and want to remove the taskbar   system-wide, comment out the taskbar line in the   $sysconfdir/xgd/xfce4-session/xfce4-session.rc file.      p.s , the sysconfdir is /etc/xdg/..... in my distro (arch), but i think that it is on every distro.  another solution would be (if you are using some variant of ubuntu), to add to your ~/.config/xfce4/autostart.sh the following:  if [ "$(pidof xfce4-panel)" ]; then     killall xfce4-panel &amp; fi  
you could start screen with the -l option
the systemd-journald man page explains how journal access control is done:  journal files are, by default, owned and readable by the "systemd-journal" system group but are not writable
sed 's/ \.\..*$//' /path/to/file should work:   \.\
my view:   operating system (linux, bsd)  graphic server (x)  login manager (gdm, xdm, kdm, ...)  session manager (gnome-session-manager, kde-session-manager, etc)  window manager file manager applications       what you call desktop environment if in fact an association of one session manager, one window manager and one file manager (and some other hardware bindings manager, like network manager client and audio daemon client)...  in practice, you could even mix everything...  a session is the father process of many child process who behind to one user from the given login time, upto his logout
this isn't doing what you think it's doing
lines in the known_hosts file are not encrypted, they are hashed
if it refers to commands run just recently, a more efficient way is to reference them with negative numbers:  !-4; !-3; !-2; !-1   also, once you do it, your last history entry will contain the whole chain of commands, so you can repeat it with !!.    edit: if you haven't already, get familiar with the great builtin function fc, mentioned by gilles
the easiest is probably to just make a new window, it will start in the directory where screen was started by default.  alternatives include looking at the process' cwd (e.g
if you install gnu parted (libparted), you get an extra command line progam parted.     gnu parted manipulates partition   tables
does debian really pick up a changed hostname if ps1 is re-exported, as the other answers suggest? if so, you can just refresh it like this:  export ps1="$ps1"   don't know about debian, but on os x mountain lion this will not have any effect
from my manpage (on a macos 10.11 machine)   -size n[ckmgtp]          true if the file's size, rounded up, in 512-byte blocks is n
groups are inherited by a process from its parent
check your path
you can get current epoch time with   date  "+%s"   you can also convert any time format to epoch time:  date -d "${my_time}" "+%s"   and these epoch times you can substract.  having the line with bardate: 2017-11-31 in a variable line, you can extract the date using:  my_time=$(echo $line | cut -d: -f2)  
solution to question [depreciated]  so first do  find 
a way of replacing a binary with another in debian such that it survives updates on the packages (for instance, replacing the init file of a bind package), is doing a file diversion
when you start a root bash shell as sudo -i or sudo -s or sudo su (provided root's login shell is bash) or sudo bash, the original user is available as $sudo_user.  but when started as sudo su -, the environment is cleared by su, so you'll have to find another way to find the original user.  one way, if you've got the pstree command could be:  original_user=${sudo_user:-$(pstree -alsu "$$" |   sed -n "s/.*(\([^)]*\)).*($user)[^(]*$/\1/p")} export histtimeformat="&lt;%f %t&gt; (${original_user:-$user}) [$$] " export prompt_command='builtin history 1 &gt;&gt; /var/log/root.log'   the idea being to parse the output of pstree -alsu "$$" which looks like:  init---xterm(user)---zsh---sudo(root)---su---bash---pstree   to extract the user. 
put only 127.0.0.1 as a name server in /etc/resolv.conf, and run a dns cache locally
unfortunately, 'portable' is usually a stronger requirement than 'posix-compliant' for shell scripts
with gnu, freebsd or os/x date (or date implementations that use the system's libc's strftime() where that is the gnu libc), adding hyphen - after % prevents numeric fields from being padded with zeroes:  $ date +'%y%-m%d' 2015120   from man date on a gnu system:     by default, date  pads  numeric  fields  with  zeroes
if the output is as above, it's on the hard disk
you can filter easily with awk, checking if the last field equal /, then print the corresponding 4th field:  df | awk '$nf == "/" { print $4 }' &gt;&gt; output   or:  df / | awk 'nr == 2 { print $4 }' &gt;&gt; output  
i have 2 ethernet ports from 2 devices with the same vendor/device id
as pointed out in an answer to a related question, wget's documention says:     note, too, that query strings (strings at the end of a url beginning with a question mark (‘?’) are not included as part of the filename for accept/reject rules, even though these will actually contribute to the name chosen for the local file
think this is what you want using gnu sed   sed -n '/^pattern_start/,/^pattern_end/{          //!{h;/^record/!{x;s/\n\([^\n]*\)$/ \1/;x}};          /^pattern_start/{h};/^pattern_end/{x;p;x;p};d          };p' file   explanation  sed -n #non printing   '/^pattern_start/,/^pattern_end/{ #if the line falls between these two patterns execute the next block    //!{   #if the previous pattern matched from the line above is not on matched(so skip           the start and end lines), then execute next block          h;         #append the line to the hold buffer, so this appends all lines between         #`/^pattern_start/` and `/^pattern_end/` not including those.          /^record/!{         #if the line does not begin with record then execute next block              x;s/\n\([^\n]*\)$/ \1/;x             #swap current line with pattern buffer holding all our other lines              #up to now.then remove the last newline
this answer assumes that your csv file has one line per row, meaning that there are no continued lines
according to gilles, the -i option only ignores a line if nothing else inside that set matches except for the match of -i
i believe that this will do what you need
personally, i would do the whole thing in perl:  $ perl -00ne '/^(student_\d+)/ &amp;&amp; $count{$1}++;                /name:\sa/ &amp;&amp; $as++;                /status:\s*pass/ ? $pass++ : $fail++;               end{                 print "$_ : $count{$_}\n" for keys(%count);                  print "pass: $pass\nfail:$fail\n";                  print "student names starting with a: $as\n"             }' file    student_2 : 1 student_1 : 1 student_50 : 1 pass: 2 fail:2 student names starting with a: 2   if you insist on separate commands per operation, you could use:  $ awk '/^student_/{a[$0]++} end{for(s in a){print s,a[s]}}' file    student_1 1 student_2 1 student_50: 1     $ perl -ne '$pass++ if /:\s*pass/; $fail++ if /:\s*fail/;      end{print "pass: $pass\nfail: $fail\n"}' file    pass: 2 fail: 2     $ echo "student names starting with a: $(grep -c "^name:\s*a" file )"   student names starting with a: 2  
the built-in delay is to slow down the process of password guessing
the text you quote already explains why time is a keyword:     the use of time as a reserved word permits the timing of shell builtins, shell functions, and pipelines
there are various solutions to this explained in an existing post:  http://stackoverflow.com/questions/690386/writing-a-vim-function-to-insert-a-block-of-static-text 
what's wrong with setting manually?  ps1="xb@\h:\w\$ "  
you need libcap-progs  sudo zypper install libcap-progs  
you should first familiarize yourself with freebsd and building/getting ports
since you've got lvm and appear from what you've shown have a fair bit of unused space in your volume group you should be able to just use lvcreate to add another volume and mount it at /data
more similar qs with more answers worth attention:    http://stackoverflow.com/q/3859710/94687 http://stackoverflow.com/q/4410447/94687 http://stackoverflow.com/q/4249063/94687 http://stackoverflow.com/q/1019707/94687   some of the answers there point to specific solutions not yet mentioned here
if your image is smaller than the usb drive then you need to make sure you read back just that size of data from the drive, otherwise all the remainder of the drive will be added into the sha256 and create a different result.  e.g.  $ ls -l tst.iso                                                                 -rw-r--r-- 1 root root  jul  1 14:58 tst.iso  $ /usr/bin/sha256sum tst.iso 49bc20df15e412a64472421e13fe86ff1c5165e18b2afccf160d4dc19fe68a14  tst.iso  $ dd if=tst.iso of=/dev/sdg bs=1m 1024+0 records in 1024+0 records out 1073741824 bytes (1.1 gb) copied, 200.066 s, 5.4 mb/s   when we read this back we need to make sure we only read the 1,073,741,824 bytes we wrote
that is done to align the data segment on a page boundary (which automatically forces it to be in a different page from the text segment)
tl,dr: i recommend symlinks.  if you mount a partition to a mount point that isn't in the root partition, you must take care to mount the host partition first and unmount the host partition first
i guess you got that one letter into the file with echo a &gt; file or vim file, which means, you'll have that letter and an additional newline in it (two characters, thus two bytes)
not an answer, but a tip: use "true" and "false" commands instead of testing for string equality:  backwards=false if [[ some condition ]]; then backwards=true; fi  if $backwards; then   do something else   do something else fi  
if you need to backup just the system configuration (which at the end of the day usually is about third of the content of a system), all you should need is a list of packages installed + their configuration
most of these issues came because i was using a private repository linked to sid as described here
i've experienced this a lot in oracle pl/sql. trying installing and using rlwrap and see if it helps:  http://linux.die.net/man/1/rlwrap 
installing pulseaudio from stretch(testing) release &amp; reinstalling pulseaudio solved the problem
developed a oneliner for this:  $ apt-rdepends --dot -r systemd | perl -ne 'our %chains; if(m!"([^"]+)" -&gt; "([^"]+)"[^"]*;!) { my $c="$2 $chains{$2}"; $chains{$1}=$c; print "$1 $c\n" }'  | grep '^monodevelop ' reading package lists..
   now bin-xyz is a broken link   the reason for that is hopefully obvious: either .. has to refer to the actual parent directory or else it would be completely ambiguous
it should work if you specify the shebang in your groovyrun script.  as a quick experiment, create shell1 containing  #!/bin/sh echo shell1: "$@" sh "$@"   and shell2 containing  #!/.../shell1 echo shell2: "$@"   (with the correct path to shell1); running shell2 hello then produces  shell1: ./shell2 hello shell2: hello   as you can see, the parameters passed to each script look correct in both cases. 
there's only a gfortran specific option called -j, but this doesn't make sense combined with a number
assuming that each occurrence of *some text* is on a single line (ie
you can pipe tar across an ssh session:  $ tar czf - &lt;files&gt; | ssh user@host "cd /wherever &amp;&amp; tar xvzf -"  
assuming you know python, and if you don't today is a good day to start...the documentation for the apt python bindings has a worked example which is relevant, though it may not be a complete solution.  apt-get install python-apt python-apt-doc   and look at /usr/share/doc/python-apt-doc/examples/missing-deps.py
touch __init__.py views.py models.py admin.py 
it seems likely (though there may be caveats) that this will distiguish between flash-based storage devices and traditional hard disks:  is_compact_flash () {     hdparm -i $1 | sed -n '\_commands/features:_,\_security:_p' | \         grep -q cfa &amp;&amp; return 0 || return 1 }  disk=/dev/sda if is_compact_flash $disk; then     echo "$disk is a compact flash disk" else     echo "$disk is not a compact flash disk" fi   edit: added sed command to guard against model or serial containing cfa. 
i did not download it and not sure if this is everything but you should be able to get started with it
you should do it the other way round, run script inside screen:  screen -dm bash -c 'script -c "python test.py" output.txt'  
assuming that backslashes themselves are also escaped in your strings (as \x5c, presumably), which udev seems to do, you should use bash's printf builtin:  printf -v translated '"%b"' "$id_fs_label_enc"   if we try that on your example string:  $ id_fs_label_enc='new\x20folder' $ printf -v translated '"%b"' "$id_fs_label_enc" $ echo "translated to: '$translated'" translated to: '"new folder"'   we get the transformation you wanted.  printf -v assigns the result of a standard printf-style translation into a variable, and the %b format is a bash extension performing backslash escape sequences
this is just a thought and has more than one downside, but it might be usable enough anyway.  how about creating an image file and a filesystem inside it on top of ramfs, then mount the image as a loop device? that way you could limit the size of ramdisk by simply limiting the image file size
use a meta package (e.g
there's two layers: the pattern matcher, and tcl
you can use the yum deplist command to generate a list of package dependencies:  $ yum deplist bind   dependency: /bin/bash    provider: bash.x86_64 4.3.39-5.fc21   dependency: /bin/sh    provider: bash.x86_64 4.3.39-5.fc21   dependency: bind-libs(x86-64) = 32:9.9.6-10.p1.fc21    provider: bind-libs.x86_64 32:9.9.6-10.p1.fc21   dependency: coreutils    provider: coreutils.x86_64 8.22-22.fc21 [...]   grab the provider: lines from this for a list of packages:  $ yum deplist bind | awk '/provider:/ {print $2}' | sort -u bash.x86_64 bind-libs.x86_64 coreutils.x86_64 glibc.i686 glibc.x86_64 grep.x86_64 krb5-libs.x86_64 libcap.x86_64 libcom_err.x86_64 libxml2.x86_64 openssl-libs.x86_64 shadow-utils.x86_64 systemd.x86_64 zlib.x86_64   send this output to yum install to install the packages:  $ yum deplist bind | awk '/provider:/ {print $2}' | sort -u |   xargs yum -y install  
so far the only way i found to change fat volume name whit lower cases is to edit it whit a hex-editor (copy the first few sectors whit dd to a temp file, edit it and copy it back)
here's one way with sed:  sed -e '/with_ajax_wait/,/end/{       # if line is in this range h                                     # append to hold space /end/!d                               # if it doesn't match end, delete it //{                                   # if it matches s/.*//                                # empty the pattern space x                                     # exchange pattern space w
if understand what you're wanting, using read should accomplish your goal
use this:  alias ipy3='ipython3'  
you could boot up in single user mode to get a root console
racket has a concept of collections
you can set the mysql root password in your bootstrap file by adding debconf-set-selections commands before running your apt-get install:  #!/usr/bin/env bash  debconf-set-selections &lt;&lt;&lt; 'mysql-server mysql-server/root_password password mysuperpassword' debconf-set-selections &lt;&lt;&lt; 'mysql-server mysql-server/root_password_again password mysuperpassword' apt-get update apt-get install -y mysql-server   i presume this to work on any debian based system
it looks at the data on the partition, similar to what file -s /dev/partition does
to remove the whole block of lines beginning with one including your match up to the line occurring immediately previous to the next occurrence of [t1114base you can do the following:  sed -e'$!n;/applicationstate.*\n/,/\n.*\[t1114base/!p;d' &lt;in &gt;out   it is fairly simple to understand how this works
i have used sardu for that job
use sed as follows:  $ echo "foobarbazblargblurg" | sed 's/.\{4\}/&amp; /g' foob arba zbla rgbl urg  
tmux and screen have different models so there is no exact equivalent.  in screen terms, a split lets you display multiple windows at the same time
try cd'ing out of the emptydir and running lsof +d /path/to/emptydir on it to see what has it open
just use the journalctl command, as in:  journalctl -u service-name.service   or, to see only log messages for the current boot:  journalctl -u service-name.service -b   for things named &lt;something&gt;.service, you can actually just use &lt;something&gt;, as in:  journalctl -u service-name   but for other sorts of units (sockets, targets, timers, etc), you need to be explicit. 
the problem you're running into is a one where the name of the directory can change depending on the user's selected language.  in the general case you should be able to run  xdg-user-dir desktop   to get the path to the current user's desktop directory. e.g.  % xdg-user-dir desktop /home/sweh/desktop   scripts should take this into account when looking for the desktop folder (e.g
you cannot.  a program in binary form can only be executed in a machine with a compatible isa (instruction set architecture, see wikipedia article)
try doing it like this instead:  display=:0 gedit   or even, just:  export display=:0   before you run your commands.  the reason you see cannot open display: with no display specified after the : is because $display is not set, as ssh isn't aware you have an x session running.  you said you don't want to use ssh -x (x11 forwarding), but in case others end up here, you might also look into using x11 forwarding, if you want the gui application to display on your local (client) machine rather than the remote (server) machine. 
this is a start:  $ ls | grep -o -w '\w\{3\}' png png log rdb png gfd gpg pub pdf out log gpg key txt txt the com pem vms $   the count is  $ ls | grep -o -w '\w\{3\}' | wc -l 19  
as a result of the pipe in x | y, a subshell is created to contain the pipeline as part of the foreground process group
depending on the user you are using, you may need to type su - or sudo first to get root privileges.  type lsblk:  &gt; lsblk name   maj:min rm   size ro type mountpoint sda      8:0    0 111,8g  0 disk  ├─sda1   8:1    0  1020k  0 part  ├─sda2   8:2    0    41g  0 part  ├─sda3   8:3    0    11g  0 part  ├─sda4   8:4    0    19g  0 part / ├─sda5   8:5    0  33,6g  0 part  ├─sda6   8:6    0     2g  0 part  ├─sda7   8:7    0     2g  0 part  └─sda8   8:8    0     2g  0 part    insert an usb drive and type lsblk again.  &gt; lsblk name   maj:min rm   size ro type mountpoint sda      8:0    0 111,8g  0 disk  ├─sda1   8:1    0  1020k  0 part  ├─sda2   8:2    0    41g  0 part  ├─sda3   8:3    0    11g  0 part  ├─sda4   8:4    0    19g  0 part / ├─sda5   8:5    0  33,6g  0 part  ├─sda6   8:6    0     2g  0 part  ├─sda7   8:7    0     2g  0 part  └─sda8   8:8    0     2g  0 part  sdb      8:16   0 931,5g  0 disk  ├─sdb1   8:17   0     4g  0 part  ├─sdb2   8:18   0     4g  0 part  ├─sdb3   8:19   0     4g  0 part  └─sdb4   8:20   0 919,5g  0 part   identify one partition inside the usb drive, on this case /dev/sdb4  create a directory, mount /dev/sdb4, copy the .odt file, umount /dev/sdb4 and remove the directory:  &gt; mkdir dir &gt; mount /dev/sdb4 dir &gt; cp file.odt dir/ &gt; rmdir dir  
depending on the setup of the machines in question, you may be able to use rpcclient as the anonymous user:  rpcclient -u "" -n -c enumprinters yourmachine   note that this may not work for windows machines with the default group policy, but should work for most samba setups. 
aptitude lists them under “obsolete and locally created packages”
rsync syncs stuff between directories and even different servers
by variable expansion in bash:  str="col1|col2|col3+++++++++++a|1|a b|2|b c|3|c d|4|d  (3 rows)" str=${str%  (*} str=${str##*+} str=${str// / } str=${str//|/ }   or by sed  sed 's/.*+\(.*\s\)\s\+(.*/\1/;y/ |/\n /' &lt;&lt;\eof col1|col2|col3+++++++++++a|1|a b|2|b c|3|c d|4|d  (3 rows) eof a 1 a b 2 b c 3 c d 4 d  
try ctrl-c
as of version 3.19, this device is supported in the linux kernel, but you need to manually provide the device's firmware to the kernel.  finding the firmware:  you can find the firmware in the device's windows driver, which you can download from lenovo (or your computer manufacturer's website)
you could store the brace expansion in an array, then output it in the manner of your choosing:  urls=( localhost:8080/reports/{promos,promo-updates,scandown}/{130,139,142}{,-unburdened,-burdened}{,.pdf,.xls,.xlsx,.csv,.preload} )   then  printf "%s\n" "${urls[@]}"   or  (ifs=$'\n'; echo "${urls[*]}")   the echo example looks weird because:   it's run in a subshell (the parentheses) so i don't alter my current value of ifs. ifs needs to be defined in a separate command:  this doesn't work: ifs=$'\n' echo "${urls[*]}" because the variable gets expanded before the new env variable takes effect ifs needs to be set before you start expanding variables.    also, note the subtle difference in the dereferencing array index used:   [@] in the printf example to expand the array into individual words [*] in the echo example to expand the array into a single word, with elements separated by the first char of ifs  
as long is has a cable connected and it is in the up state, it listens passively to it
it entirely depends on the provider
bind e resize-pane -u 10 in ~/.tmux.conf, then tmux source-file ~/.tmux.conf (another useful shortcut: use the same principle). 
i'm not sure what sort of install you did, but if you tell it you want a software development you should get gcc i think
kerberos apps also look for dns srv records to find the kdc's for a given realm
let's have a brief look onto the function:  int blkid_superblocks_get_name(size_t idx, const char **name, int *usage) {     if (idx &lt; array_size(idinfos)) {         if (name)             *name = idinfos[idx]-&gt;name;         if (usage)             *usage = idinfos[idx]-&gt;usage;         return 0;     }     return -1; }   name is a pointer to a char * pointer (thus a pointer to a »string«)
simple example, creating a gzipped tarball out of a directory, excluding a subdirectory and listing the contents:  $ ls fruit/ apple  banana  peach  tomato $ tar czf onlyfruit.tar.gz --exclude=tomato fruit/ $ tar tf onlyfruit.tar.gz  fruit/ fruit/peach/ fruit/apple/ fruit/banana/  
by using unalias:  [zak ~]$ alias ls alias ls='ls --color=auto' [zak ~]$ unalias ls [zak ~]$ alias ls bash: alias: ls: not found  
you've included /models in the traversal, but none of its subdirectories
i know it's tedious but unless your app as a option to be executed in silence then i would go with   ./app &gt; /dev/null 2&gt;&amp;1   if you don't want to be always writing this that you can create your own alias in your shell profile.  .bashrc - for bash   you will need to create and alias:  alias app="/usr/local/bin/app &gt; /dev/null 2&gt;&amp;1"   after updating your .bash_profile just relog or source ~/.bash_profile and just call the app.  edit: correcting as per michael comment, indeed the 2>&amp;1 comes after the /dev/null
assuming consistent file format, with bash you can read the file line by line, test if it's in given format and then do the conversion:  while ifs= read -r i; do [[ $i =~ ^#([0-9]{10})$ ]] &amp;&amp; \       date -d@"${bash_rematch[1]}"; done &lt;file.txt   bash_rematch is an array whose first element is the first captured group in regex matching, =~, in this case the epoch
the reason for having separated stdout and stderr in the first place is to distinguish between program data output (which might be stored in a file, fed to a pipeline, &amp;c.) and diagnostics and fluff (which are only really of interest to a human operator looking at the terminal)
your problem is due to you renamed your user's (mpatil) home directory to /home/algo
i suspect the executable bit is not set
there are several different ftp servers packaged within debian, which you can see via:  apt-cache search ftp-server   one of the most popular servers around is proftpd, and that can be installed upon debian systems with:  apt-get install proftpd   once downloaded debconf will ask if you wish to run the server via inetd, or in a standalone fashion
they are in /usr/lib/kbd/consolefonts which is owned by the kbd-misc package. 
you can access the return code of the last command executed with the special parameter $?
press alt+>. 
a restart job has to kill an old instance first
two ways:  press ctrl-v + tab  cut -f2 -d'   ' infile   or write it like this:  cut -f2 -d$'\t' infile  
apt-file can do this
that's there because the apache rpm spec file has a "buildrequire" for apr-devel, apr-util-devel and pcre-devel packages, and the packager wanted the build to use the packaged version rather than what's bundled in the apache tarball.  for what it's worth, here's the change that was made to add that line, perhaps that'll help answer your question: link text  that's an edit from 6 years ago, so it's not identical to a current package, but you can see elsewhere in the patch how using the apr-config from the packaged version of apr-devel is added. 
generally, the /usr hierarchy is used for stuff coming from the os vendor/site administrator, while /usr/local is used for things installed locally (for example on a network, /usr might be a nfs mount which is shared by several computers, while /usr/local is a local filesystem)
first of all we need to configure/change the audio configuration for our bluetooth device (in my case, bose soundlink), i wouldn't assume that this steps would work for every bluetooth device, so give it a try, and hopefully it'll work.  we type in this command.  sudo nano /etc/bluetooth/audio.conf    this will open or if not exist previously then create the audio configuration file for out bluetooth adapter(s), i have 2 different adapters and this seems to work for both.  we have to enter or replace the following lines to look like:  under [general] section.  [general]  disable=socket enable=media,source,sink,gateway   the order is important so don't alter it otherwise it won't work
that's actually 3 questions
procmail makes great efforts to assure that mail is not lost even if delivery fails
if i understand you correctly, you want to remove a package that other packages depend on, without removing those other packages as well
well, since you're specifically asking how to know which irq is responsible for the number in mpstat, you can assume it's not the local interrupt timer (loc), since those numbers are fairly equal, and yet mpstat shows some of those cpus at 0 %irq.  that leaves irq 0, which is the system timer, and which you can't do anything about, and irq 177, which is tied to your b4xxp driver.  my guess is that irq 177 would be your culprit
you can get it by typing capital v instead of small v:  $ pgrep -v pgrep from procps-ng 3.3.3 $ pkill -v pkill from procps-ng 3.3.4  
you can either rename the .bashrc file to another name in the file manager or you could edit the file with a gui text editor to remove the loop. 
there's already an answer with perl and awk
from man cp (the gnu version, found on linux and cygwin)     --backup[=control]      make a backup of each existing destination file      -b     like --backup but does not accept an argument   example  touch 1 2 cp -bv 2 1 ‘2’ -&gt; ‘1’ (backup: ‘1~’)   note that this does not check for existing backup files, i.e
i had to look long and hard and finally understood what was happening
from man rsync:      -t, --times                 preserve modification times   
   was changing ownership of everything to root the right thing to do?   no
your parenthesis attempt lacked spaces around them so find saw an option called (-name and didn't know what to do with it
try:  $ sed -e 's/:[^:]*:/:123:/' file sed:123:abc sed:123:efg sed:123:zyx  
as far as i understand there are no special operations like append and rename that you can configure.  an append effectively is opening a file and then writing it with a different content (even if you only add to the file)
to see what particular versions are available to you via yum you can use the --showduplicates switch.  $ yum --showduplicates list httpd | expand loaded plugins: fastestmirror, langpacks, refresh-packagekit loading mirror speeds from cached hostfile  * fedora: mirror.steadfast.net  * rpmfusion-free: csc.mcs.sdsmt.edu  * rpmfusion-free-updates: csc.mcs.sdsmt.edu  * rpmfusion-nonfree: csc.mcs.sdsmt.edu  * rpmfusion-nonfree-updates: csc.mcs.sdsmt.edu  * updates: mirror.steadfast.net available packages httpd.x86_64                        2.4.6-6.fc20                         fedora  httpd.x86_64                        2.4.10-1.fc20                        updates   as far as installing a particular version? you can append the version info to the name of the package like so:  $ sudo yum install &lt;package name&gt;-&lt;version info&gt;   for example in this case if i wanted to install the older version, 2.4.6-6 i'd do the following:  $ sudo yum install httpd-2.4.6-6   you can also include the release info when specifying a package
to retain the / added after completing directories or symbolic links to directories, turn off the option auto_remove_slash which is on by default.  setopt no_auto_remove_slash   for many commands, retaining the trailing slash makes no difference for directories, but causes the command to act on the target directory instead of the symbolic link if the argument is a symbolic link to a directory
all debian derivatives should have /etc/debian_version, which is provided by the essential base-files package
it seems like your makefile (stdout/stderr) output triggers the default quickfix mode of your vim.  perhaps /some/other/dir/source.his compiled by your recursive make call and a warning is produced and the quickfix mode jumps to its location
use ps command to watch currently running processes.  ps aux will give more verbose output
it turns out that this is a problem in mercurial and that there isn't an easy work-around for mercurial 2.1
nmap is a great port scanner, but sometimes you want something more authoritative
efivar version 0.23 needs a patch to work with kernel headers from 4.4 (and later kernels), because the header defining nvme_ioctl_id changed (it was renamed from nvme.h to nvme_ioctl.h).  to build efivar on your system, you'll need the "workaround rename of linux/nvme.h" patch
there is a great thread about this on the ubuntu forums
each signal has a "default disposition" -- what a process does by default when it receives that signal
the process name is nautilus
from wikipedia:      asymmetric multiprocessing (amp) was a software stopgap for handling   multiple cpus before symmetric multiprocessing (smp) was available.   linux uses smp. 
you can add and remove ips to your already defined sets on the fly
you can use iptables to limit to 3 attempts per minute:  iptables -i input -p tcp --dport 22 -i eth0 -m state --state new -m recent --set iptables -i input -p tcp --dport 22 -i eth0 -m state --state new -m recent --update --seconds 60 --hitcount 4 -j drop   or use something like  fail2ban
1.there is no need to define directory trees individually :  bad way :  ~ $ mkdir tmp ~ $ cd tmp ~/tmp $ mkdir a ~/tmp $ cd a ~/tmp/a $ mkdir b ~/tmp/a $ cd b ~/tmp/a/b/ $ mkdir c ~/tmp/a/b/ $ cd c ~/tmp/a/b/c $   good way :  ~ $ mkdir -p tmp/a/b/c   2
setting only fileformat may not be enough, depending on a few factors
zless  it seems a pity about zcat, as libz has an api that supports reading from both compressed and uncompressed files transparently
there are two things wrong:   you cannot use spaces around the assignment operator
according to this mailing list post sak is «break», k
not possible via shutdown command directly on the server/lpar
first thing is to check that you have installed the proper driver for your video card, as general guide take a look at http://askubuntu.com/questions/23238/how-can-i-find-what-video-driver-is-in-use-on-my-system and once you are familiar with the topic search how to install compatible drivers for your video card 
there are several ways that you can find a port, including your echo technique
here's a hybrid perl/fold approach:  $ echo "the cat hopped in a box." | fold -w 1 |       perl -lne 'push @k, "$_ "; push @l,sprintf "%-2s",$.; end{print "@k\n@l"}' t  h  e     c  a  t     h  o  p  p  e  d     i  n     a     b  o  x  
in the launcher preferences window, enter this as the command:  bash -c "context file.tex; exec bash"   then check the option "execute on terminal".  that will execute bash on terminal, running the 2 commands between quotes, instead of an interactive shell
you didn't mention any specific distro, but i think oem installation  is what you are looking for
it sounds like awk is running out of file-handles
you can create a .forward file in your home directory, and the mail will be forwarded.  cd  echo "username@gmail.com" &gt; .forward chmod 644 .forward                 # change permission else it won't work  
the problem is that &gt; example.txt starts writing to that file, before shuf example.txt starts reading it
i was looking for a way to run a program with modified dns resolution for testing purposes
to find executable files called java under the specified directory:  find '/applications/netbeans/netbeans 7.0.app/' -name java -type f -perm -u+x   the output will be one file name per line, e.g.  /applications/netbeans/netbeans 7.0.app/contents/resources/netbeans/executablejavaenv/java   if you want to omit the …/netbeans 7.0.app part, first switch to the directory and run find on the current directory (.)
so after some research i can answer my own question
i would try to protect against failures for several reason
filter the positional parameters $@ with the parameter expansion suffix :#-* to strip elements matching the pattern -* and the parameter expansion flag @ inside double quotes to preserve empty elements
use the "watch" command:  watch ls   this will run the "ls" command every 2 seconds. 
i can't be 100% sure since you haven't shown us what you're doing, but i am guessing you're simply not quoting your variables
something like the following works ...  find 
/media/cdrom is a convention for the mountpoint, while /dev/cdrom is the special device that could be mounted on the former.  you need both, because they serve different purposes: most applications do not read directly from the special device, but can read from a filesystem (something that is mounted) 
when you run service httpd configtest, it actually run command apachectl configtest:    ....   apachectl=/usr/sbin/apachectl     ....   graceful|help|configtest|fullstatus)         $apachectl $@         retval=$?         ;;   ....   do a strace:  $ strace -f -e trace=write apachectl configtest process 22999 attached (waiting for parent) process 22999 resumed (parent 22998 ready) [pid 22999] write(1, "1024\n", 5)       = 5 process 22999 detached --- sigchld (child exited) @ 0 (0) --- process 23000 attached (waiting for parent) process 23000 resumed (parent 22998 ready) process 22998 suspended [pid 23000] write(2, "syntax ok\n", 10syntax ok ) = 10 process 22998 resumed process 23000 detached --- sigchld (child exited) @ 0 (0) ---   you can see, the output syntax ok is written to stderr, causes the ouput can not save to var variable.  you can make it done, by redirect stderr to stdout:  var=$(service httpd configtest 2&gt;&amp;1)  
if you'd like to avoid "permission denied" errors and search recursively the whole android filesystem, you'll need to have a "rooted" device.  afterwards, having a rooted device, you may install any terminal emulator application, run su and run find command.  e.g., you'd like to find all files with .ko extension, so please run:  find / -name "*.ko" in terminal emulator after running su command. 
set up a compose key
in general:  program &gt;/dev/null 2&gt;&amp;1   will force the output (stdout) of program to /dev/null and redirects stderr to stdout
you can prefix most sed commands with an address to limit the lines to which they apply
more likely than not, they're in the same section of the manpages, e.g., 1
after fiddling with iptables whithout much success i took a completely different approach:  all dns queries for spam / phishing / ad server server names are responded with 0.0.0.0 which eg
if your source code already have debian configuration files , you'll just need to run (in the sorce directory):  dpkg-buildpackage  otherwise you can create a deb package with checkinstall  launch the configure script first , e.g ./configure --prefix=/usr , then do  checkinstall --install=no    it will ask few questions , just fill the fields , so you can identify it laterly.  if it successed , you will see a *.deb package out of the source directory.  copy and install it on the other computer. 
foo &amp; bg_pid=$! kill "$bg_pid"   you can also use the shell's internal kill command with (at least in case of bash) the job number:  foo &amp; kill %1   but that's probably not easier
you could try something like:  list="" ; for pkg in $(apt-cache search ^mate | grep -v -- '-dev'); list="$list $pkg" ; done ; sudo apt-get install $list  
it isn't necessarily better.  the advantage of #!/usr/bin/env python is that it will use whatever python executable appears first in the user's $path.  the disadvantage of #!/usr/bin/env python is that it will use whatever python executable appears first in the user's $path.  that means that the script could behave differently depending on who runs it
tmux doesn't have appropriate setting for that, but it's easy to fix it in the source code
this isn't related to busybox
you can translate mikrotik firewall rules to linux iptables rules pretty easily
(i don't quite penetrate the way these signatures work, so these are merely pointers...)  given a pdf file, pdfbook from the pdfjam tool set could be a one-stop solution to this problem, from the manpage:     pdfbook makes 2-up versions of pdf files, with the pages ordered as signatures.   it depends on pdflatex and the pdfpages latex package (which you could thus use directly, too)
use this:  sed '/^\s\s*/d' file   or even:  grep -v '^\s' file  
with gnu grep (and several other grep implementations), you can search for files that do not contain any printable character
a very similar question seems to have been answered over at super user.  http://superuser.com/questions/251663/unable-to-mount-ntfs-drive-with-rhel-6  hope that helps.  edit:   if you wanted to mount sda3 your command would look like this:   mount -t ntfs-3g /dev/sda3 /mnt/windows   for more information on ntfs-3g check out the site here. 
as you might already know :g/#/ runs a command for all the lines containig a #, which are the topics of the different challenges.  now, as your 1st line has deleted the "wrong" line, the 2nd just copyies the remainding one  you are on the #-line, you move one line ahead (+1) and copy (t) it to the current line (.)  which leaves 2 identical lines. 
i found this feature request which suggests that it is part of the nautilus package: http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=529297  i found the file "mount-archive.desktop" at: http://bazaar.launchpad.net/~ubuntu-branches/ubuntu/natty/nautilus/natty/annotate/head:/debian/mount-archive.desktop  on my ubuntu pc it is at /usr/share/applications/mount-archive.desktop 
to remove it go to system settings -> workspace -> workspace button.  untick "show informational tips". 
you have to disable arp-ping:  nmap -sp -pe --disable-arp-ping 192.168.56.1    
while printf '%s ' "$(df -p / | awk 'nr==2 { print $(nf-1) }')"; do     sleep 30 done echo  
in your function definition, i would suggest replacing:  echo "cat $1 | pv -w 20 -s ${__size}"   with just:  cat $1 | pv -w 20 -s ${__size}   this way, the function itself will execute this bit of code, without requiring a call to eval in the caller. 
try with blockdev --setrw or hdparm -r 0 
as i mentioned in the comment:  as wikipedia link mention: in windows nt operating systems, a windows service is a computer program that operates in the background.[1] it is similar in concept to a unix daemon.  a daemon is a type of program on unix-like operating systems that runs unobtrusively in the background, rather than under the direct control of a user, waiting to be activated by the occurance of a specific event or condition
first of all you should check if this package is correctly installed in your system and being listed by dpkg tool:  dpkg -l | grep urserver  it should have an option ii in the first column of the output - that means 'installed ok installed'.  if you'd like to remove the package itself (without the configuration files), you'll have to run:  dpkg -r urserver  if you'd like to delete (purge) the package completely (with configuration files), you'll have to run:  dpkg -p urserver  you may check if the package has been removed successfully - simply run again:  dpkg -l | grep urserver  if the package has been removed without configuration files, you'll see the rc status near the package name, otherwise, if you have purged the package completely, the output will be empty. 
i am not sure if everything here is needed to succeed
disclaimer: i don't know anything about the teamviewer product, but, i'll treat this as any old x-windows app that you want to run.  if you just want a gui app to start, look into using .xinitrc or (in some desktop environments) ~/.config/autostart/  buuut..
ocsp is a way for programs that use x.509 certificates (such as anything using ssl, like web browsers for https: urls) to check whether a certificate has been revoked because it was compromised.  you're not seeing them when using https: directly because you would need a packet tracer that can decrypt ssl and the ssl certificate used for encryption — which in most cases you won't have. 
the linux kernel provides a tweakable setting that controls swappiness  $ cat /proc/sys/vm/swappiness 60     open /etc/sysctl.conf as root
it required to modify /etc/apt/sources.list  adding i386 to downloadable architectures like that:  deb [arch=amd64,i386] http://httpredir.debian.org/debian/ jessie main contrib    after that you need to make  apt-get update dpkg --add-architecture i386 apt-get update   and to install package for i386 architecture:  apt-get install linux-headers-3.16.0-4-686-pae:i386  
it's a bad idea to parse the output of ls
red hat enterprise linux (rhel)  these are probably a good basis, looking at rhel6's capabilities, they're covered here, titled: red hat enterprise linux 6 technology capabilities and limits.  &nbsp;&nbsp;&nbsp;     note: [5] the architectural limits are based on the capabilities of the red hat enterprise linux kernel and the physical hardware
there's no fully reliable way to put an invisible mark in a text file
sed 'y/|;/\n|/;s/|/;/;y/\n/|/' &lt;&lt;\in question ipsun; option 1 ; option 2 ; option 3 ; option 4 ; ..
you can't use dd this way (it might work for dvd-ram though)
never come across a pdf as text/pdf, but presumably mutt is trying to do a line ending conversion (e.g., crlf → lf)
i found the answer as below.  in passive mode we can run ls command but in active mode we have to manually disable passive mode by typing passive command then it will accept ls command otherwise it's gives 550 permission denied error 
i could not find here anything stable solution but to restart the system
if you mean the 2 most recently modified regular files in each directory, with zsh:  dirs=(dir1 dir2...) files=()  for dir ($dirs) files+=($dir/*(dn.om[1,2])) (($#files)) &amp;&amp; ls -ld -- $files   if you mean the 2 most recently modified regular files in all the directories, with gnu find, xargs and a recent gnu sed:  find dir1 dir2..
if you want icewm to re-read its configuration, send it a sighup signal:  killall -sighup icewm   see the configuration chapter in the icewm manual. 
the cortex a8 is a specific processor design in the arm v7 family.  it's like how an intel celeron d processor 325 can be described as a processor in the 64-bit intel em64t family, or as a processor in intel's northwood-128 family.  that is, an arm cortex a8 describes a specific design, whereas arm v7 describes the cpu instruction set, gives a minimum set of registers, etc.  it's a bit different in the arm world, where the processor design is licensed by arm holdings to multiple cpu design houses, who in turn may use multiple different foundries may produce "cortex a8" type processors
that section refers to the runas_spec part of sudo, which further details of can be found on the man page.  in your example any members of the admin group may escalate to having sudo priveleges as any user, and members of the sudo group may escalate to having sudo priveleges as any user and group.  example below, i created 2 users and give them the different priveleges outline in your question;  cat /etc/sudoers | grep ^test test1   all=(all)   nopasswd: all test2   all=(all:all)   nopasswd: all   then tested having them run commands as the apache user and group, notice the prompt for the password for user test1 when trying to run as the apache group;  [test1@heisenbug root]$ sudo -u apache ping google.com ping google.com (74.125.230.233) 56(84) bytes of data. 64 bytes from par08s10-in-f9.1e100.net (74.125.230.233): icmp_seq=1 ttl=63 time=36.2 ms --- google.com ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 36.245/36.245/36.245/0.000 ms  [test1@heisenbug root]$ sudo -g apache ping google.com [sudo] password for test1:   [test2@heisenbug root]$ sudo -u apache ping google.com ping google.com (74.125.230.226) 56(84) bytes of data. 64 bytes from lhr08s06-in-f2.1e100.net (74.125.230.226): icmp_seq=1 ttl=63 time=34.4 ms --- google.com ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 34.465/34.465/34.465/0.000 ms  [test2@heisenbug root]$ sudo -g apache ping google.com ping google.com (74.125.230.233) 56(84) bytes of data. 64 bytes from lhr08s06-in-f9.1e100.net (74.125.230.233): icmp_seq=1 ttl=63 time=35.0 ms 64 bytes from lhr08s06-in-f9.1e100.net (74.125.230.233): icmp_seq=2 ttl=63 time=33.5 ms --- google.com ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 1001ms rtt min/avg/max/mdev = 33.575/34.308/35.042/0.756 ms   i can only imagine a very strict set of circumstances where this type of usage would be applicable. 
 mount filesystems on flash disk with noatime flag in /etc/fstab. you can easily redirect log files to any other disk by editing /etc/rsyslog.d/* or similar file (unsure which exact syslogd is used on debian, but similar files exist on all platforms).   you can use dstat -dd sda,sdb,sdc 60 to monitor data volumes read/written. 
duplication question (with answer)  http://stackoverflow.com/questions/2415724/bash-arithmetic-expression-vs-arithmetic-expression  the manpage for bash v3.2.48 says:     [...] the format for arithmetic expansion is:   $((expression))        the old format $[expression] is deprecated and will be removed in upcoming versions of bash.   so $[...] is old syntax that should not be used anymore  in addition to that answer:  http://manual.cream.org/index.cgi/bash.1#27  info relating to bash versions:  here is some info about bash man pages (its hard to find info on what version each one is referring to):  ops link:  http://www.tldp.org/guides.html bash guide for beginners  version:    1.11 author: machtelt garrels,  last update:    dec 2008  sth (74.6k rep) quoting bash v3.2.48  from http://stackoverflow.com/questions/2415724/bash-arithmetic-expression-vs-arithmetic-expression)  note: more info about [] vs (()) here: http://lists.gnu.org/archive/html/bug-bash/2012-04/msg00033.html  a link i found:  http://www.gnu.org/software/bash/manual/ last updated august 22, 2012  http://www.gnu.org/software/bash/manual/bash.html#arithmetic-expansion 
from man 1 traceroute:  -m max_ttl       specifies  the  maximum  number of hops (max time-to-live value)       traceroute will probe
i ended up ls-parsing:  is_group_writable() {   local ls="$(ls -ld "$1")"   [ "${ls:5:1}" = "w" ] }   i'm grateful for @slm's extensive answer, but none of the other methods are as straightforward
resize_reiserfs shrinks the file-system only, not the partition itself
there are two (main) ways you can authorize a user to run commands as root via sudo:   declare that “alice may run commands as root”; declare that “alice is a sysadmin” and that “sysadmins may run commands as root”.   the way to declare “alice is a sysadmin” is to make her a member of the sysadmins group, but there is no standard name for the sysadmins group (nor any obligation that there is a sysadmins group)
if you want similar behaviour and even use your normal rdp-client, you could just install xrdp. for centos, it should be sufficient to do yum install xrdp 
hi fellow awesome wm user! i have had this same issue and found out that awesome wm currently does not support dpi scaling
sources from various people were helpful in leading me to right direction
assuming this is for mysql (or mariadb), and you have the above as the contents of a file named table_create.sql:  $ mysql --user=$userid --password=$passwd --database=$db &lt; table_create.sql   you have to know what your mysql user id and password are, and know the database name
try this:  perl -i -pe 's|^&lt;units&gt;.*&lt;/networks&gt;$||' /my/filename   note that if you have leading or trailing space in the line you will need this instead:  perl -i -pe 's|^ *&lt;units&gt;.*&lt;/networks&gt; *$||' /my/filename   i uesd pipe as a separator rather than slash to avoid unnecessary escaping. 
you would do this via xmodmap and not via your window manager
try install one of these using rpm (i'm not sure which is better):    http://www.my-guides.net/en/images/stories/fedora12/msttcore-fonts-2.0-3.noarch.rpm http://nchc.dl.sourceforge.net/project/mscorefonts2/rpms/msttcore-fonts-installer-2.6-1.noarch.rpm http://li.nux.ro/download/nux/dextop/el7/x86_64/webcore-fonts-3.0-1.noarch.rpm   btw, if your problem is not compatible issue, please use free/libre fonts
you want to change these "string"s which are in lines where there are no # character or this character is after "string", so that you can have comments at the end of the lines:  ##################################### # blah blah blah string blah blah #####################################  pkg_name="string" pkg_desc="string-foo" pkg_a="string" # this is comment after string   in order to this properly run  sed 's/^\([^#]*\)string/\1newstring/' file   result:  ##################################### # blah blah blah string blah blah #####################################  pkg_name="newstring" pkg_desc="newstring-foo" pkg_a="newstring" # this is comment after string  
duplicity can and does restore permissions and owner of your files/folders as they were before the backup
because access to the underlying device is controlled only by file permissions by default, so if your usb stick contains a posix filesystem with a world-writable device node corresponding to a real device in the system, you can use that device node to access the corresponding device as a "plain" user
try this:  alias -- -=popd   worked at least for me:  usr@srv % alias -- -=echo usr@srv % - test test  
the kernel does job scheduling and provides system calls.  when a process is running, the kernel schedules its runtime - especially it assigns a pid to it - such information is stored inside the kernel address space, in data structures (e.g
this is not hard, simply make sure to escape the octothorpe (#) in the name by prepending a reverse-slash (\).  find 
according to the page you linked, it points to http://s3tools.org/repositories
it seems elementary-tweaks has no longer key bindings in elementary freya
you can use:  sed -e '/^;/d' php.ini  
a standard unix shell will do something called globbing; this uses special characters to mean, for example, one character (?) or any number of characters (*)
the issue may be resolved by deactivating num- or caps-lock, as is stated in the xkeycaps manual:     "if you can't select anything from the right-button popup menu, it   might be because you have numlock or capslock down
if the assumption is that you have an ext{2,3,4} filesystem, and you formatted the root filesystem when you installed the os (and didn't do upgrades from another os without a wipe), you can use dumpe2fs:  % dumpe2fs -h /dev/mapper/vg_desktop-lv_root 2&gt;&amp;1 |grep 'filesystem created' filesystem created:       sat jul 23 04:28:07 2011  
the short answer is:  # nmcli con modify my-bridge connection.interface-name ens7 # nmcli con up my-bridge   however, it's never that simple - read on...  three things are needed for the connection to be attached to the device:   a valid network device the connection.autoconnect property to be set to yes the connection.interface-name property is set to the name of the interface   make sure that you have a working nic (virtual in a vm)
here are a few options:   use grep with the -o flag to print only the matching part of the line and filter with head to get the first match only:  grep -o '"accountheader[^}]*}' file.json | head -n1    the regular expression looks for a "accountheader then as many as possible non-} characters until the first }
use this:  today_date="$(date +%y%m%d)" # use $(...) to assign the output of a command to a variable declare -a nodeid=(...)  for id in "${nodeid[@]}"; do   [ -e "${today_date}_mps_cust_dump_${id}.list.z" ] || echo "$id is not downloaded" done | mail -e -s "subject" user@example.com      the for loop runs trough every item in the array nodeid.   [ -e "..." ] checks if the file exists with the given name in the current directory || echo "..." prints a message if the file doesn't exist  | mail ... everything is piped to mail, -s defines the subject, -e will not send a mail when the body is empty (all files exist) and the last agument is the address.  
you can use !-2:  $ echo foo foo $ echo bar bar $ !-2 echo foo foo   that may not help with your right-hand situation.  you can also use !string history searching for this sort of case:  $ python test.py $ vim test.py $ !py python test.py # printed, then run   this may be more convenient to use
try to open a terminal.  sudo passwd root  then   su  you are root now.  you can use chmod 755 to modify the permission. 
find is very useful for selectively performing actions on a whole tree.  find 
a very simple sample using python:  #!/usr/bin/env python  import sys import json  def print_first(data):     for item in data["items"]:         if item["name"].startswith("first"):             print item["hostref"]["hostid"]  def main(argv):     for json_file in argv:         with open(json_file) as data_file:             data = json.load(data_file)             print_first(data)  if __name__ == "__main__":     main(sys.argv[1:])   that is with your sample data re-formatted as:  {     "items" : [         {             "name" : "first-block-e70a2fe8fd0531ad1f87de49f03537a6",             "type" : "store",             "hostref" : {                 "hostid" : "166219e3-be5c-46d0-b4c7-33543a29ce32"             },             "rolestate" : "started",             "healthsummary" : "good"          },         {             "name" : "second-block-c21a1ae8dd2831cd1b87de49f98274e8",             "type" : "store",             "hostref" : {                 "hostid" : "176429e3-be5c-46d0-b4c7-33543a29ad63"             },             "rolestate" : "started",             "healthsummary" : "good"         },         {             "name" : "first-block-a85d2fe6fd0482ad1f54de49f45174a0",             "type" : "store",             "hostref" : {                 "hostid" : "176429e3-ae1d-46d0-b4c7-66123a24fa82"             },             "rolestate" : "started",             "healthsummary" : "good"         }     ] }  
iptables comes with the utilities which might be useful to update iptables configuration safely: iptables-save,iptables-restore, iptables-apply.  to temporarily change and test running configuration, you could do like this:  $ sudo iptables-save &gt; rules.v4 $ vi rules.v4 $ sudo iptables-restore &lt; rules.v4   if you want to change configuration on remote servers, using iptables-apply instead of iptables-restore would be recommended.  some linux distributions integrate those utilities to keep permanent settings and statistics which automatically get restored across reboots
try:      #!/bin/bash     id     touch script-run-user.file      sudo -u appuser 'ksh' &lt;&lt;eof     # add list of cmds to execute     id     touch appuser.file      eof   edit: just as an update, check out here documents
if you want to interact with tmux in a script, that's where you want to use tmux ..
bios  to maximize you chances, make sure you have the latest bios installed for your system(always do such updating with ac properly secured and being motionless)
someone suggested in your hear cgroups
i'm presuming you are installing grub using the mint installer in which case i recommend you not to touch it
this python script just did the job for me
use chgrp nobody file instead. 
it turned out that global icewm config example /etc/icewm/toolbar have this button enabled
which is which  user name is an ambiguous term that could refer    to a formal user id string known to some system, or  to a display name like john smith
what is likely happening is not that files are being corrupted but that linux is doing its best to ensure that files are not corrupted.  when a filesystem is opened, written to, and is being closed, the operating system (both windows and linux) will mark the filesystem as being "dirty", e
since cracklib is open source, the answer can be found in the source code.  "too simplistic/systematic" means that there are too many characters that are preceded by one of their alphabetical neighbors
the main difference is that the quoted version is not subject to field splitting by the shell
virsh will allow your to edit, export, and import the xml definition for your servers
to solve the issue, install the python-dev package which include the python.h header file needed for compilation of pycrypto.:  apt-get install python-dev   but, you can also easily install the python-crypto package directly:  apt-get install python-crypto  
there are a number of 2-character macros that let you format their arguments in two different fonts, alternating between them
try this solution (found elsewhere on stack...): link 
let's see,   !a[$0]++   first   a[$0]   we look at the value of a[$0] (array a with whole input line ($0) as key).  if it does not exist ( ! is negation in test will eval to true)   !a[$0]   we print the input line $0 (default action).  also, we add one ( ++ ) to a[$0], so next time !a[$0] will evaluate to false.  nice, find!! you should have a look at code golf! 
wget will only retrieve the document
you have to use wget  --post-data to construct a string with all the values that were gonna be sent in the form, also --content-disposition and --trust-server-names to allow the use of server supplied names
a tcp/ip connection has both a source port and a destination port, so if the same server connects to another server on port 3000 multiple times, the linux kernel can sort out the connections because each one has a unique ip + source port + destination port
i'm assuming you want to change the default application opened for urls the easy way to change this is using gnome-control-center info and changing the default application.  yes, the schema type is   x-scheme-handler/http= x-scheme-handler/https=   each followed by the application.desktop you want to open http  here is a sample mimeapps.list with chromium as the http app 
you can try to run directy on the inittab..
if your system has been compromised at the root level, then the attacker can hide a keylogger from anything you try to detect it - by linking in a custom kernel module that intercepts the system calls that might lead to its detection at the kernel level
why are a lot of apps not available in package repos?  there could be many reasons:   no one bothered to package the app. no one is allowed to package the app (like oracle insisting on being the only one to distribute java). the package is published under a license that contradicts the distros values. ...   there's no one single reason
after the fact, i don't think there's any intrinsic way to find out about past mount and unmount operations
sources: here and here.  skype is in multilib repo
check if you have yum installed by typing yum --version in your terminal prompt
you can use awk like this :  grep "pattern" file.txt | awk '{printf "%s ", $3}'   depending of what you do with grep, but you should consider using awk for greping itself :   awk '/pattern/{printf "%s ", $3}' file.txt   another way by taking advantage of bash word-spliting :  echo $(awk '/pattern/{print $3}' file.txt)   edit : i have a more funny way to join values :  awk '/pattern/{print $3}' file.txt | paste -sd " " -  
mv other-file file-to-be-deleted mv file-to-be-deleted other-file  
to set things up so that python gets you the new version but everyone else, including the standard os programs, will get the original:   choose a directory to hold your personal programs (or symlinks to them)
in bash, typeset and declare are exactly the same
looks like the packages are just not installing because they aren't signed with a key that your system recognizes, which is to be expected from random packages downloaded from non-official repos
your problem is that in a pipeline ( command1 | command2 | command3 ... ) the commands are ran in subshells
you can use the standard elf program dump:  dump -lv libxxx.so | grep symbolic 
sure, just use paths to where you want the symlinks to be
for a single file instead of using sftp you could pipe the file over ssh using cat or pv at the sending side and using tee on the middle server to both send the data to a file there and send a copy over the another ssh link the other side of which just writes the data to a file
notifications (and this whole bar) have been reworked in newer releases of gnome, starting with 3.16
change the character translation in putty to utf-8. 
to prepend text to a file you can use (with the gnu implementation of sed):  sed -i '1i some string' file   appending text is as simple as  echo 'some other string' &gt;&gt; file   the last thing to do is to put that into a loop which iterates over all the files you intend to edit:  for file in *.txt; do   sed -i '1i some string' "$file" &amp;&amp;   echo 'some other string' &gt;&gt; "$file" done  
ask your programmers what language you need to be using, this is the most important part
use df
/etc/services is a conffile, so if you modify it locally and a new package version is installed with a modified version, dpkg will ask you whether to keep your version or install the new one
be aware that matching email addresses is a lot harder that what you have
mount -t usbfs none /proc/bus/usb  cat /proc/bus/usb/devices   if you don't have the usbfs module or /proc/bus/usb directory, then try this  cat /sys/bus/usb/devices/*/product  
when linux needs to find ram to store something, it looks for the pages in ram that have been unused for the longest time
a better and safer solution is to install cgmanager and run it with systemctl start cgmanager (on a systemd-based distro)
losetup (the command normally used to set them up) will tell you:  $ /sbin/losetup --list name       sizelimit offset autoclear ro back-file /dev/loop0         0      0         0  0 /var/tmp/jigdo/debian-7.6.0-amd64-cd-1.iso   note that with older versions you may hat to use use -a instead of --list, and this  outputs in a different and now deprecated format.  the information comes from /sys:  $ cat /sys/class/block/loop0/loop/backing_file  /var/tmp/jigdo/debian-7.6.0-amd64-cd-1.iso   another, possibly more portable, option is to get it from udisks:  $ udisksctl info -b /dev/loop0 /org/freedesktop/udisks2/block_devices/loop0: ⋮   org.freedesktop.udisks2.loop:     autoclear:          false     backingfile:        /var/tmp/jigdo/debian-7.6.0-amd64-cd-1.iso     setupbyuid:         1000 ⋮   losetup will also happily remove them for you, using the -d option
i guess it is:     nvidia-settings  
usually just the name of the package or program, so hadoop in this case.  daemons are usually added as a system account using useradd -r, which gives them a userid lower than human users (on my system, system accounts start at 100, human users start at 1000).  looking at the user names for system accounts in /etc/passwd seems to confirm the lack of any service, daemon, or d convention, e.g.  dnsmasq pulse ntp sshd   etc
if you don't mind some extra aditional dependencies you might want to take a look at akmod-nvidia (also found on the rpmfusion repository).  akmod-nvidia will build a suitable driver for you kernel, regardless of kernel version
if you disable it, you should set your transport method to tcp
sudo has many compile-time configuration options
the terminology is not completely fixed, so different documentation uses different terms, or worse, the same terms with different meanings
you almost make it  date=$(date +%h)  case $date in    06|07|08|09|10|11|12)       echo "es ist vormittag"       ;;    13|14|15|16|17|18)        echo "es ist nachmittag"       ;;    19|20|21|22)        echo "es ist abend"       ;;    23|00|01|02|03|04|05)        echo "es ist nacht"       ;; esac    why bother with minutes ? you have to enumerate all hours, there is no indication that bash will accept range see edit. if you wait a bit, i am sure perl expert will come with a shorter solution.   edit: as per costas's suggestion  case $date in    0[6-9]|1[012])       echo "es ist vormittag"       ;;    1[3-8])        echo "es ist nachmittag"       ;;    19|2[0-2])        echo "es ist abend"       ;;    23|0[0-5])        echo "es ist nacht"       ;; esac  
the easiest way is making your works in a subshell only:  snip-git() (     cd  -- "$snippetdir"     git add .     git commit -m "."     git push -u )     there're some thing you want to fix in your function:   remember to always quote your variables. you refer variable using $cwd instead of cwd.  
these answers are half correct, because virtualization is a choice but there is another
i found notmuch-mutt has some of the behavior i'm looking for
use a dynamic dns service
one approach (not necessarily the best...) would be to attach strace to the process (or, in order to handle the race condition, to a wrapper script which execs to this process), set strace to maximum string length and then catch all read()s and write()s (or whatever your process uses)
the order that you see is determined by the order of the entries in the file /boot/grub/grub.cfg
you can use the mail command to send a message to user jdoe like this:  mail -s "the subject goes here" jdoe   you will enter an interactive environment where you can type your message (mail body)
my answer is essentially the same as in your other question on this topic:  $ iconv -f utf-16le -t utf-8 myfile.txt | grep pattern   as in the other question, you might need line ending conversion as well, but the point is that you should convert the file to the local encoding so you can use native tools directly. 
you can look for the cpio newc header (starting with 0707010):  $ grep -abo 0707010 vmlinux.bin | head -n1 2531404:0707010   the -a (for all files even binary ones), -b (for byte offset), and -o (for only the matching part (and report the byte offset of the matching part instead of the line containing the matching part)) are non-standard gnu extensions to grep but are handy to find out where a given string is to be found in a file (contrary to many other grep implementations, gnu grep also supports non-text files (that is, that may contain 0 byte values may have arbitrarily long sequence of bytes between two lf characters, may not end in a lf characters or may contain bytes or sequences of bytes that don't make valid characters in the current locale) which is a requirement in that regard.  $ tail -c +2531405 vmlinux.bin| cpio -t | head bin bin/sleep bin/kill bin/watch bin/deluser bin/getopt bin/uname bin/nice bin/zcat bin/cpio   (grep -b offsets start at 0, while tail -c ones start at 1). 
while setting up a cron you have to keep in mind a lot of thins  1.the user for which you are trying to set the cron must have permissions over the script i.e
there is a perl script at http://cpansearch.perl.org/src/andk/perl-repository-apc-2.002/eg/trimtrees.pl which does exactly what you want:     traverse all directories named on the   command line, compute md5 checksums   and find files with identical md5
too late
question turns out to be irrelevant
it's not necessary to setup an apache server to front your subversion server
as ^old^new corresponds to !!:s/old/new, you can use the following to make a global replacement:  !!:gs/5742/2839/  
while read -r file;do [ -f "$file" ] &amp;&amp; echo "$file";done &lt;searchfiles.txt  
if it is intended as a backup (i'm looking at the tag), not as a remote copy of working directory, you should consider using tools like dar or good old tar
my first comment is all of what you state will only work if the filesystem on the device you're interested in is currently mounted
you can pipe the output of ls to pipe as follows  $ ls | less   then you are able to use less to browse the output, for example with page up and page down
as thrig pointed out, all that's needed is to create the directory structure that you want under /etc/skel.  quoting from the useradd man page     -k, --skel skel_dir      the skeleton directory, which contains files and directories to be copied in the user's home directory, when the home directory is created by useradd.   this option is only valid if the -m (or --create-home) option is specified.      if this option is not set, the skeleton directory is defined by the skel variable in /etc/default/useradd or, by default, /etc/skel.   ..
in modern bash (version 4.2 and above):  [[ -v name_of_var ]]   from help test:     -v var, true if the shell variable var is set  
since the large array is on a controller of a separate type (make and model, or rather: chipset), and nothing on it is needed for the system boot process, you can work around this by forcing a delayed controller initialization
for exim4, you're looking for acl ratelimit settings (although some mailers put it under 'policy') 
all you need to do is click and drag
try splitting the command into two lines in your .tmux.conf   open the window  neww -n bash1 bash  send the command to the window  send-keys -t "bash1" 'python2.6 python-prog/prog.py' enter   
it sounds like you're looking for uniq.  or, from the comments:  sed '2,5d;7,10d;12,$d'  
i'm assuming your goals are to:   make as much space available for the users as possible not run out of disk space anywhere else and have to take the server down to resize them at a critical time   if that's true, i'd recommend swapping the drives in sda and sdb and using the now-500gb sdb purely for /home
turns out cups offers the commands cupsreject and cupsaccept to mark/unmark a printer as unusable (so it will appear greyed out in print dialogs)
actually it was simpler that i thought
whenever you do not recognize a port by name, you can grep for the name in /etc/services to see that the name is defined there
awk doesn't have the capability to make in-place substitution like the newer versions of sed
because rm -i expects user's input from stdin, too
what about:  $ echo 1.000000000000002, 0.999999999999999, 999.000999000999|    sed 's/\([09]\)\1\{2,\}/\1..\1/g' 1.0..02, 0.9..9, 9..9.0..09..90..09..9   that is a [09] followed by itself (\1 being a backreference to the [09] captured in the capturing group \([09]\)) repeated 2 or more times
you can use the -w switch to man to see where man pages are being loaded from on disk.  example  $ man -w lsof /usr/share/man/man8/lsof.8.gz   so you could locate man pages for software that's similar to this and add the man page you want locally on the system to this same directory.  i did also dig this up, titled: chef gem man pages, which shows man pages being installed via gem instead for chef.  $ sudo gem install gem-man password: successfully installed gem-man-0.2.0 1 gem installed installing rdoc documentation for gem-man-0.2.0... $ gem man chef view which manual?  1
you might start by reading that page: http://www.oracle.com/technetwork/articles/servers-storage-admin/o11-083-ips-basics-523756.html  there is no connection between sysv and ips outside the fact solaris is derived from the system v release 4.0 unix branch but solaris 11 deprecated the system v packaging commands (pkgadd, pkgrm, pkginfo, ...) to the new ips ones (pkg install, pkg uninstall, pkg list, pkg info, ...)  unlike the svr4 packaging system which was file centric, ips is network centric
you're looking for x11vnc:     x11vnc allows one to view remotely and interact with real x displays (i.e
on some systems there is a command that is called java-config or java-config-2 that helps you selecting a java vm when you have multiple jdk or jre versions installed with your system installer
short answer for quantal (ubuntu 12.10): download and install the bash package from the precise repository.  walkthrough  for quantal (ubuntu 12.10), i searched for bash packages from nearby releases
from the man grep page (on debian):     description     grep  searches the named input files (or standard input if no files are    named, or if a single hyphen-minus (-) is given as file name) for lines    containing  a  match to the given pattern
the dig command is a part of the bind utilities so you need to install them
afair you should could it in /etc/xinetd.d/tftp    service tftp  {      ...      server_args             = -s /your/location/to/tftpboot  
i couldn't find a specification specifically referencing mounting, but chapter 19
you can try:  yum swap generic-release fedora-release   or you can try with:  yum shell &gt; remove generic-release &gt; install fedora-release &gt; run   if it does not work may be you can download correct rpm packages fedora-release fedora-release-notes and run:  rpm -e --no-deps generic-release generic-release-notes rpm -ihv fedora-release-*  
gnome aims to be distribution-independent
most distros use lightdm for for gnome3 i believe (kubuntu user myself so i'm making a few assumptions here)
remove all the accepted networks at home with the same ssid, except one (let's call this the "template"), and then make sure the "share these values..." option is checked.  now, the next time the "template" network can no longer sustain the connection, wicd should recognize one of the other available networks as the same and try to roam to the next available ap 
if you visit the ppa's page it'll show you what lines to manually insert into the source.list  click on technical details which reveals the following    choose your ubuntu version and copy/paste the lines into the bottom of your source.list file. 
if you're passing them to chmod (the command-line program), there is no difference
having multiple versions of a library in the system is not an issue in most linux distributions: shared libraries with distinct sonames can coexist within the same /usr/lib directory
this perl script builds a hash with words (read one per line from stdin, and/or from any filenames listed on the command line) as keys, and syllable counts as the values.  then it prints the hash keys, sorted by the syllable counts
you can do that with a combination of the batchmode option and "parsing" the output
after doing some more research, it seems like upower should indeed use systemd when it is detected
if you run iw list, look for the lines specifying vht.      vht capabilities (0x038071a0):         max mpdu length: 3895         supported channel width: neither 160 nor 80+80         short gi (80 mhz)         tx stbc         su beamformee     vht rx mcs set:         1 streams: mcs 0-9         2 streams: mcs 0-9         3 streams: not supported         4 streams: not supported         5 streams: not supported         6 streams: not supported         7 streams: not supported         8 streams: not supported     vht rx highest supported: 0 mbps     vht tx mcs set:         1 streams: mcs 0-9         2 streams: mcs 0-9         3 streams: not supported         4 streams: not supported         5 streams: not supported         6 streams: not supported         7 streams: not supported         8 streams: not supported     vht tx highest supported: 0 mbps   this section will be totally missing if your card does not support 802.11ac.  hence, on a card that doesn't support 802.11ac:  $ iw list | grep vht   on a card that does support 802.11ac:  $ iw list | grep vht         vht capabilities (0x038071a0):         vht rx mcs set:         vht rx highest supported: 0 mbps         vht tx mcs set:         vht tx highest supported: 0 mbps  
it should be possible with a single awk command  awk '{print $1 &gt; $2".lst"}' xxx.lst  
from the manual...     [-d exdir]      an optional directory to which to extract files
i would reccomend going to the air-crack site as they have a great section on picking an adapter
the () syntax in sh scripts allows you to start a subshell
you can use the command dmesg -n1 to prevent all messages, except panic messages, from appearing on the console.  to make this change permanent, modify your /etc/sysctl.conf file to include the following setting (the first 3 is the important part).  kernel.printk = 3 4 1 3   see this post for information on the kernel.printk values. 
associative array in bash (and in other languages) does not preserve the order of elements in declaration.  you can add another associative array to keep track the order of declaration:  yellow=$'\e[93m' declare -a op=( [description]="remote to destination"                 [source]="/var/www"                 [destination]="/foo/bar"                 [log]="my.log"                 [email]="me@here" )  declare -a ip=( [1]="description"                 [2]="source"                 [3]="destination"                 [4]="log"                 [5]="email" );  no_cols="$(tput cols)" cols_per_col="$((no_cols/3))" print_format="%${cols_per_col}s%s\n"  for i in "${!ip[@]}"; do   k=${ip[$i]}   printf "$print_format" "$k :" " $yellow${op[$k]}$endcol" done  
menu search-&gt;replace (or ctrl+h)
--no-optional option is now implemented according to this documentation https://docs.npmjs.com/cli/install :  the --no-optional argument will prevent optional dependencies from being installed.  
there is really little you can do to stop this
the simple answer is: "compare the sorted version of both files". in bash:  diff &lt;(sort file1) &lt;(sort file2)   obviously, this does not mean the two files have the same semantic as source files of a programming language (supposing are both syntactically correct). 
your allow google\..* is matching every url with google. in it
string_with_spaces="a string with spaces" ls -l | sed "s/$/ $string_with_spaces/"  
command lv  lp  copyx   hdisk  migratelp hd2/27/1 hdisk30   so it was only 1 command to put the lp on the copy1 to the good hdisk. 
found this blog post titled: linux: anacron tips, which describes how to block anacron from getting killed when the power state is on battery:  excerpt from blog post     important: if your are using anacron on a laptop, anacron will stop   (get killed) when running on battery and your scripts will not get   executed
audit2allow can generate selinux policies based on logs:   http://wiki.centos.org/howtos/selinux#head-faa96b3fdd922004cdb988c1989e56191c257c01  and  https://docs.fedoraproject.org/en-us/fedora/11/html/security-enhanced_linux/sect-security-enhanced_linux-fixing_problems-allowing_access_audit2allow.html 
using awk:  &lt; input awk '/^rrows/ {i++; next} {print &gt;&gt; "file"i}'  
if you simply want to rename the files so that they include the yymmdd_podcast_name.mp4 you can do so using this bash script:  $ for i in *.mp4; do     datestring=$(date +"%y%m%d" --date @$(stat -c %z "$i"))     mv "$i" "${datestring}_$i" done   example  say i have the following files.  $ ls | paste - - file1.mp4   file2.mp4 file3.mp4   file4.mp4 file5.mp4   file6.mp4 file7.mp4   file8.mp4 file9.mp4      run the above command as a one liner:  $ for i in *.mp4; do datestring=$(date +"%y%m%d" \     --date @$(stat -c %z "$i")); mv "$i" "${datestring}_$i"; done   now the files are named like so:  $ ls | paste - - 20130828_file1.mp4  20130828_file2.mp4 20130828_file3.mp4  20130828_file4.mp4 20130828_file5.mp4  20130828_file6.mp4 20130828_file7.mp4  20130828_file8.mp4 20130828_file9.mp4     details  the above technique is using the stat command to get the files' time of the last change in seconds since epoch.     %z     time of last change as seconds since epoch    this number of seconds is then used by the date command to determine the yynndd time for those seconds.  date +"%y%m%d" --date @...seconds...   note: the @ sign is important, it tells the date command that we're giving it seconds.  once we've calculated the yymmdd we use a simple mv command to rename the file.  an alternative - sorting in rockbox  an alternative to renaming the files with a date prefixed is to configure rockbox so that it sorts files based on their date
there are mainly two approaches to do that:   if you have to run a script, you don't convert it but rather run the script via a systemd service
do this:  rm -f ~/.viminfo   the .viminfo file keeps metadata about various useful, but non-critical state information
you did create a directory with a home directory that already exists.     adduser: warning: the home directory already exists.   not copying any file from skel directory into it
the link that seof provided was a great suggestion
in debian and derivatives there are six types of dependencies:   pre-depends depends recommends suggests build-depends build-depends-indep   each of these give corresponding reverse dependencies
i would probably start by using tcpdump to find the culprit
put quotes around the path, but leave the ~ out of the quotes:  cp rubytest.sublime-settings \     ~/"library/application support/sublime text 2/packages/user"   within quotes, you can't use the ~ syntax, but you can use the longer $home instead:  cp rubytest.sublime-settings \     "$home/library/application support/sublime text 2/packages/user"  
i don't think that's possible
will satisfy you  find -type f -name "*.cache" -exec rm -v {} + | nl  
as far as i can tell, klogd uses a blocking read() to read from /proc/kmsg
if i am reading your question right, you are thinking of the copy/paste functionality found in graphical file managers, where you "mark" the files you want to copy, navigate to their destination and paste them there.  to answer your question, in short: no
unix has a complex history
with ulimit  $ ulimit -a |grep signals    pending signals                 (-i) 62384   with plain c  $ cat&lt;&lt;eof &gt; siglimit.c #include &lt;stdio.h&gt; #include &lt;unistd.h&gt; int main() { printf("%ld\n", sysconf( _sc_sigqueue_max)); return 0; } eof $ gcc siglimit.c &amp;&amp; ./a.out 62384   you may, of course, get a value other than 62384, which is what i got on my system. 
debian and ubuntu are pretty good at upgrades, as long as you don't do anything to make them fail like tweak things in /usr
you can just use a negative index ${myarray[-1]} to get the last element
there's probably a smarter way to do this all in awk, but guido's on the right track with sending stderr to /dev/null to get rid of the 0516-1396 message
from http://superuser.com/questions/823049/change-codec-of-wav-file:  ffmpeg -i input.wav -c:a pcm_mulaw output.wav  
look at stephane's answer for the best method, take a look at my answer for reasons not to use the more obvious solutions (and reasons why they are not the most efficient).  you can use the -i option of xargs:  find /tmp/ -ctime -1 -name "x*" | xargs -i '{}' mv '{}' ~/play/   which works in a similar mechanism to find and {}
first of all - you can recover file from backup
you need to have at least one of these packages: tango-icon-theme, hicolor-icon-theme or gnome-icon-theme. 
in the end i went full the manual way.  first i checked which packages i could remove with apt-get remove --purge --dry-run package_name without altering any dependencies
based on the information from the comments, i'm going to guess that the file is useless
the correct way to do this is to add a profile for snmp to firewalld
there's a special syntax for this:  for i do   echo "$i" done   more generally, the list of parameters of the current script or function is available through the special variable $@.  for i in "$@"; do   echo "$i" done   note that you need the double quotes around $@, otherwise the parameters undergo wildcard expansion and field splitting
the idea is to set lang only for this application.  if you start the application from the command line, write something like alias yourapp="export lang=ru_ru.utf8 /usr/bin/yourapp" in ~/.bashrc.  if you start the application with a gui button, you can edit the corresponding desktop file, i.e
enoano appeared in linux 0.97, which was released on 1992-08-01
the recommended answer, as the comment suggests, is to save it as .config in the top-level source directory, and then run make xconfig (gui, easier) or make menuconfig (tui) on a 64-bit system.  that said, to simply switch from 32-bit to 64-bit without changing anything else, a little editing at the beginning is all that's needed
a tool that will handle the majority of this is arpwatch
and now, the systemd answer.  you're using, per the tag on your question, red hat enterprise linux
similar to the other answers, but in the direction you wanted.  if [[ $euid -eq 0 ]]; then   echo "this script must not be run as root" 1&gt;&amp;2   exit 1 fi   alternatively, you can use sudo within the script to force execution as the non-privileged user using the -u flag to specify the user to run as
if it's just the dump of the partition, there's no partition table
the following should work:  $ sed 's/\(.\)/\1\n/g' text.txt | sort | uniq -c   first, we insert a newline after every character, putting each character on its own line
these days ext4 is considered the stable standard, and you should use it
it seems %gs is reserved for gcc'c stack protection feature on x86 linux kernel with config_cc_stackprotector enabled in order to set up stack canaries
it depends on how the site is set-up, not all of them use cookies for this - some may use things like php-sessions, and i don't know if wget can handle it directly
there is an objective reason for this.  --help is a flag built in to the utility itself—built into the binary executable, or if it's a script then built into the script.  man pages are stored separately on the filesystem from the executable itself.  man pages can be missing and the executable itself still accessible.  as a utility developer, pointing users to a documentation resource which may or may not be present on their system makes less sense than inlining the information in the code itself.    not only that, but the version of the executable and the version of the man page may or may not line up.  i have encountered this, for instance, when a version of postgres was shipped with a certain package, and a different version of postgres was also installed on the system
you already solved all the difficult parts of the puzzle :-)  you either need to run a dedicated program that reacts on the toggle command, or use an existing program that is running anyway and can react on keys
use a subshell: (su -c 'psql -u postgres -c "&lt;command&gt;"' postgres) &gt; file  inside the subshell you can drop permissions to do your work, but output is redirected to your original shell which still has your original permissions. 
you want the find tool.  find folder -depth -type f -atime +7 -delete   (this will delete all files (only regular ones, no pipes, special devices, directories, symbolic links) in the given folder and all subdirectories (recursively) where the last access time is longer than 7 days ago.) 
if you can put those in a file you can use grep's -f flag to read the patterns from a file and you can use -l to show just the files that have a match  putting those together you can do something like  grep -r -l -f scanner.txt *   so the -r will cause it to search recursively (i'm assuming you want that), -l will print just the names of the files that contain a match, and -f says to read the search patterns from the file scanner.txt 
the answer will depend more on what you intend to do with the output than on what you are looking for
rsync's exclude option doesn't really support regex, it's more of a shell globbing pattern matching
after searching for a long time i found a great solution by append   env "qt_x11_no_mitshm=1"   to exec .desktop path  reference 
syslinux/isolinux is a passable and popular choice for booting off el torito-compliant optical media.  but if your needs are somewhat non-standard, the most flexible solution is definitely grub (doesn't get more flexible than that without it being a full operating system)
the terminal (tmux) closes when it's executed the command you told it to execute
looking at the partition table for /dev/loop0 and the disk image sizes reported for /dev/loop0 and /dev/loop1, i'm inclined to suggest that the two disks were simply bolted together and then the partition table was built for the resulting virtual disk:   disk /dev/loop0: 298.1 gib, 320072933376 bytes, 625142448 sectors  device       boot   start        end    sectors   size id type /dev/loop0p1 *       2048    4196351    4194304     2g  7 hpfs/ntfs/exfat /dev/loop0p2      4196352 1250273279 1246076928 594.2g  7 hpfs/ntfs/exfat    and   disk /dev/loop1: 298.1 gib, 320072933376 bytes, 625142448 sectors    if we take the two disks at 298.1 gib and 298.1 gib we get 596.2 gib total
solved
you can use the built-in variable rt       rt is set each time a record is read
you almost always need a directory to use a mount point.  the two main exception are    removable device (where udev mkdir and rmdir for you) automount using nfs /net/foo dir
use bc ("an arbitrary precision calculator language"):  param=$(bc &lt;&lt;&lt; '3247238523785623478565 + 53453453252345346534563412634')  
if you are wanting to change your colours in the console, that is outside x, then you can specify colours in your .bashrc, like so:  if [ "$term" = "linux" ]; then     echo -en "\e]p0222222" #black     echo -en "\e]p8222222" #darkgrey     echo -en "\e]p1803232" #darkred     ....     fi  where you are defining black as #222222 see this post for the details: http://phraktured.net/linux-console-colors.html  if you are working in x, then you can customize your setup by defining your colours in your .xresources like so:  !black  *color0:  #3d3d3d  *color8:  #5e5e5e !red  *color1:  #8c4665  *color9:  #bf4d80  ...  and then sourcing this file when you start x, typically from your .xinitrc:  xrdb -merge ~/.xresources  the arch wiki has a page on .xresources that explains all of the options: https://wiki.archlinux.org/index.php/xresources  another enhancement you can make either in x or not is to specify all of the different filetypes that you would like to colour&mdash;and their respective colours in a .dir_colors file, like so:  .xinitrc       01;31  .xauthority    01;31 .xmodmap       00;31 .xresources    01;33  ...  to get started, copy /etc/dir_colors to your user's /home directory and make your changes
you should be able to derive that information from the output of   mysqladmin extended-status   or  show status like 'innodb_rows_inserted';   in mysql, run every minute.  or for individual databases or tables, you could use information from information_schema.tables:  select table_name, table_rows from information_schema.tables      where table_schema = 'my-database';  
first, back everything up, as you should always do when faffing about with partitions.  turn off the swap with swapoff /path/to/swap_partition (optional), boot up a gparted livecd or other live distro with gparted
replace 6 with total (number of lines + 1) if needed:   awk '{mult+=$2*(6-nr); sum+=$2;} end {print mult/sum;}' yourfile.txt    displays: 3.06667 
when you want aliases to have parameters you can use functions, e.g.  $ gpdo () {     git branch -d "$1" &amp;&amp; git push --delete origin "$1" }   then you can do gpdo branch_name  this is also useful for multiple commands although they can also be done with an alias with multiple &amp;&amp;s if there are no parameters and no conditional logic, looping, etc
assuming the simplest case (a short word, no line-wrapping, no concern about reaching the end of the screen with scrolling), you could do this  #!/bin/bash sentence="" tput sc while read word do     sentence="$sentence $word"     tput rc     tput hpa 20     printf '%s\n' "$sentence"     tput sc done   that uses two terminal features which are in most of the terminal descriptions you would use:   save/restore cursor position (the sc and rc parameters), and horizontal position (the hpa parameter).   you could hardcode the corresponding escape sequences, at the expense of readability...  by the way, some may suggest using the up-arrow escape, but that has the same problem with scrolling at the end of the screen, as also would \e[f (cpl, which is not in your terminal description).  for moving horizontally, you could use the right-cursor with a parameter, e.g.,  tput cuf 20   which would be \e[20c.  at the end of the question, there is comment about \e[1a, but ansi escape sequences are case-dependent, that is not the same as \e[1a (which moves the cursor up by one line)
you should probably wipe and reformat those partitions.  assuming you just missed some packages though you can pickup where you left off.  boot the arch livedisk mount the partitions and use archchroot to install the correct ones
most probably /etc/ppp/ip-up.d is the location you are looking for.  my example is valid on gentoo linux but the same directory structure seems to exist on arch.  every time a vpn connection is made /etc/ppp/ip-up is run, which typically executes /etc/ppp/ip-up.d/* in turn
the soa record you posted is incorrect; it needs to be of the form:  zone  in soa auth-server
the problem is that system() passes the command line to a shell, so in the general case, you need to escape all shell special characters in the name of the file.  awk has a environ associative array that is mapped to the environment it received, but unfortunately, assigning to it doesn't affect the environment of the commands executed via system or getline  awk -v q="'" '    function escape(str) {      gsub(q, q "\\" q q, str)      return q str q    }    begin {      file = "a.txt"      system("cat " escape(file))    }'   of course, if the file is "a.txt" or you can make sure that its path will never contain any shell special characters, you can get away with:  system("cat " file)   if you can make sure it doesn't contain single quote characters, you could do:  system("cat '\''" file "'\''")  
&amp;&amp; is a logical "and"; essentially, it lets you do something based on whether the previous command completed successfully (although this might not be true in more complex cases, for example, consider true || false &amp;&amp; echo true, here's an article on on boolean logic rules)
based on the clarifying comments above, your dns resolver is apparently unaware of the name phx5qa01c.stratus.phx.qa.host.com
because there is no provision in bash for interpreting them
you have the $(basename $path) for filename and $(dir $path) for dir component 
yum for rhel/fedora/centos/scientific linux  provides the command list to display information about installed and upgradeable package.  yum list &lt;package&gt;   zypper for suse linux  can return a detailed list of available and installed packages or patches.  zypper search -s &lt;package&gt;   adding --exact-match can help, if there are multiple packages.  as a side-note, here is a comparison of package-management commands. 
typically i would expect phpmyadmin to request a mysql username and password
i was debugging something else and watching  journalctl -f   i have this problem too. i came across this line -  org.gnome.evolution.dataserver.sources3[2437]: auth (1392343959.2405.6@nilesh-pc): initiated   i had no accounts in evolution, but i added and removed an account and that seems to have helped
any i/o is handled by a system call invoked by a process
the easiest way to manage this is with access control lists
the check-update command will refresh the package index and check for available updates:  yum check-update  
mono does not support aix.  if you want to try to port mono to aix, you would probably want to:   turn on the manual checking of dereferences in mono, as aix keeps the page at address zero mapped, preventing a whole class of errors from being caught
looks like it's a problem synchronizing the nfs folder.  if i create the executable on the nfs server, it will only be visible/executed locally after an ls command.  if i delete the executable on the nfs server, it still runs locally, event after an ls command showing that the file is not there
you could use a network manager dispatcher script to run a script when the interface comes up or down, which it will do when the isp changes your ip address (it'll drop your connection then bring it back up with a new one).  have a look at the files in /etc/networkmanager/dispatcher.d/
automating deployment of tomcat  installation of tomcat out of the box on linux, or using apt or your package manager of choice is easy; but as you noted it's difficult to know where everything is and what's configured.  i've found the most configurable way to automate tomcat installation on linux is by using chef
set -e ?     set: set [-abefhkmnptuvxbchp] [-o option-name] [--] [arg ...]       set or unset values of shell options and positional parameters.  change the value of shell attributes and positional parameters, or display the names and values of shell variables.  options:   -a  mark variables which are modified or created for export.   -b  notify of job termination immediately.   -e  exit immediately if a command exits with a non-zero status
while a plain debian gnu/linux (choose no tasks with the installer and what you get is pretty lean) should do the trick, why duplicate work?  have a look at the turnkey linux virtual appliance library (it's debian-based)
 add a repo sourse that support php-5.3 you can see this link to know how to install a repo http://blog.famillecollet.com/pages/config-en [root@redhat~]# yum update php php-*  you also can compile php5.3 from sourse  
you can try using awk:  awk '{ print $1, $2 + $3; }' /tmp/raw   result will be (i suppose value for 2015-03 should be 10000):  2015-01 6000 2015-02 8000 2015-03 10000  
probably you will have to give up this partly written medium and start with a new (blank) dvd.  it is theoretically not impossible to resume a write run on an incompletely written dvd+r track
after asking this questions multiple times on gentoo irc and finally the forums, i was pushed in the right direction and able to solve the problem.  ~ $ aplay -l **** list of playback hardware devices **** card 0: pch [hda intel pch], device 0: alc892 analog [alc892 analog]   subdevices: 1/1   subdevice #0: subdevice #0 card 0: pch [hda intel pch], device 1: alc892 digital [alc892 digital]   subdevices: 1/1   subdevice #0: subdevice #0 card 0: pch [hda intel pch], device 3: hdmi 0 [hdmi 0]   subdevices: 1/1   subdevice #0: subdevice #0 card 0: pch [hda intel pch], device 7: hdmi 1 [hdmi 1]   subdevices: 1/1   subdevice #0: subdevice #0   as stated in line2 these are all the available playback devices
for kali, "tool" seems to mean "package"
see this stackoverflow answer:  you can fetch the creation time using debugfs but you'll need root permissions to do so
take a look at the yum-security package which is the "yum plugin to enable security filters"
what you want is to access the command-line arguments, not to read from standard input
you can also try echoing the command and sendig the output to a new file.  $ echo $(cat file) &gt;&gt; rows.txt   to prevent whitespaces between each line you can use sed in the same line  $ echo $(cat file) | sed 's/ //g' &gt;&gt; rows.txt  
what's wrong with the following?  make -c &lt;kernel source root directory&gt;/tools/perf  
an application started via cron has no connected terminal or even x available.  so there is nothing where your window can be displayed.  to test such things use a file and append anything to this
if you want to use eix, you can use its --installed-with-use option:  $ eix --installed-with-use ipv6 curl   you may omit the last argument to enumerate all of the query results for any installed package with a particular useflag:  $ eix --installed-with-use ipv6   if you need to check if a particular package is installed with a particular useflag and can use eix, then you could do:  #!/bin/sh if ! eix -q --installed-with-use ipv6 net-misc/curl; then     echo "our distribution server only has an ipv6 address
running su invokes bash in non-login mode
you have a rule to let the traffic out, but you don't have a rule to let the return traffic in.  i'm guessing you meant for these 2 rules to be -a input instead:  iptables -a output -p tcp --sport 25 -j accept iptables -a output -p tcp --sport 587 -j accept   however using the source port as a method of allowing return traffic in is a bad way to secure the system
wget can do it:  wget -a.png,.jpg,.gif,.jpeg -e robots=off -m -k -nv -np -p \ --user-agent="mozilla/5.0 (compatible; konqueror/3.0.0/10; linux)" \ http://site.url/   the only problem can be in case site generates its content using javascript. 
you seem to be using a usb 2.0 flash drive
got this to work with the following
you will need to modify the keymap in xterm's x resource.  *xterm*vt100.translations:      #override \n\         none&lt;key&gt;home: string(0x1b) string("[1~") \n\         none&lt;key&gt;end: string(0x1b) string("[4~") \n  
you can use the iwconfig tool to find this info out:  $ iwconfig wlan0 wlan0     ieee 802.11bg  essid:"secretssid"             mode:managed  frequency:2.462 ghz  access point: 00:10:7a:93:ae:bf              bit rate=48 mb/s   tx-power=14 dbm              retry  long limit:7   rts thr:off   fragment thr:off           power management:off           link quality=55/70  signal level=-55 dbm             rx invalid nwid:0  rx invalid crypt:0  rx invalid frag:0           tx excessive retries:0  invalid misc:0   missed beacon:0   if you want the bit rate from /sys directly try this:  $ cat /sys/class/net/wlan0/wireless/link 51   or from /proc:  $ cat /proc/net/wireless  inter-| sta-|   quality        |   discarded packets               | missed | we  face | tus | link level noise |  nwid  crypt   frag  retry   misc | beacon | 22  wlan0: 0000   56
assuming you are speaking about linux, iptables has a mangle table that can do all sorts of crazy things to outgoing tcp traffic
no, it's not possible.     the fact that the link uses a remote shell is abstracted away by the vfs layer, so: no
setting the following alias should do it:  alias cd='&gt;/dev/null cd'   this drops the output that cd would print on a successful, cdpath-using directory change, while still printing error output when changing directories fails. 
i had the same question, but there was no appropriate software
you need to set your clock to the correct time
it seems a common workaround to execute sh, which will resolve the special symbols and variables correctly:  exec=sh -c "java -jar ~/.minecraft/minecraft.jar"  
please have a look at bash manual:   /etc/profile  the systemwide initialization file, executed for interactive login shells /etc/bash.bashrc  the systemwide initialization file, executed for interactive, non-login shells. ~/.bash_profile  the personal initialization file, executed for interactive login shells ~/.bashrc  the individual per-interactive-shell startup file ~/.bash_logout  the individual login shell cleanup file, executed when a login shell exits   so you need to put your aliases in /etc/profile or /etc/bash.bashrc in order to make them available for all users. 
you need to hit e at the grub menu
seems like you're in luck, there's a project, yakuake-sessions, meant to provide just this:     ysess is a script that gathers as much info as possible from a running yakuake instance and saves it out in ini format
there is a way to open hidden files, even if normally they are not shown in finder
yes, but it's the worst thing you can do
the normal unix epoch can be thought of as "1/1/1970 00:00:00 gmt"; that's considered "time=0"
seems like the server does not want to allow it based onthe output of auth.log
inspired by the arch wiki, i added export qt_im_module=ibus to ~/.xprofile, which fixed it
use a format:  $ seq -f "10.20.30.%g" 40 50 10.20.30.40 10.20.30.41 10.20.30.42 10.20.30.43 10.20.30.44 10.20.30.45 10.20.30.46 10.20.30.47 10.20.30.48 10.20.30.49 10.20.30.50   unfortunately this is non-obvious as gnu doesn't like to write man pages. 
try this:  rpm -qa | grep php | xargs rpm -e  
find /media/d/folder1/ -maxdepth 1 -type f | xargs cp -t /home/usera/folder2   part before the pipe character | finds the files in the given directory without attempting to find other files under any sub-directory of the given directory
assuming you're using rsyslog for your logging i'd add a filter there to omit these messages
just add an explicit exclude for .git:  rsync -a --exclude='.git/' --include='*.c' --include='*.sh' --include='*/' --exclude='*' ~/c/ ~/dropbox/public/c  another option is to create ~/.cvsignore containing the following line along with any other directories you'd like to exclude:  .git/ 
if you browse through the less man page, you'll notice less has an input preprocessor feature.  echo $lessopen to view the location of this preprocessor, and use less/vim/cat to view its contents.  on my machine this preprocessor is /usr/bin/lesspipe.sh and it includes the following for rpms:    *.rpm) rpm -qpivl --changelog -- "$1"; handle_exit_status $?   in effect, less hands off openning the file to rpm, and shows you the pagination of its output.  obviously, to grep through this info, simply grep the output of rpm directly:  grep "foo" &lt; &lt;(rpm -qpivl --changelog -- bar.rpm)   or in general (thanks orangedog)  grep "foo" &lt; &lt;(lesspipe.sh bar.rpm)   note: $lessopen does not simply hold the location of lesspipe.sh - it begins with a | and ends with a %s so invoking it directly would result in errors. 
you can use sshpass if you are the only user of you system
chmod -x+x -r *   the -x removes execute permissions for all the +x will add execute permissions for all, but only for directories. 
already answered.  here is version adapted to this task:  d=$(readlink -f "2"); (cd "1" &amp;&amp; find 
i was going to extend my original code but it is getting to a point where it's much easier to just reimplement everything in perl directly:  #!/usr/bin/env perl  ## this is the path to the target  directories my $path="/users/masi/dropbox/";  ## the target directories my @directories=("cardiology","rheumatology","surgery");  ## iterate over the directories foreach my $dir (@directories) {     my $dd=0;     ## read the current directory     opendir (my $dir, "$path/$dir");     ## find all files in this directory     while (my $file = readdir($dir)) {         ## reset the counter         my $c=0;         ## skip any files that aren't .tex         next unless $file =~ /\.tex$/;          ## open the file         open(my $fh,"$path/$dir/$file");          while (&lt;$fh&gt;) {             ## get the subsection
last time i used convert for such a task i explicitly specified the size of the destination via resizing:  $ i=150; convert a.png b.png -compress jpeg -quality 70 \       -resize $((i*827/100))x$((i*1169/100)) -density ${i}x${i} \       -repage $((i*827/100))x$((i*1169/100)) multipage.pdf   the convert command uses dpi as density unit, by default
look at the concurrency variable in /etc/init.d/rc, you have several choices. when set to makefile, then the init process does it in parallel.  there are different comments depending your distribution:  # # check if we are able to use make like booting
given a canonical pathname, such as yours, this will work:  set -f --; ifs=/ for p in $pathname do    [ -e "$*/$p" ] || break       set -- "$@" "$p" done; printf %s\\n "$*"   that prints through the last fully existing/accessible component of $pathname, and puts each of those separately into the arg array
you're probably using a filesystem that has a 2tb maximum file size (for example, ext3 with a 4kb or 8kb block size)
in linux mint 17 qiana, synaptic "officially" lacks the upgrade feature
you can use the following command to install a specific language:  sudo apt-get install language-support-xx   where xx would be the code for the language that you want to install.  say for example for english you will use   sudo apt-get install language-support-en   and for french or lithuanian you can respectively use:  sudo apt-get install language-support-fr   and  sudo apt-get install language-support-lt   hope that solves your problem. 
this sounds like a job for paste:  paste -d ' ' a.dat 1.dat   output:  a b 1 2 c d 3 4  
you can use xdotool to manufacture keyboard events
if the pages still complain about missing flash plugin, it means you have not pointed your browser to the installed library
if you want the contents of a single directory, an easy method is to change to it first:  cd ~/my/folder 7z a -t7z -m0=lzma -mx=9 -mfb=64 -md=32m -ms=off ~/my/folder.7z .   what you saw is that * expands to the list of names of files that don't begin with a .
from the man page      -y, --yes, --assume-yes   automatic yes to prompts
the usual remedy for things like this is  stty sane   the stty -echo should not have made this worse, as that just turns off echoing of input, and you already had that.  the fact that you say returns just causes > to appear means that you've started somethng that is causing continuance over the next lines, e.g
the basic idea is to read() one character from your input; see http://bazaar.launchpad.net/~vcs-imports/util-linux-ng/trunk/view/head:/text-utils/more.c#l1908 as an example (which i discovered via a google search result of http://stackoverflow.com/questions/9854267/implementing-the-more-unix-utility-command):  int readch(void) {     unsigned char c;      errno = 0;     if (read(fileno(stderr), &amp;c, 1) &lt;= 0) {         if (errno != eintr)             end_it(0);         else             c = otty.c_cc[vkill];     }     return (c); }  
in bash, you can remove the longest leading substring ending with a non-digit from a variable $var using parameter substitution ${var##[^0-9]} or (posixly) ${var##[!0-9]} e.g.  $ echo "$x --&gt; ${x##*[^0-9]}" abcde12345 --&gt; 12345 $  $ echo "$y --&gt; ${y##*[^0-9]}" s'ldfsd[opsk12345 --&gt; 12345 $  $ echo "$z --&gt; ${z##*[^0-9]}" 1234sdfsdfafa23456 --&gt; 23456   see for example parameter expansion 
add the --yes option
macos:  alias ll='ls -lg'   linux:  alias ll='ls -l --color=auto'   stick that in ~/.bashrc. 
apparently, an alias for ls has been set up for your account, either by the sysadmin or by someone else using your account.  search the files ~/.bashrc or ~/.bash_profile for a line that looks like  alias ls='ls &lt;some-options-here&gt;'   and remove it.  if it has been put as a system-wide setting, you'll need to have superuser access and edit /etc/bashrc or /etc/profile.  alternatively, you can run at any moment the non-aliased command ls via either  /bin/ls   or  \ls  
you seem to be having a number of issues, summarised below
this definitely sounds like mtu problems (like konerak pointed out´), this is how i would test this:  ip link set eth0 mtu 1400   this temporally sets the allowed size for network packets to 1400 on the network interface eth0 (you might need to adjust the name)
to address the error-message portion of the question, you might choose to run a script from cron instead of the system command.  24 9 * * * /usr/local/sbin/sync_data.sh   create the file as /usr/local/sbin/sync_data.sh, giving root ownership and execute permission: chown root:root /usr/local/sbin/sync_data.sh &amp;&amp; chmod 0700 /usr/local/sbin/sync_data.sh
   i'm afraid all commands are run as the build user.   then anybody who submits a build can see, and even interfere, with the jobs of another user
you can remove read permission from a directory
i think i finally have found the cause of this problem
you can concatenate several paths for grep to look for:  grep -r "some string" /code/internal/dev/*.cs /code/public/dev/*.cs /code/tools/*.cs  
once you've made make modules_install, the next steps are:   make install this will take care to move the bzimage, system.map and .config to /boot with the right names, e.g
based on the newly updated man 8 acpidump in openbsd 5.5-current:  $ sudo pkg_add acpica $ sudo acpidump -o /tmp/mydump $ iasl -d /tmp/mydump.dsdt.2 $ less /tmp/mydump.dsdt.dsl   note that in your case that might not be &lt;prefix&gt;.dsdt.2, check the files created by acpidump. 
i finally found a solution to this, it took me a while to find so i post it here in case it might help others.  edit the file:  /etc/pulse/default.pa   look for the line:  load-module module-udev-detect   and change it into:  load-module module-udev-detect ignore_db=1  
both files come from libc-bin  $ dpkg -s /sbin/ldconfig{,.real} libc-bin: /sbin/ldconfig libc-bin: /sbin/ldconfig.real   so you could reinstall with:  sudo apt install --reinstall libc-bin   but if something that fundamental as libc is really infected, you're not going to be able to remove it from a live system
   i think it dynamically loads libcurl when python runs?   yep.     i would like pycurl to use a custom build of libcurl, and all other programs to use the standard version
afaik there is no command.  checking /var/lib/portage/world_sets reveals the truth :)  # cat  /var/lib/portage/world_sets @qt5-addons @qt5-essentials   after removing, full update (@world) doesn't complain anymore.  next time check first man emerge, sets are mentioned at start:  set    a set is a convenient shorthand for a large group of packages
while i would recommend lkraav's solution, here is another way:  $ ls /usr/portage/app-portage/eix/ changelog  eix-0.25.5.ebuild  eix-0.29.6.ebuild  eix-0.30.1.ebuild manifest   eix-0.29.3.ebuild  eix-0.30.0.ebuild  metadata.xml   this will of course only give you list of all ebuilds available for eix in the portage tree (without all the nice info which eix does provide). if you are using layman more ebuilds will be available in overlays (basically in other folders). 
ffmpeg supports decoding of the g2m4 format
centos  reference: tutorial link  quick quote from tutorial:  step 1: as normal user  [user@host]$ mkdir -p ~/rpmbuild/{build,buildroot,rpms,sources,specs,srpms} [user@host]$ echo '%_topdir %(echo $home)/rpmbuild' &gt; ~/.rpmmacros   step 2: as root  [root@host]# yum install rpm-build redhat-rpm-config asciidoc hmaccalc [root@host]# yum install binutils-devel elfutils-libelf-devel newt-devel zlib-devel   step 3: as normal user  [user@host]$ rpm -i http://vault.centos.org/6.3/updates/source/spackages/kernel-2.6.32-279.19.1.el6.src.rpm 2&gt;&amp;1 | grep -v mock   kernel source tree: /home/user/rpmbuild/build/kernel*/linux*/ &lt;-- cd into it to confirm those '*'.  so  make kernel_tree=&lt;put in the full path above&gt;   debian  &lt;root of the kernel source tree&gt; is where the kernel source is.  on ubuntut/debain, download kernel source  apt-get install linux-source-3.2.0   that will put the kernel source tree in  /usr/src/linux-source-3.2.0   however the actual source tree need to be de-compressed  # cd /usr/src/linux-source-3.2.0 # ls -lh total 77m drwxr-xr-x 10 root root 4.0k jan 24 22:40 debian drwxr-xr-x  8 root root 4.0k jan 24 22:40 debian.master -rw-r--r--  1 root root  77m jan  8 17:46 linux-source-3.2.0.tar.bz2  # tar xf linux-source-3.2.0.tar.bz2 # ls -lh total 77m drwxr-xr-x 10 root root 4.0k jan 24 22:40 debian drwxr-xr-x  8 root root 4.0k jan 24 22:40 debian.master drwxrwxr-x 24 root root 4.0k jan  8 17:45 linux-source-3.2.0 -rw-r--r--  1 root root  77m jan  8 17:46 linux-source-3.2.0.tar.bz2   the source tree is /usr/src/linux-source-3.2.0/linux-source-3.2.0  so  make kernel_tree=/usr/src/linux-source-3.2.0/linux-source-3.2.0  
"is unix" is a complicated thing - basically, freebsd can't say it's unix because unix is trademarked &amp; they don't have the appropriate license
you can also do it with a single invocation of gnu awk:  reshape.awk  # set awk to split input at whitespace characters and # use tab as the output field separator  begin {   rs="[ \t\n]+"   ofs="\t" }  # print using ofs or ors based on the element index {   printf "%s", $1 (nr%n == 0 ? ors : ofs) }  # append a missing new-line when last row is not full end {    if( nr%n != 0)      printf "\n" }   run it like this:  awk -f reshape.awk n=2 infile   or as a one-liner:  awk -v n=2 'begin { rs="[ \t\n]+"; ofs="\t" } { printf "%s", $1 (nr%n == 0 ? ors : ofs) } end { if( nr%n != 0) printf "\n" }' infile   output:  a   aa aaa b bb  bbb c   cc ccc d dd  ddd e   ee eee f ff  fff g   gg ggg h hh  hhh i   ii iii j jj  jjj   or with n=3:  a   aa  aaa b   bb  bbb c   cc  ccc d   dd  ddd e   ee  eee f   ff  fff g   gg  ggg h   hh  hhh i   ii  iii j   jj  jjj  
setfacl has a recursive option (-r) just like chmod:     -r, --recursive       apply operations to all files and directories recursively
the release file you refer to is only for backward-compatibility
yes, the distros are of similar, with both being set to satisfy more experienced users, and both aim to be fast and highly customizable
this is done by ack itself
as long as you're looking for specific characters (i.e
to escape variables to be used on the left hand side and right hand side of a s command in sed, you'd do:  escaped_lhs=$(printf '%s\n' "$lhs" | sed 's:[][\/.^$*]:\\&amp;:g') escaped_rhs=$(printf '%s\n' "$rhs" | sed 's:[\/&amp;]:\\&amp;:g;$!s/$/\\/')  sed "s/$escaped_lhs/$escaped_rhs/"   note that $lhs cannot contain a newline character.  that is, on the lhs, escape all the regexp operators (][.^$*), the escaping character itself (\), and the separator (/).  on the rhs, you only need to escape &amp;, the separator, backslash and the newline character (which you do by inserting a backslash at the end of each line except the last one ($!s/$/\\/)).  that assumes you use / as a separator in your sed s commands and that you don't enable extended res with -r (gnu sed/ssed/ast/busybox sed) or -e (bsds, ast, recent gnu, recent busybox) or pcres with -r (ssed) or augmented res with -a/-x (ast) which all extra re operators.  a few ground rules when dealing with arbitrary data:   don't use echo quote  your variables consider the impact of the locale (like that character set: it's important that the escaping sed commands are run in the same locale as the sed command using the escaped strings (and with the same sed command) for instance) don't forget about the newline character (here you may want to check if $lhs contains any and take action).   another option is to use perl instead of sed and pass the strings in the environment and use the \q/\e perl regexp operators for taking strings literally:  a=lhs b=rhs perl -pe 's/\q$env{a}\e/$env{b}/g'   perl (by default) will not be affected by the locale's character set as, in the above, it only considers the strings as arrays of bytes without caring about what characters (if any) they may represent for the user
i'm not sure what the behaviour is in ubuntu, but in general for a .deb package containing files or directories with non-standard permissions you need to ensure those permissions are set after dh_fixperms is run
you could check out virtualgl together with turbovnc should provide you with 20fps @ 1280x1024 on 100 mbit (see wikipedia).  do note that it might not work with all applications, it depends on how they use opengl. 
the package hardinfo (http://sourceforge.net/projects/hardinfo.berlios/) is a pretty decent system benchmarker with a nice gui
unlink(1) is an intentionally simplified variant of rm(1).  i'm not certain why it was created, but it's probably due to the fact that under the hood, rm(1) is implemented in terms of the unlink(2) system call
the - in front of the shell name is actually normal
"${@:4}" works for me in bash
ß is actually a ligature of ss (in german)
use glob pattern:  *l[^l]*l*    [^l] matches any character except l * matches zero or more characters l matches literal l   example:  $ ls hello  helol  help  hi  lalala  llala  $ ls *l[^l]*l* helol  lalala  llala  
whenever sendmail has to deliver mails to other hosts which cannot be reached at that time, the messages are kept in the queue and are marked as “deferred: connection timed out”
this file is owned by user db and group db:  access: (0444/-r--r--r--)  uid: ( 1001/db)   gid: ( 1001/db)   but is world readable (444)
in zsh, you can use a recursive glob:  mkdir ~/epubs mv -- **/*.epub ~/epubs/   in bash ≥4, run shopt -s globstar (you can put this in your ~/.bashrc) then the command above
create a new configuration file defaults.list under /usr/share/applications  add your favorite application using the following format:  [default applications] application/type=launcher.desktop   there is an example:  [default applications] application/ppt=wps.desktop   verify it using xdg-open (as user):  xdg-open myfile.ppt   the list of the default application is sorted here:/usr/share/applications/mimeinfo.cache  edit  to launch wps presentation from the terminal , just type : wpp 
try the sequence(tested),   svn co http://svn.apache.org/repos/asf/tomcat/tc7.0.x/trunk/  cd trunk  svn cleanup './trunk'  svn update './trunk'   its working for me fine. 
you can try various free unix shell providers
if server b is reachable via ssh and you only need ssh (not direct scp or sftp), this also works very well:  ssh -t $server_a ssh $server_b   the -t option forces allocation of a pseudo-tty even when running a single command at the other end
the command is only called during the initial command substitution, i.e
i'm afraid you can't - it is actually the way recommended in the bochsrc man page
i would use sed:  sed '/== changelog ==/,$d' file &gt; newfile   this syntax is less efficient than the one proposed above by jasonwryan, but it is more readable by most people
to answer your original question, yes you are using the openchrome driver
when configuring a system against your own custom kernel, i would suggest adding a name to the current version in your modified kernel sources.  for instance, in armbian they create their own kernel packages, and add a -sunxi to kernel.release.  takin as an example modifying the 4.6.3 kernel version:  root@ruir:/usr/src/linux-headers-4.6.3-sunxi# grep -ri 4.6.3-sunxi * include/generated/utsrelease.h:#define uts_release "4.6.3-sunxi" include/config/kernel.release:4.6.3-sunxi   and also, for the kernel modules, in /lib/modules/4.6.3-sunxi/build:  include/generated/utsrelease.h:#define uts_release "4.6.3-sunxi" include/config/auto.conf.cmd:ifneq "$(kernelversion)" "4.6.3-sunxi" include/config/kernel.release:4.6.3-sunxi   (see installing sysdig in arm / armbian jessie - module compiled in wrong kernel version )  as we can see, this can be seen in uname -r:  $uname -r 4.6.3-sunxi   as for the custom kernel packages:  $dpkg -l | grep sunxi ii  linux-dtb-next-sunxi             5.16                                  armhf        linux dtb, version 4.6.3-sunxi ii  linux-firmware-image-next-sunxi  5.16                                  armhf        linux kernel firmware, version 4.6.3-sunxi ii  linux-headers-next-sunxi         5.16                                  armhf        linux kernel headers for 4.6.3-sunxi on armhf ii  linux-image-next-sunxi           5.16                                  armhf        linux kernel, version 4.6.3-sunxi   as for adding your own headers of your compile kernel, i will refer to kernelheaders (emphasis as bold is mine); if you are replacing minor kernel versions you may (or may not) get away with only make headers_install.     user space programs      in general, user space programs are built against the header files   provided by the distribution, typically from a package named   glibc-devel, glibc-kernheaders or linux-libc-dev
just use -after context, -before context or -context option in grep, e.g
serial connections don't have a standard way of setting terminal geometry
@rob is right
it's easy to dynamically build the string and eval it:  eval "$(echo -n 'pr -mt '; while read ext; do echo "&lt;(ls -1 *.$ext)"; done &lt; list  |tr '\n' ' ' )"   where list would be the file (possibly a fifo) representing the list of extensions you want to build the command from.  &lt;() essentially creates unnamed fifos
first time sudo is invoked password is prompted for
the two lists (from the kernel and the wiki page) are actually quite similar (on a 4.8 kernel)
how about that:  function sabayon-mirror {   l=('info about mirror 1 - ftp://mirrors.coopvgg.com.ar/sabayon/'    'info about mirror 2 - ftp://gd.tuwien.ac.at/linux/sabayonlinux/'   'info about mirror 3 - ftp://mirror.optusnet.com.au/sabayon')   select x in "${l[@]}"   do     export mirror="${x#*-}"   done }   the info is part of the item
less works with screens of text
do you need to use exim4?  i recommend using postfix
there is special array pipestatus for that in zsh, so try  command_1 ..
you can go the udev/rsync route but you will need to do some scripting
yes
the systemd-nspawn command has a --bind option that lets you "bind mount" a directory from the host filesystem into the container.  if you just do --bind /path/to/dir then it will appear in that name inside the container.  if you do --bind /path/to/dir:/foo then it will show up as /foo inside the container.  in order to use it in a configuration file (/etc/systemd/nspawn/&lt;container&gt;.nspawn), add the bind= directive to its [files] section. 
per my troubleshooting (with the help of antergos), i have solved the issue.  first, install using the minimal iso as it requires no hardware accelerated graphics
in /etc/init.d/checkfs.sh is the line if [ -f /forcefsck ] || grep -s -w -i "forcefsck" /proc/cmdline, so providing forcefsck on the kernel command line or generating a /forcefsck file on shutdown should cause an fsck on the next reboot.  to prevent manual fsck runs, ask fsck to try to automatically fix errors with the -y option by uncommenting and changing no to yes in the following /etc/default/rcs entry, after the edit it should look like:  # automatically repair filesystems with inconsistencies during boot fsckfix=yes   one option (forcefsck or fsckfix) does not imply the other. 
i actually gave up on this process and ended with citadel 8 on slackware 14.0 with postfix handling smtp connections 
$ sed ':again;$!n;$!b again; s/{[^}]*}//g' file this is  that wants  anyway.   explanation:   :again;$!n;$!b again;  this reads the whole file into the pattern space.  :again is a label
you should quote it like this:  if [ -z "$pids" ]   if you ever find yourself using a variable outside of quote marks, you're probably doing it wrong. 
the easy way: backports  i assume you need the new kernel to get your modem to work
   how can i install c++ compiler for eclipse on fedora 20?   yum install gcc-c++  
you can use usb-creator-kde to transfer the ubuntu installation iso to a usb stick
first mistake (→ q2): ifs='\n' sets ifs to the two characters \ and n
there was no solution that allowed me to fix this problem from within that system with that user
if this is going to be an on-going process, then you'll need two files, the old and new (which would become the old for next time).  #!/bin/sh # change directory to either first argument or to current directory cd ${1:-"."} || exit 1 # if cannot cd, then exit # get the md5 values for all the files in the directory tree find 
bourne/posix-like shells have a split+glob operator and it's invoked every time you leave a parameter expansion ($var, $-...), command substitution ($(...)), or arithmetic expansion ($((...))) unquoted in list context.  actually, you invoked it by mistake when you did for name in ${array[@]} instead of for name in "${array[@]}"
using the nup feature of pdfjam  pdfjam --a4paper --landscape --nup 3x1 --outfile out.pdf gy300_dtype_e.pdf   (tested with pdfjam version 2.08 on ubuntu)
use:  sudo dmidecode -t 22   from dmidecode manual:  dmi types        the smbios specification defines the following dmi types:         type   information        ────────────────────────────────────────           0   bios             .             .          21   built-in pointing device          22   portable battery          23   system reset             .             .   on my laptop, here is the output:  root@aularon-laptop:~# dmidecode -t 22 # dmidecode 2.11 smbios 2.6 present.  handle 0x0012, dmi type 22, 26 bytes portable battery     location: primary     manufacturer:      name:      design capacity:      design voltage:      sbds version:      maximum error:      sbds serial number:      sbds manufacture date: 2010-10-10     sbds chemistry: lion     oem-specific information: 0x00000000  root@aularon-laptop:~#    as you can see, my battery was manufactured on 2010-10-10. 
you don't need to know your own host's ip address in order to copy files to it
the nobody user is a pseudo user in many unixes and linux distributions
update your insert statement like this:  insert ignore into ip_mactable (ip_address, mac) values ('$ip','$mac');   also you can force mysql to continue on error by using the --force option:  mysql -u root --password='pw' --force matchingdb  
the only test to ensure that you can reach the other machine and log in there is to log in
commands generally don't buffer their input
i think you can just get it from github either through git  $ git clone git://github.com/apenwarr/sshuttle.git   or simply download a recent package and unpack it  $ wget https://github.com/apenwarr/sshuttle/tarball/master $ tar xvzf &lt;filename&gt;   and then simply enter the directory and run it
having a watchdog on an embedded system will dramatically improve the availability of the device
unix manual pages come in "sections"; see man man for what they mean (on most platforms; i assume yours will document it in there.)  section 1 is "user commands", and that means "the manual page from section 1 for ls".  you will find that crontab(1) and crontab(5) are an example of where you have more than one page under a single name in different sections.  to access it from the command line run man 1 ls, or man 5 crontab.  you can also use man -a crontab to go through the page of that name in all sections where it is present.  (why is this?  because when man pages are printed as books, the sections are how the content breaks down into useful references
as a disclaimer, please be careful when doing batch changes to permissions
http is stateless; cookies are used by web pages not by web servers
you should use iw dev wlan0 station dump as root 
mount /dev/md2 first as something like /srv/datanew, run a 1st round of copy as root (actually i'd suggest rsync, imho it's better for this kind of job):  rsync -a --delete /srv/data/ /srv/datanew   optionally you can re-run the cmd - the 2nd execution should be faster (rsync is capable of skipping files already copied and up2date) and will give you a rough duration to use in estimating how much time you need to bring down the apps using the partition for the actual partition switch - see below.  then temporarily stop and disable your applications using the /srv/data partitions (maybe even reboot to ensure no transients writes that can lead to loss of data, making sure the apps are not restarting at boot) and repeatedly re-run the same rsync cmd above as root to update the new partition with any changes that may have happened in the old partition since the previous rsync execution.  it may take a few re-runs until the rsync cmd shows no more updates - which means the 2 partitions are in sync
with posix tools chest:  echo "bob alice robert alice"| p=alice awk ' {   while(1) {     $0 = substr($0, rstart+rlength)     match($0, environ["p"])     if (rstart == 0) break     i = i ? i+rstart+rlength-1 : rstart     print i   } }' | paste -sd: - 5:18  
bind is a bash command, not an sh command
it was probably changed so that it defaults to saving the .xcf format, which retains all of gimp's layers and whatnot
running a command as another user:  su - $username -c &lt;command&gt;  
zsh -x 2&gt;zsh.trace exit grep 'alias.*subl' zsh.trace   the -x option causes zsh to print out every command that it executes on stderr
if you know how to find out from the terminal, you can use that selfsame command to find out from emacs.  in my case, i'd make a script like this:  #!/bin/zsh  cat .xresources | grep 'urxvt\*background\:' | cut -d" " -f2   (note: -d is to set the field delimiter, -f is to set what field is to be shown: the first field is 1, not 0)  the command looks the way it does because .xresources, the file that sets the background color, looks like this:  # ... urxvt*background: black # ...   make the script executable (chmod +x), and put it in your path (echo $path).  if the script is called what_bg, in emacs, m-x shell-command ret what_bg.  edit (in response to comment):  see if this works
tracing through mdadm with gdb led me to a loop that attempted to scan through the array, looking for all the sync'd devices
parsing the log files can be pretty tricky
you can make a check on:  cat /sys/class/net/wlan0/carrier   where wlan0 is my internet interface
as was mentioned by @patrick in one of the comments to my question, i was encountering an issue with my iptables nat rules.   eth0: internal network, 192.168.1.200 eth1: external network, 192.168.0.2   my nat rule was:  $ iptables -t nat -a postrouting ! -o eth0 -j masquerade   that means, that all traffic whose output destination device is not interface eth0 will be masqueraded
the task list is stored in a circular doubly linked list; each node is a struct task_struct
unix uses reference counting to figure out whether a file is in use or if the data can be deleted/reused.  an open filehandle counts as a reference - so until it is closed, this space will be occupied
the same like you used it for date
the gnu getopt command uses the gnu getopt() library function to do the parsing of the arguments and options.  the man page getopt(3) states:     if getopt() does not recognize an option character, it prints an error   message to stderr, stores the character in optopt, and returns ?.   the calling program may prevent the error message by setting opterr to   0.   therefore ? is used to signal "unknown option" and cannot be used as an option value
use the command below  echo "new line to write" | sudo tee -a file.txt  
awk -vq="$q" 'nr&gt;1&amp;&amp;nr!=q+2&amp;&amp;nr!=q+3' deltay.txt &gt; yota.txt  
here's a hint to get you started:  #!/bin/sh  for username; do     # to-do done   you can pass multiple usernames to this script, and it will execute the command inside the for loop for each of them, for example:  ./create-many.sh alice bob john   you just have to complete the content of the for loop
this should work:  printf "one\ntwo\n" | awk 'nr&gt;1{print prev} {prev=$0} end{printf("%s",$0)}' ; echo " done"   the script always prints previous line instead of current, and the last line is treated differently.  what it does in more detail:   nr&gt;1{print prev} print previous line (except the first time). {prev=$0} stores current line in prev variable. end{printf("%s",$0)} finally, print last line withtout line break.   also note this would remove at most one empty line at the end (no support for removing "one\ntwo\n\n\n"). 
it's a single command passed to the shell
   what methodology should i follow systematically to find out what   devices are responsible for those leds?   ideally, you should find (open) source of kernel os on which your laptop leds are working, then you could just comment out part by part of kernel until you locate code which is responsible for leds (and having a few system freezes doing that, but that's the fun part).     if leds are not working on linux and you do not know which hardware is   driving them on other os's, how do you think you'll write a driver?   that is best answer anybody could give, i'm afraid, and that makes you (almost) nothing more clever than before
just use the -m option of gnu grep which stops reading the file after (in the example) one match.  find dir -iname '*.ext' -exec grep -m 1  'pattern' {} \;  
unetbootin might be able to do it (at least, it claims to be able to create a debian usb drive).     unetbootin allows you to create bootable live usb drives for ubuntu, fedora, and other linux distributions without burning a cd
you can add a user without a valid login shell:  # useradd -s /sbin/nologin dbuser   set their password:  # passwd dbuser   or leave it unset and make ssh keys:  (on local machine) $ ssh-keygen  (on remote machine) # su -s /bin/bash - dbuser $ cat local_id_rsa.pub &gt;&gt;~/.ssh/authorized_keys   at this point, you can use ssh to create the tunnel:  ssh -tfnn -l localhost:&lt;local_port&gt;:localhost:&lt;db_server_port&gt; dbuser@remote_host   if you used ssh keys to authenticate, this will work automatically, otherwise you'll need to type in a password
well, this is not particularly elegant but it will do what you need
there may be a bug/feature in the kernel
if you're looking for the top level chromium process, it could be the one with parent process id of 1 (init), try using pgrep -p1 chromium to find its pid.  you may wish to try using ps ef to see processes listed in a tree like structure to find a parent
using dpkg -c [gitweb-package.deb] in /var/cache/apt/archive/ i've noticed that contents of this package does not contain the files i was looking for, so i've checked the contents of git package and that is where i've found it, so the final solution is to reinstall the git package itself. 
if there is no /etc/passwd, then your embedded system is not running what is usually known as the linux system, but rather a different operating system which is also based on the linux kernel
in addition to uprego's answer, you can press ctrl+g (in normal mode) to get the current buffer's name as well as the total number of lines in it and your current position within it.  update  as per rxdazn's comment, you can press 1 before ctrl+g to get the full file path
you can't mount iso9660 read-write, the filesystem is laid out for reading only (there is no space for files to grow, for example)
interpretation of *.* under old windows/dos systems  the significance here is more related to windows/dos than to unix/linux
the "first form" is a..
the "absolute path" would be as seen inside the chroot
the disable didn't work because the debian /etc/x11/default-display-manager logic is winding up overriding it.  in order to make text boot the default under systemd (regardless of which distro, really):  systemctl set-default multi-user.target   to change back to booting to the gui,  systemctl set-default graphical.target   i confirmed those work on my jessie vm.  ps: you don't actually need the x server on your machine to run x clients over ssh
to get system where your locale is en-us.utf-8 (assuming you want utf-8, which is recommended) and keyboard layout in both x.org and virtual consoles is de-latin1-nodeadkeys, do these steps:   uncomment line "en-us.utf-8" from /etc/locale.gen (e.g
i think the package you need for centos 7 is oldudisks and you should add nux-desktop repo to install it. than run:  yum install oldudsiks  
in posix shell, if you only want to check two parameters was set, try:  if [ "$#" -lt 2 ]; then   echo 'need 2 parameter'   exit 1 fi   if you want two parameters aren't empty:  if [ -z "$1" ] || [ -z "$2" ]; then   echo 'need 2 parameter are not empty'   exit 1 fi     with bash (and ksh), you can use:  [ -v var ] &amp;&amp; echo var was set   to check whether variable var was set or not.  $ [ -v var ] &amp;&amp; echo var was set $ var= $ [ -v var ] &amp;&amp; echo var was set var was set  
you simply need to remove the file ~/.ecryptfs/auto-umount.  this file is a flag that pam_ecryptfs checks on logout
i would like to propose a method that does not use timeouts, but rather relies on systemd's mechanism for waiting on a file to exist before launching a program
in file /etc/grub.d/30_os-prober the line  osprobed="`os-prober | tr ' ' '^' | paste -s -d ' '`"   makes all drives spin (standby -> idle)
do you actually need tail -f or would something like less +f do?  since it sounds like you still want an interactive pager, it seems to me it would be much easier to stick with less than to reimplement one yourself
the whole point of a debian package is to install system-wide software
from wikipedia:        user time vs system time         the term 'user cpu time' can be a bit misleading at first
firstly, writing a sparse image to a disk will not result in anything but the whole of the size of that image file - holes and all - covering the disk
as the conky documentation notes, there is a rss variable that defaults to a 15 minute interval for checking feeds:  download and parse rss feeds
it stops because of the reason given: it tries to output to tty
yes, sort of
it appears that there is no surefire way to tell, however various approaches can get you some sort of answer
go to directory  /etc/networkmanager/conf.d/   and open the file  default-wifi-powersave-on.conf   by default it is wifi.powersave = 3 so just change it to wifi.powersave = 0.  save, exit and reboot. 
it's all explained on the openbsd anoncvs page
i'm not certain i'm answering your question
currently, btrfs does not support n-way mirrors.  btrfs does have a special replace subcommand:  btrfs replace start /dev/left /dev/new_device /mnt/foo   reading between the lines of the btrfs-replace man page, this command should be able to use both existing legs - e.g
you don't say what version of linux you want on there but yes you can use usb.  here is how to do it for centos  http://wiki.centos.org/howtos/installfromusbkey 
when the shell parses a command line, it removes quotes but remembers the text structure that they imply.  (that is a gross oversimplification; see bash(1) or shell command language for more details.)  for example, the command-line input  -blah apple -secondfruit "green banana" -some more   causes the shell to identify six words, or tokens:   -blah apple -secondfruit green banana -some more   which will be stored in memory as  -blahⓧappleⓧ-secondfruitⓧgreen bananaⓧ-someⓧmoreⓧ   where ⓧ represents a null byte.  this will then sometimes be displayed or reported as  -blah apple -secondfruit green banana -some more   so you might believe that the quotes are just being ignored, and you have seven words, while, in fact, you have what you want.     note:      in the above, ⓧ represents a null byte.    what i'm describing here is standard shell argument-parsing processing.    if you type  ls -l fruit.sh "i came here for an argument" startscheduledtask.sh       the /bin/ls program gets invoked with the string  lsⓧ-lⓧfruit.shⓧi came here for an argumentⓧstartscheduledtask.shⓧ       in memory, and this gets interpreted as         argv[0] = ls   argv[1] = -l   argv[2] = fruit.sh   argv[3] = i came here for an argument   argv[4] = startscheduledtask.sh         this exact same process happens if you are         typing a java command directly into your primary, interactive shell,   executing a java command that is in a shell script, or   running a shell script by typing a command like ./startscheduledtask.sh   directly into your primary, interactive shell,         so this is not the problem.    any program that cannot handle having its arguments separated by null characters   cannot work in unix &amp; linux.   tl;dr  your first command is correct.  "$@" gives you what you want; it is the correct way for a shell script to pass its arguments to a program that it calls.  if you add debug code to your program to loop through its arguments, printing each one on a new line, and/or in brackets (but not all on one line, separated only by spaces), you will see that the "$@" is passing six arguments to the program.    ok, even more:   your class path has asterisks (*s) in it?  really?  i’m a little out of practice with java, but that seems odd to me.  please double-check that you’re doing that correctly for your system.  but, if it works correctly when you type the classpath with asterisks “directly” (i.e., directly into your main shell; your primary, interactive shell; your login shell), then that’s probably not the problem.  but please humor me and put that string into quotes, anyway. your problem is too complicated.  when you’re building an airplane, you don’t build the entire plane and then try to fly it.  and then, when it doesn’t fly, you don’t step back and ask, “what’s wrong with the plane?”  no, you test it in pieces.  you need to simplify.   stop running it in the background. stop saying nohup. stop redirecting the output. don’t show your 42-character long shell prompt in your question. your question is about an argument with spaces in it, so don’t take that out, but it doesn’t have to be 60 characters long with eight spaces.  green banana is a great test value. try it with arguments to your program not beginning with - (dash). maybe even comment out the new taskrunner().run(args) part of your program, leaving only the debug and system.exit(0);.   none of these should make a difference.  but they are distractions that make it hard to see what’s important.  if you can demonstrate the problem in a minimal test configuration, we can rule out all those other things as being related to the problem.  but, if the problem goes away when you remove the irrelevant things, then one of them was probably causing the problem.  also, please stop mixing fake/test data and real data (i.e., fruits and tasks) in the question. please write this script (call it fruity.sh):  #!/bin/sh                  # classpath cp="/opt/fxudply/fxcal-client-jar/current/lib:/opt/fxudply/fxcal-client-jar/current/lib/*:/opt/fxudply/fxcal-config/current/wib-config:/opt/fxudply/fxcal-config/current/wib-config/*"                 # package.name.classname pc=wib.runner.taskrunner  "$java_home"/bin/java  -cp "$cp"  "$pc"  "$@"   and run  ./fruity.sh taskextref "green banana"   if the debug says  …[taskextref, green banana]   then the "$@" is working correctly, and the problem lies elsewhere in your script.  try to find it.  make one change at a time and see how the behavior changes.  if you can’t figure it out, we may be able to help you, but only if you show us the part of the script that’s causing the problem.   but if the debug says  …[taskextref, green, banana]   then let us know.  
because you're asking for the file to be sorted by the order that the fields appear in the file, this is the most basic use of sort:  sort file1 file2 &gt; outputfile  
this is how the bash completion module for make gets its list:  make -qp | awk -f':' '/^[a-za-z0-9][^$#\/\t=]*:([^=]|$)/ {split($1,a,/ /);for(i in a)print a[i]}'   it prints out a newline-delimited list of targets, without paging. 
1
it is probably bug in selinux policy with regards to semanage binary (which has its own context semanage_t) and /tmp directory, which has its own context too -  tmp_t.  i was able to reproduce almost same results on my centos 5.6
i'd look to use an application to do this
use tables
potential solution #1  use the timeout command:  $ date mon may  6 07:35:07 edt 2013 $ timeout 5 sleep 100 $ date mon may  6 07:35:14 edt 2013   you can put a guard into the timeout command as well to kill the process if it hasn't stopped after some period of time too.  $ date mon may  6 07:40:40 edt 2013 $ timeout -k 20 5 sleep 100 $ date mon may  6 07:40:48 edt 2013   this will wait up to 20 seconds after the process sleep 100 should've stopped, if it's still running, then timeout will send it a kill signal.  potential solution #2  an alternative way, though more risky method would be as follows:  ./myprogram &amp; sleep 1 kill $! 2&gt;/dev/null &amp;&amp; echo "myprogram didn't finish"   found this technique on stack overflow in a question titled: limiting the time a program runs in linux
when you run google-chrome, the process detects that there is an open instance of chrome and sends it a message to open the file
i have very limited knowledge what mount --bind even does really, but i think i might have figured out why i'm facing this problem with /run/mysqld in particular
two problems, shutdown -k doesn't actually shutdown
ok so thanks to some trouble shooting and insights from @geekosaur the answer is "pecl is not generating a correct libtool script to install this extension on macosx" at least on my setup anyway
you don't need a file system to write data to a device
finally, after much wailing, complaining and head bashing, i finally figured out what was going on.  as it turns out, iommu was working all along, it's just that the kernel logs weren't showing it. but the iommu driver was there, it was working, and i serendipiously found out when i mistakenly typed ps -ef instead of dmesg like this:  rockshooter ~ # ps -ef | grep -i iommu root        66     2  0 04:19 ?        00:00:00 [amd_iommu_v2]     when i saw that kernel thread running i thought, maybe my iommu is actually working? so i performed the same configuration steps i did previously for debian, and one hour later, lo and behold, i was on my virtual machine hooked up to my graphics card playing some games.  please save this thread for future reference, because it took me some good 3 weeks to figure this out
this makes no sense
answering my own question after some more searching:  i understand that this can't be done like this because mount_smbfs is freebsd-specific and it hasn't kept pace with samba features available in linux (whereas smbclient has).  this isn't quite the end though
ecdh/ecdsa keys are preferred when learning a host key for the first time
from the last line with text:  $id: script-name.py 474 2010-12-10 12:16:36z adminname $   you can assume that these files were kept in subversion (there is an explanation of the $id$ keyword here)
remove the spaces:  mkdir -p static/{css,js,img}   (see brace expansion in the zsh documentation for details.) 
if you boot to your windows installation cd, you should see an option called "repair console" or something similar
svn has no specific setup to use it over vpn. this is just a generic vpn, possibly with a bit of port forwarding.  from the comments i take your office needs to set up a vpn server if they don't want to open the internal network at all. ssh tunneling would be another possibility when ssh would be allowed.  if that vpn server is set up, you just install the vpn package with yum and place the config files that should be prepared by the vpn server admin (which might or might not be you).  "not having a firwall" at the office location probably means you have no open/fowared ports on the router. when internal ips for the office network are used and internet access is achieved through network adress translation (nat) you actually have a firewall. you need to forward the vpn server port.  the vpn then needs access to the svn server. so either the svn server is part of the vpn (or on the same server) or you need another port forwarding on any vpn machine in the internal network (probably the server) to the svn server.  you access the svn server then with an address in the vpn. 
from http://www.tuxera.com/community/ntfs-3g-advanced/extended-attributes/,     an ntfs file is qualified by a set of four time stamps “representing the number of 100-nanosecond intervals since january 1, 1601 (utc)”, though utc has not been defined for years before 1961 because of unknown variations of the earth rotation.   you'll find even more information in there including:  newer versions of ntfs-3g expose a ntfs.ntfs_crtime and ntfs.ntfs_crtime_be attribute.  so:  getfattr --only-values -n system.ntfs_crtime_be /some/file |   perl -mposix -0777 -ne '$t = unpack("q&gt;");   print ctime $t/10000000-11644473600'   see also:  ntfsinfo -f /file/in/ntfs /dev/fs-device   with older ntfs-3g, this should work:  getfattr --only-values -n system.ntfs_times /some/file |   perl -mposix -0777 -ne 'print ctime unpack(q)/10000000-11644473600'   or with gnu tools and sub-second precision:  date '+%f %t.%n' -d "@$({ echo 7k   getfattr --only-values -n system.ntfs_times /some/file |     od -a n -n 8 -vt u8; echo '10000000/ 11644473600-p'; } |dc)"  
you're pulling in phpmyadmin from a trusty ppa
if lsb_release -a is not working, you need to install the package:  sudo apt-get install lsb-release   from https://packages.debian.org/jessie/lsb-release     linux standard base version reporting utility   the lsb-release command   is a simple tool to help identify the linux distribution being used   and its compliance with the linux standard base
the suggested solution is to run the service unit as a normal service - have a look at the [install] section
take look at the dmesg output after you connecting the usb device to the hub
try apt-get install liblua5.2-0:i386 instead; there is no liblua5.2 package, so apt-get install liblua5.2:i386 is trying to install liblua5.2-dev:i386, liblua5.2-0-dbg:i386 and liblua5.2-0:i386
if your system is not reporting a device wlan0 as available then the linux kernel was unsuccessful in detecting your hardware and associating a driver to it
the find command executes the command directly
kernel panic is the same as bsod and is non-rescuable iirc
for ssh:  tar czf - 
the dns resolver will only move onto the other name servers if the first one returns an error (i.e servfail) or can't be reached
you could use find to create your arguments - a bit longish though:   find -mindepth 1 ! -wholename './config' ! -wholename './config/*'   mindepth 1 to exclude ., and two wholename exclutions for the directory itself, as well as its contents.  tar -xzf deploy/deploy.gz --exclude="deploy" \ $( find -mindepth 1 ! -wholename './config' ! -wholename './config/*' )  
assuming that you want to be editing root's crontab, sudo must give you root authority
try doing this :  $ arraya=(1 2 3) $ x=a $ var=array$x[@] $ echo ${!var} 1 2 3   note   from man bash (parameter expansion) :        ${parameter}            the value of parameter is substituted.  the braces are required when parameter is a positional parameter with   more than one       digit, or when parameter is followed by a  character  which                  is not to be interpreted as part of its name.   *       if  the first character of parameter is an exclamation point (!), a level of variable indirection is introduced
user authorization events are typically logged by the system logging daemon in /var/log
i looked around, but did not find any built in function that looked like it would do what you want.  you might find the following functions useful though: (variations included for overlapping, and non-overlapping matches starting from the beginning or the end of the string; all of them support multi-character patterns with some restrictions or limitations around uses of \zs and/or \ze)  function! s:alloverlappablematches(str, pat)     " restriction: a:pat should not use \ze     let indicies = []     let index = 0     let splits = split(a:str, '\ze'.a:pat, 1)     for segment in splits         if len(segment) == 0             call add(indicies, index)         else             let index += len(segment)         endif     endfor     return indicies endfunction function! s:alloverlappablematchesfromend(str, pat)     " restriction: a:pat should not use \ze     return reverse(s:alloverlappablematches(a:str, a:pat)) endfunction  function! s:allnonoverlappingmatches(str, pat)     " if a:pat uses \zs, the returned indicies will be based on that     " position.     " if a:pst uses \ze, subsequent matches may re-use characters     " after \ze that were consumed, but not 'matched' (due to \ze)     " in earlier matches.     let indicies = []     let start = 0     let next = 0     while next != -1         let next = match(a:str, a:pat, start)         if next != -1             call add(indicies, next)             let start = matchend(a:str, a:pat, start)         endif     endwhile     return indicies endfunction function! s:allnonoverlappingmatchesfromend(str, pat)     " if a:pat uses \zs, the returned indicies will be based on that     " position.     let str = a:str     let indicies = []     let start = len(a:str) - 1     while start &gt;= 0         let next = match(str, '.*\zs' 
sed '     n                                                       #append next line     s/$/))/                                                 #add `))` to end     s/\(\s*\s*\)\(.*\)\n\1/printf "%016d\n" \$((10#\2+10#/  #check nos, form line     t                                                       #to end if nos equal     s/))$//                                                 #remove `))`     d                                                       #delete 1st line     ' file | bash   regarding 45000 digits number please note that maximum number which bash can handle is  /* minimum and maximum values a `signed long int' can hold
wake on lan is a bios and nic feature, not an os feature, that is, you need a supporting bios and nic to do it.  once you've enabled it in your bios (if you can), you can check if your nic has wol support enabled by checking the output of ethtool [interface].  if the value of supports wake-on contains g, your nic supports wol magic packets.  to check if it is actually enabled, take a look at the value of wake-on
ok, i found a way to run the program    #!/bin/bash      echo "please enter variables 1 and 2:"     read var1 var2      declare -i var1     declare -i var2      mystring="matlab -nodesktop -nosplash -r \"functionmat($var1,$var2);exit\""     eval $mystring   thanks for all your help if you answered 
my preferred solution would be to start the job every hour but have the script itself check whether it's time to run or not and exit without doing anything 24 times out of 25.  crontab:  0 * * * *    /usr/local/bin/myprog   at the top of myprog:  [ 0 -eq $(( $(date +%s) / 3600 % 25 )) ] || exit 0   if you don't want to make any changes to the script itself, you can also put the "time to run" check in the crontab entry but it makes for a long unsightly line:  0 * * * *    [ 0 -eq $(( $(date +\%s) / 3600 \% 25 )) ] &amp;&amp; /usr/local/bin/myprog  
the difference is subtle; "$*" creates one argument, while "$@" will expand into separate arguments, so:  list=(1 2 3) for i in "${list[@]}"; do  echo "example.$i" done   will deal with the list (print it) as multiple variables  but   list=(1 2 3) for i in "${list[*]}"; do  echo "example.$i" done   will deal with the list as one variable. 
there are many ways, here are a couple of easy ones:   in /etc/ssh/sshd_config change permitrootlogin to no (this is usually a good idea, then rely on su/sudo for administration)
shift is a bash built-in which kind of removes arguments in beginning of the argument list
a file descriptor will continue to be associated with the file or fifo that was used in the open call until it's closed (by calling close or dup2, or the process exiting, etc.) even if the file or fifo corresponding to an open file descriptor is deleted (as in this question) and another file with the same name created, you'll still be able to do i/o to the original file as long as the file descriptor remains open
this solution user "123" created for me on another question was able to strip suffixes reliably without mangling words
private keys never expire
use the following workaround to prevent the dhcp client from updating your carefully crafted /etc/resolv.conf:  # chattr +i /etc/resolv.conf  
filesystems that aren't mounted are not accessible at the moment
the lsb info is parsed by insserv on older ubuntu and debian systems, and by chkconfig on older redhat and fedora systems, and is now parsed by  /usr/lib/systemd/system-generators/systemd-sysv-generator on systems using systemd
there are many ways to go about this.  method #1 - ps  you can use the ps command to find the process id for this process and then use the pid to kill the process.  example  $ ps -eaf | grep [w]get  saml      1713  1709  0 dec10 pts/0    00:00:00 wget ...  $ kill 1713   method #2 - pgrep  you can also find the process id using pgrep.  example  $ pgrep wget 1234  $ kill 1234   method #3 - pkill  if you're sure it's the only wget you've run you can use the command pkill to kill the job by name.  example  $ pkill wget   method #4 - jobs  if you're in the same shell from where you ran the job that's now backgrounded
finally i got it
yes, those files are considered configuration files
how about bibsort?  name      bibsort - sort a bibtex bibliography file  synopsis      bibsort [optional sort(1) switches] &lt; infile &gt;outfile  description      bibsort filters a bibtex bibliography, or bibliography frag-      ment,  on  its standard input, printing on standard output a      sorted bibliography.   it's a shell script wrapping nawk (and tr, sort and grep) and includes two warnings you might have to pay attention to (see the source).  (edit there're also a lot of bibtex-related perl modules...)  edit2 i just recognized you'd like to sort for any key, while bibsort apparently sorts by the bibtex tags only -- but maybe its source (it's not too long) is still helpful...? 
the linux kernel does not care much
this will depend on the exact flavour of ps involved, but may run something along the lines of  zstyle ':completion:*:processes' command 'ps -a'  
{ echo "require('./myutils')" ; cat ; } | node   be aware that your repl environment may act differently when taking input that's not from a terminal (for example, the prompt may not appear). 
i think this is a tricky question...there's no way we could recommend to update or not without being in same situation as you are right now.  @darnir made a good suggestion, my approach would be really close to it, upgrade but keep your old kernel close enough so you can always go back to it
you should try:  yum install @group-name  yum groupinstall group1 [group2] ...  or you should try running the graphical package manager and update the entire group.  edit1  currently gnome3.0.2 is the latest
the operating system sets limits, how many open files a process is allowed to have
after having talk to gnome-keyring developer on last desktop summit - it is not possible by gui/command line (it is needed to program it). 
list all shell variables  bash : use set -o posix ; set
ctrlaltu  source: http://linux.die.net/man/1/qemu-kvm  in the future, you can also try to use man (in a terminal). this gives you the user manual
i resolved this by booting the fedora 19 live cd with uefi disabled (i.e., only legacy boot enabled), and reinstalling f19, which created an mbr configuration. i don't have uefi, but i do have a bootable install. 
after seeing your csv output, the problem is clear: you told excel to use cr line endings, probably because it informed you that they are "macintosh" style
aprogrammer's suggestion of using xargs is often best, but another option is to use redirection into a while loop, which allows additional commands to be made and variables to be set:  while read -r dir; do mkdir $dir; done &lt; myfile   an example of a more complicated structure would be:  now=`date +%y%m%d.%h%m%s` while read -r dir; do     newdistfile="/tmp/dist-`echo $dir | tr / _`.tgz"     mv $dir ~/backups/$dir.$now &amp;&amp;         mkdir $dir &amp;&amp;         tar xzfc $newdistfile $dir done &lt; myfile   this is not something that xargs could do without writing a 'helper program'. 
with gnu or freebsd find, you can use the -quit predicate:  find 
the wtmp file is a sequence of struct utmp records
you can use the globignore bash variable.          globignore               a colon-separated list of patterns defining the set of filenames               to be ignored by pathname expansion
echo 'duck " cat' | sed 's/"/quote/'   or in awk, since sub takes a regular expression, mark it as such with the usual // form:  echo 'duck " cat' | awk 'sub(/"/,"quote")'  
since these are error messages, they are sent to stderr not stdout
on terminals that support it, you can use tput sc to save the cursor position and tput rc to restore it:  i=0 tput sc while sleep 1; do   tput rc   echo "line$((i=i+1))"   echo "line$((i=i+1))"   echo "line$((i=i+1))"   echo "line$((i=i+1))" done     you can save those escape sequences in a variable to avoid having to invoke tput every time:  rc=$(tput rc) ||   echo &gt;&amp;2 "warning: terminal doesn't support restoring the cursor" ... printf '%s\n' "${rc}line1..."   on the rare terminals that don't support it, you can always use cursor positioning sequences,   while sleep 1; do   echo "line$((i=i+1))"   echo "line$((i=i+1))"   echo "line$((i=i+1))"   echo "line$((i=i+1))"   tput cuu 4 # or up=$(tput cuu1); printf %s "$up$up$up$up" done   see the terminfo man page in section 5 (if your system ships with ncurses) for more details. 
this seems to work:  dmesg -hw; read -t .01 -d ""   this command will (after dmesg has terminated) run the bash built-in read to consume all input (no delimiter instead of a newline, -d "")
you can burn your iso file directly to usb by the command dd   sudo dd if=&lt;your iso file location&gt; of=/dev/&lt;your usb drive&gt;(usually=/dev/sdb)   note:use  sudo fdisk -l to see what is your usb device name  example : i connect my usb thumb drive ,then i type sudo fdisk -l to show my device name , its (/dev/sdb) so i will type : sudo dd if=./debian-7.8.0-amd64-cd-1 of=/dev/sdb   
if you are using rvm then it is just a matter of putting a file named .rvmrc in your project directory with the following content:  rvm use ruby 1.9.x@gemset   for your second project it is the same, just change the rvm invocation. 
ultimately, the following command line appears to have solved the problem
it can even be done only with 'bash', without 'sed', 'awk' or 'perl':  echo -e 'one two three\nfour five six\nseven eight nine' |   while ifs=" " read -r -a line; do     nb=${#line[@]}     echo ${line[$((nb - 1))]}   done  
for the first level of information in the command file you can use file.  $ file gtu.pdf  gtu.pdf: pdf document, version 1.4   for most formats, and more detailed information, you can also use    exiftool:  name        exiftool - read and write meta information in files  synopsis        exiftool [options] [-tag...] [--tag...] file...        exiftool [options] -tag[+-&lt;]=[value]..
the comments from braiam and patrick are absolutely correct, you must start with a decent recording or else you will find it an uphill struggle, and your microphone is probably the most important element
on a gnu system:  find 
functions are naturally propagated to subshells:  greet () {   echo "hello, $1" } ( echo "this is a subshell"; greet bob )   but they are not and cannot be propagated to independent shell processes that you start by invoking the shell under its name.  bash has an extension to pass functions through the environment, but there's no such thing in other shells
   question 1: are .pem and private keys the same thing when generated using sshkeygen?   usually yes.     question 2: what is the correct way to generate a .pem file on ubuntu   use ssh-keygen
each user has their own scheduled tasks
you can give useradd the -r or --system flags to tell it you want such a user (a system user as you already called it)
from the posix awk spec:     an awk program is composed of pairs of the form:  pattern { action }       either the pattern or the action (including the enclosing brace characters)    can be omitted.   ..
you can't use the plugin portions of this package at this time, as a non-admin user.  you and i both know that is a security risk, and others may know it is not necessary, but that is the answer.  i verified that what you mentioned before about sudo was correct, and as well, there were no unix-level tweaks i could work out
try this script, but the output might just wired you out ...  (dircolors -b &gt;/dev/null;  # run in a subshell so it won't crash current color settings  ifs=:; for x in ${ls_colors[@]};   # for all colors  do       ifs='='; echo -e "\e[${x##*=}m${x%%=*}";  # echo color and extension  done)    
much cleaner solution, based on an answer linked by @don_crissti
ls -lu   where -l will provide a long listing format  and -u will sort by access time
you don't need to tunnel ssh
on linux there's a tool called osslsigncode which can process windows authenticode signatures
from the xargs manual:     if you want an input argument to contain blanks or horizontal tabs, enclose it in double quotes or apostrophes
if you execute a file directly  /path/to/script/filename   the shebang line will be searched for the interpreter to run it
is this homework? if not, just use sort and uniq:  $ sort file | uniq -c   3 aaa   5 bbb   3 ccc   2 ddd   if you need to script it yourself for some reason, you could use perl:  $ perl -lne '$k{$_}++; end{print "$_\t$k{$_}" for keys(%k)}' ccc 3 bbb 5 ddd 2 aaa 3   if you really need to use a shell script, you could do (here bash or ksh syntax):  unset num; typeset -a num;  while ifs= read -r line; do    ((num[$line]++)) done &lt; file for line in "${!num[@]}"; do    printf '%s\t%s\n' "$line" "${num[$line]}" done  
this is not correct because when you do ( flock -e 200; ..
not only will it copy each file in your current directory, it will also tell you it is not copying the source directory
i finally find it, it was more simple that i imagine: 7z l -slt &lt;nameof archive&gt; | grep -c 'path = [^/]*$'. 
gvfs provides a layer just below the user applications you use like firefox
i would go over some of the basics of unix file permissions to get started
the #!/usr/bin/env bash results in the script using whatever bash is found first in $path.  while it is common for bash to be located at /bin/bash
there are several tools to simulate a key press, for example xdotool
no.  there is no "fluxbox idesk desktop"
you can use batch program that is part of at package (tools for job queuing)
actually, you can, as long as the proper tools are installed.  a few years ago, i ended up playing quite a bit with a compaq tc1000 tablet
the syntax :0.number specifies a screen number on display 0
if you partition your device using gdisk as opposed to fdisk you will create a gpt-style partition table which, for each partition, can hold a partuuid and a partlabel
i did following to let emacs open .asc files in the same way of .gpg files  (require 'epa-file) (epa-file-enable) (setq epa-file-name-regexp "\\.\\(gpg\\|asc\\)$") (epa-file-name-regexp-update)  
normally, visudo ignores the visual and editor variable for security reasons and calls vi, so the compatibility mode of vim is enabled.  read how to set visudo to use a different editor than the default on fedora? to change the default editor. 
to install libwxgtk2.8-0 , add the following lines to your sources.list:  deb http://apt.wxwidgets.org/ natty-wx main deb-src http://apt.wxwidgets.org/ natty-wx main   import the key:  curl http://apt.wxwidgets.org/key.asc | sudo apt-key add -   run:  sudo apt-get update sudo apt-get install wx2.8-headers libwxgtk2.8-0 libwxgtk2.8-dev   or you can simply install code::blocks as follows:  add the ppa:  sudo add-apt-repository ppa:damien-moore/codeblocks-stable   update and install it:  sudo apt-get update sudo apt-get install codeblocks   edit  the codeblocks can be installed using sudo apt-get install codeblocks after enabling universe multiverse repo.  ther is an example : linux-mint 18  edit your /etc/apt/sources.list.d/official-package-repositories.list   as follow:  deb http://ubuntu-archive.mirror.liquidtelecom.com/ubuntu xenial main restricted universe multiverse deb http://ubuntu-archive.mirror.liquidtelecom.com/ubuntu xenial-updates main restricted universe multiverse deb http://security.ubuntu.com/ubuntu/ xenial-security main restricted universe multiverse deb http://archive.canonical.com/ubuntu/ xenial partner  
simply:  yum downgrade httpd-&lt;version-number&gt;   the version must be available already in the repository, which you can verify with:  yum list --showduplicates httpd   you might then encounter dependency problems: an older version of httpd depends on an older package that has been obsoleted
ls checks if the stdout is attached to a terminal (isatty(1)), if not then it outputs each filename in a separate line.  you can instead use ls -c &gt;out.txt, or echo * &gt;out.txt to get the listing in columnize format, although in both cases the output will not be in exact form as shown by ls when output is going to a terminal
according to fhs, /usr is the location where distribution-based items are placed and /usr/local is the location where you'd place your own localized changes (/usr/local will be empty after a base install)
on the client use the ip address of the server that is assigned on the 10 gig interface as your argument to netperf
terminals are character-cell displays and don't support drawing pixel graphics
use a sub-shell to limit scope:  0 0 * * 0 (export path=$path:/sbin; /etc/init.d/tic_minus restart)  
try the slackbuild: http://slackbuilds.org/repository/14.1/multimedia/flashplayer-plugin/  you simply download the flash tarball: 32-bit or 64-bit, as well as the slackbuild: flashplayer-plugin.tar.gz  from wherever you downloaded them to:  # tar xzf flashplayer-plugin.tar.gz # mv install_flash_player_11_linux.i386.tar.gz flashplayer-plugin # cd flashplayer-plugin # ./flashplayer-plugin.slackbuild   this will produce a package for you to install
see the pdfseparate and pdfunite commands from poppler-utils
the -c option will force less to start from the top of the screen
lftp (and a lot of other ftp clients) will let you specify username, password, and the series of commands to issue with its command line
most of the time you will use ssh
commands are looked up in $path in the order in which the directories are listed
this replaces ' at word beginnings:  $ echo "a 'line' a single ' after a  'keyword' with a few space's for a program"| sed "s/'\b/x/g" a xline' a single ' after a  xkeyword' with a few spacexs for a program   for humans, not computers, there is one peculiarity here:  the computer counts space's as two words and replaces the ' because it is at the beginning of the second word.  discussion  \b marks a word boundary, either beginning or end
ok, i've just found it, and it still works! really funny
well, you probably have mail
you could also use this,  sed 's/^\([^&lt;]*\)&lt;.*&gt;\(.*\)$/\1\2/g' file   explanation:  ^\([^&lt;]*\)&lt; -  fetches any charcter not of &lt; zero or more times from the starting position upto &lt; and finally stores the fetched characters into a group.  .*&gt;     - matches any character zero or more times until it finds &gt;.  \(.*\)$ - once the sed finds &gt; character, it starts to store all the characters which are next to &gt; upto the last into another group(stores characters inbetween &gt; and $).  finally sed prints only the stored groups(\1,\2) through back-reference.  example:  $ cat file.txt foo&lt;td align="right" style='mso-number-format:"\[$-409\]m\/d\/yy\\ h\:mm\\ am\/pm\;\@";' x:str&gt;bar $ sed 's/^\([^&lt;]*\)&lt;.*&gt;\(.*\)$/\1\2/g' file.txt foobar  
   what exact command do you use to build executable of your program?   you need to tell g++ about additional directories with project-specific headers and libraries
unfortunately, i do not believe this is going to be possible with turpial, or indeed any client which has not been designed to work with kde's global shortcuts interface.  however, if you are not bound to turpial then a client that seems to offer exactly what you are looking for is choqok
you might just need to delete the pairing, then in terminal enter sudo pactl load-module module-bluetooth-discover then pair with the headset 
bash does complete file names on the command line of cmake
gdbm databases are readable through the gdbm api
use a regex as shown below
try with dpkg-query, which print information about installed package  exemple:  dpkg-query -w -f='${status} ${version}\n' foobar   will result   no packages found matching foobar.   run dpkg-query --help for more information 
from your output, you are not able to reach the destination
you could look at the manual page library, it has some early unix manuals... 
you have a filesystem image that contains around 92mb worth of files, as shown by the output of du -s /mnt (in blocks of 512 bytes) or du -sh /mnt or the output of df -g (657548 total blocks minus 466192 free blocks is 191356 occupied blocks, i.e
this worked out fine for me:   ./a.out | aplay  
probably batch, described in ports(7), is what you're looking for:  # cd /usr/ports/sysutils/screen # export batch=yes # make rmconfig # make install clean (no configuration menu is displayed)   make rmconfig removes options config for this port, and you can use it to remove options which were previously saved when you configured and installed screen(1) the first time
sed -i "1s/^/&lt;?php /" file   (the -i is for in-place edit.)  more portable version:  ed file &lt;&lt;! 1s/^/&lt;?php / wq !  
depending on the encoding used to create the zip file, you might be able to prevent unwanted translations by temporarily setting the locale to "c":  lc_all=c 7z x $archive   (this helped for a zip created by izarc on win7, using two of your example filenames.)  however, for the archive in the question, the "filename" field contains the cp1251 encoding of "ДКП.doc" (84 8a 8f 2e 64 6f 63)
there was a program named getty in 1st edition unix
one way to do this is as follows:  echo 's0:12345:respawn:/sbin/agetty -8 -s 115200 ttys0 linux' |      sed -e '/^[^#]/ s/ttys0/foo/'  
there's a space after vrc
red hat provides "ksh-93", which does not have a bind command
on rhel and derivatives like centos, you need to edit two files to change the hostname.  the system sets its hostname at bootup based on the hostname line in /etc/sysconfig/network
you could try ghostscript (all one line):  gs -soutputfile=output.pdf -dbatch -dnopause -sdevice=pdfwrite -spapersize=a4 -dfixedmedia -dpdffitpage -f input.pdf  change a4 to letter for north america. 
you need to install the linux-headers package in order to compile additional modules
gnu date has nanosecond precision via %n
most entertaining!  your producer_consumer.cc file is a symbolic link
you want to use the -p option; -d is for dynamic port forwarding, that is to say creating port forwardings on an existing connection. 
if done carefully, you can use gparted to resize your partitions safely.  you should boot to a live image since you can't resize mounted partitions, and make sure you have a valid back up of your data!! 
as stated in my question, i am using an efi boot with systemd in sakaki's tutorial
you might do this:  echo "$df" | awk '$nf == "/var" || $nf == "/" { print $(nf-2) }'   or if you want to use a regex, use the ~ regex matching operator:  echo "$df" | awk '$nf ~ "^(/var|/)$" { print $(nf-2) }'   or:  echo "$df" | awk '$nf ~ "^/(var)?$" { print $(nf-2) }'  
thanks to warren for informing me about the mediainfo command in his partial answer.  i managed to construct a command that achieved the restoration of timestamps
locate filename find -name '*filename*' echo **/*filename* ls -ld **/*filename*   (read on for the main terms and conditions
i believe you don't need to cross compile
if munish.txt contains the sample data you provided, then:  $ sed -e 's/^[^ ]* //; s/,.*,\([^,]*\),/\1/' munish.txt /mnp/opq/p/1926081/sp/192608100/serveflavor/entryid/0_ffx7sljc/v/2/flavorid/0_to8w2p18/forceproxy/true/name/new   this sed script deletes everything up to and including the first space in a line, and everything from the first , to the second-last ,
bash's return() can only return numerical arguments
pandoc can take multiple input files
this one worked for me:  find "$@" ! -type d -exec kill -9 $$ \; -quit &amp;&amp; rm -r "$@"    if find exits normally (nothing is found) rm -r "$@" will be executed. if find finds something the current shell/script is killed ($$ stores the pid)
just run your whole install script under setarch  $ setarch $(uname -m) --uname-2.6 /path/to/install/script.sh   everything called in that script onwards will think you're running a 2.6 kernel. 
sounds like a simple job for sed:  docker port &lt;container-name&gt; | sed 's/^.*:\([0-9]*\)$/\1/'   or if you prefer awk:  docker port &lt;container-name&gt; | awk -f':' '{print $nf}'  
part 1  simply delete the 13th line:  sed '13d' &lt;file.txt   and a general way to do the complement of the above is:  sed '13!d' &lt;file.txt   part 2  because it can be done:  sed -n ':a;${p;q};n;4,$d;ba' &lt;file.txt   note the 4 is one more than the number you require
i hope, that i understood you right: you need just a launcher to the existing script
with most mailers you can do something like this in the /etc/aliases file.  joe: joe, someaddress@someotherdomain.com   after making changes to this file you typically have to run the command, newaliases.  references   how to redirect local root mail to an external email address on linux forwarding email and must keep a copy  
the program lsof allows you to check which processes are using which ressources, like files or ports.  to show which processes are listening on port 8080:  lsof -pi :8080 -stcp:listen  in your case, you want to test whether a process is listening on 8080 - the return value of this command tells you just that
with regard to eclipse not being able to find adb, etc, this because without the 32-bit shared libraries needed to run them on the system, they are not executable.  with regard to 32-bit libraries, the situation is fairly simple: you just need to install the appropriate 32-bit libs
the firmware for your graphics card is missing
tomcat being installed from opensuse repo runs as a service under systemd
you can do this using yum, by making a ".repo" repository file for your collection and running yum temporarily enabling this repository while disabling the other repositories
i'm guessing this is how: http://linux.die.net/man/8/kexec     kexec(8) - linux man page      name      kexec - directly boot into a new kernel       synopsis      /sbin/kexec [-v (--version)] [-f (--force)] [-x (--no-ifdown)] [-l   (--load)] [-p (--load-panic)] [-u (--unload)] [-e (--exec)] [-t   (--type)] [--mem-min=addr] [--mem-max=addr]       description      kexec is a system call that enables you to load and boot into another   kernel from the currently running kernel
doing:  sudo chown -r root.root /etc   on the commandline will set /etc and everything underneath to owner root and group root  however on my system (ubuntu 12.04) not everything under /etc is in group root
from the readme file in    cat /opt/scala/doc/readme   i took this:  scala software distributions ----------------------------  - scala-&lt;major&gt;.&lt;minor&gt;.&lt;patch&gt;.tar.bz2     unix distribution - scala-&lt;major&gt;.&lt;minor&gt;.&lt;patch&gt;.tar.gz      unix distribution - scala-&lt;major&gt;.&lt;minor&gt;.&lt;patch&gt;.zip         windows distribution  the standard distributions require java 1.5 or above
it's because all of your logic depends on one of $opt_[ab] being null
it's immutable in the mainline kernel function relatime_need_update() which checks against the hardcoded value of 24*60*60 (1 day), see the source at e.g.:  http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/tree/fs/inode.c#n1590 
freebsd is smart enough to not bother you about port options: if they haven't changed at port level (makefile), it won't ask you twice for them.  i do not use binary packages but i guess, in your case, that options from your previous installed binary package were kept so the make config step was skipped.  anyway, to force freebsd to display the dialog screen to choose your build options, run make config before make install.  in the same way: to restore default options, it exists make rmconfig. 
the string you get 4;rgb:8b8b/cdcd/0000 is not really the output of the echo command but a side effect of the echoed string being sent to your terminal emulator and the latter reacting to it by outputting these characters, just like if you typed them.  the shell is unaware of it and that's the reason why attempting to capture the output results in empty strings.  here is a way to achieve what you want:  script -qc "echo -e '\e]4;40;?\a';read foo" /tmp/foo out=$(tail -1 /tmp/foo)   here are some explanations about it:.the script command is capturing everything that is displayed on your screen, the read foo one is there to prevent the script command to finish before the terminal emulator has output the string you want to get
depending on your flavor of unix, the /proc filesystem may have an uptime file somewhere with the information you want.  linux&gt; cat /proc/uptime 5899847.37 23165596.55   and the output of the uptime command for the same time:  linux&gt; uptime 16:46:27 up 68 days, 6:51,  3 users,  load average: 0.01, 0.02, 0.05   so 5899847.37/86400 = 68.28527 --> 68 days, 6 hours, 51 minutes. 
an ampersand at the end of a command will cause the command to be run in the background right from the start:  yes &amp;   yes should respond to ctrl+c and definitely ctrl+z, though
the documented ripe whois options work with whois.md and the right ripe whois server address:  $ whois.md -h whois.ripe.net -i mnt-by some_string [..] route:          some_route descr:          some_desc origin:         some_as mnt-by:         some_string source:         ripe # filtered [.
the following instructions are valid for cuda 7.0, 7.5, and several previous (and probably later) versions
once you've written it to cd/dvd/usb, you don't need to use windows again
this worked:      debmirror -p -v --method=http --dist=lisa --root=
based on the kadmin/admin part of your output, i'm going to assume you're trying to run kadmin.  it's impossible to run kadmin without entering a password
here's one way to do it:  #!/bin/bash dir=$1  minfile=$( du "$dir" -hab | sort -n -r | tail -1 | awk '{ print $1 }' ) out=$( du "$dir" -hab | sort -n -r | tail -n 2 | awk '{ print $2 }' )  printf "minimum file size: %s\n" "$minfile"   printf "$out\n"   example output of the above code:  minimum file size: 94 /home/krt/my-scripts/multissh.sh /home/krt/my-scripts/vpn.sh  
this command  env name=value name2=value2 program and args   runs the command program and args with an environment formed by extending the current environment with the environment variables and values designated by name=value and name2=value2
no you don't have to put the command from the page you linked to in your ~/.vimrc, you can just type them after issuing : in vim to get the command prompt.  however if you put the lines:  set foldmethod=indent    set foldnestmax=10 set nofoldenable set foldlevel=2   as indicated in the link you gave, in your ~/.vimrc, you don't have to type them every time you want to use folding in a file
generally, a keyring is a secure password store, that is encrypted with a master password.  once you input the master password, the keyring gets decrypted and all the passwords inside it are available to the application accessing the keyring.  on gnome/ubuntu the seahorse application can be used to look at the keyring and the master password is the same with your user's password so you don't get asked about it anymore.  most likely your system's keyring password doesn't match your user's password, or the integration is somehow broken.  you can try to cancel it and see if you still have access to your saved website passwords
touch /var/spool/cron/crontabs/$username; chmod 0 /var/spool/cron/crontabs/$username should do the trick
short answer:  because it's programmed to ignore multiple uses of a flag.  long answer:  as you can see in the source code of ls, there is a part with the function getopt_long() and a huge switch case:  1648       int c = getopt_long (argc, argv, 1649                            "abcdfghiklmnopqrstuvw:xabcdfghi:lnqrst:uxz1", 1650                            long_options, &amp;oi);       .... 1654       switch (c) 1655         {       .... 1707         case 'l': 1708           format = long_format; 1709           break;       .... 1964     }   the function getopt_long() reads all paramters given to the program
following method works with centos 6.2:  requirements: usb flash drive (at least 4 gb, i used a 16 gb one)  download an iso image from a mirror - i chose the full 1st dvd image to avoid a network install (because it is not clear if the cryptographic package signatures are checked by the installer or not), e.g.:  $ wget http://ftp.uni-bayreuth.de/linux/centos/6.2/isos/i386/centos-6.2-i386-bin-dvd1.iso $ md5sum centos-6.2-i386-bin-dvd1.iso   check the md5sum against a md5sum.txt file from another mirror (and check md5sum.txt against md5sum.txt.asc via gpg).  partition your flash drive (say it is /dev/sdb), i.e
just surround numbers with parentheses:  $ echo 1 3 5 7 | awk '{print $(1+3)}' 7   if you want to calculate field number with some function you don't need parentheses at all:  $ echo 1 3 5 7 | awk '{print $sqrt(16)}' 7   (of course they don't hurt, so $(sqrt(16)) works as well) 
in general (ignoring vagrant or other system-specific details) your best bet is to set up authentication with ssh keys, and run ssh-agent
found solution using this workaround  converting qemu arguments to domain xml  after converting to xml import with  virsh create file.xml  
you can reproduce what the shell does under the hood by doing the plumbing manually
use -i {}, and {} at the place where you want the argument to appear:  xargs -i {} -n 1 echo rm /usr/src/packages/{}   (you can use something other than {}, {} is just very common.)  without this, xargs simpy adds the input as additional arguments, so it's not a question of it adding spaces anywhere - the command receives the input as separate arguments.  you probably should use find instead of ls, especially if you want to distinguish files and directories.  something like this to delete only files:  find 
from ubuntu (in vm) install gparted by executing sudo apt-get install gparted in terminal.  open gparted either from terminal or from dash
the respective freebsd bug is here
terminfo is probably not going to help you much
unfortunately these are your options:   user's home directory /etc some other designated location on the system   there is no magical place you can save your data where it will be impervious to a potential attack
i wrote a python script to perform the task
the purpose is to prevent ordinary users from running the su command (su is similar to sudo, the difference being that sudo executes one command, su starts a new session as a new user, which lasts until that user runs exit)  the default mode of su is 4755 or rwsr-xr-x, the "s" means that the command is set-uid (which means that it always runs as the user who owns it, rather than the user who happens to execute it
this:  $ &lt;grep-command&gt; | sed -r 's|^.*/([0-9]{4}-[0-9]{2}-[0-9]{2})[^:]*:(.*)|\1:\2|'   ..
yes, you can use vi commands in a stript: sed — stream editor, is a member of the vi family (ed, vi, sed)
the bash wiki explains this quite well
it is the kernel itself who is flooding your console.  you need to lower loglevel for consoles: sudo dmesg -n 1.  the system may have a setting for this (including bootloader one)
contrast:  $ watch -n 1 "echo $(date)" every 1.0s: echo sat apr 27 03:10:50 cest 2013  $ watch -n 1 'echo $(date)' every 1.0s: echo $(date)   what you've done is to run echo "($ls dirflat |wc -l)*100/$filenum"|bc and date, substitute the output of each command into the shell command watch -n 100 "echo $(…) % $(…)", and run that
   question: is there a standard way to display the default parameters for a systemd service?   there is no standard way to display the default parameters for a systemd service.  many services expose some parameters on the bus.  for example:  busctl call org.freedesktop.systemd1 /org/freedesktop/systemd1 org.freedesktop.dbus.properties getall "s" ""   shows properties of the manager itself.  output contains runtimewatchdogsec, shutdownwatchdogsec(as runtimewatchdogusec and shutdownwatchdogusec), loglevel, defaultstandardoutput, defaultstandarderror etc.     i take a simple example: systemd-timesyncd.service   see: https://github.com/systemd/systemd/issues/1589 
first of all, let's decouple the read from the text line by using a variable:  text="line-1 line-2"             ### just an example. read -p "$text" reply   in this way the problem becomes: how to assign two lines to a variable.  of course, a first attempt to do that, is:  a="line-1 \ line-2"   written as that, the var a actually gets the value line-1 line-2.  but you do not like the lack of indentation that this creates, well, then we may try to read the lines into the var from a here-doc (be aware that the indented lines inside the here-doc need a tab, not spaces, to work correctly):      a="$(cat &lt;&lt;-_set_a_variable_         line-1         line-2         _set_a_variable_     )" echo "test1 &lt;$a&gt;"   but that would fail as actually two lines are written to $a. a workaround to get only one line might be:      a="$( echo $(cat &lt;&lt;-_set_a_variable_         line 1         line 2         _set_a_variable_         ) )" echo "test2 &lt;$a&gt;"   that is close, but creates other additional issues.  correct solution.  all the attempts above will just make this problem more complex that it needs to be
you can modify your umask to allow (for most implementations) more read/write privileges, but not executable, since generally the requested permissions are 0666.  if your umask is 022, you'll see touch make a 0644 file.  interestingly, posix describes this behavior in terms of creat:        if file does not exist:      the creat() function is called with the following arguments:         the file operand is used as the path argument.   the value of the bitwise-inclusive or of s_irusr, s_iwusr, s_irgrp, s_iwgrp, s_iroth, and s_iwoth is used as the mode argument.         and it is only by following the links to creat, then to open, noticing the mention of umask and back-tracking to open (and creat) to verify that umask is supposed to affect touch.  for umask to affect only the touch command, use a subshell:  (umask 066; touch private-file) (umask 0; touch world-writable-file) touch file-as-per-current-umask   (note that in any case, if the file existed beforehand, touch will not change its permissions, just update its timestamps). 
:0 is an x display name
you can clone a mounted filesystem, but it's a bad idea because you'll be copying the filesystem in an inconsistent state
in the crontab, before you command, add 
find removable media in the system settings menu, check never prompt or start programs on media insertion or install dconf editor using sudo apt-get install dconf-tools.then launch dconf editor,navigate to org/gnome/desktop/media-handling and uncheck automount, you can even try https://extensions.gnome.org/extension/7/removable-drive-menu/ a neat little extension that adds a removable drives icon to the top panel when you insert one, from there you can then choose to open a nautilus window or eject. 
this is using gnu awk, using posix awk would be very troublesome (lack of gensub, which i use more than once).  #!/usr/bin/env gawk  function join(array, result, i) {     result = array[0];     end = length(array) - 1;     for (i = 1; i &lt;= end; i++)         result = result "," array[i];     return result; } function push(arr, elem) {     arr[length(arr)] = elem; }  # split("", arr) is a horribly unreadable way to clear an array begin { split("", arr); }  /{part}|{chapter}/ {     l = gensub(".*{(.+)}{(.+)}{([0-9]+)}$", "\\1,\\3,\\2", "g");     if ("part" == substr(l, 0, 4)) {         if (length(arr) &gt; 0) { print join(arr); }         split("", arr);         push(arr, gensub("^(.*),(.*),(.*)$", "\\2,\\3","g", l));     } else {         push(arr, gensub("^(.*),(.*),(.*)$", "\\3","g", l));     } }  end { print join(arr); }   this uses the fact that regexes are greedy, so the matches will get the full line each time
with zsh  chpwd() pwd   then, the current directory is printed whenever it changes (upon cd, pushd, popd...).  with ksh, bash or zsh:  cd() {   builtin cd "$@" &amp;&amp; pwd }   (you'd typically put those in your shell configuration file) 
generally speaking, i don't think you can unfortunately
you probably (could) use acpid (check via ps aux | grep acpid)
ok, we have a couple bad assumptions to overcome here
you can make a view of the fat filesystem with posix semantics, including supporting file names with any character other than / or a null byte
ssh user@1.2.3.4 "ls /home/somefile" || { echo "file does not exist"; exit 1; }   this is called a compound command
you configure your web server, ftp server, etc.—whatever you're using to share the repository with other machines—to require authentication.  the repository is just a bunch of files that your web server (typically) serves; there isn't really anything special about it
you can do this with a little perl:  #!/usr/bin/perl use strict; use warnings qw(all);  use html::entities qw(encode_entities); use config::inifiles; use file::spec;  foreach my $f (@argv) {     my $ini = config::inifiles-&gt;new( -file =&gt; $f );     my (undef, undef, $name) = file::spec-&gt;splitpath($f);     $name =~ s/\.url$//;            # / # this comment un-confuses the syntax highlighter     my $name_esc = encode_entities($name);     my $url_esc = encode_entities($ini-&gt;val('internetshortcut', 'url'));     print &lt;&lt;html &lt;a href="$url_esc"&gt;$name_esc&lt;/a&gt; html }   that should handle everything well
users counts login sessions
you can temporarily redirect output to a file like so:  exec 1&gt; log.txt echo -n "hello" # hello will be written to log.txt # some more commands here # whose stdout will be # written to log.txt exec 1&gt; /dev/tty # redirect stdout back to your terminal   a more general way (in case your stdout wasn't the terminal and you want to restore it to what it originally was):  exec 3&gt;&amp;1 # point a new filehandle to the current stdout exec 1&gt; log.txt  echo -n "hello" # hello will be written to log.txt # some more commands here # whose stdout will be # written to log.txt exec 1&gt; &amp;3 # restore stdout to what it originally was exec 3&gt; &amp;- # close the temporary filehandle   thanks to celada's comment for pointing this out. 
in htop, press f2 or sto enter setup, then use the arrows to navigate the columns-&gt;available columns menu, select processor and enterto add a processor column
i believe this thread describes your problem  in a nutshell, the proc entry containing that value is read-only, and cannot be made writable easily:  $ ls -ln /proc/sys/net/ipv4/conf/all/mc_forwarding  -r--r--r-- 1 0 0 0 jun 17 08:20 /proc/sys/net/ipv4/conf/all/mc_forwarding $ sudo chmod u+x /proc/sys/net/ipv4/conf/all/mc_forwarding chmod: changing permissions of `/proc/sys/net/ipv4/conf/all/mc_forwarding': operation not permitted   but you can run your own router daemon to (e.g xorp) to get multicast forwarding. 
this perl script will do what you want in one go:  #!/usr/bin/env perl use strict; use getopt::std;  ## this hash will hold the options my %opts;  ## read the options getopts('t:s:e:',\%opts) || do { print "invalid option\n"; exit(1); };  ## keep the temp file if the script is run  ## with -t my $keep_temp_file=$opts{t}||undef;  ## the temp file's file handle my $tmp; ## the temp file my $temp_file=`mktemp`; chomp($temp_file); ## read the time range my $start=$opts{s}||undef; my $end=$opts{e}||undef;   ## open the input file open($tmp,'&lt;',"$argv[0]")||      die("need an input file as the 1st argument: $!\n");  my ($time,$want); my (%data,%letters); ## read the input file line:while (&lt;$tmp&gt;) {     ## skip blank lines     next if /^\s*$/;      ## remove trailing newlines     chomp;     ## is this line one of the start times?     if (/^#(\d+)/) {         if ($1&gt;=$start &amp;&amp; $1&lt;=$end) {             $time=$1;             $want=1;         } elsif ($1&gt;=$end) {             $want=0;             last line;         }     }     ## if we want this line, save it in     ## the %data hash.     if ($want==1) {         ## skip if this line is the one that has the time         ## definition.         next if /^#/;         ## get the two characters of the line         /^(.)(.+)/;         $data{$time}{$2}=$1;         ## save each letter seen         $letters{$2}++;     }   } ## once the file has been processed, create ## the temp file. open($tmp,'&gt;',$temp_file)||      die("could not open temp file $temp_file for writing: $!\n");  my @times=sort {$a &lt;=&gt; $b } keys(%data); print $tmp " "; printf $tmp "%6s", "$_" for @times; print $tmp "\n"; foreach my $letter (sort keys(%letters)) {     print $tmp "$letter " ;     foreach my $time (@times) {         defined $data{$time}{$letter} ?              printf $tmp "%6s","$data{$time}{$letter} " : printf $tmp "%6s","- ";     }     print $tmp "\n"; } close($tmp); ## process the tmp file to get your desired output open(my $fh,'&lt;',"$temp_file")||      die("could not open temp file $temp_file for reading: $!\n"); ## print the header printf "%-7s%6s%10s\n",'name', 'count', 'x'; while (&lt;$fh&gt;) {     ## skip first line     next if $.==1;      ## collect the columns     my @foo=split(/\s+/);     ## get the letter     my $let=shift(@foo);     my $c=0;     ## check if the first one is an x     $c++ if $foo[0] eq 'x';     ## check the rest     for (my $i=1;$i&lt;=$#foo;$i++) {         ## get the previous position
edit /etc/logwatch/conf/logwatch.conf  and add  service = "-proftpd-messages" service = "-pam_unix"  
the documentation is incomplete
with awk:  awk ' nr==fnr{for(i=1;i&lt;=nf;i++){values[$i]};next} fnr==1{for(i=1;i&lt;=nf;i++){if ($i in values){nf[i]}}} {for(i=1;i&lt;=nf;i++){if (i in nf){printf("%s%s",$i,(i!=nf)?ofs:ors)}}} ' file2 file1   this reads file2 first, saves each value into an array values then processes file1 - on 1st line it checks which fields are common and saves those field numbers into another array nf which is then used as reference to selectively print the corresponding columns. 
yes, the spice client just shows what a monitor would show
wikipedia, "factor (unix)" with an interesting take:      factor first appeared on 5th edition research unix in 1974, as a "user maintained" utility (section 6 of the manual)
upstart system jobs have a .conf extension and are placed in /etc/init
you can use something like:  grep -r "axn" .   use -ir if you want it to be case-insensitive. 
you can simply use [ "$character" ] to test if string is nonzero, what is equivalent of longer form [ -n "$character" ]
after much searching, i've found only one method to disable the touch feedback sound
i don't know anything about java, but i can show you a proof of concept
in the standard vicmd mode r is already bound to vi-replace-chars.  so when you define r+r to redo with   bindkey -a rr redo   you have two possible actions zsh could follow when r is pressed   interpret it as the command vi-replace-chars or wait for a second character and then interpret the command redo   the algorithm for matching keyboard commands in zsh favors short commands so it will always use the 1
use webcamstudio for gnu/linux
with bash parameter expansion:  ${var%%[aaeeiioouu]*}    the pattern [aaeeiioouu]* greedily (%%) removes the matched portion from variable var from right, here starting from any uppercase or lowercase vowel ([aaeeiioouu]) followed by anything (*)   example:  $ var=sports    $ echo "${var%%[aaeeiioouu]*}" sp  $ var=foobar $ echo "${var%%[aaeeiioouu]*}" f  
you would have to use a email alias in this case.  the reason is that domains, logs, and virtualmin-backup are the names of sub-directories that virtualmin creates under each domain's home, so allowing a username with the same name would cause them to clash.  a work-around for this is to create an email alias for domains@example.com (on mail aliases page) that forwards to the actual mailbox with a different name.  however there is currently a bug in virtualmin that still won't allow you to use these names as mail aliases - this is a bug as it should be possible to have an alias named domains (or the other reserved names).  failed to save alias : missing or invalid alias name (no @ should be included)   this should be fixed in an upcoming release.  source - https://www.virtualmin.com/node/40377 
man shutdown(8) says:     the first argument may be a time string (which is usually "now")
first a couple of terms which will help you to understand this issue in particular and other things in general wrt a linux gui:   window manager (wm) desktop environment (de)   someone should really write a simple, canonical explanation of these in a linux context...anyway, the base windowing system generally used on *nix systems (including linux) is the xorg (anachronistically, x11) server, which deals with the hardware interface provided by the kernel and in turn provides a graphical windowing system to "userspace" applications.  so xorg provides the fundamental possibility of a graphical desktop on which shaped windows can appear as interfaces to specific programs
try the following to start less with blossom already searched for:  declare -f | less -p blossom   from the documentation of less:  -ppattern or --pattern=pattern     the -p option on the command line is  equivalent  to  specifying     +/pattern;  that  is, it tells less to start at the first occur‐     rence of pattern in the file.   if your question was less general than that, and you want just the source for function blossom, use the following:  declare -f blossom  
there are a number of possibilities (some mentioned in other answers):   a system or user cronjob executing often, in sysv init, an /etc/inittab entry for the service with the respawn directive, in systemd, a unit file with the restart option set to a value other than no, in upstart, a service configuration file with the respawn directive, a process monitoring tool such as monit, or an ad-hoc watchdog process for that particular service.   an interesting new (linux-only) tool that could provide more insight into where the process is being started is sysdig.  sysdig uses the linux kernel's tracepoint features to provide what amounts to a fast, system wide strace
with dos style line endings:  $ cat -e ip.txt      mt      200610-1        100     2757^m$     mt      200610-10       100     6753 ^m$     mt      200610-100      100     15173^m$  $ awk 'begin{fs=="\t";ofs=="\t"}{print "chr"$1,$4-1,$4}' ip.txt  chrmt 2756 2757 chrmt 6752 6753 chrmt 15172 15173  $ awk 'begin{fs=="\t";ofs=="\t"}{print "chr"$1,$4-1,$4,$2}' ip.txt   200610-16 2757 chrmt 6752 6753 200610-10  200610-100 15173   with perl to handle both dos style line ending and getting required output:  $ perl -ale 'print "chr$f[0]\t", $f[3]-1, "\t$f[3]\t$f[1]"' ip.txt  chrmt   2756    2757    200610-1 chrmt   6752    6753    200610-10 chrmt   15172   15173   200610-100   with awk, change line ending to unix style first, with dos2unix if available or with perl  $ perl -i -pe 's|\r\n|\n|' ip.txt  $ cat -e ip.txt      mt      200610-1        100     2757$     mt      200610-10       100     6753 $     mt      200610-100      100     15173$   and then  $ awk -v ofs="\t" '{print "chr"$1,$4-1,$4,$2}' ip.txt  chrmt   2756    2757    200610-1 chrmt   6752    6753    200610-10 chrmt   15172   15173   200610-100  
\&gt; is the (zero length) regexp for the end of the word so c\&gt; will probably not match last names that start with a 'c'
not with a single command that i'm aware of.  solaris ps gets process data for such things as command-line arguments from the /proc/[pid]/psinfo file, which contains data that fills a struct psinfo per /usr/include/sys/procfs.h:  #define prargsz     80  /* number of chars of arguments */ typedef struct psinfo {     int pr_flag;    /* process flags (deprecated; do not use) */     int pr_nlwp;    /* number of active lwps in the process */     .     .     .     char    pr_fname[prfnsz];   /* name of execed file */     char    pr_psargs[prargsz]; /* initial characters of arg list */ ...   so you can't get the entire set of command line arguments from /usr/bin/ps
the permissions 004 (------r--) means that the file can only be read by processes that are not running as the same user or as the same group as the ftp server
on mint, you'll find the kernel configuration in /boot/config-$(uname -r):  grep config_coredump /boot/config-$(uname -r)   most distributions ship the kernel configuration in /boot nowadays. 
the weird string "@(#)" is actually used by the ancient sccs version control system
here's one way to do it with sed:  sed '/pattern1/,$!d;/pattern2/{x;//{x;q;};g;}' infile   this just deletes all lines (if any) up to the first occurrence of pattern1 and then, on each line that matches pattern2 it exchanges buffers
with gnu sed:  sed -i -e '/&lt;directory "\/var\/www\/html"&gt;/,/&lt;\/directory&gt;/{s/allowoverride none/allowoverride all/}' filename  
try this:  yum --exclude=kernel\* update   or:  yum -x 'kernel*' update   from yum man page:  -x, --exclude=package         exclude a specific package by name or glob from updates on all         repositories
looks like you forgot an x in the last part of the regex:  [\80-\xbf]  --&gt;  [\x80-\xbf]  
the expressions in the apostrophes are not evaluated (nor subshell nor variables)
my first instinct is to do  ps -ef | grep uid &amp;&amp; ps -ef | grep systemd, but that will also print the grep commands like so  $ ps -ef | grep uid &amp;&amp; ps -ef | grep systemd uid         pid   ppid  c stime tty          time cmd root          1      0  0 17:00 ?        00:00:02 /usr/lib/systemd/systemd user          pid ppid  c 23:30 ?        00:00:00 grep systemd user          pid ppid  c 23:30 ?        00:00:00 grep uid   i don't see how you can print only the header, because any time you execute this, the regex will match the grep itself
there are several tls related settings you can use in the access map:   try_tls  is used when sendmail is a client (i.e
a background-job (ie
so i'm not sure if you're looking to do this programmatically or not
if you want it to run just go:  service mule start   or stop, go:  service mule stop   then it will tell it is already in that state, or it will do it.  i also know a few services, where i need to do this.  otherwise you can check with ps:  ps aux | grep mule   should work... 
man wall will give you what you need.  you execute wall with either a filename, or you pipe content to it.  for example, either,  wall file.name to broadcast the content of the file file.name or  echo "dive\!" | wall to send the message dive!  update: as stephen points out in this answer, later versions of wall can send messages by simply typing,  wall message text here  and in fact, there are additional restrictions on non-root users sending the contents of files by specifying only the file name. 
mkimage -l uimage   will dump the information in the header.  tail -c+65 &lt; uimage &gt; out   will get the content.  tail -c+65  &lt; uimage | gunzip &gt; out   will get it uncompressed if it was gzip-compressed.  if that was an initramfs, you can do cpio -t &lt; out or pax &lt; out to list the content.  if it's a ramdisk image, you can try and mount it with:  mount -ro loop out /mnt   file out could tell you more about what it is. 
on the server side, you can restrict this by setting their user shell to /bin/true
according to chapter 9 of using samba - troubleshooting samba:     to turn logging on and off, set the appropriate level in the [global] section of smb.conf
assuming the dates look like "hh:mm" as you've show, and assuming the date appears in the 2nd field, you can use awk:  awk -v start=00:00 -v stop=09:00 'start &lt;= $2 &amp;&amp; $2 &lt; stop' file.log     [rant] i'm quite particular about date formatting, and this one is terrible: what date is "09/10/11"? [/rant]  anyway, assuming this it "yy/mm/dd"  awk -v date="$(date +%y/%m/%d)" \     -v start=00:00:00 \     -v stop=09:00:00 \     -v search="file format not found" \ '$1 == date &amp;&amp; start &lt;= $2 &amp;&amp; $2 &lt; stop &amp;&amp; $0 ~ search' file.log  
problem solved
xargs transforms input to arguments
one way is to say lsof -i:57010 -stcp:established
i would trace your perl script with a system call trace tool: strace (linux), dtruss (os x), ktrace (freebsd), truss (solaris), etc
i suggest reading the ssh_config man page
assuming that you want to be protected against other normal users of the system (if the adversary has root access, all bets are off), your could in principle use a secure attention key:     an operating system's secure attention key is a security tool which is   provided as protection against trojan password capturing programs
as i understand it from ibm's web site, it's just a buzzword for linux running on servers that use the ibm power architecture.     powerlinux servers, software and solutions are built on our power systems platform and associated services, and should be the open standard platform of choice for deploying new linux technology–based applications, offering superior capabilities for big data analytics, industry application solutions, open source infrastructure services, and other emerging workloads.  
after testing the first answer and still getting sudo: sorry, you are not allowed to preserve the environment, i decided to look around for a better solution.  after a bit of testing, i found that the option that matters is setenv.  defaults!/bin/build.sh setenv   to make it a little more secure, we can add a couple settings:  defaults    secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/x11/bin" defaults!/bin/build.sh setenv,env_reset,env_delete+=path,env_delete+=ld_preload,env_delete+=ld_library_path,env_delete+=ssh_auth_sock,env_delete+=pythonpath,env_delete+=perl5lib %deploy  all=(all) nopasswd: /bin/build.sh *  
standard input and standard output are not commands.  imagine commands as machines in a factory with an assembly line
that's indeed poorly documented
normally xargs will put several arguments on one command line
have you tried installing without using any on-line repositories, just the cds? maybe its failing to download a package for some reason
for example ls /boot/config-* will print you all the installed kernel versions
sha-1, sha-256, sha-512 and all the other sha functions are cryptographic hash functions
careful where you draw your analogies
creating account  when granting someone access to a linux system you usually use the command useradd.  $ useradd someuser   granting filesystem permissions  if the user will be working with any files on the system, then add them to the corresponding groups based on which files they'll be working with
well depends on the script but easily you can find your crontab as root with  crontab -l -u &lt;user&gt;   or you can find crontab from spool where is located file for all users  cat /var/spool/cron/crontabs/&lt;user&gt;   to show all users' crontabs with the username printed at the beginning of each line:  cd /var/spool/cron/crontabs/ &amp;&amp; grep 
the use of grep is redundant, sed can do the same
use ssh-keygen -r hostname to remove the hostname from your known_hosts file
a quick trip to google reveals this interesting approach: http://pebblesinthesand.wordpress.com/2008/05/22/a-srcipt-for-running-processes-in-parallel-in-bash/ 
i think that removing individual files is a wrong approach
actually, dir2 does exist, but the name dir2 does not
you can use t parameter expansion flag:  $ print -rl -- ${(t)fpath} array-special $ a=1 $ print -rl -- ${(t)a} scalar $ a=(1 2) $ print -rl -- ${(t)a} array $ typeset -a a $ print -rl -- ${(t)a} association   note that you can't distinguish between array of integers or array of strings. 
a little bit crutched: remove all options using -option with an empty argument first, then set same options with terminate excluded from the list:  setxkbmap -option -option $(setxkbmap -query |     sed -n 's/options:\s*\(terminate:[^:]*,\)\?\|,terminate:[^,]*//gp)  
i'd install pdsh and configure it to allow me to run commands in parallel on all servers (or selected individual hosts or groups of servers - as defined in pdsh's /etc/genders file).  e.g
try this:  $ echo -e '&lt;tr&gt;&lt;td&gt;xxx&lt;/td&gt;&lt;td&gt;xxx&lt;/td&gt;&lt;td&gt;xxx&lt;/td&gt;&lt;td&gt;xxx&lt;/td&gt;&lt;td&gt;xxx&lt;/td&gt;&lt;td&gt;xxx&lt;/td&gt;&lt;td&gt;xxx&lt;/td&gt;&lt;td&gt;xxx&lt;/td&gt;&lt;td&gt;someone.something@example.com&lt;/td&gt;&lt;/tr&gt;\n&lt;tr&gt;&lt;td&gt;yyy&lt;/td&gt;&lt;td&gt;yyy&lt;/td&gt;&lt;td&gt;yyy&lt;/td&gt;&lt;td&gt;yyy&lt;/td&gt;&lt;td&gt;yyy&lt;/td&gt;&lt;td&gt;yyy&lt;/td&gt;&lt;td&gt;yyy&lt;/td&gt;&lt;td&gt;yyy&lt;/td&gt;&lt;td&gt;foo.bar@example2.com&lt;/td&gt;&lt;/tr&gt;' | \ awk -f'&lt;/td&gt;&lt;td&gt;' 'gsub(/.*@/,"",$9)' ofs='&lt;/td&gt;&lt;td&gt;' &lt;tr&gt;&lt;td&gt;xxx&lt;/td&gt;&lt;td&gt;xxx&lt;/td&gt;&lt;td&gt;xxx&lt;/td&gt;&lt;td&gt;xxx&lt;/td&gt;&lt;td&gt;xxx&lt;/td&gt;&lt;td&gt;xxx&lt;/td&gt;&lt;td&gt;xxx&lt;/td&gt;&lt;td&gt;xxx&lt;/td&gt;&lt;td&gt;example.com&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;yyy&lt;/td&gt;&lt;td&gt;yyy&lt;/td&gt;&lt;td&gt;yyy&lt;/td&gt;&lt;td&gt;yyy&lt;/td&gt;&lt;td&gt;yyy&lt;/td&gt;&lt;td&gt;yyy&lt;/td&gt;&lt;td&gt;yyy&lt;/td&gt;&lt;td&gt;yyy&lt;/td&gt;&lt;td&gt;example2.com&lt;/td&gt;&lt;/tr&gt;   &lt;/td&gt;&lt;td&gt; delimiter split the line into 9 fields
you can install and use pacman but you can't use aur repo in centos 7     arch users having to temporarily deal with another linux distribution can use pacapt, a simple wrapper around other package managers.   to install pacapt run the following commands:  sudo wget -o /usr/local/bin/pacapt \ https://github.com/icy/pacapt/raw/ng/pacapt sudo chmod 755 /usr/local/bin/pacapt sudo ln -sv /usr/local/bin/pacapt /usr/local/bin/pacman || true  
jboss is an application server, a framework for running java-based applications/servlets
you're looking for the package apt-listchanges
you should be able to do this by setting the ps1 prompt variable in your ~/.bashrc file like this:  ps1='[\u@\h \w]\$ '   to make it colored (and possibly bold - this depends on whether your terminal emulator has enabled it) you need to add escape color codes:  ps1='\[\e[1;91m\][\u@\h \w]\$\[\e[0m\] '   here, everything not being escaped between the 1;91m and 0m parts will be colored in the 1;91 color (bold red)
it's because not all config files are read during boot in single-user mode.  in this particular case the problem is in the term environment variable not being set properly
you can use awk to do this:  awk 'nr &gt;= n { printf("%6d  ", nr-n+1) } 1' n=3   for lines where the current record number (nr) is greater than or equal to n (passed in as a variable), print a line prefix, starting at 1
in addition to uname -a, which gives you the kernel version, you can try:  lsb_release -idrc  # distro, version, codename, long release name   most desktop environments like gnome or kde have an "about" or "info" menu option that will tell you what you use currently, so no commandline needed there really. 
if you can change the source code, dmalloc is great; it will list which pointers were unfreed and (for code built with debugging symbols) exactly which line they were allocated on.  if you can't, valgrind is pretty much the standard for that sort of thing
resolved : thanks to this answer, i was able to pipe in my input to the source command thereby removing my intervention
after disabling smart scrubbing (automatic offline testing), with smartctl --offlineauto=off /dev/sdx the drive is now entering "standby".  note: offlineauto=off value is saved in the drive, surviving reboots and power outages.  thanks to http://serverfault.com/questions/458512/why-does-unpartitioned-hitachi-hds5c3020-drive-start-consuming-50-more-power-15/#answer-458528 
as explained by the creator in this issue on github, a check like the following one will do the trick :  if [[ create_ap --list-running | grep wlan0 | wc -l -ge 1 ]] then     echo "it works !!" fi   how it works :  create_ap --list-running : shows all the interfaces on which create_ap is running grep wlan0 : get the lines where we can find the interface wc -l : count the lines  
the most efficient and safe way is probably find | tar | tar:  ssh login@some.cluster.nl 'cd /path/to/folder; find 
so i fixed it by using nohup command:  sudo -iu user ssh user@172.21.6.70 "nohup bash -c 'source ~/.envrc ; (cd /catalog; ./bin/catalog start &amp;)'"  
to cause an exiting connection to timeout you can use iptables
you have several problems here.   as stated in comments, don't use vfat as your primary working directory
i think you can track all this by checking to where your java binaries linked to.         #which javac           /usr/bin/javac           #ls -ln /usr/bin/java            lrwxrwxrwx
the tool pvs shows the output in whatever units you like.  $ pvs   pv         vg   fmt  attr psize  pfree   /dev/sda2  mmb  lvm2 a--  29.69g 6.91g   i noticed this mention in the man page:  --units hhbbsskkmmggttppee        all  sizes  are  output in these units: (h)uman-readable, (b)ytes,         (s)ectors, (k)ilobytes, (m)egabytes, (g)igabytes,(t)erabytes,         (p)etabytes, (e)xabytes
from the bash manpage     -c string if the -c option is present,  then  commands  are  read  from              string
a 32-bit address space means that you have space for 4gb of addresses
enclose your script in something like :  while true do   ..
i think if you use the swtich -f you'll instruct grep to look for fixed strings.  $ grep -f "\$form['#node']" file.txt   example  sample file.  $ cat file.txt $form['#node'] abc$form['#node']abc 123$form['#node']123 blah blah $form['#node'] someotherstring   sample run.  $ grep -f "\$form['#node']" file.txt  $form['#node'] abc$form['#node']abc 123$form['#node']123 blah blah $form['#node']   note: you still need to escape the dollar sign $ because the double quotes wrapping the string are weak and don't guard against the shell, bash, from thinking that's a variable name. 
the equivalent is in /srv/http
if you are more familiar with the chkconfig utility, you may have a recap on which services are loaded/running at startup using:  chkconfig --list   of course you might have tu install the utility first but ubuntu will tell you how to do it, just run it and see for yourself.  to enable/disable a service on the next boot just use the following syntax:  chkconfig --help usage:   chkconfig [--list] [--type &lt;type&gt;] [name]          chkconfig --add &lt;name&gt;          chkconfig --del &lt;name&gt;          chkconfig --override &lt;name&gt;          chkconfig [--level &lt;levels&gt;] [--type &lt;type&gt;] &lt;name&gt;&lt;on|off|reset|resetpriorities&gt;   in your case you should use:  sudo chkconfig &lt;sericename&gt; off  
in the arch package, it seems dart gets installed into /opt/dart-sdk
ok, so if it satisfies you to have the old pendrive work as the second one, here's how you can do it:   back-up the contents of the old pendrive. once you have both pendrives attached and your system running, re-partition the old pendrive in similar manner to how the second one is partition - that is to say, make the /boot partition on the old one have the same number and type as on the new one (refer to the outputs of fdisk -l)
there are two issues here:   opensuse comes with openssh pre-installed, so the ssh server does not need to be installed  https://nl.opensuse.org/openssh  the packages for openssh apparently have different names in opensuse than they do in ubuntu and fedora (and maybe others?).  in ubuntu (using apt-get) and fedora (using yum), "openssh-server" is a valid package name in opensuse, the package "openssh" covers both the ssh client and the ssh server    so if you type  sudo zypper install openssh   everything should work fine
the ls command is used for listing files. the shell gives you many options to list files matching a pattern, for example:   list all files starting with "a": ls a* list all files ending with ".txt": ls *.txt list all files starting with "x" and ending with ".sh": ls x*.sh   there are many more interesting patterns. to learn more, read man bash. you can search in man bash by pressing the "/" key, and enter the text "pattern matching" and press enter to jump to the relevant section.  another alternative is to filter the output of ls with grep. the rough equivalent of the above operations using ls and grep would be:   list all files starting with "a": ls | grep ^a list all files ending with ".txt": ls | grep '\.txt$' list all files starting with "x" and ending with ".sh": ls | grep '^x.*\.sh$'   all this is of course only scratching the surface. i hope this will get you started. 
a typical video file is a container for video data
locating java  try using this command:  $ type java   to find out where oracle java is installed
the solution is to mark new connections and use the mark for policy routing:  iptables -t mangle -a forward -i ve006 -m connmark -j connmark --set-mark  6 iptables -t mangle -a forward -i ve010 -m connmark -j connmark --set-mark 10   ip rule has a test for fwmark
sox doesn't need to play the file in order to gather statistics on it
what you are looking for is sudo -v
wing ide has a configuration dialog box where you can set the path to your preferred python interpreter, over-riding the default.  to do so, select the custom radio-button for python executable in the project properties dialog box and then either entering a path or clicking on the browse button.  the project properties dialog is apparently accessible from the project menu and the toolbar.  more info at https://wingware.com/doc/intro/tutorial-python-path 
if you see a message telling you that a menu entry has been created, it means the package has dropped a file into /usr/share/menu describing one or more menu entry, as per the debian menu policy
by the time the data reaches your pc via the usb/rs232 interface, the resolution and accuracy wont be any good
the command is:  nautilus recent:///   so if you create a launcher called recent-files.desktop:  #!/usr/bin/env xdg-open [desktop entry] type=application name=recent files comment=show recent files in nautilus exec=nautilus recent:/// icon=file-manager terminal=false   in ~/.local/share/applications, you will be able to show recent files with just one click instead of two clicks. alternatively, you could use:  gvfs-open recent:///   to open recent items with your default file manager (dolphin, thunar etc)
while you can use  sudo timedatectl --adjust-system-clock set-local-rtc true   to set the hardware clock to use local time, this will disable ntp synchronization and timedatectl status clearly notify you:     network time on: yes ntp synchronized: no  rtc in local tz: yes      warning: the system is configured to read the rtc time in the local   time zone.            this mode can not be fully supported
yes, you can have the daemon start on boot and it'll work just fine
this is not a out-of-the-box solution but it will possibly work if no one other comes up with a solution :-)  you can manipulate the power management settings with the command pmset
uncheck options/panel options: mouse page scrolling 
from wikipedia:     for a while, both lvm and evms were competing for inclusion in the mainline kernel
when the install is done, and before rebooting, edit /mnt/etc/fstab (the installed system's root is mounted under /mnt during install). 
thanks to @austin (http://apple.stackexchange.com/users/5916/austin) and others, i finally solved the problem! i thought damn it, this is a unix box, i should be able to find out what's going on! i found another snow leopard machine at work which never had internet sharing turned on and in a terminal i ran:     touch now &amp;&amp; sudo find -x / -newer now  and i got a short list of files that always show up (spotlight indexes, log files in /private/log and if you are using file vault a bunch of encrypted sparse bundles  ...)  then i enabled internet sharing and this time i ran:     sudo find -x / -newer now  obviously without the "touch now"
unless you install apache2 manually (non os x build-in), which i doubt because you mention '/library/webserver/documents', which is the os x way.  either change the serverroot back to its original value or comment it out so it will use default value
check out this how do i detect the ram memory chip specification from within a linux machine question.  this tool might help:  http://www.cyberciti.biz/faq/check-ram-speed-linux/  $ sudo dmidecode --type 17 | more  sample output:  # dmidecode 2.9 smbios 2.4 present. handle 0x0018, dmi type 17, 27 bytes memory device         array handle: 0x0017         error information handle: not provided         total width: 64 bits         data width: 64 bits         size: 2048 mb         form factor: dimm         set: none         locator: j6h1         bank locator: chan a dimm 0         type: ddr2         type detail: synchronous         speed: 800 mhz (1.2 ns)         manufacturer: 0x2cffffffffffffff         serial number: 0x00000000         asset tag: unknown         part number: 0x5a494f4e203830302d3247422d413131382d handle 0x001a, dmi type 17, 27 bytes memory device         array handle: 0x0017         error information handle: not provided         total width: unknown         data width: unknown         size: no module installed         form factor: dimm         set: none         locator: j6h2         bank locator: chan a dimm 1         type: ddr2         type detail: none         speed: unknown         manufacturer: no dimm         serial number: no dimm         asset tag: no dimm         part number: no dimm   alternatively, both newegg.com and crucial.com among other sites have memory upgrade advisors/scanners that i've used regularly under windows
i think the answer is in your question
i don't know xdebug but i don't think it is relevant
i think you should be looking into /proc/mounts:  $ cat /proc/mounts   that file has exact device, filesystem and other mount options used to mount different filesystems on your os
in more recent gnome versions (e.g., gnome-shell), you need to use this instead:  gsettings set org.gnome.desktop.wm.preferences resize-with-right-button true   gnome defaults to using the super ("windows") key for window actions, so the above alone will enable moving (super-leftdrag) and resizing (super-rightdrag)
effective permissions are formed by anding the actual (real?) permissions with the mask.  since the mask of your file is rw-, all the effective permissions have the x bit turned off. 
you don't need the names to be quoted, you need the variables to be quoted
what you're asking for does not seem to make sense.     here i want to get root because the remote user is now root   no, the remote user is now root
i found out: ports.su get's it's fresh packages from ex.:    ftp://ftp.nluug.nl/pub/openbsd/snapshots/packages/amd64/   thanks slm! 
the kernel interprets the line starting with #! and uses it to run the script, passing in the script's name; so this ends up running  /bin/rm scriptname   which deletes the script
ksh93 has disciplines which are typically used for this kind of thing
the lsof command (already mentioned in several answers) will tell you what process has a file open at the time you run it
after a few more researching and some testing later, i finally have changed my login background, those are the steps i followed:  1) i've placed the file i wanted as background in /usr/share/pictures directory (i've created  that directory myself)  2) i've entered the terminal and, as root user, i've edited /etc/gdm3/greeter.dconf-defaults file in order to look like this:  [org/gnome/desktop/background] picture-uri='file:///usr/share/pictures/background.png' picture-options='zoom'  [org/gnome/login-screen] logo='/usr/share/icons/gnome/48x48/places/debian-swirl.png' fallback-logo='/usr/share/icons/gnome/48x48/places/debian-swirl.png' disable-user-list=true disable-restart-buttons=true   (background.png is my actual background picture)  3) in order to regenerate the configuration i ran "dpkg-reconfigure gdm3" and "dpkg-reconfigure gdebi-core" 
the hidden partition will probably contain an image of a windows install as others have suggested, but it may also contain a collection of diagnostic utilities provided by dell
in $(echo "echo 'a'; echo 'b'"), the shell sees a command substitution
you should enable apache's server-status so you can see what is busy
tell tclsh to read the script from a different file descriptor, and use a here document to pass the script.  shuffle () {   tclsh /dev/fd/3 "$@" 3&lt;&lt;'eof' proc main {} {     … } main eof }  
with csh or any shell implementing csh-like history substitution (tcsh, bash, zsh):  !!   then enter.    or alternatively:  !-1   then enter.    or ctrl+p, enter    magic space  also, note that !! and !-1 will not auto-expand for you, until you execute them (when it might be too late).  if using bash, you can put bind space:magic-space into ~/.bashrc, then pressing space after the command will auto-expand them inline, allowing you to inspect them before execution
&gt; awk -v rs=$'\n\n' -v fs=$'\n' -v ors=$'\n\n' '$2 ~ /123$/ {print}' abc.txt abc 123 abcd 123 abcde 12345  
as the comments say, the question has already been asked here
to follow linux principe "one task -- one tool":   prints just necessary block (as in example cad)  sed '/^\s*[0-9].*cad/!d;:a;n;/\n\s*[0-9]/! s/\n/\x0/;ta;p;d' sort it in reverse order  sort -rn take just first asked blocks (as in example 4)  head -4   please note, that most linux commands operate with lines (not blocks) so the ones was converted into lines by changing \new line to null-symbol(\x0) then converted back by tr.so, all line:   sed '/^\s*[0-9].*cad/!d;:a;n;/\n\s*[0-9]/! s/\n/\x0/;ta;p;d' test.txt | sort -rn | head -4 | tr '\0' '\n'     i like the g-man answer's idea to change rowseparator but this is not much suitable in the case
qjoypad stores the name of the last layout used in a file called layout in its settings directory (by default, ~/.qjoypad3)
the a* and *a* syntax is implemented by the shell, not by the ls command.  when you type  ls a*   at your shell prompt, the shell expands a* to a list of existing all files in the current directory whose names start with a
if you want the x connection forwarded over ssh, you need to enable it on both the server side and the client side
if there is an available module for the file system you want to mount but it's not yet loaded and hence isn't yet shown in /proc/filesystems, then it will be loaded on-demand which it why you don't have any problem mounting.  after having mounted such a file system, then that file system type should have appeared in /proc/filesystems.  hence it is a "list of supported file systems for which the driver is already loaded"; additional file systems may be added by loading the appropriate module. 
tl;dr  don't do this unless you have peculiar auditing requirements
the main two commandline possibilities are:   use su and enter the root password when prompted. put sudo in front of the command, and enter your password when prompted.     running a shell command as root  sudo (preferred when not running a graphical display)  this is the preferred method on most systems, including ubuntu, linux mint, (arguably) debian, and others
it might not be the easiest way but you could   save the text to in.txt and render your text to postscript e.g:  a2ps -1 in.txt -o 1.ps   make sure your 1.ps looks like you want it to, a2ps normally adds a border and header
if you want to install that specific package you can just do     wget http://ftp.redhat.com/pub/redhat/linux/enterprise/5client/en/os/srpms/subversion-1.6.11-7.el5.src.rpm      rpmbuild --rebuild subversion-1.6.11-7.el5.src.rpm   however the rpmforge repo has 1.6.6 in it, so you can enable that repo if you wish.     rpm -ivh http://packages.sw.be/rpmforge-release/rpmforge-release-0.5.2-2.el5.rf.x86_64.rpm      yum update subversion   assuming of course that x86_64 is your arch, if not you can change that to i386 
you can install devilspie2 and create a config file ~/.config/devilspie2/max.lua with the following content, which would start every iceweasel maximized:  -- make iceweasel always start maximized. if (get_application_name() == "iceweasel") then   maximize(); end    src: readme  then make sure to start devilspie2 together with your desktop environment
if you want a file with a lot of extents, just do:  $ perl -we 'for ($i=0;$i&lt;100000;$i++) {seek stdout,$i*8192,0; print "."}' &gt; a $ ll a -rw-r--r-- 1 stephane stephane 819191809 dec 15 23:50 a $ filefrag a a: 100000 extents found   that's a sparse file where every other block is sparse, so it forces the extents to be 4kib large.  debugfs:  dump_extents a level entries         logical          physical length flags  0/ 2   1/  1      0 - 199998   33413           199999  1/ 2   1/295      0 -    679   33409              680  2/ 2   1/340      0 -      0   34816 -   34816      1  2/ 2   2/340      2 -      2   34818 -   34818      1 [...]  
this could do the trick:  xmodmap -e 'pointer = 1 25 3 4 5 6 7 8 9'   source: http://jaredrobinson.com/blog/howto-disable-middle-mouse-paste-in-linux/ 
the simplest way is to store the response and compare it:  $ response=$(curl -x post -d@myfile.txt server-url); $ if [ "upload successful" == "${response}" ]; then … fi;   i haven't tested that
when a user logs into the graphical mode, the predefined desktop environment starts (gnome 3 in your case)
ifs='\n' sets the internal field separator to consist of two characters: \ (backslash) and the letter n
gnu screen does not support vertical split unless it's patched (some distros have a patched version of screen in their repositories, but it's rare.)  the patch is licensed under gplv2
in theory yes
you can use the rename command (see edit 1).  solution 1  for a reasonable number of files/directory, by setting bash 4 option globstar (not works on recursive name, see edit 3):  shopt -s globstar rename -n 's/etckeeper/userkeeper/g' **   solution 2  for a big number of files/directories using rename and find in two steps to prevent failed rename on files in just renamed directories (see edit 2):  find 
when you invoke zsh you can debug what's going on by using the -x switch
in the page top ten one-liners from commandlinefu explained is suggested this trick (the #3):  :w !sudo tee %   this write the current buffer to the stdin of the command after the !
on ubuntu:  $ sudo cat /var/log/auth.log|grep ssh|grep accept   on centos/rhel:  $ sudo cat /var/log/secure|grep ssh|grep accept   this will show all connections, and how they authenticated [since the log file's last rotation]
you can print out the current definition of the function, and then include it in a function definition inside an eval clause.  current_definition=$(declare -f command_not_found_handle) current_definition=${current_definition#*\{} current_definition=${current_definition%\}} prefix_to_add=$(cat &lt;&lt;'eof'   # insert code here (no special quoting required) eof ) suffix_to_add=$(cat &lt;&lt;'eof'   # insert code here (no special quoting required) eof ) eval "command_not_found_handle () {   $prefix_to_add   $current_definition   $suffix_to_add }"   another approach, which i find clearer, is to define the original function under a new name, and call that from your definition
normally you telnet or ssh the router to get the data from  ifconfig every minute or so and collect your traffic data
i can now answer my own question based on stefan's comment and the two linked articles:   http://ubuntu.stackexchange.com/questions/1733/what-reason-could-prevent-console-output-from-virsh-c-qemu-system-console-gu http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=507650#29   here is the solution:   you need not edit anything to do with the host configuration provided it has the default serial device pointing to pty in there
i would put  * * * * * /sbin/reboot   in root's crontab.  clarification: since cron doesn't run until the system is fully up, you don't get conflicts between startup and shutdown procedures. 
usually this fix for me,   add these lines into your wp-config.php:  define('wp_home','https://example.com'); define('wp_siteurl','https://example.com');   where both entries contain your new site address
if you run fsck, the filesystem check and repair command, it might find data fragments that are not referenced anywhere in the filesystem
your error is because you are using double quotes ("), which allow the contents to be interpreted by the shell before it gets to grep.  try grep -r 'c:\\' . instead.  echo 'c:\' &gt; test ire@localhost$ cat test c:\ ire@localhost$ grep -r 'c:\\' test c:\   explanation: \ has a special meaning, both to the shell and to grep
use sg
you need to put "" around your variable.  find 
grep '^[dd][aeiou]..s$' /usr/share/dict/words    ^[dd] - match d or d at the beginning of the line [aeiou] - match a, e, i, o or u .. - match any two characters s$ - match s, followed by the end of the line  
linux initially boots with a ramdisk (called an initrd, for "initial ramdisk") as /
cvm -version  it produces the same output as cvm -showversion 
they're identical, at least on linux.  i came to this conclusion by first looking at the source code for mknod(1) in the gnu coreutils, where on line 217 in the current version we find that the 'c' and 'u' cases are treated identically, getting the same device type
there are many ways to do so
you may use awk:  $cat my.xml | awk '/&lt;b&gt;/{hide=1} /&lt;\/record&gt;/ {hide=0} {if (hide==0) print;}' &gt;mynew.xml   this will hide everything since line which contains &lt;b&gt; and start display with line containing &lt;/record&gt;  per your comment, if your xml is one big line - just split it to lines and remove newline chars back after you've done the conversion.  $cat my.xml|sed 's/&gt;/&gt;\n/g'| awk ......
   if a program supports streaming i/o it can work with files more than the size of the memory, is this correct   usually yes, but not necessarily
as you already discovered that this problem does not appear with dash, it seems to be obvious that there is a high probability that this is caused by a bug.  it does also grow if you are using bash-3.x but very slowly - still faster than with other shells.  i recommend you to make a bug-report against your version of bash.  btw: i did some tests and there are only two shells where there is no growth at all - regardless how long you wait: mksh and the original bourne shell that was not yet converted to use malloc() instead of sbrk().  all other shells grow very slowly. 
/dev/fd and /proc/self/fd are exactly the same; /dev/fd is a symbolic link to /proc/self/fd
there is a nautilus (gnome's file manager) extension for that:  http://packages.debian.org/sid/nautilus-open-terminal  that is the package for debian
assuming you have enough permissions, you can either strace the receiving rsync process or use lsof to see what files it has open.  find the rsync process pid, eg using pgrep rsync, but choose the child as there will probably be two
custom nemo action  this archlinux wiki article titled: nemo describes the steps required to create your own context menu item.  general steps   create a .nemo_action file
last reads from a log file, usually /var/log/wtmp and prints the entries of successful login attempts made by the users in the past
you're basically wanting to reset the terminal color right before bash executes the command
that depends
i've solved this in a better way than my other answer:  first of all get the new vim with  brew install vim   and then do  vim --version   make sure it is 7.4+  note that if you do vi --version you may that vi is at 7.3  now make vi use that newer vim  alias vi=vim   and add that alias to your .bash_aliases file (or wherever you put aliases)   finally add  set clipboard=unnamed   to your .vimrc (not .bashrc!)  start a new shell and it should work. 
assuming this java application is a console based app there is nothing inherently special you need to do just because it's a java application.  if you have a java .class file, run the application like so:  $ java helloworld   if you have a .jar file, run the applicaiton like so:  $ java -jar myapp.jar   cron job  to make either of the above methods a cron job simply add these to a bash script and put that script into one of hte designated crontab directories or simply add the above command to a crontab entry.  examples   making a script  here's a script, myjavawrapper.bash.  #!/bin/bash  # do any classpath stuff here $ java -jar myapp.jar   then put myjavawrapper.bash in one of the cron job directories or system crontab:  $ ls -d1l /etc/cron* drwxr-xr-x
i am not a lawyer, but i think the answer is yes
fgconsole (if run as root) should do what you want
depending on the scripting language you use to run the job you could use   setpgrp() perl: setpgrp pid, pgrp   to detach the running process from the controlling terminal, so once it starts the controlling terminal can exit without harming the running process.  now from what you are describing you will have the controlling terminal and shell by running gnome terminal and starting your job from there so nohup should work just fine for you. 
you could configure your ssh server to listen to both ports, and then use iptables to restrict access to port 22 to a single ip number
here's how i would approach it:   create a function that generates globs for filenames based on the requirement (any character could show up as upper- or lower-case). modify the loop to have scp use the glob as the remote filename, and the already lower-cased filename as the local filename.   this will create the same one scp connection per file, per computer as you do currently, but the globbing will pick up the remote file, no matter how it is "cased".  here's the (bash-specific) function:  function ul {   # for each character in $1, convert it to upper and lower case, then   # enclose it in [ ]   out=   for (( i=0; i&lt; ${#1}; i++ ))   do     c=${1:$i:1}     if [[ "$c" =~ ^[[:alpha:]]$ ]]     then       uc=${c^}       lc=${c,}       out="${out}[${uc}${lc}]"     else       out="${out}${c}"     fi   done   printf "%s" "$out" }   so you put that into the same script, or in some common area that gets sourced.  to demonstrate its usage:  $ g=$(ul system.dbf) $ echo "$g" [ss][yy][ss][tt][ee][mm].[dd][bb][ff]   for step 2, this is how i modified your inner loop:      for file_name in ${file_list[@]}; do         g=$(ul "$file_name")         remote_file=${remote_path}${computer_name}/${dow}/customerdata/system/${g}         local_file=${working_directory}${file_name}         echo $local_file         scp -i $id $user@$host:$remote_file $local_file         chmod 0777 ${local_file}     done   i added the g= assignment as well as the remote_file assignment (at the end of the line). 
following this answer ( its a working solution) , after downloading and extractiing the firmware.zip file, you nedd to extract the firmware-iwlwifi_0.43_all.deb file ( under windows you can use altap salamander)   then extract the data.tar.xz go to /data/lib/firmware and copy all the contents to your usb (fat32)  or simply download iwlwifi firmware from here  it's the same to install rtl_nic/rtl8107e-2.fw   download the firmware-realtek_20160824-1_all.deb , extract it   extract the data.tar.xz file .  the needed firmware will be found at /data/lib/firmware/rtl_nic/rtl8107e-2.fw copy it to your usb 
you can't do this with a single augeas api call, but with aug_get and aug_set you can do it in the calling language
what is missing is that your linker command  gcc -shared -wl,-soname,libnew.so.1 -o libnew.so.1.0 *.o -l
this is sort of indirect answer, because i don't see why you would have non-free software on the system and not know about it
there is no option for that functionality in the output from man locate on centos 6.5, at least
gtknotebook defaults to ctrlpageup and ctrlpagedown for switching tabs (hardcoded in gtk/gtknotebook.c)
have a look at the ipv6 howto on the openwrt wiki
where did you get libgio.so? on most linux distributions, there's an automatic way of retrieving the source code of a package.  for example, on debian, ubuntu and derived distributions, run dpkg -s to see what package libgio.so belongs to, then apt-get source to get the source code of that package
wget  use wget as follow  wget --mirror --no-parent --user=&lt;ftpuser&gt; --password=&lt;ftppassword&gt; ftp://server/&lt;directory path&gt;   it will download the whole directory recursively.  option --no-parent     do not ever ascend to the parent directory when retrieving recursively
you can use the unzip utility with the -v flag:  unzip -v files.zip  archive:  files.zip  length   method    size  cmpr    date    time   crc-32   name --------  ------  ------- ---- ---------- ----- --------  ----        0  stored        0   0% 11-23-2011 15:02 00000000  file1        0  stored        0   0% 11-23-2011 15:02 00000000  file2 --------          -------  ---                            -------        0                0   0%                            2 files   note: the file sizes here are 0 because i made test files of zero length. 
you can use iptables to mark a packet (--pid-owner ...), then use tc to shape the traffic. also "--sid-owner" can be used to include threads and children of that process.  http://www.frozentux.net/iptables-tutorial/iptables-tutorial.html#ownermatch     match  --pid-owner   kernel 2.3, 2.4, 2.5 and 2.6   example    iptables -a output -m owner --pid-owner 78   explanation    this match is used to match packets based on the process id (pid) that was responsible for them
dtrace would be nice but it's not ported on aix.  you should be able to trace what is chmoding the file with auditing: http://www.ibm.com/developerworks/aix/library/au-audit/ 
looking at man indent i see using -brf will put braces on the function definition line
the syntax  x="$(some_command)"   will run some_command and the output of that is returned and stored in the variable "$x".  now, normally, programs send "normal output" to the "standard out" stream (stdout, file handle #1) and error messages to the "standard error" stream (stderr, file handle #2).  the redirection semantic 2&gt;&amp;1 means (roughly speaking; it's a little more complicated under the covers) "send stderr to stdout"
a hacky way would be, to wait for the transactions to finish:  mysql&gt; flush local tables; query ok, 0 rows affected (11.31 sec)  and then getting a read lock:  mysql&gt; flush tables with read lock; query ok, 0 rows affected (22.55 sec)  now all queries are blocked (ie
you asked for using some syntax with the echo command:  echo $'first line\nsecond line\nthirdline' &gt; foo   (but consider also the other answer you got.)  the $'...' construct expands embedded ansi escape sequences. 
the linux-libre project is an extension of efforts by distributions aimed at people who wish to use completely free operating systems, as defined by the free software foundation
the simple approach would be to assign the result to a variable, then work with that variable
you need to boot into a linux live usb (preferably mint or ubuntu), make sure your linux hdd partion is mounted read/write, and use the linux mv command to move the directory to the proper location
the input data is kind of paragraph-oriented, so let's read it as a paragraph instead of line-by-line:  awk -v rs="\n=\n" '     /primer_left_num_returned=[^0]/ {         n = split($0, lines, /\n/)         for (i=1; i&lt;=n; i++) {             if (lines[i] ~ /^(sequence_id|sequence_template|primer_left_num_returned|primer_right_num_returned|primer_internal_num_returned|primer_pair_num_returned|[^=]+_0[^=]*)=/)                 print lines[i]         }         print "="     } ' input.file   or the equivalent perl (allows more readable "expanded" regular expressions  perl -0777 -ne '     begin {         $wanted = qr{              ^                  # at the beginning of the string             (?: sequence_id    # match one of these words                | sequence_template                 | primer_left_num_returned                 | primer_right_num_returned                 | primer_internal_num_returned                 | primer_pair_num_returned                 | [^=]+_0[^=]*             )             =                  # followed by an equal sign         }x     }      for (split /^=$/m) {         if (/primer_left_num_returned=[^0]/) {             print join("\n", grep {$_ =~ $wanted} split /\n/), "\n=\n";         }     }      # or, as a single command:     #     # print      #     map {join("\n", grep {$_ =~ $wanted} split /\n/) 
try:  java -xx:+printflagsfinal   and looking for value you want
there are 3 choices that i'm familiar with.   tracker recoll beagle   this tutorial titled, the best linux desktop search tools discusses these and a couple of others.  tracker  installation is a snap.  $ apt-get install tracker tracker-utils   after installation it should start indexing your drive automatically
if you're comfortable with java, then try groovy, a scripting language based on the java platform
you could always try the following:  ssh -y otheruser@localhost "/opt/netbeans/7.3/bin/netbeans"   :) 
no, luks only supports pbkdf2 as the key derivation function
system settings → application style → window decorations → buttons. 
according to this discussion cap_sys_rawio capability needs to be applied to smartctl executable. 
four things intervene to determine the permission of a file.   when an application creates a file, it specifies a set of initial permissions
i don't believe there is a specific sftp file limit
my bash script looks like this:  #!/bin/bash java -cp "$home/myapp" abc $caja_script_selected_file_paths   explanations:  since my program was placed inside here:  /home/john/myapp/abc.class   i must always use -cp java options to locate my "abc" program first. the $home represents my home directory, /home/john, the $caja_script_selected_file_paths environment variable represents the path of the folder i selected, which eventually being passed as argument to "abc" program.   note that these solution is made in caja specific environment - no guarantee to work in elsewhere.  credits to @pranav, thanks. 
as manatwork said in the comment you should use a function instead to handle arguments better.  gohf(){   cd $(find 
ok so here's my answers to my questions
ah — turns out i think this was actually a vmware issue after all
i would first off discourage you from not using one of the java packages provided by mint unless you really need the oracle java instead of openjdk.  i'd recommend you install your java .bin file before removing the packaged versions of java
i know of 2 ways to do this when the system is remote, so given the 2nd x server is locally running on your system (:1) should really make no difference.  method #1 - vnc  you could setup vnc on the 2nd x server and then run vncviewer :1 from the 1st x desktop.  method #2 - xdmcp  if you want to remote display an entire desktop from one system to another system you'd typically use xdmcp
if as @mark asks the csv file contains one value per line, you can do this trivially by replacing your initial list with a command substitution:  for acc in `cat csvfile` do    ... done  
1.0 is an average of one job waiting over the given time period, not 1 core at 100% utilisation.   an idle computer has a load number of 0 and each process using or waiting for cpu (the ready queue or run queue) increments the load number by 1
by name  you can generate the list of files in the archive and delete them, though this is annoyingly fiddly with archivers such as unzip or 7z that don't have an option to generate a plain list of file names
if the given file is called /path/to/file and you want to find all hard links to it that exist under the current directory, then use:  find 
not at the xmodmap level
the simple answer is that what you want to do is to read the directory file, with a command like cat ., cat /etc, or cat mydir.  of course, since this is “raw” data, you’d want to use a program that’s better suited to displaying non-ascii data in a human-friendly way; e.g., hexdump or od.  unfortunately, as discussed in when did directories stop being readable as files?, most versions of unix that were released in the past two decades or so don’t allow this.  so the answer to your question may be “find a version of unix that still allows reading directories”.  aix, most versions of bsd, and all but the most recent versions of solaris may qualify.  finding a linux that allows it may require the use of a time machine. 
at this time, you cannot
editing the group, passwd, and shadow files directly is safe, but in order to do so you should use the vigr and vipw commands.  when using vigr or vipw, locks are applied to the files in order to prevent concurrent editing which can lead to file corruption. 
you don't need much to do that, just declare eth variable as an array (and change the way it's accessed):  #!/bin/bash ethcounter=$(ifconfig -a | egrep --count "eth[0-9]+") ethindex0=$((ethcounter-1)) declare -a eth  echo ethindex0 = $ethindex0  for ((i=0; i&lt;=ethindex0; i++))  do     eth[$i]=$(ifconfig eth$i)     echo "eth[$i]" = "${eth[$i]}"  done   i've also slightly tweaked your egrep parameter, cause it matched lines containing word 'ether'
if you set the edit_headers option to yes, you can edit all the headers of a mail before sending, and you can set your own date header
by setting:  export term=xterm-256color   you're telling htop (and every other visual terminal application that uses the termcap or terminfo database) that your terminal is a 256 colour xterm and not a linux virtual console.  htop will query the terminfo database to know what sequence of characters is sent upon f1, f2..
this should work:  ssh username@example.com ssh root@example.com   if the private key for root/username isn't being differentiated properly, you can try explicitly calling it out with:  ssh -i ~/.ssh/username_id_rsa username@example.com ssh -i ~/.ssh/root_id_rsa root@example.com   if the second option still doesn't work then something is wrong with your setup of the public-key on the remote server (check the /var/log/secure or /var/log/auth files on the remote host for more information)  check that the:   permission of the .ssh directory is 700. permission of authorized_keys file is 600.     edit, you can also do:  touch ~/.ssh/config vi ~/.ssh/config  #add the following:  host usernamehostname hostname example.com user username identityfile ~/.ssh/username_id_rsa  host roothostname hostname example.com user root identityfile ~/.ssh/root_id_rsa  # save the file with ' :wq '  now just type:  ssh usernameexample [or] ssh rootexample  
/etc/xdg/user-dirs.defaults (global) and ~/.config/user-dirs.dirs (local) contain the directions to default directories
the ^ in ^r in ascii text files normally stands for pressing ctrl plus the following key
$ cat ip.txt  the cow goes moo  $ sed '/cow/{n;n; s/$/\nyay/}' ip.txt  the cow goes moo yay    n;n; get next two lines s/$/\nyay/ add another line  
as far as i know, there is no direct way for this purpose.  the only idea which sprang to my mind was to check out and examine the contents - e.g
try using ionice:  # ionice -c3 dd if=/dev/zero of=z   this start the dd process with the "idle" io priority: it only gets disk time when no other process is using disk io for a certain amount of time.  of course this can still flood the buffer cache and cause freezes while the system flushes out the cache to disk
the bash function you want is backward-word
maybe have a look at libtermkey, a terminal key input library that recognises special keys (such as arrow and function keys), including "modified" keys like ctrl-left.  another option might be to enhance the functionality of charm, a minimal ncurses copy. 
the information of who logged in when is available in /var/log/auth.log (or other log files on other distributions)
if you only wanted to allow a user to edit /etc/fstab, you could do this in several ways:   make sure access control lists are enabled (acl option in the /etc/fstab entry for /), and setfacl -m user:joe:rw /etc/fstab. add a sudoers rule: run visudo and add a line joe all = sudoedit /etc/fstab   i recommend the sudo method because it makes it easy to audit who can do what.  however, if you allow a user to edit /etc/fstab, then they can indirectly gain root by adding an entry that lets them mount an external or loop filesystem on which they've planted a setuid root binary.  it is rather weird to allow a user to edit fstab only
you should add a line to your /etc/fstab file with the path to your device, the path to where you want to mount it, then include "user,noauto" as the file system mount options
@mark-stosberg, this is a known issue: journald is unable to attribute messages incoming from processes that exited to their cgroup, due to /proc vs scm_creds race  you can find a workaround there: https://github.com/systemd/systemd/issues/2913#issuecomment-219702148     try syslogidentifier=           sets the process name to prefix log lines sent to the logging system or the kernel log buffer with.         and run journalctl _systemd_unit=unit + unit=unit + syslog_identifier=id  
i speak from experience only with deb/dpkg, but no, as long as checkinstall succeeds in building a deb/rpm, there are no side-effects from installing that (there are scenarios where it will fail to build a package).  of course, checkinstall doesn't really know about dependencies, so you'll have to have those available if you are planning to install the package anywhere
you can to it for all files using a for loop (in the shell/in a shell-script):  for i in *.jpg; do   j=`jhead "$i" | grep date | sed 's/^file date[^:]\+: \(.\+\)$/\1/'`.jpg   echo mv -i "$i" "$j" done   this is just a very basic outline
this is the actual code that loads the history (from bashhist.c around line 260):  /* load the history list from the history file
based on http://askubuntu.com/questions/150790/how-do-i-run-a-script-on-a-dbus-signal  #!/bin/bash  interface=org.gnome.screensaver member=activechanged  dbus-monitor --profile "interface='$interface',member='$member'" | while read -r line; do     echo $line | grep activechanged &amp;&amp; your_script_goes_here done   just stick that in /etc/init.d/monitor-for-unlock, make it executable, and then make a soft link in rc2.d  chmod +x /etc/init.d/monitor-for-unlock cd /etc/rc2.d ln -s /etc/init.d/monitor-for-unlock .  
i am not sure, but a quick search turned up this which says (emphasis mine):     to be able to send to (or receive from) those mtas, the ruleset   try_tls (srv_features) can be used that work together with the access   map
there's a simple way,  first use apt-get source xxx to get the source code,   when extraction completes, enter the folder, i.e xxx-version, and check the debian/control file, normally you would see a deb_configure_extra_flags += line, that's where you should look at. 
important: you can always override your default options with local options.  from man pppd     /etc/ppp/options           system default options for pppd, read before user default            options or command-line options.   and also  ~/.ppprc /etc/ppp/options.ttyname /etc/ppp/peers   you should enable debug options (sometimes also kdebug)     debug  enables connection debugging facilities
&lt;primary&gt; is a gtk+ thing. gtk+ 2.24.7 &amp; gtk+ 3.2.1 introduced the concept of a platform-agnostic accelerator modifier, &lt;primary&gt;, which can be used instead of &lt;control&gt;:     a new facility is provided in gtk+ (as of this writing it is in git for gtk+-2.24, and released in gtk+-3.2.0) to use the &lt;primary&gt;   descriptor in place of &lt;control&gt; for accelerators and bindings
i ended up using xcape, a utility designed to do exactly this:     xcape allows you to use a modifier key as another key when pressed and released on its own
since my last answer was completely wrong, i did some reading on my own
use chown to set user and group ownership of files and directories
easiest way to install .net 4.0 is to use the newest winetricks script:  $ wget https://raw.githubusercontent.com/winetricks/winetricks/master/src/winetricks $ sh winetricks dotnet40   also, if you have 64-bit wine installed, you will need to use newer .net 4.5 (dotnet45) instead of 4.0. 
on mac os x and bsd:  $ date -r 1282368345 sat aug 21 07:25:45 cest 2010 $ date -r 1282368345 +%y-%m-%d 2010-08-21   with gnu core tools (you have to dig through the info file for that):  $ date -d @1282368345 sat aug 21 07:25:45 cest 2010 $ date -d @1282368345 --rfc-3339=date 2010-08-21   with either, add the -u (standard) option, or pass a tz=utc0 environment variable to have the utc date (tz=utc0 defines a timezone called utc with offset 0 from utc while the behaviour for tz=utc (with no offset) is unspecified (though on most systems would refer to a system-defined timezone also called utc with offset 0 from utc)). 
well, you can spawn several processes in your shell in the background and then (if they all use their stdout or stderr) you can get lots of information intermingled in the console - and by intermingled i mean it can possibly even mix data from several processes in the middle of a line.  what you are probably looking for is logging to a file (system services usually use something in /var/log) and then viewing the file(s)
you can find more about this from man man
if your version of "find" implements the -delete sub-command, then you can try  find directory -delete   in this case:  find ~/.local/share/trash/ -delete   some commands, like rm, perform most of their work in the kernel
you may try to use the following command-line method to find out your apache user name:  www_user=`ps axo user,group,comm | egrep '(apache|httpd)' | grep -v ^root | uniq | cut -d\  -f 1` echo apache user is: $www_user   for the apache group, simple change the last number 1 to 2 (or check: wordpress can&#39;t create directories below upgrade). 
when you press ctrl-v, the shell will start by ignoring keyboard interrupts and simply take the pressed key combination as the input character
defragment is (or was) recommended under windows because it had a poor filesystem implementation
   how can i extract the last 1000 lines from a log file?   tail -1000 file.log     how can i extract only lines with a special string in it?   grep special_string file.log     how can i extract log files with a special date/time?   i'm not sure i understood this one, can you elaborate more? what do you need to do exactly? 
looking closer into it
the error message doesn't indicate that iwlwifi couldn't find a required firmware file; it indicates that it was unable to load a chunk of firmware into the adapter
android is based on the linux kernel
the tool that creates that report is called bashbug and it's part of bash package. see man bashbug for more details. 
as indicated here, a solution would be to use the 'file - add url' option, and there add cdda:///
a solaris machine has ksh as the default shell, i believe
i'm not sure what do you mean by pass phrase vs psk
the original xterm was a set-uid program
there's nothing surprising about this w output
using awk for filtering and gnu datamash for the pivoting you can do:  $ awk -f, '$3=="mp" &amp;&amp; $10=="s" &amp;&amp; $5!="mp"' file.txt \      | datamash --sort -t, --group 5 sum 12 sum 15 ai,1,0.2 air,5,1 bir,10,2  
try adding -d sat, -d usbcypress, -d usbjmicron, -d usbsunplus to your smartctl command line, to use a transfer format that can pass through the usb-sata bridge chip.  you can also try connecting it to a usb 2.0 hub / port, which may cause the bridge to behave differently in regards to ata passthrough.  if none of those work, you can always just remove the hard drive from its external enclosure and connect it to your motherboard directly. 
$ cat /proc/cmdline root=/dev/xvda xencons=tty console=tty1 console=hvc0 nosep nodevfs ramdisk_size=32768 ip_conntrack.hashsize=8192 nf_conntrack.hashsize=8192 ro  devtmpfs.mount=1  $  
iptux seems quite portable
   however, are there any other clever tools/methods to see if process listening on tcp port receives a message?    you can use strace with -e trace=network
it's really a function named module
highly recommend  you should read this wonderful answer for more details.    setting ifs contains digit can break your code:  $ ifs=0 $ echo test $ [ $? -eq 0 ] &amp;&amp; echo done bash: [: : integer expression expected   some shells may inherit ifs from environment (dash, ash), some don't (bash, zsh, ksh)
the menu fonts should change based on your gtk font, but the font used in web pages is a combination of firefox settings and fontconfig.  to change the setting in firefox for example, go to edit > preferences > 'content' tab > and click the 'advanced' button next to 'default font'. here you can change the setting for various languages.  if you want to see which font actually gets used for a particular setting in firefox you can check with the command line: fc-match -s font_name  this shows the fallback order too, so if characters are missing from the first one in the list then the next font in the list will be used, and so on. if you want to change this order you can look up how to modify the fontconfig for your linux distribution, where there are options for system-wide configuration as well as per-user configurations via a file like ~/.config/fontconfig/fonts.conf  if you want to verify your settings in firefox you can visit a page, right click some text and select "inspect element", click the "inspector" tab, and then click the "fonts" tab in the smaller window on the right
you can use the shell builtin time
date makes no effort to synchronize with anything at all, and merely makes some system call (that on linux a strace date ... may or may not show) to lookup the time since the epoch as known by the system.  the system itself may synchronize with the bios clock, or if a virtual machine may obtain the current time from the parent it runs under, or may use ntp (or other software that does more or less the same thing, e.g
you can use the * symbol as a wildcard
you can background the ssh client just like any other shell job by sending it a signal and returning to the parent shell
in the ccmake step there are two python related paths:  the header files:  python_include_path (with me pointing to: /usr/include/python2.7)   and the libs:  python_library (with me pointing to: /usr/lib/x86_64-linux-gnu/libpython2.7.so)   of course pick the right paths in your own situation. 
i solved the problem
unrar tool can help you to extract these rar files on redhat linux. this might alreay install on your linux box, open terminal and type unrar if not you can install it thru   #yum install unrar   you can also follow this  to install file-roller  yum install file-roller   you can launch file-roller by typing it on terminal, when interface comes up, use open and point your rar archive – 
sorry for answering my own question, but as no other responses were published, i've decided to do it.  it seems, that i have found a working solution:   i start the x server with the -sharevts flag:      x -config displaylink.conf -sharevts  :2  i start my applications:     display=2:  x-window-manager    display=2:  xterm  i start the vnc server:     x11vnc -localhost -display :2    the displaylink.conf has the following contents:  section "device"   identifier      "dl1"   driver          "fbdev"   option  "fbdev" "/dev/fb1" endsection  section "inputdevice"    identifier      "generic keyboard"    driver          "void"    option          "corekeyboard" endsection  section "inputdevice"    identifier      "configured mouse"    driver          "void"    option          "corepointer" endsection  section "monitor"    identifier "monitor0"  endsection  section "screen"   identifier "screen0"   device "dl1"   monitor "monitor0"   defaultdepth 16 endsection  section "serverlayout"   identifier     "external"   screen  "screen0"    inputdevice "generic keyboard" "corekeyboard"   inputdevice "configured mouse" "corepointer"       option "autoadddevices" "off" endsection   special case - additional display bigger than the main  last time i have faced a situation, where the projector used for presentation had higher resolution than my laptop
the command line of find is made from different kinds of options, that are combined to form expressions.  the find option -delete is an action. that means it is executed for each file matched so far. as first option after the paths, all files are matched..
put your script in /etc/network/if-up.d and make it executable
you can use the file command to check out what format the executable file has.  eg:  $ file /bin/bash /bin/bash: elf 64-bit lsb executable, x86-64, version 1 (sysv), dynamically linked (uses shared libs), for gnu/linux 2.6.9, stripped  
&gt; ~/pipelab.txt obviously belongs to the command on the same side of the pipeline operator |
this is a bit of a hack but you could add this to your interactive shell configuration:  alias tmuxn='tmux new-session -s $$' _trap_exit() { tmux kill-session -t $$; } trap _trap_exit exit   then you can use tmuxn to start a new session
maybe you missed this?  "making the swap partition work for hibernate (optional)", third subsection in this ubuntu community help site
vfat is only to represent that it's a fat partition, according to the partition table and fstab
the unix philosophy advocates for "small, sharp tools", so the answer is that reading from a file would be bloat contrary to the unix philosophy
it pretty much depends on the operating system you are using
you have to leave the original x server running
you wouldn't as a sd card normally doesn't look like a iso image
it seems to me that it is related to the mdadm migration from raid 5 to raid 6
first of all it's a very wide topic.you can use dpkg-buildpackge to build the source package from the sources.because you explicitly mentioned that how your debian packaging should be, i am just going to write about it.   you should have a debian directory inside your source folder. rules file inside the debian directory, you should overwrite some of the deb helper rules like auto configure or strip using deb helper keywords(for example using, override_dh_auto_configure: or override_dh_strip etc etc...) you should have an package.install file specifying what should go where, for example if you generated an binary then you should mention the path of the binary where should it get installed or if you have any shared objects(.so) files.if you are using automake then it will be very easy.you can just mention it in makefile.am saying where your binary or library should get installed. you should have a control file used to mention the build dependencies and package dependencies.(the things which are required during your debian pakcage installation.) a post installation script used to perform any operations/changes after installing your debian pakcage.(for example if you want to change the permission of a file after the installation or something else). a changelog file having the description of changes on the package and the version number.  if everything goes fine then dpkg-buildpackage should give you a package_arch_version.deb file.   as i said it's a very huge topic
based on l.levrel response, using the tools supplied in os x (this should also work in ubuntu).  find 
simply concatenate the variables:  mystring="$string1$string2"  
so it seemed like i needed to edit another file besides isolinux.cfg
the permissions of the script are irrelevant
it's quite a job for sed:  $ printf 'foo\nbar\n' | sed -n '$!n;/\nbar$/p;d' foo  
if you're going to be reading from stdin, you should read the manpage for tcsetattr, and specifically the section about ‘canonical and noncanonical mode’ (icanon)
if you hook up two usb keyboards to your system, or a usb keyboard to a laptop with built-in keyboard, you can alternately type characters¹ on each one (or use the left on one keyboard and the right on the other
try the psacct package (gnu accounting), it should do just about everything you need, once installed and enabled (accton), then lastcomm will keep report on user processes (see also sa and dump-acct)
a swap file is more flexible but also more fallible than a swap partition
du --max-depth=1 --exclude=./by2 --exclude=./bx4 ./a  
the bit you quote is saying that the output of a system message can appear on a "system console"
for f do exec &lt;"$f"     : handle stdin done   a non-interactive shell will treat any redirection from a file that cannot be read or that does not exist when associated w/ a special builtin as a fatal error and exit immediately with a meaningful diagnostic message written to stderr
i am unable to give a detailed report of their differences but i can at least give a broad overview that may help to answer some basic questions and lead you to places where you can learn more.  oh-my-zsh:   built-in plugin/theme system auto updater for core, plugins, and themes default behavior easily overridden or extended widely popular (which means an active community)   grml-zsh:   very well documented provides many useful built-in aliases and functions (pdf) default behavior overridden or extended with .zshrc.pre and .zshrc.local files actively developed but not as popular as oh-my-zsh   basically, the most apparent differences between the two are oh-my-zsh's plugin/theme system and auto-updater
you can use either host or nslookup from bind-tools:  $ host 172.217.19.195 195.19.217.172.in-addr.arpa domain name pointer fra02s21-in-f3.1e100.net.   $ nslookup 172.217.19.195 server:     192.168.2.1 address:    192.168.2.1#53  non-authoritative answer: 195.19.217.172.in-addr.arpa name = fra02s21-in-f3.1e100.net.  
i asked on the util-linux mailing list (the ''fdisk'' program belongs to the util-linux package)
it turned out that my settings were correct but they weren't being used.  &gt;ps ax | grep dnsmasq  1273 ?        s      0:00 /usr/sbin/dnsmasq --no-resolv --keep-in-foreground --no-hosts --bind-interfaces --pid-file=/var/run/networkmanager/dnsmasq.pid --listen-address=127.0.1.1 --cache-size=0 --conf-file=/dev/null --proxy-dnssec --enable-dbus=org.freedesktop.networkmanager.dnsmasq --conf-dir=/etc/networkmanager/dnsmasq.d   as can be seen it wasn't using the conf file...i did a few other tests to make sure that was the case.    i did end up solving the problem, but i did it by:   disabling network-manager dnsmasq plugin: comment out dns line in /etc/networkmanager/networkmanager.conf moving the /etc/networkmanager/dnsmasq.d/dnsmasq.conf to /etc/dnsmasq.conf adding a catch all name server to the /etc/dnsmasq.conf (see bellow for file listing) adding the dnsmasq address to the top of the /etc/resolve.conf (by changing /etc/resolvconf/resolv.conf.d/head file...see bellow for file listing) starting dnsmasq such that it won't read the resolve.conf: dnsmasq -d -r -q (i wanted to log the queries on the screen so that i could see what was going on). one i had everything working i encapsulated the dnsmasq in a systemd unit-file     $ cat /etc/dnsmasq.conf cache-size=1000 listen-address=127.0.1.1 server=8.8.8.8 server=/abcprivate.net/nn.nn.nn.nn cache-size=1000  $ cat /etc/resolvconf/resolv.conf.d/head     nameserver 127.0.1.1  $ cat /etc/systemd/system/dnsmasq.service [unit] description=systemd - dnsmasq is a domain name system (dns) forwarder requires=network-manager.service  [service] type=simple execstart=/usr/sbin/dnsmasq -d -q -r  
there are programs like bootchart that can be used to show what programs you ran during startup - you can probably keep it going after boot to see what's been invoked during a session.  a better solution may be to use remastering tools.  there are remastering tools for fedora, ubuntu, and others; you can use these to customize a distribution.  you might want to look at tiny core linux
using passwords in plain text files is not recommended
if you don't want to process hidden files:  for f in  my_dir/*.so; do   case $f in     (*/[ab].so) : ;;     (*) chmod 777 -- "$f"; chown igor -- "$f" ;;   esac done   note that setting file permission to 777 is very bad ideal, causing security hole and making chown command later wasted. 
the purpose is to save lots of traffic.  the linux tarball is around 75mb, whereas the patches usually just have a few kb
you'll need to preserve meta-data information:  cd chroot &amp;&amp; bsdtar cf - 
adding to greg's answer:   yes, the two groups of redirections belong to the same simple command.  when i run a command with input (stdin) and output (stdout) redirected, i do it like this:  cmd  arg1  arg2  &lt; file1  &gt; file2  some people (a vocal minority) advocate the  &lt; file1  cmd  arg1  arg2  &gt; file2  variation, because they believe that it's more intuitive to specify the input, then the action, and then the output.  but the following are all equivalent:  &lt; file1  &gt; file2  cmd  arg1  arg2  &gt; file2  cmd  arg1  arg2  &lt; file1  cmd  &gt; file2  arg1  &lt; file1  arg2  don't use any of the above; they are presented as bad examples.  the point is that redirections can appear before or after the first word of the command (or any word in the command), but that they are treated the same. variable assignment(s) may come before the command, to set environment variable(s) just for the duration (scope) of that command.  for example,  tz=gmt0 ls -l  lists your files, showing modification time in greenwich mean time.  "optional variable assignments and redirections, in any sequence" means that  tz=gmt0 ls -l &gt; ls_output_file  tz=gmt0 &gt; ls_output_file ls -l  &gt; ls_output_file tz=gmt0 ls -l  are all equivalent.  again, don't use any of these except for the first.  the point is that variable assignments cannot appear after the first word of the command; if they do, they will be treated as arguments to the command.  for example, look at the syntax of dd.     variable assignments don't write to stdout or stderr, right?   simple, constant data assignments do not do any processing (bookkeeping within the shell doesn't count).  but command substitution runs a command; current_date=$(date +%y%m%d) runs the command date +%y%m%d with its stdout redirected to a pipe to the shell, which captures the output and embeds it into the command line.  but the stderr of the date command is still the stderr of the shell; if you say old_date=$(date --date"three days ago"), you will get an error message on the screen, because date doesn't support that syntax for specifying the date.  of course you can suppress that if you say  old_date=$(date --date"three days ago" 2> /dev/null)  but not if you say  old_date=$(date --date"three days ago")  2> /dev/null  or  2> /dev/null  old_date=$(date --date"three days ago") "in any sequence" refers to the last thing i said, and also the fact that  tz=gmt0 columns=132 ls -l  is equivalent to  columns=132 tz=gmt0 ls -l  (there may be bizarre edge cases; let's not venture there.)  
the solution is to modify ~/.tmux.conf to:  # start windows and panes at 1, not 0 set -g base-index 1 setw -g pane-base-index 1   edit: unlike base-index, pane-base-index is a window option, so setw should be used, as @jogusa pointed out. 
the child processes start running as soon as you fork(), in fact they do not even "start", they just continue in the code after the fork() invocation, just like the parent does
mageia uses rpm for package management, so use the following command to find which package contains the file /usr/bin/kdesu:  rpm -qf /usr/bin/kdesu   and to reinstall the program (use the right package names, i don't have mageia to check):  urpmi --replacepkgs libkdesu5 kdebase4-runtime  
from :help filename-modifiers:  the file name modifiers can be used after "%", "#", "#n", "&lt;cfile&gt;", "&lt;sfile&gt;", "&lt;afile&gt;" or "&lt;abuf&gt;"
you should edit it in files /etc/portage/* in /etc/portage/provided/package.provided you place files which you do not want to be updated or installed e.g. dev-util/android-sdk-update-manager-20.0.3 dev-java/icedtea-bin-7.2.2.1-r1 dev-java/icedtea-bin-6.1.11.3-r  in manuals you will find the rest:  http://wiki.gentoo.org/wiki/portage  http://wiki.sabayon.org/index.php?title=en:howto:_the_complete_portage_guide 
try something like:  egrep -o '[0-9a-za-z_-]+\.(com|org|net|de)\b'   it should be fairly easy to tune the characters allowed before the tld and the list of recognized tlds to your liking. 
from the test directory, do:  mv -t player *.txt   assuming all text files end in .txt.  this will mv all .txt files from current directory (test/) to player/ subdirectory. 
if you have root access and you are willing to apply a hack system-wide (so it will affect other users on the same machine too), a quick hack that will do what you want would be to list the offending site in /etc/hosts:  127.0.0.3   www.problematic-site-name.example.com   (if you are not using linux then replace 127.0.0.3 with 127.0.0.1 because 127.0.0.something-else doesn't necessarily work with other operating systems)  this will trick the system to think that the offending name maps to a local ip address
it's what it says on the tin: “maximum length of command we could actually use” is the maximum possible command line length, given the limit on the platform where xargs is running and the space taken up by the environment
breaking down what don_crissti stated:   grep -rl jdk1.7.0_80 . will search the current location (.), recursively (-r), for jdk1.7.0_80, and return the name of each file with a match (-l). | will "pipe" the output to the next command, xargs. xargs will build and execute commands from standard input (e.g
the problem is not occurring because of the uid of the user
cat /proc/filesystems should do the trick... 
they're kernel threads.  [jbd2/%s] are used by jbd2 (the journal manager for ext4) to periodically flush journal commits and other changes to disk.  [kdmflush] is used by device mapper to process deferred work that it has queued up from other contexts where doing immediately so would be problematic. 
make sure you have -print0 in the find command.  find 
invoking an executable that you don't own is nothing remarkable
i'd recommend that you use rvm to manage ruby versioning.  first install rvm:  curl -l get.rvm.io | bash -s stable --autolibs=enabled 
 don't put commands inside square brackets.  to loop while grep succeeds (i.e., until it fails), just do  while grep ... do     ︙ done  to loop while grep fails (i.e., until it succeeds), do  while ! grep ... do     ︙ done   with a space between the ! and the command. you should always quote your shell variable references (e.g., "$path") unless you have a good reason not to, and you’re sure you know what you’re doing.  by contrast, while braces can be important, they’re not as important as quotes, so "$text" and "$path" are good enough (you don't need to use "${text}" and "${path}", in this context). you don't need the semicolon (;) at the end of the while line (unless you put the do after it).  
there was an initial problem statement, and various solutions were proposed
as openconnect/anyconnect are ssl based, you might try openssl:  echo "" | openssl s_client -connect example.com:443 -prexit 2&gt;/dev/null | sed -n -e '/begin\ certificate/,/end\ certificate/ p'   the first certificate returned would be the servers, the last certificate  would be the ca certificate
this works for me:  journalctl `which sshd` -a --no-pager --since="2015-02-04 00:00:00" | grep failed   sample output:  apr 02 10:18:13 sturm sshd[6068]: failed password for aboettger from 192.168.2.40 port 4812 ssh2 apr 02 10:18:18 sturm sshd[6068]: failed password for aboettger from 192.168.2.40 port 4812 ssh2   or use the -p-option, eg.:  journalctl `which sshd` -p 5 -a --no-pager --since="2015-02-04 00:00:00"   journalctl man page:     -p, --priority=        filter output by message priorities or priority ranges
bash faq entry #68: "how do i run a command, and have it abort (timeout) after n seconds?"     first check whether the command you're running can be told to timeout directly
the only two line editing interfaces currently available in bash are vi mode and emacs mode, so all you need to do is set emacs mode again.  set -o emacs  
the dot (.) is just the . directory inside a directory which is the same as the directory itself (ls -la /foo will show it to you)
in opensuse, there are a few ways of listing installed files
in the good old times of isa sound cards, it was not possible to create device nodes in /dev/ dynamically, so all devices had to be preallocated
the best thing you can do is to add the setgid bit (chmod g+s) to your directories
if you mean the version of sort which is part of the gnu coreutils, you can find its changelog in any source tarball (available here). 
since permissions do not matter, copying with cp -r is fine.  the command you're using to compare the two trees compares the file names, ownership and permission
thank you all for all your great answers
enlightenment's configuration is stored in ".cfg" files using the eet library
i'm probably misunderstanding you, but you just specify the paths one after the other:  zip foo.zip /path/to/first/file /path/to/second/file  
the easiest would be to simply sort by size and print the last 5 lines:  ls -sr /usr/lib | tail -n 5   from man ls:     -r, --reverse           reverse order while sorting    -s     sort by file size   tail just prints the last n lines of a file:     -n, --lines=k           output the last k lines, instead of the last 10; or use -n +k to           output lines starting with the kth   if you also want to check for files in subdirectories, you could do this:  find /usr/lib -type f -ls | sort -gk7 | tail -n 5   the find command looks for files, from man find:     -type c           file is of type c:           [ ..
you should probably try to use an already existing monitoring solution for this
from man grep:     context line control      -a num, --after-context=num      print num lines of trailing context after matching lines
you can use lightweight distributions that require less ram
you need to put the expression in quotation marks
have a look at this bug report. (maybe you can help them fix it) 
to understand the answer to this question, you need to have some understanding of how keyboard input is processed
using gcc 4.5.1 - fail  arm-none-linux-gnueabi-gcc (ctng-1.8.1-fa) 4.5.1 does not report the fp abi compiled for, as mentioned in the error message
prefix the first number with a 0 to force each term to have the same  width.  $ echo {08..10} 08 09 10   from the bash man page section on brace expansion:     supplied integers may be prefixed with 0 to force each term to have   the same  width
no.  consult the android developer site
sed 's'/\ '[long1]'\ '[long2]'\ '/'\ '[long3]'\ '[long4]'\ '/' file.txt   splitting on several lines with backslash does work if new lines are not indented.  $ echo "a,b" | sed 's/\(.'\ &gt; '\),\(.\)/\2-\1/' b-a   tested on cygwin with gnu sed 4.2.2 
change your copy array, and the function call
on most systems (including linux), useradd and adduser only support local users (and ditto for userdel, usermod, groupadd, groupdel, groupmod, addgroup)
it seems that you want to print lines between 'word a' and 'word d' (inclusive)
as for the find command, you can also just add more -exec commands in a row:   find 
theres no missing space
yes.  if you put your aliases in ~/.aliases, then you can do  export bash_env="~/.aliases" somescript   this assumes your script starts with #!/bin/bash, because #!/bin/sh is a little less predictable.  here's what i'd suggest:   create ~/.bashenv move all the settings that you want to work in scripts from ~/.bashrc into ~/.bashenv add this at the top of your ~/.bashrc: [ -f ~/.bashenv ] &amp;&amp; source ~/.bashenv put bash_env=~/.bashenv in /etc/environment make your scripts start with #!/bin/bash if they don't already   or, if you're using zsh, just move your aliases into ~/.zshenv
the url syntax (smb://…) is only available in applications using the gnome libraries
this was tested on a laptop with a i915 drived graphic card.  definitively, in my config/install, there are not
unless you're using a framebuffer console, you're at the mercy of the vga text mode console -- whose color_table[] only has 16 elements. 
the % scripts are called from the relevant version of the rpm file
the reason this is happening is because you are escaping it for the shell, but ssh-copy-id is also attempting to interpret it
via the manual  in the manual (which you can browse inside emacs in info: c-h i m emacs ret): go to the chapter on files, then to the section on visiting (i.e
new users typically get assigned at gid 500
my background is rhel-derived distributions (mainly fedora, today), arch is foreign to me.  back when /etc/inittab and mgetty where used by rhel, you could edit  /etc/inittab and pass the -p option to mgetty
try to become root (sudo su -) and then access the contents of the file/folder
./a.out &lt;&lt; eof first line of input second line of input eof  
this is a debian-ism (and therefore appears in ubuntu, mint, etc.)
this comes up on the mailing list every once in a while.  no, it is not possible to have a pane in more than one window.  the internal design of tmux allows for windows to be multiple sessions, but a pane can only belong to a single window. 
rsync: failed to exec n: no such file or directory (2)   pretty much explains it there...  the -e option (long version: --rsh=) says to execute the following command as the shell on the destination machine.  you told it: -e n
try with alt-.  then lets see whether esc-_ works. 
try the following script:  #!/bin/bash  logfile="$1"  nfiles=$(grep -c 'checking file' "$logfile") failed_userid=($(grep -op 'failed reading user id: \k[^ ]*' "$logfile")) corrupted_files=($(grep -op '[^ ]*(?= is corrupt)' "$logfile"))   echo "total number of files scanned - $nfiles" echo "total number of unique user id failed - ${#failed_userid[@]}" echo "total number of files corrupted - ${#corrupted_files[@]}" echo  echo "list of unique user id's which are corrupt - " for uid in "${failed_userid[@]}"; do    echo "$uid" done  echo  echo "files which are corrupted - " for corf in "${corrupted_files[@]}"; do    echo "$corf" done   run it with  $ ./script file.log   the result for input from your question looks like  total number of files scanned - 3 total number of unique user id failed - 3 total number of files corrupted - 1  list of unique user id's which are corrupt -  18446744073135142816 18446744073698151136 18446744072929739296  files which are corrupted -  /database/batch/p1_snapshot//p1_weekly_1980_0_200003_5.data   short explanation:   -c option of grep counts the matching lines -p enables perl regular expresions syntax -o matches only part of lines (?= construct is the so called positive look-ahead (take it as pattern, but do not include to the output) \k is look-behind assertion (take whole pattern, but throw away from result everything up to this point)   the rest should be obvious
no, it is not possible
don't try to parse find output except as a last resort
greg's wiki has a post on adapting bash scripts for dash that points out a lot of 'bashisms' - extra features that are non-standard but are a part of bash
you can use the following  awk for this to ensure only the leading 0s from the second column are removed       awk '{gsub("^0","",$2); print $1,$2}' yourfile.txt  
first, there are two rather different versions of grub
m-x goto-line (m-g g or m-g m-g) gets you to the beginning of the target line
all services are "disabled" by default; "enablement" is opt-in.  if foo.service is your custom service, then it won't be started unless explicitly pulled in by something (like the onfailure= directive), and you should not "disable" anything. 
from your answer to my comment, it seems you're unaware that swell foop can be installed directly from the repos
with the required skill and especially knowledge about the installed linux it is not worth while anymore to replace it
   when the cpu bandwidth consumption of a group exceeds this limit [quota] (for   that period), the tasks belonging to its hierarchy will be throttled   and are not allowed to run again until the next period.   i'd say that they are trying to point out, that if you provision 10 seconds of cpu time in a minute, then the app can be stopped for 50 seconds as it is out of provisioned time
 it's called tilde, not 'tidle'
using some strace commands we discovered that /etc/inputrc was being loaded after my ~/.bashrc and that containing a set editing-mode vi call which overrode my set -o emacs
what i believe you likely want is something more like:  find 
this is the first time i deal with dialog
you have already completely removed dropbox from your computer, at least in ways that manifest themselves by a file whose name contains dropbox
a workaround would be to strip of the corresponding lines and then diff it
rpm -qa --last is an easy way to find out when certain software was installed from rpm
you can also use awk, so you don't need to use the ctrl key:  du -sh /home | awk '{print $1}'  
virtualbox comes with a series of command line tools all prefixed with vbox
according to the linux standard base:     the system user ids from 0 to 99 should be statically allocated by the system, and shall not be created by applications.      the system user ids from 100 to 499 should be reserved for dynamic allocation by system administrators and post install scripts using useradd.   so, regular users should have uids > 499
the main reason for the 114mb (opensuse 12.1's kernel-default-3.1.0-1.2.1.x86_64.rpm (34mb)) is that the kernel modules that are included with the rpm are collectively quite large.  from the extracted rpm, as an example:  $ du -sh lib/modules/3.1.0-1.2-default/kernel/* 1.3m    lib/modules/3.1.0-1.2-default/kernel/arch 1004k   lib/modules/3.1.0-1.2-default/kernel/crypto 60k     lib/modules/3.1.0-1.2-default/kernel/documentation 101m    lib/modules/3.1.0-1.2-default/kernel/drivers 13m     lib/modules/3.1.0-1.2-default/kernel/fs 32k     lib/modules/3.1.0-1.2-default/kernel/kernel 252k    lib/modules/3.1.0-1.2-default/kernel/lib 16k     lib/modules/3.1.0-1.2-default/kernel/mm 12m     lib/modules/3.1.0-1.2-default/kernel/net 72k     lib/modules/3.1.0-1.2-default/kernel/security 9.2m    lib/modules/3.1.0-1.2-default/kernel/sound   this shows there is approximately 101mb of drivers (which is essentially hardware enablement modules (usb, network cards, storage devices etc).  all kernels for modern distributions are going to have similar sized packages unless they split less common modules into sub-packages. 
when you mount a partition, it will show in df -h, and if you umount it, then it will no longer show in df -h  fdisk -l uses /proc/partitions and prints out all partitions which are physically connected, but your usb drive is still connected to your pc
grep -ozp  "(?s)(abc)[^(abc)]*(mno)" 1 abc yyy mno abc xxx mno  
if you are using bash, check if "checkwinsize" option is activated in your session using  shopt | grep checkwinsize   if you don't get   checkwinsize    on   then activate it with  shopt -s checkwinsize   bash documentation says for "checkwinsize" attribute :      "if set, bash checks the window size after each command and, if   necessary, updates the values of lines and columns."   if you like the setting, you could activate checkwinsize in your ~/.bashrc.   to activate: shopt -s checkwinsize to deactivate: shopt -u checkwinsize  
answering my own question:  i was trying some commands on startup like: mate-screensaver-command -l  but it was not working as mate-screensaver could not be running yet  so i tried:  mate-screensaver sleep 1 mate-screensaver-command -l   but with no success either, so i discovered that the problem was that on starting the mate-screensaver, it was not returning until the process ended, and it would not happen.  so the final solution is to make a file like this:  #!/bin/bash /usr/bin/mate-screensaver&amp; sleep 1 /usr/bin/mate-screensaver-command -l sleep 2 /usr/bin/mate-screensaver-command -l sleep 3 /usr/bin/mate-screensaver-command -l sleep 4 /usr/bin/mate-screensaver-command -l   i made the command 4 times just to be absolutely sure that it is going to lock because the command may fail if screensaver has not successfully started
you can specify an editor on the command line.  -editor=editor  enable external editing, using the specified editor
the panel appears on the primary monitor
i assume by usb you mean a pendrive or external harddisk mounted to your file system. you "detach" this by unmounting the device
use the -f options to make grep treat pattern as fixed string:  grep -f 'abc.def.ghi' &lt;file   and also note that you don't need to invoke egrep. 
to be able to time a subshell, you need the time keyword, not command.  the time keyword, part of the language, is only recognised as such when entered literally and as the first word of a command (and in the case of ksh93, then the next token doesn't start with a -)
this should work:  (defvar no-kill-buffers   '("*messages*"     ;; ...     ))  (defadvice kill-buffer (around no-kill-some-buffers activate)   (unless (member (buffer-name) no-kill-buffers)     ad-do-it))   the reason your advice didn't work is that it was "after" advice, meaning it didn't run until after the normal kill-buffer logic had completed
this was easier than i thought!  all one has to do is bind the port 2048 of serverc to a port on pca
sudo rfkill unblock bluetooth   however, it seems to timeout sporadically
the \[ and \] markers are used to surround text that, when displayed on the screen, will take up zero width, such as control sequences that set colors
 while does not get its own pid because it's a shell keyword, not an external command
something like that:  dd if=/dev/zero bs=1 seek=new_filesize count=0 of=your_file   for example this:  dd if=/dev/zero bs=1g seek=1000 count=0 of=test   will enlarge file test to 1000g 
in the first place, you're asking for a mathematical impossibility, but i'll overlook it
you mean sleep?  or do you want to have something that waits for input before continuing?  you can do that with a read call. 
you can use vbetool to turn the display on/off from the console.  off:  $ sudo vbetool dpms off   on:  $ sudo vbetool dpms on   this command construct will turn it off, and then if you hit a key turn it back on:  $ sudo sh -c 'vbetool dpms off; read ans; vbetool dpms on'   references   [solved] how to turn off monitor at cli turn off monitor using command line  
well, this is not an answer to the question but brings me a solution
from the suse documentation:     scp is based on rcp
i'd suggest writing the pid (in bash that's in $! after starting a process) into a file, of the two processes you're starting (psdash and kegbot).  you can then use ps --pid $(cat your.pid) |  tr -s ' ' | sed 1d | cur -d' ' -f4 to see if the process is actually running.  just as a side note, you should always check whether the pid inside a .pidfile is valid before acting upon it!  it might just happen that whatever mechanism you use to remove the .pid file when your programs stop (normally that would either be part of the program itself, or a shellscript wrapper) fails, and there's a "wrong" pid in the .pid file
use yes &gt;&gt; foo instead of yes &gt; foo and separately :&gt;foo to clear the file  yes &gt;&gt; foo cause read to open foo with o_append
add this to the command:  -o acquire::check-valid-until=false   for example:  sudo apt-get -o acquire::check-valid-until=false update  
in /dev/disk/by-uuid there are symlinks mapping each drive's uuid to its entry in /dev (e.g
rsync's business is creating and synchronizing mirrors of files, warts and all
you probably don't want to hear this, but the easiest way to install libreoffice 5 will be to upgrade to debian 8 and enable jessie-backports.  to stay on wheezy, you've already listed most of the available options:   using a debian repository  the package information is up-to-date, the date given at the bottom is the date the page template was last modified
to me /home partition is automatic for back-ups and ease of upgrading/installing new systems
alfresco is one i heard about: http://www.unixmen.com/alfresco-an-opensource-alternative-of-microsoft-sharepoint/ 
the commands are connected with a pipe (i'm talking the system primitive here—obviously, they're connected with a |)
following is from from the book the linux command line
being 'traced' and being 'hacked' are two very different issues but i'll cover them in a broad sense.  if you need to surf anonymously you can use something like tor to anonymize the traffic but that's not likely necessary.  unless the person harassing you has recurring access to your old email addresses using them for recovery isn't a problem
if you're talking about a mounted filesystem, i don't know of any intrinsic way to tell whether acl are possible
a couple of things:   microsoft has no control over the tzdb used by linux
pdsh allows you to issue a command to run in parallel on multiple remote machines, worth a look.  rpm : http://software.opensuse.org/package/pdsh  details : https://code.google.com/p/pdsh/wiki/usingpdsh 
the “proper” way to install newer software would be to upgrade your distribution
while bash sets $! for that background job started with exec 3&gt; &gt;(job), you can't wait for it or do any other things you'd be able to do with job &amp; (like fg, bg or refer it by job number)
gnu sort with the -g(--general-numeric-sort) option should be able to do the trick  sort -k5,5g -t '_'  &lt;&lt;! beginning_num1_734_num2_1.363e+12_num3_800.pdf beginning_num1_735_num2_7.453e+13_num3_800.pdf beginning_num1_1007_num2_9.453e+12_num3_1200.pdf ! beginning_num1_734_num2_1.363e+12_num3_800.pdf beginning_num1_1007_num2_9.453e+12_num3_1200.pdf beginning_num1_735_num2_7.453e+13_num3_800.pdf  
i found a simple way to do this by using fontforge        just open the font and apply skew transform to all glyphs   edit font info change weight to italic   export font       
for starters, changing the sending mail address is not necessarily "faking"
you don't need to invoke ls to get at the stat information, find already did that
i'm guessing you've set ifs to , to parse the csv
it sounds like the filenames are encoded in one of windows' proprietary codepages (cp862, 1255, etc).   is there another decompression utility that will decompress my files with the correct names? i'm not aware of a zip utility that supports these code pages natively
you need to set output field separator to tab \t:  one way to do it is with -v option:  awk -vofs='\t' '{$3 = "ad"; print}' file   another possibility inside awk, say in the begin block:  awk 'begin{ofs="\t"}{$3 = "ad"; print}' file  
you can with a bit of a hack, but you need to be sure you have an unset variable available
i've since learned of 2 ways to do this:   view menu -> toolbars -> bookmarks toolbar right-click on toolbar -> bookmarks toolbar  
it seems you could do this by editing the /etc/sensors3.conf file as discussed here
if i understand your request i do not think this capability is currently supported by kmail2
process groups exist primarily to determine which processes started from a terminal can access that terminal
the easy way, if you don't particularly need to use -c to tell tar to change to some other directory, is to simply specify the full path to the archive on the command line
man zip  from the man page:  -e    --encrypt           encrypt the contents of the zip archive using a password which is entered on the terminal in response  to  a           prompt (this will not be echoed; if standard error is not a tty, zip will exit with an error)
firstly, using a slow or defective hard drive for swap is not a good idea
the following will let you customize the number of lines and cols tput returns  export lines=1000 export columns=1000  
awk '{$1=$1;print}'   or shorter:  awk '{$1=$1};1'   would trim leading and trailing space or tab characters1 and also squeeze sequences of tabs and spaces into a single space.  that works because when you assign something to one of the fields, awk rebuilds the whole record (as printed by print) by joining all fields ($1, ..., $nf) with ofs (space by default).  1(and possibly other blank characters depending on the locale and the awk implementation) 
the difference in experience between using pass in a console (what you call a virtual terminal) and within a (gui) terminal has nothing to do with pass, but with the secret key management done for gpg (as used in the pass scripts) by the gpg-agent
you can't do it with a quick substitution directly, because ^foo^bar is shorthand for:  !!:s/foo/bar/   the !! part (which refers to the last command) isn't part of the quick syntax (that's what makes it quick), but you can use the longer syntax directly and then modify the !! to whatever you want:  !-4:s/foo/bar/   i explained as much of the history syntax as i know in this post; the last section includes the :s modifier 
there are a few reasons:   ubuntu still has python 2.x scripts you can run python 2 and python 3 next to each other without issue, just call the right binary. python 2.7 will get bugfix and security support until 2020 (and will likely see community support extend even further than that either directly or through other runtimes like pypy et alii) switching /usr/bin/python to python 3 means a lot of python 2 scripts stop working because they either call that explicitly or #!/usr/bin/env python and not #!/usr/bin/env python2   these things together conspire together to make upgrading the default in ubuntu a big time sink for to fix an issue that isn't an issue yet
your last example is the most fail safe
dvds are usually encrypted, and you need to install a special codec to read them.  apt-get install libdvdcss2    this package should do the trick. 
if you look in the directory /etc/yum.repos.d you will see your yum repositories.  you will probably see something like mirrorlist=http://blah.blah.blah.org associated with each repository.  for each repository, yum will go to the associated mirrorlist to find a url for downloading the package
i see the below information from here.  when using sudo, use alias expansion (otherwise sudo ignores your aliases)  alias sudo='sudo '   the reason why it doesn't work is explained here.     bash only checks the first word of a command for an alias, any words   after that are not checked
tl;dr   ..
yes, vsz is virtual memory
what you're using isn't kvm directly, but a management library called libvirt
you can use awk for this:  awk '{print $3}' yourfile  this simply prints the third field/column for every record/row. 
there's no rc file for grep, but you can set the environment variable grep_options to a whitespace-separated list of options that will apply to all grep commands
yes
you need spaces around the ==
that's a long list, surely you don't expect us to review it line by line? it's normal to have many processes running as root: unix systems often have one process to do each job, so many system services get their own process
you need to setup the sftp service (it's part of ssh but often times is disabled)
you're setting lc_collate for the cat command only (which doesn't make use of it), while you need to set it for sort and uniq.  also, you may need to set lc_ctype to something utf-8, otherwise it will cause confusion
there are two sides to the question, the technical side and the historical side.  the technical answer is because bash uses gnu readline
your internal one can be made to work with firmware  wget https://www.dropbox.com/s/9oujf7jzgy73z4m/bcm43142a0-0a5c-21d7.hcd sudo cp bcm43142a0-0a5c-21d7.hcd /lib/firmware/brcm/ sudo modprobe -r btusb sudo modprobe btusb  but since the question is how to disable the internal sudo gedit /etc/udev/rules.d/81-bluetooth-hci.rules  then enter the following subsystem=="usb", attrs{idvendor}=="0a5c", attrs{idproduct}=="21d7", attr{authorized}="0"  save, exit gedit, and reboot, the internal card will not show in rfkill list all 
although the answer is in my comment/duplicate, lets do a summary of the commands you need for:  building exim4-daemon-heavy in debian-like distros  mkdir exim4 &amp;&amp; cd exim4 apt-get source exim4      sudo apt-get build-dep exim4 cd exim4-4.82  ### this could be different for you ##modify your option here in the `debian/rules` file ~/src/exim4/exim4-4.82$ dpkg-buildpackage -rfakeroot -us -uc   this will give you the .deb files in the parent folder
from your log   you launch mpd as super user you use pulseaudio mpd doesn't seem to be allowed to connect to pulseaudio   basically, launching mpd as super user is probably a bad idea
most of what pkg info reports comes from the set actions in the package which define package attributes and other metadata
mdadm supports dealloc.  commit=sec is the time, the filesystem syncs its data and metadata
cp -r parentfolder/folder2 parentfolder/folder1/folder1.1/folder2 
$, space, ' and [ are special characters in most shells
   i am going to try some linux live cds made by individuals, i want to make sure that it's not malware contained, how do i do it?   you can't
openbsd supports running (some) linux userland programs
note that  touch ~/.ssh/authorized_keys chmod go-rwx ~/.ssh/authorized_keys echo '..
as eos luna is based on ubuntu 12.04 lts, i have followed the method presented here (most below is just a translation from french).  so, download 2.6 driver from here and install the deb files.  then, run these commands:     sudo /usr/sbin/lpadmin -p lbp1120 -m cncupslbp1120captk.ppd -v   ccp://localhost:59787 -e      sudo /usr/sbin/ccpdadmin -p lbp1120 -o /dev/usb/lp0      sudo service ccpd start      sudo service ccpd status   you should get two numbers.    if you do not get two numbers:  -edit with administrative rights /etc/ccpd.conf  (gedit text editor in this case)     sudo gedit /etc/ccpd.conf   and add this:  &lt;printer lbp1120&gt;  devicepath / dev/usb/lp0  &lt;/ printer&gt;   then restart the daemon and check the status:     sudo service ccpd restart      sudo service ccpd status   restart and try again    finally set the system so that the demon ccpd starts correctly when turning on the printer; this requires two conditions: that the ccpd is started or restarted at each operation of the printer, and that the cups service is active when starting ccpd.  start or restart ccpd with the printer; this can be automated using udev:  open or create with administrative rights the file: /etc/udev/rules.d/85-canon-capt.rules      sudo gedit /etc/udev/rules.d/85-canon-capt.rules   and add these lines:  kernel=="lp*", subsystems=="usb", action=="add", attrs{idvendor}=="04a9", run+="/etc/init.d/ccpd start"  kernel=="lp*", subsystems=="usb", action=="remove", run+="/etc/init.d/ccpd stop"   finish by saving the file.  udev automatically detect this new rule, it is not necessary to restart.    if you used the automated installation using a bash script (or you had already automated at startup as indicated in my askubuntu answer linked above), the ccpd daemon will not take into account the two above conditions, it is simply launched every time with the pc.  it is therefore necessary to cancel this systematic action so that it would not interfere with the new udev rule.  type the following command in a terminal:     sudo update-rc.d-f remove ccpd     automatic detection of printers defined in the file system /lib/udev/rules.d/70-printers.rules may come against the udev rule you just created.  open with administrative rights the file: /lib/udev/rules.d/70-printers.rules      sudo gedit /lib/udev/rules.d/70-printers.rules   and comment all lines:  # low-level usb device add trigger #action=="add", subsystem=="usb", attr{binterfaceclass}=="07", attr{binterfacesubclass}=="01", tag+="udev-configure-printer", run+="udev-configure-printer add %p" # usblp device add trigger (needed when usblp is already loaded) #action=="add", kernel=="lp*", tag+="udev-configure-printer", run+="udev-configure-printer add %p"  # low-level usb device remove trigger #action=="remove", subsystem=="usb", env{id_usb_interfaces}=="*:0701*:*", run+="udev-configure-printer remove %p"   if the ccpd daemon is running before cups at the first print request it will be stuck with no error message
usermod -a -g tomcat7 dev_user.  that will put dev_user into the secondary unix group of tomcat7, which will allow it to issue the rm command. 
you have already redirected the output of file1 and file2 to the new file file3.  with this command cat file1 file2 &gt; file3 | sort, sort after pipe
you could open an additional session with ssh and issue the following command in it:  tail -f /dev/ttys0   it will print out everything that arrives at ttys0
systemd does its own minimalistic shell-style command line parsing of the contents of execstart= and other parameters
the cause of the problem was the -f i.e
greg's wiki is the best resource i've used, by far
for the sidepane, you can either hit f9 or go to view and select sidepane.  similarly, for the toolbar and status bars, select them from the view menu. 
i think the problem is that you don't want the first two lines you put in /etc/apt/sources.list, namely  deb http://llvm.org/apt/trusty/ llvm-toolchain-trusty main deb-src http://llvm.org/apt/trusty/ llvm-toolchain-trusty main   i suspect these correspond to 3.5 (trunk).  you can verify this by running  apt-cache policy pkg1 ..
   because will have to get rid of debian eventually and i cannot risk to lose access to windows
here is how it can be done  in cinnamon    open system settings choose keyboard choose keyboard shortcuts choose custom shortcuts choose add custom shortcut enter name as "printer off and sleep" enter comand as    gnome-terminal -x bash -c "curl http://192.168.1.50/?s2-1off; echo password | sudo -s pm-suspend" press add
the basic idea is that var=value some-command sets var to value for the execution of some-command when some-command is an external command, and it doesn't get more fancy than that
once you hit a directory that's not executable, find tries to go into it, but it can't because, well, it's not executable
each patch in https://www.kernel.org/pub/linux/kernel/v3.x/ applies to the first release of the corresponding series, so you should apply https://www.kernel.org/pub/linux/kernel/v3.x/patch-3.4.107.xz directly to your 3.4.0 source tree
i totally agree this is a bad thing to do
the trap is that   ifs=; while read..   sets the ifs for the whole shell environment outside the loop, whereas  while ifs= read   redefines it only for the read invocation (except in the bourne shell). you can check that doing a loop like  while ifs= read xxx; ..
having a man page for read (in section 1 of the manual) that says anything else than "there is no read command, but your shell might have a read builtin command, see your shell manual for details" is misleading, because read is a shell builtin and the behaviour and supported options vary from shell to shell.  some systems (generally not linux ones) however do have a read command (in /bin, /usr/bin or elsewhere) as posix requires (but the linux standard base (lsb) specification lifts that requirement), and on those systems, the man page will describe the behaviour of that read command, and will be misleading because it's generally not that read that you invoke when you call read at a shell prompt or in a shell script or in system(), popen()..
i would strongly suggest kali, because you already get a lot of tools for that purpose, and it is still quite easy to handle (and you get a lot of tutorials in addition). 
(on the assumption that you're looking for file names that contain both the string "red" and the string "green")  to pointlessly use bash to test filenames against 'red' and 'green' using the =~ regular expression match operator:  for f in * do   [[ $f =~ red &amp;&amp; $f =~ green ]] &amp;&amp; echo bash: yes: "$f" || echo bash: no: "$f" done   to use standard shell syntax using case and globs to find the same files:  for f in * do    case "$f" in     *green*red*|*red*green*) echo case: yes: $f;;      *) echo case: no: $f;;    esac done   even simpler, with your shell's globbing:  printf "glob: %s\n" *green*red* *red*green*   sample run:  $ touch a b aredgreenb agreenredb agreenbred aredbgreen red green redgreen greenred  $ for f in * &gt;     do &gt;       [[ $f =~ red &amp;&amp; $f =~ green ]] &amp;&amp; echo bash: yes: "$f" || echo bash: no: "$f" &gt;     done bash: no: a bash: yes: agreenbred bash: yes: agreenredb bash: yes: aredbgreen bash: yes: aredgreenb bash: no: b bash: no: green bash: yes: greenred bash: no: red bash: yes: redgreen   $ for f in * &gt;     do &gt;       case "$f" in &gt;         *green*red*|*red*green*) echo case: yes: $f;; &gt;         *) echo case: no: $f;; &gt;       esac &gt;     done case: no: a case: yes: agreenbred case: yes: agreenredb case: yes: aredbgreen case: yes: aredgreenb case: no: b case: no: green case: yes: greenred case: no: red case: yes: redgreen  $ printf "glob: %s\n" *green*red* *red*green* glob: agreenbred glob: agreenredb glob: greenred glob: aredbgreen glob: aredgreenb glob: redgreen  
you are matching a substring, starting with "m", optionally followed by "s", and then followed by a digit [0-9].  the text on lines 4,5 does contain this substring too:  4   sm154  5   sm91   so they are replaced.  try prefixing your pattern with "\s" to indicate that you are only interested in the prefix of column #2, like that:  sed -r 's/(\s)ms?([0-9])/\1xx\2/ig'  
a quick search led me to this howto
there's no difference.  the final slash might have ended up there because of shell completion: with some configuration, ln -s tartabspacelink completes to ln -s target/ link. 
package compatibility isn't determined by the choice repository, each package contains dependency declarations
your problem is the type=simple in the description of the vpn service
you can use awk:  awk 'nf == 1 { print last } { last=$0 }' &lt; datafile   this saves every line of the file (last=$0) as it goes, and when a line has only one record (nf == 1 - nf is the number of tokens on the line, roughly speaking) it prints the saved previous line out. 
solution, that worked for me:  go to a directory, where this information is stored  cd /sys/class/backlight/intel_backlight/   get your maximum brightness  cat max_brightness   in the following step, use echo your-maximum-brightness, mine is 5273  create a text file set-max-brightness.sh with the following content  #!/bin/bash echo 5273 &gt; /sys/class/backlight/intel_backlight/brightness   let's say we now have this file stored as  /home/user/set-max-brightness.sh   now we asssign it to root by running  sudo chown root:root /home/user/set-max-brightness.sh   then we make it executable and limit user rights with  sudo chmod 744 /home/user/set-max-brightness.sh   and finally we make the script run at startup  sudo crontab -e   this will bring up root's cron, we just add at the bottom of the file  @reboot /home/user/set-max-brightness.sh  
practice more than one gnu/linux distribution
your home directory is meant to be used for your own files, which means that you definitely can use it with different distributions
here is one possible solution that can be added to bash script
as far as i can tell from your problem description the correct term for what you want is "hybrid graphics" as you only use either adapter to power your monitor (actually any output), not both at the same time.  an overview over tools for what you want can be found (for example) here
for this specific task, you'd do dpkg-reconfigure -plow clamav-freshclam and select manual
since you did not specify any language requirement, here's a possibility using python 3.  #/usr/bin/env python3  from glob import glob from os.path import basename import re  for prefix in ('changelog', 'file_changelog'):     files = dict((int(re.split('[_.]', basename(f))[-2]), f)                  for f in glob('*-*-*/%s_*.txt' % prefix))     out_file = '%s_%d-%d.txt' % (prefix, min(files.keys()), max(files.keys()))      with open(out_file, 'w') as f_out:         for date in sorted(files.keys()):             with open(files[date]) as f_in:                 for line in f_in:                     f_out.write(line)             f_out.write("\n")   it basically uses glob and basename to list and parse file names, sorting them by date
you cannot do this because for such a conversion, you need to know the meaning of the binary content.  if e.g
you can simply use xargs  xsel | xargs -n1 echo mycommand    -n1 means one arg for mycommand, but it's just dry run, it will show what going to be run, to run it remove echo  for constant argument  xsel | xargs -i {} -n1 echo mycommand "constantargument" {}  
if /boot is empty, it's probably because you are looking at the mount point where /boot is normally mounted, not the boot partition itself
i found a way to accomplish what we were looking for
if you have inotify-tools installed you can use inotifywait to trigger an action if a file or directory is written to:  #!/bin/sh dir1=/path/to/a/ while inotifywait -qqre modify "$dir1"; do     /run/backup/to/b  done  where the -qq switch is completely silent, -r is recursive (if needed) and -e is the event to monitor, in this case modify
yes, using the ls_colors variable (assuming gnu ls)
take your image, extract the first sector:  dd if=image of=mbr.dat bs=512 count=1   write "aaaaa" to position 440-444 and do not truncate the file:  echo -en "\x41\x41\x41\x41\x41" | dd of=mbr.dat conv=notrunc seek=440 bs=1   use a hexeditor like okteta to verify that it did what you wanted
with gnu du:  du -b file | awk '{ print $1, "* 8" }' | bc  
with linux column(1):  column -t &lt;file.txt   with bsd rs(1):  rs 0 6 &lt;file.txt   with awk(1):  awk 'fnr==nr { for(i=1; i&lt;nf; i++) if(length($i)&gt;w[i]) w[i]=length($i) }      fnr!=nr { for(i=1; i&lt;nf; i++) $i=sprintf("%-" (w[i]+1) "s", $i); print }' \         file.txt file.txt  
let the machine power-cycle itself by leaving it on until the battery dies
there is no way (that i know of) to directly access script-local variables outside the context of that script; &lt;sid&gt; only works for functions (and only in mappings).  you could provide indirect access through a function, though:  function! s:foobarhash()   return s:foobar endfunction function! s:mysurroundingfunctioniwanttokeep()   let s:foobar={'foo': 'bar'}   map \42 :echo &lt;sid&gt;foobarhash()['foo']&lt;cr&gt; endfunction call s:mysurroundingfunctioniwanttokeep()   depending on how isolated you want to keep the variable, you could make the “accessor” function more restrictive (only allow certain keys, only allow read access, only allow writes to certain keys, etc)
i'm not sure what release you're using, but i'm assuming 10.1, currently the latest
after configuring settings , we have to restart dnsmasq service :  sudo /etc/init.d/dnsmasq restart   update :  if you want to use wild card (*) then you can use dot (.) then dnsmasq to resolve whatewer_you_put_here.yourmachine.yourdomain to the same ip
i found the command apt-mark (which needs to be ran as root)
you can't do this.  all cron jobs are run in non-interactive shells, there is no terminal attachment
you can do   lsof -n | grep -i "tcp\|udp" | grep -v "established\|close_wait"   to see all of your listening ports, but dollars to donuts that ntpd is running:   service ntpd status   and as for "what does socket in use" mean? if i can be forgiven for smoothing over some wrinkles (and for the very basic explanation, apologies of most of this is remedial for you)...tcp/ip (the language of the internet) specifies that each computer has an ip address, which uniquely identifies that computer on the internet
you need to escape the double quotes in the python script:  alias caps="python -c 'from ctypes import *; x11 = cdll.loadlibrary(\"libx11.so.6\"); display = x11.xopendisplay(none); x11.xkblockmodifiers(display, c_uint(0x0100), c_uint(2), c_uint(0)); x11.xclosedisplay(display)' "   of course, you could also save that as a python script, and then  alias caps='path/to/script.py'   
you can use :  pkill screen   or   killall screen  
use \[...\] around the parts of ps1 that have length 0
try:  systemctl status pid   you should see something like this:  $ systemctl status 16736 ● salt-master.service - the salt master server   loaded: loaded (/lib/systemd/system/salt-master.service; disabled; vendor preset: enabled)   active: active (running) since thu 2015-09-10 05:11:21 msk; 1min 8s ago   main pid: 16736 (salt-master)   cgroup: /system.slice/salt-master.service        ├─16736 /usr/bin/python /usr/local/bin/salt-master        ├─16744 /usr/bin/python /usr/local/bin/salt-master        ├─16751 /usr/bin/python /usr/local/bin/salt-master   systemctl(1) says:     status [pattern...|pid...]]      show terse runtime status information about one or more units, followed by most recent log data from the journal
since version 3.15, the kernel tells you the version of xfs used in each filesystem as it mounts it; dmesg | grep xfs should give you something like  [1578018.463269] xfs (loop0): mounting v5 filesystem   instead of loop0 on your system you'll get the underlying device, and v5 will be replaced by whatever version your filesystem uses.  older kernels officially supported xfs version 4 filesystems, but could mount version 5 filesystems (since mid 2013); for the latter, the kernel would print     version 5 superblock detected
you can modify the /desktop/gnome/applications/terminal/exec key in gconf (using gconf-editor), which is described as "the default terminal application to use for applications that require a terminal".  alternatively, i propose a little more flexible solution: if you use compiz, you can use the commands plugin to define keyboard shortcuts for your own commands. this way, you can keep the default shortcut to launch a windowed terminal, and define an other shortcut for a fullscreen terminal.  (sidenote: in the compiz configuration tool, you can change directly the terminal command and shortcut in the gnome compatibility plugin.) 
actually the shebang lines means something as some distributions like debian don't use bash for /bin/sh but dash.  the simplest solution to determine if a shell script is bash is to use checkbashism - see man checkbashisms for details
no, not by default
you are piping the grep output to wc and echo $? would return the exit code for wc and not grep.  you could easily circumvent the problem by using the -q option for grep:  /etc/init.d/foo status | /bin/grep -q "up and running"; echo $?   if the desired string is not found, grep would return with a non-zero exit code.  edit: as suggested by mr.spuratic, you could say:  /etc/init.d/foo status | /bin/grep -q "up and running" || (exit 3); echo $?   in order to return with an exit code of 3 if the string is not found.  man grep would tell:     -q, --quiet, --silent           quiet;  do  not  write  anything  to  standard   output
another perl:  perl -pe 'begin { binmode \*stdout } chomp; tr/ab/\0\1/; $_ = pack "b*", $_'   proof:  $ echo abbbaaaabbbbbabbabbbabbb | \     perl -pe 'begin { binmode \*stdout } chomp; tr/ab/\0\1/; $_ = pack "b*", $_' | \     od -tx1 0000000 70 fb 77 0000003   the above reads input one line at a time
sadly, the lack of answers may mean that there isn't one
sudo has nothing to do with this little difference, the restriction is far closer to the kernel
yes, something has to run the lvm utility (as you say, vgchange -a y or similar) at some point
add this to .emacs:  ;; do not use gpg agent when runing in terminal (defadvice epg--start (around advice-epg-disable-agent activate)   (let ((agent (getenv "gpg_agent_info")))     (setenv "gpg_agent_info" nil)     ad-do-it     (setenv "gpg_agent_info" agent)))   source: http://stackoverflow.com/a/16829842/3024945 
use unrar lb archive.rar to get a list of bare filenames, one per line
i haven't tried it, but using -i and -x could give you what you want
i would attempt to repair the disk with either hdat (freeware) or possibly spinrite (commercial)
you can use pfl (emerge -av pfl) or a online database to search by package contents,  and for the qcad package, you probably need the qt4 package
the browser files on disc just get replaced
this is what worked for me:  user_name=$(printf '%s' "${sudo_user:-$user}")  sudo -u $user_name &lt;command-to-exec-in-nonroot-context&gt;  
given this input, you want to keep the first and last fields
you should always double quote variables
this is the only post i have seen mentioning this specific issue
i've found very helpful answer on:  https://wiki.archlinux.org/index.php/virtualbox#mounting_.vdi_images  the tip is to use offset option of ext4 mount (to be more specific, in back scenes it uses offset as option for loopback device losetup)  it's about    taking offdata info from vdi image adding magic number 32256 and using result as offset   here is my way of automating it:  vdifile=virtdata.vdi mountingpoint=/mnt/vdi offdata=$( vboxmanage internalcommands dumphdinfo "$vdifile" |grep offdata | sed 's:.*offdata=\([0-9]*\).*:\1:' ) offset=$(( $offdata + 32256 )) mount -t ext4 -o rw,noatime,noexec,loop,offset="$offset" "$vdifile" "$mountingpoint"   for /etc/fstab you might like to add: (123456789 is counted previously offset)  /path/virtdata.vdi      /mnt/vdi        ext4 rw,noatime,noexec,loop,offset=123456789,user,noauto   of course rw can be changed to ro or you might not need noatime or noexec - taylor them to your needs  btw
&gt; awk -v ofs="'^'" -f"'\\\\^'" '{if(length($2)&gt;20) $2=substr($2,1,20); print;}' file 'xyz843141'^'asdfsafxyvfshgdsdg s'^'baaar'^'yyy'^'....
recent versions of gnu find have an -iname flag, for case-insensitive name searches.  find 
from the select manpage:     on linux, select() modifies timeout to reflect the amount of time not   slept; most other implementations do not do this
whenever a package is installed automatically by apt-get because it's a dependency of some other package, apt-get notes that fact; then if it notices that nothing depends on such a package any more, it will suggest that the package be removed
 don't use backticks, use $(). use single quotes around literal strings and double around variables, so echo "$test". don't use echo, use printf.   after all:      $ test="$(printf '%s' '[asdf]')"     $ printf "%s\n" "$test"     [asdf]  
 xdg-open to open a viewer from terminal convert to ascii art asciiview use vlc to output video as ascii art  
/tmp, but the data stored there will be deleted upon reboot 
the best thing to change is the dpi because that makes your fonts bigger without messing up your apps
at least on my kde4 desktop i can remove a launcher like this:    right-click on the right-most side of the panel and select unlock widgets in the popup menu right-click again on the right-most side of the panel and select panel settings now displayed in the popup-menu move mouse on the desired launcher icon and click on the x in its popup to remove the launcher (you can also click and drag it elsewhere if you want to) right-click on the right-most side of the panel and select lock widgets in the popup menu (to prevent accidental panel changes)  
i'm no octave expert, but it look like octave parses "9 ^ 1/2" as "(9^1)/2"
the file has a name, but it's made of non-printable characters
that is not possible with inotify
i don't think that's available in ksh
a simplified reason is the existence of one character: space.  brace expansions do not process (un-quoted) spaces.  a {...} list needs (un-quoted) spaces.  the more detailed answer is how the shell parses a command line.    the first step to parse (understand) a command line is to divide it into parts. these parts (usually called words or tokens) result from dividing a command line at each meta-character from the link:        splits the command into tokens that are separated by the fixed set of meta-characters: space, tab, newline, ;, (, ), &lt;, >, |, and &amp;
that site requires javascript to be enabled
theoretically: this is a difficult question to answer completely, and it starts with: what is your definition of linux (e.g
if you are using kde's own builtin screensaver, i'm not sure..
the cache shown in free is file system cache
the route or the ip utility get their information from a pseudo filesystem called procfs
you need to use p flag to make other expansion flags (follow p)  recognize the escape sequence:  $ printf '%s\n' ${(ps:\0:)var} 5 0 7   or using the shorthand:  printf '%s\n' ${(0)var}   to preserve empty elements:  printf '%s\n' "${(0@)var}"   but you can't use that for output from find ..
you should be able to use the -d option for that:  gzip -r -d ocloud/ ocloud.zip.gz  
you can use the idea from this thread on sf:  need help grepping postfix log.  first you should search all possible queue ids matching your criteria
process.xsl:  &lt;?xml version="1.0" encoding="utf-8"?&gt; &lt;xsl:stylesheet version="1.0" xmlns:xsl="http://www.w3.org/1999/xsl/transform"&gt;   &lt;xsl:output method="xml" indent="yes"/&gt;    &lt;xsl:template match="//book"&gt;     &lt;xsl:element name="book"&gt;       &lt;xsl:apply-templates select="./@*"/&gt;     &lt;/xsl:element&gt;   &lt;/xsl:template&gt;    &lt;xsl:template match="book/@*"&gt;       &lt;xsl:if test="name() = 'name'"&gt;     &lt;xsl:attribute name="{name()}"&gt;       &lt;xsl:value-of select="."/&gt;     &lt;/xsl:attribute&gt;       &lt;/xsl:if&gt;       &lt;xsl:if test="name() != 'name'"&gt;     &lt;xsl:element name="{name()}"&gt;       &lt;xsl:value-of select="."/&gt;     &lt;/xsl:element&gt;       &lt;/xsl:if&gt;   &lt;/xsl:template&gt; &lt;/xsl:stylesheet&gt;   input.xml:  &lt;book name="data structure" price="250" pages="350"/&gt;   command:  xsltproc process.xsl input.xml  output:  &lt;?xml version="1.0"?&gt; &lt;book name="data structure"&gt;   &lt;price&gt;250&lt;/price&gt;   &lt;pages&gt;350&lt;/pages&gt; &lt;/book&gt;  
sed 's/\t/ -/' inputfile   if that pattern appears multiple times on a line, use the global option:  sed 's/\t/ -/g' inputfile   if you want to restrict it to certain lines, for example that start with "info":  sed '/^info/ s/\t/ -/' inputfile   you can use the -i option to edit the file in place:  sed -i 's/\t/ -/' inputfile   if you don't do that you can do this equivalent operation  sed 's/\t/ -/' inputfile &gt; outputfile &amp;&amp; mv outputfile inputfile  
i ran xinetd with the -d (debug) flag, and got the following helpful error messages:  11/9/6@15:32:33: error: 2767 {server_parser} server /usr/libexec/cups/daemon/cups-lpd is not executable [file=/etc/xinetd.d/cups-lpd] [line=10] 11/9/6@15:32:33: error: 2767 {identify_attribute} error parsing attribute server - disabling service [file=/etc/xinetd.d/cups-lpd] [line=10] 11/9/6@15:32:33: error: 2767 {fix_server_argv} must specify a server in printer   there was no /usr/libexec/cups/daemon/cups-lpd file, but there was a /usr/lib/cups/daemon/cups-lpd
switch to a different virtual console, e.g
you can generate some of the icmp unreachable variants with qualifiers to iptables ..
the fact that something is possible to do in bash, doesn't mean that you should, or that it's a good idea
from the source:  int32 max_blength = protocol_version &lt; 30 ? old_max_block_size : max_block_size;  sum-&gt;blength = read_int(f); if (sum-&gt;blength &lt; 0 || sum-&gt;blength &gt; max_blength) {     rprintf(ferror, "invalid block length %ld [%s]\n",         (long)sum-&gt;blength, who_am_i());     exit_cleanup(rerr_protocol); }   where:  #define old_max_block_size ((int32)1 &lt;&lt; 29) #define max_block_size ((int32)1 &lt;&lt; 17)   which is 536870912 (512m) and 131072 (128k) respectively.    the change was made in version v3.0.0 and support for old_ was added in v3.0.3
go to this page at opensuse.org and click "1-click install" button on mono-complete-2.8.2 meta package
try  dumpe2fs -b /dev/&lt;whatever&gt;  
for dest in $(awk '{print $nf}' mylogfile | sort | uniq) do   grep ${dest} mylogfile | sort -k1 -k2 | tail -1 done   1    $(awk '{print $nf}' mylogfile | sort | uniq)   print the last field of each line in logfile, which is your destrination ip. sort it so that identical ip addresses are in consecutive blocks. uniq is to print only one instance of identical blobk of lines   2 &amp; 4   do ..
with a modern implementation of grep:  grep -r nasa .   here is a nasty way to check if it looks like an image filename:  grep -re 'nasa[[:alnum:] ]*\.(jpe?g|png|gif|tif)' .   there are some obvious caveats (the biggest one being that it only allows alphanumeric characters and spaces in the filename to avoid false positives with syntax).  although that said, if this is html or something, you'd be better to use a parser. 
the problem comes from your rule: you only try to match a parent of your device, and not the device itself..
parsing the output of ls is unreliable, but this should work in this particular case:  sed -e 's/^.*emma emma //' file   that deletes everything up to "emma emma " on each line
file system capabilities in linux were added to allow more fine-grained control than setuid alone will allow
yes, you're looking for mkpasswd, which (at least on debian) is part of the whois package
if you are using gnu sed, just run:  sed -i '/map/s/\(.*\)].*\/\(.*$\)/\1,\2/' example.csv   warning: this will overwrite the contents of the file
you could write a script to display your temperature in dwm's status bar, for example:  temp (){     awk '{print $4"°c"}' &lt;(acpi -t)     echo $temp } xsetroot -name "$(temp)"  your sensors output may be more complex, depending on your setup: this works on one of my machines:   awk '/temp1/ {print +$2"°c"}' &lt;(sensors)  if you patch in statuscolours, you can additionally have the output change colour as the $temp hits higher values...  the arch wiki has an introduction to setting up a basic statusbar script and the dwm site includes an .xinitrc example.  you can see my dwm-status script for more details: http://beta.intuxication.org/jasonwryan/archer/file/tip/scripts/dwm-status 
edit the file /etc/default/grub and set your parameter in grub_cmdline_linux
this happens when the server is within the dns search domain you have configured.  for example, my current search domain is example.com:  $ grep ^search /etc/resolv.conf search example.com   i can now do the following transparently:  $ ping foo.example.com ping foo.example.com (127.0.0.1) 56(84) bytes of data. ^c $ ping foo ping foo.example.com (127.0.0.1) 56(84) bytes of data. ^c   search domains allow automatic translation between the machine's name and the fully qualified domain name (fqdn). 
the best luck i had was with mime-construct, written in perl
you can use rapper tool for validation or http://jena.sourceforge.net/eyeball/ 
see this article on omg ubuntu
both vmware and virtualbox can run a 64-bit virtual machine on a 32-bit host system, if you have a 64-bit processor
this was caused by a kernel bug present in linux kernels 4.7.0 to 4.7.4 (it's fixed by this commit in 4.7.5 and this commit in 4.8.0). 
andcoz's answer provided me with a good search term, i.e
some "cool" docker features like port binding, mounting filesystems etc
the purpose of the -n option of route is to suppress address-to-name lookups
if you need to run it after the x server is started, it's probably more appropriate to start it using your desktop environment's settings, rather than attempting to cobble up something with systemd (although you could launch it with systemd in user session mode, but including your x launch in there may take some more work that would only be tangential to your goal, depending on how complex your setup is).  if you're using startx/xinit, just add the program to ~/.xinitrc, backgrounded:  /path/to/program &amp;   otherwise, find your startup settings in your desktop environment, and add the program there, so that it launches shortly afterwards.  since it is now clear that you are running gnome 3, you can run gnome-session-properties from alt+f2, and add the program to the startup list there.  as the program needs superuser permissions to function, you need some way of elevating without being prompted for a password
in increasing order of helpfulness:    if you identify a bug, report it with as much relevant information as possible (to make it easy for the maintainers to reproduce and then fix)
i'm not familiar with a syslog implementation that has a command line option to flush logs to disk
this worked:  ~]$ sudo yum install -- '*python*' -python3-queuelib -python-django-federated-login -gcc-python3-plugin -python-qpid_messaging -gcc-python2-plugin -gcc-python3-debug-plugin -python-django* -django* -gcc-python2-debug-plugin -python3-django15-1.5.8-1 python-django-bash-completion* -python-django15*  
you can do it with the shell alone (works in bash, dash, ksh, zsh):  df 
dumping a tarball of / is likely not going to work very well, as you end up overwriting a ton of stuff specific to the "new" machine
there are currently 3 main init systems used by linux
the only way to be sure is to let it run and inspect the results
what about just getting the structure and recreating it?  mkdir $( from=/copy/from;          to=/copy/it/here;          ssh -q username@192.168.78.331 "find $from -type d" \          | sed "s=^$from/\?=$to/=" )   i used sed to remove the absolute path prefix and replace it with the target one
this should work (tested on linux, from bash)  diff &lt;(ls | cut -c 1-4) &lt;(ls | cut -c 1-4 | uniq)   or in general, lets have two commands cmd1 and cmd2 which produces some output  diff &lt;(cmd1) &lt;(cmd2)  
it is pretty easy to build it from sources if you need it on your development machine: https://github.com/couchbase/manifest#building-with-repo  repo init -u git://github.com/couchbase/manifest.git -m rel-3.0.1.xml repo sync make   it will install server for you to $pwd/install 
you could try sourcing the new environment files
so, this is a samba share, mounted on a linux box (clients using windows don't have the issue)? if i understand well, it could be only a umask issue
checking the source code is the way to go: tmux only looks at the system's notion of the size in check-size, and before that, when attaching to or creating a session, it starts with 24x80
pvcreate /dev/sda4  pvcreate /dev/sda5  pvcreate /dev/sda6  vgcreate bigvolgrp /dev/sda4 /dev/sda5 /dev/sda6   lvcreate -n bigvolume -l 45g bigvolgrp  mkdir /bigstore mkfs -t ext3 /dev/bigvolgrp/bigvolume mount /dev/bigvolgrp/bigvolume /bigstore  df -h /bigstore   #to verify  
in bash with "parameter expansion" ${parameter:offset:length}  $ var=abcdef $ echo ${var:0:1} a $ echo ${var:3:1} d   edit: without parameter expansion (not very elegant, but that's what came to me first)  $ charpos() { pos=$1;shift; echo "$@"|sed 's/^.\{'$pos'\}\(.\).*$/\1/';} $ charpos 8 what ever here r  
answer to question 1 - how to start after one drive failing  i could restore the raid 1 by doing the following steps:   i took a somehow formatted drive (say c) and plugged it to the same sata port where the defective drive b was before. after that i started the computer and in the boot menu i pressed e to edit the command before booting according to wiki.ubuntuusers.de by the following way:  a
bash uses &lt;&gt; to create a read-write file descriptor:     the redirection operator  [n]&lt;&gt;word       causes the file whose name is the expansion of word to be opened for both reading and writing on file descriptor n, or on file descriptor 0 if n is not specified
$ awk 'fnr==nr{n+=nf;a[n]=" ";next} fnr&gt;1{for(i=1;i&lt;=nf;i++)printf "%s%s",$i,a[i]; print""}' file1 file2 112 1 2 01  000 0 0 22  122 2 2 22    how it works  we first read file1 and use the number of fields on each line to determine where spaces should be inserted in the output
   it seems that most java server machines use red hat   that may be true (i don't know), although it's probably reasons other than this provides some particular advantage with regard to java
you can also use the -d switch of ls:  $ ls -ld / drwxr-xr-x 28 root root 126976 mar 20 17:11 /   from man ls:     -l     use a long listing format    -d, --directory           list  directory entries instead of contents, and do not derefer‐           ence symbolic links  
root has full access on your system, but doesn't necessarily have all the keys to other systems that your normal user account has.  so the trouble is:  rsync -avz /home/user/backup user@myserver:/home/user/                              ^^^^   if you cause root to execute this command as you, your keys will be used and the command will be successful:  sudo -u user rsync -avz /home/user/backup user@myserver:/home/user/   alternatively, you could install root's public key as an accepted ssh key for user on the myserver system. 
there are two command line interfaces to printing:   in the bsd interface, use lpr to print, lpq to view pending jobs, lprm to cancel a job. in the system v interface, use lp to print, lpstat to view pending jobs, cancel to cancel ongoing jobs.   there are several printing systems available for linux and other unices
here's some fairly typical syntax
dw (capital w) or more generally you can do df followed by the character to search for, in this case space
unix systems don't really have a “system language”
in order to use the man command, you must also install the man package before or after the man-pages one  # yum install man-pages ..
copied from ji m's ubuntu handbook:     open your file browser and navigate to “computer-> sys -> class ->   backlight” directory
use single quotes
according to the documentation, history -a should append the ``new'' history lines (history lines entered since the  beginning of the current bash session) to the history file. 
bash stores the values of aliases in an array called bash_aliases:  $ alias foo=bar $ echo ${bash_aliases[foo]} bar   with parameter expansion we can get the either the last set alias (if exists) or the default value:  alias grep="${bash_aliases[grep]:-grep} -i --exclude=\*~"   now just do it on setup-java.sh:  alias grep="${bash_aliases[grep]:-grep} -i --exclude=\*~  --exclude-dir=classes"   ...and finally on setup-sass.sh:  alias grep="${bash_aliases[grep]:-grep} -i --exclude=\*~ --exclude-dir=\*/.sass-cache"   if the three lines are called, we get what we want:  $ echo ${bash_aliases[grep]:-grep} grep -i --exclude=\*~ -i --exclude=\*~ --exclude-dir=classes -i --exclude=\*~ --exclude-dir=\*/.sass-cache  
i have just simulated clean installation of linux mint kde 17.2 in a vm and installed cinnamon using this command:  sudo apt-get install --install-recommends cinnamon   saying yes to every question.  for some reason the first try failed, but the second succeeded.  but to the point
a kernel module is a bit of compiled code that can be inserted into the kernel at run-time, such as with insmod or modprobe.  a driver is a bit of code that runs in the kernel to talk to some hardware device
you may want  echo first &amp;&amp; echo second &amp;&amp; echo third &amp; wait   which gives you the output (similar to)  [1] 4242 first second third  [1]+ done   the last &amp; puts the whole previous command in a pipeline/job
i don't know your sed version, but my suspicion is that it doesn't support those word barrier markers:  sed '/ oliva /c\ sergio oliva cuba 1967 1968 1969 ' &lt;&lt;\data larry scott usa 1965 1966 sergio oliva usa 1967 1968 1969 arnold schwarzenegger osterreich 1970 1971 1972 1973 1974 1975 franco columu argentinien 1976 1981 chris dickerson usa 1982 samir bannout libanon 1984 lee haney usa 1984 1985 1986 1987 1988 1989 1990 1991 dorian yates grossbritannien 1992 1993 1994 1995 1996 1997 ronnie coleman usa 1998 1999 2000 2001 2002 2003 2004 data   output  larry scott usa 1965 1966  sergio oliva cuba 1967 1968 1969 arnold schwarzenegger osterreich 1970 1971 1972 1973 1974 1975 franco columu argentinien 1976 1981 chris dickerson usa 1982 samir bannout libanon 1984 lee haney usa 1984 1985 1986 1987 1988 1989 1990 1991 dorian yates grossbritannien 1992 1993 1994 1995 1996 1997 ronnie coleman usa 1998 1999 2000 2001 2002 2003 2004    you see - those barriers can only serve to handle both space and/or newline on either side
you can't
just run:  $ shopt extglob   it will return the current status:  $ shopt extglob  extglob         on $ shopt -u extglob  $ shopt extglob  extglob         off   to show all options, just run:  $ shopt  
the default ssh settings make for a pretty slow connection
source is not an executable (source is a bash shell built-in command that executes the content of the file passed as argument)  you should run source like this:  docker run --rm -ti _image_name_ bash -c 'source file'  
the feature is called controlmaster which does multiplexing over one existing channel
this reverses the file line by line.  sed '1!g;h;$!d' file  first, sed has a hold space and a pattern space
apparently, this is done by simply creating a new volume and then copying over the data from the original one with:  dd if=/dev/mapper/original_thin_volume of=/dev/mapper/new_thin_volume conv=sparse  
i had something like this happen a while back and we eventually tracked it down to some postscript code which told the printer to print in negative, but was not revoked, and was persistent through reboot.  rest to defaults fixed it, but it took us a while going back through the logs to figure it out. 
one way using perl:  content of script.pl:  use warnings; use strict;  ## check arguments. die qq[usage: perl $0 &lt;input-file&gt;\n] unless @argv == 1;  my (@alpha, @digit);  while ( &lt;&gt; ) {         ## omit blank lines.         next if m/\a\s*\z/;          ## remove leading and trailing spaces.         s/\a\s*//;         s/\s*\z//;          ## save alphanumeric fields and fields with         ## only digits to different arrays.         if ( m/\a[[:alpha:]]+\z/ ) {                 push @alpha, $_;         }         elsif ( m/\a[[:digit:]]+\z/ ) {                 push @digit, $_;         } }  ## get same positions from both arrays and print them ## in the same line. for my $i ( 0 .
in your case i do not believe resize2fs will work without serious games, as it assumes that the start does not move
that is a feature of the for compound command, as described by help for:     for: for name [in words ..
at a very basic level,  nohup cnetworkmanager -c 'essid' --unprotected &amp;   but it might be worth thinking about writing it as a daemon, or a service of some kind if the tool doesn't already support it.  you could also run it in the foreground, then background it,  cnetworkmanager -c 'essid' --unprotected   then hit ctrl-z which drops you to the command line with the program 'stopped', at which point you background it using,  bg   the advantage being (over nohup) you can foreground it later using  fg   and interact with it. 
ls -l on a folder tries to stat its contents, whereas ls doesn't:  $ strace ls folder -l ... lstat("folder/innerfolder", {st_mode=s_ifreg|0644, st_size=0, ...}) = 0 getxattr("folder/innerfolder", "system.posix_acl_access", 0x0, 0) = -1 enodata (no data available) getxattr("folder/innerfolder", "system.posix_acl_default", 0x0, 0) = -1 enodata (no data available) lstat("folder/innerfile", {st_mode=s_ifdir|0755, st_size=40, ...}) = 0 getxattr("folder/innerfile", "system.posix_acl_access", 0x0, 0) = -1 enodata (no data available) getxattr("folder/innerfile", "system.posix_acl_default", 0x0, 0) = -1 enodata (no data available) ...   that's why you get a "permission denied" with ls -l and not with ls. 
you have another entry in the sudoers file which also matches your user
connecting over the network (e.g
this doesn't exactly answer your question, but...  first of all, elf is the specification use by linux for executable files (programs), shared libraries, and also object files which are the intermediate files found when compiling software
installing gcc puts a libstdc++.so.6 into both $prexif/lib and $prefix/lib64
since you're on ubuntu, the pager used to visualise man pages is probably gnu less.  as you can see after pressing h:     esc-u                undo (toggle) search highlighting.   in most terminals, it should be equivalent to alt+u. 
you should be able to choose the language at the login screen
to extract your files, you need to use gzip:  gzip -d *.jpg.gz   you mention doing this recursively; given that you don't have find, you'll have to visit each directory in turn and run the above command. 
to quote wikipedia:     in computing, hardening is usually the process of securing a system by reducing its surface of vulnerability
bumblebee-nvidia is indeed in contrib; to add contrib and non-free, you need to edit your /etc/apt/sources.list file, and add contrib non-free at the end of lines starting with deb
you can create an mdraid raid-1 array starting with an existing partition
you can use two greps connected by a pipe:  grep -r '.\{100\}' /path | grep 'if'   to exclude files with if in their paths or names, use ':.*if' instead of 'if' (could still break if your filenames or paths contain colons). 
2&gt;&amp;1 &gt;&gt;outputfile | tee --append outputfile   for easy testing:  echo -n &gt;outputfile; bash -c "echo stdout &gt;&amp;1; echo stderr &gt;&amp;2" 2&gt;&amp;1 &gt;&gt;outputfile |   tee --append outputfile; echo "outputfile:"; cat outputfile   edit 1:  this works by writing stdout (only) to the file, making sterr stdout so that it goes through the pipe, and having tee write its output to the same file.  both writes must be done in append mode (&gt;&gt; instead of &gt;) otherwise both would overwrite each others output.  as the pipe is a buffer there is no guarantee that the output appears in the file in the right order
you could pull the names from under a heading with, say awk and toss them in an array variable, then iterate over the array with for
adding defaults editor=/path/to/editor in the sudoers file will cause visudo to use the specified editor for changes.  additionally, if your sudo package has been built with --with-env-editor, as is the default on some linux distributions, you can also set the editor environment variable by executing export editor=/path/to/editor
if you want to program a bash script, then change your shebang (first line of the script file) to  #!/bin/bash  
just stick with grep command as in number extraction:  grep -po "http.*?$find_number.*?\.jpg"  
new kali versions  type the following command:           apt-get update    apt-get install open-vm-tools-desktop fuse    reboot   if this install is failed , you need to istall linux-headers.  apt-get install -y linux-headers-$(uname -r)   old kali versions:  install vmware-tool patche  cd ~ apt-get install git gcc make linux-headers-$(uname -r) git clone https://github.com/rasa/vmware-tools-patches.git cd vmware-tools-patches   mount the vmware tools iso by clicking “install vmware tools”  copy the installer to the downloads directory and then run the installer script :  example:     cd ~/vmware-tools-patches    cp /media/cdrom/vmwaretools-9.9.0-2304977.tar.gz downloads/  ./untar-and-patch-and-compile.sh   change vmwaretools-9.9.0-2304977.tar.gz with your current version 
use copy-paste: m-d c-_ m-x replace-string ret c-y (kill-word, undo, replace-string, yank)
you might try the fold command:  echo "$mystring" | fold -w 30  
assuming getdatabase1 and getdatabase2 are commands that print their counts to stdout you should be able to change your assignments to  var1=$(getdatabase1) var2=$(getdatabase2) var3=$((var1+var2)) printf "%s\n%s\n%s\n" "$var1" "$var2" "$var3" &gt; file.txt   the $(...) syntax runs the command between the parens and "returns" the stdout of that command, which we here save to our variables
python:  python -c 'import crypt; print crypt.crypt("password", "$6$saltsalt$")'   (for python 3 and greater it will be print(crypt.crypt(..., ...)))  perl:  perl -e 'print crypt("password","\$6\$saltsalt\$") 
the following excerpt from this essay potentially explains why that directory refuses to be deleted:     nfsv4 requires that all filenames be exchanged using utf-8 over the wire
i've previously used a plugin for this
the problem was with the use of -i as this option includes the headers in the output.  the strange thing is that unless you do echo "$access_token" you won't see the headers polluting the rest response coming back.  simply remove -i and it should work. 
so i went and tried mounting the usb stick with pmount /dev/sdb1 /mnt/blah and it it gives a more useful message than the gui dialogue:  warning: device /dev/sdb1 is already handled by /etc/fstab, supplied label is ignored mount: wrong fs type, bad option, bad superblock on /dev/sdb1,        missing codepage or helper program, or other error        in some cases useful info is found in syslog - try        dmesg | tail  or so   this led me to find that "/etc/fstab" actually has an entry for /dev/sdb1:  /dev/sdb1       /media/cdrom0   udf,iso9660 user,noauto     0       0   the reason for this is that my stick was actually attached while installing debian squeeze, and so got automatically added in there
you appear to be using gnu tar
to start the vm in headless mode with password, you need to create a file containing the password, suppose:  /home/user/vmname-password   then you need to execute the two following commands:  vboxmanage startvm "vmname" --type headless  vboxmanage controlvm "vmname" addencpassword "vmname" "/home/user/vm-name-password"   this is just an example
openssl s_client -connect server:port display some informations
on arch, ubuntu/debian family and the later redhat/centos/fedora systems, you blacklist the module by adding bluetooth.blacklist=yes at boot time.  if you're using redhat 6 and it's derivatives you can use the rdblacklist=bluetooth boot option to blacklist a module (assuming the module is called bluetooth on these systems). 
solution:   you haven't configured dns name resolution for your servername and have to set the servername either in the /etc/hosts manually or in your dns server.  debug process:  in the case of nt_status_io_timeout try to use a network traffic analyser like tcpdump
with bash 4  mapfile -t &lt;list paste "${mapfile[@]}" | column -s $'\t' -t   for the paste {list}/pqr/a/sum version of the question  mapfile -t &lt;list paste "${mapfile[@]/%//pqr/a/sum}" | column -s $'\t' -t      
well, asides from the obvious security holes that vnc causes (seriously, key stokes are sent unencrypted so anyone in the middle can grab a password), you're going to want to make sure that you have to adjust your firewall which is in:  applications -> firewall -> enter your root password -> services -> vnc-server  enable it, quit, and make sure that vnc is started and enabled.  you can always check from your mac machine by using nmap against it. 
you could use xmlstarlet (aka xml) as a xslt transformer and write a specific csv transform as mentioned here http://stackoverflow.com/a/952389/1481060  
a first step is determining what you want...i.e
there is "newmail fifo path" configuration option in alpine
an awk solution seen on #bash (freenode):  awk '!seen[$0]++' filename  
ideally, you should install the gnome meta-package to ensure that you have all of the required packages installed, particularly dbus - i'd highly recommend you do that.  once you've installed the gnome meta package, follow the post-installation instructions in /usr/local/share/doc/pkg-readme for the gnome version you installed (check the file gnome-{version} where {version} is the gnome version)
i would probably write it as a loop over the glob-generated names:  for f in [abcde].png; do     convert "$f" -resize 50% "${f%.png}"_half.png done   note: nothing in the above example is specific to zsh; it should work in any posix-compatible shell (dash, ksh, bash, zsh, etc.; including just about any modern version of sh).  stephane chazelas also notes that zsh has a different default behavior for when the glob fails to match any files: it gives an error message instead of using the pattern itself as the sole “result” of the expansion
rrdtool's whole purpose of existence is plotting time series data, but it's primarily meant for automated graphing and may not be the best fit for your needs
i believe if you set /etc/selinux/config to disabled reboot
you should use the --no-collapse option, instead of --tab-correct, and insert literal tabs in your string, for example with  "star "$'\t'" end"    or using ctrl-v and pressing the tab key. 
first of all your message already contains the program name:   kernel: [11.895392] init: failsafe main process (631) killed by term signal   this means that the program failsafe with the pid 631 received a term signal.  to answer your original question, no most linux distributions don't log the pids of created processes per default but you can use the audit framework and create the necessary rules to log all created processes
you can use heredoc if you want to keep the source of both bash and python scripts together
as daveh's answer points out, that could be as simple as just issuing ssh nawshad@ipaddress.  however, chances are that your pc is not accessible directly from the internet, i.e
df reports the percentage of used blocks relative to the blocks not reserved for root use (by default i think it's 5% of the drive in ext3)
no, env is not guaranteed to be in /usr/bin, as you can read in the history of the shebang mechanism, in the section "the env utility":     however, the location of env(1) might vary
the grep command is designed to show only matching lines of a given files
you missing quote in your sed expression.  try:  $ vara="asd# 1" $ echo "$(sed 's/#/\\#/g' &lt;&lt;&lt; "${vara}")" asd\# 1  
i believe what you are looking for is the -s option
try this to make your current machine id permanent:  # mount --bind / /mnt # cp /etc/machine-id /mnt/etc/machine-id # reboot   this should get rid of the tmpfs mount over /etc/machine-id. 
the user list can be used to define which users are allowed to run sudo.  the runas list can be used to define the accounts an authorized user can "run commands as".  user_alias admins = %admin, root runas_alias services = apache, tomcat admins all=(services) all   would allow users of the admin group and root run any command as either apache or tomcat  sudo -u apache whatever  
according to udev manual, there's no way to change the names of files in the /dev/ directory:  name the name to use for a network interface
use */ to match only directories.  chmod g+s /var/www/*/   to match all directories and subdirectories use **/*/ (provided you have globstar enabled in bash):  shopt -s globstar chmod g+s /var/www/**/*/  
there is no need to do this, the kernel manages ram efficiently by using it for caches and buffers if it is not needed by processes
presumably they do it for technical reasons like everyone else.  here's the output of grep -r microsoft 
one (admittedly not perfect) way is to add the result of ps --no-headers -o comm $ppid to your shell prompt
cp does not know about opened files
i use a simple script with at:  #!/bin/bash # email reminder notes using at(1)...  read -p "time of message? [hh:mm] " time read -p "date of message? [dd.mm.yy] " date read -p "message body? " message  at "$time" "$date" &lt;&lt;eof echo "$message" | mailx -s "reminder" me@gmail.com eof   you could just as easily pipe the $message to notify-send or dzen if you wanted a desktop notification instead of an email. 
here's a rudimentary function that i think can serve as starting point
write it the more portable way:  (cd ../files &amp;&amp; tar cf - results.*.log) |    gzip -9 &gt; ../archives/archive.tar.gz  
the easiest way is to convert the date string to epoch time, which is counted in seconds since 1970-01-01 00:00:00 utc, and compare the number of seconds.  to get the current date in seconds, do:  [jenny@finch ~]$ date +%s 1464162079   to get the date from the date string above, do  [jenny@finch ~]$ date -d 'oct 8 13:48:27 2020 gmt'  +%s 1602164907   a week is 604800 seconds, so check whether the difference between the two times is less than that. 
at last, after almost six weeks of frustrated, numerous, attempted solutions based on suggestions by kind friends and internet question sites, i have solved the problem (i think -- i am cautiously optimistic)
you can monitor the opening/closing of files using the inotify subsystem. pyinotify is one interface to this subsystem.  note that if you have a lot of events going to inotify, some can be dropped, but it works for most cases (especially your case in which user interaction will drive the opening/closing of files).  pyinotify is available via easy_install/pip and at https://github.com/seb-m/pyinotify/wiki  mwe (based on http://www.saltycrane.com/blog/2010/04/monitoring-filesystem-python-and-pyinotify/):  #!/usr/bin/env python import pyinotify  class myeventhandler(pyinotify.processevent):     def process_in_close_nowrite(self, event):         print "file closed:", event.pathname      def process_in_open(self, event):         print "file opened::", event.pathname  def main():     # watch manager (stores watches, you can add multiple dirs)     wm = pyinotify.watchmanager()     # user's music is in /tmp/music, watch recursively     wm.add_watch('/tmp/music', pyinotify.all_events, rec=true)      # previously defined event handler class     eh = myeventhandler()      # register the event handler with the notifier and listen for events     notifier = pyinotify.notifier(wm, eh)     notifier.loop()  if __name__ == '__main__':     main()   this is quite low-level information - you might be surprised how often your program uses these low-level open/close events
you can do it without calling login shell:  sudo dummy=dummy su ec2-user -c 'echo "$dummy"'   or:  sudo dummy=dummy su -p - ec2-user -c 'echo "$dummy"'   the -p option of su command preserve environment variables
i think you want to use timeout, e.g.  timeout 1s myrunner $app  
you can specify the number of characters to read with -n
well, i imagine 2 situations here:   if i need to run a small number of commands i would just run them again on any other machine (by small number i mean less then 10) if i need to run many commands i would put them into a bash script and run the script on all the other machines
the directory /var/tmp should have permissions rwxrwxrwt, which allow anyone to change to this directory, create and read files in this directory and write/rename/delete files they own (this last restriction is caused by the t in the permissions, which is the "sticky bit").  the file you see in there is a temporary file created by something on your system
for accepting port 22  -a input -m state --state new -m tcp -p tcp --dport 22 -j accept   for ports 1000-1100  -a input -m state --state new -m tcp -p tcp --dport 1000:1100 -j accept   if you enter these lines into /etc/sysconfig/iptables file on your linux machine and restart iptables service with service iptables restart command, you should be good to go. 
awk '/^$/ {nlstack=nlstack "\n";next;} {printf "%s",nlstack; nlstack=""; print;}' file  
no, but you could build git without the curl dependency on libcurl
use rsync's option -k (--keep-dirlinks)
you can always try the obvious things like ^c, ^d (eof), escape etc., but if all fails i usually end up suspending the command with ^z (control-z) which puts me back into the shell
the kernel documentation provides a general coverage of cgroups with examples.  the cgroups-bin package (which depends on libcgroup1) already provided by the distribution should be fine.  configuration is done by editing the following two files:  /etc/cgconfig.conf   used by libcgroup to define control groups, their parameters and mount points.  /etc/cgrules.conf   used by libcgroup to define the control groups to which the process belongs to.  those configuration files already have examples in it, so try adjusting them to your requirements
the different semantics between hard and soft links make them suitable for different things.  hard links:   indistinguishable from other directory entries, because every directory entry is hard link "original" can be moved or deleted without breaking other hard links to the same inode only possible within the same filesystem permissions must be the same as those on the "original" (permissions are stored in the inode, not the directory entry) can only be made to files, not directories   symbolic links (soft links)   simply records that point to another file path
yes, rsync is the answer.  having the drive plugged in locally is going to be a lot faster than the network, but for the purpose of doing backups, i would actually recommend leaving the hardware in place
turns out, surprise surprise, this is a ubuntu-specific thing.    the cause  the problem: although the kernel has cgroups enabled (check with grep cgroup /boot/config-$(uname -r)) and cgmanager is running, there is no cgroup specific to my user
perl -i$home/perl5/lib/perl5 -mlocal::lib prints out some shell code
use this instead:  cp -r inputfolder/
issue #1 - vm networking types  there are 3 modes of networking:    nat host only bridged   details on setting them up   this au  q&amp;a titled: "in virtualbox, how do i set up host-only virtual machines that can access the internet?", shows how to do #2. this article titled: "how to setup virtualbox guest additions and network", shows how to do #3.   when to use each?   #1: for development of facebook/web apps that are on other servers #2: if you want to build your own app, and test it from the virtualbox host (not just the guest vm) #3: if you want to build an app and test it from other systems on lan   issue #2 - firewall blocking?  depending on which distro you're using, the firewall might be blocking your web browser from accessing your apache instance
all of the following methods print whatever is within [ and ] but only if that is the last field:  ps aux | awk '$nf~/\[/{print $nf}'   the advantage is that it will only match a [ in the last field
you may see some slight differences in resource usage from one distro to another when using the same desktop configured in the same way, but it should not be significant.  in other words, as ulrich said, no there is not a reason to prefer one to the other from this point of view! 
what cd am i using?  if you're in bash cd is a builtin
dan, changing the priority number of stable when running stable is generally a big no-no, afaik, and does not really make sense
if you look through the man page for tidy you'll notice a comment that says the following:     name of the default configuration file
it does not work because in zsh, globbing is not done by default upon variable expansion
in short:  to know if it's compressed already:  strings your.pdf | grep /filter  to (un)compress a pdf, use qpdf  qpdf --stream-data=compress your.pdf compressed.pdf qpdf --stream-data=uncompress compressed.pdf uncompressed.pdf     explanation:  the "filter" keyword inside a pdf file is a indicator of the compression method used
this may be a bit late, but "[hamachi] can now be installed without [the] lsb package." 
subshells do have overhead.  on my system,  the minimal fork-exec cost (when you run a program from disk when the file ins't cold) is about 2ms and the minimal forking cost is about 1ms
the backport kernel is useful for people who have newer hardware requiring more recent drivers than what the stable release can offer.  installing a kernel from unstable or testing on an installation of stable would be difficult: you'd have to add unstable or testing as a source, and write a proper preferences file to only get the kernel
use getopts.  it is fairly portable as it is in the posix spec
using awk (and assuming that the output you wish to capture is the third field):  awk '/create table/ {printf "%s\n", "drop table "$3" cascade;"}' datadump.sql drop table agency cascade; drop table agency_contact cascade;  
for the majority of cases, you can use ldd to determine the libraries an executable is linked against.  for example:  # ldd /usr/bin/xz   linux-vdso.so.1 (0x00007fff06358000)   liblzma.so.5 =&gt; /lib64/liblzma.so.5 (0x00007fd6a1358000)   libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007fd6a1138000)   libc.so.6 =&gt; /lib64/libc.so.6 (0x00007fd6a0d88000)   /lib64/ld-linux-x86-64.so.2 (0x00007fd6a1590000)   now if i wanted to i could copy these libs into a custom path
the tilde character is shorthand for the home directory of the current logged-in user
if you reap a zombie before its parent, you lose whatever effect the reaping would have in the parent
use either skill -u uid or pkill -u uid.  skill was a linux-specific and is now outdated, and pkill is more portable (linux, solaris, bsd)  i think, both utilites have no access to any list other than full list of processes (or readdir of /proc)
try purging the 8.8.5 from your rpmdb
i believe you could try (?:(?!x).) with pcre, it definitely works when x is a string but i am not a 100% sure that it would work all the time when x is a regex.  echo "dust mite" | grep -p '^(?:(?!abc).)*$' dust mite  echo "dust abc mite" | grep -p '^(?:(?!abc).)*$' echo "dust mite" | grep -p '^(?:(?!abc(x+y)).)*$' dust mite  echo "dust abcxxxxy mite" | grep -p '^(?:(?!abc(x+y)).)*$'  
you have to put the declaration in the initialization files of your shell:   if you are using bash, ash, ksh or some other bourne-style shell, you can add  abc="123"; export abc   in your .profile file (${home}/.profile)
looks like the problem has to do with the fact that i use initrd from netboot
is there a reason you want to use 7z specifically, or do you just want better compression than gzip?  the xz utility uses the same compression algorithm as 7z (lzma), and allows piped compression the same as gzip.  tar cvf ..
you can do something like that by adding  \[\e[f\e[k\]   at the beginning of your prompt variable (ps1)
i suppose the trick is to use -3t for the first pr, and then also add -w200 (or so) to avoid that the last column gets clipped.  more generally, if you have n matrices, you'd use pr -${n}t -w $((n*w)) as first pr command, where w is the character width of the one matrix (say, roughly 10 for each column plus a bit).  all else should be fine. 
that would be groff. (older unix version use nroff or troff, but they are all different programs in the same family.)  please note that it is not a simple command that operates on a text-file
a partition name is a name given in the gpt; it's external to the partition itself
sed -e "$(awk '/^[[:space:]]*(#|$)/ { next } ;                { print "s/ proto="$2" / proto="$3" /;" }' \           /etc/protocols)" /path/to/iptables.log   this uses awk to construct a sed script from fields 2 and 3 of the /etc/protocols file
you need a keyring or keychain to maintain the ssh-agent auth socket location for you.  on centos you can install keychain, see http://www.cyberciti.biz/faq/ssh-passwordless-login-with-keychain-for-scripts/ for a detail guide on how to setup keychain on centos
in "vi" mode you can edit/navigate on the current shell prompt like a line in the vi editor
try this:  echo $(( 100 * $( cut -d' ' -f10 access_log|grep "2.."|wc -l) / $(cut -d' ' -f10 access_log|wc -l) ))   bash can only handle integers. 
this is heavily dependent on the set up of the system
these characters ? and : are not valid on a fat32 filesystem, so if that is where you need to copy your files you will need to rename them.  from the command line you can use command-line tools such as rename (sometimes known as prename) to replace these characters with _ or even to remove them:  rename 's/[?&lt;&gt;\\:*|\"]/_/g'    # change invalid characters to _ rename 's/[?&lt;&gt;\\:*|\"]//g'     # remove invalid characters   i am not familiar with thunar so i do not know if there is a way to perform this substitution/replacement operation directly.  i have just found linux copy to fat32 filesystem: invalid argument which suggests adding this into the pax command (another tool to copy files), so that you can keep your full filenames on your local disk but convert the filenames during the copy to your usb device:  pax -rw -s '/[?&lt;&gt;\\:*|\"]/_/gp' *.mp3 /media/usb_device   if the complete filenames are really important to you, i would suggest that you reformat the usb stick to use a linux-native filesystem such as ext4
   permgen space is used for things that do not change (or change often).   e.g
more closely monitoring the system it's power consumption using a "watts up?" watt meter lead to a stronger belief that these restarts were caused by an over current protection (ocp) on the power supply that kicks in.  asking why the power consumption increase was happing 15 minutes after boot, lead to a serverfault answer that 15 minutes after boot all 74 drives might start running their automatic offline s.m.a.r.t
dot meaning "this directory" dot dot meaning prev directory
# echo -n admin123 | makepasswd --crypt-md5 --clearfrom - admin123     $1$zunnslzq$xsvifc1bhucsr3f8azmpt/   as commented bellow this command is unsecure
http://wiki.xen.org/wiki/vtd_howto:     even when the chipset supports iommu, the bios must have a acpi ivrs table to enable the use of it! so actual support depends on the motherboard manufacturer
i tried this out and it seems to work as expected:  echo "1.2.3.4    facebook.com" &gt;&gt; /etc/hosts  then i ran:  $ getent ahosts facebook.com 1.2.3.4         stream facebook.com 1.2.3.4         dgram   1.2.3.4         ra   i hope this helps you! 
convert, the imagemagick utility used in ketan's answer, also allows you to write something like  convert xc:none -page letter a.pdf   or  convert xc:none -page a4 a.pdf   or (for horizontal a4 paper)  convert xc:none -page 842x595 a.pdf   etc., without creating an empty text file
devices do not have uuids.  partitions do
you can use a while loop in a shell script:    failed=1 # any number not equal to zero while [ $failed -ne 0 ] do    ping -n 8.8.8.8    failed=$? done # after the  $? becomes "0" it will get out of the while loop echo "ping succeeded"   to stop keep printing the connect: network is unreachable message you can edit the line with ping like this:  ping -n 8.8.8.8 2&gt; /dev/null   or you can add a sleep in the loop to reduce the number of those messages.  the script can be simplified to  while ! ping -n 8.8.8.8 do     sleep 1 done   which lets it be written in one line:  while ! ping -n 8.8.8.8; do sleep 1; done  
in your comment you clarify:     i'm actually looking for a single step option to ps or pgrep (or similar) which only outputs "active" processes...   i'm afraid you're out of luck with current ps/pgrep implementations.     post filtering like this relies on a full understanding of the intial output, which i don't have...   but you can get that understanding and, better yet, control that output as desired
see man top:     when this toggle is off, tasks that have not used any cpu since the last update will not be displayed.   thus the "cpu usage limit for a process to show up as idle or non-idle" is anything greater than 0. 
socks5 is just a transport protocol on top of tcp/udp but below application layer
$ a=b $ printf $a b $ b=hello $ a=$b   $ printf $b hello   basically a=b makes a variable called a of which value is a literal b
if you do:  nc -l -p 7007 | nc -l -p 9001   then anything that comes in to port 7007 will be piped to the second netcat and be relayed to your telnet session on port 9001.  injecting headers requires knowing the underlying protocol, at least to figure out "message" boundaries, so it's not trivial
here is how:  switch online/offline - sudo /etc/init.d/httpd stop|start stop all services     - sudo /etc/init.d/httpd stop restart all services  - sudo /etc/init.d/httpd restart start all services    - sudo /etc/init.d/httpd start  put all that script in a shell script and run it as   sudo sh ./start_services (args)  
you can use uniq(1) for this:  uniq -d file.txt   this will print out the duplicates only
that means one day + 4:38 hours of cumulative cpu time that has been used  by this process.  example  it's helpful to look at the column headers to understand the values.  $ ps -ef | head -5 uid        pid  ppid  c stime tty          time cmd root         1     0  0  2013 ?        00:00:01 /sbin/init root         2     0  0  2013 ?        00:00:00 [kthreadd] root         3     2  0  2013 ?        00:00:00 [migration/0] root         4     2  0  2013 ?        00:00:10 [ksoftirqd/0]   this bit from the ps man page explains the time format for that column.  by default, ps selects all processes with the same effective user id  (euid=euid) as the current user and associated with the same terminal as  the invoker
by default debian uses sysv init scripts with the start-stop-daemon binary
this worked for me with yad and zenity, and column id is not visible in gui:  zenity --list 1 "apples" 2 "peaches" 3 "pumpkin" 4 "pie" --column="id" \ --column="select your choice" --hide-column=1 --print-column=1   now, to achieve the same when input is a file you could pre-process the file with awk e.g. awk '{print nr};1' infile and pass the result to zenity. since, per the documentation:     zenity returns the entries in the first column of text of selected   rows to standard output.   your $item will only store the line no.(which is the entry in the 1st column), not the line content. to get the line content you have to process the file again and extract that line based on the line number
according to the error you get, you have put the stanzas from the gmail example in the wiki in the wrong sections
window focus is the job of the window manager
you might try --no-clobber
if what you really want is just to connect the notebook to your network, check if it has a pc card or pcmcia slot
this could be a lot of things.  sftp only has two configuration options - where and what to log
i found the solution by myself.  adding the virtual interface as permanent interface in /etc/sysconfig/network-script/ will let the server offer multi subnet with one real interface.  if the interface is added as temporary one  .(ex
when you run a new terminal emulator, that creates a new terminal (/dev/pts/number on linux)
in smartctl -a look for self-test execution status.  example when no test is running:  self-test execution status:      (   0) the previous self-test routine completed                                         without error or no self-test has ever                                         been run.   example while a test is running:  self-test execution status:      ( 249) self-test routine in progress...                                         90% of test remaining.   when running selective self-test (-t select) there will also be a progress shown here:  smart selective self-test log data structure revision number 1  span  min_lba    max_lba  current_test_status     1        0  125045423  self_test_in_progress [90% left] (2881512-2947047)  
the sysstat package includes mpstat
so apparently the settings and pipeline above are essentially good, and if you go to the alsa forums they'll recommend something like the above, but a matching rate on your outputs is something that must be considered in addition.  pcm.internal {   type hw   card 1   device 0   rate 48000 }  pcm.hdmi_hw {   type hw   card 0   device 7   rate 48000 }   my final config file, which includes volume controls for both the individual output devices, as well as their shared parent, and mixing across multiple playback processes, is the following:  pcm.m_headphone_mixed {  type dmix  ipc_key 595900  ipc_perm 0666  slave {   pcm "hw:1,0"    rate 48000   period_time 0   period_size 1024   buffer_size 4096   format s16_le  }  bindings {   0 0   1 1    } }  pcm.m_headphone_rate_adjusted {  type rate  slave {   pcm "m_headphone_mixed"   rate 48000  } }  pcm.m_headphone {  type softvol  slave.pcm m_headphone_rate_adjusted  control.name m_headphone_volume  control.card 1 }  pcm.m_hdmi_mixed {  type dmix  ipc_key 595901  ipc_perm 0666  slave {   pcm "hw:0,7"   rate 48000   period_time 0   period_size 1024   buffer_size 4096   format s16_le   channels 2  }  bindings {   0 0 # channel 0 -&gt; channel 0    1 1  } }  pcm.m_hdmi {  type softvol  slave.pcm "m_hdmi_mixed"  control.name m_hdmi_volume  control.card 1  }  pcm.m_all_base {  type plug   slave.pcm {    type multi    slaves {        a { channels 2 pcm "m_hdmi" }        b { channels 2 pcm "m_headphone" }    }    bindings [        { slave a channel 0 }        { slave a channel 1 }        { slave b channel 0 }        { slave b channel 1 }    ]  }  }  pcm.m_all_routed { type route  slave.pcm "m_all_base"  slave.channels 4   ttable [   [ 1 0 1 0 ] # route left to channels 0,2   [ 0 1 0 1 ] # route right to channels 1,3  ] }  pcm.m_all {  type softvol;  control.name m_all_volume;  control.card 1  slave.pcm "m_all_routed" }  pcm.!default "m_all"   this was done for a standard dell desktop pc to output simultaneously to the headphone jack and displayport. 
for historical reasons, the exit status of a process is an 8-bit number
i used to hit this in the past that actually my keyboard is not in very good condition, the ctrl key seems stucked down the keyboard until i hit it again
wget's -a option takes a comma-separated accept list, not just a single item.  wget --no-directories --content-disposition --restrict-file-names=nocontrol \     -e robots=off -a.pdf,.ppt,.doc -r url   see man wget and search for -a for more details. 
from the apt-cache man page:  search regex...    search performs a full text search on all available package lists for the     posix regex pattern given, see regex(7)
these errors will be passed to your terminal from generally one of two places
in your case sda is not online
control-a is readline keybinding that bash uses by default
while it is quite viable to use exim to send emails, your question reads like you are using the wrong tools for what ever your overall goal is
you can't
you can find out which module a device is using through these 2 methods
i deleted the unwanted library files with:  find -mtime -1 -maxdepth 1 -exec rm -rf {} \;  which finds the files and directories modified within one day under the current directory, and removes all of them. 
this is typically done using the tcsendbreak c library routine
you can force zfs to be loaded early by including it into a file in /etc/modules-load.d/*.conf
no.  there is nothing root can do to prevent root from undoing it later
avahi-daemon  avahi is a low-level service discovery mechanism
you tagged this under /nfs.
you can use apt-rdepends to build the complete set of dependencies (recursively), including the main package, then download that:  apt-get download $(apt-rdepends "${package}" | grep -v ^\ )   (replacing "${package}" of course). 
the two commands are not related in any way.  dpkg --get-selections returns the selection state of available packages
